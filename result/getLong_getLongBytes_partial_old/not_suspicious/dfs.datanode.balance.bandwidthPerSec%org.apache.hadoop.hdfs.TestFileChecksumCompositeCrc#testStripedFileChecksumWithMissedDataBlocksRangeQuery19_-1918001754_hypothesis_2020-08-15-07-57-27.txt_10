reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-362454571-172.17.0.11-1597478268377:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34929,DS-6d114a42-9a68-4c94-9208-776b5a609e46,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-807e66c5-c287-4d6c-b217-07669285c3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-7963a6e8-0fb1-47b8-8555-009acb7c2a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-ccce3d8b-463f-4217-b882-16ec44a32aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-0c89b92f-2a56-4e49-8dfc-fd3d4ccc5148,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-fb7089cb-742f-4999-a46c-4274c8226cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-535cf4ee-1eca-4c3b-a035-e903d3de72bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-d5239972-4d5c-4f1d-b74d-5755c82ad28c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-362454571-172.17.0.11-1597478268377:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34929,DS-6d114a42-9a68-4c94-9208-776b5a609e46,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-807e66c5-c287-4d6c-b217-07669285c3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-7963a6e8-0fb1-47b8-8555-009acb7c2a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-ccce3d8b-463f-4217-b882-16ec44a32aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-0c89b92f-2a56-4e49-8dfc-fd3d4ccc5148,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-fb7089cb-742f-4999-a46c-4274c8226cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-535cf4ee-1eca-4c3b-a035-e903d3de72bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-d5239972-4d5c-4f1d-b74d-5755c82ad28c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-284012786-172.17.0.11-1597478443093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44713,DS-8f37e6e7-8c15-48a0-a81d-528adda22a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-28b99e19-bc34-4aff-8896-0488c3a29e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-3cda36e0-eb99-437d-a4db-e64e6f0289bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-41260aa3-65f9-49f8-a7ca-f17ad3a78295,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-742224b1-c9b0-4598-8c9c-04dcd0cee354,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-cca8c798-10c7-4feb-8440-1c75953c1d89,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-dd72a3bb-4882-4f85-9f56-f3f9954168d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-c79935e6-398c-417a-a7fb-251e32731bb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-284012786-172.17.0.11-1597478443093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44713,DS-8f37e6e7-8c15-48a0-a81d-528adda22a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-28b99e19-bc34-4aff-8896-0488c3a29e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-3cda36e0-eb99-437d-a4db-e64e6f0289bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-41260aa3-65f9-49f8-a7ca-f17ad3a78295,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-742224b1-c9b0-4598-8c9c-04dcd0cee354,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-cca8c798-10c7-4feb-8440-1c75953c1d89,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-dd72a3bb-4882-4f85-9f56-f3f9954168d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-c79935e6-398c-417a-a7fb-251e32731bb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1151787101-172.17.0.11-1597478489116:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40060,DS-32e42309-b612-4b72-b9ea-b25ee3de347c,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-ee8d14ee-c093-432b-a79e-99a92f164a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-0eb521fe-5d94-4f27-91e4-9e06beebb7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-67013fc2-6542-4005-8878-4ba61d26b5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-88010d34-4d04-485f-aaf5-fa06df65a42d,DISK], DatanodeInfoWithStorage[127.0.0.1:36301,DS-3922bcc0-9c71-4cd3-9de3-33db379d4182,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-cf03d09c-b245-4581-9f6a-64083da8775f,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-0446dbaf-b8c7-4e85-aef1-15e946a2cd55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1151787101-172.17.0.11-1597478489116:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40060,DS-32e42309-b612-4b72-b9ea-b25ee3de347c,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-ee8d14ee-c093-432b-a79e-99a92f164a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-0eb521fe-5d94-4f27-91e4-9e06beebb7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-67013fc2-6542-4005-8878-4ba61d26b5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-88010d34-4d04-485f-aaf5-fa06df65a42d,DISK], DatanodeInfoWithStorage[127.0.0.1:36301,DS-3922bcc0-9c71-4cd3-9de3-33db379d4182,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-cf03d09c-b245-4581-9f6a-64083da8775f,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-0446dbaf-b8c7-4e85-aef1-15e946a2cd55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1647122087-172.17.0.11-1597478726122:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33109,DS-504b657b-7732-4e23-95b6-2c5cbbf0205c,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-b0ab1de4-d322-4574-a716-2ffeabc3f26a,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-d8a8c6f2-2086-4968-be9c-590645e284bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-4dcf5802-bee3-45b8-8e57-5d735c65e8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-659c767a-ce53-4842-96dd-8b82918e76eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41021,DS-95c2e736-b1db-4d8f-ba8a-0773ce8cf6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-0eeb5133-1bc4-44d4-b5aa-3171590d23d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-6e9a23e5-8c7a-414a-af4d-d3ace6d5913f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1647122087-172.17.0.11-1597478726122:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33109,DS-504b657b-7732-4e23-95b6-2c5cbbf0205c,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-b0ab1de4-d322-4574-a716-2ffeabc3f26a,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-d8a8c6f2-2086-4968-be9c-590645e284bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-4dcf5802-bee3-45b8-8e57-5d735c65e8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-659c767a-ce53-4842-96dd-8b82918e76eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41021,DS-95c2e736-b1db-4d8f-ba8a-0773ce8cf6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-0eeb5133-1bc4-44d4-b5aa-3171590d23d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-6e9a23e5-8c7a-414a-af4d-d3ace6d5913f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2068804178-172.17.0.11-1597478944911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42662,DS-72d1902c-2b7d-4965-aace-8ea1f42a6029,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-abcf064f-f422-4444-9bee-d33d5aea8dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:46117,DS-05d9dd5e-82d4-44ec-a63c-34437b76f7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-3d4b5143-80f0-491a-b11d-5ebffd3e9282,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-e03ae46e-df8b-45fe-ae05-6b574c000de5,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-6cdd2a63-ca86-4aeb-b447-a1d37b43df8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-eea5ad00-62f3-4638-bcd8-f3338068eddf,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-bcb80c1a-8f6d-4fe2-837b-67cbd983ab45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2068804178-172.17.0.11-1597478944911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42662,DS-72d1902c-2b7d-4965-aace-8ea1f42a6029,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-abcf064f-f422-4444-9bee-d33d5aea8dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:46117,DS-05d9dd5e-82d4-44ec-a63c-34437b76f7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-3d4b5143-80f0-491a-b11d-5ebffd3e9282,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-e03ae46e-df8b-45fe-ae05-6b574c000de5,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-6cdd2a63-ca86-4aeb-b447-a1d37b43df8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-eea5ad00-62f3-4638-bcd8-f3338068eddf,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-bcb80c1a-8f6d-4fe2-837b-67cbd983ab45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1745479868-172.17.0.11-1597479039096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46851,DS-d014a1c1-4630-45c2-900e-67abbb0f6d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33322,DS-c8899fa6-e149-44e5-8467-8ccb9b26d57a,DISK], DatanodeInfoWithStorage[127.0.0.1:35054,DS-507b942a-02c3-4bf2-b294-fcfb025f068b,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-ca5337e2-95d4-463b-a731-3f50f073c4af,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-b8f49e51-c2e3-4321-adfb-676a040c30db,DISK], DatanodeInfoWithStorage[127.0.0.1:42877,DS-1124a086-b3e9-4ff0-b2b1-1bca504bf76a,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-1b1477d1-7b36-494f-960f-251e7a4c0677,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-df0122ec-82d0-406a-bdaa-fbb47779d803,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1745479868-172.17.0.11-1597479039096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46851,DS-d014a1c1-4630-45c2-900e-67abbb0f6d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33322,DS-c8899fa6-e149-44e5-8467-8ccb9b26d57a,DISK], DatanodeInfoWithStorage[127.0.0.1:35054,DS-507b942a-02c3-4bf2-b294-fcfb025f068b,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-ca5337e2-95d4-463b-a731-3f50f073c4af,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-b8f49e51-c2e3-4321-adfb-676a040c30db,DISK], DatanodeInfoWithStorage[127.0.0.1:42877,DS-1124a086-b3e9-4ff0-b2b1-1bca504bf76a,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-1b1477d1-7b36-494f-960f-251e7a4c0677,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-df0122ec-82d0-406a-bdaa-fbb47779d803,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-384257077-172.17.0.11-1597480228778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35336,DS-84f6c927-b9c0-4354-9b9f-d9e55eae95b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36005,DS-9a4b91ad-4049-4dee-96e5-8a70eb69de86,DISK], DatanodeInfoWithStorage[127.0.0.1:38144,DS-a50513a6-bab2-4efb-835d-fa5f03873e80,DISK], DatanodeInfoWithStorage[127.0.0.1:37756,DS-a3e47d48-1a5f-4543-b9a7-d7377ee3300b,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-197c0cc3-4827-46fe-85e4-0cb6e7111e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-7847efe7-4c2a-4736-9637-c349d5dc22bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-e04f7021-7805-4cd8-a6ee-7b9ef74cc40b,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-12126b9b-67b9-4621-8f4d-36f6e9b1bdcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-384257077-172.17.0.11-1597480228778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35336,DS-84f6c927-b9c0-4354-9b9f-d9e55eae95b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36005,DS-9a4b91ad-4049-4dee-96e5-8a70eb69de86,DISK], DatanodeInfoWithStorage[127.0.0.1:38144,DS-a50513a6-bab2-4efb-835d-fa5f03873e80,DISK], DatanodeInfoWithStorage[127.0.0.1:37756,DS-a3e47d48-1a5f-4543-b9a7-d7377ee3300b,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-197c0cc3-4827-46fe-85e4-0cb6e7111e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-7847efe7-4c2a-4736-9637-c349d5dc22bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-e04f7021-7805-4cd8-a6ee-7b9ef74cc40b,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-12126b9b-67b9-4621-8f4d-36f6e9b1bdcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1416306626-172.17.0.11-1597480741612:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42329,DS-fe49c579-c8be-4cc6-a1ef-4bf6dab54b10,DISK], DatanodeInfoWithStorage[127.0.0.1:34309,DS-aa970608-4be2-4e27-8b9d-54e9762e6305,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-a788fd86-bdf0-474d-90a3-c9536d1fd25d,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-a394b8b0-f308-4518-9ca6-4f4b9956eee9,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-61132357-efda-4723-a6f3-563c17fa18e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-8f1bb47e-1d45-45ee-bb56-7e36aa915e03,DISK], DatanodeInfoWithStorage[127.0.0.1:44782,DS-b0904578-a2e7-48c9-a180-21b53b3623fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-c5784fc4-fdd1-4f4b-8f38-7f284b11b7ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1416306626-172.17.0.11-1597480741612:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42329,DS-fe49c579-c8be-4cc6-a1ef-4bf6dab54b10,DISK], DatanodeInfoWithStorage[127.0.0.1:34309,DS-aa970608-4be2-4e27-8b9d-54e9762e6305,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-a788fd86-bdf0-474d-90a3-c9536d1fd25d,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-a394b8b0-f308-4518-9ca6-4f4b9956eee9,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-61132357-efda-4723-a6f3-563c17fa18e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-8f1bb47e-1d45-45ee-bb56-7e36aa915e03,DISK], DatanodeInfoWithStorage[127.0.0.1:44782,DS-b0904578-a2e7-48c9-a180-21b53b3623fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-c5784fc4-fdd1-4f4b-8f38-7f284b11b7ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1075245397-172.17.0.11-1597480961159:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41828,DS-1c290125-cd6e-4ee0-919f-bfcc47404b68,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-43e202a8-a386-4107-9527-207f1fe93bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-ffd459b0-71ab-43de-a77d-cb5e798343b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-e488e34f-221c-407c-9ea4-a18faf792475,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-19159973-3db6-494a-9cea-956e061cde94,DISK], DatanodeInfoWithStorage[127.0.0.1:45094,DS-58761911-b998-481e-8d71-1424ccede856,DISK], DatanodeInfoWithStorage[127.0.0.1:36596,DS-798bf5bd-701b-4625-b783-75a024645a22,DISK], DatanodeInfoWithStorage[127.0.0.1:46495,DS-f5e07fd6-1763-466b-ac0e-1e532f13b2fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1075245397-172.17.0.11-1597480961159:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41828,DS-1c290125-cd6e-4ee0-919f-bfcc47404b68,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-43e202a8-a386-4107-9527-207f1fe93bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-ffd459b0-71ab-43de-a77d-cb5e798343b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-e488e34f-221c-407c-9ea4-a18faf792475,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-19159973-3db6-494a-9cea-956e061cde94,DISK], DatanodeInfoWithStorage[127.0.0.1:45094,DS-58761911-b998-481e-8d71-1424ccede856,DISK], DatanodeInfoWithStorage[127.0.0.1:36596,DS-798bf5bd-701b-4625-b783-75a024645a22,DISK], DatanodeInfoWithStorage[127.0.0.1:46495,DS-f5e07fd6-1763-466b-ac0e-1e532f13b2fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1585706437-172.17.0.11-1597481053078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37642,DS-81463c8c-adac-4858-a441-3afce15a4384,DISK], DatanodeInfoWithStorage[127.0.0.1:42578,DS-078601c7-5d0d-42e7-97e2-154f6371c227,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-51ee508d-3e9e-4898-915b-3fb70a6d76ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-8bbdbfe3-de7d-4c69-aab1-841db4043434,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-ec80e5bb-dccf-4f8b-aac4-4183ff823136,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-32b30204-bbed-4f44-9613-9b3022e97e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37846,DS-7686cd00-2df4-4c8a-b6e9-bc68f4d1d209,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-ec9262de-94fa-4207-8426-e1d95d560812,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1585706437-172.17.0.11-1597481053078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37642,DS-81463c8c-adac-4858-a441-3afce15a4384,DISK], DatanodeInfoWithStorage[127.0.0.1:42578,DS-078601c7-5d0d-42e7-97e2-154f6371c227,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-51ee508d-3e9e-4898-915b-3fb70a6d76ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-8bbdbfe3-de7d-4c69-aab1-841db4043434,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-ec80e5bb-dccf-4f8b-aac4-4183ff823136,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-32b30204-bbed-4f44-9613-9b3022e97e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37846,DS-7686cd00-2df4-4c8a-b6e9-bc68f4d1d209,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-ec9262de-94fa-4207-8426-e1d95d560812,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1172685608-172.17.0.11-1597481685200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46052,DS-abf0466d-6281-49e0-a44c-e8a223c09f07,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-4c636e8f-17dd-43aa-9ddc-f3cf570584ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-f48332ab-bb00-4339-b6b2-42c8139de07c,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-e7eb13e1-22de-48da-9c75-ff9fb2faa964,DISK], DatanodeInfoWithStorage[127.0.0.1:37684,DS-bf13b18d-febb-480d-a567-20baed77d6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-d3ee59f7-d58f-41f9-9402-71b24c544b95,DISK], DatanodeInfoWithStorage[127.0.0.1:39470,DS-87e54df1-b6ab-4dfb-ba2f-d627513745ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-36c3c39c-407d-4c91-b755-a2c644880ce7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1172685608-172.17.0.11-1597481685200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46052,DS-abf0466d-6281-49e0-a44c-e8a223c09f07,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-4c636e8f-17dd-43aa-9ddc-f3cf570584ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-f48332ab-bb00-4339-b6b2-42c8139de07c,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-e7eb13e1-22de-48da-9c75-ff9fb2faa964,DISK], DatanodeInfoWithStorage[127.0.0.1:37684,DS-bf13b18d-febb-480d-a567-20baed77d6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-d3ee59f7-d58f-41f9-9402-71b24c544b95,DISK], DatanodeInfoWithStorage[127.0.0.1:39470,DS-87e54df1-b6ab-4dfb-ba2f-d627513745ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-36c3c39c-407d-4c91-b755-a2c644880ce7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-920863040-172.17.0.11-1597481857350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41061,DS-ba1bc83e-6320-404a-99d7-6e32192a358d,DISK], DatanodeInfoWithStorage[127.0.0.1:43427,DS-f155fbf7-6998-4fd5-a1bf-f02fa928d22b,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-3cee4144-fc50-48e7-b2ac-f4ffc6d1e0de,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-fb7477f7-c2da-4af3-b149-c54fa91bea35,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-8c435688-a1a6-41ba-b494-92fe01a86764,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-6ee40681-5196-4630-a3fd-27e851630e49,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-a9e5b95d-8622-4ffd-946b-0bcf3d464c85,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-df50994a-0a9d-481a-94e5-3a06337ce2f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-920863040-172.17.0.11-1597481857350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41061,DS-ba1bc83e-6320-404a-99d7-6e32192a358d,DISK], DatanodeInfoWithStorage[127.0.0.1:43427,DS-f155fbf7-6998-4fd5-a1bf-f02fa928d22b,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-3cee4144-fc50-48e7-b2ac-f4ffc6d1e0de,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-fb7477f7-c2da-4af3-b149-c54fa91bea35,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-8c435688-a1a6-41ba-b494-92fe01a86764,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-6ee40681-5196-4630-a3fd-27e851630e49,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-a9e5b95d-8622-4ffd-946b-0bcf3d464c85,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-df50994a-0a9d-481a-94e5-3a06337ce2f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-886184933-172.17.0.11-1597482260565:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44088,DS-770f0af9-5f69-4d3b-8eef-5ceb1654e3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33176,DS-ca295e7e-58eb-4ead-8c17-e57d12a2cc3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-54a683ba-be0d-4497-96c4-f90edbab5419,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-f7768264-11dc-4687-af7e-f7b165a2a873,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-61b57632-367a-4338-a2f2-ff884ebec5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-fb72c9b6-4e86-459c-806d-11bef5282a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-dbe4b461-8a06-490c-b40a-26384edc89cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-a8a1f663-d891-4ec7-b4f0-91e83bc38e4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-886184933-172.17.0.11-1597482260565:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44088,DS-770f0af9-5f69-4d3b-8eef-5ceb1654e3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33176,DS-ca295e7e-58eb-4ead-8c17-e57d12a2cc3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-54a683ba-be0d-4497-96c4-f90edbab5419,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-f7768264-11dc-4687-af7e-f7b165a2a873,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-61b57632-367a-4338-a2f2-ff884ebec5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-fb72c9b6-4e86-459c-806d-11bef5282a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-dbe4b461-8a06-490c-b40a-26384edc89cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-a8a1f663-d891-4ec7-b4f0-91e83bc38e4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-334977900-172.17.0.11-1597482483979:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33083,DS-d70ab63d-b088-4b0c-8d93-33610c7599b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-dd206bed-93d3-4f50-a800-f6c1bc9cd25d,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-2fd8d952-78cb-4f87-8533-5fafe4464067,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-3b9f590b-73b9-4ab6-9be7-01e7c224da89,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-cba0df0a-1fe9-49f6-9e05-ffe33d787e90,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-6ada73f3-6a30-44e8-9b23-1046e38ebaf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-5050a6b0-a982-49dd-8df6-0b0020652e94,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-ca1dec6d-403e-4ce3-a847-330fd28f3848,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-334977900-172.17.0.11-1597482483979:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33083,DS-d70ab63d-b088-4b0c-8d93-33610c7599b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-dd206bed-93d3-4f50-a800-f6c1bc9cd25d,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-2fd8d952-78cb-4f87-8533-5fafe4464067,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-3b9f590b-73b9-4ab6-9be7-01e7c224da89,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-cba0df0a-1fe9-49f6-9e05-ffe33d787e90,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-6ada73f3-6a30-44e8-9b23-1046e38ebaf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-5050a6b0-a982-49dd-8df6-0b0020652e94,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-ca1dec6d-403e-4ce3-a847-330fd28f3848,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1193830814-172.17.0.11-1597483111526:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43007,DS-79a24ecf-359a-4afe-884e-6628a4597ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-ba160e7a-960d-4c4b-bbc0-0e0cd50a217b,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-1b561a74-42df-4e82-b412-9e6ebfe8bd40,DISK], DatanodeInfoWithStorage[127.0.0.1:44631,DS-ad626bca-3427-4fab-8022-56250ccce95b,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-34ed7776-40fd-4f3c-80c5-b4c47987701d,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-481f1caf-33bd-49fb-8080-d60d78970b67,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-1e9ded88-3c2d-4ad6-9c1e-cb962702ddf8,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-1e6ad464-6890-44ee-bbb9-65623d658a89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1193830814-172.17.0.11-1597483111526:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43007,DS-79a24ecf-359a-4afe-884e-6628a4597ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-ba160e7a-960d-4c4b-bbc0-0e0cd50a217b,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-1b561a74-42df-4e82-b412-9e6ebfe8bd40,DISK], DatanodeInfoWithStorage[127.0.0.1:44631,DS-ad626bca-3427-4fab-8022-56250ccce95b,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-34ed7776-40fd-4f3c-80c5-b4c47987701d,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-481f1caf-33bd-49fb-8080-d60d78970b67,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-1e9ded88-3c2d-4ad6-9c1e-cb962702ddf8,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-1e6ad464-6890-44ee-bbb9-65623d658a89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-888449070-172.17.0.11-1597483985392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35022,DS-f66f8ebf-9657-4db5-ad0a-b9e4b19bf357,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-862dfb84-938f-42cd-af7d-b6896d37f6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-5d8afc6c-cf28-415c-aa80-7523bb634fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-8c54a779-ee81-4a9b-b13b-c2433d686025,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-c3d8e631-6d0d-490a-82aa-9836efe6367c,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-1f3d30cd-f492-4233-8045-180ff68373ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-57ed22df-416e-4bc2-aa7f-92f219db7aed,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-8a874d20-6463-4e89-b6b7-778fddd673ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-888449070-172.17.0.11-1597483985392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35022,DS-f66f8ebf-9657-4db5-ad0a-b9e4b19bf357,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-862dfb84-938f-42cd-af7d-b6896d37f6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-5d8afc6c-cf28-415c-aa80-7523bb634fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-8c54a779-ee81-4a9b-b13b-c2433d686025,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-c3d8e631-6d0d-490a-82aa-9836efe6367c,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-1f3d30cd-f492-4233-8045-180ff68373ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-57ed22df-416e-4bc2-aa7f-92f219db7aed,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-8a874d20-6463-4e89-b6b7-778fddd673ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1788061820-172.17.0.11-1597484996902:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33622,DS-dfd3827a-1e0f-432e-80b6-c01a3167b00f,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-b845e153-df38-4e4d-a8fe-9babf48e406a,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-77a9c73c-8c7a-4f19-845b-c100a62379ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-b88068ff-143b-4bda-8ece-dc28c8e036de,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-3089c195-dec4-4a78-a17c-669ea4b12ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-89c43851-0940-41a8-84fb-3170cd3c4aac,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-a0b13acd-f5c4-4f2b-a719-b302ef01f57c,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-546bc1d5-36cb-4827-96d9-08678ed7b907,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1788061820-172.17.0.11-1597484996902:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33622,DS-dfd3827a-1e0f-432e-80b6-c01a3167b00f,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-b845e153-df38-4e4d-a8fe-9babf48e406a,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-77a9c73c-8c7a-4f19-845b-c100a62379ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-b88068ff-143b-4bda-8ece-dc28c8e036de,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-3089c195-dec4-4a78-a17c-669ea4b12ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-89c43851-0940-41a8-84fb-3170cd3c4aac,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-a0b13acd-f5c4-4f2b-a719-b302ef01f57c,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-546bc1d5-36cb-4827-96d9-08678ed7b907,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 6859
