reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-981714402-172.17.0.7-1597275656238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38066,DS-50661486-0f83-441f-8bde-730b58d2d500,DISK], DatanodeInfoWithStorage[127.0.0.1:46377,DS-d1beec39-48dc-40a8-af34-2872d57a403d,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-4b245991-60c5-44be-bbaf-22cde16eb54c,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-aadd93d3-705f-483a-be6a-9c39ea8c20fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-61a80223-cca6-471e-a89a-adef5b26b4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-53b6226f-073e-4f74-9471-fc068b158bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:45042,DS-b81bec0e-cdf4-4923-a9dc-825c915f9bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45758,DS-478865da-144c-48aa-88be-13f3e11558b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-981714402-172.17.0.7-1597275656238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38066,DS-50661486-0f83-441f-8bde-730b58d2d500,DISK], DatanodeInfoWithStorage[127.0.0.1:46377,DS-d1beec39-48dc-40a8-af34-2872d57a403d,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-4b245991-60c5-44be-bbaf-22cde16eb54c,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-aadd93d3-705f-483a-be6a-9c39ea8c20fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-61a80223-cca6-471e-a89a-adef5b26b4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-53b6226f-073e-4f74-9471-fc068b158bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:45042,DS-b81bec0e-cdf4-4923-a9dc-825c915f9bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45758,DS-478865da-144c-48aa-88be-13f3e11558b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1121915743-172.17.0.7-1597275785723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40147,DS-63cb6ea0-bd96-47c2-83c0-f209965e3178,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-c937608b-0599-4791-9372-c4a034aaadf2,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-d03299f8-4306-4dce-abe7-5d7c0c80e6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-08c8690b-415f-4e8e-b9cf-a17929dbaff1,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-e0fa8933-2839-44c2-81f2-1b2148f03288,DISK], DatanodeInfoWithStorage[127.0.0.1:36161,DS-c5013f02-fa6a-445f-a638-cabb7ffc2be9,DISK], DatanodeInfoWithStorage[127.0.0.1:42813,DS-220cde65-b6ac-45ad-8765-0556dace80ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-239ffb9f-2f56-47a8-bbf9-de8d37585e21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1121915743-172.17.0.7-1597275785723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40147,DS-63cb6ea0-bd96-47c2-83c0-f209965e3178,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-c937608b-0599-4791-9372-c4a034aaadf2,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-d03299f8-4306-4dce-abe7-5d7c0c80e6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-08c8690b-415f-4e8e-b9cf-a17929dbaff1,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-e0fa8933-2839-44c2-81f2-1b2148f03288,DISK], DatanodeInfoWithStorage[127.0.0.1:36161,DS-c5013f02-fa6a-445f-a638-cabb7ffc2be9,DISK], DatanodeInfoWithStorage[127.0.0.1:42813,DS-220cde65-b6ac-45ad-8765-0556dace80ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-239ffb9f-2f56-47a8-bbf9-de8d37585e21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2137567706-172.17.0.7-1597276377541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41658,DS-2ead1ee3-dcdd-40b2-a98b-898dd170a6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-ccfc1081-5714-46f5-acba-6068e6014f24,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-d22515e2-5563-4f23-9468-ecdef6c3ebe1,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-2e94a3c4-15cd-461f-9359-e148e569c7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-99b0e1b4-86d4-4530-b49d-d1a29fc9807e,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-8e21ae31-06b1-4d75-b1a9-cf9aeaccd9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-f6029ff3-6e1c-4212-a54e-62275f391f39,DISK], DatanodeInfoWithStorage[127.0.0.1:41842,DS-161906d5-447b-4f9e-8780-c7dc4116748e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2137567706-172.17.0.7-1597276377541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41658,DS-2ead1ee3-dcdd-40b2-a98b-898dd170a6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-ccfc1081-5714-46f5-acba-6068e6014f24,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-d22515e2-5563-4f23-9468-ecdef6c3ebe1,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-2e94a3c4-15cd-461f-9359-e148e569c7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-99b0e1b4-86d4-4530-b49d-d1a29fc9807e,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-8e21ae31-06b1-4d75-b1a9-cf9aeaccd9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-f6029ff3-6e1c-4212-a54e-62275f391f39,DISK], DatanodeInfoWithStorage[127.0.0.1:41842,DS-161906d5-447b-4f9e-8780-c7dc4116748e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1769562900-172.17.0.7-1597276823861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39628,DS-af2aacdb-2efe-43db-90e5-642156d429c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-451a3208-ceb6-4438-a9c6-1ff1b2220ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-8faae3fb-cac2-4e58-b9d7-444d3bf6c1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-cf957be2-3b7f-404f-8e9e-1311e8ab9a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-9a77c920-1eaa-4a6b-9e0c-6c9d6bc2a47a,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-28f2ef1c-d89f-4a81-ace1-4fde858d3dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-b1d07517-abbf-472a-9bba-a8767c991409,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-1f48cc66-9367-4d83-869d-873743398fe8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1769562900-172.17.0.7-1597276823861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39628,DS-af2aacdb-2efe-43db-90e5-642156d429c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-451a3208-ceb6-4438-a9c6-1ff1b2220ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-8faae3fb-cac2-4e58-b9d7-444d3bf6c1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-cf957be2-3b7f-404f-8e9e-1311e8ab9a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-9a77c920-1eaa-4a6b-9e0c-6c9d6bc2a47a,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-28f2ef1c-d89f-4a81-ace1-4fde858d3dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-b1d07517-abbf-472a-9bba-a8767c991409,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-1f48cc66-9367-4d83-869d-873743398fe8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1984050703-172.17.0.7-1597276942794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33745,DS-8694abba-fe4f-4359-8ea2-1d87fafb7219,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-d6d8a11d-cd64-4d89-addb-ca446e5fa166,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-ca2abb5a-93c4-41fe-bd10-50938f3444be,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-4db98356-5658-48f0-8607-8cf4b325c82e,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-654dd510-5d69-47e9-9de9-9b64299148d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-7ff15345-762b-4e9d-b487-159271af5e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-bf98a22d-ab06-40c5-928e-94c31a507938,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-f6dd615f-849c-4b12-8fc8-7cad4af30149,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1984050703-172.17.0.7-1597276942794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33745,DS-8694abba-fe4f-4359-8ea2-1d87fafb7219,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-d6d8a11d-cd64-4d89-addb-ca446e5fa166,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-ca2abb5a-93c4-41fe-bd10-50938f3444be,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-4db98356-5658-48f0-8607-8cf4b325c82e,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-654dd510-5d69-47e9-9de9-9b64299148d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-7ff15345-762b-4e9d-b487-159271af5e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-bf98a22d-ab06-40c5-928e-94c31a507938,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-f6dd615f-849c-4b12-8fc8-7cad4af30149,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-871430434-172.17.0.7-1597277019217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43088,DS-7791af8c-8a14-4ecb-a807-75bb9f254388,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-9e9fd77d-0b8d-4eb2-9fd1-3ceb27697ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-46f7b91f-29fb-4fca-9444-6728aea1587b,DISK], DatanodeInfoWithStorage[127.0.0.1:42282,DS-99d85bc3-3448-4d75-9ba7-7ca64f297716,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-d96a70e9-d139-47f8-aeff-a22317264ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-03aebab4-1dfe-4378-bc2c-22f87736f8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39418,DS-31a205a0-d76f-48d4-889e-1a9ea301b22d,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-942c169a-5b90-4183-bc94-15bdae42464f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-871430434-172.17.0.7-1597277019217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43088,DS-7791af8c-8a14-4ecb-a807-75bb9f254388,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-9e9fd77d-0b8d-4eb2-9fd1-3ceb27697ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-46f7b91f-29fb-4fca-9444-6728aea1587b,DISK], DatanodeInfoWithStorage[127.0.0.1:42282,DS-99d85bc3-3448-4d75-9ba7-7ca64f297716,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-d96a70e9-d139-47f8-aeff-a22317264ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-03aebab4-1dfe-4378-bc2c-22f87736f8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39418,DS-31a205a0-d76f-48d4-889e-1a9ea301b22d,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-942c169a-5b90-4183-bc94-15bdae42464f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1181774901-172.17.0.7-1597277171205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46723,DS-8f17ce50-28a1-43dc-bf5c-ebf67445b806,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-c0cfe9cf-3e29-4412-8251-e8db2c497bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-b1ce34ab-6540-44fa-accd-d4b3fb27bb05,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-ae6032a6-d009-46ce-ac21-d3efba34477e,DISK], DatanodeInfoWithStorage[127.0.0.1:42072,DS-681ec12d-cb7a-4b05-a129-9d922a19a99f,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-ffec92f5-fc95-49ac-b7a3-50883dbd3138,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-dc01ac14-dbff-41b1-850f-ab566b994c18,DISK], DatanodeInfoWithStorage[127.0.0.1:42112,DS-feee6779-8fe6-4976-926b-ba3db4f9b434,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1181774901-172.17.0.7-1597277171205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46723,DS-8f17ce50-28a1-43dc-bf5c-ebf67445b806,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-c0cfe9cf-3e29-4412-8251-e8db2c497bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-b1ce34ab-6540-44fa-accd-d4b3fb27bb05,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-ae6032a6-d009-46ce-ac21-d3efba34477e,DISK], DatanodeInfoWithStorage[127.0.0.1:42072,DS-681ec12d-cb7a-4b05-a129-9d922a19a99f,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-ffec92f5-fc95-49ac-b7a3-50883dbd3138,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-dc01ac14-dbff-41b1-850f-ab566b994c18,DISK], DatanodeInfoWithStorage[127.0.0.1:42112,DS-feee6779-8fe6-4976-926b-ba3db4f9b434,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-416158255-172.17.0.7-1597277516601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44095,DS-e25cc177-9d63-4d3b-904a-4e5b824d091a,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-88fad17e-2599-4080-90ec-db1fd6ce6404,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-e84b9a81-e467-4963-acb8-fa24c7abc7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-99edf831-96d4-437b-9a43-601a29301130,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-89759bd1-3b17-4ba7-8174-174d82cf395b,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-658163cd-80f0-4188-b9e5-59094157f5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-8eda6ca4-39b1-4f8a-84ab-c5c480d46a05,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-18a40c1b-f8a7-40d0-9491-aaca42dd1618,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-416158255-172.17.0.7-1597277516601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44095,DS-e25cc177-9d63-4d3b-904a-4e5b824d091a,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-88fad17e-2599-4080-90ec-db1fd6ce6404,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-e84b9a81-e467-4963-acb8-fa24c7abc7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-99edf831-96d4-437b-9a43-601a29301130,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-89759bd1-3b17-4ba7-8174-174d82cf395b,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-658163cd-80f0-4188-b9e5-59094157f5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-8eda6ca4-39b1-4f8a-84ab-c5c480d46a05,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-18a40c1b-f8a7-40d0-9491-aaca42dd1618,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2035208395-172.17.0.7-1597277712897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45270,DS-6cf0fdcb-cac7-4e21-83fc-83102e395824,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-73681c16-3349-4370-88b7-e7beb3a579b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45426,DS-d45e4ff7-e6cf-4261-a564-981be1ba44c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-887fdaf2-2d13-408a-9fcc-3c5d63db5378,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-bd58733e-2fe8-4cb9-b7f1-81e666d62ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-026527fa-c448-4da6-a23e-7985b5211e76,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-1a445c0e-140c-44e2-848d-41e78893e921,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-03f04265-e1be-47c1-b7fa-b94640acc04b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2035208395-172.17.0.7-1597277712897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45270,DS-6cf0fdcb-cac7-4e21-83fc-83102e395824,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-73681c16-3349-4370-88b7-e7beb3a579b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45426,DS-d45e4ff7-e6cf-4261-a564-981be1ba44c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-887fdaf2-2d13-408a-9fcc-3c5d63db5378,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-bd58733e-2fe8-4cb9-b7f1-81e666d62ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-026527fa-c448-4da6-a23e-7985b5211e76,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-1a445c0e-140c-44e2-848d-41e78893e921,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-03f04265-e1be-47c1-b7fa-b94640acc04b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-258101620-172.17.0.7-1597278039105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35871,DS-e4b6f3f5-814c-4121-9c35-04c9c639d849,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-de158c50-7485-4c7e-ad87-14c771b31cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-a2f8e723-4e3b-45ce-8458-2b38ab32c297,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-fd3419bf-7972-4643-9e7e-62627de0d5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-4f93cbf8-8d46-4d5d-8244-4bd25732dd56,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-9ad28523-f075-40ef-902b-6a2382f17c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40142,DS-a32dd8c0-c15d-4be9-93de-2d6319d74afa,DISK], DatanodeInfoWithStorage[127.0.0.1:39979,DS-779176f0-9962-4435-8a4c-6d28fcbc25ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-258101620-172.17.0.7-1597278039105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35871,DS-e4b6f3f5-814c-4121-9c35-04c9c639d849,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-de158c50-7485-4c7e-ad87-14c771b31cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-a2f8e723-4e3b-45ce-8458-2b38ab32c297,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-fd3419bf-7972-4643-9e7e-62627de0d5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-4f93cbf8-8d46-4d5d-8244-4bd25732dd56,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-9ad28523-f075-40ef-902b-6a2382f17c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40142,DS-a32dd8c0-c15d-4be9-93de-2d6319d74afa,DISK], DatanodeInfoWithStorage[127.0.0.1:39979,DS-779176f0-9962-4435-8a4c-6d28fcbc25ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-284782413-172.17.0.7-1597278380524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33150,DS-91336f0b-0717-4eca-b113-7ce176b326a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37397,DS-089fad0e-e53a-4ed8-a8e0-068b8ed811b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-5698021f-a0b8-4cf0-985d-46d08430a7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46515,DS-8fc7fc62-a4f8-466a-ac5b-7369e95c1c51,DISK], DatanodeInfoWithStorage[127.0.0.1:43619,DS-2da2d780-ad3a-4879-811e-3cb3225effad,DISK], DatanodeInfoWithStorage[127.0.0.1:32931,DS-a61eda93-08a4-45e0-82d0-99059c729bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-682a93e4-dacf-4229-b6d7-f72971ad26f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40836,DS-42a69db7-586b-4bfe-a7ac-72e3e891e428,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-284782413-172.17.0.7-1597278380524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33150,DS-91336f0b-0717-4eca-b113-7ce176b326a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37397,DS-089fad0e-e53a-4ed8-a8e0-068b8ed811b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-5698021f-a0b8-4cf0-985d-46d08430a7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46515,DS-8fc7fc62-a4f8-466a-ac5b-7369e95c1c51,DISK], DatanodeInfoWithStorage[127.0.0.1:43619,DS-2da2d780-ad3a-4879-811e-3cb3225effad,DISK], DatanodeInfoWithStorage[127.0.0.1:32931,DS-a61eda93-08a4-45e0-82d0-99059c729bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-682a93e4-dacf-4229-b6d7-f72971ad26f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40836,DS-42a69db7-586b-4bfe-a7ac-72e3e891e428,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663458068-172.17.0.7-1597278498494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43930,DS-a8cb76cf-d391-4efc-a880-7b0dbc52cf3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-4fded97b-1746-4805-b9ea-fc268630fe47,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-4070efe5-ad0c-49f1-bd69-297ad38b17b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-a32166c4-4d33-489a-82f3-6e1f947453e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-9cb3715f-f064-4107-9841-86320cc8b9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-9088b2dc-9da7-497b-972e-4dc08ec1d2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-e663abb4-d537-473c-9605-608f90c7ea9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-48063a01-085c-4b6b-997e-6588410bef1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663458068-172.17.0.7-1597278498494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43930,DS-a8cb76cf-d391-4efc-a880-7b0dbc52cf3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-4fded97b-1746-4805-b9ea-fc268630fe47,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-4070efe5-ad0c-49f1-bd69-297ad38b17b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-a32166c4-4d33-489a-82f3-6e1f947453e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-9cb3715f-f064-4107-9841-86320cc8b9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-9088b2dc-9da7-497b-972e-4dc08ec1d2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-e663abb4-d537-473c-9605-608f90c7ea9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-48063a01-085c-4b6b-997e-6588410bef1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1617705655-172.17.0.7-1597278542232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44829,DS-502ce8f3-f938-4bf0-8a97-d1c3985acdad,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-185e492a-fc92-4d51-897c-c960a9527c12,DISK], DatanodeInfoWithStorage[127.0.0.1:46359,DS-05b5a6c3-f671-4e6a-84a3-cc0a8e9cbf16,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-b31b1be3-3670-4044-9ce8-10e51c0b7197,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-69130960-7003-44e9-903e-0d8914a2286d,DISK], DatanodeInfoWithStorage[127.0.0.1:39305,DS-b1487180-37cc-4a63-b437-73b4822adcff,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-d7bf2c02-7a9d-4be1-9790-dd79550805f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-f67219c7-997c-41d4-9268-42f15f16c902,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1617705655-172.17.0.7-1597278542232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44829,DS-502ce8f3-f938-4bf0-8a97-d1c3985acdad,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-185e492a-fc92-4d51-897c-c960a9527c12,DISK], DatanodeInfoWithStorage[127.0.0.1:46359,DS-05b5a6c3-f671-4e6a-84a3-cc0a8e9cbf16,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-b31b1be3-3670-4044-9ce8-10e51c0b7197,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-69130960-7003-44e9-903e-0d8914a2286d,DISK], DatanodeInfoWithStorage[127.0.0.1:39305,DS-b1487180-37cc-4a63-b437-73b4822adcff,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-d7bf2c02-7a9d-4be1-9790-dd79550805f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-f67219c7-997c-41d4-9268-42f15f16c902,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2019498717-172.17.0.7-1597278581729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44916,DS-1144de5a-d948-40f4-b3f7-f28b9d938fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-da2f1a09-e086-4c22-9803-179aec21d698,DISK], DatanodeInfoWithStorage[127.0.0.1:46042,DS-13c3e248-d532-4e6c-a73f-7096102d5182,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-771f68e1-dd3e-422c-abb9-2e030c43583a,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-cf27ced7-9b9b-444d-91a7-dcd0f23de7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-fe6fce86-f3a5-4e0a-9eaf-82bf7e7e7eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-865b6e3e-4d70-45a4-96f2-8e7f34377ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-6420b852-2d4f-4e26-8550-4da29a0b0847,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2019498717-172.17.0.7-1597278581729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44916,DS-1144de5a-d948-40f4-b3f7-f28b9d938fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-da2f1a09-e086-4c22-9803-179aec21d698,DISK], DatanodeInfoWithStorage[127.0.0.1:46042,DS-13c3e248-d532-4e6c-a73f-7096102d5182,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-771f68e1-dd3e-422c-abb9-2e030c43583a,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-cf27ced7-9b9b-444d-91a7-dcd0f23de7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-fe6fce86-f3a5-4e0a-9eaf-82bf7e7e7eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-865b6e3e-4d70-45a4-96f2-8e7f34377ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-6420b852-2d4f-4e26-8550-4da29a0b0847,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-614323356-172.17.0.7-1597278992815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33166,DS-adfd4b4b-ddfa-451b-8283-4af2e7a7b7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37123,DS-7a33d5da-6a2a-4952-974d-318ab340bd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-7ccf6d84-54a5-4e5e-917e-2a8f95ba810e,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-e547919b-aa2a-410d-9cf2-f999ac207e77,DISK], DatanodeInfoWithStorage[127.0.0.1:44821,DS-7548d669-9fac-43b4-b983-d8986aced784,DISK], DatanodeInfoWithStorage[127.0.0.1:35560,DS-1829d8b6-3d90-4569-a320-d8b1636d4bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-01c861f3-58d5-466e-9e15-3dba90d3746c,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-9b67d0ff-8adf-4a93-9983-543278530e84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-614323356-172.17.0.7-1597278992815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33166,DS-adfd4b4b-ddfa-451b-8283-4af2e7a7b7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37123,DS-7a33d5da-6a2a-4952-974d-318ab340bd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-7ccf6d84-54a5-4e5e-917e-2a8f95ba810e,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-e547919b-aa2a-410d-9cf2-f999ac207e77,DISK], DatanodeInfoWithStorage[127.0.0.1:44821,DS-7548d669-9fac-43b4-b983-d8986aced784,DISK], DatanodeInfoWithStorage[127.0.0.1:35560,DS-1829d8b6-3d90-4569-a320-d8b1636d4bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-01c861f3-58d5-466e-9e15-3dba90d3746c,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-9b67d0ff-8adf-4a93-9983-543278530e84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1552776837-172.17.0.7-1597279951399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45923,DS-d542ac6b-9a56-4c89-b8ad-94ca07be75eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-d6eb3588-6ea8-4bf2-9960-78d3d799ab0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-71ba1e97-fae0-41b8-ab91-fa17936c2412,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-f2902e0f-dcc3-4a63-9d3c-deb17947408c,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-198449e0-42f5-4005-83d3-45d9a8d318c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-dc94a8a4-615a-4023-b060-d7840827c52f,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-5cbea848-8e6e-4500-8a4e-707ddf7a3c94,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-8bd5e552-bda7-4b3b-8374-adf2796f53e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1552776837-172.17.0.7-1597279951399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45923,DS-d542ac6b-9a56-4c89-b8ad-94ca07be75eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-d6eb3588-6ea8-4bf2-9960-78d3d799ab0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-71ba1e97-fae0-41b8-ab91-fa17936c2412,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-f2902e0f-dcc3-4a63-9d3c-deb17947408c,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-198449e0-42f5-4005-83d3-45d9a8d318c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-dc94a8a4-615a-4023-b060-d7840827c52f,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-5cbea848-8e6e-4500-8a4e-707ddf7a3c94,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-8bd5e552-bda7-4b3b-8374-adf2796f53e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1728469365-172.17.0.7-1597280028222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42660,DS-4ad05477-5fbd-46fb-8056-14c99c7ab522,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-ab52287f-03ad-479e-99a3-ed011a4040f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-28daa58b-1625-4f4c-9a9b-01afb035e5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-9e97f322-07c6-4377-9c0d-c7a53454cd04,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-c433035f-0250-4eef-8128-8b729f2c2b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45683,DS-e0a718d7-bb77-4506-8394-3231ad8d4bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-daf1a3b1-5657-44b0-b6d4-41f10add95bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-8cf41111-280d-439a-b74e-228878308080,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1728469365-172.17.0.7-1597280028222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42660,DS-4ad05477-5fbd-46fb-8056-14c99c7ab522,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-ab52287f-03ad-479e-99a3-ed011a4040f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-28daa58b-1625-4f4c-9a9b-01afb035e5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-9e97f322-07c6-4377-9c0d-c7a53454cd04,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-c433035f-0250-4eef-8128-8b729f2c2b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45683,DS-e0a718d7-bb77-4506-8394-3231ad8d4bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-daf1a3b1-5657-44b0-b6d4-41f10add95bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-8cf41111-280d-439a-b74e-228878308080,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-543877413-172.17.0.7-1597280738571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35197,DS-8e5ceb94-fad1-4aa6-8e29-b48a77187bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-82b013a2-8ccb-482b-8bde-3111ae66d095,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-904241a3-da51-4d1a-b578-54dbd3643c41,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-9cd0daa0-33b2-4e36-bbcc-8e87d5fa60f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-4aa81f6f-65f2-47ca-9198-5076a83378b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38433,DS-b11200da-32cb-407a-853f-ca8008c3f536,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-0794c89e-da13-4bcb-b823-317f32a398c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-d9e34cb9-3b18-427f-be0c-61e7fde45dee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-543877413-172.17.0.7-1597280738571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35197,DS-8e5ceb94-fad1-4aa6-8e29-b48a77187bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-82b013a2-8ccb-482b-8bde-3111ae66d095,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-904241a3-da51-4d1a-b578-54dbd3643c41,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-9cd0daa0-33b2-4e36-bbcc-8e87d5fa60f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-4aa81f6f-65f2-47ca-9198-5076a83378b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38433,DS-b11200da-32cb-407a-853f-ca8008c3f536,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-0794c89e-da13-4bcb-b823-317f32a398c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-d9e34cb9-3b18-427f-be0c-61e7fde45dee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1621948069-172.17.0.7-1597280927758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39987,DS-e63198c3-8a7a-400c-ad00-55321894a8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-d360f209-0aaa-4523-b136-42e52ff9d033,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-48840547-d9ae-43ec-89e9-a5b92e91c086,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-d44f9162-d25c-42ce-af2d-90741762b91c,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-d2dd361b-95ea-4e0a-b03c-a1ba4b3b8722,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-3439aec4-0637-4a1e-b263-8f80bc051662,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-61944b46-ca97-4459-824e-688a89b87aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-52328450-4850-46b7-beeb-f724e07d3ed6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1621948069-172.17.0.7-1597280927758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39987,DS-e63198c3-8a7a-400c-ad00-55321894a8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-d360f209-0aaa-4523-b136-42e52ff9d033,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-48840547-d9ae-43ec-89e9-a5b92e91c086,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-d44f9162-d25c-42ce-af2d-90741762b91c,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-d2dd361b-95ea-4e0a-b03c-a1ba4b3b8722,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-3439aec4-0637-4a1e-b263-8f80bc051662,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-61944b46-ca97-4459-824e-688a89b87aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-52328450-4850-46b7-beeb-f724e07d3ed6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5666
