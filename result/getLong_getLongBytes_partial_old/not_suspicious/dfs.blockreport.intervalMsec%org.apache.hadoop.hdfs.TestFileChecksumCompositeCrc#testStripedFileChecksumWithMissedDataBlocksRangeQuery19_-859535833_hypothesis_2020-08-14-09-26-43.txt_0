reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-650402633-172.17.0.18-1597397628364:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45913,DS-b486b308-2fc1-4368-90a7-14094b283496,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-ccfa365c-74d8-4fe5-bab8-035284ae1222,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-892cfe87-aad9-4626-80f0-f5597885bcb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-82098b1c-02ef-4d1c-9740-787a9db1eb34,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-f5e0ea75-4c88-4b16-9210-81c8f037526a,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-167b596b-f710-4eac-9749-6cc5c2474bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:43937,DS-7b3bdc08-d425-44db-88ad-14c59771e606,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-afd31e49-961c-424d-9313-f0031da235db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-650402633-172.17.0.18-1597397628364:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45913,DS-b486b308-2fc1-4368-90a7-14094b283496,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-ccfa365c-74d8-4fe5-bab8-035284ae1222,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-892cfe87-aad9-4626-80f0-f5597885bcb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-82098b1c-02ef-4d1c-9740-787a9db1eb34,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-f5e0ea75-4c88-4b16-9210-81c8f037526a,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-167b596b-f710-4eac-9749-6cc5c2474bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:43937,DS-7b3bdc08-d425-44db-88ad-14c59771e606,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-afd31e49-961c-424d-9313-f0031da235db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1659149744-172.17.0.18-1597398057590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37864,DS-b96be2f8-9bc7-4e54-9b58-8a474a85b4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-e0d9a896-783a-4cb0-a2b7-238b80f357aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36447,DS-93394ba0-f02f-4ad2-ad99-4e0b7946d424,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-d0ab66dc-bf13-4f95-9a71-1cf90394000f,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-2626eba9-23ca-43a4-a393-45bd19111ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-37c975e9-d150-4f1c-9705-7f15df96505a,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-f809ff3f-cdc6-4857-b85d-8e280ddb2e90,DISK], DatanodeInfoWithStorage[127.0.0.1:43051,DS-333ab80b-a740-4564-b5b6-fe61bf74d4e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1659149744-172.17.0.18-1597398057590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37864,DS-b96be2f8-9bc7-4e54-9b58-8a474a85b4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-e0d9a896-783a-4cb0-a2b7-238b80f357aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36447,DS-93394ba0-f02f-4ad2-ad99-4e0b7946d424,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-d0ab66dc-bf13-4f95-9a71-1cf90394000f,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-2626eba9-23ca-43a4-a393-45bd19111ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-37c975e9-d150-4f1c-9705-7f15df96505a,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-f809ff3f-cdc6-4857-b85d-8e280ddb2e90,DISK], DatanodeInfoWithStorage[127.0.0.1:43051,DS-333ab80b-a740-4564-b5b6-fe61bf74d4e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-672347162-172.17.0.18-1597399108735:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35769,DS-feafd25d-39f4-4a3d-8078-48ac0f2cc0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-62849db4-0fc9-401a-9973-6a58fd9e644c,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-317e2cf5-4761-43f8-a36b-eeac86956337,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-bc809f09-3a26-452c-8151-3f14f38b2337,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-99dcfc81-9fe5-48b3-8b44-599c3aabd52d,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-78e8ecf7-d1e5-4a87-b4be-a5f88e5cfe4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-fe71a7dd-2aed-49dc-997f-05caca3f6e65,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-0a5d592f-0a00-4da2-95d2-0c37b52b8338,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-672347162-172.17.0.18-1597399108735:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35769,DS-feafd25d-39f4-4a3d-8078-48ac0f2cc0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-62849db4-0fc9-401a-9973-6a58fd9e644c,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-317e2cf5-4761-43f8-a36b-eeac86956337,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-bc809f09-3a26-452c-8151-3f14f38b2337,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-99dcfc81-9fe5-48b3-8b44-599c3aabd52d,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-78e8ecf7-d1e5-4a87-b4be-a5f88e5cfe4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-fe71a7dd-2aed-49dc-997f-05caca3f6e65,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-0a5d592f-0a00-4da2-95d2-0c37b52b8338,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1529259376-172.17.0.18-1597399665327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44284,DS-2b6b5027-5498-497b-9b69-b923631a9bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-27576d31-2ac2-4872-8902-22408382df99,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-3b5a8282-e591-4b47-86b4-b744166c95f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-7398b694-7789-4cf4-9f9c-48c345c1fa5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-2476ad1c-1f50-43c4-ad09-ed5d6e160076,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-75740719-9538-4c18-8dbc-675e091735cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-ec4c0261-aca6-45d4-8fd8-5f748ce7bc62,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-cc58a144-a864-4112-ab1b-14a335e5aaed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1529259376-172.17.0.18-1597399665327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44284,DS-2b6b5027-5498-497b-9b69-b923631a9bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-27576d31-2ac2-4872-8902-22408382df99,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-3b5a8282-e591-4b47-86b4-b744166c95f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-7398b694-7789-4cf4-9f9c-48c345c1fa5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-2476ad1c-1f50-43c4-ad09-ed5d6e160076,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-75740719-9538-4c18-8dbc-675e091735cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-ec4c0261-aca6-45d4-8fd8-5f748ce7bc62,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-cc58a144-a864-4112-ab1b-14a335e5aaed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1402720068-172.17.0.18-1597399908463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41855,DS-a45b10ce-849b-47ba-84b0-2ed02113eff7,DISK], DatanodeInfoWithStorage[127.0.0.1:36288,DS-b3453f36-760e-4251-b62c-c880240cd84c,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-62ba81b7-156e-4536-9621-e485c06f902e,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-aabf5ffd-3cfe-4ef2-8d0a-a59fe9226b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-8d8bd724-4f7f-41db-905e-9277b8ae8a96,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-e44ea153-f457-49c8-ab31-f98b1775479f,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-414c22dc-e54e-46f7-825d-5176b1744449,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-6e4e5ea5-7834-4022-9ecb-ce0e7fd24a9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1402720068-172.17.0.18-1597399908463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41855,DS-a45b10ce-849b-47ba-84b0-2ed02113eff7,DISK], DatanodeInfoWithStorage[127.0.0.1:36288,DS-b3453f36-760e-4251-b62c-c880240cd84c,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-62ba81b7-156e-4536-9621-e485c06f902e,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-aabf5ffd-3cfe-4ef2-8d0a-a59fe9226b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-8d8bd724-4f7f-41db-905e-9277b8ae8a96,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-e44ea153-f457-49c8-ab31-f98b1775479f,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-414c22dc-e54e-46f7-825d-5176b1744449,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-6e4e5ea5-7834-4022-9ecb-ce0e7fd24a9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1851133822-172.17.0.18-1597400090354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41066,DS-16a34c8a-2259-41e7-a6d1-4933adafeede,DISK], DatanodeInfoWithStorage[127.0.0.1:39497,DS-d67681eb-c889-4228-909f-edf1b7ac3483,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-77b2ef50-7ea9-40b3-b29b-a34b41464e71,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-e33b0a40-07fe-4282-ac33-38cc6548dcb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-dbb2d7e4-9cb4-4fae-9128-21ae57be5b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-ebb72ab4-41b4-49f8-a717-43234ef5eb54,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-aeee7594-9f14-4668-87d8-65baf8c15073,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-3a671f88-c8b9-4013-a8be-9ea75330687f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1851133822-172.17.0.18-1597400090354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41066,DS-16a34c8a-2259-41e7-a6d1-4933adafeede,DISK], DatanodeInfoWithStorage[127.0.0.1:39497,DS-d67681eb-c889-4228-909f-edf1b7ac3483,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-77b2ef50-7ea9-40b3-b29b-a34b41464e71,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-e33b0a40-07fe-4282-ac33-38cc6548dcb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-dbb2d7e4-9cb4-4fae-9128-21ae57be5b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-ebb72ab4-41b4-49f8-a717-43234ef5eb54,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-aeee7594-9f14-4668-87d8-65baf8c15073,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-3a671f88-c8b9-4013-a8be-9ea75330687f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1803550226-172.17.0.18-1597400315312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40408,DS-ba007160-173f-4ff3-b8d1-1e0e3e9470a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-9902e7db-e0b3-4739-8dc5-b51052483ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:46005,DS-ec0484b8-3c7f-4c54-b266-d6ddcdb45dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46745,DS-1f4e73a0-afe2-4f29-9fff-651ecb74715e,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-4fcc53fb-dee9-4575-aabe-46d8888ab6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-162025bf-b197-4960-b708-f1fd1429a6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-8f5b949f-58ae-46c7-b3b3-b55858171723,DISK], DatanodeInfoWithStorage[127.0.0.1:33648,DS-b759a164-f6b5-49c1-a03f-98dbb276f586,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1803550226-172.17.0.18-1597400315312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40408,DS-ba007160-173f-4ff3-b8d1-1e0e3e9470a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-9902e7db-e0b3-4739-8dc5-b51052483ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:46005,DS-ec0484b8-3c7f-4c54-b266-d6ddcdb45dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46745,DS-1f4e73a0-afe2-4f29-9fff-651ecb74715e,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-4fcc53fb-dee9-4575-aabe-46d8888ab6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-162025bf-b197-4960-b708-f1fd1429a6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-8f5b949f-58ae-46c7-b3b3-b55858171723,DISK], DatanodeInfoWithStorage[127.0.0.1:33648,DS-b759a164-f6b5-49c1-a03f-98dbb276f586,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1881135927-172.17.0.18-1597400498571:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45527,DS-3eec05cc-224b-4d00-95a7-d41b6023fa15,DISK], DatanodeInfoWithStorage[127.0.0.1:37145,DS-99e01504-9e1c-4f7d-b5c2-70b1c0da4e27,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-b3964d89-d849-4291-bebb-e35f39ff1264,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-91f70194-f9b1-4f6f-9e54-c7e7a34ad5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-3d235871-d8ce-4053-b26c-6bcad5f6e426,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-441035f8-1366-4a6b-b8be-062cc19b16eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-d13d3406-b122-41b2-b7df-2d13fe32e32e,DISK], DatanodeInfoWithStorage[127.0.0.1:38806,DS-988838ae-75bc-44b4-81c8-f6f235932f3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1881135927-172.17.0.18-1597400498571:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45527,DS-3eec05cc-224b-4d00-95a7-d41b6023fa15,DISK], DatanodeInfoWithStorage[127.0.0.1:37145,DS-99e01504-9e1c-4f7d-b5c2-70b1c0da4e27,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-b3964d89-d849-4291-bebb-e35f39ff1264,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-91f70194-f9b1-4f6f-9e54-c7e7a34ad5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-3d235871-d8ce-4053-b26c-6bcad5f6e426,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-441035f8-1366-4a6b-b8be-062cc19b16eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-d13d3406-b122-41b2-b7df-2d13fe32e32e,DISK], DatanodeInfoWithStorage[127.0.0.1:38806,DS-988838ae-75bc-44b4-81c8-f6f235932f3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-790213603-172.17.0.18-1597401523539:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43537,DS-e42b430d-739d-4b50-911b-9ea03bf2500d,DISK], DatanodeInfoWithStorage[127.0.0.1:40510,DS-4d87c0ea-f5d5-4569-ba28-db99e4cd3357,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-e8cc1bb8-64d6-4921-81a0-1c990c162869,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-58aeb311-e87f-4178-92b2-7ab04ea1e6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-03fd09e0-47a7-4a5b-828c-ea93468b5c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-4e53a270-d046-467d-9690-f4bb39f89194,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-9d5bb479-3b3b-4114-ba59-b8dce06afab9,DISK], DatanodeInfoWithStorage[127.0.0.1:37505,DS-88d06fdf-7711-4958-98b8-338642f4c1a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-790213603-172.17.0.18-1597401523539:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43537,DS-e42b430d-739d-4b50-911b-9ea03bf2500d,DISK], DatanodeInfoWithStorage[127.0.0.1:40510,DS-4d87c0ea-f5d5-4569-ba28-db99e4cd3357,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-e8cc1bb8-64d6-4921-81a0-1c990c162869,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-58aeb311-e87f-4178-92b2-7ab04ea1e6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-03fd09e0-47a7-4a5b-828c-ea93468b5c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-4e53a270-d046-467d-9690-f4bb39f89194,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-9d5bb479-3b3b-4114-ba59-b8dce06afab9,DISK], DatanodeInfoWithStorage[127.0.0.1:37505,DS-88d06fdf-7711-4958-98b8-338642f4c1a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2004567469-172.17.0.18-1597401864205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33886,DS-ab058045-acb5-44ba-9222-68160c90ac6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-96cb13d8-7c34-46ce-807f-2c14dbb77746,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-3e8f1451-d24b-43a3-a0b6-0ed216669afe,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-e9bea91d-a88d-4d54-83b9-934b8a353fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-4120ea21-3cc4-408a-bd55-d274883bc974,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-3f4d10cf-01b1-41ec-a860-dfe062df8a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44768,DS-831de530-92eb-4f1b-a8e7-81efac6ce595,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-03ba631a-b597-4f8b-bd3b-a3b5ac727836,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2004567469-172.17.0.18-1597401864205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33886,DS-ab058045-acb5-44ba-9222-68160c90ac6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-96cb13d8-7c34-46ce-807f-2c14dbb77746,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-3e8f1451-d24b-43a3-a0b6-0ed216669afe,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-e9bea91d-a88d-4d54-83b9-934b8a353fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-4120ea21-3cc4-408a-bd55-d274883bc974,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-3f4d10cf-01b1-41ec-a860-dfe062df8a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44768,DS-831de530-92eb-4f1b-a8e7-81efac6ce595,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-03ba631a-b597-4f8b-bd3b-a3b5ac727836,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-350690756-172.17.0.18-1597402609131:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40726,DS-ff561265-133d-49b2-a22f-e6f4017daee4,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-09214a8f-f572-4de3-9753-39024642a097,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-77a9a8e0-2767-40fc-92c7-52ae3c3db3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-9274d501-856e-400b-b233-2dc886e10df2,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-09b9c4e4-e9af-4e3f-88b9-efff42219ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:38475,DS-30d0ec6c-9d94-4ee3-a245-ef8f3668fb80,DISK], DatanodeInfoWithStorage[127.0.0.1:46750,DS-aaca88f0-9ba5-4bf5-bbd0-58f373fedbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-59d398e9-c85d-4f2e-a238-95c9693b4cf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-350690756-172.17.0.18-1597402609131:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40726,DS-ff561265-133d-49b2-a22f-e6f4017daee4,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-09214a8f-f572-4de3-9753-39024642a097,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-77a9a8e0-2767-40fc-92c7-52ae3c3db3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-9274d501-856e-400b-b233-2dc886e10df2,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-09b9c4e4-e9af-4e3f-88b9-efff42219ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:38475,DS-30d0ec6c-9d94-4ee3-a245-ef8f3668fb80,DISK], DatanodeInfoWithStorage[127.0.0.1:46750,DS-aaca88f0-9ba5-4bf5-bbd0-58f373fedbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-59d398e9-c85d-4f2e-a238-95c9693b4cf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-423994007-172.17.0.18-1597402835778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43054,DS-07d6e9b0-9f96-463a-b1c9-255c82c6f882,DISK], DatanodeInfoWithStorage[127.0.0.1:37294,DS-f33c9a43-b39d-4f40-ad74-d23ebe454777,DISK], DatanodeInfoWithStorage[127.0.0.1:43700,DS-8a4e8763-852a-4178-bc12-7d9a88e078dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41532,DS-053ebf12-999f-44ca-9fbe-402ef1edabfa,DISK], DatanodeInfoWithStorage[127.0.0.1:39925,DS-c66f058c-1b81-457c-8256-046b25582aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-d3dd6029-98e7-4bfa-8e20-a1a399c21906,DISK], DatanodeInfoWithStorage[127.0.0.1:36312,DS-6feca7ed-9a80-4307-bd69-4fccd51ad5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-dfd1dbfc-3e75-43c0-a0e9-0398437652de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-423994007-172.17.0.18-1597402835778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43054,DS-07d6e9b0-9f96-463a-b1c9-255c82c6f882,DISK], DatanodeInfoWithStorage[127.0.0.1:37294,DS-f33c9a43-b39d-4f40-ad74-d23ebe454777,DISK], DatanodeInfoWithStorage[127.0.0.1:43700,DS-8a4e8763-852a-4178-bc12-7d9a88e078dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41532,DS-053ebf12-999f-44ca-9fbe-402ef1edabfa,DISK], DatanodeInfoWithStorage[127.0.0.1:39925,DS-c66f058c-1b81-457c-8256-046b25582aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-d3dd6029-98e7-4bfa-8e20-a1a399c21906,DISK], DatanodeInfoWithStorage[127.0.0.1:36312,DS-6feca7ed-9a80-4307-bd69-4fccd51ad5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-dfd1dbfc-3e75-43c0-a0e9-0398437652de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-898539762-172.17.0.18-1597402940905:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38721,DS-fbf69b1c-c854-4eae-86b8-e7e5fb404da8,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-f595bfcb-3615-483e-aefe-f0eec40ff672,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-64e7a4a8-9d88-4f32-9f30-a852515b3842,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-3c356036-d170-4836-bd42-5e25fd2b9262,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-68cf880e-be34-4288-8108-414f04abfe16,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-dd7d0ce5-a028-4049-bbdb-f262a19a29a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43517,DS-3fe898dd-217e-41d4-be35-be1883abaa91,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-c5238eca-3220-4e3d-b8ff-dd893de46c6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-898539762-172.17.0.18-1597402940905:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38721,DS-fbf69b1c-c854-4eae-86b8-e7e5fb404da8,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-f595bfcb-3615-483e-aefe-f0eec40ff672,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-64e7a4a8-9d88-4f32-9f30-a852515b3842,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-3c356036-d170-4836-bd42-5e25fd2b9262,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-68cf880e-be34-4288-8108-414f04abfe16,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-dd7d0ce5-a028-4049-bbdb-f262a19a29a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43517,DS-3fe898dd-217e-41d4-be35-be1883abaa91,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-c5238eca-3220-4e3d-b8ff-dd893de46c6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1923553303-172.17.0.18-1597403281779:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42117,DS-b6c92354-31d3-47c2-b3aa-8a7e13846666,DISK], DatanodeInfoWithStorage[127.0.0.1:34047,DS-948a16f2-acfb-4b65-ab84-af5998919d10,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-eca52180-a7ab-4ce8-99ef-1a57a0e136e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-fd77361c-c82e-4d31-bece-a4145c319310,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-614617b5-50be-4dc0-8a2e-2d645793ce30,DISK], DatanodeInfoWithStorage[127.0.0.1:34293,DS-d8f0f784-ec61-43ce-b133-d12aea6ab0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-71e8eb2c-296a-41a6-a36b-36b0adcfe6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-86c86372-2d53-4378-adac-d078328c8cda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1923553303-172.17.0.18-1597403281779:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42117,DS-b6c92354-31d3-47c2-b3aa-8a7e13846666,DISK], DatanodeInfoWithStorage[127.0.0.1:34047,DS-948a16f2-acfb-4b65-ab84-af5998919d10,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-eca52180-a7ab-4ce8-99ef-1a57a0e136e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-fd77361c-c82e-4d31-bece-a4145c319310,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-614617b5-50be-4dc0-8a2e-2d645793ce30,DISK], DatanodeInfoWithStorage[127.0.0.1:34293,DS-d8f0f784-ec61-43ce-b133-d12aea6ab0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-71e8eb2c-296a-41a6-a36b-36b0adcfe6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-86c86372-2d53-4378-adac-d078328c8cda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1350952859-172.17.0.18-1597403331087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40509,DS-d242c818-317c-4768-bd53-2ed5f5a6460e,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-2a8dc5bf-8ecd-46fd-bdcf-54cc97debc2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-031f79e7-37a9-4fcb-9174-3a18d81a5895,DISK], DatanodeInfoWithStorage[127.0.0.1:39348,DS-5cbd614d-8c69-46c2-963b-bb0c8db624a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-16ec8cd9-9d21-4879-949b-267d7bd6aeb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-4ca6c756-2349-480f-9253-f7a3d21b54e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-3a5378fa-b5d3-4c4c-aa63-5b35c6dbe045,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-32ffb922-8b25-4c97-8684-30527277e228,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1350952859-172.17.0.18-1597403331087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40509,DS-d242c818-317c-4768-bd53-2ed5f5a6460e,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-2a8dc5bf-8ecd-46fd-bdcf-54cc97debc2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-031f79e7-37a9-4fcb-9174-3a18d81a5895,DISK], DatanodeInfoWithStorage[127.0.0.1:39348,DS-5cbd614d-8c69-46c2-963b-bb0c8db624a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-16ec8cd9-9d21-4879-949b-267d7bd6aeb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-4ca6c756-2349-480f-9253-f7a3d21b54e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-3a5378fa-b5d3-4c4c-aa63-5b35c6dbe045,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-32ffb922-8b25-4c97-8684-30527277e228,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-169786326-172.17.0.18-1597403717293:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45766,DS-6b1d4553-6aff-40ea-b419-08dc70902978,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-716def5b-6e93-467e-86d9-b017403e4731,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-8fb4c461-4204-4872-863c-f3ae2f19223b,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-2bf441ef-9daa-438c-9a84-6cd2db8e27c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37400,DS-8a5d6912-13c7-42f5-b1fe-f2f6c8e074b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-63c2a4e6-6c5d-4ce3-b86f-81f6f77f9fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-fe332554-f8e3-4704-b122-aaa03cf0ae82,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-aa41cbca-09c5-4705-85b0-074ac041a718,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-169786326-172.17.0.18-1597403717293:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45766,DS-6b1d4553-6aff-40ea-b419-08dc70902978,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-716def5b-6e93-467e-86d9-b017403e4731,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-8fb4c461-4204-4872-863c-f3ae2f19223b,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-2bf441ef-9daa-438c-9a84-6cd2db8e27c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37400,DS-8a5d6912-13c7-42f5-b1fe-f2f6c8e074b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-63c2a4e6-6c5d-4ce3-b86f-81f6f77f9fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-fe332554-f8e3-4704-b122-aaa03cf0ae82,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-aa41cbca-09c5-4705-85b0-074ac041a718,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-118176361-172.17.0.18-1597403758543:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37205,DS-d68f9c59-9f88-477d-aa8e-73a33b10fd5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-e064bd3e-7fbf-4ec4-8eb5-9700a7396f17,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-12d671df-2c89-40a0-b303-7869ce8e16a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-040fb005-49ac-44da-9e23-c742330a161f,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-38118397-a541-4593-86f4-8ca8d1cd07f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-e0c81bba-32e5-49da-a1da-694b69e22e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-4cbe0260-5e0e-4239-8257-2f7403792086,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-8a02028b-2f4f-46ac-8cd9-be447082e9e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-118176361-172.17.0.18-1597403758543:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37205,DS-d68f9c59-9f88-477d-aa8e-73a33b10fd5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-e064bd3e-7fbf-4ec4-8eb5-9700a7396f17,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-12d671df-2c89-40a0-b303-7869ce8e16a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-040fb005-49ac-44da-9e23-c742330a161f,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-38118397-a541-4593-86f4-8ca8d1cd07f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-e0c81bba-32e5-49da-a1da-694b69e22e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-4cbe0260-5e0e-4239-8257-2f7403792086,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-8a02028b-2f4f-46ac-8cd9-be447082e9e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-311400364-172.17.0.18-1597404164456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44539,DS-90ebd8d0-b3a4-4776-976a-a49a4a963e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-03bf4865-12be-4527-961a-73c25dfc74d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-526c3168-413b-44d1-9ac7-cf928f4e99aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-8abafc81-5a93-4030-b7c7-92d89d4dc35b,DISK], DatanodeInfoWithStorage[127.0.0.1:38295,DS-cc0e2093-6553-4800-b9c4-c11c7aa6c3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-eba7fdf7-77d1-4bed-9911-0159c248add6,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-9196f29f-ce07-4934-b722-a0a0ce640dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-81d92021-3592-4b03-b36c-1062887f064f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-311400364-172.17.0.18-1597404164456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44539,DS-90ebd8d0-b3a4-4776-976a-a49a4a963e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-03bf4865-12be-4527-961a-73c25dfc74d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-526c3168-413b-44d1-9ac7-cf928f4e99aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-8abafc81-5a93-4030-b7c7-92d89d4dc35b,DISK], DatanodeInfoWithStorage[127.0.0.1:38295,DS-cc0e2093-6553-4800-b9c4-c11c7aa6c3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-eba7fdf7-77d1-4bed-9911-0159c248add6,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-9196f29f-ce07-4934-b722-a0a0ce640dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-81d92021-3592-4b03-b36c-1062887f064f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 7127
