reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-479378094-172.17.0.3-1597496152364:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39506,DS-457e1010-646d-45ec-a66f-6971df0fd056,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-e6dc2e7c-2880-4582-8231-3a657d77bf4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-8a1148df-26ac-4dae-a793-a2e76b3ef58d,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-e378edbb-bb6e-449e-b2f4-b04f24779a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-7bf8aa64-9276-4a68-9bb2-89c71036dd22,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-e1712607-6d61-4683-8f2e-a52de5c45a41,DISK], DatanodeInfoWithStorage[127.0.0.1:40191,DS-b4e0d27e-5dd3-4295-b2a6-53c116cb7545,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-84512cb4-f69c-4657-a087-bb6950501824,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-479378094-172.17.0.3-1597496152364:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39506,DS-457e1010-646d-45ec-a66f-6971df0fd056,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-e6dc2e7c-2880-4582-8231-3a657d77bf4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-8a1148df-26ac-4dae-a793-a2e76b3ef58d,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-e378edbb-bb6e-449e-b2f4-b04f24779a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-7bf8aa64-9276-4a68-9bb2-89c71036dd22,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-e1712607-6d61-4683-8f2e-a52de5c45a41,DISK], DatanodeInfoWithStorage[127.0.0.1:40191,DS-b4e0d27e-5dd3-4295-b2a6-53c116cb7545,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-84512cb4-f69c-4657-a087-bb6950501824,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2102211526-172.17.0.3-1597496464292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34116,DS-05ff874a-10ef-4f5f-8ad9-7acdc4d93441,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-9a2c30c1-d80c-406a-9ef8-e595ec5cb0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-a380bc5f-b8ce-4a11-ac63-10f8315fb408,DISK], DatanodeInfoWithStorage[127.0.0.1:38600,DS-a3b39807-003d-4318-8971-1a9193f9d24d,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-84dbdb25-e53c-4f24-bbab-d7bc9dc55630,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-254a2227-6e17-42aa-aedd-76d9b4a72cde,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-464bf598-87ec-43d7-8516-9e91b58db6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-4e4192e7-ef64-44e8-a1db-4747c1b9bcb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2102211526-172.17.0.3-1597496464292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34116,DS-05ff874a-10ef-4f5f-8ad9-7acdc4d93441,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-9a2c30c1-d80c-406a-9ef8-e595ec5cb0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-a380bc5f-b8ce-4a11-ac63-10f8315fb408,DISK], DatanodeInfoWithStorage[127.0.0.1:38600,DS-a3b39807-003d-4318-8971-1a9193f9d24d,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-84dbdb25-e53c-4f24-bbab-d7bc9dc55630,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-254a2227-6e17-42aa-aedd-76d9b4a72cde,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-464bf598-87ec-43d7-8516-9e91b58db6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-4e4192e7-ef64-44e8-a1db-4747c1b9bcb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-80882359-172.17.0.3-1597497707546:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35806,DS-6d49a5a3-1d2b-4551-9e74-b12f20ce2661,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-bf50c73d-9812-485f-84dc-724b26ca0371,DISK], DatanodeInfoWithStorage[127.0.0.1:37105,DS-27aebc11-850a-41f0-ae51-4163800b4b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-804fa8f1-ba40-4149-a83d-dd11421b8c53,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-e296dcf2-e70a-4b99-b39a-957240e1de23,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-9d94a0c7-bd5f-4da9-a3e1-bed4efdaad55,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-d10fdbd9-69d3-4ac3-be2f-fdd6f86d894c,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-3692deb7-8130-496f-9308-ae71ec236f4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-80882359-172.17.0.3-1597497707546:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35806,DS-6d49a5a3-1d2b-4551-9e74-b12f20ce2661,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-bf50c73d-9812-485f-84dc-724b26ca0371,DISK], DatanodeInfoWithStorage[127.0.0.1:37105,DS-27aebc11-850a-41f0-ae51-4163800b4b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-804fa8f1-ba40-4149-a83d-dd11421b8c53,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-e296dcf2-e70a-4b99-b39a-957240e1de23,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-9d94a0c7-bd5f-4da9-a3e1-bed4efdaad55,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-d10fdbd9-69d3-4ac3-be2f-fdd6f86d894c,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-3692deb7-8130-496f-9308-ae71ec236f4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1367588487-172.17.0.3-1597498015391:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42918,DS-d09ce41f-58e3-42b1-9f66-51b45b0740e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-833195c4-c2cb-4225-88ba-93ba328d8658,DISK], DatanodeInfoWithStorage[127.0.0.1:35761,DS-4f440f4a-1975-4005-899a-62d186bc70c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-4154b287-13ec-4384-90fc-ff287d2fc1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-93581dd3-29dc-435a-b97f-c8488e4de12c,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-8ca7840a-9734-4f61-836c-29354a81a75b,DISK], DatanodeInfoWithStorage[127.0.0.1:37769,DS-2e4e3fac-e71f-4c26-b635-7fc748b4b261,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-28d6efbc-603f-4f97-b71f-90a34c8454e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1367588487-172.17.0.3-1597498015391:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42918,DS-d09ce41f-58e3-42b1-9f66-51b45b0740e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-833195c4-c2cb-4225-88ba-93ba328d8658,DISK], DatanodeInfoWithStorage[127.0.0.1:35761,DS-4f440f4a-1975-4005-899a-62d186bc70c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-4154b287-13ec-4384-90fc-ff287d2fc1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-93581dd3-29dc-435a-b97f-c8488e4de12c,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-8ca7840a-9734-4f61-836c-29354a81a75b,DISK], DatanodeInfoWithStorage[127.0.0.1:37769,DS-2e4e3fac-e71f-4c26-b635-7fc748b4b261,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-28d6efbc-603f-4f97-b71f-90a34c8454e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-462024090-172.17.0.3-1597498150159:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43242,DS-abf04874-fb07-4db4-a49a-8d8114c7cd21,DISK], DatanodeInfoWithStorage[127.0.0.1:33031,DS-19b6fc2b-ec5f-49f3-9ab8-86236d8a30a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-98f58899-b9e3-4541-aab2-e69e7ecb7f54,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-b6cdc6df-4f01-419e-90f6-1eb44a8f743c,DISK], DatanodeInfoWithStorage[127.0.0.1:34529,DS-a23d1235-5078-40cf-ba9e-3d3d5479c4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-1c7eb0a0-b9a1-4050-8a6b-2c41395bb84f,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-ee56751c-d53e-4360-8fd0-ae6b970d3df2,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-3af6bb92-281f-4b67-84f0-4a14d5cf05cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-462024090-172.17.0.3-1597498150159:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43242,DS-abf04874-fb07-4db4-a49a-8d8114c7cd21,DISK], DatanodeInfoWithStorage[127.0.0.1:33031,DS-19b6fc2b-ec5f-49f3-9ab8-86236d8a30a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-98f58899-b9e3-4541-aab2-e69e7ecb7f54,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-b6cdc6df-4f01-419e-90f6-1eb44a8f743c,DISK], DatanodeInfoWithStorage[127.0.0.1:34529,DS-a23d1235-5078-40cf-ba9e-3d3d5479c4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-1c7eb0a0-b9a1-4050-8a6b-2c41395bb84f,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-ee56751c-d53e-4360-8fd0-ae6b970d3df2,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-3af6bb92-281f-4b67-84f0-4a14d5cf05cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1402682657-172.17.0.3-1597498380921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45518,DS-a4283758-f0df-4a0a-8c26-8c6a3aa96355,DISK], DatanodeInfoWithStorage[127.0.0.1:38542,DS-71ccb8b7-951b-4205-a942-fd18fa626567,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-edf6df12-b4bb-46f0-93be-7c953aff47e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-ba565f5f-9a6f-4dd7-a4fe-8f601ffa65c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44693,DS-aed90314-e9d4-4dbf-be41-aa89495278fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-28f801c0-2c5c-46c2-884f-5e6f5875c49b,DISK], DatanodeInfoWithStorage[127.0.0.1:42973,DS-dfb0ad9d-922b-4e8e-ba49-86825670e655,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-63a14b41-c420-4c45-b856-c705b472b3eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1402682657-172.17.0.3-1597498380921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45518,DS-a4283758-f0df-4a0a-8c26-8c6a3aa96355,DISK], DatanodeInfoWithStorage[127.0.0.1:38542,DS-71ccb8b7-951b-4205-a942-fd18fa626567,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-edf6df12-b4bb-46f0-93be-7c953aff47e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-ba565f5f-9a6f-4dd7-a4fe-8f601ffa65c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44693,DS-aed90314-e9d4-4dbf-be41-aa89495278fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-28f801c0-2c5c-46c2-884f-5e6f5875c49b,DISK], DatanodeInfoWithStorage[127.0.0.1:42973,DS-dfb0ad9d-922b-4e8e-ba49-86825670e655,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-63a14b41-c420-4c45-b856-c705b472b3eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-951726847-172.17.0.3-1597498562105:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37084,DS-99827ff4-a5a3-4b74-9635-dc69f809f89e,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-9d925203-0b4e-4b27-9201-8f9ae787b9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-60f572f3-f2d2-4ac5-89f6-7e86840a47a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-115ca1c4-6641-4dd5-9ef7-2d8c08ca7eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-76257830-408d-4dd4-b375-522638c00888,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-1311e4a2-e77b-4a21-8868-ce91c08bcf2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-79eb1a5e-3db6-472b-acd5-8d3e506d2cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-5db24aa2-12a4-4a43-98fd-537b1c8899a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-951726847-172.17.0.3-1597498562105:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37084,DS-99827ff4-a5a3-4b74-9635-dc69f809f89e,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-9d925203-0b4e-4b27-9201-8f9ae787b9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-60f572f3-f2d2-4ac5-89f6-7e86840a47a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-115ca1c4-6641-4dd5-9ef7-2d8c08ca7eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-76257830-408d-4dd4-b375-522638c00888,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-1311e4a2-e77b-4a21-8868-ce91c08bcf2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-79eb1a5e-3db6-472b-acd5-8d3e506d2cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-5db24aa2-12a4-4a43-98fd-537b1c8899a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-409831412-172.17.0.3-1597499351893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42395,DS-06f451ba-5f46-45f1-9b7c-f74eeb5df5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-bd4ee9a2-cff7-4f2e-ad92-a7e1ff217241,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-660fdcf9-f8d5-48a2-befd-2f4c5667a228,DISK], DatanodeInfoWithStorage[127.0.0.1:41420,DS-b5c9b29d-cb43-40d8-b9ad-959c4b8f166c,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-063df558-7949-4ff4-990d-486a0de2e91b,DISK], DatanodeInfoWithStorage[127.0.0.1:41513,DS-fec7f933-2002-4a29-a3d3-6ab7ea7061e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-cf5f7727-98c3-4d4b-9ba7-7c568e74d88e,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-b06cab28-1855-4359-9490-1534244ebf99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-409831412-172.17.0.3-1597499351893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42395,DS-06f451ba-5f46-45f1-9b7c-f74eeb5df5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-bd4ee9a2-cff7-4f2e-ad92-a7e1ff217241,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-660fdcf9-f8d5-48a2-befd-2f4c5667a228,DISK], DatanodeInfoWithStorage[127.0.0.1:41420,DS-b5c9b29d-cb43-40d8-b9ad-959c4b8f166c,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-063df558-7949-4ff4-990d-486a0de2e91b,DISK], DatanodeInfoWithStorage[127.0.0.1:41513,DS-fec7f933-2002-4a29-a3d3-6ab7ea7061e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-cf5f7727-98c3-4d4b-9ba7-7c568e74d88e,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-b06cab28-1855-4359-9490-1534244ebf99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-916090844-172.17.0.3-1597499453905:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42161,DS-96b39527-2e58-4114-a677-4d1e54d7df5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-8319ce2b-f796-42ad-b8ab-8638b8c9ec11,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-0ae55f2a-7fb2-4493-828c-527ff428fdf7,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-fab4cc57-3314-49da-8a90-96a18a7a06da,DISK], DatanodeInfoWithStorage[127.0.0.1:46044,DS-b3732f9a-aa35-4019-aab8-a69ee9547578,DISK], DatanodeInfoWithStorage[127.0.0.1:42333,DS-2de80b6f-a8be-4730-a94f-67306006da99,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-5ac2bd69-8fc2-4008-a561-4910619bac15,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-b438422d-c9f2-4abc-90bf-027b07183d92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-916090844-172.17.0.3-1597499453905:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42161,DS-96b39527-2e58-4114-a677-4d1e54d7df5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-8319ce2b-f796-42ad-b8ab-8638b8c9ec11,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-0ae55f2a-7fb2-4493-828c-527ff428fdf7,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-fab4cc57-3314-49da-8a90-96a18a7a06da,DISK], DatanodeInfoWithStorage[127.0.0.1:46044,DS-b3732f9a-aa35-4019-aab8-a69ee9547578,DISK], DatanodeInfoWithStorage[127.0.0.1:42333,DS-2de80b6f-a8be-4730-a94f-67306006da99,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-5ac2bd69-8fc2-4008-a561-4910619bac15,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-b438422d-c9f2-4abc-90bf-027b07183d92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-809752865-172.17.0.3-1597499501861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37436,DS-089c9e40-457e-457a-b63c-44e158cc54b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-6f741b15-ce2e-42ea-9caf-9423ebb1c5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-0b282844-44af-464f-b801-c0ccae8c1d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43670,DS-e3c776fe-9353-44c8-a453-6b92ee0a0917,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-f4bf04a3-b99c-4a41-9e42-dec4ce953a16,DISK], DatanodeInfoWithStorage[127.0.0.1:42057,DS-d1542c67-9eaf-4ad3-94e3-99d3934ef2af,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-2bdc2aef-6d3a-4589-908f-b1d84b83cf42,DISK], DatanodeInfoWithStorage[127.0.0.1:40722,DS-65ff1d7a-dc7a-4c98-9375-d63d18973956,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-809752865-172.17.0.3-1597499501861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37436,DS-089c9e40-457e-457a-b63c-44e158cc54b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-6f741b15-ce2e-42ea-9caf-9423ebb1c5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-0b282844-44af-464f-b801-c0ccae8c1d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43670,DS-e3c776fe-9353-44c8-a453-6b92ee0a0917,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-f4bf04a3-b99c-4a41-9e42-dec4ce953a16,DISK], DatanodeInfoWithStorage[127.0.0.1:42057,DS-d1542c67-9eaf-4ad3-94e3-99d3934ef2af,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-2bdc2aef-6d3a-4589-908f-b1d84b83cf42,DISK], DatanodeInfoWithStorage[127.0.0.1:40722,DS-65ff1d7a-dc7a-4c98-9375-d63d18973956,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1973485139-172.17.0.3-1597499541434:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44364,DS-61fd927e-45d8-45cd-b6a9-d2bbfd8da2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34207,DS-c9337d61-8d50-426a-a5c6-d68805e46319,DISK], DatanodeInfoWithStorage[127.0.0.1:45979,DS-20a8d34c-1538-4057-a86c-88e52fd44e64,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-4e763136-df8e-45bb-80e5-29d22357c344,DISK], DatanodeInfoWithStorage[127.0.0.1:46274,DS-ff876e7a-49c4-4847-9910-4fb2b5379943,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-65717759-b0dd-4c67-93a8-363e1ede6653,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-438afa8f-4536-4475-9384-98248fa160c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36843,DS-84363768-861c-4e6a-aee9-e6e2f71f7828,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1973485139-172.17.0.3-1597499541434:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44364,DS-61fd927e-45d8-45cd-b6a9-d2bbfd8da2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34207,DS-c9337d61-8d50-426a-a5c6-d68805e46319,DISK], DatanodeInfoWithStorage[127.0.0.1:45979,DS-20a8d34c-1538-4057-a86c-88e52fd44e64,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-4e763136-df8e-45bb-80e5-29d22357c344,DISK], DatanodeInfoWithStorage[127.0.0.1:46274,DS-ff876e7a-49c4-4847-9910-4fb2b5379943,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-65717759-b0dd-4c67-93a8-363e1ede6653,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-438afa8f-4536-4475-9384-98248fa160c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36843,DS-84363768-861c-4e6a-aee9-e6e2f71f7828,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-457087422-172.17.0.3-1597499838556:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40461,DS-381e46a7-72c5-416f-a7c3-fd381af1a7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-a1674679-92b5-4550-95ce-847a0eff0355,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-f56a7dd7-e663-42d5-9460-fe7a817804e4,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-7ed3c195-2725-447c-95f2-0aa600769dac,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-ebde7a0b-ad47-4c7b-9040-58cf0d804fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-e07a33ca-5128-49ff-880d-d845f0298e17,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-9281cc8b-1202-4503-9404-0e5b0c35cd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-5944df5a-4765-486e-973f-48a5d7da883b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-457087422-172.17.0.3-1597499838556:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40461,DS-381e46a7-72c5-416f-a7c3-fd381af1a7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-a1674679-92b5-4550-95ce-847a0eff0355,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-f56a7dd7-e663-42d5-9460-fe7a817804e4,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-7ed3c195-2725-447c-95f2-0aa600769dac,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-ebde7a0b-ad47-4c7b-9040-58cf0d804fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-e07a33ca-5128-49ff-880d-d845f0298e17,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-9281cc8b-1202-4503-9404-0e5b0c35cd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-5944df5a-4765-486e-973f-48a5d7da883b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-767117750-172.17.0.3-1597502377107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46048,DS-3f219a62-2eee-4d99-9b9a-7e41d85e7319,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-4fe687e9-11c2-4122-a416-babb91ffb679,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-29c325ca-a86e-4e99-a75e-9222b377c6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-5be1cf66-3580-4465-9de8-e90a69637628,DISK], DatanodeInfoWithStorage[127.0.0.1:37080,DS-7abe39f9-9b9e-43b4-88c6-00d54d61968e,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-a010c7bb-7bf4-47b2-8073-4d184a7e98b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-18c17e9e-3737-46dc-8aad-71e2c0e9bee9,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-63694d71-5603-4e60-af9c-341e3ea15783,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-767117750-172.17.0.3-1597502377107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46048,DS-3f219a62-2eee-4d99-9b9a-7e41d85e7319,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-4fe687e9-11c2-4122-a416-babb91ffb679,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-29c325ca-a86e-4e99-a75e-9222b377c6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-5be1cf66-3580-4465-9de8-e90a69637628,DISK], DatanodeInfoWithStorage[127.0.0.1:37080,DS-7abe39f9-9b9e-43b4-88c6-00d54d61968e,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-a010c7bb-7bf4-47b2-8073-4d184a7e98b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-18c17e9e-3737-46dc-8aad-71e2c0e9bee9,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-63694d71-5603-4e60-af9c-341e3ea15783,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1924983021-172.17.0.3-1597502422004:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42701,DS-2c9bfab4-8eeb-4d2a-9980-de5c98345eba,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-7ee17d35-2aa0-4330-85ec-e7361b3626c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-7bcd33c2-ca23-4555-976c-94280cb93000,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-4cad859a-58a9-417d-a3ab-ced35b9bcbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-01142c4b-3e8e-434f-a5c7-1589cf8d8064,DISK], DatanodeInfoWithStorage[127.0.0.1:35522,DS-e2661444-0107-4de5-9b40-b20a61fe6f29,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-8aa43600-2ef3-406c-9bc5-bfb429a6f914,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-9f82b72a-e2f6-47c2-85e1-698755b7d1aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1924983021-172.17.0.3-1597502422004:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42701,DS-2c9bfab4-8eeb-4d2a-9980-de5c98345eba,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-7ee17d35-2aa0-4330-85ec-e7361b3626c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-7bcd33c2-ca23-4555-976c-94280cb93000,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-4cad859a-58a9-417d-a3ab-ced35b9bcbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-01142c4b-3e8e-434f-a5c7-1589cf8d8064,DISK], DatanodeInfoWithStorage[127.0.0.1:35522,DS-e2661444-0107-4de5-9b40-b20a61fe6f29,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-8aa43600-2ef3-406c-9bc5-bfb429a6f914,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-9f82b72a-e2f6-47c2-85e1-698755b7d1aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1908231144-172.17.0.3-1597502663831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46801,DS-7d4a0e50-ed20-4548-9a74-ce024b050a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-4e940f08-00a5-4e8e-b417-620f584a8a65,DISK], DatanodeInfoWithStorage[127.0.0.1:37285,DS-56f395e5-6983-4a24-9dec-ecdc81906d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36754,DS-173cb5c8-2bff-430d-9aa7-2f233b3a8b30,DISK], DatanodeInfoWithStorage[127.0.0.1:33509,DS-ab887802-72f5-4b17-a532-541e6ab99461,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-c98389b9-0da0-407f-81f6-971421c2419e,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-57950e9b-9623-4e84-9e09-7a7df5680f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-9137940a-4e2e-4edc-90c5-d7a22c4a70b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1908231144-172.17.0.3-1597502663831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46801,DS-7d4a0e50-ed20-4548-9a74-ce024b050a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-4e940f08-00a5-4e8e-b417-620f584a8a65,DISK], DatanodeInfoWithStorage[127.0.0.1:37285,DS-56f395e5-6983-4a24-9dec-ecdc81906d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36754,DS-173cb5c8-2bff-430d-9aa7-2f233b3a8b30,DISK], DatanodeInfoWithStorage[127.0.0.1:33509,DS-ab887802-72f5-4b17-a532-541e6ab99461,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-c98389b9-0da0-407f-81f6-971421c2419e,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-57950e9b-9623-4e84-9e09-7a7df5680f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-9137940a-4e2e-4edc-90c5-d7a22c4a70b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-751977594-172.17.0.3-1597502939410:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46100,DS-e8c50126-ddda-4dbd-9443-cdef649ecee6,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-49d07137-0911-42df-bc8c-dd1a2ce2fc23,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-aef7932e-ba12-4772-8715-0b85811cd25a,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-f97e95b4-095d-4087-b761-06d7fd1b8557,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-be859350-4758-4a01-97d2-ee4eeefc038d,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-d00c7636-69a3-4044-a5f0-4a18da060322,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-608db101-0623-4b00-a801-457ad9b1c51f,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-a905e4ab-71f4-43bc-be14-600555011508,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-751977594-172.17.0.3-1597502939410:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46100,DS-e8c50126-ddda-4dbd-9443-cdef649ecee6,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-49d07137-0911-42df-bc8c-dd1a2ce2fc23,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-aef7932e-ba12-4772-8715-0b85811cd25a,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-f97e95b4-095d-4087-b761-06d7fd1b8557,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-be859350-4758-4a01-97d2-ee4eeefc038d,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-d00c7636-69a3-4044-a5f0-4a18da060322,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-608db101-0623-4b00-a801-457ad9b1c51f,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-a905e4ab-71f4-43bc-be14-600555011508,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6841
