reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130680742-172.17.0.5-1597560985225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37979,DS-80201cd1-f404-4ab5-931a-08e45b20d6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-69c2fdec-8d3e-44f1-85d2-6aa305a078af,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-57ce1097-ac92-4602-ab72-a1ded8042f74,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-f70a411e-06fe-47f8-88ce-e32711a09917,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-406c8fec-ef10-4bf1-919f-95cec29eb1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-17447d84-d8d1-4d47-89aa-42d431ee812b,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-e7b39723-1607-470c-9f04-ed283e127c12,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-d9e54b00-02c0-4f50-a136-d8a63b20f942,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130680742-172.17.0.5-1597560985225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37979,DS-80201cd1-f404-4ab5-931a-08e45b20d6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-69c2fdec-8d3e-44f1-85d2-6aa305a078af,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-57ce1097-ac92-4602-ab72-a1ded8042f74,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-f70a411e-06fe-47f8-88ce-e32711a09917,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-406c8fec-ef10-4bf1-919f-95cec29eb1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-17447d84-d8d1-4d47-89aa-42d431ee812b,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-e7b39723-1607-470c-9f04-ed283e127c12,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-d9e54b00-02c0-4f50-a136-d8a63b20f942,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1057139699-172.17.0.5-1597561024971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33183,DS-86b15d31-0497-4d31-bf62-75de9afb5a66,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-22f003fc-6751-4ec5-aeaa-f9ac8a157157,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-84d0640c-da25-4871-aff0-699ef186fb8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43585,DS-d5507e02-43e8-484f-baee-d22498094098,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-cd67dd68-7347-467d-a763-4fba8fd37624,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-0611a120-195f-4829-98b3-a9d8beb7a2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44821,DS-cf720fda-5048-4116-8578-0baf57b3fa44,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-900e8d80-d93d-43b1-9531-6dfdb63fce83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1057139699-172.17.0.5-1597561024971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33183,DS-86b15d31-0497-4d31-bf62-75de9afb5a66,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-22f003fc-6751-4ec5-aeaa-f9ac8a157157,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-84d0640c-da25-4871-aff0-699ef186fb8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43585,DS-d5507e02-43e8-484f-baee-d22498094098,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-cd67dd68-7347-467d-a763-4fba8fd37624,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-0611a120-195f-4829-98b3-a9d8beb7a2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44821,DS-cf720fda-5048-4116-8578-0baf57b3fa44,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-900e8d80-d93d-43b1-9531-6dfdb63fce83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-407773688-172.17.0.5-1597561064274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36179,DS-b467bcc2-c3eb-4549-a686-32c9e214d04b,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-8724d3d0-d8be-4834-bfe0-4e6f2c949eab,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-20f529ad-cb41-4939-9e48-ebbbce768f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-be3e0173-ec5a-4931-b507-2f25b476d893,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-278c7d34-98a6-463e-a77d-180a55accba3,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-3d820456-f023-49e4-bc16-ec11babf8a20,DISK], DatanodeInfoWithStorage[127.0.0.1:42158,DS-461b338c-86fd-4cdf-b2eb-5e4a0b7b2560,DISK], DatanodeInfoWithStorage[127.0.0.1:33141,DS-cc848201-0531-4064-8b29-d76aee17b162,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-407773688-172.17.0.5-1597561064274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36179,DS-b467bcc2-c3eb-4549-a686-32c9e214d04b,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-8724d3d0-d8be-4834-bfe0-4e6f2c949eab,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-20f529ad-cb41-4939-9e48-ebbbce768f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-be3e0173-ec5a-4931-b507-2f25b476d893,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-278c7d34-98a6-463e-a77d-180a55accba3,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-3d820456-f023-49e4-bc16-ec11babf8a20,DISK], DatanodeInfoWithStorage[127.0.0.1:42158,DS-461b338c-86fd-4cdf-b2eb-5e4a0b7b2560,DISK], DatanodeInfoWithStorage[127.0.0.1:33141,DS-cc848201-0531-4064-8b29-d76aee17b162,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1374230781-172.17.0.5-1597561375778:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44021,DS-46401333-dfd4-4c47-87fb-c53ce6dbceb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-5d598341-f3eb-4009-a5f8-380d18bd2d81,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-0e639f2d-72df-4754-9c54-f0943e60e85b,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-24050898-7a4d-42e9-b323-63d1c68591e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-1c83133a-2399-47c9-b657-8c6f625247ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-8a50e132-10ee-4d7e-adec-c1afd8e103c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45915,DS-a9469820-ceea-4b44-b8cc-b8323dbefde0,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-65508df4-56cc-44e3-8dec-fd4840a4617f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1374230781-172.17.0.5-1597561375778:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44021,DS-46401333-dfd4-4c47-87fb-c53ce6dbceb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-5d598341-f3eb-4009-a5f8-380d18bd2d81,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-0e639f2d-72df-4754-9c54-f0943e60e85b,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-24050898-7a4d-42e9-b323-63d1c68591e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-1c83133a-2399-47c9-b657-8c6f625247ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-8a50e132-10ee-4d7e-adec-c1afd8e103c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45915,DS-a9469820-ceea-4b44-b8cc-b8323dbefde0,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-65508df4-56cc-44e3-8dec-fd4840a4617f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-167029510-172.17.0.5-1597561646715:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45001,DS-32910529-7c22-4517-9bb0-706a0baa7ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-d0e108df-f32b-4111-ab4e-6261ae8422f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-380824dd-c954-4cec-bc99-664182f223cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-0257b746-0198-45c5-8d68-fe1feb6f0778,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-f163ca6c-0f5a-4494-a8bc-a59877db9e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-0f28d6a2-05b5-4751-b0f2-5666c08b59cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36211,DS-8f0c348a-c332-48a3-8c51-fb1a37b93798,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-708868ac-73c0-4af1-a6cf-5869f1832c8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-167029510-172.17.0.5-1597561646715:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45001,DS-32910529-7c22-4517-9bb0-706a0baa7ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-d0e108df-f32b-4111-ab4e-6261ae8422f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-380824dd-c954-4cec-bc99-664182f223cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-0257b746-0198-45c5-8d68-fe1feb6f0778,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-f163ca6c-0f5a-4494-a8bc-a59877db9e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-0f28d6a2-05b5-4751-b0f2-5666c08b59cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36211,DS-8f0c348a-c332-48a3-8c51-fb1a37b93798,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-708868ac-73c0-4af1-a6cf-5869f1832c8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-506751958-172.17.0.5-1597561716442:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44364,DS-022c9d8d-3e78-43fa-92ef-312a17ffcd72,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-7b2d2719-ddf5-41af-862e-5f2e397e7b06,DISK], DatanodeInfoWithStorage[127.0.0.1:32835,DS-5e7dc2b5-9d1e-4d9c-8b80-c9e695038bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-af0a7fc1-7c09-4de6-9cee-c624e478752b,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-ccd3ea92-cdf7-4f62-a286-6c8463bea0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-f9065775-0ddb-4269-8bb4-902782bad12f,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-ef29afab-7da3-408d-9251-7919bf1c340d,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-d3347eeb-7b16-49b8-b678-2667f3793400,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-506751958-172.17.0.5-1597561716442:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44364,DS-022c9d8d-3e78-43fa-92ef-312a17ffcd72,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-7b2d2719-ddf5-41af-862e-5f2e397e7b06,DISK], DatanodeInfoWithStorage[127.0.0.1:32835,DS-5e7dc2b5-9d1e-4d9c-8b80-c9e695038bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-af0a7fc1-7c09-4de6-9cee-c624e478752b,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-ccd3ea92-cdf7-4f62-a286-6c8463bea0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-f9065775-0ddb-4269-8bb4-902782bad12f,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-ef29afab-7da3-408d-9251-7919bf1c340d,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-d3347eeb-7b16-49b8-b678-2667f3793400,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-655866626-172.17.0.5-1597561953709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44607,DS-8a36ba30-2749-4377-a3c4-08d548a42ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-3ed77f70-e3c5-4849-a557-c53b882516cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-2509c008-0c5e-47ba-994b-6deb8f4ce883,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-976efd09-05cd-4f56-91bf-b5a697fd69ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-3c56e569-218c-42b0-877e-0e375f5d45a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-9d88339c-241a-47bc-a200-7c434ea76ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-f87fcf44-b396-4b27-8090-2ec18da709e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-f1c40f16-710e-4090-ad4e-a5366ef98fab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-655866626-172.17.0.5-1597561953709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44607,DS-8a36ba30-2749-4377-a3c4-08d548a42ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-3ed77f70-e3c5-4849-a557-c53b882516cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-2509c008-0c5e-47ba-994b-6deb8f4ce883,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-976efd09-05cd-4f56-91bf-b5a697fd69ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-3c56e569-218c-42b0-877e-0e375f5d45a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-9d88339c-241a-47bc-a200-7c434ea76ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-f87fcf44-b396-4b27-8090-2ec18da709e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-f1c40f16-710e-4090-ad4e-a5366ef98fab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1027468982-172.17.0.5-1597562278339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39793,DS-c6df7302-c2a4-4ca9-8084-49d0b423d0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-76657bf1-2409-4c25-9ae5-07d9eb7bf125,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-775e68b2-557f-4400-a2cc-3b6d37c46d29,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-b353f2a6-ff9b-40c3-b945-54580c8c5135,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-44daca61-44fe-4fe3-ab02-0a883532bfae,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-81ecdb09-00e8-4bd3-b439-f698c798bd52,DISK], DatanodeInfoWithStorage[127.0.0.1:34657,DS-490266ea-ef53-46d5-a9fa-bc901c8bfdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-e876805f-93b6-4ed4-96ee-a1f35d66e2e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1027468982-172.17.0.5-1597562278339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39793,DS-c6df7302-c2a4-4ca9-8084-49d0b423d0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-76657bf1-2409-4c25-9ae5-07d9eb7bf125,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-775e68b2-557f-4400-a2cc-3b6d37c46d29,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-b353f2a6-ff9b-40c3-b945-54580c8c5135,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-44daca61-44fe-4fe3-ab02-0a883532bfae,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-81ecdb09-00e8-4bd3-b439-f698c798bd52,DISK], DatanodeInfoWithStorage[127.0.0.1:34657,DS-490266ea-ef53-46d5-a9fa-bc901c8bfdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-e876805f-93b6-4ed4-96ee-a1f35d66e2e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-308177043-172.17.0.5-1597564289020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40802,DS-02ce9f41-d587-4e1e-816b-29ca9c7b3d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-490e3582-b514-4f81-a73e-928366240bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-edd0365a-2c24-4fb0-81a7-06b41f02380d,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-a91e8dbd-1f66-4018-a5b6-094b00ce6f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-5e777719-3ce2-4f0a-be9f-2a0efe1c32d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-483bdb37-e27e-4550-975a-f88d939bd4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-a88cba70-03f5-4718-8ee8-b86e337435af,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-edc25e42-01e4-4707-89b9-10e13e947c9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-308177043-172.17.0.5-1597564289020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40802,DS-02ce9f41-d587-4e1e-816b-29ca9c7b3d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-490e3582-b514-4f81-a73e-928366240bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-edd0365a-2c24-4fb0-81a7-06b41f02380d,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-a91e8dbd-1f66-4018-a5b6-094b00ce6f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-5e777719-3ce2-4f0a-be9f-2a0efe1c32d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-483bdb37-e27e-4550-975a-f88d939bd4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-a88cba70-03f5-4718-8ee8-b86e337435af,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-edc25e42-01e4-4707-89b9-10e13e947c9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-756841423-172.17.0.5-1597564687717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37066,DS-b5d27e16-f88e-4278-9060-16a606956830,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-d443bd25-1fbe-4a91-99fd-82420fffc8da,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-34dcae87-24cb-43d8-b272-82a1e493ec4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-eb8619f4-c2c7-4b01-9936-3a4dca401de0,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-5d10462d-0065-4fb6-bd1b-65d1d7698536,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-7644f397-19aa-4b59-bd7c-bf16e30bca96,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-f765fd02-d24f-455d-b62a-56352cedb422,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-786e3bd3-d147-43b3-86ed-7a0b451b54a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-756841423-172.17.0.5-1597564687717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37066,DS-b5d27e16-f88e-4278-9060-16a606956830,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-d443bd25-1fbe-4a91-99fd-82420fffc8da,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-34dcae87-24cb-43d8-b272-82a1e493ec4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-eb8619f4-c2c7-4b01-9936-3a4dca401de0,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-5d10462d-0065-4fb6-bd1b-65d1d7698536,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-7644f397-19aa-4b59-bd7c-bf16e30bca96,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-f765fd02-d24f-455d-b62a-56352cedb422,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-786e3bd3-d147-43b3-86ed-7a0b451b54a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-378789299-172.17.0.5-1597564764552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46346,DS-bf199143-29ff-46c5-a496-cbaa9c4669bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-a4f97a23-3b3d-45b1-b600-0de224760937,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-79fb614e-e8ec-48c1-ad8d-9f9de32f958e,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-fbcbbf1d-5409-41cb-84ac-672b91ecd524,DISK], DatanodeInfoWithStorage[127.0.0.1:45122,DS-535ea8c6-585b-450c-a503-adfe969dedef,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-fc3be131-190f-485d-b7a5-a2d42dfe0d54,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-dff83519-309a-480b-ab0c-e6d99a6fff12,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-1781432b-caa5-4df3-8c33-ebdf84ca8995,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-378789299-172.17.0.5-1597564764552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46346,DS-bf199143-29ff-46c5-a496-cbaa9c4669bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-a4f97a23-3b3d-45b1-b600-0de224760937,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-79fb614e-e8ec-48c1-ad8d-9f9de32f958e,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-fbcbbf1d-5409-41cb-84ac-672b91ecd524,DISK], DatanodeInfoWithStorage[127.0.0.1:45122,DS-535ea8c6-585b-450c-a503-adfe969dedef,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-fc3be131-190f-485d-b7a5-a2d42dfe0d54,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-dff83519-309a-480b-ab0c-e6d99a6fff12,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-1781432b-caa5-4df3-8c33-ebdf84ca8995,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1701348283-172.17.0.5-1597564881044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41970,DS-fb3129fe-f240-4c98-a2fe-539d69df4255,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-8c20bb10-a219-4693-a22d-379585166130,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-ad9ad027-491a-41d0-af29-5da63671873c,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-54e03d43-19db-451c-a598-7732df7f9995,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-d875c652-cd92-4461-9223-483d1e3232fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36040,DS-edd1c53b-d832-43bd-9759-b2dcfaeda192,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-cbc6672a-6eb2-45c5-ae30-7ee8bd1dfc08,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-2b5163f1-a02c-4a52-b663-2cb658ee0105,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1701348283-172.17.0.5-1597564881044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41970,DS-fb3129fe-f240-4c98-a2fe-539d69df4255,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-8c20bb10-a219-4693-a22d-379585166130,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-ad9ad027-491a-41d0-af29-5da63671873c,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-54e03d43-19db-451c-a598-7732df7f9995,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-d875c652-cd92-4461-9223-483d1e3232fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36040,DS-edd1c53b-d832-43bd-9759-b2dcfaeda192,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-cbc6672a-6eb2-45c5-ae30-7ee8bd1dfc08,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-2b5163f1-a02c-4a52-b663-2cb658ee0105,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1091463127-172.17.0.5-1597566457029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34832,DS-35eb9a4e-686b-4d21-b3e9-d352ce84f9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-e48eb8d1-aa8e-4835-a75d-22973117925f,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-741a028b-1a7d-4643-af18-1fca3787c243,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-ca9f07b0-b88d-440f-81ac-edeb5cee7f21,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-7a059634-f624-44e9-92f1-b8d245ca0ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-19f8e2a6-815f-49ac-bc07-bf29d4ee8968,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-5bb1262c-d97b-4ff6-a7bc-ca7b00c2ac34,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-79134870-6a10-45b4-8276-ea7a7347085e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1091463127-172.17.0.5-1597566457029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34832,DS-35eb9a4e-686b-4d21-b3e9-d352ce84f9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-e48eb8d1-aa8e-4835-a75d-22973117925f,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-741a028b-1a7d-4643-af18-1fca3787c243,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-ca9f07b0-b88d-440f-81ac-edeb5cee7f21,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-7a059634-f624-44e9-92f1-b8d245ca0ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-19f8e2a6-815f-49ac-bc07-bf29d4ee8968,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-5bb1262c-d97b-4ff6-a7bc-ca7b00c2ac34,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-79134870-6a10-45b4-8276-ea7a7347085e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 62914560
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1047513291-172.17.0.5-1597566494833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45272,DS-1fa6a541-247b-4d2b-89a0-6c9db34a3dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-63f45fe4-1483-4bff-a793-09f29b593093,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-e398d4f2-2a55-457d-9419-f90cbe956827,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-d09be6b8-90c7-432c-8158-3bbdac4c482a,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-8911c54b-b2c4-41da-9691-a9ebab83e90f,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-cb172eb2-8fbd-4989-b5ee-974bc29e00e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-ddbf6758-f199-4cea-bfaa-ccdad8873852,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-fdc022fa-0efb-4c50-99fa-6a0d7fb7cf49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1047513291-172.17.0.5-1597566494833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45272,DS-1fa6a541-247b-4d2b-89a0-6c9db34a3dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-63f45fe4-1483-4bff-a793-09f29b593093,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-e398d4f2-2a55-457d-9419-f90cbe956827,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-d09be6b8-90c7-432c-8158-3bbdac4c482a,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-8911c54b-b2c4-41da-9691-a9ebab83e90f,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-cb172eb2-8fbd-4989-b5ee-974bc29e00e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-ddbf6758-f199-4cea-bfaa-ccdad8873852,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-fdc022fa-0efb-4c50-99fa-6a0d7fb7cf49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5746
