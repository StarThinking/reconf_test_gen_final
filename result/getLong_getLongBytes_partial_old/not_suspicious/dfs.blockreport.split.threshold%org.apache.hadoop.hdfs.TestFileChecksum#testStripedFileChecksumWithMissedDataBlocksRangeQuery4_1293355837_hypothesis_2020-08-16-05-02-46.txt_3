reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-479780615-172.17.0.6-1597554420665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32964,DS-f1ef75d8-206e-4f3c-ad8d-22852feb242f,DISK], DatanodeInfoWithStorage[127.0.0.1:34923,DS-89e87bbc-3eb4-4099-bfca-379834ec3323,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-a248dfdf-1538-4d12-82fa-f81cca2158db,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-d3dedd6f-0de6-4d00-ba8c-e062943bb3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-edbcde41-f5cd-48e1-a17d-34ca1eb970a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-e89ec968-c0ca-47e1-8001-48ba50a27baa,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-d6b0586a-ccf5-4b87-82cd-7e431e7e3dde,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-bc358766-5f99-418e-a9e6-4e9105cd6f4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-479780615-172.17.0.6-1597554420665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32964,DS-f1ef75d8-206e-4f3c-ad8d-22852feb242f,DISK], DatanodeInfoWithStorage[127.0.0.1:34923,DS-89e87bbc-3eb4-4099-bfca-379834ec3323,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-a248dfdf-1538-4d12-82fa-f81cca2158db,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-d3dedd6f-0de6-4d00-ba8c-e062943bb3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-edbcde41-f5cd-48e1-a17d-34ca1eb970a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-e89ec968-c0ca-47e1-8001-48ba50a27baa,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-d6b0586a-ccf5-4b87-82cd-7e431e7e3dde,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-bc358766-5f99-418e-a9e6-4e9105cd6f4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63977513-172.17.0.6-1597554653117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44524,DS-b874d71e-0785-4433-9776-117ff3ed6906,DISK], DatanodeInfoWithStorage[127.0.0.1:35293,DS-45b0e8e3-8d80-468f-b031-9d5a5361fa27,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-bb5dd116-cda7-4fde-ba99-75f5748d5487,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-5877789b-d573-4e2e-82a9-88d4a7df00a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-8b93de62-af1d-489a-b431-cdf823518fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-ba7245c7-2f97-4951-8adb-46abad906c14,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-0b7e1e65-3452-4c86-804f-e57e6af25916,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-82cc1958-5b40-4c2a-bb4d-856da5180876,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63977513-172.17.0.6-1597554653117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44524,DS-b874d71e-0785-4433-9776-117ff3ed6906,DISK], DatanodeInfoWithStorage[127.0.0.1:35293,DS-45b0e8e3-8d80-468f-b031-9d5a5361fa27,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-bb5dd116-cda7-4fde-ba99-75f5748d5487,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-5877789b-d573-4e2e-82a9-88d4a7df00a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-8b93de62-af1d-489a-b431-cdf823518fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-ba7245c7-2f97-4951-8adb-46abad906c14,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-0b7e1e65-3452-4c86-804f-e57e6af25916,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-82cc1958-5b40-4c2a-bb4d-856da5180876,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1872563234-172.17.0.6-1597554721981:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38276,DS-86b3e698-f476-4dcc-997a-b16493f28bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-16a83148-d477-4c11-8c69-31217c84226c,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-df51cc29-f923-4922-8572-03aabe6e3a41,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-343f93f6-8199-43ce-8d65-4791674ecf7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-de446020-2d09-47ea-9d8f-47fbba4162c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-d1ec0063-573e-4e05-922a-49b947e37a85,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-39c8e8af-9a42-4807-8ec3-54088e18e479,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-5c3a9e80-daf1-49e2-9c14-ec066c197f99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1872563234-172.17.0.6-1597554721981:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38276,DS-86b3e698-f476-4dcc-997a-b16493f28bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-16a83148-d477-4c11-8c69-31217c84226c,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-df51cc29-f923-4922-8572-03aabe6e3a41,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-343f93f6-8199-43ce-8d65-4791674ecf7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-de446020-2d09-47ea-9d8f-47fbba4162c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-d1ec0063-573e-4e05-922a-49b947e37a85,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-39c8e8af-9a42-4807-8ec3-54088e18e479,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-5c3a9e80-daf1-49e2-9c14-ec066c197f99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1615270237-172.17.0.6-1597554761400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44336,DS-09d72ac3-2040-4ad1-b1b1-2b3986aa1da5,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-9d8b0e96-5c3b-4ffc-a88b-461d966491b5,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-150dad86-c394-47e5-b7ea-fecbc476217e,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-3802b6c7-5ed3-4e32-93f0-2e9582e890a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-7f311a66-35dc-463b-8c90-a83f87dec940,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-08b1fc55-acf0-4ee3-8bef-34d5491b8380,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-774f99fa-aa2a-49e8-9dfc-8378ab85b9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44288,DS-4ee33c40-4761-4e68-ac54-6878f622ed33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1615270237-172.17.0.6-1597554761400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44336,DS-09d72ac3-2040-4ad1-b1b1-2b3986aa1da5,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-9d8b0e96-5c3b-4ffc-a88b-461d966491b5,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-150dad86-c394-47e5-b7ea-fecbc476217e,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-3802b6c7-5ed3-4e32-93f0-2e9582e890a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-7f311a66-35dc-463b-8c90-a83f87dec940,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-08b1fc55-acf0-4ee3-8bef-34d5491b8380,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-774f99fa-aa2a-49e8-9dfc-8378ab85b9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44288,DS-4ee33c40-4761-4e68-ac54-6878f622ed33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-722365296-172.17.0.6-1597554832925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44547,DS-a0712ae1-afd3-4faf-b3f0-cc6bf3128686,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-830f028b-dbba-4b76-a46a-0d24fbba6d90,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-7b02056f-8260-47c7-95a4-2f93339800d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-45ab0f7d-dc5a-4ef5-9d44-dcdf63cfdd4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-6c36b3a4-0128-441e-8495-52b1a1bd527b,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-506f586e-0450-4da4-b529-e54bd93deb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-0b43432d-21a7-4782-b51b-ed6283f328d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-9e922bdc-32e3-4a49-b93c-6437b6b083e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-722365296-172.17.0.6-1597554832925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44547,DS-a0712ae1-afd3-4faf-b3f0-cc6bf3128686,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-830f028b-dbba-4b76-a46a-0d24fbba6d90,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-7b02056f-8260-47c7-95a4-2f93339800d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-45ab0f7d-dc5a-4ef5-9d44-dcdf63cfdd4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-6c36b3a4-0128-441e-8495-52b1a1bd527b,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-506f586e-0450-4da4-b529-e54bd93deb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-0b43432d-21a7-4782-b51b-ed6283f328d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-9e922bdc-32e3-4a49-b93c-6437b6b083e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-40492323-172.17.0.6-1597554868937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42115,DS-fd6ef27b-902b-4c7a-9e2d-796b42feb216,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-81031ca5-d00d-4560-8dd9-6336fc2cba7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-58a70962-4b01-48fc-8888-13a428a5d46b,DISK], DatanodeInfoWithStorage[127.0.0.1:42317,DS-bba9140b-711c-4565-8fec-50302f3bd0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-f6fd4597-ede6-44f1-897c-8a87acd27b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-15b583d9-2c2f-4dcc-a4db-a21fd07c951a,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-aef5cf5b-6461-4463-8b3f-1acaf610e5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-d73da22b-02ca-4433-be4b-b46bc5b1f7e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-40492323-172.17.0.6-1597554868937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42115,DS-fd6ef27b-902b-4c7a-9e2d-796b42feb216,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-81031ca5-d00d-4560-8dd9-6336fc2cba7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-58a70962-4b01-48fc-8888-13a428a5d46b,DISK], DatanodeInfoWithStorage[127.0.0.1:42317,DS-bba9140b-711c-4565-8fec-50302f3bd0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-f6fd4597-ede6-44f1-897c-8a87acd27b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-15b583d9-2c2f-4dcc-a4db-a21fd07c951a,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-aef5cf5b-6461-4463-8b3f-1acaf610e5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-d73da22b-02ca-4433-be4b-b46bc5b1f7e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-478787678-172.17.0.6-1597555390309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40966,DS-d19cc9cd-3ef2-45be-8e5d-ad7b75ee7cba,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-6208763a-90db-4f61-ab9d-bf3adf0337d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-e5fdb1b3-fdfe-4a96-9eee-2bb162f8856e,DISK], DatanodeInfoWithStorage[127.0.0.1:37444,DS-44953991-1edf-4164-8745-4506189b6bda,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-bcaa7e51-a5ea-4547-b623-0bf22f5fad85,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-d1fe148d-8e12-499f-a67a-c18eeaaf6252,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-923a495c-019a-4237-a707-c630d38980aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33952,DS-1d754c7d-1cbf-4a27-9464-e6c16ae06ae0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-478787678-172.17.0.6-1597555390309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40966,DS-d19cc9cd-3ef2-45be-8e5d-ad7b75ee7cba,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-6208763a-90db-4f61-ab9d-bf3adf0337d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-e5fdb1b3-fdfe-4a96-9eee-2bb162f8856e,DISK], DatanodeInfoWithStorage[127.0.0.1:37444,DS-44953991-1edf-4164-8745-4506189b6bda,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-bcaa7e51-a5ea-4547-b623-0bf22f5fad85,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-d1fe148d-8e12-499f-a67a-c18eeaaf6252,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-923a495c-019a-4237-a707-c630d38980aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33952,DS-1d754c7d-1cbf-4a27-9464-e6c16ae06ae0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1784732117-172.17.0.6-1597555430461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38880,DS-c1983aa9-9fd4-45c2-be00-5578936ae9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40121,DS-708c2969-7722-4e3b-9bec-c0650f51d350,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-6169a2c1-ddf5-4ceb-acae-90c5fd561998,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-b433e19b-907e-4822-a099-8f6b75f74b34,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-9f5377dd-5fb7-4fd8-9c40-593a41a052c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46757,DS-34c92073-fbf0-4c57-a927-89182ca294d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-14dbfdfd-8307-4437-86a5-4be0053aa655,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-e7d29a58-b400-4973-900c-0e1d928764c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1784732117-172.17.0.6-1597555430461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38880,DS-c1983aa9-9fd4-45c2-be00-5578936ae9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40121,DS-708c2969-7722-4e3b-9bec-c0650f51d350,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-6169a2c1-ddf5-4ceb-acae-90c5fd561998,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-b433e19b-907e-4822-a099-8f6b75f74b34,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-9f5377dd-5fb7-4fd8-9c40-593a41a052c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46757,DS-34c92073-fbf0-4c57-a927-89182ca294d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-14dbfdfd-8307-4437-86a5-4be0053aa655,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-e7d29a58-b400-4973-900c-0e1d928764c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1655276263-172.17.0.6-1597555464174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46072,DS-015b76e7-9512-48e6-a0e9-df8fb1073f86,DISK], DatanodeInfoWithStorage[127.0.0.1:42853,DS-08cb9e00-89aa-42b4-a2d4-89bd4271334c,DISK], DatanodeInfoWithStorage[127.0.0.1:41818,DS-aa6f333c-c360-49fb-a2f8-986a5c560ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-ae4a5251-c1db-4483-b134-2633a5f335fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-9dd798bc-63d5-48db-bff7-163338dce097,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-40d77ac7-3ba0-48e0-8080-a51f05f03d94,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-0f3cced0-1073-4c20-bc7f-639669db423f,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-e9c26204-5408-45d7-a573-bf57f140d198,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1655276263-172.17.0.6-1597555464174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46072,DS-015b76e7-9512-48e6-a0e9-df8fb1073f86,DISK], DatanodeInfoWithStorage[127.0.0.1:42853,DS-08cb9e00-89aa-42b4-a2d4-89bd4271334c,DISK], DatanodeInfoWithStorage[127.0.0.1:41818,DS-aa6f333c-c360-49fb-a2f8-986a5c560ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-ae4a5251-c1db-4483-b134-2633a5f335fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-9dd798bc-63d5-48db-bff7-163338dce097,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-40d77ac7-3ba0-48e0-8080-a51f05f03d94,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-0f3cced0-1073-4c20-bc7f-639669db423f,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-e9c26204-5408-45d7-a573-bf57f140d198,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-653926744-172.17.0.6-1597555820400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38730,DS-aa8c9906-e1eb-4ce8-ae36-8bcdce3200b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-462bf0f1-d4f1-47b7-9d29-1a7696b2f031,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-6665f7e8-717d-46ca-a4e0-99edc737493e,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-659b6466-958d-4be8-8205-3c7373f683eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-2d972ec2-f36b-4815-b5c4-fa0663bfc077,DISK], DatanodeInfoWithStorage[127.0.0.1:34291,DS-33058780-6a92-43a6-87af-5356281835b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-073455d3-ac8f-4a5e-a655-5975a117f4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-5a926376-7cd2-4aec-8858-4af6f2d6451c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-653926744-172.17.0.6-1597555820400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38730,DS-aa8c9906-e1eb-4ce8-ae36-8bcdce3200b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-462bf0f1-d4f1-47b7-9d29-1a7696b2f031,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-6665f7e8-717d-46ca-a4e0-99edc737493e,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-659b6466-958d-4be8-8205-3c7373f683eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-2d972ec2-f36b-4815-b5c4-fa0663bfc077,DISK], DatanodeInfoWithStorage[127.0.0.1:34291,DS-33058780-6a92-43a6-87af-5356281835b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-073455d3-ac8f-4a5e-a655-5975a117f4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-5a926376-7cd2-4aec-8858-4af6f2d6451c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-29522440-172.17.0.6-1597555973442:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45382,DS-bae15a8b-5309-4642-9c40-598cd8339588,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-7c292ae3-eb6b-4568-8a41-568ba30b6c52,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-48741bd7-ad78-4e74-a8d2-bddf9da2413d,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-d3d45db4-251f-4855-89de-59bce5ab43f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-94d420cd-eb95-40ae-910f-900657504a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-c8e5b916-5245-4f4e-9c80-3932946f291a,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-04b9fd54-5f29-4d9e-8c91-b694e1aab7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37894,DS-816333f4-658a-41e3-bec2-ae167dc8cee5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-29522440-172.17.0.6-1597555973442:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45382,DS-bae15a8b-5309-4642-9c40-598cd8339588,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-7c292ae3-eb6b-4568-8a41-568ba30b6c52,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-48741bd7-ad78-4e74-a8d2-bddf9da2413d,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-d3d45db4-251f-4855-89de-59bce5ab43f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-94d420cd-eb95-40ae-910f-900657504a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-c8e5b916-5245-4f4e-9c80-3932946f291a,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-04b9fd54-5f29-4d9e-8c91-b694e1aab7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37894,DS-816333f4-658a-41e3-bec2-ae167dc8cee5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1858325395-172.17.0.6-1597556170495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33509,DS-9890b0a3-8c64-44ae-8255-3fcc539840a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-67157a72-af05-488e-96ab-73b015660802,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-58ff882b-bc62-494a-8904-a699e0817f58,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-f06bcc21-37d1-4e14-b01f-49bff1e14916,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-0fb6c112-6163-4407-a0ee-a93bb3e34264,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-3b336e84-da29-4e9a-a136-dc947d06e72d,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-e77c7cf0-c9ae-43a9-ae11-fd98460c2dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34186,DS-34996f8e-608c-46da-9584-32e945d1133b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1858325395-172.17.0.6-1597556170495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33509,DS-9890b0a3-8c64-44ae-8255-3fcc539840a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-67157a72-af05-488e-96ab-73b015660802,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-58ff882b-bc62-494a-8904-a699e0817f58,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-f06bcc21-37d1-4e14-b01f-49bff1e14916,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-0fb6c112-6163-4407-a0ee-a93bb3e34264,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-3b336e84-da29-4e9a-a136-dc947d06e72d,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-e77c7cf0-c9ae-43a9-ae11-fd98460c2dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34186,DS-34996f8e-608c-46da-9584-32e945d1133b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1466488396-172.17.0.6-1597556281890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34871,DS-944c1a70-fd17-4948-9bc6-3f606be02088,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-3ce9057d-53d6-40d5-94c2-1ae76efd91ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-86278707-a6f3-4cdc-a529-00758a646622,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-b371d438-6670-45c5-8ebd-74770dded772,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-b967bc95-6b52-45de-8876-c419e7cf39c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-28841e32-6f5a-46fb-8493-3ab416be711a,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-fe3308c8-8707-40e9-88a7-2e490e1d1828,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-9978101a-a571-44ac-9f11-272c6e84019b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1466488396-172.17.0.6-1597556281890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34871,DS-944c1a70-fd17-4948-9bc6-3f606be02088,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-3ce9057d-53d6-40d5-94c2-1ae76efd91ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-86278707-a6f3-4cdc-a529-00758a646622,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-b371d438-6670-45c5-8ebd-74770dded772,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-b967bc95-6b52-45de-8876-c419e7cf39c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-28841e32-6f5a-46fb-8493-3ab416be711a,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-fe3308c8-8707-40e9-88a7-2e490e1d1828,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-9978101a-a571-44ac-9f11-272c6e84019b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1919200339-172.17.0.6-1597557046523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35512,DS-61548aa7-a0b8-4905-82f5-985e3508983b,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-6a776fbc-e425-4907-9b8c-760283cb01a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-6e64ca67-886d-42e4-8dc6-e01387dc341a,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-eb406254-4902-41be-801d-3952fa19e12e,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-c422953d-ef11-4a28-b3ae-9f3c8aada9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-5b8448a7-723e-4814-b65e-85009d2011f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-c881e9b8-b48b-469e-9131-73dd042559ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35013,DS-d2eab079-ce3a-4943-8fb5-2fedb77c41e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1919200339-172.17.0.6-1597557046523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35512,DS-61548aa7-a0b8-4905-82f5-985e3508983b,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-6a776fbc-e425-4907-9b8c-760283cb01a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-6e64ca67-886d-42e4-8dc6-e01387dc341a,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-eb406254-4902-41be-801d-3952fa19e12e,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-c422953d-ef11-4a28-b3ae-9f3c8aada9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-5b8448a7-723e-4814-b65e-85009d2011f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-c881e9b8-b48b-469e-9131-73dd042559ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35013,DS-d2eab079-ce3a-4943-8fb5-2fedb77c41e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1864234138-172.17.0.6-1597557644498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42626,DS-05901e57-3991-4206-8fd3-6ebb776d155d,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-42924c4c-33df-49b7-8814-20a77a139b03,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-8f788dae-b86f-48af-b23b-f6787bb599db,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-67e53dcd-dd27-4327-a3ed-e0fb744b7597,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-7c792c62-fe43-4485-8b02-c7fd975420ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-78a83061-b001-4b12-9273-4992276e09eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-779a86ae-cf66-4708-b28d-ab379726bb11,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-70f2665f-928f-436a-8bd1-f1ae9926b66c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1864234138-172.17.0.6-1597557644498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42626,DS-05901e57-3991-4206-8fd3-6ebb776d155d,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-42924c4c-33df-49b7-8814-20a77a139b03,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-8f788dae-b86f-48af-b23b-f6787bb599db,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-67e53dcd-dd27-4327-a3ed-e0fb744b7597,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-7c792c62-fe43-4485-8b02-c7fd975420ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-78a83061-b001-4b12-9273-4992276e09eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-779a86ae-cf66-4708-b28d-ab379726bb11,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-70f2665f-928f-436a-8bd1-f1ae9926b66c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-594688621-172.17.0.6-1597557683010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33767,DS-c9ceab67-c8e3-44a6-966b-8726559900ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-e38a7611-bd2d-4f75-bc4c-d4c0645def79,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-736dda96-ce38-470c-98c7-812c67e80cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38910,DS-d92aa834-cd85-4e13-a15b-9ef88de9a34e,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-61505eed-e467-4691-a4fb-f0199977354b,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-16e78d1b-948c-4451-8fcf-ba803033973a,DISK], DatanodeInfoWithStorage[127.0.0.1:46138,DS-c3e26218-dfe4-4ebe-b214-f362beb734b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41328,DS-073c9b3e-ec38-4833-9f9a-ee5084533d10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-594688621-172.17.0.6-1597557683010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33767,DS-c9ceab67-c8e3-44a6-966b-8726559900ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-e38a7611-bd2d-4f75-bc4c-d4c0645def79,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-736dda96-ce38-470c-98c7-812c67e80cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38910,DS-d92aa834-cd85-4e13-a15b-9ef88de9a34e,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-61505eed-e467-4691-a4fb-f0199977354b,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-16e78d1b-948c-4451-8fcf-ba803033973a,DISK], DatanodeInfoWithStorage[127.0.0.1:46138,DS-c3e26218-dfe4-4ebe-b214-f362beb734b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41328,DS-073c9b3e-ec38-4833-9f9a-ee5084533d10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1557248108-172.17.0.6-1597557859264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38209,DS-5e13b15f-a66a-466d-a8ba-3aeb6830a927,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-8f44c99a-1684-4bce-9f45-ab019e65d779,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-da9d09f9-bffd-4c61-a908-bfe6d5d391eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-314b0f51-f2c5-49b7-9666-41adccc71165,DISK], DatanodeInfoWithStorage[127.0.0.1:35408,DS-d99e4fe2-057a-4ef6-81c7-6358c17addb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-cc7ede7b-2d93-487e-a3c7-c74f56602bff,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-b8b0c9b5-a5fb-4ac2-8b08-f902b436aca8,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-d5d6861b-b4d5-4a78-bb9e-aee7b7eef5dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1557248108-172.17.0.6-1597557859264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38209,DS-5e13b15f-a66a-466d-a8ba-3aeb6830a927,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-8f44c99a-1684-4bce-9f45-ab019e65d779,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-da9d09f9-bffd-4c61-a908-bfe6d5d391eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-314b0f51-f2c5-49b7-9666-41adccc71165,DISK], DatanodeInfoWithStorage[127.0.0.1:35408,DS-d99e4fe2-057a-4ef6-81c7-6358c17addb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-cc7ede7b-2d93-487e-a3c7-c74f56602bff,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-b8b0c9b5-a5fb-4ac2-8b08-f902b436aca8,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-d5d6861b-b4d5-4a78-bb9e-aee7b7eef5dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-212136417-172.17.0.6-1597559180967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32830,DS-95a9e76a-52d6-4996-89ce-582d0079510b,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-323de1b5-7951-4d2f-aa9a-01b0c0b01b53,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-2ec49288-2480-4f0b-9a63-29115ff02adb,DISK], DatanodeInfoWithStorage[127.0.0.1:33463,DS-e5427c5c-91a8-41dd-b0dc-d1697b444bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-0c0df66c-8c02-47cf-84e9-ddb3046a632e,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-86e338dd-9b64-456b-a4d5-5b5ee96ab12a,DISK], DatanodeInfoWithStorage[127.0.0.1:37170,DS-df95e53d-8b76-4eeb-b7d8-0382aa9e14c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-f357a381-b133-4938-9f94-9d3e1143901b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-212136417-172.17.0.6-1597559180967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32830,DS-95a9e76a-52d6-4996-89ce-582d0079510b,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-323de1b5-7951-4d2f-aa9a-01b0c0b01b53,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-2ec49288-2480-4f0b-9a63-29115ff02adb,DISK], DatanodeInfoWithStorage[127.0.0.1:33463,DS-e5427c5c-91a8-41dd-b0dc-d1697b444bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-0c0df66c-8c02-47cf-84e9-ddb3046a632e,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-86e338dd-9b64-456b-a4d5-5b5ee96ab12a,DISK], DatanodeInfoWithStorage[127.0.0.1:37170,DS-df95e53d-8b76-4eeb-b7d8-0382aa9e14c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-f357a381-b133-4938-9f94-9d3e1143901b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1384944967-172.17.0.6-1597559569141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42827,DS-b53a6174-5af4-4f1e-8663-3a22121ad761,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-819a1c97-d043-41c8-a278-995b04d10eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-418c5060-d4c7-428a-a835-32f4cb601d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-1ee16bfd-ab38-46f1-aa54-2320d59212b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-b30f077e-539f-49eb-975c-78624fd2394e,DISK], DatanodeInfoWithStorage[127.0.0.1:45112,DS-0076b145-42af-49e4-b0f4-41a22e1ee51a,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-b16c8583-5140-49d9-87ee-6b65d4f718d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36911,DS-7013c740-fe7d-4d5d-83dd-529b7dc6bc8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1384944967-172.17.0.6-1597559569141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42827,DS-b53a6174-5af4-4f1e-8663-3a22121ad761,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-819a1c97-d043-41c8-a278-995b04d10eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-418c5060-d4c7-428a-a835-32f4cb601d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-1ee16bfd-ab38-46f1-aa54-2320d59212b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-b30f077e-539f-49eb-975c-78624fd2394e,DISK], DatanodeInfoWithStorage[127.0.0.1:45112,DS-0076b145-42af-49e4-b0f4-41a22e1ee51a,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-b16c8583-5140-49d9-87ee-6b65d4f718d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36911,DS-7013c740-fe7d-4d5d-83dd-529b7dc6bc8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1739250196-172.17.0.6-1597559687093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44073,DS-e03a3f12-ef16-44d7-8f85-9221cd88dfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42593,DS-cc04cf9f-06c8-4fa1-a06a-fe07d24845ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-08bbe665-2ca6-4c24-ac0b-6c57f4b67bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38726,DS-e8633a0e-0a6c-4d74-bfcd-5d1ae4a11c77,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-4be1c0a5-6aa1-401b-b66b-29d32fce5b77,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-1fb8bec4-7b8d-4d78-b58b-b5c0117a938d,DISK], DatanodeInfoWithStorage[127.0.0.1:39898,DS-b43864db-9676-45b2-a190-71ae9e7e9fac,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-04a49de9-37cc-4458-9243-9274aac90e1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1739250196-172.17.0.6-1597559687093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44073,DS-e03a3f12-ef16-44d7-8f85-9221cd88dfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42593,DS-cc04cf9f-06c8-4fa1-a06a-fe07d24845ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-08bbe665-2ca6-4c24-ac0b-6c57f4b67bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38726,DS-e8633a0e-0a6c-4d74-bfcd-5d1ae4a11c77,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-4be1c0a5-6aa1-401b-b66b-29d32fce5b77,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-1fb8bec4-7b8d-4d78-b58b-b5c0117a938d,DISK], DatanodeInfoWithStorage[127.0.0.1:39898,DS-b43864db-9676-45b2-a190-71ae9e7e9fac,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-04a49de9-37cc-4458-9243-9274aac90e1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5665
