reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1768452677-172.17.0.2-1597513839553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40985,DS-0039c3f7-55f0-4600-b2a7-b9cb191d51c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-d6e7d220-9918-44fc-ba0d-25f5dba46275,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-efb92adf-0014-4588-b81f-e45a4f3b8096,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-474f0e06-029c-4fc7-9de0-c299aac65ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-dfb2d38a-5553-4c66-8ef8-e645983e0e77,DISK], DatanodeInfoWithStorage[127.0.0.1:44545,DS-ea1fb28c-482a-43b6-9001-ed60e898962d,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-cd39eb87-4ff3-4230-a7d8-f190e75b3276,DISK], DatanodeInfoWithStorage[127.0.0.1:38266,DS-60b0685f-7802-4219-a15d-2d10c6fe7891,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1768452677-172.17.0.2-1597513839553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40985,DS-0039c3f7-55f0-4600-b2a7-b9cb191d51c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-d6e7d220-9918-44fc-ba0d-25f5dba46275,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-efb92adf-0014-4588-b81f-e45a4f3b8096,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-474f0e06-029c-4fc7-9de0-c299aac65ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-dfb2d38a-5553-4c66-8ef8-e645983e0e77,DISK], DatanodeInfoWithStorage[127.0.0.1:44545,DS-ea1fb28c-482a-43b6-9001-ed60e898962d,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-cd39eb87-4ff3-4230-a7d8-f190e75b3276,DISK], DatanodeInfoWithStorage[127.0.0.1:38266,DS-60b0685f-7802-4219-a15d-2d10c6fe7891,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1400470364-172.17.0.2-1597513951077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37721,DS-23278deb-5302-4cf9-ab26-92d334187393,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-45d4a0d0-0094-46ea-914b-2ccabb7f2667,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-fe9f2155-e295-44c0-928d-d013ec5a54ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44762,DS-9db58bd0-12dd-470d-8746-8d0a80a316e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34892,DS-ff2f087a-eeb0-4579-83e4-9e6e77a78f44,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-f165aee1-5e28-4455-aceb-b1fd4d8f1940,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-9d9eb47a-3af6-4dbf-b7b5-32c2698cafcc,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-2d537fcd-41db-44e8-85d4-c09220c47b6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1400470364-172.17.0.2-1597513951077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37721,DS-23278deb-5302-4cf9-ab26-92d334187393,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-45d4a0d0-0094-46ea-914b-2ccabb7f2667,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-fe9f2155-e295-44c0-928d-d013ec5a54ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44762,DS-9db58bd0-12dd-470d-8746-8d0a80a316e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34892,DS-ff2f087a-eeb0-4579-83e4-9e6e77a78f44,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-f165aee1-5e28-4455-aceb-b1fd4d8f1940,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-9d9eb47a-3af6-4dbf-b7b5-32c2698cafcc,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-2d537fcd-41db-44e8-85d4-c09220c47b6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1343987053-172.17.0.2-1597513994816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46137,DS-c8c60193-16fc-471d-9904-1db125f665bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-4d162b6b-b9a0-4074-a67b-e41ff6c23aae,DISK], DatanodeInfoWithStorage[127.0.0.1:37707,DS-2030c1b1-d215-4f16-9814-8447d9529e68,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-90ed6b3f-fddb-4cd9-b943-b1a4b85466ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-9332928a-df76-4717-a1fa-ac4f60f0d945,DISK], DatanodeInfoWithStorage[127.0.0.1:34918,DS-593ae906-6c56-488f-848d-087016f9ebf5,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-c5a23343-f5e9-4bcb-9251-2285844cef26,DISK], DatanodeInfoWithStorage[127.0.0.1:41727,DS-202ce7d2-ff19-4cf8-a4e3-908ed2407d73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1343987053-172.17.0.2-1597513994816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46137,DS-c8c60193-16fc-471d-9904-1db125f665bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-4d162b6b-b9a0-4074-a67b-e41ff6c23aae,DISK], DatanodeInfoWithStorage[127.0.0.1:37707,DS-2030c1b1-d215-4f16-9814-8447d9529e68,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-90ed6b3f-fddb-4cd9-b943-b1a4b85466ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-9332928a-df76-4717-a1fa-ac4f60f0d945,DISK], DatanodeInfoWithStorage[127.0.0.1:34918,DS-593ae906-6c56-488f-848d-087016f9ebf5,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-c5a23343-f5e9-4bcb-9251-2285844cef26,DISK], DatanodeInfoWithStorage[127.0.0.1:41727,DS-202ce7d2-ff19-4cf8-a4e3-908ed2407d73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712209259-172.17.0.2-1597514527786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42139,DS-95137e69-d9f3-4ad3-a1ad-af3a24aa043f,DISK], DatanodeInfoWithStorage[127.0.0.1:44135,DS-22c7cb66-4117-4f68-b67b-29d66da0cf09,DISK], DatanodeInfoWithStorage[127.0.0.1:45012,DS-61640bbb-b90b-4c91-9a35-79d94181c789,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-2c236d3c-cb2a-46af-a28c-9d5a7e975267,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-fe54aa9e-7665-41aa-bd36-5f112285d69e,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-ecf95a22-66b6-4bb8-be9e-97d4a4c5eb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-db83ab46-c489-4568-96db-704a4ab8041d,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-49c54ee3-4664-4937-98a4-2de5ce25ead1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712209259-172.17.0.2-1597514527786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42139,DS-95137e69-d9f3-4ad3-a1ad-af3a24aa043f,DISK], DatanodeInfoWithStorage[127.0.0.1:44135,DS-22c7cb66-4117-4f68-b67b-29d66da0cf09,DISK], DatanodeInfoWithStorage[127.0.0.1:45012,DS-61640bbb-b90b-4c91-9a35-79d94181c789,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-2c236d3c-cb2a-46af-a28c-9d5a7e975267,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-fe54aa9e-7665-41aa-bd36-5f112285d69e,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-ecf95a22-66b6-4bb8-be9e-97d4a4c5eb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-db83ab46-c489-4568-96db-704a4ab8041d,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-49c54ee3-4664-4937-98a4-2de5ce25ead1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1824743199-172.17.0.2-1597514639218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34127,DS-bb375151-e38d-4680-a2df-f5ed17bf7860,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-8f32654d-d731-40f1-99a7-e1888ee0d1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-01d9509a-3725-48c6-8633-351606387938,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-d7e33ad3-2243-41d3-b832-fdd3f73c6de2,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-827d9a81-42b5-465e-b210-a4dc5e33e10f,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-8c2f21f3-cab5-406a-9e0d-5848e0f9e988,DISK], DatanodeInfoWithStorage[127.0.0.1:45749,DS-5d28498e-9248-43ca-b974-3b4125652b77,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-ec99748f-50e5-4614-b1fc-0b646909abe7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1824743199-172.17.0.2-1597514639218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34127,DS-bb375151-e38d-4680-a2df-f5ed17bf7860,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-8f32654d-d731-40f1-99a7-e1888ee0d1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-01d9509a-3725-48c6-8633-351606387938,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-d7e33ad3-2243-41d3-b832-fdd3f73c6de2,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-827d9a81-42b5-465e-b210-a4dc5e33e10f,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-8c2f21f3-cab5-406a-9e0d-5848e0f9e988,DISK], DatanodeInfoWithStorage[127.0.0.1:45749,DS-5d28498e-9248-43ca-b974-3b4125652b77,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-ec99748f-50e5-4614-b1fc-0b646909abe7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-310507516-172.17.0.2-1597514868098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34357,DS-6764eadf-1862-40de-b495-7db8b5cbbbdd,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-fd5eaccf-b879-4351-b9e7-9f5f898e9a44,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-b29fc629-5124-47f4-8e90-71cfde512e23,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-edc2fa59-0277-4d13-bef4-6d513722cef6,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-099c685d-6c22-4916-8f37-020f3e047791,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-0f9c4a46-ae2f-4728-b86c-a2e4288c5097,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-b3c0a9e8-a553-4f2a-acc5-bc18da91b8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39351,DS-d2317155-64f9-4e70-accc-6d0b636dfc7a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-310507516-172.17.0.2-1597514868098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34357,DS-6764eadf-1862-40de-b495-7db8b5cbbbdd,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-fd5eaccf-b879-4351-b9e7-9f5f898e9a44,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-b29fc629-5124-47f4-8e90-71cfde512e23,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-edc2fa59-0277-4d13-bef4-6d513722cef6,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-099c685d-6c22-4916-8f37-020f3e047791,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-0f9c4a46-ae2f-4728-b86c-a2e4288c5097,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-b3c0a9e8-a553-4f2a-acc5-bc18da91b8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39351,DS-d2317155-64f9-4e70-accc-6d0b636dfc7a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-566481113-172.17.0.2-1597514910998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38771,DS-6008a841-79d2-4012-8e73-e36a556a0ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-9977cf3a-5adc-4e13-8e03-218f6f9f91f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-fb6b7f69-d286-4880-b51d-59e7c6c36c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-2cf4c2d2-b6ff-4e58-8f27-49518488161c,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-66a82c53-b455-4804-a07d-0e904d93af9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-5840ba67-1174-42d6-b75c-592ead3d758c,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-39a3da18-9bc0-4b98-bf9c-9d4987883590,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-141ea075-e724-4632-906b-a4c0d90536e3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-566481113-172.17.0.2-1597514910998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38771,DS-6008a841-79d2-4012-8e73-e36a556a0ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-9977cf3a-5adc-4e13-8e03-218f6f9f91f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-fb6b7f69-d286-4880-b51d-59e7c6c36c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-2cf4c2d2-b6ff-4e58-8f27-49518488161c,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-66a82c53-b455-4804-a07d-0e904d93af9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-5840ba67-1174-42d6-b75c-592ead3d758c,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-39a3da18-9bc0-4b98-bf9c-9d4987883590,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-141ea075-e724-4632-906b-a4c0d90536e3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1265239698-172.17.0.2-1597515097599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38589,DS-e1a1c6a2-8273-4ce3-af03-48948cd681ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-c166f589-1736-49c2-ad28-faf666af8040,DISK], DatanodeInfoWithStorage[127.0.0.1:42667,DS-0e7028e9-455c-4c09-933e-7cd757aee62e,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-10f2fdd2-fa7e-4fd5-a46e-be0b6c11f757,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-8a0491b5-4b1c-4c47-b15d-712d08bc360a,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-6a21a43e-2c9c-4bbd-b870-29b93343b772,DISK], DatanodeInfoWithStorage[127.0.0.1:41719,DS-e3eaecb0-cb2f-4d55-8440-5b54ba56c1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-cbc33548-19b6-46c9-a4d3-890484816c20,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1265239698-172.17.0.2-1597515097599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38589,DS-e1a1c6a2-8273-4ce3-af03-48948cd681ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-c166f589-1736-49c2-ad28-faf666af8040,DISK], DatanodeInfoWithStorage[127.0.0.1:42667,DS-0e7028e9-455c-4c09-933e-7cd757aee62e,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-10f2fdd2-fa7e-4fd5-a46e-be0b6c11f757,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-8a0491b5-4b1c-4c47-b15d-712d08bc360a,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-6a21a43e-2c9c-4bbd-b870-29b93343b772,DISK], DatanodeInfoWithStorage[127.0.0.1:41719,DS-e3eaecb0-cb2f-4d55-8440-5b54ba56c1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-cbc33548-19b6-46c9-a4d3-890484816c20,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-237995457-172.17.0.2-1597515135675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35211,DS-9a113413-e4f6-4f7f-bb66-fb80d5123ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-043310e2-8b34-4d47-9608-be9639ac69f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-a7216b58-cdaa-4e4e-acda-3791e80c9128,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-01ce60c5-ddc8-4214-b034-4aa78b924c78,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-48ecf472-aeb4-4c69-988e-6d95d8c2cb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-e2973af3-40c7-4ab5-bcfe-902c63aa5fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-06be8e22-1659-461f-8bb1-6708a7a1d0b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-e5666a20-c592-439f-857c-d78fd5f0a3a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-237995457-172.17.0.2-1597515135675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35211,DS-9a113413-e4f6-4f7f-bb66-fb80d5123ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-043310e2-8b34-4d47-9608-be9639ac69f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-a7216b58-cdaa-4e4e-acda-3791e80c9128,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-01ce60c5-ddc8-4214-b034-4aa78b924c78,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-48ecf472-aeb4-4c69-988e-6d95d8c2cb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-e2973af3-40c7-4ab5-bcfe-902c63aa5fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-06be8e22-1659-461f-8bb1-6708a7a1d0b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-e5666a20-c592-439f-857c-d78fd5f0a3a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-820651275-172.17.0.2-1597515247866:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42384,DS-c84b7097-c74d-4d55-bbe4-c10369199c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-7c2a4c0c-26cb-4afa-be88-2059290f2205,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-66b4ca56-2fa9-4c2e-b84e-5de9151be0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-c0e4b561-b1eb-4a1a-95ff-022d3efdd68e,DISK], DatanodeInfoWithStorage[127.0.0.1:43458,DS-78e9835f-ee66-46c5-ae10-8d98d6d2febb,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-0bfcf324-7295-4743-8d88-4973f25f5509,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-bfcb73f0-b8b8-4870-8dd5-3190d57f1ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-a2e9a13f-9192-4658-bd34-b536e03e1536,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-820651275-172.17.0.2-1597515247866:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42384,DS-c84b7097-c74d-4d55-bbe4-c10369199c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-7c2a4c0c-26cb-4afa-be88-2059290f2205,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-66b4ca56-2fa9-4c2e-b84e-5de9151be0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-c0e4b561-b1eb-4a1a-95ff-022d3efdd68e,DISK], DatanodeInfoWithStorage[127.0.0.1:43458,DS-78e9835f-ee66-46c5-ae10-8d98d6d2febb,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-0bfcf324-7295-4743-8d88-4973f25f5509,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-bfcb73f0-b8b8-4870-8dd5-3190d57f1ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-a2e9a13f-9192-4658-bd34-b536e03e1536,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-854771384-172.17.0.2-1597515471716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45309,DS-1ead4680-2212-4335-ab65-70e8019dd4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-f67d3175-073a-4fa6-9718-2d3823bc61ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-2a7b7474-c28e-4456-9409-653500f8a82e,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-49946bf5-69fa-44ff-a8ee-634c497e5c69,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-cc67c2b7-0d72-462f-8fe8-4b4ac81b6391,DISK], DatanodeInfoWithStorage[127.0.0.1:37290,DS-0404099b-3713-4b45-907c-e10c829d8bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-c0c0abdc-dcca-45e3-a4e8-b91d67b5add3,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-b248486a-8ee8-434b-a4b7-73901da57223,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-854771384-172.17.0.2-1597515471716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45309,DS-1ead4680-2212-4335-ab65-70e8019dd4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-f67d3175-073a-4fa6-9718-2d3823bc61ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-2a7b7474-c28e-4456-9409-653500f8a82e,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-49946bf5-69fa-44ff-a8ee-634c497e5c69,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-cc67c2b7-0d72-462f-8fe8-4b4ac81b6391,DISK], DatanodeInfoWithStorage[127.0.0.1:37290,DS-0404099b-3713-4b45-907c-e10c829d8bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-c0c0abdc-dcca-45e3-a4e8-b91d67b5add3,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-b248486a-8ee8-434b-a4b7-73901da57223,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-870762157-172.17.0.2-1597515724515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46582,DS-dc29020f-eceb-4dba-af28-69253611ebfc,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-54f35f48-c0ad-4b8d-8f4d-ea51808b8992,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-5359ea76-d771-4fee-b5bf-154945a48b53,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-7b36490c-3650-4af0-a74b-f65ca7b8ad37,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-18f9de62-d7af-4bbd-9370-9afb04be4fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-f75fdd08-7a73-4083-939e-99d673b39416,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-ca9674d9-43f3-437a-81df-055286001297,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-24c431cd-b551-42e2-93af-d2ed08f0e69a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-870762157-172.17.0.2-1597515724515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46582,DS-dc29020f-eceb-4dba-af28-69253611ebfc,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-54f35f48-c0ad-4b8d-8f4d-ea51808b8992,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-5359ea76-d771-4fee-b5bf-154945a48b53,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-7b36490c-3650-4af0-a74b-f65ca7b8ad37,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-18f9de62-d7af-4bbd-9370-9afb04be4fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-f75fdd08-7a73-4083-939e-99d673b39416,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-ca9674d9-43f3-437a-81df-055286001297,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-24c431cd-b551-42e2-93af-d2ed08f0e69a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1766135821-172.17.0.2-1597515833820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40383,DS-72f8d347-1baa-459a-acf9-992aa17959c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-88294e64-9f71-4c3c-b7ef-e06dd86ab129,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-c59a735a-b8b5-4bc0-8b14-ead116b66867,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-468f5f28-2e8d-4242-b533-33e51cd4df5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-fb6e9405-aa78-4b9d-a2d9-ed6eebe3317d,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-9036fbe0-fa5c-4706-bc08-b56e57322627,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-72b9b412-3fe2-4af1-9f55-929a50046017,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-3349e910-5727-4a2a-9934-fc13e72e2d8c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1766135821-172.17.0.2-1597515833820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40383,DS-72f8d347-1baa-459a-acf9-992aa17959c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-88294e64-9f71-4c3c-b7ef-e06dd86ab129,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-c59a735a-b8b5-4bc0-8b14-ead116b66867,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-468f5f28-2e8d-4242-b533-33e51cd4df5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-fb6e9405-aa78-4b9d-a2d9-ed6eebe3317d,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-9036fbe0-fa5c-4706-bc08-b56e57322627,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-72b9b412-3fe2-4af1-9f55-929a50046017,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-3349e910-5727-4a2a-9934-fc13e72e2d8c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-898008623-172.17.0.2-1597515956631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35740,DS-7f0076b0-8e59-44ae-bd20-b88e34f8397f,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-45293510-ed15-424d-a831-03893cdbd585,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-62e37525-c575-4422-8917-8d8df3f7b08d,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-2a9985cb-0699-4e4a-8d53-bc5879443423,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-4c6a27cb-2b84-4c4a-a8bb-311fa860e349,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-d34c5dfe-eece-4663-a38b-994f58924c53,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-aa5c34d1-231a-4da1-bbc5-01c651b17b90,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-69560827-8f79-4a79-90cf-83382d2998dc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-898008623-172.17.0.2-1597515956631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35740,DS-7f0076b0-8e59-44ae-bd20-b88e34f8397f,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-45293510-ed15-424d-a831-03893cdbd585,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-62e37525-c575-4422-8917-8d8df3f7b08d,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-2a9985cb-0699-4e4a-8d53-bc5879443423,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-4c6a27cb-2b84-4c4a-a8bb-311fa860e349,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-d34c5dfe-eece-4663-a38b-994f58924c53,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-aa5c34d1-231a-4da1-bbc5-01c651b17b90,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-69560827-8f79-4a79-90cf-83382d2998dc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-156376543-172.17.0.2-1597516159503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42650,DS-f9e8bb91-89d7-4053-8afe-3e8c5630bb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-dff5de0a-8968-40e9-80fc-3da7b1c5390f,DISK], DatanodeInfoWithStorage[127.0.0.1:37167,DS-c4497441-97da-4aab-ad93-bdbd9ae0c0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-b5e3c6a1-bcae-42b5-a54b-bd971ac431a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-98f134cf-2633-499d-a420-8d54967f5da0,DISK], DatanodeInfoWithStorage[127.0.0.1:37769,DS-22670db9-b479-4779-9538-63644be90d21,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-87daaeda-7e1a-47bb-acd6-53a2c6eabe10,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-4afecc79-a4ea-4f09-b289-1c1a160af0e1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-156376543-172.17.0.2-1597516159503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42650,DS-f9e8bb91-89d7-4053-8afe-3e8c5630bb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-dff5de0a-8968-40e9-80fc-3da7b1c5390f,DISK], DatanodeInfoWithStorage[127.0.0.1:37167,DS-c4497441-97da-4aab-ad93-bdbd9ae0c0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-b5e3c6a1-bcae-42b5-a54b-bd971ac431a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-98f134cf-2633-499d-a420-8d54967f5da0,DISK], DatanodeInfoWithStorage[127.0.0.1:37769,DS-22670db9-b479-4779-9538-63644be90d21,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-87daaeda-7e1a-47bb-acd6-53a2c6eabe10,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-4afecc79-a4ea-4f09-b289-1c1a160af0e1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-815892178-172.17.0.2-1597516235421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43828,DS-f09846cd-2a77-4f62-bdd4-b2efd98dea14,DISK], DatanodeInfoWithStorage[127.0.0.1:35062,DS-8f71843b-35d1-4306-baf6-c594cb0bf23b,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-a0ec1261-ec25-4b54-bf3c-88fbdef13cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-90a098d1-c28a-4ae5-a266-f9d32a9714e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-d9a93a04-2aed-41e2-9057-8ec8c067744b,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-4dd925d5-42d8-4535-8e1b-e73a5a28b7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44469,DS-af4308e0-66c5-450e-8b8c-5ff59b717e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-4ca65c61-4f18-469b-9881-053704455976,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-815892178-172.17.0.2-1597516235421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43828,DS-f09846cd-2a77-4f62-bdd4-b2efd98dea14,DISK], DatanodeInfoWithStorage[127.0.0.1:35062,DS-8f71843b-35d1-4306-baf6-c594cb0bf23b,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-a0ec1261-ec25-4b54-bf3c-88fbdef13cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-90a098d1-c28a-4ae5-a266-f9d32a9714e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-d9a93a04-2aed-41e2-9057-8ec8c067744b,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-4dd925d5-42d8-4535-8e1b-e73a5a28b7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44469,DS-af4308e0-66c5-450e-8b8c-5ff59b717e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-4ca65c61-4f18-469b-9881-053704455976,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1885500877-172.17.0.2-1597516354030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33454,DS-e5bd56ed-db0f-4b5e-a953-f9bb3d3c5baa,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-3355ecc6-644e-46f5-8ff5-728ca642d73c,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-387fc0a6-79c6-4024-82dd-fa5892576b28,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-b894166f-67f5-441e-baad-7338b301b109,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-97915275-0ac3-406a-bf34-ab7573513816,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-807de0ee-bcad-4ed7-9af6-5e35cfbe78de,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-5f6337a4-a415-4f01-95b5-eca5463fee68,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-37b14016-1f61-47ce-9902-aa3900968e72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1885500877-172.17.0.2-1597516354030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33454,DS-e5bd56ed-db0f-4b5e-a953-f9bb3d3c5baa,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-3355ecc6-644e-46f5-8ff5-728ca642d73c,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-387fc0a6-79c6-4024-82dd-fa5892576b28,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-b894166f-67f5-441e-baad-7338b301b109,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-97915275-0ac3-406a-bf34-ab7573513816,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-807de0ee-bcad-4ed7-9af6-5e35cfbe78de,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-5f6337a4-a415-4f01-95b5-eca5463fee68,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-37b14016-1f61-47ce-9902-aa3900968e72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1542792497-172.17.0.2-1597516397094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33484,DS-a501ad55-4300-437f-a26d-690d42c342bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-08cd7fb6-80a7-496b-8191-cf7aaec1189c,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-c4d4b9d4-ccf5-48c9-908f-266d84c176c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-0b9f07af-9968-4204-a820-c4b26a621a20,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-b9d029c6-c43b-4217-bb92-33cc1694f3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-afab81ba-7819-4870-9896-60e7d7950621,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-b8f4a789-cae9-411a-894b-fcb0845de806,DISK], DatanodeInfoWithStorage[127.0.0.1:37622,DS-281a2a52-3aa7-45fb-a7ae-0b6024f64ff2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1542792497-172.17.0.2-1597516397094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33484,DS-a501ad55-4300-437f-a26d-690d42c342bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-08cd7fb6-80a7-496b-8191-cf7aaec1189c,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-c4d4b9d4-ccf5-48c9-908f-266d84c176c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-0b9f07af-9968-4204-a820-c4b26a621a20,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-b9d029c6-c43b-4217-bb92-33cc1694f3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-afab81ba-7819-4870-9896-60e7d7950621,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-b8f4a789-cae9-411a-894b-fcb0845de806,DISK], DatanodeInfoWithStorage[127.0.0.1:37622,DS-281a2a52-3aa7-45fb-a7ae-0b6024f64ff2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-508760339-172.17.0.2-1597516980096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45305,DS-8d350715-ca4b-4f7a-812a-27066c7db09b,DISK], DatanodeInfoWithStorage[127.0.0.1:45862,DS-ecbd09e0-3a80-43c7-8e76-4a931ac19c52,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-6a41573b-9046-4de7-aed4-e2339eed9d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-078a1094-921a-480d-9935-31448956a43a,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-2bef2a0e-b083-4d92-a4cc-d2995d92fe69,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-e66037b4-cfdb-460d-a5a2-b840f5e761e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-2faf4624-d40e-4a49-a8aa-22b5439b4404,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-cae15232-e63a-4f11-8ac6-cb0b73b7c0f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-508760339-172.17.0.2-1597516980096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45305,DS-8d350715-ca4b-4f7a-812a-27066c7db09b,DISK], DatanodeInfoWithStorage[127.0.0.1:45862,DS-ecbd09e0-3a80-43c7-8e76-4a931ac19c52,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-6a41573b-9046-4de7-aed4-e2339eed9d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-078a1094-921a-480d-9935-31448956a43a,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-2bef2a0e-b083-4d92-a4cc-d2995d92fe69,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-e66037b4-cfdb-460d-a5a2-b840f5e761e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-2faf4624-d40e-4a49-a8aa-22b5439b4404,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-cae15232-e63a-4f11-8ac6-cb0b73b7c0f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1333622150-172.17.0.2-1597517061502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38595,DS-f27af185-7580-4546-8b9c-b6160717cc2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-f9f46ae9-fb04-438f-a50b-bab24ebfa844,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-c0456a38-8916-46a2-9e54-44be9876ac43,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-6581d098-0966-4a0e-be82-f3b50d2639c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-59350b0d-7b23-4f55-a488-3280c41041bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-4a5f63b9-6c8f-453c-813e-f1ef8f134e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44153,DS-64e60358-3748-4bc5-a30e-3a287d7a0c82,DISK], DatanodeInfoWithStorage[127.0.0.1:37595,DS-99c4d84e-f609-4967-93b0-c19a4fb73c33,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1333622150-172.17.0.2-1597517061502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38595,DS-f27af185-7580-4546-8b9c-b6160717cc2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-f9f46ae9-fb04-438f-a50b-bab24ebfa844,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-c0456a38-8916-46a2-9e54-44be9876ac43,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-6581d098-0966-4a0e-be82-f3b50d2639c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-59350b0d-7b23-4f55-a488-3280c41041bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-4a5f63b9-6c8f-453c-813e-f1ef8f134e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44153,DS-64e60358-3748-4bc5-a30e-3a287d7a0c82,DISK], DatanodeInfoWithStorage[127.0.0.1:37595,DS-99c4d84e-f609-4967-93b0-c19a4fb73c33,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-279619056-172.17.0.2-1597517264362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37926,DS-95526177-a625-4cef-824e-eefc8ceef512,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-6d46b2bd-09cc-4570-bff3-f54e67aa219a,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-332a5732-4761-47d3-ab63-1ebebb1389a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-2d018117-a3f5-4ad0-ab0a-2a2129cc269d,DISK], DatanodeInfoWithStorage[127.0.0.1:46308,DS-ab12d8ef-3c40-45bb-a5d6-4d35d1d1d25e,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-4dc3b971-c7a1-4e82-b418-6c6367825dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:46877,DS-2daf2012-c1bb-44f0-8858-c78c23a459ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-421d861d-6ae4-41da-b2ab-bfa2bf64c1dd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-279619056-172.17.0.2-1597517264362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37926,DS-95526177-a625-4cef-824e-eefc8ceef512,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-6d46b2bd-09cc-4570-bff3-f54e67aa219a,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-332a5732-4761-47d3-ab63-1ebebb1389a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-2d018117-a3f5-4ad0-ab0a-2a2129cc269d,DISK], DatanodeInfoWithStorage[127.0.0.1:46308,DS-ab12d8ef-3c40-45bb-a5d6-4d35d1d1d25e,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-4dc3b971-c7a1-4e82-b418-6c6367825dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:46877,DS-2daf2012-c1bb-44f0-8858-c78c23a459ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-421d861d-6ae4-41da-b2ab-bfa2bf64c1dd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-28156890-172.17.0.2-1597517595097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46027,DS-d3e482d4-7fc7-49ed-b242-c0cb9477700d,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-43090747-ecd7-47c5-969f-86fd171819f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-dd4a62ed-c49a-42ca-9c73-7477e4a5c9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-a2c8dfb4-454a-46f3-8233-29d9c3169634,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-46291ba6-820d-47f0-9595-de28545210a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-4b37b7e8-b19b-401d-8a39-2c8b2dc5dd80,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-4b710e96-eee2-42bf-bdfc-98c798878fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-4eaa77d7-4ebf-491b-9d5c-61c392b19a8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-28156890-172.17.0.2-1597517595097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46027,DS-d3e482d4-7fc7-49ed-b242-c0cb9477700d,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-43090747-ecd7-47c5-969f-86fd171819f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-dd4a62ed-c49a-42ca-9c73-7477e4a5c9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-a2c8dfb4-454a-46f3-8233-29d9c3169634,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-46291ba6-820d-47f0-9595-de28545210a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-4b37b7e8-b19b-401d-8a39-2c8b2dc5dd80,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-4b710e96-eee2-42bf-bdfc-98c798878fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-4eaa77d7-4ebf-491b-9d5c-61c392b19a8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1601033030-172.17.0.2-1597517950185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39430,DS-be417985-28cf-4438-b8c7-e8f844ded298,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-c59d5e30-caf4-461d-8fe4-566db98c00a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-cbf1046d-f3dd-4924-8377-a3cc8fcc1868,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-b351af3d-1a49-438e-bc93-3a5fa660c136,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-6ab75a93-bd6f-45ff-9820-81ebfbe0ed2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-80cbe4f1-01d3-4d39-aa11-0fc7021630d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-5dee4785-307c-4d10-907c-6d9289f88e41,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-c0462879-7c2b-4c46-8124-5631c0c72b9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1601033030-172.17.0.2-1597517950185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39430,DS-be417985-28cf-4438-b8c7-e8f844ded298,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-c59d5e30-caf4-461d-8fe4-566db98c00a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-cbf1046d-f3dd-4924-8377-a3cc8fcc1868,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-b351af3d-1a49-438e-bc93-3a5fa660c136,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-6ab75a93-bd6f-45ff-9820-81ebfbe0ed2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-80cbe4f1-01d3-4d39-aa11-0fc7021630d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-5dee4785-307c-4d10-907c-6d9289f88e41,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-c0462879-7c2b-4c46-8124-5631c0c72b9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258610475-172.17.0.2-1597518135189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39243,DS-7b167949-4d73-47e8-900b-971bf6c048a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40265,DS-554b1f48-5757-4148-9805-9065e14dfa34,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-460194ab-6d51-473d-b426-8b7cfd2dc08d,DISK], DatanodeInfoWithStorage[127.0.0.1:40510,DS-3d599bef-86a0-4b7e-856a-30fb9a150adc,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-f3c737f9-fe5a-40f8-badf-7ee20080dc81,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-36c98bce-9e35-433f-be08-131f811bc271,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-999cef7d-0fbf-4fe3-8021-8a2538d8c984,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-2885f962-91fc-4787-8732-f2a7715c0cd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258610475-172.17.0.2-1597518135189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39243,DS-7b167949-4d73-47e8-900b-971bf6c048a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40265,DS-554b1f48-5757-4148-9805-9065e14dfa34,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-460194ab-6d51-473d-b426-8b7cfd2dc08d,DISK], DatanodeInfoWithStorage[127.0.0.1:40510,DS-3d599bef-86a0-4b7e-856a-30fb9a150adc,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-f3c737f9-fe5a-40f8-badf-7ee20080dc81,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-36c98bce-9e35-433f-be08-131f811bc271,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-999cef7d-0fbf-4fe3-8021-8a2538d8c984,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-2885f962-91fc-4787-8732-f2a7715c0cd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-36269108-172.17.0.2-1597518209095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33950,DS-54f5a508-48c3-4692-99ad-8861d4032ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:38877,DS-e2473571-eed3-4f4e-a73d-1e56283bd5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-e92351ed-d0ed-4ee9-91d2-3a35fcef5163,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-1052f05a-7cc5-4ecd-8797-2cf2c87fcb66,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-1c26a852-49b5-4d47-9747-9709d198e2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-9b45406d-376b-4b1c-88a1-c169de8166b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-73669883-6ca6-4724-8d2e-d41dc859fd2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-e393f50e-25f9-4247-ac87-445eb4211f28,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-36269108-172.17.0.2-1597518209095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33950,DS-54f5a508-48c3-4692-99ad-8861d4032ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:38877,DS-e2473571-eed3-4f4e-a73d-1e56283bd5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-e92351ed-d0ed-4ee9-91d2-3a35fcef5163,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-1052f05a-7cc5-4ecd-8797-2cf2c87fcb66,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-1c26a852-49b5-4d47-9747-9709d198e2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-9b45406d-376b-4b1c-88a1-c169de8166b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-73669883-6ca6-4724-8d2e-d41dc859fd2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-e393f50e-25f9-4247-ac87-445eb4211f28,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-377771173-172.17.0.2-1597518533058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39810,DS-6c52cb62-3e4b-485d-9236-a83cfaf2079e,DISK], DatanodeInfoWithStorage[127.0.0.1:46105,DS-f2562e22-a126-49fc-a466-f845a34001f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-cba72f52-ae48-4709-946a-2fd54e7198d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-2e7e45b6-c71a-4d96-83fc-d88da8d77cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-61364868-3a50-4bca-9d1c-037b1a77e516,DISK], DatanodeInfoWithStorage[127.0.0.1:36858,DS-0c2b7483-e887-4b56-86f4-fe95321d9cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-bcd6d5d7-ee2d-41d7-a108-53da3881c484,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-50cb6d37-5797-4385-af7b-710638e48fc8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-377771173-172.17.0.2-1597518533058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39810,DS-6c52cb62-3e4b-485d-9236-a83cfaf2079e,DISK], DatanodeInfoWithStorage[127.0.0.1:46105,DS-f2562e22-a126-49fc-a466-f845a34001f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-cba72f52-ae48-4709-946a-2fd54e7198d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-2e7e45b6-c71a-4d96-83fc-d88da8d77cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-61364868-3a50-4bca-9d1c-037b1a77e516,DISK], DatanodeInfoWithStorage[127.0.0.1:36858,DS-0c2b7483-e887-4b56-86f4-fe95321d9cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-bcd6d5d7-ee2d-41d7-a108-53da3881c484,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-50cb6d37-5797-4385-af7b-710638e48fc8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891477969-172.17.0.2-1597519054983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39025,DS-b1db9d45-3860-47ef-b56c-43980dcffe22,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-a541a1d3-fe86-4be7-8bd9-ad076c2469e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-772cfc1f-62e9-459b-9b9a-3ffba8be5f39,DISK], DatanodeInfoWithStorage[127.0.0.1:41150,DS-84884624-eb9c-4c38-8b48-f3e623279bec,DISK], DatanodeInfoWithStorage[127.0.0.1:41605,DS-7b55d5eb-25df-402f-865e-dd076aac2ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-704e1d32-8c31-47e5-a760-fead95f7043b,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-a4687cc9-dc53-4cd7-b517-c6c3d5fa674f,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-2cdd304a-0678-4a49-b2ef-03133e14188d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891477969-172.17.0.2-1597519054983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39025,DS-b1db9d45-3860-47ef-b56c-43980dcffe22,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-a541a1d3-fe86-4be7-8bd9-ad076c2469e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-772cfc1f-62e9-459b-9b9a-3ffba8be5f39,DISK], DatanodeInfoWithStorage[127.0.0.1:41150,DS-84884624-eb9c-4c38-8b48-f3e623279bec,DISK], DatanodeInfoWithStorage[127.0.0.1:41605,DS-7b55d5eb-25df-402f-865e-dd076aac2ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-704e1d32-8c31-47e5-a760-fead95f7043b,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-a4687cc9-dc53-4cd7-b517-c6c3d5fa674f,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-2cdd304a-0678-4a49-b2ef-03133e14188d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 18 out of 50
result: false positive !!!
Total execution time in seconds : 5701
