reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 2000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 2000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-115765434-172.17.0.5-1597491059354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45977,DS-dbd691e5-3915-4636-b567-efb35de1db82,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-2fd1490f-dfcb-4be4-a7ee-cb04d1b349c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39886,DS-df5b82f5-6fb5-4893-87f2-8636fc02a624,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-c9cca57f-5152-4350-963b-292d670bc792,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-5162d4b4-dcda-409b-a693-04f59b06586e,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-f6ae235a-7ea7-4276-84df-99a003218db4,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-21e95e13-c61d-40f9-a127-e16dc04a3c36,DISK], DatanodeInfoWithStorage[127.0.0.1:44631,DS-5f01308f-3337-47a4-a714-cfda76a89400,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-115765434-172.17.0.5-1597491059354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45977,DS-dbd691e5-3915-4636-b567-efb35de1db82,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-2fd1490f-dfcb-4be4-a7ee-cb04d1b349c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39886,DS-df5b82f5-6fb5-4893-87f2-8636fc02a624,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-c9cca57f-5152-4350-963b-292d670bc792,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-5162d4b4-dcda-409b-a693-04f59b06586e,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-f6ae235a-7ea7-4276-84df-99a003218db4,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-21e95e13-c61d-40f9-a127-e16dc04a3c36,DISK], DatanodeInfoWithStorage[127.0.0.1:44631,DS-5f01308f-3337-47a4-a714-cfda76a89400,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 2000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-855613250-172.17.0.5-1597491325342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45380,DS-0fbdf03d-937f-47f6-950a-6e0bedb55755,DISK], DatanodeInfoWithStorage[127.0.0.1:34984,DS-5168b0bb-97ec-41a1-8715-274b4ba5388a,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-aa04e833-6ace-41fc-93c5-639814834898,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-bcb0b07d-a491-423a-9cf1-70ac89fe4bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-7463208b-b94b-471f-8cd5-3a1996ebfc84,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-d82dc0fb-0aa9-4787-bfcf-6360575cacba,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-09ac5b4e-21f1-479b-bfe3-d69e3c43162b,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-bf9d6472-7995-493c-83ca-a4aa4cec51d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-855613250-172.17.0.5-1597491325342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45380,DS-0fbdf03d-937f-47f6-950a-6e0bedb55755,DISK], DatanodeInfoWithStorage[127.0.0.1:34984,DS-5168b0bb-97ec-41a1-8715-274b4ba5388a,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-aa04e833-6ace-41fc-93c5-639814834898,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-bcb0b07d-a491-423a-9cf1-70ac89fe4bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-7463208b-b94b-471f-8cd5-3a1996ebfc84,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-d82dc0fb-0aa9-4787-bfcf-6360575cacba,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-09ac5b4e-21f1-479b-bfe3-d69e3c43162b,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-bf9d6472-7995-493c-83ca-a4aa4cec51d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 2000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1724063361-172.17.0.5-1597491816529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33115,DS-a995c5ba-e1be-4384-b98d-a7518ab7eb92,DISK], DatanodeInfoWithStorage[127.0.0.1:41328,DS-5976368f-2789-4656-ac67-ff1d617e040c,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-1842262b-2899-4726-ada5-efbd3377495a,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-2e90d51d-83e4-42f9-b171-90ac9820c30c,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-2fe7d88b-54c3-48f9-9f56-8fa532607a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-0fd762ab-5b2a-411c-87c0-43a2ead23b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-4788a9cc-5424-442a-b817-d2952d3d42ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-993e7cc8-2429-4e84-b494-429046cb843d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1724063361-172.17.0.5-1597491816529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33115,DS-a995c5ba-e1be-4384-b98d-a7518ab7eb92,DISK], DatanodeInfoWithStorage[127.0.0.1:41328,DS-5976368f-2789-4656-ac67-ff1d617e040c,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-1842262b-2899-4726-ada5-efbd3377495a,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-2e90d51d-83e4-42f9-b171-90ac9820c30c,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-2fe7d88b-54c3-48f9-9f56-8fa532607a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-0fd762ab-5b2a-411c-87c0-43a2ead23b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-4788a9cc-5424-442a-b817-d2952d3d42ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-993e7cc8-2429-4e84-b494-429046cb843d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 2000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1113366673-172.17.0.5-1597491850767:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37443,DS-486c6c51-c424-4068-b817-da125095c87f,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-d5eb938d-0135-4712-9685-7a8c88b71694,DISK], DatanodeInfoWithStorage[127.0.0.1:36770,DS-21b23e01-7847-4eed-a2a6-dd65f9f5441d,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-88b1f7ee-51a2-4205-9188-338a7c8c8826,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-7f6b6d28-5fc1-4fd4-a9e1-4861bcec9f34,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-55cbb7be-3f38-48fe-abd1-cce1eaefc7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-a373fd65-7aae-4fbe-a2fd-0e0558a6fa81,DISK], DatanodeInfoWithStorage[127.0.0.1:44677,DS-f86dac80-4df5-4f01-83d3-6b42323ebd09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1113366673-172.17.0.5-1597491850767:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37443,DS-486c6c51-c424-4068-b817-da125095c87f,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-d5eb938d-0135-4712-9685-7a8c88b71694,DISK], DatanodeInfoWithStorage[127.0.0.1:36770,DS-21b23e01-7847-4eed-a2a6-dd65f9f5441d,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-88b1f7ee-51a2-4205-9188-338a7c8c8826,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-7f6b6d28-5fc1-4fd4-a9e1-4861bcec9f34,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-55cbb7be-3f38-48fe-abd1-cce1eaefc7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-a373fd65-7aae-4fbe-a2fd-0e0558a6fa81,DISK], DatanodeInfoWithStorage[127.0.0.1:44677,DS-f86dac80-4df5-4f01-83d3-6b42323ebd09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 2000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2117447370-172.17.0.5-1597491891002:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34082,DS-1ce4eb15-0030-4992-a8f9-1f6bdbe39388,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-ad55225e-cfde-4c30-adff-a512dc79cbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-62a94b3e-8b53-49d0-afad-ef7f49413b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39276,DS-1185ee2a-1cda-45ce-aef5-889e13b7a0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34360,DS-077379de-347f-429b-9bb3-cbfa34c3621d,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-f39ddc64-d7c5-4a40-b01e-01e538c8fdcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-89ad4ae1-613d-40f7-8052-251847960b74,DISK], DatanodeInfoWithStorage[127.0.0.1:34043,DS-eb05dafd-e642-4ff3-b1de-6d184077da74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2117447370-172.17.0.5-1597491891002:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34082,DS-1ce4eb15-0030-4992-a8f9-1f6bdbe39388,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-ad55225e-cfde-4c30-adff-a512dc79cbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-62a94b3e-8b53-49d0-afad-ef7f49413b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39276,DS-1185ee2a-1cda-45ce-aef5-889e13b7a0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34360,DS-077379de-347f-429b-9bb3-cbfa34c3621d,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-f39ddc64-d7c5-4a40-b01e-01e538c8fdcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-89ad4ae1-613d-40f7-8052-251847960b74,DISK], DatanodeInfoWithStorage[127.0.0.1:34043,DS-eb05dafd-e642-4ff3-b1de-6d184077da74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 2000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1416996909-172.17.0.5-1597492942825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37713,DS-8bbb7ab8-d3c2-4fe0-b459-96b4991c23ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-ad4143c0-f119-4084-9540-44433b58c995,DISK], DatanodeInfoWithStorage[127.0.0.1:44407,DS-751b1501-9788-4532-b57f-e7b42ba47599,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-cf5a4141-8477-44e2-98d6-24ebb68620e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-ddd58d95-41dd-46e2-b4d5-a520a8582cec,DISK], DatanodeInfoWithStorage[127.0.0.1:40615,DS-15a190d1-72b5-4955-a1d4-c97cce980d58,DISK], DatanodeInfoWithStorage[127.0.0.1:37323,DS-7efc106c-f16d-42d6-8dd7-22d909b49a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39352,DS-4b9f8334-91ff-4b89-bf1d-aaa01f0b4cc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1416996909-172.17.0.5-1597492942825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37713,DS-8bbb7ab8-d3c2-4fe0-b459-96b4991c23ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-ad4143c0-f119-4084-9540-44433b58c995,DISK], DatanodeInfoWithStorage[127.0.0.1:44407,DS-751b1501-9788-4532-b57f-e7b42ba47599,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-cf5a4141-8477-44e2-98d6-24ebb68620e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-ddd58d95-41dd-46e2-b4d5-a520a8582cec,DISK], DatanodeInfoWithStorage[127.0.0.1:40615,DS-15a190d1-72b5-4955-a1d4-c97cce980d58,DISK], DatanodeInfoWithStorage[127.0.0.1:37323,DS-7efc106c-f16d-42d6-8dd7-22d909b49a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39352,DS-4b9f8334-91ff-4b89-bf1d-aaa01f0b4cc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 2000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1248993002-172.17.0.5-1597493020583:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45468,DS-df655abd-37f8-453d-8d3a-3dad5e737ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-c70f5667-5797-4766-b2c6-d42025fe9f37,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-ea753b6a-d9f0-4d77-8317-fe5d54cad912,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-64950113-8497-4f19-8720-41baf39364c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-1259be5b-4634-4e51-996c-0c761e4f57b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-634ac38b-6166-4ce5-a697-8ba3c56562a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-9aad4e4a-f9f2-45d9-a377-458f9a90c17c,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-ef152430-3441-4046-832c-a9334ce8ccf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1248993002-172.17.0.5-1597493020583:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45468,DS-df655abd-37f8-453d-8d3a-3dad5e737ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-c70f5667-5797-4766-b2c6-d42025fe9f37,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-ea753b6a-d9f0-4d77-8317-fe5d54cad912,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-64950113-8497-4f19-8720-41baf39364c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-1259be5b-4634-4e51-996c-0c761e4f57b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-634ac38b-6166-4ce5-a697-8ba3c56562a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-9aad4e4a-f9f2-45d9-a377-458f9a90c17c,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-ef152430-3441-4046-832c-a9334ce8ccf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 2000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-754101056-172.17.0.5-1597493216312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43173,DS-aaa6c092-cd32-43f2-8571-7c191d77b0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-d503ffd8-a63b-493f-a81f-c315ac2bf8db,DISK], DatanodeInfoWithStorage[127.0.0.1:40345,DS-62e6180d-f816-4f18-b1a9-5cc4b0f281d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-5c518297-d867-477c-befe-d0c043299a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-54a06f98-e6f9-45de-9fa7-83d400af4147,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-45a54dda-b51d-474f-b7d5-04039d380522,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-bc9fc28a-cf68-4522-8415-978c8a35e510,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-7e198d6d-e624-4fe0-9024-968ffa03c7e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-754101056-172.17.0.5-1597493216312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43173,DS-aaa6c092-cd32-43f2-8571-7c191d77b0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-d503ffd8-a63b-493f-a81f-c315ac2bf8db,DISK], DatanodeInfoWithStorage[127.0.0.1:40345,DS-62e6180d-f816-4f18-b1a9-5cc4b0f281d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-5c518297-d867-477c-befe-d0c043299a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-54a06f98-e6f9-45de-9fa7-83d400af4147,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-45a54dda-b51d-474f-b7d5-04039d380522,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-bc9fc28a-cf68-4522-8415-978c8a35e510,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-7e198d6d-e624-4fe0-9024-968ffa03c7e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 2000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1862855417-172.17.0.5-1597493692792:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41051,DS-b7b45860-a2f3-4d0a-bcf2-fa26b83ecf55,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-0d12afe7-d058-4e1d-a74a-d15f4b5c8371,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-96ca5016-df74-4274-b789-e1be00eaeaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-0ec0e802-cb00-4544-82ad-0063aba61e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-ab82348d-29e2-4cd3-9515-04d0ec396ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-6666c421-66a2-4df6-998c-f951888cb026,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-237c1af0-a933-4ff6-b280-6e681331384b,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-96e9ec5b-b9c2-4593-ba68-e1f715599eff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1862855417-172.17.0.5-1597493692792:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41051,DS-b7b45860-a2f3-4d0a-bcf2-fa26b83ecf55,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-0d12afe7-d058-4e1d-a74a-d15f4b5c8371,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-96ca5016-df74-4274-b789-e1be00eaeaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-0ec0e802-cb00-4544-82ad-0063aba61e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-ab82348d-29e2-4cd3-9515-04d0ec396ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-6666c421-66a2-4df6-998c-f951888cb026,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-237c1af0-a933-4ff6-b280-6e681331384b,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-96e9ec5b-b9c2-4593-ba68-e1f715599eff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 2000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-707695785-172.17.0.5-1597493967657:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36888,DS-bec0ecad-a7c3-492f-855b-e58c78cf037c,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-9db49f00-4381-4ecb-81dc-87cbf9fc894d,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-e60955f6-0e18-491c-8f84-b4c03beec043,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-04320728-dcf7-4170-a826-8e45b6f9d8ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36419,DS-2253da14-f084-49bb-8850-e405b2b554b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41585,DS-9100ba3e-5afc-4c24-8e5b-7f54930641f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-38384e6b-1596-461d-9d40-ad37d26ba816,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-ea588b9d-eec3-4b1c-87ec-571a1518b1ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-707695785-172.17.0.5-1597493967657:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36888,DS-bec0ecad-a7c3-492f-855b-e58c78cf037c,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-9db49f00-4381-4ecb-81dc-87cbf9fc894d,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-e60955f6-0e18-491c-8f84-b4c03beec043,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-04320728-dcf7-4170-a826-8e45b6f9d8ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36419,DS-2253da14-f084-49bb-8850-e405b2b554b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41585,DS-9100ba3e-5afc-4c24-8e5b-7f54930641f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-38384e6b-1596-461d-9d40-ad37d26ba816,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-ea588b9d-eec3-4b1c-87ec-571a1518b1ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 2000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-541889002-172.17.0.5-1597494071324:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46851,DS-7334e5b1-ba52-4260-a5b2-e7460a97012d,DISK], DatanodeInfoWithStorage[127.0.0.1:40154,DS-d2e09eb6-6ec6-4f0a-a750-77bc01ecf7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-2d8673de-5289-4e00-9d22-cf0193afad8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-0c810e9a-ade8-440a-9b72-00f9cd5886e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-e7e511f6-74e9-476d-ae6c-44340dfe066d,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-c0f5127e-0828-4d89-b680-6a8f2ba9b8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-7ec122b1-22bb-4046-9714-3ab3039a697a,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-1934aa48-49da-4e21-864b-ff4469171edb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-541889002-172.17.0.5-1597494071324:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46851,DS-7334e5b1-ba52-4260-a5b2-e7460a97012d,DISK], DatanodeInfoWithStorage[127.0.0.1:40154,DS-d2e09eb6-6ec6-4f0a-a750-77bc01ecf7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-2d8673de-5289-4e00-9d22-cf0193afad8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-0c810e9a-ade8-440a-9b72-00f9cd5886e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-e7e511f6-74e9-476d-ae6c-44340dfe066d,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-c0f5127e-0828-4d89-b680-6a8f2ba9b8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-7ec122b1-22bb-4046-9714-3ab3039a697a,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-1934aa48-49da-4e21-864b-ff4469171edb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 2000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-318163670-172.17.0.5-1597494148209:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36082,DS-0f699956-9567-4860-9a1d-ff5e5bb4037e,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-b9ba94bf-0165-451c-963a-925c21838f30,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-f3b2ab4c-b5c7-40e6-becb-ef2ee8708b50,DISK], DatanodeInfoWithStorage[127.0.0.1:39663,DS-3b08c66f-4994-4bb7-be9b-a9baf633f240,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-fd180602-f79e-4e2d-a294-c5cce41d9e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39414,DS-4a16fc6c-b9df-4ac8-86fe-ffc80e9ee396,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-7ea646ff-97a2-436e-b3e7-f37f1252b9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-d784001e-75bc-4fe3-ad23-3c52947cb06c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-318163670-172.17.0.5-1597494148209:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36082,DS-0f699956-9567-4860-9a1d-ff5e5bb4037e,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-b9ba94bf-0165-451c-963a-925c21838f30,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-f3b2ab4c-b5c7-40e6-becb-ef2ee8708b50,DISK], DatanodeInfoWithStorage[127.0.0.1:39663,DS-3b08c66f-4994-4bb7-be9b-a9baf633f240,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-fd180602-f79e-4e2d-a294-c5cce41d9e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39414,DS-4a16fc6c-b9df-4ac8-86fe-ffc80e9ee396,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-7ea646ff-97a2-436e-b3e7-f37f1252b9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-d784001e-75bc-4fe3-ad23-3c52947cb06c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 2000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1487545670-172.17.0.5-1597494441589:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40384,DS-56e19a61-353c-4acd-88fc-f511088ee037,DISK], DatanodeInfoWithStorage[127.0.0.1:33821,DS-e7b03c05-3391-461d-b355-9d39cd162f15,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-cf70d89b-1403-4d85-80a5-193f8fc1ac2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-fb5d8fa0-a1ee-4368-a577-4a27d17b503f,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-084cc833-b6a1-48e4-9585-ef971930083e,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-2985faba-e81f-46e5-a212-2572c2cbfd83,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-21862692-41c7-43aa-9f35-fc8077946d48,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-7d83282c-9ea7-4ec2-82ef-a12e6335824b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1487545670-172.17.0.5-1597494441589:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40384,DS-56e19a61-353c-4acd-88fc-f511088ee037,DISK], DatanodeInfoWithStorage[127.0.0.1:33821,DS-e7b03c05-3391-461d-b355-9d39cd162f15,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-cf70d89b-1403-4d85-80a5-193f8fc1ac2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-fb5d8fa0-a1ee-4368-a577-4a27d17b503f,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-084cc833-b6a1-48e4-9585-ef971930083e,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-2985faba-e81f-46e5-a212-2572c2cbfd83,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-21862692-41c7-43aa-9f35-fc8077946d48,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-7d83282c-9ea7-4ec2-82ef-a12e6335824b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 2000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-155214144-172.17.0.5-1597494850070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39517,DS-13964389-4ba1-466e-9bf6-8f4a8344d726,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-1b40d0b8-9028-4872-90bd-35ff0960c121,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-ed87a1ad-8e42-4f58-835f-49ffaec42cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-4dfc2b38-0769-47c1-bdfd-48cc3266b5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-3f6a80b3-b992-4344-b762-d40fe56f485b,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-9c318cf9-3430-4f68-b12c-7aebb3b23b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-635cb106-ebfa-4966-9fea-b3a2151b0d80,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-d0fdf589-b864-4218-ae10-81d5362f159d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-155214144-172.17.0.5-1597494850070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39517,DS-13964389-4ba1-466e-9bf6-8f4a8344d726,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-1b40d0b8-9028-4872-90bd-35ff0960c121,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-ed87a1ad-8e42-4f58-835f-49ffaec42cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-4dfc2b38-0769-47c1-bdfd-48cc3266b5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-3f6a80b3-b992-4344-b762-d40fe56f485b,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-9c318cf9-3430-4f68-b12c-7aebb3b23b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-635cb106-ebfa-4966-9fea-b3a2151b0d80,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-d0fdf589-b864-4218-ae10-81d5362f159d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 2000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1198403036-172.17.0.5-1597494894151:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36355,DS-c62fd176-a21e-4904-b221-af5aa2f1106b,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-dad8c200-5278-4d2b-b427-ee95e87afaaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35553,DS-0a488848-6e20-4f23-8579-4f5af58bd525,DISK], DatanodeInfoWithStorage[127.0.0.1:36088,DS-a9bc2043-b251-472c-9d0e-4a413047bd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-bb964575-59e5-4e10-b69d-03f61227ff74,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-e5cfd582-a6e9-4d04-b356-2032e568e835,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-afe2798f-3544-47ef-a724-2ce0e3ee4cca,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-1471a294-68f8-48f6-a262-6235d9ad40b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1198403036-172.17.0.5-1597494894151:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36355,DS-c62fd176-a21e-4904-b221-af5aa2f1106b,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-dad8c200-5278-4d2b-b427-ee95e87afaaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35553,DS-0a488848-6e20-4f23-8579-4f5af58bd525,DISK], DatanodeInfoWithStorage[127.0.0.1:36088,DS-a9bc2043-b251-472c-9d0e-4a413047bd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-bb964575-59e5-4e10-b69d-03f61227ff74,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-e5cfd582-a6e9-4d04-b356-2032e568e835,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-afe2798f-3544-47ef-a724-2ce0e3ee4cca,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-1471a294-68f8-48f6-a262-6235d9ad40b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 2000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1339656760-172.17.0.5-1597495184967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38367,DS-c54b2afa-6042-41a9-be9e-b92c5dcc3b22,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-46016dc4-90cd-4c5e-8a36-c8f53743bb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37776,DS-a1d902d2-29be-49e1-bcba-2bf6823f6e26,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-261bcf84-302e-4305-8c73-95d3fdb5f716,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-b21b92da-8e29-4371-a4a8-829bd66b5193,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-b7cca762-2ffe-449d-8f17-e09a40c8cd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-8b5fdfba-78e0-4aaf-ae60-e0bf74050eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-5cf7149e-eaeb-405c-bbb1-593be4a5dc46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1339656760-172.17.0.5-1597495184967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38367,DS-c54b2afa-6042-41a9-be9e-b92c5dcc3b22,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-46016dc4-90cd-4c5e-8a36-c8f53743bb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37776,DS-a1d902d2-29be-49e1-bcba-2bf6823f6e26,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-261bcf84-302e-4305-8c73-95d3fdb5f716,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-b21b92da-8e29-4371-a4a8-829bd66b5193,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-b7cca762-2ffe-449d-8f17-e09a40c8cd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-8b5fdfba-78e0-4aaf-ae60-e0bf74050eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-5cf7149e-eaeb-405c-bbb1-593be4a5dc46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 2000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1317345492-172.17.0.5-1597495683753:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44351,DS-03c6c021-1a98-4126-917a-45e96783e03b,DISK], DatanodeInfoWithStorage[127.0.0.1:39245,DS-cdc846c8-41e5-4102-aeb3-d18e601cc031,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-a84e3880-2365-42c8-bea1-41bb2c7c7721,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-82c820bf-0b0f-40ee-b719-08d03145d9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-27b39e3b-d3c5-485e-b5a4-305aa277fc76,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-694edc6c-f4ba-4430-9b37-709ee039959c,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-1fdbb075-4b43-4ae1-9fa0-fddd19bbc37f,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-004119bb-cbd2-444e-aceb-49ce2ec33f77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1317345492-172.17.0.5-1597495683753:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44351,DS-03c6c021-1a98-4126-917a-45e96783e03b,DISK], DatanodeInfoWithStorage[127.0.0.1:39245,DS-cdc846c8-41e5-4102-aeb3-d18e601cc031,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-a84e3880-2365-42c8-bea1-41bb2c7c7721,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-82c820bf-0b0f-40ee-b719-08d03145d9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-27b39e3b-d3c5-485e-b5a4-305aa277fc76,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-694edc6c-f4ba-4430-9b37-709ee039959c,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-1fdbb075-4b43-4ae1-9fa0-fddd19bbc37f,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-004119bb-cbd2-444e-aceb-49ce2ec33f77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 2000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-112614117-172.17.0.5-1597495721562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33317,DS-460b0b28-29fa-49cf-a863-75cc771a3b20,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-13111fec-2aaf-4cba-937d-a3f7e4b263d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-237636b1-3a8b-4aae-8ffb-03b2155d12cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-b2ab0bdc-bf93-45d9-8c76-e140c0133ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-4a2f0f3e-d6c3-4fa9-aad6-2b3ad181a658,DISK], DatanodeInfoWithStorage[127.0.0.1:43806,DS-cc61039d-eb78-40d9-add2-3456fe5c625b,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-a6635958-1e1d-4cd2-84f5-d77f9fff7893,DISK], DatanodeInfoWithStorage[127.0.0.1:44273,DS-9bb928d8-1d59-42a3-8f3e-5360abdbb391,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-112614117-172.17.0.5-1597495721562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33317,DS-460b0b28-29fa-49cf-a863-75cc771a3b20,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-13111fec-2aaf-4cba-937d-a3f7e4b263d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-237636b1-3a8b-4aae-8ffb-03b2155d12cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-b2ab0bdc-bf93-45d9-8c76-e140c0133ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-4a2f0f3e-d6c3-4fa9-aad6-2b3ad181a658,DISK], DatanodeInfoWithStorage[127.0.0.1:43806,DS-cc61039d-eb78-40d9-add2-3456fe5c625b,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-a6635958-1e1d-4cd2-84f5-d77f9fff7893,DISK], DatanodeInfoWithStorage[127.0.0.1:44273,DS-9bb928d8-1d59-42a3-8f3e-5360abdbb391,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 2000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1985175499-172.17.0.5-1597495758034:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44231,DS-bb08846d-cded-4a5f-b9ab-f517250de679,DISK], DatanodeInfoWithStorage[127.0.0.1:46403,DS-44d42f49-578d-433d-b90e-0023989e5e32,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-f6083f96-fe05-4560-a5a6-55e263768de8,DISK], DatanodeInfoWithStorage[127.0.0.1:38588,DS-13a9527f-be99-4a90-8ba5-34f4e87480a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-08ca8232-ed46-4512-8b68-a55220b3e7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-e3f17bb9-cfef-4b28-bcba-6451061c91d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35755,DS-83a0ae1d-18b7-48da-b11d-878c9cc5b1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-c3a29422-9054-4efc-b294-d5b07e92017a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1985175499-172.17.0.5-1597495758034:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44231,DS-bb08846d-cded-4a5f-b9ab-f517250de679,DISK], DatanodeInfoWithStorage[127.0.0.1:46403,DS-44d42f49-578d-433d-b90e-0023989e5e32,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-f6083f96-fe05-4560-a5a6-55e263768de8,DISK], DatanodeInfoWithStorage[127.0.0.1:38588,DS-13a9527f-be99-4a90-8ba5-34f4e87480a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-08ca8232-ed46-4512-8b68-a55220b3e7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-e3f17bb9-cfef-4b28-bcba-6451061c91d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35755,DS-83a0ae1d-18b7-48da-b11d-878c9cc5b1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-c3a29422-9054-4efc-b294-d5b07e92017a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 2000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1274125753-172.17.0.5-1597496080292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45119,DS-0961e51f-7490-4baa-a3b2-44bcaef1ab6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44111,DS-9e11df5b-669a-46bc-bd46-005ab8738501,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-161278f1-f9b7-49f4-af3b-02a24d1b3d31,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-1ea185ec-7d78-4426-a7c6-d2e4e4189238,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-dfc28fa4-bca7-4537-8f6c-5a37ac07c1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-e42a5154-6b58-4d85-95dd-10b56f2fbba8,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-3640f299-9e8b-4308-87e4-f83c9e7a5f92,DISK], DatanodeInfoWithStorage[127.0.0.1:41713,DS-c0ab0e50-4e9e-4e1f-ab36-7a343afb8739,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1274125753-172.17.0.5-1597496080292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45119,DS-0961e51f-7490-4baa-a3b2-44bcaef1ab6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44111,DS-9e11df5b-669a-46bc-bd46-005ab8738501,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-161278f1-f9b7-49f4-af3b-02a24d1b3d31,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-1ea185ec-7d78-4426-a7c6-d2e4e4189238,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-dfc28fa4-bca7-4537-8f6c-5a37ac07c1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-e42a5154-6b58-4d85-95dd-10b56f2fbba8,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-3640f299-9e8b-4308-87e4-f83c9e7a5f92,DISK], DatanodeInfoWithStorage[127.0.0.1:41713,DS-c0ab0e50-4e9e-4e1f-ab36-7a343afb8739,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5656
