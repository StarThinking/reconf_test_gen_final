reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1995505603-172.17.0.12-1597381540913:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34500,DS-aaca225a-6637-403a-a547-54ef32786c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-fe411684-777d-4dd7-b9d9-fefbb9e07123,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-8d14e074-4e75-4363-b50a-7c699846e806,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-ed693e49-2a27-4857-9a58-c24f229a1161,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-827c6b8a-4f81-4f64-8e28-5bbcfee8ff8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-e1265f31-6f81-430c-b355-97099d6f5981,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-f9f3f9d1-d81b-4e1b-97c0-12f467419ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-563f27b1-dba5-48c9-a58b-34f72013f9e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1995505603-172.17.0.12-1597381540913:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34500,DS-aaca225a-6637-403a-a547-54ef32786c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-fe411684-777d-4dd7-b9d9-fefbb9e07123,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-8d14e074-4e75-4363-b50a-7c699846e806,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-ed693e49-2a27-4857-9a58-c24f229a1161,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-827c6b8a-4f81-4f64-8e28-5bbcfee8ff8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-e1265f31-6f81-430c-b355-97099d6f5981,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-f9f3f9d1-d81b-4e1b-97c0-12f467419ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-563f27b1-dba5-48c9-a58b-34f72013f9e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-331423876-172.17.0.12-1597381856817:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33093,DS-32389a3b-8ed5-41d0-9444-ad1e340c95fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41972,DS-aca9066b-803f-446b-b171-4256addd6e53,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-e8a6dc86-d986-47c3-bb67-034539b59d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-cb069a89-0adf-4995-8694-b6e5253d4a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-0419add7-9b6b-45cb-9744-645aaa566f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43801,DS-28b30662-2cf0-4678-a4dd-daca2a941617,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-5451bd40-630b-4453-abe7-f14e72025490,DISK], DatanodeInfoWithStorage[127.0.0.1:44679,DS-46adafe2-74a0-45b6-b652-a6cacee6ff0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-331423876-172.17.0.12-1597381856817:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33093,DS-32389a3b-8ed5-41d0-9444-ad1e340c95fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41972,DS-aca9066b-803f-446b-b171-4256addd6e53,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-e8a6dc86-d986-47c3-bb67-034539b59d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-cb069a89-0adf-4995-8694-b6e5253d4a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-0419add7-9b6b-45cb-9744-645aaa566f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43801,DS-28b30662-2cf0-4678-a4dd-daca2a941617,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-5451bd40-630b-4453-abe7-f14e72025490,DISK], DatanodeInfoWithStorage[127.0.0.1:44679,DS-46adafe2-74a0-45b6-b652-a6cacee6ff0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1984388683-172.17.0.12-1597382906114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36098,DS-0742ee76-8e55-419d-a080-7bf032bfba6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-fdc8d43f-7496-4ffa-8240-519e936254dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36870,DS-60d15239-8d02-4a46-ae88-c3ce4d7eec4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-c08eda28-381c-41f6-afc5-04bd47b033a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-6f9ae716-9d9f-421b-a297-18d91f8039a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-fa9ec472-6e25-4340-b610-86dbd99a7c35,DISK], DatanodeInfoWithStorage[127.0.0.1:40461,DS-f6f9d3ae-416c-4793-9df0-85a8a7474951,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-c1d5f964-b1d6-4cf5-a544-1d816517950d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1984388683-172.17.0.12-1597382906114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36098,DS-0742ee76-8e55-419d-a080-7bf032bfba6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-fdc8d43f-7496-4ffa-8240-519e936254dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36870,DS-60d15239-8d02-4a46-ae88-c3ce4d7eec4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-c08eda28-381c-41f6-afc5-04bd47b033a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-6f9ae716-9d9f-421b-a297-18d91f8039a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-fa9ec472-6e25-4340-b610-86dbd99a7c35,DISK], DatanodeInfoWithStorage[127.0.0.1:40461,DS-f6f9d3ae-416c-4793-9df0-85a8a7474951,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-c1d5f964-b1d6-4cf5-a544-1d816517950d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1200598051-172.17.0.12-1597383539893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44076,DS-7d3ae396-2b28-4e86-b9a6-88be1d53d30a,DISK], DatanodeInfoWithStorage[127.0.0.1:39133,DS-6b9ec1d9-85c9-48c8-88fc-caf94fff1b08,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-01ce22de-5a68-4ade-8c39-a542e7f43d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-83bf0e85-332b-40ed-9226-fa64932ea3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43875,DS-fab57839-61c5-418f-a52d-8376cb29f592,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-f98f6d99-6502-4bfa-b77c-f1bac60a560c,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-2649064a-86b4-49da-ba55-57027d7f8a31,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-3b724889-d247-48fd-b77d-2615a8305e72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1200598051-172.17.0.12-1597383539893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44076,DS-7d3ae396-2b28-4e86-b9a6-88be1d53d30a,DISK], DatanodeInfoWithStorage[127.0.0.1:39133,DS-6b9ec1d9-85c9-48c8-88fc-caf94fff1b08,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-01ce22de-5a68-4ade-8c39-a542e7f43d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-83bf0e85-332b-40ed-9226-fa64932ea3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43875,DS-fab57839-61c5-418f-a52d-8376cb29f592,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-f98f6d99-6502-4bfa-b77c-f1bac60a560c,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-2649064a-86b4-49da-ba55-57027d7f8a31,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-3b724889-d247-48fd-b77d-2615a8305e72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-445316779-172.17.0.12-1597383572681:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37595,DS-e0c2afb0-eecf-4166-862f-1a19d621027d,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-5a117c0c-51c5-4207-b681-d5923e083d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-c6efac0d-76f2-4091-90ac-507fe140c212,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-6e0c7a16-5622-471c-931b-fd0feb864810,DISK], DatanodeInfoWithStorage[127.0.0.1:33340,DS-a0b5a835-2c35-4ec3-9eaa-1a3f44a7cb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-6bc36d2d-ab8c-4a51-a0e5-d06f237333b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-9e427cf2-7ffd-453f-a4f4-e85b274f2e63,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-082a77ae-1d74-4bae-96b2-2115cdea0193,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-445316779-172.17.0.12-1597383572681:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37595,DS-e0c2afb0-eecf-4166-862f-1a19d621027d,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-5a117c0c-51c5-4207-b681-d5923e083d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-c6efac0d-76f2-4091-90ac-507fe140c212,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-6e0c7a16-5622-471c-931b-fd0feb864810,DISK], DatanodeInfoWithStorage[127.0.0.1:33340,DS-a0b5a835-2c35-4ec3-9eaa-1a3f44a7cb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-6bc36d2d-ab8c-4a51-a0e5-d06f237333b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-9e427cf2-7ffd-453f-a4f4-e85b274f2e63,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-082a77ae-1d74-4bae-96b2-2115cdea0193,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-265411261-172.17.0.12-1597384221927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44136,DS-bebaa551-1039-4ebd-ada3-b20e359b5169,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-988dbd2d-579c-4781-8985-50e1b4e11160,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-74157e4e-c61c-45be-8c08-7e395caedd56,DISK], DatanodeInfoWithStorage[127.0.0.1:37611,DS-f2fd97fa-b76d-4f67-b55f-c0d92d9b1869,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-d8114cc9-562c-4735-8711-7ccf36e70c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-46e963af-00a8-4714-b9f6-f8bee7a15373,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-a1ba3501-c5cd-4d7b-a5c2-e475b9d9a575,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-d7a9a9a8-0a1a-486c-8ad1-461262b4ab1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-265411261-172.17.0.12-1597384221927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44136,DS-bebaa551-1039-4ebd-ada3-b20e359b5169,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-988dbd2d-579c-4781-8985-50e1b4e11160,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-74157e4e-c61c-45be-8c08-7e395caedd56,DISK], DatanodeInfoWithStorage[127.0.0.1:37611,DS-f2fd97fa-b76d-4f67-b55f-c0d92d9b1869,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-d8114cc9-562c-4735-8711-7ccf36e70c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-46e963af-00a8-4714-b9f6-f8bee7a15373,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-a1ba3501-c5cd-4d7b-a5c2-e475b9d9a575,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-d7a9a9a8-0a1a-486c-8ad1-461262b4ab1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-995993488-172.17.0.12-1597384638032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44041,DS-4e40a648-1bd4-47d9-ba89-9e14d0b75fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-3fd7319a-39ca-40b5-9751-74feedac5384,DISK], DatanodeInfoWithStorage[127.0.0.1:43283,DS-30e9f2a0-6830-4d24-b044-03b74e784773,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-46a2336c-b873-4fd2-8c9a-cec4499c5706,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-fc81cdad-3fe3-4c07-900d-0ec6f42948f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-b9ee4504-d619-4c92-8c9a-5e5a32be3776,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-86f7d2d1-b3b3-4adb-a469-380f663e8d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39834,DS-7fb56499-ca84-43e6-8ea8-a57316b0e0d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-995993488-172.17.0.12-1597384638032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44041,DS-4e40a648-1bd4-47d9-ba89-9e14d0b75fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-3fd7319a-39ca-40b5-9751-74feedac5384,DISK], DatanodeInfoWithStorage[127.0.0.1:43283,DS-30e9f2a0-6830-4d24-b044-03b74e784773,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-46a2336c-b873-4fd2-8c9a-cec4499c5706,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-fc81cdad-3fe3-4c07-900d-0ec6f42948f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-b9ee4504-d619-4c92-8c9a-5e5a32be3776,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-86f7d2d1-b3b3-4adb-a469-380f663e8d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39834,DS-7fb56499-ca84-43e6-8ea8-a57316b0e0d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-832349097-172.17.0.12-1597384824070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36761,DS-cbac9dc5-8fe6-4687-8134-73a61ed4e10a,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-4309c992-f68b-4a43-ba5c-91578c734fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:43110,DS-f968b475-84cf-4de1-8661-43891ce064c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-fcd2975a-1287-425c-84c7-f86cfd752e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34644,DS-e9ad0377-7b6c-4c4f-a845-5189f52d7255,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-019bc6e2-5f3d-4f09-9d1a-69feac47e9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-62ecd002-b970-4de1-b2a4-e809d53fabc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-0f3bc6fa-ca40-4fcd-bfde-cc668854c5fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-832349097-172.17.0.12-1597384824070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36761,DS-cbac9dc5-8fe6-4687-8134-73a61ed4e10a,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-4309c992-f68b-4a43-ba5c-91578c734fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:43110,DS-f968b475-84cf-4de1-8661-43891ce064c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-fcd2975a-1287-425c-84c7-f86cfd752e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34644,DS-e9ad0377-7b6c-4c4f-a845-5189f52d7255,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-019bc6e2-5f3d-4f09-9d1a-69feac47e9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-62ecd002-b970-4de1-b2a4-e809d53fabc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-0f3bc6fa-ca40-4fcd-bfde-cc668854c5fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1497856843-172.17.0.12-1597385046095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39052,DS-db0ca9cf-6c2a-4ef9-968a-c2c1175281b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-2b57f85f-7cf0-4777-b83d-033e47ac6913,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-5c5c70f0-e3c1-43cf-a1a7-32722a090149,DISK], DatanodeInfoWithStorage[127.0.0.1:40311,DS-2fb052f7-1e01-40cf-90e8-07406b21b2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-39a41348-2f3d-41c3-bd59-11f1b947bcbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-f1a124c7-8f07-4d46-a1b9-557a5209a948,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-4c39d144-6672-429c-bce6-832a25b13a47,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-61789cda-a3ca-4b2e-98f4-1dffc067d6e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1497856843-172.17.0.12-1597385046095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39052,DS-db0ca9cf-6c2a-4ef9-968a-c2c1175281b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-2b57f85f-7cf0-4777-b83d-033e47ac6913,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-5c5c70f0-e3c1-43cf-a1a7-32722a090149,DISK], DatanodeInfoWithStorage[127.0.0.1:40311,DS-2fb052f7-1e01-40cf-90e8-07406b21b2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-39a41348-2f3d-41c3-bd59-11f1b947bcbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-f1a124c7-8f07-4d46-a1b9-557a5209a948,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-4c39d144-6672-429c-bce6-832a25b13a47,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-61789cda-a3ca-4b2e-98f4-1dffc067d6e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1602338850-172.17.0.12-1597385279066:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41611,DS-85fc4e4c-2138-4a9d-a72c-be42ef1491db,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-4dde45bd-9a2b-47b6-8837-f9f354451ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-8aaf18ce-d3aa-4370-a1f1-72e849b7497f,DISK], DatanodeInfoWithStorage[127.0.0.1:43102,DS-261fe233-3324-4262-bb0d-77261756904c,DISK], DatanodeInfoWithStorage[127.0.0.1:41727,DS-6e22a366-b0a7-4b34-96dd-dd601333a736,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-3120a3c6-684f-4acb-81ff-5bd9b3e4e185,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-e8a4c8d6-1470-4c9d-9112-ed6a3222739e,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-7f3fb5f2-9808-43d6-beb7-653e8755242c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1602338850-172.17.0.12-1597385279066:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41611,DS-85fc4e4c-2138-4a9d-a72c-be42ef1491db,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-4dde45bd-9a2b-47b6-8837-f9f354451ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-8aaf18ce-d3aa-4370-a1f1-72e849b7497f,DISK], DatanodeInfoWithStorage[127.0.0.1:43102,DS-261fe233-3324-4262-bb0d-77261756904c,DISK], DatanodeInfoWithStorage[127.0.0.1:41727,DS-6e22a366-b0a7-4b34-96dd-dd601333a736,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-3120a3c6-684f-4acb-81ff-5bd9b3e4e185,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-e8a4c8d6-1470-4c9d-9112-ed6a3222739e,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-7f3fb5f2-9808-43d6-beb7-653e8755242c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-708906304-172.17.0.12-1597385975800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44720,DS-62904afe-1e60-404b-af03-9a5ca5de0168,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-296c2acd-457a-4104-ad8e-3a05051aa90b,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-caae6d0a-9b26-4670-93c0-380876103aef,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-2e48c0cc-01e5-4594-9d90-490c3f9e0ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-3cc6e3c6-a163-482e-ad9a-93d225e95115,DISK], DatanodeInfoWithStorage[127.0.0.1:42497,DS-712f7380-e719-4443-9308-6008310b7546,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-0643bc45-65e5-4cd9-81c6-40f6ebc07776,DISK], DatanodeInfoWithStorage[127.0.0.1:33624,DS-4af0f35b-80aa-4d43-a57d-6a7222d6baa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-708906304-172.17.0.12-1597385975800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44720,DS-62904afe-1e60-404b-af03-9a5ca5de0168,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-296c2acd-457a-4104-ad8e-3a05051aa90b,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-caae6d0a-9b26-4670-93c0-380876103aef,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-2e48c0cc-01e5-4594-9d90-490c3f9e0ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-3cc6e3c6-a163-482e-ad9a-93d225e95115,DISK], DatanodeInfoWithStorage[127.0.0.1:42497,DS-712f7380-e719-4443-9308-6008310b7546,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-0643bc45-65e5-4cd9-81c6-40f6ebc07776,DISK], DatanodeInfoWithStorage[127.0.0.1:33624,DS-4af0f35b-80aa-4d43-a57d-6a7222d6baa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 0 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: v1v2 failure didn't occur
Total execution time in seconds : 5378
