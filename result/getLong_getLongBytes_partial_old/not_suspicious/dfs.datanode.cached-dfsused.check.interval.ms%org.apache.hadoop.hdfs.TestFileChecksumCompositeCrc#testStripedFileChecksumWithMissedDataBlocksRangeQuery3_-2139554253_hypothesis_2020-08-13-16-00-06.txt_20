reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948105093-172.17.0.11-1597334427372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35640,DS-c1e7e87c-93f9-4317-af7c-8b67e6c03abc,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-3bdc7c63-5a31-48db-a5ef-c96922874117,DISK], DatanodeInfoWithStorage[127.0.0.1:35998,DS-ee879ee6-0133-4064-8b7c-7d5f8e5f23b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-b4fbef74-43d6-4a50-bbe1-545fc4696b38,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-68c2a1f8-eaa8-4fb1-9c67-15415cc9b4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-1c56dd90-4d9b-46da-83a7-31cd0452f6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-d63b1660-2a95-4708-ac9b-349e66421459,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-76c239ab-e77d-490c-b471-269fb267da7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948105093-172.17.0.11-1597334427372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35640,DS-c1e7e87c-93f9-4317-af7c-8b67e6c03abc,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-3bdc7c63-5a31-48db-a5ef-c96922874117,DISK], DatanodeInfoWithStorage[127.0.0.1:35998,DS-ee879ee6-0133-4064-8b7c-7d5f8e5f23b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-b4fbef74-43d6-4a50-bbe1-545fc4696b38,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-68c2a1f8-eaa8-4fb1-9c67-15415cc9b4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-1c56dd90-4d9b-46da-83a7-31cd0452f6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-d63b1660-2a95-4708-ac9b-349e66421459,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-76c239ab-e77d-490c-b471-269fb267da7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-138533190-172.17.0.11-1597334699353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46882,DS-a820bc1d-2baa-4ba2-843d-f26856f0314e,DISK], DatanodeInfoWithStorage[127.0.0.1:40201,DS-c771a1c7-33f1-4f59-ae4b-0f7c2ddd9dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:34513,DS-6dca7f66-c0f9-4fb1-9677-c44b59192c31,DISK], DatanodeInfoWithStorage[127.0.0.1:33509,DS-d69b0043-6e5e-4083-9e99-6ff4eab24288,DISK], DatanodeInfoWithStorage[127.0.0.1:38866,DS-2159155d-d4b2-48c5-b182-a305907917fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-0c877adf-0b73-4f1a-9dfa-f34d5f664f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-77dede7e-48db-4f79-83e1-2f66478dda17,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-38e95ee3-4ccf-4f56-9063-62f7543139d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-138533190-172.17.0.11-1597334699353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46882,DS-a820bc1d-2baa-4ba2-843d-f26856f0314e,DISK], DatanodeInfoWithStorage[127.0.0.1:40201,DS-c771a1c7-33f1-4f59-ae4b-0f7c2ddd9dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:34513,DS-6dca7f66-c0f9-4fb1-9677-c44b59192c31,DISK], DatanodeInfoWithStorage[127.0.0.1:33509,DS-d69b0043-6e5e-4083-9e99-6ff4eab24288,DISK], DatanodeInfoWithStorage[127.0.0.1:38866,DS-2159155d-d4b2-48c5-b182-a305907917fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-0c877adf-0b73-4f1a-9dfa-f34d5f664f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-77dede7e-48db-4f79-83e1-2f66478dda17,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-38e95ee3-4ccf-4f56-9063-62f7543139d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-437006743-172.17.0.11-1597335021527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36627,DS-0a8ef48c-23ce-4c76-84e0-a732ab6b1bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-e9dce520-f403-4640-b12f-5cbc9541dd1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-001b92cb-bd90-4d24-871b-30a495c444b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-da5c8cb1-a43e-4e1d-ba42-ed368ab5ed6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41495,DS-278c1116-737f-4c0a-a31c-928c55582cff,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-88766f89-f587-4129-b3d0-b099e1b60a03,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-5bc85452-b4dc-4a2d-8370-ba7d47bcbf90,DISK], DatanodeInfoWithStorage[127.0.0.1:36364,DS-3c8c50ac-2bae-479f-9459-03ce8be97439,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-437006743-172.17.0.11-1597335021527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36627,DS-0a8ef48c-23ce-4c76-84e0-a732ab6b1bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-e9dce520-f403-4640-b12f-5cbc9541dd1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-001b92cb-bd90-4d24-871b-30a495c444b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-da5c8cb1-a43e-4e1d-ba42-ed368ab5ed6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41495,DS-278c1116-737f-4c0a-a31c-928c55582cff,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-88766f89-f587-4129-b3d0-b099e1b60a03,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-5bc85452-b4dc-4a2d-8370-ba7d47bcbf90,DISK], DatanodeInfoWithStorage[127.0.0.1:36364,DS-3c8c50ac-2bae-479f-9459-03ce8be97439,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1182379238-172.17.0.11-1597335064606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43141,DS-1796b67c-3e4d-42d9-aad7-84c5c13b0957,DISK], DatanodeInfoWithStorage[127.0.0.1:35184,DS-23714851-8e33-414d-a720-62f5b2ac8532,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-85b69f40-8258-4f0e-b95c-c8cf1cccd696,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-f44bbc59-0d55-4279-8e2e-3ad973e253d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-fdbf21a1-8e16-4b9b-a3ef-5e523ba1f21c,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-29ca9347-c37a-46c2-93e5-b6acf4afc72d,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-ca76de79-c6ad-4637-aa53-c69dce15582d,DISK], DatanodeInfoWithStorage[127.0.0.1:43355,DS-7d3d962a-150c-48d8-9579-390b934924f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1182379238-172.17.0.11-1597335064606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43141,DS-1796b67c-3e4d-42d9-aad7-84c5c13b0957,DISK], DatanodeInfoWithStorage[127.0.0.1:35184,DS-23714851-8e33-414d-a720-62f5b2ac8532,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-85b69f40-8258-4f0e-b95c-c8cf1cccd696,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-f44bbc59-0d55-4279-8e2e-3ad973e253d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-fdbf21a1-8e16-4b9b-a3ef-5e523ba1f21c,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-29ca9347-c37a-46c2-93e5-b6acf4afc72d,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-ca76de79-c6ad-4637-aa53-c69dce15582d,DISK], DatanodeInfoWithStorage[127.0.0.1:43355,DS-7d3d962a-150c-48d8-9579-390b934924f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1137216545-172.17.0.11-1597335195880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35594,DS-4506aced-1db1-471d-aa56-e06d066e8e68,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-5dc579b9-bd32-495b-a3c2-14199b59ab0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-d7f0a167-e1ca-4bed-b2a3-6611ea4e383f,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-fefa4907-eaf7-4916-bfc8-89c6ef8af1df,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-9e24760c-eb6b-431d-bcaa-2b43fe4bc36b,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-6dfe983c-c0d5-4da6-afdf-d862d5f75b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37108,DS-c5293993-59e1-46cf-b67b-d08310c8c8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-205f28cd-5b6e-4e8c-8470-a02dd71fdcfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1137216545-172.17.0.11-1597335195880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35594,DS-4506aced-1db1-471d-aa56-e06d066e8e68,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-5dc579b9-bd32-495b-a3c2-14199b59ab0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-d7f0a167-e1ca-4bed-b2a3-6611ea4e383f,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-fefa4907-eaf7-4916-bfc8-89c6ef8af1df,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-9e24760c-eb6b-431d-bcaa-2b43fe4bc36b,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-6dfe983c-c0d5-4da6-afdf-d862d5f75b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37108,DS-c5293993-59e1-46cf-b67b-d08310c8c8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-205f28cd-5b6e-4e8c-8470-a02dd71fdcfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-558104291-172.17.0.11-1597335507167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34316,DS-4b7c9c68-199c-41d2-936d-61f1513eae8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-b4d9814e-e30b-4195-b20a-f53649641860,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-f20f3909-b3ec-4e13-af2f-38f16fa61ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-72b5575b-3b1a-4efa-a9a2-d644544a6cae,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-65645555-210d-4e0e-ab26-6677f15cb8cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36300,DS-dbff5d0c-b6bf-4df6-a5ec-6587efff327b,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-bed2adb7-05d1-4d3f-ba9c-4c6e8bbba877,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-73fefb0e-aa8f-488d-ae1e-bed109723164,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-558104291-172.17.0.11-1597335507167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34316,DS-4b7c9c68-199c-41d2-936d-61f1513eae8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-b4d9814e-e30b-4195-b20a-f53649641860,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-f20f3909-b3ec-4e13-af2f-38f16fa61ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-72b5575b-3b1a-4efa-a9a2-d644544a6cae,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-65645555-210d-4e0e-ab26-6677f15cb8cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36300,DS-dbff5d0c-b6bf-4df6-a5ec-6587efff327b,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-bed2adb7-05d1-4d3f-ba9c-4c6e8bbba877,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-73fefb0e-aa8f-488d-ae1e-bed109723164,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1806421677-172.17.0.11-1597335630704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38490,DS-296e54d3-42e5-4c19-b5d5-4d50fed4ed12,DISK], DatanodeInfoWithStorage[127.0.0.1:44265,DS-f76eff32-5064-49b8-8609-ef2b270af12e,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-800541f3-a439-4088-929d-56c79746204f,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-86e3be3d-217d-4fe4-b3fe-82aaf11aa3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37218,DS-4664b8f3-b563-42dd-9fe2-70b1ddb11f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-a8494a9e-fe37-4d66-b045-e2bc4c62ff8a,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-9432b12b-e40b-483f-bdd5-cff845ea5b75,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-078cf49f-a110-4a9f-8e2d-4162fcdf2520,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1806421677-172.17.0.11-1597335630704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38490,DS-296e54d3-42e5-4c19-b5d5-4d50fed4ed12,DISK], DatanodeInfoWithStorage[127.0.0.1:44265,DS-f76eff32-5064-49b8-8609-ef2b270af12e,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-800541f3-a439-4088-929d-56c79746204f,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-86e3be3d-217d-4fe4-b3fe-82aaf11aa3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37218,DS-4664b8f3-b563-42dd-9fe2-70b1ddb11f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-a8494a9e-fe37-4d66-b045-e2bc4c62ff8a,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-9432b12b-e40b-483f-bdd5-cff845ea5b75,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-078cf49f-a110-4a9f-8e2d-4162fcdf2520,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-197295716-172.17.0.11-1597335670692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33070,DS-002a22a2-849f-4379-aec1-fb5dc097c0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-b8f6861b-6a9f-411f-8e96-d5aebaa6de6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44202,DS-f8a4bf08-9fd2-49a2-a18f-114491d4a96f,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-f5b078de-56d5-4fc0-988d-8097e078ced8,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-6674821e-fdf5-426e-bd69-3a0db4c93c16,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-b7187445-7541-4230-931c-ea114ff8fb10,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-955167bd-433a-4db4-befd-4ae6aab87254,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-3ca8d881-256a-4a3d-b49e-eefcf2090bc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-197295716-172.17.0.11-1597335670692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33070,DS-002a22a2-849f-4379-aec1-fb5dc097c0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-b8f6861b-6a9f-411f-8e96-d5aebaa6de6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44202,DS-f8a4bf08-9fd2-49a2-a18f-114491d4a96f,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-f5b078de-56d5-4fc0-988d-8097e078ced8,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-6674821e-fdf5-426e-bd69-3a0db4c93c16,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-b7187445-7541-4230-931c-ea114ff8fb10,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-955167bd-433a-4db4-befd-4ae6aab87254,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-3ca8d881-256a-4a3d-b49e-eefcf2090bc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1454627646-172.17.0.11-1597336245061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35376,DS-12039cd6-9e1e-4b3d-94e1-4f9af2c7faa3,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-b118ff8f-9b4c-43b3-940a-faa757e97b61,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-965ef805-eed5-4ba2-a1a2-f701482ca86f,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-e4ac8594-394f-4361-8676-4b993b403fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-9d41699e-f0af-439b-add7-c777585219b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-36bd639d-8827-417f-8f9a-3996c3ae643d,DISK], DatanodeInfoWithStorage[127.0.0.1:37503,DS-b6b0fd3b-6424-4b92-a4cd-0a47cba8be2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-74e586d2-3d88-49df-9ca5-5d6b5b1579f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1454627646-172.17.0.11-1597336245061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35376,DS-12039cd6-9e1e-4b3d-94e1-4f9af2c7faa3,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-b118ff8f-9b4c-43b3-940a-faa757e97b61,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-965ef805-eed5-4ba2-a1a2-f701482ca86f,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-e4ac8594-394f-4361-8676-4b993b403fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-9d41699e-f0af-439b-add7-c777585219b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-36bd639d-8827-417f-8f9a-3996c3ae643d,DISK], DatanodeInfoWithStorage[127.0.0.1:37503,DS-b6b0fd3b-6424-4b92-a4cd-0a47cba8be2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-74e586d2-3d88-49df-9ca5-5d6b5b1579f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-561884307-172.17.0.11-1597336299144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37061,DS-8e068d01-ad78-4217-a0e3-329059e85440,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-769dd95f-06c6-4b2f-a6b8-239277ad7c79,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-f0dfb7f9-28e3-4765-9e3a-9d3f55e82439,DISK], DatanodeInfoWithStorage[127.0.0.1:38893,DS-d3bc79bf-eea4-410f-a2d0-77f31c993b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44564,DS-b2a3fe38-fdf8-4dec-83f2-e2a380771851,DISK], DatanodeInfoWithStorage[127.0.0.1:42127,DS-d9e54d7d-72e5-4018-875b-d1510dbb057f,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-b85c558e-cf1e-4b44-bb7f-26888d45389e,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-82b36c11-8a7e-4d40-bf00-1e8c7e8ca1dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-561884307-172.17.0.11-1597336299144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37061,DS-8e068d01-ad78-4217-a0e3-329059e85440,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-769dd95f-06c6-4b2f-a6b8-239277ad7c79,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-f0dfb7f9-28e3-4765-9e3a-9d3f55e82439,DISK], DatanodeInfoWithStorage[127.0.0.1:38893,DS-d3bc79bf-eea4-410f-a2d0-77f31c993b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44564,DS-b2a3fe38-fdf8-4dec-83f2-e2a380771851,DISK], DatanodeInfoWithStorage[127.0.0.1:42127,DS-d9e54d7d-72e5-4018-875b-d1510dbb057f,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-b85c558e-cf1e-4b44-bb7f-26888d45389e,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-82b36c11-8a7e-4d40-bf00-1e8c7e8ca1dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1716921644-172.17.0.11-1597338187886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37342,DS-73c5d936-9f58-4a3c-a482-7c54670ad120,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-21ab9a05-c1b4-49b0-bdb9-84b74132d398,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-231108dc-4bb2-4ae9-aa30-7c229e80ab6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39739,DS-fd7feeef-d9a0-4583-8a10-c554d9fcd3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-6a611d51-0652-4237-8f73-3bba3135b303,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-13ce6ed0-8b91-4c3d-9b00-4b2d73a7da5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-42ee4a7b-53c7-46a2-8db7-7be2618b746d,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-9a95676b-e736-470e-882b-4145880ce09b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1716921644-172.17.0.11-1597338187886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37342,DS-73c5d936-9f58-4a3c-a482-7c54670ad120,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-21ab9a05-c1b4-49b0-bdb9-84b74132d398,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-231108dc-4bb2-4ae9-aa30-7c229e80ab6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39739,DS-fd7feeef-d9a0-4583-8a10-c554d9fcd3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-6a611d51-0652-4237-8f73-3bba3135b303,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-13ce6ed0-8b91-4c3d-9b00-4b2d73a7da5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-42ee4a7b-53c7-46a2-8db7-7be2618b746d,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-9a95676b-e736-470e-882b-4145880ce09b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1852705479-172.17.0.11-1597338508759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37732,DS-df754bbc-9833-4dab-9501-7b9a039a221a,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-89e2accd-fce5-42a8-a89b-7546f7be7083,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-c2a5c1fc-8cf7-403b-b0c3-7917acd0efdf,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-744f6e10-bc23-450e-8601-fc8911024c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43433,DS-b8084ad2-7c76-49bb-b90b-32747dc76ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-033d0beb-bc0c-4d92-a709-3e51daae4590,DISK], DatanodeInfoWithStorage[127.0.0.1:39166,DS-0842af32-7951-4b69-b6c0-1c8e91af8b89,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-e658ef94-20dd-42eb-9232-c9b762f3122d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1852705479-172.17.0.11-1597338508759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37732,DS-df754bbc-9833-4dab-9501-7b9a039a221a,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-89e2accd-fce5-42a8-a89b-7546f7be7083,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-c2a5c1fc-8cf7-403b-b0c3-7917acd0efdf,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-744f6e10-bc23-450e-8601-fc8911024c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43433,DS-b8084ad2-7c76-49bb-b90b-32747dc76ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-033d0beb-bc0c-4d92-a709-3e51daae4590,DISK], DatanodeInfoWithStorage[127.0.0.1:39166,DS-0842af32-7951-4b69-b6c0-1c8e91af8b89,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-e658ef94-20dd-42eb-9232-c9b762f3122d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1279427744-172.17.0.11-1597338593449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33024,DS-97ff6372-040a-4218-82ae-326c01e93b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-52c2382a-06da-4280-b912-11ec9806a406,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-720a3e17-29e5-414e-9541-8426c0b5a1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-1a44d732-f840-4c1a-a506-fa2444f47d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41958,DS-a1291463-1b76-411e-abb3-c70daa24a542,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-cd3ec74c-368f-44d4-a0f5-b81c4c1ecbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-f492c3e2-3595-4bc2-acdb-63f69d7d928a,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-10c25112-822f-4ad8-87ce-d1db78c62865,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1279427744-172.17.0.11-1597338593449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33024,DS-97ff6372-040a-4218-82ae-326c01e93b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-52c2382a-06da-4280-b912-11ec9806a406,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-720a3e17-29e5-414e-9541-8426c0b5a1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-1a44d732-f840-4c1a-a506-fa2444f47d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41958,DS-a1291463-1b76-411e-abb3-c70daa24a542,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-cd3ec74c-368f-44d4-a0f5-b81c4c1ecbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-f492c3e2-3595-4bc2-acdb-63f69d7d928a,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-10c25112-822f-4ad8-87ce-d1db78c62865,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1031463243-172.17.0.11-1597338763946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35518,DS-453e5cd7-1127-4b0c-8192-f07de3ed4e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-4a21a9ef-fb69-4b96-8145-3b4d1aa53cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-720e98bb-bf69-48a1-9a9e-8d0e2a66f067,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-9c98afd6-5502-425c-867b-f59f2a7a8a57,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-02dc4e9f-a11d-4460-a5a1-836aa5173e15,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-34f488f4-6a5c-4bea-81d5-6e7180bfc6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-19d8e17e-f797-4884-8aa6-9fd68548f1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-f358f50d-41b8-4875-a162-5b547e7c4847,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1031463243-172.17.0.11-1597338763946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35518,DS-453e5cd7-1127-4b0c-8192-f07de3ed4e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-4a21a9ef-fb69-4b96-8145-3b4d1aa53cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-720e98bb-bf69-48a1-9a9e-8d0e2a66f067,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-9c98afd6-5502-425c-867b-f59f2a7a8a57,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-02dc4e9f-a11d-4460-a5a1-836aa5173e15,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-34f488f4-6a5c-4bea-81d5-6e7180bfc6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-19d8e17e-f797-4884-8aa6-9fd68548f1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-f358f50d-41b8-4875-a162-5b547e7c4847,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1131506758-172.17.0.11-1597338818898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34223,DS-fd9203e8-3857-4964-aec3-729760a7e56b,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-45bd58c5-7b8f-4f24-8644-036d564fe9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-526f9b0e-4a10-4284-a6cb-1bcc49738ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-a408a74d-468b-4d48-a306-ea1670a74d56,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-984fe498-b882-41aa-ae22-64123e01f778,DISK], DatanodeInfoWithStorage[127.0.0.1:33612,DS-9f062802-c6f9-4b27-a2de-3a60b9367598,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-5b001118-8cd3-4c05-9e9f-1e972e67e0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45995,DS-61378afb-2363-45aa-bd11-83c1f7e63f16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1131506758-172.17.0.11-1597338818898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34223,DS-fd9203e8-3857-4964-aec3-729760a7e56b,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-45bd58c5-7b8f-4f24-8644-036d564fe9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-526f9b0e-4a10-4284-a6cb-1bcc49738ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-a408a74d-468b-4d48-a306-ea1670a74d56,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-984fe498-b882-41aa-ae22-64123e01f778,DISK], DatanodeInfoWithStorage[127.0.0.1:33612,DS-9f062802-c6f9-4b27-a2de-3a60b9367598,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-5b001118-8cd3-4c05-9e9f-1e972e67e0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45995,DS-61378afb-2363-45aa-bd11-83c1f7e63f16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1501304331-172.17.0.11-1597338995661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34958,DS-c574bfcd-16b6-4add-8b68-6421820935bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-35209a38-8a11-4887-a0bd-3c058a806edd,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-f000986f-9a33-4481-83b7-7462c15fd8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-7d8753d0-2b76-4f82-839a-bcf33a86e02b,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-227cf6ac-a5c6-46b7-8e44-20fa750ea0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-7b5ad19b-04cc-465b-930c-d2f8040afb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-7045b95f-70a1-4856-a9d0-89e544ec2885,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-35eac4dc-bdc7-4d0c-87af-f394cd1f52fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1501304331-172.17.0.11-1597338995661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34958,DS-c574bfcd-16b6-4add-8b68-6421820935bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-35209a38-8a11-4887-a0bd-3c058a806edd,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-f000986f-9a33-4481-83b7-7462c15fd8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-7d8753d0-2b76-4f82-839a-bcf33a86e02b,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-227cf6ac-a5c6-46b7-8e44-20fa750ea0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-7b5ad19b-04cc-465b-930c-d2f8040afb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-7045b95f-70a1-4856-a9d0-89e544ec2885,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-35eac4dc-bdc7-4d0c-87af-f394cd1f52fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-961184792-172.17.0.11-1597339401599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44371,DS-17c337ef-5442-4c9b-8ce6-71984ad85c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-82b091a7-d049-4669-a6e0-81b7e61c881b,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-77465401-056b-46ab-a1c1-ecb26300525e,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-e17de56a-9d33-4345-8aa8-947fe77ff63d,DISK], DatanodeInfoWithStorage[127.0.0.1:34453,DS-cebbd129-9130-4731-9760-ceb4ed875b69,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-92495a7e-d64e-43f7-8422-aba57bd0389c,DISK], DatanodeInfoWithStorage[127.0.0.1:32819,DS-868ec2d9-4769-49d4-9a6e-85cf536a3f19,DISK], DatanodeInfoWithStorage[127.0.0.1:37192,DS-9a79a387-c481-4657-8c25-0de9e20dddc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-961184792-172.17.0.11-1597339401599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44371,DS-17c337ef-5442-4c9b-8ce6-71984ad85c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-82b091a7-d049-4669-a6e0-81b7e61c881b,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-77465401-056b-46ab-a1c1-ecb26300525e,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-e17de56a-9d33-4345-8aa8-947fe77ff63d,DISK], DatanodeInfoWithStorage[127.0.0.1:34453,DS-cebbd129-9130-4731-9760-ceb4ed875b69,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-92495a7e-d64e-43f7-8422-aba57bd0389c,DISK], DatanodeInfoWithStorage[127.0.0.1:32819,DS-868ec2d9-4769-49d4-9a6e-85cf536a3f19,DISK], DatanodeInfoWithStorage[127.0.0.1:37192,DS-9a79a387-c481-4657-8c25-0de9e20dddc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-390271253-172.17.0.11-1597340202761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40534,DS-b8e73608-fd8a-4710-bce4-86d44eb56b21,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-0e70e7e6-043c-4317-8378-aed53fe40352,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-0c8962ff-5add-4c2d-9945-4e31ce25b85b,DISK], DatanodeInfoWithStorage[127.0.0.1:34941,DS-86da20c1-fb15-42d8-8c7d-910278c12f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-7421830f-6de4-4a09-8765-67ac6a66eb9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-ab377bd2-b70b-426f-a9da-749bb49f9a10,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-287b6fe2-c3cf-4523-945d-19e43e578520,DISK], DatanodeInfoWithStorage[127.0.0.1:45487,DS-9c67ce0d-55f3-420d-a3b6-b59e58b99d4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-390271253-172.17.0.11-1597340202761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40534,DS-b8e73608-fd8a-4710-bce4-86d44eb56b21,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-0e70e7e6-043c-4317-8378-aed53fe40352,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-0c8962ff-5add-4c2d-9945-4e31ce25b85b,DISK], DatanodeInfoWithStorage[127.0.0.1:34941,DS-86da20c1-fb15-42d8-8c7d-910278c12f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-7421830f-6de4-4a09-8765-67ac6a66eb9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-ab377bd2-b70b-426f-a9da-749bb49f9a10,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-287b6fe2-c3cf-4523-945d-19e43e578520,DISK], DatanodeInfoWithStorage[127.0.0.1:45487,DS-9c67ce0d-55f3-420d-a3b6-b59e58b99d4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-512980158-172.17.0.11-1597340855665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39877,DS-29e6b52c-a831-43f4-bcbd-f7804bd9cec0,DISK], DatanodeInfoWithStorage[127.0.0.1:41196,DS-96679b62-0237-491e-bc4e-e4d265a5ef2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40647,DS-80e42770-c9d7-4f9f-b3f4-aee8c5972d35,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-f0709b82-c72a-41ba-a4e5-3e2583dc8b51,DISK], DatanodeInfoWithStorage[127.0.0.1:42112,DS-f9ef1af2-d274-40f7-87a9-2417f9711957,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-1461d801-d5f4-440d-8e05-56a1d926b23d,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-5b54374c-db31-4f06-80c4-fb2631dbbf9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-c746e76f-b511-4d96-a6be-417fa384e6f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-512980158-172.17.0.11-1597340855665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39877,DS-29e6b52c-a831-43f4-bcbd-f7804bd9cec0,DISK], DatanodeInfoWithStorage[127.0.0.1:41196,DS-96679b62-0237-491e-bc4e-e4d265a5ef2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40647,DS-80e42770-c9d7-4f9f-b3f4-aee8c5972d35,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-f0709b82-c72a-41ba-a4e5-3e2583dc8b51,DISK], DatanodeInfoWithStorage[127.0.0.1:42112,DS-f9ef1af2-d274-40f7-87a9-2417f9711957,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-1461d801-d5f4-440d-8e05-56a1d926b23d,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-5b54374c-db31-4f06-80c4-fb2631dbbf9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-c746e76f-b511-4d96-a6be-417fa384e6f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-560377797-172.17.0.11-1597340949209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42413,DS-723f091b-e466-4044-8ab8-3d4596c9c781,DISK], DatanodeInfoWithStorage[127.0.0.1:39679,DS-7d23d81f-c906-48c4-8a2a-e9179c495648,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-67af66c8-0016-4a4b-a8aa-6afa71ae1acd,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-6b849d54-a708-4321-bef4-0d615d2baca3,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-a05db1b4-41c4-4c21-9837-fede9ba8ab1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-ffc621bc-658c-4c61-a68f-338a00e07d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-1bb4ebbf-414b-4957-b8c0-50a532f63c99,DISK], DatanodeInfoWithStorage[127.0.0.1:43834,DS-7c594585-5eeb-4c51-92bc-15507d275592,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-560377797-172.17.0.11-1597340949209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42413,DS-723f091b-e466-4044-8ab8-3d4596c9c781,DISK], DatanodeInfoWithStorage[127.0.0.1:39679,DS-7d23d81f-c906-48c4-8a2a-e9179c495648,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-67af66c8-0016-4a4b-a8aa-6afa71ae1acd,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-6b849d54-a708-4321-bef4-0d615d2baca3,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-a05db1b4-41c4-4c21-9837-fede9ba8ab1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-ffc621bc-658c-4c61-a68f-338a00e07d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-1bb4ebbf-414b-4957-b8c0-50a532f63c99,DISK], DatanodeInfoWithStorage[127.0.0.1:43834,DS-7c594585-5eeb-4c51-92bc-15507d275592,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6571
