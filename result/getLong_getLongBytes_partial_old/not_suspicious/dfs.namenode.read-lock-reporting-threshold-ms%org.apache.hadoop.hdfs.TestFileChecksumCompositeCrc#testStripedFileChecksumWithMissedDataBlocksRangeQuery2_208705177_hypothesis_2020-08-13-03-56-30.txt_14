reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691491712-172.17.0.6-1597291369229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33105,DS-35c560d3-6455-45a4-a065-bb875f37e80c,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-e6f91ff9-8009-4a0d-8ef5-613efcd42bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-c82c72a3-5878-47ae-85f4-8af72a2f16cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43497,DS-ef8cd7d1-ae28-4c50-aaa9-ae3380f876f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-5b839f45-dde2-4ed7-a299-48283292c136,DISK], DatanodeInfoWithStorage[127.0.0.1:45355,DS-41dc152c-83e1-4126-9a6b-af97a9e77a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-881546a3-9943-4d57-be83-fb5d9d7f0760,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-93a1d84e-ba9f-4628-8263-ca074e8cfe7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691491712-172.17.0.6-1597291369229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33105,DS-35c560d3-6455-45a4-a065-bb875f37e80c,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-e6f91ff9-8009-4a0d-8ef5-613efcd42bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-c82c72a3-5878-47ae-85f4-8af72a2f16cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43497,DS-ef8cd7d1-ae28-4c50-aaa9-ae3380f876f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-5b839f45-dde2-4ed7-a299-48283292c136,DISK], DatanodeInfoWithStorage[127.0.0.1:45355,DS-41dc152c-83e1-4126-9a6b-af97a9e77a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-881546a3-9943-4d57-be83-fb5d9d7f0760,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-93a1d84e-ba9f-4628-8263-ca074e8cfe7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-48142231-172.17.0.6-1597291421080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35143,DS-00418e92-f4e0-4e28-9600-d6bdb24b5af0,DISK], DatanodeInfoWithStorage[127.0.0.1:35871,DS-b5b4200d-3a78-4844-aaeb-84c59c569cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-72aea08c-868e-4b10-9d4b-2cca683f82d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42877,DS-757f93d1-0ce6-4f4f-82c9-ca600befc49b,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-2605aec9-0b99-47b8-b2b4-7aea47a0e176,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-126ef8c8-c6a7-404e-a98e-65a75ccb8c56,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-b2b2a3fd-17cc-4710-9254-ddbaf62101dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-95c11520-e9f6-49d2-a03b-256e7f200fe7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-48142231-172.17.0.6-1597291421080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35143,DS-00418e92-f4e0-4e28-9600-d6bdb24b5af0,DISK], DatanodeInfoWithStorage[127.0.0.1:35871,DS-b5b4200d-3a78-4844-aaeb-84c59c569cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-72aea08c-868e-4b10-9d4b-2cca683f82d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42877,DS-757f93d1-0ce6-4f4f-82c9-ca600befc49b,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-2605aec9-0b99-47b8-b2b4-7aea47a0e176,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-126ef8c8-c6a7-404e-a98e-65a75ccb8c56,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-b2b2a3fd-17cc-4710-9254-ddbaf62101dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-95c11520-e9f6-49d2-a03b-256e7f200fe7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-997736841-172.17.0.6-1597291851377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36850,DS-bb861a96-c7f8-42f0-a815-fa37de154c94,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-1dd6c2e7-4b6f-4955-bbd1-dfd3ce9cc211,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-a2ebdaeb-6a3a-4838-9c9a-cc73eb71e668,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-d46a83a6-ffa5-4964-b6eb-f4bd210e2d74,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-945463f5-ae10-45aa-8ee0-24be706efa30,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-dcdbf952-ecc2-4df3-8fe9-b2b3606d9ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-f5f4751e-c738-422b-af7e-245b2d718815,DISK], DatanodeInfoWithStorage[127.0.0.1:37933,DS-67700b42-8c39-4285-93f4-4ffb5391afb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-997736841-172.17.0.6-1597291851377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36850,DS-bb861a96-c7f8-42f0-a815-fa37de154c94,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-1dd6c2e7-4b6f-4955-bbd1-dfd3ce9cc211,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-a2ebdaeb-6a3a-4838-9c9a-cc73eb71e668,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-d46a83a6-ffa5-4964-b6eb-f4bd210e2d74,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-945463f5-ae10-45aa-8ee0-24be706efa30,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-dcdbf952-ecc2-4df3-8fe9-b2b3606d9ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-f5f4751e-c738-422b-af7e-245b2d718815,DISK], DatanodeInfoWithStorage[127.0.0.1:37933,DS-67700b42-8c39-4285-93f4-4ffb5391afb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-769946349-172.17.0.6-1597292554634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45224,DS-78a2a1ec-9b51-46a2-b2e1-190e131b413a,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-f7714600-a4b9-422c-8735-69bfe4e7d9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-88c97f32-acb2-45fb-af6e-dea5b074798a,DISK], DatanodeInfoWithStorage[127.0.0.1:41196,DS-c0959195-8900-4d8e-9187-c050d42a62a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-73e114d1-a710-4fed-b3d8-4bc5a3a981f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-20fa1ffa-db0b-4df8-a017-64dd8a8d2474,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-aff1c4c7-ed84-4da0-b03d-e5667ecfe287,DISK], DatanodeInfoWithStorage[127.0.0.1:41318,DS-22889a2b-2950-4c13-8feb-399ce46a6eb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-769946349-172.17.0.6-1597292554634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45224,DS-78a2a1ec-9b51-46a2-b2e1-190e131b413a,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-f7714600-a4b9-422c-8735-69bfe4e7d9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-88c97f32-acb2-45fb-af6e-dea5b074798a,DISK], DatanodeInfoWithStorage[127.0.0.1:41196,DS-c0959195-8900-4d8e-9187-c050d42a62a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-73e114d1-a710-4fed-b3d8-4bc5a3a981f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-20fa1ffa-db0b-4df8-a017-64dd8a8d2474,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-aff1c4c7-ed84-4da0-b03d-e5667ecfe287,DISK], DatanodeInfoWithStorage[127.0.0.1:41318,DS-22889a2b-2950-4c13-8feb-399ce46a6eb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1744728901-172.17.0.6-1597292609798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34071,DS-5ad23b75-f70b-46ea-b538-3e2784163878,DISK], DatanodeInfoWithStorage[127.0.0.1:35743,DS-1fce2681-230e-4fa3-a8f9-3be2008d9046,DISK], DatanodeInfoWithStorage[127.0.0.1:36303,DS-a41cb2ee-1620-4ce4-8d73-4a23f54f3a62,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-3d1f2211-caa1-4dce-b41e-aa89ef1136e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46631,DS-7dac5eed-7340-4625-a27a-ffa209bed6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-8b020d7f-9e0c-46c8-b7f2-037ab7051108,DISK], DatanodeInfoWithStorage[127.0.0.1:35148,DS-47f97078-786a-4a6d-b5a3-97b0f2c7ed8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35052,DS-014edcd2-7aa4-4e93-9dbd-73102f235c7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1744728901-172.17.0.6-1597292609798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34071,DS-5ad23b75-f70b-46ea-b538-3e2784163878,DISK], DatanodeInfoWithStorage[127.0.0.1:35743,DS-1fce2681-230e-4fa3-a8f9-3be2008d9046,DISK], DatanodeInfoWithStorage[127.0.0.1:36303,DS-a41cb2ee-1620-4ce4-8d73-4a23f54f3a62,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-3d1f2211-caa1-4dce-b41e-aa89ef1136e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46631,DS-7dac5eed-7340-4625-a27a-ffa209bed6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-8b020d7f-9e0c-46c8-b7f2-037ab7051108,DISK], DatanodeInfoWithStorage[127.0.0.1:35148,DS-47f97078-786a-4a6d-b5a3-97b0f2c7ed8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35052,DS-014edcd2-7aa4-4e93-9dbd-73102f235c7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-372517245-172.17.0.6-1597293294682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36031,DS-daf42983-909a-4ce5-870e-a64434caf6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42921,DS-1e37bf0f-f9b0-41ae-bb04-655f01cf3c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-bc5fbe1f-c0bf-4ac6-8021-764b05f844b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-363f5405-4156-43dc-bf7a-590b9055c9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-e66b88af-6f27-46dd-b9b3-a22e0f2f74c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-e389dc76-0726-453f-b934-06afc1521bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-04b99ee0-5c2e-4d85-b199-0500bcad8c97,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-75398d57-d7f4-4ba4-8dee-3b111f0cda99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-372517245-172.17.0.6-1597293294682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36031,DS-daf42983-909a-4ce5-870e-a64434caf6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42921,DS-1e37bf0f-f9b0-41ae-bb04-655f01cf3c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-bc5fbe1f-c0bf-4ac6-8021-764b05f844b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-363f5405-4156-43dc-bf7a-590b9055c9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-e66b88af-6f27-46dd-b9b3-a22e0f2f74c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-e389dc76-0726-453f-b934-06afc1521bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-04b99ee0-5c2e-4d85-b199-0500bcad8c97,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-75398d57-d7f4-4ba4-8dee-3b111f0cda99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-831776424-172.17.0.6-1597294287169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32899,DS-bab3c74e-85dc-4698-9406-0d10112d7f91,DISK], DatanodeInfoWithStorage[127.0.0.1:42483,DS-e65ae634-e74c-4b3d-99a7-c3aefe037c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-e27a4d43-1da7-495e-b861-24da5ff6dd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-2c40c17a-2f54-4dc3-a439-a550a29dc2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-1201a1b1-575b-47ed-9884-2c252efff228,DISK], DatanodeInfoWithStorage[127.0.0.1:33121,DS-5085f087-5158-4b8d-a1e6-9ce77c671f11,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-69068254-1b1b-4ea5-9cc6-21921cdaa567,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-04999218-6982-434b-8896-52d090e6f187,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-831776424-172.17.0.6-1597294287169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32899,DS-bab3c74e-85dc-4698-9406-0d10112d7f91,DISK], DatanodeInfoWithStorage[127.0.0.1:42483,DS-e65ae634-e74c-4b3d-99a7-c3aefe037c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-e27a4d43-1da7-495e-b861-24da5ff6dd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-2c40c17a-2f54-4dc3-a439-a550a29dc2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-1201a1b1-575b-47ed-9884-2c252efff228,DISK], DatanodeInfoWithStorage[127.0.0.1:33121,DS-5085f087-5158-4b8d-a1e6-9ce77c671f11,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-69068254-1b1b-4ea5-9cc6-21921cdaa567,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-04999218-6982-434b-8896-52d090e6f187,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-512290934-172.17.0.6-1597294427327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44619,DS-9a63d8fa-f0c9-4538-bd38-91f4a2fddd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-ee22c5eb-f777-4cc3-a7d8-c62d36d96f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-ecd75aa0-594e-4018-8546-2c83bbe5aa74,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-b6203425-84ce-4aef-b957-66a3c6afe4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-54a51ac6-cc08-4369-9e51-9625afa4ca25,DISK], DatanodeInfoWithStorage[127.0.0.1:40172,DS-a17300b8-5fec-4b60-b7d2-65f312701386,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-3c09feae-4041-41b2-bdcf-edabfa247719,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-ec305503-b2c6-4780-a692-36d6e4eaa123,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-512290934-172.17.0.6-1597294427327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44619,DS-9a63d8fa-f0c9-4538-bd38-91f4a2fddd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-ee22c5eb-f777-4cc3-a7d8-c62d36d96f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-ecd75aa0-594e-4018-8546-2c83bbe5aa74,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-b6203425-84ce-4aef-b957-66a3c6afe4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-54a51ac6-cc08-4369-9e51-9625afa4ca25,DISK], DatanodeInfoWithStorage[127.0.0.1:40172,DS-a17300b8-5fec-4b60-b7d2-65f312701386,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-3c09feae-4041-41b2-bdcf-edabfa247719,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-ec305503-b2c6-4780-a692-36d6e4eaa123,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2120871446-172.17.0.6-1597294719183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37702,DS-10b77f0e-50ae-4037-bd94-43670bacc482,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-9f097d97-221b-4870-aa01-5dee443bd8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33243,DS-5d1f2889-2bef-4084-a1cf-9218378d86a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-84282f19-b008-4b1f-ad60-d68b80e29b23,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-934ed6da-9067-465f-bf00-bb2916117fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-a59dfec6-d773-4d3d-ba08-5301e1e8d49c,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-2bc85f64-f7c1-45cb-8f1c-2b7ca1085a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-6c6f8578-591d-4f1e-b2bc-73f6d902f30f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2120871446-172.17.0.6-1597294719183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37702,DS-10b77f0e-50ae-4037-bd94-43670bacc482,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-9f097d97-221b-4870-aa01-5dee443bd8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33243,DS-5d1f2889-2bef-4084-a1cf-9218378d86a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-84282f19-b008-4b1f-ad60-d68b80e29b23,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-934ed6da-9067-465f-bf00-bb2916117fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-a59dfec6-d773-4d3d-ba08-5301e1e8d49c,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-2bc85f64-f7c1-45cb-8f1c-2b7ca1085a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-6c6f8578-591d-4f1e-b2bc-73f6d902f30f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1162784668-172.17.0.6-1597295994424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36583,DS-9354ce93-cd19-4987-84ce-905c915fec5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-044cb2be-e1fa-4c4c-b06e-d6bf6c154146,DISK], DatanodeInfoWithStorage[127.0.0.1:38468,DS-efd92faf-d5a6-494e-8496-f6f763ebe3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-9fae056a-d027-4928-ae48-80236bfaa803,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-d3b8b183-a948-485d-a583-fdefa6408dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-0424c382-5940-4794-889d-99d301fa6690,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-85cc7562-a59f-4cb8-800a-e3ae4d7dd31b,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-687ed13a-c544-481f-ad9a-508cd201b99f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1162784668-172.17.0.6-1597295994424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36583,DS-9354ce93-cd19-4987-84ce-905c915fec5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-044cb2be-e1fa-4c4c-b06e-d6bf6c154146,DISK], DatanodeInfoWithStorage[127.0.0.1:38468,DS-efd92faf-d5a6-494e-8496-f6f763ebe3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-9fae056a-d027-4928-ae48-80236bfaa803,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-d3b8b183-a948-485d-a583-fdefa6408dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-0424c382-5940-4794-889d-99d301fa6690,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-85cc7562-a59f-4cb8-800a-e3ae4d7dd31b,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-687ed13a-c544-481f-ad9a-508cd201b99f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-238304098-172.17.0.6-1597296190465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34249,DS-70f77d36-6dc5-4e9b-a9d3-a2e703f0cc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-24ae1c75-5f2d-4545-bd8d-6fc6bf96c75d,DISK], DatanodeInfoWithStorage[127.0.0.1:44851,DS-3d76c774-5403-4418-9231-7bf88afe6a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-cd666025-4e31-421a-9a0a-48975d0bc65d,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-81e188a2-c7f1-476b-b5cc-06db3fe3378e,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-772d37fb-e9e5-4439-b232-180e4a5db106,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-a49fa6a3-de4f-43c9-8772-8be224e93623,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-249cb20c-e5b9-4a20-a029-f1d945093760,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-238304098-172.17.0.6-1597296190465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34249,DS-70f77d36-6dc5-4e9b-a9d3-a2e703f0cc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-24ae1c75-5f2d-4545-bd8d-6fc6bf96c75d,DISK], DatanodeInfoWithStorage[127.0.0.1:44851,DS-3d76c774-5403-4418-9231-7bf88afe6a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-cd666025-4e31-421a-9a0a-48975d0bc65d,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-81e188a2-c7f1-476b-b5cc-06db3fe3378e,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-772d37fb-e9e5-4439-b232-180e4a5db106,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-a49fa6a3-de4f-43c9-8772-8be224e93623,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-249cb20c-e5b9-4a20-a029-f1d945093760,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1453803021-172.17.0.6-1597297062411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46411,DS-75e9b050-ed94-4ac1-aafb-c7d1eba7727f,DISK], DatanodeInfoWithStorage[127.0.0.1:36830,DS-4fc5c892-00e7-4eb4-94cf-2138f1ad860b,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-ba9e5d16-ed12-4fb6-bd70-50441baf72e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42144,DS-7c738203-c520-4c67-94b9-1b9cfb3f45fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46241,DS-1b8f88f9-85d3-4773-b172-1eabc2446688,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-27612edf-2db6-4e49-9af6-06801419fac0,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-8e8b5acf-8838-4ec5-b694-85d417181dea,DISK], DatanodeInfoWithStorage[127.0.0.1:37280,DS-cb018f28-4d15-4c8c-aeac-43f6ed4fdf4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1453803021-172.17.0.6-1597297062411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46411,DS-75e9b050-ed94-4ac1-aafb-c7d1eba7727f,DISK], DatanodeInfoWithStorage[127.0.0.1:36830,DS-4fc5c892-00e7-4eb4-94cf-2138f1ad860b,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-ba9e5d16-ed12-4fb6-bd70-50441baf72e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42144,DS-7c738203-c520-4c67-94b9-1b9cfb3f45fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46241,DS-1b8f88f9-85d3-4773-b172-1eabc2446688,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-27612edf-2db6-4e49-9af6-06801419fac0,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-8e8b5acf-8838-4ec5-b694-85d417181dea,DISK], DatanodeInfoWithStorage[127.0.0.1:37280,DS-cb018f28-4d15-4c8c-aeac-43f6ed4fdf4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1259533977-172.17.0.6-1597297111463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43337,DS-c5eefd2d-8550-490d-9963-ce02cbf89d88,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-441f9e65-07ae-4830-8c3e-25d000923d24,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-37dbcc85-5b7c-47a3-9c46-b8ef30223032,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-3bf37713-6744-4e24-9137-fc88aeb9aab3,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-9e7750bd-f597-48fd-912f-a95c6ee3d938,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-ed18ca17-ec80-4a33-980d-d808457df69b,DISK], DatanodeInfoWithStorage[127.0.0.1:39422,DS-2d8d81db-f64c-464e-b61a-b40804974639,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-0993f990-b82e-4eba-ace5-82dd636cff18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1259533977-172.17.0.6-1597297111463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43337,DS-c5eefd2d-8550-490d-9963-ce02cbf89d88,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-441f9e65-07ae-4830-8c3e-25d000923d24,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-37dbcc85-5b7c-47a3-9c46-b8ef30223032,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-3bf37713-6744-4e24-9137-fc88aeb9aab3,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-9e7750bd-f597-48fd-912f-a95c6ee3d938,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-ed18ca17-ec80-4a33-980d-d808457df69b,DISK], DatanodeInfoWithStorage[127.0.0.1:39422,DS-2d8d81db-f64c-464e-b61a-b40804974639,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-0993f990-b82e-4eba-ace5-82dd636cff18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1216112688-172.17.0.6-1597297153042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37801,DS-b2d1ff11-f471-4764-bf5f-9ac7b389014e,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-3ff8391a-0a39-42cd-96c3-fdd01d4dbacb,DISK], DatanodeInfoWithStorage[127.0.0.1:45426,DS-2cffd727-835f-477b-8e4d-94175407879c,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-a92e3220-6ca6-4cde-96be-11d77fe8ca69,DISK], DatanodeInfoWithStorage[127.0.0.1:40609,DS-2e3dfb57-c3ca-498f-9be9-b7d20fcdbc37,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-8ddc1d3e-c333-4124-a392-7d12cc2727b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-45e181b4-ad7c-47e0-84b1-ea1c44d44655,DISK], DatanodeInfoWithStorage[127.0.0.1:44896,DS-10a3ba98-a4b7-44c9-a190-03fdfc7e8c6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1216112688-172.17.0.6-1597297153042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37801,DS-b2d1ff11-f471-4764-bf5f-9ac7b389014e,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-3ff8391a-0a39-42cd-96c3-fdd01d4dbacb,DISK], DatanodeInfoWithStorage[127.0.0.1:45426,DS-2cffd727-835f-477b-8e4d-94175407879c,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-a92e3220-6ca6-4cde-96be-11d77fe8ca69,DISK], DatanodeInfoWithStorage[127.0.0.1:40609,DS-2e3dfb57-c3ca-498f-9be9-b7d20fcdbc37,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-8ddc1d3e-c333-4124-a392-7d12cc2727b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-45e181b4-ad7c-47e0-84b1-ea1c44d44655,DISK], DatanodeInfoWithStorage[127.0.0.1:44896,DS-10a3ba98-a4b7-44c9-a190-03fdfc7e8c6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1298523650-172.17.0.6-1597297306001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41739,DS-97769258-262d-47aa-8421-26540deb4eec,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-4a8fbce0-6efd-410a-8291-d6c9439a187e,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-6741bfa2-c93c-4ea7-b0e3-f6e62f6e161d,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-1d494148-c286-43e2-8cca-8f8451cf3c30,DISK], DatanodeInfoWithStorage[127.0.0.1:41065,DS-074bbbee-df49-4648-aa4c-df8dd9e79c59,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-92aee1f8-e49d-4b03-89b3-b2ec242596dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-25abced5-6ec0-4a54-a136-e57823942243,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-4db4314f-d808-44d7-862f-3fe34fedd2d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1298523650-172.17.0.6-1597297306001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41739,DS-97769258-262d-47aa-8421-26540deb4eec,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-4a8fbce0-6efd-410a-8291-d6c9439a187e,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-6741bfa2-c93c-4ea7-b0e3-f6e62f6e161d,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-1d494148-c286-43e2-8cca-8f8451cf3c30,DISK], DatanodeInfoWithStorage[127.0.0.1:41065,DS-074bbbee-df49-4648-aa4c-df8dd9e79c59,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-92aee1f8-e49d-4b03-89b3-b2ec242596dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-25abced5-6ec0-4a54-a136-e57823942243,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-4db4314f-d808-44d7-862f-3fe34fedd2d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1180232784-172.17.0.6-1597297410848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39952,DS-5291e17a-4926-4cc6-8340-51f2a231fadd,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-6e695430-e588-48ba-8d4a-ec4bbff94c99,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-1ff22f40-b8ee-4318-af13-c5a8328afe47,DISK], DatanodeInfoWithStorage[127.0.0.1:43004,DS-206dfc6f-e8f1-4c3b-b76c-8fcbb97b8362,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-1e6f96b4-60b8-4d40-8905-1befc7d6ed8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-2b6262e6-2407-4141-aec9-5ae2af0ebaeb,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-3c3f92d0-6f4b-4e36-ac09-c098c7db00a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42351,DS-82d58f92-cfff-4e94-9369-83b7eb0bd256,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1180232784-172.17.0.6-1597297410848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39952,DS-5291e17a-4926-4cc6-8340-51f2a231fadd,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-6e695430-e588-48ba-8d4a-ec4bbff94c99,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-1ff22f40-b8ee-4318-af13-c5a8328afe47,DISK], DatanodeInfoWithStorage[127.0.0.1:43004,DS-206dfc6f-e8f1-4c3b-b76c-8fcbb97b8362,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-1e6f96b4-60b8-4d40-8905-1befc7d6ed8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-2b6262e6-2407-4141-aec9-5ae2af0ebaeb,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-3c3f92d0-6f4b-4e36-ac09-c098c7db00a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42351,DS-82d58f92-cfff-4e94-9369-83b7eb0bd256,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1441066838-172.17.0.6-1597297459005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38936,DS-76efae1b-d9f5-40ab-a4fe-2e7f7106910e,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-4041c3f9-6321-4fb6-b075-8b2bf9e1f1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-f423a7b8-1dba-4de3-b6aa-503a7d894b01,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-b29dfbbb-c27f-4127-80b8-aa808aeb530f,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-10d00de1-b08d-487c-b3e4-f873917e77e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-6be85360-cd8a-4e7c-a700-77c61f34a28c,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-80f41bc3-6d00-4ee3-975b-1ec5c8796957,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-5051a0ff-32fc-45ba-adcc-b83c40532d60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1441066838-172.17.0.6-1597297459005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38936,DS-76efae1b-d9f5-40ab-a4fe-2e7f7106910e,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-4041c3f9-6321-4fb6-b075-8b2bf9e1f1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-f423a7b8-1dba-4de3-b6aa-503a7d894b01,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-b29dfbbb-c27f-4127-80b8-aa808aeb530f,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-10d00de1-b08d-487c-b3e4-f873917e77e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-6be85360-cd8a-4e7c-a700-77c61f34a28c,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-80f41bc3-6d00-4ee3-975b-1ec5c8796957,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-5051a0ff-32fc-45ba-adcc-b83c40532d60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1099940464-172.17.0.6-1597297510533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34321,DS-f4091ae8-f114-4e18-87ef-5439e8e57f83,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-5ab8dddf-a6e3-4b78-b21e-751d66d73493,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-191345f5-3dc4-4a06-ad88-7c9c04afe7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-96b3b872-662b-4a78-bf48-599c6c97c751,DISK], DatanodeInfoWithStorage[127.0.0.1:40193,DS-d9cbb6cb-11de-4a79-8f19-3500e8f28840,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-ef6e0f4e-7043-457f-adbb-9d8369ebd92c,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-51fe95e6-344b-4133-b560-638dadf0e108,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-68f0b2b2-bd4c-41d8-a364-46f0ae128b54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1099940464-172.17.0.6-1597297510533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34321,DS-f4091ae8-f114-4e18-87ef-5439e8e57f83,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-5ab8dddf-a6e3-4b78-b21e-751d66d73493,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-191345f5-3dc4-4a06-ad88-7c9c04afe7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-96b3b872-662b-4a78-bf48-599c6c97c751,DISK], DatanodeInfoWithStorage[127.0.0.1:40193,DS-d9cbb6cb-11de-4a79-8f19-3500e8f28840,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-ef6e0f4e-7043-457f-adbb-9d8369ebd92c,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-51fe95e6-344b-4133-b560-638dadf0e108,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-68f0b2b2-bd4c-41d8-a364-46f0ae128b54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483384631-172.17.0.6-1597297654358:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37179,DS-c8bd82ec-2abe-4010-8f0d-a848ccb0863b,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-30a8abed-baf7-4f44-9eb3-017a04681875,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-a4142545-c7e9-440f-bd9b-d7cffc6536d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46817,DS-2f03240a-5dca-4988-97f9-a1c3d8ee040b,DISK], DatanodeInfoWithStorage[127.0.0.1:42268,DS-b4e23edd-4f9b-4eaf-981d-1a5519ddd28d,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-8f59c7e3-2262-4015-afd6-24783370655c,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-f03da8a4-52d8-4cc8-8c1e-99949da1a3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33796,DS-cfd8ef8a-466a-4e9d-a303-f9295d5ba058,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483384631-172.17.0.6-1597297654358:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37179,DS-c8bd82ec-2abe-4010-8f0d-a848ccb0863b,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-30a8abed-baf7-4f44-9eb3-017a04681875,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-a4142545-c7e9-440f-bd9b-d7cffc6536d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46817,DS-2f03240a-5dca-4988-97f9-a1c3d8ee040b,DISK], DatanodeInfoWithStorage[127.0.0.1:42268,DS-b4e23edd-4f9b-4eaf-981d-1a5519ddd28d,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-8f59c7e3-2262-4015-afd6-24783370655c,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-f03da8a4-52d8-4cc8-8c1e-99949da1a3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33796,DS-cfd8ef8a-466a-4e9d-a303-f9295d5ba058,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548795054-172.17.0.6-1597298121582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36055,DS-d4f734fb-77a2-4162-8291-6a78dcdaa82a,DISK], DatanodeInfoWithStorage[127.0.0.1:36369,DS-c96a72b5-a596-4c92-86c0-f03ae0bd3505,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-d0fd01eb-c177-41c7-a70d-069e2ab7ae6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-d0c0467a-f41b-4310-ab60-13c80e4704c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-f5d56fad-2a47-48c3-9d57-e4cc8e783358,DISK], DatanodeInfoWithStorage[127.0.0.1:39048,DS-7b65f0bf-8ef9-4c04-b135-db0b85f3d1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-2204ebda-16a3-454a-8e3d-e8c80e275456,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-84c03023-8967-4c97-8a84-48ef239711bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548795054-172.17.0.6-1597298121582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36055,DS-d4f734fb-77a2-4162-8291-6a78dcdaa82a,DISK], DatanodeInfoWithStorage[127.0.0.1:36369,DS-c96a72b5-a596-4c92-86c0-f03ae0bd3505,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-d0fd01eb-c177-41c7-a70d-069e2ab7ae6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-d0c0467a-f41b-4310-ab60-13c80e4704c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-f5d56fad-2a47-48c3-9d57-e4cc8e783358,DISK], DatanodeInfoWithStorage[127.0.0.1:39048,DS-7b65f0bf-8ef9-4c04-b135-db0b85f3d1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-2204ebda-16a3-454a-8e3d-e8c80e275456,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-84c03023-8967-4c97-8a84-48ef239711bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 7299
