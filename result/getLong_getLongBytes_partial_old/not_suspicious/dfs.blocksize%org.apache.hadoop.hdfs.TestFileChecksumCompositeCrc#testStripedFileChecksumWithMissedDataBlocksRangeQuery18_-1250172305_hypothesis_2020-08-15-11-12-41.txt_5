reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1613996173-172.17.0.9-1597490200578:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44102,DS-099df71b-b574-42bc-8cb7-3b006bc30a67,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-fb3539b5-26ca-415a-b270-742efde9b448,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-d026b061-cacd-4271-9b39-d41634a2eb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-f38e705f-94dd-4695-bbf2-234b26f76d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-83d78398-a40b-4546-be2c-8f2cf76ffef2,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-33a2c2a1-7096-4279-b47e-1468e60c4688,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-114e127f-27ed-474f-8a62-0f4c64a3a540,DISK], DatanodeInfoWithStorage[127.0.0.1:46393,DS-04423fe7-7b42-4775-b01e-869618968796,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1613996173-172.17.0.9-1597490200578:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44102,DS-099df71b-b574-42bc-8cb7-3b006bc30a67,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-fb3539b5-26ca-415a-b270-742efde9b448,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-d026b061-cacd-4271-9b39-d41634a2eb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-f38e705f-94dd-4695-bbf2-234b26f76d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-83d78398-a40b-4546-be2c-8f2cf76ffef2,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-33a2c2a1-7096-4279-b47e-1468e60c4688,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-114e127f-27ed-474f-8a62-0f4c64a3a540,DISK], DatanodeInfoWithStorage[127.0.0.1:46393,DS-04423fe7-7b42-4775-b01e-869618968796,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-802913849-172.17.0.9-1597490531596:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34371,DS-f8c01f6b-a952-4485-8bf6-eb40cf4f06d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38026,DS-7e52342a-fb9f-4151-a9e4-c8bbed7f9b82,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-4a058a23-1af6-4215-9cbf-01b890988c13,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-f0bb33a2-9daa-4cbe-b513-819270b1da70,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-d5eabc31-836a-4bf2-9f29-ef9791633aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-3a15bf7d-1b89-4421-882b-98581e2b61c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-47519a0e-e6f1-42e4-abf3-72685005241e,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-3370c586-266b-4e67-92af-6a4d2a29e441,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-802913849-172.17.0.9-1597490531596:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34371,DS-f8c01f6b-a952-4485-8bf6-eb40cf4f06d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38026,DS-7e52342a-fb9f-4151-a9e4-c8bbed7f9b82,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-4a058a23-1af6-4215-9cbf-01b890988c13,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-f0bb33a2-9daa-4cbe-b513-819270b1da70,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-d5eabc31-836a-4bf2-9f29-ef9791633aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-3a15bf7d-1b89-4421-882b-98581e2b61c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-47519a0e-e6f1-42e4-abf3-72685005241e,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-3370c586-266b-4e67-92af-6a4d2a29e441,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2053825870-172.17.0.9-1597491207864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39981,DS-fc794fd2-0170-444f-a054-2c8e8f498fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-015982a9-429f-4253-ba48-292b4af52984,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-c2a9ab70-d662-4b1e-9483-156a1f235500,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-df33f731-020b-4635-85ba-667c9e03778b,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-3ed1b994-e1ae-4e27-abbb-db012ccb2b50,DISK], DatanodeInfoWithStorage[127.0.0.1:38444,DS-25a35d15-5541-4234-a0e3-3b0137b1ea3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-f93cc2a3-811d-464d-922e-474704b1e6dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46862,DS-d284da2e-70e3-4e32-9fdf-e76a40967c62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2053825870-172.17.0.9-1597491207864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39981,DS-fc794fd2-0170-444f-a054-2c8e8f498fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-015982a9-429f-4253-ba48-292b4af52984,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-c2a9ab70-d662-4b1e-9483-156a1f235500,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-df33f731-020b-4635-85ba-667c9e03778b,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-3ed1b994-e1ae-4e27-abbb-db012ccb2b50,DISK], DatanodeInfoWithStorage[127.0.0.1:38444,DS-25a35d15-5541-4234-a0e3-3b0137b1ea3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-f93cc2a3-811d-464d-922e-474704b1e6dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46862,DS-d284da2e-70e3-4e32-9fdf-e76a40967c62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-427113746-172.17.0.9-1597491278300:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39779,DS-81489a4d-e9a8-49f3-9a94-4914511eb0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-12068411-78b7-426e-ad88-28b733f25d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-64af17c8-d170-45a3-b7a5-0651343b04db,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-e1148386-9a1d-40d5-9c9b-1a666a527687,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-36539eaf-d29e-4ff1-b1a9-a356c65d5ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-8e646ed3-1bc1-4925-89c4-ec8d2c89eaa3,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-0e68a605-0205-47a6-88e4-430671e78cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-a941f5bd-3df6-4555-8821-2a9af154c4e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-427113746-172.17.0.9-1597491278300:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39779,DS-81489a4d-e9a8-49f3-9a94-4914511eb0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-12068411-78b7-426e-ad88-28b733f25d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-64af17c8-d170-45a3-b7a5-0651343b04db,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-e1148386-9a1d-40d5-9c9b-1a666a527687,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-36539eaf-d29e-4ff1-b1a9-a356c65d5ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-8e646ed3-1bc1-4925-89c4-ec8d2c89eaa3,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-0e68a605-0205-47a6-88e4-430671e78cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-a941f5bd-3df6-4555-8821-2a9af154c4e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-667295238-172.17.0.9-1597491453364:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40704,DS-cb732d0f-9a67-41cb-9e44-35ad6acae6be,DISK], DatanodeInfoWithStorage[127.0.0.1:42163,DS-55fabba7-9efd-4784-bfb7-2ee79d554151,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-48b86c70-1d92-46fc-bc6a-610364bea97f,DISK], DatanodeInfoWithStorage[127.0.0.1:36369,DS-b50328ae-a4c5-427e-ba43-05e430837e65,DISK], DatanodeInfoWithStorage[127.0.0.1:34030,DS-88d88e0e-8dc6-4500-aaf6-bdfb56c34739,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-e69edbae-db4d-4f3c-858b-5ae785aa4258,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-1dd52cce-0171-41e2-aee0-4249e609dbb8,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-55f1a5e1-8cd8-4224-a36e-6b3ea893a61b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-667295238-172.17.0.9-1597491453364:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40704,DS-cb732d0f-9a67-41cb-9e44-35ad6acae6be,DISK], DatanodeInfoWithStorage[127.0.0.1:42163,DS-55fabba7-9efd-4784-bfb7-2ee79d554151,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-48b86c70-1d92-46fc-bc6a-610364bea97f,DISK], DatanodeInfoWithStorage[127.0.0.1:36369,DS-b50328ae-a4c5-427e-ba43-05e430837e65,DISK], DatanodeInfoWithStorage[127.0.0.1:34030,DS-88d88e0e-8dc6-4500-aaf6-bdfb56c34739,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-e69edbae-db4d-4f3c-858b-5ae785aa4258,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-1dd52cce-0171-41e2-aee0-4249e609dbb8,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-55f1a5e1-8cd8-4224-a36e-6b3ea893a61b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-70994335-172.17.0.9-1597491499110:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42255,DS-9d08a76f-36a6-403b-a8f8-d170f17a2317,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-6fa16f83-a26b-4990-a645-62ef5fbb398b,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-fa978131-b7d4-49ea-ba67-a8938e54f75b,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-b0778245-c1ce-4fa4-a2d7-fe0862aefa2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33695,DS-cd501e1e-a4d8-4bed-a201-e6278dcfdd92,DISK], DatanodeInfoWithStorage[127.0.0.1:41384,DS-38f3310e-02d0-405a-b796-d8ff5f51e042,DISK], DatanodeInfoWithStorage[127.0.0.1:35587,DS-fc29f822-d3f0-4df2-b19d-999fbbd45890,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-4df78cfd-4085-4ff3-ab30-75e5970cf5a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-70994335-172.17.0.9-1597491499110:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42255,DS-9d08a76f-36a6-403b-a8f8-d170f17a2317,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-6fa16f83-a26b-4990-a645-62ef5fbb398b,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-fa978131-b7d4-49ea-ba67-a8938e54f75b,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-b0778245-c1ce-4fa4-a2d7-fe0862aefa2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33695,DS-cd501e1e-a4d8-4bed-a201-e6278dcfdd92,DISK], DatanodeInfoWithStorage[127.0.0.1:41384,DS-38f3310e-02d0-405a-b796-d8ff5f51e042,DISK], DatanodeInfoWithStorage[127.0.0.1:35587,DS-fc29f822-d3f0-4df2-b19d-999fbbd45890,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-4df78cfd-4085-4ff3-ab30-75e5970cf5a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1412081462-172.17.0.9-1597491782100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44790,DS-3dd0c71f-2a26-4de7-8f9f-276b360c9a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39262,DS-d08095a4-59bc-4b89-bd63-f15155e6fda0,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-2b72a531-bd43-45e8-b81a-3d51cdd17714,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-a2a91e5e-ca27-47ac-8418-b46073719fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-c1440aa6-2460-48d3-b782-37583e338d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-3be2d3fc-9955-4aa6-8d39-28279e8c3efa,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-fd5b29d4-99f1-41e9-bd5d-4b84aecb8031,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-114e97fe-3556-492d-824a-d1e76a0947a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1412081462-172.17.0.9-1597491782100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44790,DS-3dd0c71f-2a26-4de7-8f9f-276b360c9a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39262,DS-d08095a4-59bc-4b89-bd63-f15155e6fda0,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-2b72a531-bd43-45e8-b81a-3d51cdd17714,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-a2a91e5e-ca27-47ac-8418-b46073719fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-c1440aa6-2460-48d3-b782-37583e338d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-3be2d3fc-9955-4aa6-8d39-28279e8c3efa,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-fd5b29d4-99f1-41e9-bd5d-4b84aecb8031,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-114e97fe-3556-492d-824a-d1e76a0947a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-780122700-172.17.0.9-1597491819827:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46852,DS-fb1dfaec-3267-40bb-9ccb-0a35e54d9019,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-972ac16c-5d04-4ec4-a82e-044e0ae33be5,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-a0cc0600-ddc1-47d3-a884-e7815547e4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-e57dd9fd-c77b-4939-8c01-8fe0d9756af9,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-4cf8743c-2a77-4d01-807a-da857654674a,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-a7ed1e53-3a80-4912-aac0-5ea20d687d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-5f7b5edb-7f2f-4448-ad3e-f9a8f07c1251,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-9968343b-0728-4dac-8de5-a848887bf661,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-780122700-172.17.0.9-1597491819827:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46852,DS-fb1dfaec-3267-40bb-9ccb-0a35e54d9019,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-972ac16c-5d04-4ec4-a82e-044e0ae33be5,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-a0cc0600-ddc1-47d3-a884-e7815547e4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-e57dd9fd-c77b-4939-8c01-8fe0d9756af9,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-4cf8743c-2a77-4d01-807a-da857654674a,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-a7ed1e53-3a80-4912-aac0-5ea20d687d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-5f7b5edb-7f2f-4448-ad3e-f9a8f07c1251,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-9968343b-0728-4dac-8de5-a848887bf661,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-261508584-172.17.0.9-1597491888726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43708,DS-c2f9a7cf-260f-48cc-a86c-a4a7ae921de0,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-8691e7bd-4e4e-44e0-a4d5-585c2d645b77,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-cee999a7-0108-4e50-934c-aa8d2634dc31,DISK], DatanodeInfoWithStorage[127.0.0.1:33620,DS-7edf9fbe-21ce-4592-948f-afd71b408610,DISK], DatanodeInfoWithStorage[127.0.0.1:44896,DS-e09305af-894b-42b1-beda-5aad6c786b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-448f48a9-f9f7-4265-b3ed-f3decb596537,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-539c940b-3de6-4b41-9f44-65e94484493b,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-bdac8610-7e0f-4296-baa8-ff1d8c685e2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-261508584-172.17.0.9-1597491888726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43708,DS-c2f9a7cf-260f-48cc-a86c-a4a7ae921de0,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-8691e7bd-4e4e-44e0-a4d5-585c2d645b77,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-cee999a7-0108-4e50-934c-aa8d2634dc31,DISK], DatanodeInfoWithStorage[127.0.0.1:33620,DS-7edf9fbe-21ce-4592-948f-afd71b408610,DISK], DatanodeInfoWithStorage[127.0.0.1:44896,DS-e09305af-894b-42b1-beda-5aad6c786b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-448f48a9-f9f7-4265-b3ed-f3decb596537,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-539c940b-3de6-4b41-9f44-65e94484493b,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-bdac8610-7e0f-4296-baa8-ff1d8c685e2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1163207571-172.17.0.9-1597492474485:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33897,DS-c0e9a9f8-0d5f-4f3d-a3bd-4d4693429b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40572,DS-4b36534f-4042-44bc-969b-3247d0ba2cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-743fce64-b8d2-4a43-a2d7-e371c2888d87,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-e246f1b8-68fe-42cb-a10a-9b16c7032918,DISK], DatanodeInfoWithStorage[127.0.0.1:35809,DS-4e5264a3-57b2-48f5-b6e3-e35b53233b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-9f94b0c7-15f2-4511-b8df-f4574a1a2dec,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-7a9bdacc-7c0a-4442-8efb-2dabe9539a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-658bfd19-1a0b-4e72-bded-74801bbeb80d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1163207571-172.17.0.9-1597492474485:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33897,DS-c0e9a9f8-0d5f-4f3d-a3bd-4d4693429b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40572,DS-4b36534f-4042-44bc-969b-3247d0ba2cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-743fce64-b8d2-4a43-a2d7-e371c2888d87,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-e246f1b8-68fe-42cb-a10a-9b16c7032918,DISK], DatanodeInfoWithStorage[127.0.0.1:35809,DS-4e5264a3-57b2-48f5-b6e3-e35b53233b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-9f94b0c7-15f2-4511-b8df-f4574a1a2dec,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-7a9bdacc-7c0a-4442-8efb-2dabe9539a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-658bfd19-1a0b-4e72-bded-74801bbeb80d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-905272875-172.17.0.9-1597493181587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36813,DS-c800062c-55db-4b52-b873-4d41f3db1fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:44668,DS-99a08f41-78bd-42ba-b037-52f5cc1da648,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-b24f878a-d640-46c3-b97d-b6b39a38b4af,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-238fcd7d-a7bc-45ce-8fd0-aa3d93728b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-cd2d9b58-4a0e-4e46-b244-7f71a05ff973,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-eeb91eca-b475-4f4a-8503-af7aeb900282,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-49558d9d-7aa9-47d3-aab1-68879f277803,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-b71ce555-a555-4fd7-828c-222e59a0c046,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-905272875-172.17.0.9-1597493181587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36813,DS-c800062c-55db-4b52-b873-4d41f3db1fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:44668,DS-99a08f41-78bd-42ba-b037-52f5cc1da648,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-b24f878a-d640-46c3-b97d-b6b39a38b4af,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-238fcd7d-a7bc-45ce-8fd0-aa3d93728b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-cd2d9b58-4a0e-4e46-b244-7f71a05ff973,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-eeb91eca-b475-4f4a-8503-af7aeb900282,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-49558d9d-7aa9-47d3-aab1-68879f277803,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-b71ce555-a555-4fd7-828c-222e59a0c046,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-90744019-172.17.0.9-1597494196452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42071,DS-8a4dd4f9-e4c1-4667-81bc-6f01df565c56,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-5cf3b08a-4e0c-433e-9920-a47d7fb3c72a,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-016f6667-49a3-4857-ad94-77c9377cf11d,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-cfa0caab-ecd6-4e33-943e-c54dc0641ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-941b6b39-4185-4f3a-a883-7d59f4d23cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:45652,DS-ef512d2b-b39e-48b3-b590-caf5d49fad63,DISK], DatanodeInfoWithStorage[127.0.0.1:34305,DS-5063be93-bb83-4f82-b20b-d996eac80e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-627b4e62-f695-41d3-8a97-53f95ad917d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-90744019-172.17.0.9-1597494196452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42071,DS-8a4dd4f9-e4c1-4667-81bc-6f01df565c56,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-5cf3b08a-4e0c-433e-9920-a47d7fb3c72a,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-016f6667-49a3-4857-ad94-77c9377cf11d,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-cfa0caab-ecd6-4e33-943e-c54dc0641ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-941b6b39-4185-4f3a-a883-7d59f4d23cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:45652,DS-ef512d2b-b39e-48b3-b590-caf5d49fad63,DISK], DatanodeInfoWithStorage[127.0.0.1:34305,DS-5063be93-bb83-4f82-b20b-d996eac80e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-627b4e62-f695-41d3-8a97-53f95ad917d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-544624777-172.17.0.9-1597494716251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37652,DS-f054b0a8-587d-4bdf-8904-045df97a7d85,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-c041df3e-25a8-40cc-9421-847e94b77fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-2ba9e12b-caed-4f8a-8f9d-6812a3c62b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-cd1caa57-8aba-4c3f-947e-633a07893682,DISK], DatanodeInfoWithStorage[127.0.0.1:43080,DS-4be390a5-9a7b-4a70-b36e-79c019cdf5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-c66ad092-e80a-4eb5-81f3-96e863160590,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-5557d409-380d-4117-be40-f146776bcf58,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-77345fbd-5b37-4ec0-86ec-2de004a242c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-544624777-172.17.0.9-1597494716251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37652,DS-f054b0a8-587d-4bdf-8904-045df97a7d85,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-c041df3e-25a8-40cc-9421-847e94b77fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-2ba9e12b-caed-4f8a-8f9d-6812a3c62b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-cd1caa57-8aba-4c3f-947e-633a07893682,DISK], DatanodeInfoWithStorage[127.0.0.1:43080,DS-4be390a5-9a7b-4a70-b36e-79c019cdf5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-c66ad092-e80a-4eb5-81f3-96e863160590,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-5557d409-380d-4117-be40-f146776bcf58,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-77345fbd-5b37-4ec0-86ec-2de004a242c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-228383818-172.17.0.9-1597494783599:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44796,DS-35dc131d-31dc-41b6-83a1-f4b2184a2e60,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-964f53f9-0a09-4421-b5cb-2a3a1d07103d,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-9a19b8ca-2c84-44ba-ba0e-7bf684c17625,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-4026fa5b-fffb-42c5-b6a8-d2d036a71230,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-2986c410-a479-42fa-8c35-540bf3d055cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-d81716c4-258d-4d5f-9634-a24010a9c54a,DISK], DatanodeInfoWithStorage[127.0.0.1:36040,DS-07b79afd-0538-49de-96f9-b302c0c91cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:38589,DS-92369e13-52e2-4750-815a-11235d2506b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-228383818-172.17.0.9-1597494783599:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44796,DS-35dc131d-31dc-41b6-83a1-f4b2184a2e60,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-964f53f9-0a09-4421-b5cb-2a3a1d07103d,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-9a19b8ca-2c84-44ba-ba0e-7bf684c17625,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-4026fa5b-fffb-42c5-b6a8-d2d036a71230,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-2986c410-a479-42fa-8c35-540bf3d055cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-d81716c4-258d-4d5f-9634-a24010a9c54a,DISK], DatanodeInfoWithStorage[127.0.0.1:36040,DS-07b79afd-0538-49de-96f9-b302c0c91cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:38589,DS-92369e13-52e2-4750-815a-11235d2506b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-202867181-172.17.0.9-1597495164011:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44531,DS-9af2457a-c825-4456-99bf-fdc2651d5201,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-81498c83-bd79-43cf-a25d-5433ffa32769,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-38010122-8929-45e7-93eb-335d918749d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-05005b11-3322-4919-90c3-a5493bf5da99,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-4df9723b-8da7-4a12-bab4-c5553024bb61,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-e3835a16-6825-476e-b7db-6bd3a9aaa559,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-e21c615f-6cc2-4768-b3bd-e81f341b92df,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-46b6b9b5-8b7b-4424-8df5-623676d8a5b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-202867181-172.17.0.9-1597495164011:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44531,DS-9af2457a-c825-4456-99bf-fdc2651d5201,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-81498c83-bd79-43cf-a25d-5433ffa32769,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-38010122-8929-45e7-93eb-335d918749d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-05005b11-3322-4919-90c3-a5493bf5da99,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-4df9723b-8da7-4a12-bab4-c5553024bb61,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-e3835a16-6825-476e-b7db-6bd3a9aaa559,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-e21c615f-6cc2-4768-b3bd-e81f341b92df,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-46b6b9b5-8b7b-4424-8df5-623676d8a5b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5254
