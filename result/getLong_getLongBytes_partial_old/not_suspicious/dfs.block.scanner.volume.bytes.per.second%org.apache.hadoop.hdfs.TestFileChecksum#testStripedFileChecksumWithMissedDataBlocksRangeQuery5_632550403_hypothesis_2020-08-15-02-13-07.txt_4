reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-552899023-172.17.0.19-1597457601828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42680,DS-e0696751-f297-48a4-8d5a-f897748946af,DISK], DatanodeInfoWithStorage[127.0.0.1:38191,DS-612072a5-14f9-4745-a98c-240a02964968,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-da74222b-3669-4086-ba2c-4e4da90c25cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-63561df0-82b2-49c4-8e7a-34c62c96a361,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-c3904909-7039-41eb-b5d9-94f069600532,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-56cc1f1a-9fe7-45ea-b6d2-12177cc12be3,DISK], DatanodeInfoWithStorage[127.0.0.1:43600,DS-accd369a-16e3-480f-99c5-ffa057dc0b29,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-5919e36f-f8ce-4959-bf9c-3f4bafe3c031,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-552899023-172.17.0.19-1597457601828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42680,DS-e0696751-f297-48a4-8d5a-f897748946af,DISK], DatanodeInfoWithStorage[127.0.0.1:38191,DS-612072a5-14f9-4745-a98c-240a02964968,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-da74222b-3669-4086-ba2c-4e4da90c25cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-63561df0-82b2-49c4-8e7a-34c62c96a361,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-c3904909-7039-41eb-b5d9-94f069600532,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-56cc1f1a-9fe7-45ea-b6d2-12177cc12be3,DISK], DatanodeInfoWithStorage[127.0.0.1:43600,DS-accd369a-16e3-480f-99c5-ffa057dc0b29,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-5919e36f-f8ce-4959-bf9c-3f4bafe3c031,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-262591421-172.17.0.19-1597457827039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45255,DS-a2f885ea-2110-4a13-ba78-2f516c574dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-6e2fa4f5-d1d3-4314-a28a-a25059008723,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-deadec96-7c13-4c3f-9301-aa89cb52e1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-97cb30ee-6bab-4272-974a-880ce74fdc80,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-0afdec97-503a-48bc-b019-dae3e51feb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-3045fbaa-3063-47b5-98e8-4acad577acee,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-5ba1156f-000c-4dbc-a619-a1739d8f716e,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-f434988c-9bf6-4d6a-ae50-631f0c98a16b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-262591421-172.17.0.19-1597457827039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45255,DS-a2f885ea-2110-4a13-ba78-2f516c574dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-6e2fa4f5-d1d3-4314-a28a-a25059008723,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-deadec96-7c13-4c3f-9301-aa89cb52e1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-97cb30ee-6bab-4272-974a-880ce74fdc80,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-0afdec97-503a-48bc-b019-dae3e51feb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-3045fbaa-3063-47b5-98e8-4acad577acee,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-5ba1156f-000c-4dbc-a619-a1739d8f716e,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-f434988c-9bf6-4d6a-ae50-631f0c98a16b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1063740042-172.17.0.19-1597458097832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36718,DS-3b7aa802-a7d2-4988-bf66-c5c37d52541d,DISK], DatanodeInfoWithStorage[127.0.0.1:38468,DS-8f424360-7a00-4c1a-a2fe-2e9e0696a4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-b2f02b4e-4767-4ea8-98bd-2c8b73ab0711,DISK], DatanodeInfoWithStorage[127.0.0.1:42269,DS-d3776e96-377d-4e62-9045-df3481f68bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-fd351b41-8163-475e-b8d4-e579d3c70aca,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-e095c64c-06c8-4a7a-ab14-21a36ed209c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-91bd1995-ba8f-4269-980b-5910f4732bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:42711,DS-4559ef6c-1c0f-4f59-94a1-3572ce030c8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1063740042-172.17.0.19-1597458097832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36718,DS-3b7aa802-a7d2-4988-bf66-c5c37d52541d,DISK], DatanodeInfoWithStorage[127.0.0.1:38468,DS-8f424360-7a00-4c1a-a2fe-2e9e0696a4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-b2f02b4e-4767-4ea8-98bd-2c8b73ab0711,DISK], DatanodeInfoWithStorage[127.0.0.1:42269,DS-d3776e96-377d-4e62-9045-df3481f68bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-fd351b41-8163-475e-b8d4-e579d3c70aca,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-e095c64c-06c8-4a7a-ab14-21a36ed209c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-91bd1995-ba8f-4269-980b-5910f4732bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:42711,DS-4559ef6c-1c0f-4f59-94a1-3572ce030c8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1585420280-172.17.0.19-1597458220718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34072,DS-2b5f74d5-a00d-4491-ae2a-2b5431262b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-ae9d6dca-c593-41b2-a73e-7fb3252f3767,DISK], DatanodeInfoWithStorage[127.0.0.1:39170,DS-93c02f94-8947-4cae-a746-7eb71eeb8ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-008089df-ad0b-4d2b-80fe-956a7975fd70,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-b64de223-8864-4194-b57b-388dcc48e7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-1f6639e4-8cd5-40c3-a7fb-f89966e209fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-d62d6402-0408-41d5-9934-b4fa74e28c70,DISK], DatanodeInfoWithStorage[127.0.0.1:38126,DS-fa60918d-c983-4767-81ef-a48c31726df6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1585420280-172.17.0.19-1597458220718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34072,DS-2b5f74d5-a00d-4491-ae2a-2b5431262b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-ae9d6dca-c593-41b2-a73e-7fb3252f3767,DISK], DatanodeInfoWithStorage[127.0.0.1:39170,DS-93c02f94-8947-4cae-a746-7eb71eeb8ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-008089df-ad0b-4d2b-80fe-956a7975fd70,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-b64de223-8864-4194-b57b-388dcc48e7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-1f6639e4-8cd5-40c3-a7fb-f89966e209fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-d62d6402-0408-41d5-9934-b4fa74e28c70,DISK], DatanodeInfoWithStorage[127.0.0.1:38126,DS-fa60918d-c983-4767-81ef-a48c31726df6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1770251677-172.17.0.19-1597458259142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39065,DS-fd9066bb-fc8f-4398-a538-c9e743e89f78,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-745a644a-cf0f-4193-8f5c-3e0b6741a403,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-08dffb71-3e92-4919-9327-9afd7e93690a,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-f3db3008-adb5-4b08-bdbb-617b0aa7a8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-734ae3ff-a4a6-4183-afd4-f9f6b631ae65,DISK], DatanodeInfoWithStorage[127.0.0.1:46482,DS-8e697e4f-40bc-41f4-a193-51b73db5b238,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-65a34007-0963-42ed-8e26-e373205a1023,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-40fd679d-1f3b-437c-ac1b-34df1031ac3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1770251677-172.17.0.19-1597458259142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39065,DS-fd9066bb-fc8f-4398-a538-c9e743e89f78,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-745a644a-cf0f-4193-8f5c-3e0b6741a403,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-08dffb71-3e92-4919-9327-9afd7e93690a,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-f3db3008-adb5-4b08-bdbb-617b0aa7a8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-734ae3ff-a4a6-4183-afd4-f9f6b631ae65,DISK], DatanodeInfoWithStorage[127.0.0.1:46482,DS-8e697e4f-40bc-41f4-a193-51b73db5b238,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-65a34007-0963-42ed-8e26-e373205a1023,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-40fd679d-1f3b-437c-ac1b-34df1031ac3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1489089730-172.17.0.19-1597459189442:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36536,DS-bac63cd2-d199-49a6-a7e3-f70ce26e213b,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-d865b2ad-d790-452b-9387-304fa48f81a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35622,DS-1f7b991d-9f0e-4d26-a423-5160fcae8ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:42361,DS-f54e23b8-8d42-4af0-9ffd-b1e9e5234d75,DISK], DatanodeInfoWithStorage[127.0.0.1:45585,DS-33d7e693-4971-47d4-94b0-8fa559e85328,DISK], DatanodeInfoWithStorage[127.0.0.1:43291,DS-b0e6669e-4489-4ad4-bcae-9d6d4a188b30,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-a410e8fa-cbf0-4788-aabf-b0167e9fcd85,DISK], DatanodeInfoWithStorage[127.0.0.1:33043,DS-bc632934-9618-4066-8b4d-47ba00001fcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1489089730-172.17.0.19-1597459189442:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36536,DS-bac63cd2-d199-49a6-a7e3-f70ce26e213b,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-d865b2ad-d790-452b-9387-304fa48f81a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35622,DS-1f7b991d-9f0e-4d26-a423-5160fcae8ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:42361,DS-f54e23b8-8d42-4af0-9ffd-b1e9e5234d75,DISK], DatanodeInfoWithStorage[127.0.0.1:45585,DS-33d7e693-4971-47d4-94b0-8fa559e85328,DISK], DatanodeInfoWithStorage[127.0.0.1:43291,DS-b0e6669e-4489-4ad4-bcae-9d6d4a188b30,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-a410e8fa-cbf0-4788-aabf-b0167e9fcd85,DISK], DatanodeInfoWithStorage[127.0.0.1:33043,DS-bc632934-9618-4066-8b4d-47ba00001fcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-843554815-172.17.0.19-1597459223809:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42943,DS-ef2b9f01-b47f-40e1-a2c7-f28f9dc5e259,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-1012c8b0-9a60-428b-a551-472d1dd3abe8,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-0c8e8a52-10e8-40f6-ae7b-779f2177261d,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-a225c5c9-f82e-43b8-a7a1-1d1fc61699e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-1043a8e9-99c1-4a49-bc40-26f287b27c51,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-38add638-48ba-456f-88d2-b7483fb4fccf,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-00b290ba-9c74-4e37-b111-ebc0070e0392,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-6c46b9c6-83a4-4939-b233-cd36052a105a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-843554815-172.17.0.19-1597459223809:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42943,DS-ef2b9f01-b47f-40e1-a2c7-f28f9dc5e259,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-1012c8b0-9a60-428b-a551-472d1dd3abe8,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-0c8e8a52-10e8-40f6-ae7b-779f2177261d,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-a225c5c9-f82e-43b8-a7a1-1d1fc61699e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-1043a8e9-99c1-4a49-bc40-26f287b27c51,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-38add638-48ba-456f-88d2-b7483fb4fccf,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-00b290ba-9c74-4e37-b111-ebc0070e0392,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-6c46b9c6-83a4-4939-b233-cd36052a105a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1237700881-172.17.0.19-1597459665129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33795,DS-594b864b-74b7-40ac-91c3-1b5aa4a1f90d,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-06346863-3aa8-455c-a11c-61beacc1ac30,DISK], DatanodeInfoWithStorage[127.0.0.1:38886,DS-af9d094b-e58b-496a-8719-dcb738bbea76,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-af19d46c-4adc-48f2-91af-667317997917,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-d900b27d-20f9-44e1-aa66-9f9d8d418b04,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-e05c3bd5-262a-49bc-9c8d-a18c75cc0e65,DISK], DatanodeInfoWithStorage[127.0.0.1:41485,DS-b9738a6d-274d-43a0-b9ef-68620a94e708,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-f372c805-5301-42ce-a524-d2de551e2985,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1237700881-172.17.0.19-1597459665129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33795,DS-594b864b-74b7-40ac-91c3-1b5aa4a1f90d,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-06346863-3aa8-455c-a11c-61beacc1ac30,DISK], DatanodeInfoWithStorage[127.0.0.1:38886,DS-af9d094b-e58b-496a-8719-dcb738bbea76,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-af19d46c-4adc-48f2-91af-667317997917,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-d900b27d-20f9-44e1-aa66-9f9d8d418b04,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-e05c3bd5-262a-49bc-9c8d-a18c75cc0e65,DISK], DatanodeInfoWithStorage[127.0.0.1:41485,DS-b9738a6d-274d-43a0-b9ef-68620a94e708,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-f372c805-5301-42ce-a524-d2de551e2985,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2130127049-172.17.0.19-1597460267435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40270,DS-fb7e24ec-dee9-41be-95e5-b5e4790a7006,DISK], DatanodeInfoWithStorage[127.0.0.1:44638,DS-196d3309-eeb9-4b1f-a1b6-d9dc0e395154,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-a91a4594-9eff-4887-b12c-522aca8491e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-e8922ba1-a36c-4adc-9d44-ae205a782639,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-8461f027-a7e3-4f8e-8224-87a0ea23398a,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-b400e526-a223-4a17-b170-1b08d94c19bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-e55e9ae5-60d1-4f91-931b-921c2850b623,DISK], DatanodeInfoWithStorage[127.0.0.1:33944,DS-a6188a84-67b1-4117-8358-ffb4d67b45bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2130127049-172.17.0.19-1597460267435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40270,DS-fb7e24ec-dee9-41be-95e5-b5e4790a7006,DISK], DatanodeInfoWithStorage[127.0.0.1:44638,DS-196d3309-eeb9-4b1f-a1b6-d9dc0e395154,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-a91a4594-9eff-4887-b12c-522aca8491e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-e8922ba1-a36c-4adc-9d44-ae205a782639,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-8461f027-a7e3-4f8e-8224-87a0ea23398a,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-b400e526-a223-4a17-b170-1b08d94c19bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-e55e9ae5-60d1-4f91-931b-921c2850b623,DISK], DatanodeInfoWithStorage[127.0.0.1:33944,DS-a6188a84-67b1-4117-8358-ffb4d67b45bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-372251965-172.17.0.19-1597460431470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46469,DS-94d500cd-423d-4160-b5b9-e00f76fafae6,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-e23cef22-0554-47ad-8c40-22c467cb558e,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-9a750f44-57f9-46cf-840a-9bd7e7e90bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-490e7b2a-70db-4302-bb99-640b5e18a062,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-73354a35-2219-42b9-8477-ea80e46b27f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-21aa686d-fb09-4a3d-978e-483a3757a545,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-1e8919d0-7edb-4c57-bd44-5bc991d13f31,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-c532e642-0c39-484a-b174-71797e6b9c47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-372251965-172.17.0.19-1597460431470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46469,DS-94d500cd-423d-4160-b5b9-e00f76fafae6,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-e23cef22-0554-47ad-8c40-22c467cb558e,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-9a750f44-57f9-46cf-840a-9bd7e7e90bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-490e7b2a-70db-4302-bb99-640b5e18a062,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-73354a35-2219-42b9-8477-ea80e46b27f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-21aa686d-fb09-4a3d-978e-483a3757a545,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-1e8919d0-7edb-4c57-bd44-5bc991d13f31,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-c532e642-0c39-484a-b174-71797e6b9c47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-300278758-172.17.0.19-1597460855681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45231,DS-f47c063e-f559-495c-afcb-7a81ebcf40d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-3d9baa6c-7c39-4a86-82d2-87d65c25fae2,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-05f55d8a-276e-406b-af2e-163b014d2cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-2018caa6-26f7-4557-927a-057db1a60059,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-55210995-41d0-4ed4-b166-d5576447aaa6,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-8afc9d40-4c74-4385-84a8-3b2cd16032d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-016a30f2-75ab-4eeb-8c4d-d0dd2f601bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:37394,DS-7951589d-696a-434b-ba66-b9b79b4ddc62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-300278758-172.17.0.19-1597460855681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45231,DS-f47c063e-f559-495c-afcb-7a81ebcf40d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-3d9baa6c-7c39-4a86-82d2-87d65c25fae2,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-05f55d8a-276e-406b-af2e-163b014d2cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-2018caa6-26f7-4557-927a-057db1a60059,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-55210995-41d0-4ed4-b166-d5576447aaa6,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-8afc9d40-4c74-4385-84a8-3b2cd16032d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-016a30f2-75ab-4eeb-8c4d-d0dd2f601bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:37394,DS-7951589d-696a-434b-ba66-b9b79b4ddc62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980604739-172.17.0.19-1597461049046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35830,DS-aed14f1a-52c5-416e-961f-9e26b1e11fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-b1481c79-6528-4506-9828-a8fdafaabe90,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-0d63d507-621b-444c-8db7-f509a9296ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-d9efc553-2e9b-4236-b2e3-18edc41197b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-4a494c21-5410-483c-ad6d-3b4c9f552751,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-e0920fe2-6d34-42ee-87c5-9776510a8f81,DISK], DatanodeInfoWithStorage[127.0.0.1:37608,DS-f45ec079-2ee5-434c-94e0-499f6966a54a,DISK], DatanodeInfoWithStorage[127.0.0.1:40102,DS-60f536b0-27b8-4990-987e-de36e455f138,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980604739-172.17.0.19-1597461049046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35830,DS-aed14f1a-52c5-416e-961f-9e26b1e11fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-b1481c79-6528-4506-9828-a8fdafaabe90,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-0d63d507-621b-444c-8db7-f509a9296ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-d9efc553-2e9b-4236-b2e3-18edc41197b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-4a494c21-5410-483c-ad6d-3b4c9f552751,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-e0920fe2-6d34-42ee-87c5-9776510a8f81,DISK], DatanodeInfoWithStorage[127.0.0.1:37608,DS-f45ec079-2ee5-434c-94e0-499f6966a54a,DISK], DatanodeInfoWithStorage[127.0.0.1:40102,DS-60f536b0-27b8-4990-987e-de36e455f138,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1941042174-172.17.0.19-1597461135830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43437,DS-a2d768c3-2ad5-4d7d-8ce6-2c7c286acd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46309,DS-d5a2f2fd-4e79-4b5f-a730-cffc43e00b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41558,DS-84d42afe-cae2-4aaf-a26d-cea5041914db,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-6861e0ff-7e88-4bd1-bc2a-aed4cf914ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-3aed9d5b-8b36-4b2c-b151-8445435f5b40,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-cd4ddf24-f095-4bba-9dc9-cc9f1c126eef,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-97b99a50-b4f2-4c47-b5ef-9c30b7e09b25,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-0945ce03-f587-471b-80bf-e3838f587731,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1941042174-172.17.0.19-1597461135830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43437,DS-a2d768c3-2ad5-4d7d-8ce6-2c7c286acd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46309,DS-d5a2f2fd-4e79-4b5f-a730-cffc43e00b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41558,DS-84d42afe-cae2-4aaf-a26d-cea5041914db,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-6861e0ff-7e88-4bd1-bc2a-aed4cf914ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-3aed9d5b-8b36-4b2c-b151-8445435f5b40,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-cd4ddf24-f095-4bba-9dc9-cc9f1c126eef,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-97b99a50-b4f2-4c47-b5ef-9c30b7e09b25,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-0945ce03-f587-471b-80bf-e3838f587731,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-645381111-172.17.0.19-1597461556591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36060,DS-f0585f3f-a13b-43d6-a9e4-3b7ed896d5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-4fde16f6-448b-4397-afa6-d21c64c42031,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-de6990a6-e963-4974-8f7c-4dacaad88991,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-7b211d8a-1f87-4717-bbef-95f49ed607c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-d20e5bff-dff1-4104-b4ba-b2a2462c96ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-56ad7797-e09c-4312-8405-84420497f965,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-bccde13d-664c-47f1-a3de-3aab3ec9368b,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-fe55fe56-5171-48ca-adf3-da0e6fbb97ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-645381111-172.17.0.19-1597461556591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36060,DS-f0585f3f-a13b-43d6-a9e4-3b7ed896d5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-4fde16f6-448b-4397-afa6-d21c64c42031,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-de6990a6-e963-4974-8f7c-4dacaad88991,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-7b211d8a-1f87-4717-bbef-95f49ed607c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-d20e5bff-dff1-4104-b4ba-b2a2462c96ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-56ad7797-e09c-4312-8405-84420497f965,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-bccde13d-664c-47f1-a3de-3aab3ec9368b,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-fe55fe56-5171-48ca-adf3-da0e6fbb97ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-822982988-172.17.0.19-1597462155548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37265,DS-8ed103b0-5c05-4c64-9dd2-646efbec033d,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-680f201f-5ebd-4181-8797-c1fa8c4adc1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-309c8a22-3f3a-4388-8e7b-e944afea7514,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-d6a7745f-7a5d-4575-9881-ce8ce59811af,DISK], DatanodeInfoWithStorage[127.0.0.1:44597,DS-2e486299-53c8-45d2-8e32-dadead703211,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-6cc4dc22-4770-474c-987b-c534d6720c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41451,DS-441b22f1-6a4c-443c-b7db-c8d5e71f7373,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-c105dfd5-eac7-49dd-8fb6-03d44320e90c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-822982988-172.17.0.19-1597462155548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37265,DS-8ed103b0-5c05-4c64-9dd2-646efbec033d,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-680f201f-5ebd-4181-8797-c1fa8c4adc1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-309c8a22-3f3a-4388-8e7b-e944afea7514,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-d6a7745f-7a5d-4575-9881-ce8ce59811af,DISK], DatanodeInfoWithStorage[127.0.0.1:44597,DS-2e486299-53c8-45d2-8e32-dadead703211,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-6cc4dc22-4770-474c-987b-c534d6720c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41451,DS-441b22f1-6a4c-443c-b7db-c8d5e71f7373,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-c105dfd5-eac7-49dd-8fb6-03d44320e90c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2078769492-172.17.0.19-1597462516796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39292,DS-f827661f-8f17-415b-8a4e-f659d4c98a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-68b5e63a-7cee-4967-a431-7865e10ae69e,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-8e478b2f-01b8-4b5b-b548-9b4a19b9cd17,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-85201e03-eb29-4658-b7ad-fa08f50382cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38323,DS-04231aa8-102b-4ccb-967c-9531146dbc36,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-6aa1e0a1-f123-4b43-b2c8-a776867cd222,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-8551e08e-5451-4d42-9b09-0b0204a66660,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-40969bea-b228-490a-a697-500aa554be45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2078769492-172.17.0.19-1597462516796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39292,DS-f827661f-8f17-415b-8a4e-f659d4c98a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-68b5e63a-7cee-4967-a431-7865e10ae69e,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-8e478b2f-01b8-4b5b-b548-9b4a19b9cd17,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-85201e03-eb29-4658-b7ad-fa08f50382cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38323,DS-04231aa8-102b-4ccb-967c-9531146dbc36,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-6aa1e0a1-f123-4b43-b2c8-a776867cd222,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-8551e08e-5451-4d42-9b09-0b0204a66660,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-40969bea-b228-490a-a697-500aa554be45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1404476037-172.17.0.19-1597462556617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40225,DS-1e427fd7-d7ea-4253-810e-8765e644efeb,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-42bdc9e7-1d76-4013-b812-3b01148244e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-d1486657-f627-4512-ad19-e0d524e65a97,DISK], DatanodeInfoWithStorage[127.0.0.1:46789,DS-016438c4-656b-43f6-96b7-68eb01f05555,DISK], DatanodeInfoWithStorage[127.0.0.1:39174,DS-8ce67d9b-c14c-4c78-96df-ed7b2c61ca4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36635,DS-0dee3c60-f81b-44a8-91f6-25671abc2339,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-958822ba-c3bd-4d4a-8111-428cef28c0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-ea8984e1-7c55-4ebd-92e3-a1bde563f156,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1404476037-172.17.0.19-1597462556617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40225,DS-1e427fd7-d7ea-4253-810e-8765e644efeb,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-42bdc9e7-1d76-4013-b812-3b01148244e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-d1486657-f627-4512-ad19-e0d524e65a97,DISK], DatanodeInfoWithStorage[127.0.0.1:46789,DS-016438c4-656b-43f6-96b7-68eb01f05555,DISK], DatanodeInfoWithStorage[127.0.0.1:39174,DS-8ce67d9b-c14c-4c78-96df-ed7b2c61ca4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36635,DS-0dee3c60-f81b-44a8-91f6-25671abc2339,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-958822ba-c3bd-4d4a-8111-428cef28c0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-ea8984e1-7c55-4ebd-92e3-a1bde563f156,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-85855726-172.17.0.19-1597462654495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37512,DS-a29f259d-b39a-4d3b-9d6a-469a1a309620,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-85542756-743a-4fe2-83fc-c81f93c308eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-006050b8-21a3-4954-84ae-093c61258b83,DISK], DatanodeInfoWithStorage[127.0.0.1:46861,DS-b9bd2e53-cdee-43fb-a03f-feeb89b82c09,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-4a3d6618-bc76-4c6d-9f63-1050bf2d097a,DISK], DatanodeInfoWithStorage[127.0.0.1:34498,DS-4f9ff244-ed62-4e79-9422-837f9d066beb,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-87584542-d759-4f88-af84-db865b51802c,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-2840b5a1-4591-4314-a48a-aeb05588ed69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-85855726-172.17.0.19-1597462654495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37512,DS-a29f259d-b39a-4d3b-9d6a-469a1a309620,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-85542756-743a-4fe2-83fc-c81f93c308eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-006050b8-21a3-4954-84ae-093c61258b83,DISK], DatanodeInfoWithStorage[127.0.0.1:46861,DS-b9bd2e53-cdee-43fb-a03f-feeb89b82c09,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-4a3d6618-bc76-4c6d-9f63-1050bf2d097a,DISK], DatanodeInfoWithStorage[127.0.0.1:34498,DS-4f9ff244-ed62-4e79-9422-837f9d066beb,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-87584542-d759-4f88-af84-db865b51802c,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-2840b5a1-4591-4314-a48a-aeb05588ed69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5903
