reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-550194584-172.17.0.21-1597347103127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45021,DS-30b55da6-18e8-42ef-8215-bad50efcec3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-91ef7e4b-e31a-4ee9-bb2c-0a569347d0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-54eaf415-bf49-4deb-9d74-fdd5c06cdbff,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-496ad631-77fb-4bbd-bc16-6e877dacab8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-010befa5-1d69-43e3-a70c-6befda49d2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-42ee398c-a8b3-417a-bbe6-a45d2c64ddbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-2be02eeb-a46b-4fc7-bd0f-1a45c53fee96,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-a8338917-bdb9-4064-b2a1-cf51d5a1c431,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-550194584-172.17.0.21-1597347103127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45021,DS-30b55da6-18e8-42ef-8215-bad50efcec3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-91ef7e4b-e31a-4ee9-bb2c-0a569347d0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-54eaf415-bf49-4deb-9d74-fdd5c06cdbff,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-496ad631-77fb-4bbd-bc16-6e877dacab8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-010befa5-1d69-43e3-a70c-6befda49d2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-42ee398c-a8b3-417a-bbe6-a45d2c64ddbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-2be02eeb-a46b-4fc7-bd0f-1a45c53fee96,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-a8338917-bdb9-4064-b2a1-cf51d5a1c431,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-991612930-172.17.0.21-1597347463351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38203,DS-b4abc7d9-4545-4636-bf2c-c83021bbf074,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-97a9c72d-f56e-4c4f-8e50-e5c9268c56ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-fe8cf5bf-f59b-484b-998d-eab3c460babc,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-3c01586b-073e-48b2-82ca-4512d6272c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33695,DS-55d6f1fc-5f0b-4ab8-9a8d-35d5c53cbeeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44794,DS-72f3d914-4475-4560-b2fe-a713983dddbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-dd1e649f-90d7-4c76-9ee6-81b3572f3245,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-faac659b-28e4-4064-9011-6f3b33ac6851,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-991612930-172.17.0.21-1597347463351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38203,DS-b4abc7d9-4545-4636-bf2c-c83021bbf074,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-97a9c72d-f56e-4c4f-8e50-e5c9268c56ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-fe8cf5bf-f59b-484b-998d-eab3c460babc,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-3c01586b-073e-48b2-82ca-4512d6272c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33695,DS-55d6f1fc-5f0b-4ab8-9a8d-35d5c53cbeeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44794,DS-72f3d914-4475-4560-b2fe-a713983dddbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-dd1e649f-90d7-4c76-9ee6-81b3572f3245,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-faac659b-28e4-4064-9011-6f3b33ac6851,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1212372887-172.17.0.21-1597347639168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41585,DS-5b6ae503-afe6-430f-918c-e005ae0c0fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-0a35c5f4-cb8d-4e7e-9fe3-b87850a65c58,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-d925e854-4944-4f2c-8ffc-88715d9c50a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-02b5e37f-e0c7-4ec1-ad7b-7c3a907d80ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-8e149776-5f51-4dd0-aa49-6082c57d9ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-0e5ac08e-21fc-4f00-8cc8-77bf748c0b18,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-f9c0db06-120a-45fe-92f0-a8a9a98c82cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-0a283279-015e-43b0-8148-12596fb3c7af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1212372887-172.17.0.21-1597347639168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41585,DS-5b6ae503-afe6-430f-918c-e005ae0c0fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-0a35c5f4-cb8d-4e7e-9fe3-b87850a65c58,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-d925e854-4944-4f2c-8ffc-88715d9c50a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-02b5e37f-e0c7-4ec1-ad7b-7c3a907d80ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-8e149776-5f51-4dd0-aa49-6082c57d9ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-0e5ac08e-21fc-4f00-8cc8-77bf748c0b18,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-f9c0db06-120a-45fe-92f0-a8a9a98c82cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-0a283279-015e-43b0-8148-12596fb3c7af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980406291-172.17.0.21-1597348260418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45964,DS-c41d0c3e-df8d-43b3-9b69-6373300e76b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-34dfe2be-2141-4e8e-8ec0-aa474703e0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-1aef4501-d8de-4736-be8e-aa9198dd6de2,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-20b664ce-3ad1-43c3-abcb-d0ee3ad661f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33129,DS-cb4c3b67-d436-42ec-a850-96700862db3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-fb39df3c-0c1a-449a-b6cb-8b8c69a20aee,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-f8c58a38-099a-430a-9cc2-707c2d78df93,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-5551bc46-e8bb-4589-9969-2731df1b3211,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980406291-172.17.0.21-1597348260418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45964,DS-c41d0c3e-df8d-43b3-9b69-6373300e76b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-34dfe2be-2141-4e8e-8ec0-aa474703e0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-1aef4501-d8de-4736-be8e-aa9198dd6de2,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-20b664ce-3ad1-43c3-abcb-d0ee3ad661f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33129,DS-cb4c3b67-d436-42ec-a850-96700862db3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-fb39df3c-0c1a-449a-b6cb-8b8c69a20aee,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-f8c58a38-099a-430a-9cc2-707c2d78df93,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-5551bc46-e8bb-4589-9969-2731df1b3211,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1911439611-172.17.0.21-1597348737645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37139,DS-49be5e3f-8505-4e5f-9e95-241ccb82b59d,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-3ec990f6-70ca-479e-af06-6892b9af7587,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-8e6b12d2-43ba-4114-90d3-0ed3d7854f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-9ab7e306-eea0-4e7f-8933-917637577016,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-10433fb3-65a0-4567-8178-f7884159972d,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-4f43286c-1e6e-4bb8-a636-6be3c892bead,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-f2501ddd-7dab-433a-a18a-7558837afd41,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-f9aeef5c-08e6-4838-87fb-7e52d0292df6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1911439611-172.17.0.21-1597348737645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37139,DS-49be5e3f-8505-4e5f-9e95-241ccb82b59d,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-3ec990f6-70ca-479e-af06-6892b9af7587,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-8e6b12d2-43ba-4114-90d3-0ed3d7854f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-9ab7e306-eea0-4e7f-8933-917637577016,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-10433fb3-65a0-4567-8178-f7884159972d,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-4f43286c-1e6e-4bb8-a636-6be3c892bead,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-f2501ddd-7dab-433a-a18a-7558837afd41,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-f9aeef5c-08e6-4838-87fb-7e52d0292df6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-149803000-172.17.0.21-1597348836150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36735,DS-c2f181a0-d4a0-49a7-85ed-e14dc05f731f,DISK], DatanodeInfoWithStorage[127.0.0.1:43690,DS-313cd9a8-b804-4478-a263-a0672e7dafc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-568173ec-7eab-4a36-a5f1-e64651f55c99,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-1fd5bdcc-c638-42fa-99e9-9652fb93181f,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-f622dafd-5149-40f1-a30f-060c04933630,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-a69dbbc5-1db6-4fb5-9891-63712c478f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-5b540e8f-8799-4808-8679-d67180a642c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-a7e4cd48-fc47-4469-82b6-1031586e2cd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-149803000-172.17.0.21-1597348836150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36735,DS-c2f181a0-d4a0-49a7-85ed-e14dc05f731f,DISK], DatanodeInfoWithStorage[127.0.0.1:43690,DS-313cd9a8-b804-4478-a263-a0672e7dafc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-568173ec-7eab-4a36-a5f1-e64651f55c99,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-1fd5bdcc-c638-42fa-99e9-9652fb93181f,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-f622dafd-5149-40f1-a30f-060c04933630,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-a69dbbc5-1db6-4fb5-9891-63712c478f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-5b540e8f-8799-4808-8679-d67180a642c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-a7e4cd48-fc47-4469-82b6-1031586e2cd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1599106151-172.17.0.21-1597349100043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42013,DS-fe7c1431-d1d1-4d95-81c5-902f76401362,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-a26e803f-c447-41c9-8ed1-b96f1da4a8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43783,DS-b4c68dce-2ecb-44c7-a5b5-752029cc36d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-44e1cb40-6e68-446a-b1af-25cf813ac5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33006,DS-c40da48a-52ac-4b40-aaf7-8be5c485ae97,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-a7ac0389-711e-43c6-b67d-7f3cceb705ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40022,DS-064edfb8-4090-4215-aba7-546de3a69df5,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-2d583789-9c44-4d24-aedb-a5b09df71e5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1599106151-172.17.0.21-1597349100043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42013,DS-fe7c1431-d1d1-4d95-81c5-902f76401362,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-a26e803f-c447-41c9-8ed1-b96f1da4a8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43783,DS-b4c68dce-2ecb-44c7-a5b5-752029cc36d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-44e1cb40-6e68-446a-b1af-25cf813ac5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33006,DS-c40da48a-52ac-4b40-aaf7-8be5c485ae97,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-a7ac0389-711e-43c6-b67d-7f3cceb705ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40022,DS-064edfb8-4090-4215-aba7-546de3a69df5,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-2d583789-9c44-4d24-aedb-a5b09df71e5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1271485481-172.17.0.21-1597349168386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36358,DS-6f82a279-d874-4555-a266-dd516d2e9d87,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-bd7e2179-3088-41b1-89ce-7c25eae59050,DISK], DatanodeInfoWithStorage[127.0.0.1:34751,DS-c4256578-7140-4afd-aa25-ea9748f569cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-0fa64f03-9ac8-444e-bcc6-882aa9c2919a,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-4882e68f-e6b7-463c-be66-288aced7d8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-2e60b141-8b93-4743-a234-77e7e82e4c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41033,DS-1e4e0018-37f6-42ce-8922-b0e2b579a6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-bbf79950-7590-440d-bebf-541c67c3d614,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1271485481-172.17.0.21-1597349168386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36358,DS-6f82a279-d874-4555-a266-dd516d2e9d87,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-bd7e2179-3088-41b1-89ce-7c25eae59050,DISK], DatanodeInfoWithStorage[127.0.0.1:34751,DS-c4256578-7140-4afd-aa25-ea9748f569cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-0fa64f03-9ac8-444e-bcc6-882aa9c2919a,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-4882e68f-e6b7-463c-be66-288aced7d8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-2e60b141-8b93-4743-a234-77e7e82e4c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41033,DS-1e4e0018-37f6-42ce-8922-b0e2b579a6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-bbf79950-7590-440d-bebf-541c67c3d614,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-852586278-172.17.0.21-1597349383422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40864,DS-018f7e2e-d625-407a-927b-b115cc407a27,DISK], DatanodeInfoWithStorage[127.0.0.1:44153,DS-029dfe82-a7de-42cd-ab95-c958cd435a04,DISK], DatanodeInfoWithStorage[127.0.0.1:44652,DS-cffc58cb-7e7d-419d-8827-4279b0503193,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-adfdbe42-d4ba-4851-8cc5-00910180c192,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-47f8674e-6f32-49f9-b600-2a8a2e8ac2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-cdef91fe-ede2-4ac5-9987-9b71e15d7d46,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-b349eef8-bd84-4bf5-af0d-49c866307b54,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-9780e9b8-fd4f-454e-8627-222063b8af8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-852586278-172.17.0.21-1597349383422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40864,DS-018f7e2e-d625-407a-927b-b115cc407a27,DISK], DatanodeInfoWithStorage[127.0.0.1:44153,DS-029dfe82-a7de-42cd-ab95-c958cd435a04,DISK], DatanodeInfoWithStorage[127.0.0.1:44652,DS-cffc58cb-7e7d-419d-8827-4279b0503193,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-adfdbe42-d4ba-4851-8cc5-00910180c192,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-47f8674e-6f32-49f9-b600-2a8a2e8ac2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-cdef91fe-ede2-4ac5-9987-9b71e15d7d46,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-b349eef8-bd84-4bf5-af0d-49c866307b54,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-9780e9b8-fd4f-454e-8627-222063b8af8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1895114675-172.17.0.21-1597349618315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43597,DS-b139349c-5847-4bf3-8093-3689d57c3e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-c33b9a74-0d4d-44d0-bc89-142057c0c63e,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-025d35fe-05d2-4b0a-b03e-8b72f30e84ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39781,DS-217c73c6-5b4e-4ed1-be69-690d9c3f4dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-57dba33f-61e3-4a29-8be3-e59ae11871ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-392bdafd-5a4e-4bf2-b421-26236cbeb1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35727,DS-3a2513e5-7b7e-453a-b7da-f8d24353b8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-3e72afe1-b27f-43ab-95ae-54ace5dbe8f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1895114675-172.17.0.21-1597349618315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43597,DS-b139349c-5847-4bf3-8093-3689d57c3e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-c33b9a74-0d4d-44d0-bc89-142057c0c63e,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-025d35fe-05d2-4b0a-b03e-8b72f30e84ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39781,DS-217c73c6-5b4e-4ed1-be69-690d9c3f4dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-57dba33f-61e3-4a29-8be3-e59ae11871ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-392bdafd-5a4e-4bf2-b421-26236cbeb1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35727,DS-3a2513e5-7b7e-453a-b7da-f8d24353b8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-3e72afe1-b27f-43ab-95ae-54ace5dbe8f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1383021148-172.17.0.21-1597349660083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42335,DS-a9a5114f-e437-42ca-b86f-e148900af1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-60fecea4-f047-48e5-a0a0-e8e5df6e43cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-f7a80358-2c8a-4dc9-b76f-b534a36e7834,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-1c1365e0-96a2-47e6-a080-27be52db5b62,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-db61cb05-3c95-4cc8-9b59-3a0c5049d5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46356,DS-6e29d1ac-eea0-461b-a847-5ad0d46b3d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-0af9cc3f-6769-41cd-995d-2c4c13b84aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-b770a501-b549-4598-b60e-be103dc11727,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1383021148-172.17.0.21-1597349660083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42335,DS-a9a5114f-e437-42ca-b86f-e148900af1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-60fecea4-f047-48e5-a0a0-e8e5df6e43cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-f7a80358-2c8a-4dc9-b76f-b534a36e7834,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-1c1365e0-96a2-47e6-a080-27be52db5b62,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-db61cb05-3c95-4cc8-9b59-3a0c5049d5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46356,DS-6e29d1ac-eea0-461b-a847-5ad0d46b3d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-0af9cc3f-6769-41cd-995d-2c4c13b84aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-b770a501-b549-4598-b60e-be103dc11727,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851161004-172.17.0.21-1597350077080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37043,DS-022d40c3-834e-4bcf-8c7e-55ad668f5e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-8af35ace-41a6-4389-8f83-ff64a2de7c73,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-2bf770c6-1e2c-41f8-ab95-65614ff270df,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-e7eca6eb-a3c6-44a1-99ec-e749a90ddb13,DISK], DatanodeInfoWithStorage[127.0.0.1:33422,DS-1a4550f7-cc95-4033-964a-ac5d0759443b,DISK], DatanodeInfoWithStorage[127.0.0.1:43088,DS-7135b7ba-7734-41f5-936b-9c402ccd4d27,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-31559694-0fcd-4d48-a01f-dc43eaa196de,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-47bb45b9-4405-405f-b0c1-7b60deb629b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851161004-172.17.0.21-1597350077080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37043,DS-022d40c3-834e-4bcf-8c7e-55ad668f5e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-8af35ace-41a6-4389-8f83-ff64a2de7c73,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-2bf770c6-1e2c-41f8-ab95-65614ff270df,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-e7eca6eb-a3c6-44a1-99ec-e749a90ddb13,DISK], DatanodeInfoWithStorage[127.0.0.1:33422,DS-1a4550f7-cc95-4033-964a-ac5d0759443b,DISK], DatanodeInfoWithStorage[127.0.0.1:43088,DS-7135b7ba-7734-41f5-936b-9c402ccd4d27,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-31559694-0fcd-4d48-a01f-dc43eaa196de,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-47bb45b9-4405-405f-b0c1-7b60deb629b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1305188591-172.17.0.21-1597350319823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40031,DS-7700ba79-5375-4b8d-9aba-53922d151a59,DISK], DatanodeInfoWithStorage[127.0.0.1:40664,DS-70b1d5ab-1d83-487a-943c-37121560e34e,DISK], DatanodeInfoWithStorage[127.0.0.1:46773,DS-88d1ba1c-1430-46c2-b236-4491f46f5fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-c61c3c8c-99a4-48ff-b551-1d0a520b53d3,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-ec41eee3-ae35-4051-a5a6-158f09ee513e,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-ffa8178d-5d88-4ac9-aaa9-944eb18f8019,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-bd3f301f-0c75-4b66-8258-169c10a7aa9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34465,DS-d002422b-ec5f-47a4-91ee-ab08c9af16b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1305188591-172.17.0.21-1597350319823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40031,DS-7700ba79-5375-4b8d-9aba-53922d151a59,DISK], DatanodeInfoWithStorage[127.0.0.1:40664,DS-70b1d5ab-1d83-487a-943c-37121560e34e,DISK], DatanodeInfoWithStorage[127.0.0.1:46773,DS-88d1ba1c-1430-46c2-b236-4491f46f5fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-c61c3c8c-99a4-48ff-b551-1d0a520b53d3,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-ec41eee3-ae35-4051-a5a6-158f09ee513e,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-ffa8178d-5d88-4ac9-aaa9-944eb18f8019,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-bd3f301f-0c75-4b66-8258-169c10a7aa9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34465,DS-d002422b-ec5f-47a4-91ee-ab08c9af16b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1489244042-172.17.0.21-1597350402239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46078,DS-7c9d3a8c-469b-4151-b0d3-090b2bd5dbda,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-2c6836ec-45fe-4cd9-9da9-2e29c717151d,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-69544dca-6168-4c16-9fcd-7c5e6a319f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-ee8d72b2-806e-4022-a707-edfd3e681b52,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-467535e3-b0bb-4260-a8cb-afb51c441e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38191,DS-089eafec-a829-436f-a8fd-4fbd3a78c002,DISK], DatanodeInfoWithStorage[127.0.0.1:36475,DS-b982f8a2-6c32-4e16-abd9-74d344826200,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-de6ceaab-b109-4bf0-9a48-0c0b57a91e59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1489244042-172.17.0.21-1597350402239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46078,DS-7c9d3a8c-469b-4151-b0d3-090b2bd5dbda,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-2c6836ec-45fe-4cd9-9da9-2e29c717151d,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-69544dca-6168-4c16-9fcd-7c5e6a319f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-ee8d72b2-806e-4022-a707-edfd3e681b52,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-467535e3-b0bb-4260-a8cb-afb51c441e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38191,DS-089eafec-a829-436f-a8fd-4fbd3a78c002,DISK], DatanodeInfoWithStorage[127.0.0.1:36475,DS-b982f8a2-6c32-4e16-abd9-74d344826200,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-de6ceaab-b109-4bf0-9a48-0c0b57a91e59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2127543793-172.17.0.21-1597350445710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45261,DS-d831cad7-cf45-43f6-8870-17bd1e09bdf6,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-5951d7bc-d73b-4b5f-929f-b08edd618108,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-ef3c868d-97ca-4082-96cf-8e31bd0944c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-caf5fb3c-0684-4b3e-b9cc-a68e86b8999a,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-79dc9e65-0c02-4087-b0ae-2c87d99da1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39752,DS-c9731315-1372-4a25-90ce-6cb153f4dd45,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-c4cd62f6-69a8-4284-9058-48b89269b089,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-76b37f41-3679-4a21-98e7-21a376d8e723,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2127543793-172.17.0.21-1597350445710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45261,DS-d831cad7-cf45-43f6-8870-17bd1e09bdf6,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-5951d7bc-d73b-4b5f-929f-b08edd618108,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-ef3c868d-97ca-4082-96cf-8e31bd0944c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-caf5fb3c-0684-4b3e-b9cc-a68e86b8999a,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-79dc9e65-0c02-4087-b0ae-2c87d99da1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39752,DS-c9731315-1372-4a25-90ce-6cb153f4dd45,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-c4cd62f6-69a8-4284-9058-48b89269b089,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-76b37f41-3679-4a21-98e7-21a376d8e723,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1025206006-172.17.0.21-1597350478628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38817,DS-638504ab-25f8-4ff3-9c71-5bba1b873b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-92c9b083-294a-4f21-b1e9-1697b6c0e02a,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-f8e94b85-1b40-470d-9940-b2dea3bb1e06,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-95fbf897-3a59-42a7-b2e1-75d56a871a62,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-f797b34f-ff75-4d42-bd39-c56974d5ad94,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-2ae6f49d-f129-4dcb-9ae8-2626a746bcff,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-c6b89b69-bacf-484e-ab5d-f0015aba9a89,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-ad878dda-ade1-453c-beea-fb204a7f0289,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1025206006-172.17.0.21-1597350478628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38817,DS-638504ab-25f8-4ff3-9c71-5bba1b873b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-92c9b083-294a-4f21-b1e9-1697b6c0e02a,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-f8e94b85-1b40-470d-9940-b2dea3bb1e06,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-95fbf897-3a59-42a7-b2e1-75d56a871a62,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-f797b34f-ff75-4d42-bd39-c56974d5ad94,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-2ae6f49d-f129-4dcb-9ae8-2626a746bcff,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-c6b89b69-bacf-484e-ab5d-f0015aba9a89,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-ad878dda-ade1-453c-beea-fb204a7f0289,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1078614085-172.17.0.21-1597350712624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42218,DS-7f24bfcf-e7cd-4b68-8314-cc6b354438a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-15e03f4a-4864-4701-981a-230d6a091160,DISK], DatanodeInfoWithStorage[127.0.0.1:41664,DS-bbf36796-d574-4cbd-858d-0045a74e2815,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-258e4e5d-ef63-471e-a3ef-96686b4c4505,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-c8583b33-dc32-4785-9629-6d2bf8e3ec53,DISK], DatanodeInfoWithStorage[127.0.0.1:43701,DS-293c6807-2822-45f9-bad3-28b34e4164f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-634a27ae-7b9b-43c6-873c-abb7e5d44bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-b20a0ca7-fe23-4a0e-8594-957dd51e583c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1078614085-172.17.0.21-1597350712624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42218,DS-7f24bfcf-e7cd-4b68-8314-cc6b354438a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-15e03f4a-4864-4701-981a-230d6a091160,DISK], DatanodeInfoWithStorage[127.0.0.1:41664,DS-bbf36796-d574-4cbd-858d-0045a74e2815,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-258e4e5d-ef63-471e-a3ef-96686b4c4505,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-c8583b33-dc32-4785-9629-6d2bf8e3ec53,DISK], DatanodeInfoWithStorage[127.0.0.1:43701,DS-293c6807-2822-45f9-bad3-28b34e4164f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-634a27ae-7b9b-43c6-873c-abb7e5d44bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-b20a0ca7-fe23-4a0e-8594-957dd51e583c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-316782047-172.17.0.21-1597350751425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41514,DS-039f12f0-d397-4d66-ad9f-fae0fe743808,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-078fc584-fbca-4185-a86e-31544f367c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-fc455d47-c9aa-494f-b75c-537c3bc56a06,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-02829e37-f51f-41f9-bc2a-bfb830fb2389,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-cdd44c36-0220-4803-ad46-789c373af028,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-51530a04-24e9-4e77-bada-debb9ff1c2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-2b01d0c0-988f-4f5a-8a40-ce66127529f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-9bf48437-fba7-44a4-974e-608f3af4e968,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-316782047-172.17.0.21-1597350751425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41514,DS-039f12f0-d397-4d66-ad9f-fae0fe743808,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-078fc584-fbca-4185-a86e-31544f367c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-fc455d47-c9aa-494f-b75c-537c3bc56a06,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-02829e37-f51f-41f9-bc2a-bfb830fb2389,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-cdd44c36-0220-4803-ad46-789c373af028,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-51530a04-24e9-4e77-bada-debb9ff1c2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-2b01d0c0-988f-4f5a-8a40-ce66127529f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-9bf48437-fba7-44a4-974e-608f3af4e968,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1833204912-172.17.0.21-1597351179377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35143,DS-5e26840c-5301-476f-9eca-eb1a63d05463,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-2fc6ed82-d1f7-4a16-9918-e36ffa2544fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-14505666-2b2b-437b-ba83-4fe47631c0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-f3cb2fab-3b93-473e-8fb9-ac35fe61167a,DISK], DatanodeInfoWithStorage[127.0.0.1:46515,DS-fa9d3fe0-0592-49a1-a191-9b2222e57c89,DISK], DatanodeInfoWithStorage[127.0.0.1:39051,DS-7fdef0ce-03f4-47a2-861b-7da8461fe281,DISK], DatanodeInfoWithStorage[127.0.0.1:42012,DS-6b7cd56f-4626-4b55-8e05-1452ac460f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-c94fd0aa-b85e-4f67-8c10-8b9ac8907aa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1833204912-172.17.0.21-1597351179377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35143,DS-5e26840c-5301-476f-9eca-eb1a63d05463,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-2fc6ed82-d1f7-4a16-9918-e36ffa2544fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-14505666-2b2b-437b-ba83-4fe47631c0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-f3cb2fab-3b93-473e-8fb9-ac35fe61167a,DISK], DatanodeInfoWithStorage[127.0.0.1:46515,DS-fa9d3fe0-0592-49a1-a191-9b2222e57c89,DISK], DatanodeInfoWithStorage[127.0.0.1:39051,DS-7fdef0ce-03f4-47a2-861b-7da8461fe281,DISK], DatanodeInfoWithStorage[127.0.0.1:42012,DS-6b7cd56f-4626-4b55-8e05-1452ac460f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-c94fd0aa-b85e-4f67-8c10-8b9ac8907aa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5659
