reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41630,DS-de31e6e9-e350-4ffc-9448-07118c33fd1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-b8a50abf-f280-4006-a227-446e3d5b5126,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41630,DS-de31e6e9-e350-4ffc-9448-07118c33fd1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-b8a50abf-f280-4006-a227-446e3d5b5126,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41630,DS-de31e6e9-e350-4ffc-9448-07118c33fd1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-b8a50abf-f280-4006-a227-446e3d5b5126,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41630,DS-de31e6e9-e350-4ffc-9448-07118c33fd1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-b8a50abf-f280-4006-a227-446e3d5b5126,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45767,DS-1cfa952d-662a-4369-8f64-32fd2354c1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-aba6ce4d-13cf-473b-9585-d8dde78e0e77,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36859,DS-aba6ce4d-13cf-473b-9585-d8dde78e0e77,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-1cfa952d-662a-4369-8f64-32fd2354c1dc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45767,DS-1cfa952d-662a-4369-8f64-32fd2354c1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-aba6ce4d-13cf-473b-9585-d8dde78e0e77,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36859,DS-aba6ce4d-13cf-473b-9585-d8dde78e0e77,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-1cfa952d-662a-4369-8f64-32fd2354c1dc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46284,DS-a623fd54-f6d6-4086-b8bc-f2aed830821b,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-a5764600-5996-49c6-a1e5-b279f8200e61,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46284,DS-a623fd54-f6d6-4086-b8bc-f2aed830821b,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-a5764600-5996-49c6-a1e5-b279f8200e61,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46284,DS-a623fd54-f6d6-4086-b8bc-f2aed830821b,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-a5764600-5996-49c6-a1e5-b279f8200e61,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46284,DS-a623fd54-f6d6-4086-b8bc-f2aed830821b,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-a5764600-5996-49c6-a1e5-b279f8200e61,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35179,DS-5f183422-7372-47a1-b83c-423ace51d3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-5fb10165-a3b8-4542-9ac2-45abfc69f47d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35817,DS-5fb10165-a3b8-4542-9ac2-45abfc69f47d,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-5f183422-7372-47a1-b83c-423ace51d3f6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35179,DS-5f183422-7372-47a1-b83c-423ace51d3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-5fb10165-a3b8-4542-9ac2-45abfc69f47d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35817,DS-5fb10165-a3b8-4542-9ac2-45abfc69f47d,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-5f183422-7372-47a1-b83c-423ace51d3f6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36163,DS-988df5d8-b26e-45ec-bd29-67ecb82bd967,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-6722d5d9-a28a-4c0f-8343-92c662058a33,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36163,DS-988df5d8-b26e-45ec-bd29-67ecb82bd967,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-6722d5d9-a28a-4c0f-8343-92c662058a33,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36163,DS-988df5d8-b26e-45ec-bd29-67ecb82bd967,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-6722d5d9-a28a-4c0f-8343-92c662058a33,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36163,DS-988df5d8-b26e-45ec-bd29-67ecb82bd967,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-6722d5d9-a28a-4c0f-8343-92c662058a33,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45765,DS-093beafa-6985-4f41-ad4b-69017d8a5ade,DISK], DatanodeInfoWithStorage[127.0.0.1:40355,DS-271a563c-322c-4f90-a1a1-a94764d3a402,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40355,DS-271a563c-322c-4f90-a1a1-a94764d3a402,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-093beafa-6985-4f41-ad4b-69017d8a5ade,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45765,DS-093beafa-6985-4f41-ad4b-69017d8a5ade,DISK], DatanodeInfoWithStorage[127.0.0.1:40355,DS-271a563c-322c-4f90-a1a1-a94764d3a402,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40355,DS-271a563c-322c-4f90-a1a1-a94764d3a402,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-093beafa-6985-4f41-ad4b-69017d8a5ade,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44046,DS-2c496176-9f27-4dcd-b36b-4a95dfb8e8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-b90f3406-d039-4e4c-a06a-9dd6eb97fb28,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39387,DS-b90f3406-d039-4e4c-a06a-9dd6eb97fb28,DISK], DatanodeInfoWithStorage[127.0.0.1:44046,DS-2c496176-9f27-4dcd-b36b-4a95dfb8e8ce,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44046,DS-2c496176-9f27-4dcd-b36b-4a95dfb8e8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-b90f3406-d039-4e4c-a06a-9dd6eb97fb28,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39387,DS-b90f3406-d039-4e4c-a06a-9dd6eb97fb28,DISK], DatanodeInfoWithStorage[127.0.0.1:44046,DS-2c496176-9f27-4dcd-b36b-4a95dfb8e8ce,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40984,DS-b023dfe0-eded-47aa-8982-0db3a4eef764,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-378e2e6f-94eb-4e58-b9fb-2d8452c43e8c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35482,DS-378e2e6f-94eb-4e58-b9fb-2d8452c43e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-b023dfe0-eded-47aa-8982-0db3a4eef764,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40984,DS-b023dfe0-eded-47aa-8982-0db3a4eef764,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-378e2e6f-94eb-4e58-b9fb-2d8452c43e8c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35482,DS-378e2e6f-94eb-4e58-b9fb-2d8452c43e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-b023dfe0-eded-47aa-8982-0db3a4eef764,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44328,DS-c42f060b-7cfb-4171-b144-06e7c10ca793,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-bc2f3514-aaae-44c7-a7a5-17505bc001a3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37110,DS-bc2f3514-aaae-44c7-a7a5-17505bc001a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-c42f060b-7cfb-4171-b144-06e7c10ca793,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44328,DS-c42f060b-7cfb-4171-b144-06e7c10ca793,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-bc2f3514-aaae-44c7-a7a5-17505bc001a3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37110,DS-bc2f3514-aaae-44c7-a7a5-17505bc001a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-c42f060b-7cfb-4171-b144-06e7c10ca793,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35464,DS-c2945e58-6f14-4a9f-97f6-a4e946063eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-c9a6fa94-2b00-42b1-ad77-c64e232b6793,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35464,DS-c2945e58-6f14-4a9f-97f6-a4e946063eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-c9a6fa94-2b00-42b1-ad77-c64e232b6793,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35464,DS-c2945e58-6f14-4a9f-97f6-a4e946063eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-c9a6fa94-2b00-42b1-ad77-c64e232b6793,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35464,DS-c2945e58-6f14-4a9f-97f6-a4e946063eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-c9a6fa94-2b00-42b1-ad77-c64e232b6793,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36673,DS-926db487-d66d-4590-98ce-e4a92b6e1629,DISK], DatanodeInfoWithStorage[127.0.0.1:37511,DS-46aaa9ec-39df-45c4-bbd6-9968797ebd32,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36673,DS-926db487-d66d-4590-98ce-e4a92b6e1629,DISK], DatanodeInfoWithStorage[127.0.0.1:37511,DS-46aaa9ec-39df-45c4-bbd6-9968797ebd32,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36673,DS-926db487-d66d-4590-98ce-e4a92b6e1629,DISK], DatanodeInfoWithStorage[127.0.0.1:37511,DS-46aaa9ec-39df-45c4-bbd6-9968797ebd32,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36673,DS-926db487-d66d-4590-98ce-e4a92b6e1629,DISK], DatanodeInfoWithStorage[127.0.0.1:37511,DS-46aaa9ec-39df-45c4-bbd6-9968797ebd32,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39602,DS-34c069b9-ed50-4453-8580-54622eec8a88,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-2d05a187-06b1-40f2-855c-5eec1c98b632,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39602,DS-34c069b9-ed50-4453-8580-54622eec8a88,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-2d05a187-06b1-40f2-855c-5eec1c98b632,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39602,DS-34c069b9-ed50-4453-8580-54622eec8a88,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-2d05a187-06b1-40f2-855c-5eec1c98b632,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39602,DS-34c069b9-ed50-4453-8580-54622eec8a88,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-2d05a187-06b1-40f2-855c-5eec1c98b632,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36129,DS-7a6c8956-e36a-4d3f-ae77-3f94cb97a755,DISK], DatanodeInfoWithStorage[127.0.0.1:38332,DS-95f9eddd-4719-4c7c-a5f5-fbaba49bc56b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38332,DS-95f9eddd-4719-4c7c-a5f5-fbaba49bc56b,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-7a6c8956-e36a-4d3f-ae77-3f94cb97a755,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36129,DS-7a6c8956-e36a-4d3f-ae77-3f94cb97a755,DISK], DatanodeInfoWithStorage[127.0.0.1:38332,DS-95f9eddd-4719-4c7c-a5f5-fbaba49bc56b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38332,DS-95f9eddd-4719-4c7c-a5f5-fbaba49bc56b,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-7a6c8956-e36a-4d3f-ae77-3f94cb97a755,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40878,DS-356b3f5f-f0be-4105-ae8a-8ecb2d00cd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-12d6f8c0-4450-4013-a661-dcf67c1893f9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40878,DS-356b3f5f-f0be-4105-ae8a-8ecb2d00cd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-12d6f8c0-4450-4013-a661-dcf67c1893f9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40878,DS-356b3f5f-f0be-4105-ae8a-8ecb2d00cd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-12d6f8c0-4450-4013-a661-dcf67c1893f9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40878,DS-356b3f5f-f0be-4105-ae8a-8ecb2d00cd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-12d6f8c0-4450-4013-a661-dcf67c1893f9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35172,DS-4fa89cf1-2d68-4179-b86e-4b103e0df90e,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-336a7f69-7ba1-4407-b008-1e1db8c9871f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35172,DS-4fa89cf1-2d68-4179-b86e-4b103e0df90e,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-336a7f69-7ba1-4407-b008-1e1db8c9871f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35172,DS-4fa89cf1-2d68-4179-b86e-4b103e0df90e,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-336a7f69-7ba1-4407-b008-1e1db8c9871f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35172,DS-4fa89cf1-2d68-4179-b86e-4b103e0df90e,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-336a7f69-7ba1-4407-b008-1e1db8c9871f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44652,DS-b964132f-3d90-41ce-b50f-57def6539c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-d07bc1cf-d34d-44f5-bfa0-430a8745637e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44652,DS-b964132f-3d90-41ce-b50f-57def6539c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-d07bc1cf-d34d-44f5-bfa0-430a8745637e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44652,DS-b964132f-3d90-41ce-b50f-57def6539c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-d07bc1cf-d34d-44f5-bfa0-430a8745637e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44652,DS-b964132f-3d90-41ce-b50f-57def6539c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-d07bc1cf-d34d-44f5-bfa0-430a8745637e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37254,DS-d87abdd7-8671-4cc5-bfd1-3dcc83000098,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-bd4e7cda-12bb-4303-8bcb-5954c54bd72b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37254,DS-d87abdd7-8671-4cc5-bfd1-3dcc83000098,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-bd4e7cda-12bb-4303-8bcb-5954c54bd72b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37254,DS-d87abdd7-8671-4cc5-bfd1-3dcc83000098,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-bd4e7cda-12bb-4303-8bcb-5954c54bd72b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37254,DS-d87abdd7-8671-4cc5-bfd1-3dcc83000098,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-bd4e7cda-12bb-4303-8bcb-5954c54bd72b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41648,DS-f0a31a6e-deba-4a74-8ce2-bf270345fcac,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-0f0d832a-dc13-4bed-8ba1-5d15de3f3ff6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41648,DS-f0a31a6e-deba-4a74-8ce2-bf270345fcac,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-0f0d832a-dc13-4bed-8ba1-5d15de3f3ff6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41648,DS-f0a31a6e-deba-4a74-8ce2-bf270345fcac,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-0f0d832a-dc13-4bed-8ba1-5d15de3f3ff6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41648,DS-f0a31a6e-deba-4a74-8ce2-bf270345fcac,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-0f0d832a-dc13-4bed-8ba1-5d15de3f3ff6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43463,DS-ae2cd410-b7ba-4883-a71e-4cca2b301fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-7d24b316-e31b-4a79-9751-d9e4a41ef795,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43463,DS-ae2cd410-b7ba-4883-a71e-4cca2b301fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-7d24b316-e31b-4a79-9751-d9e4a41ef795,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43463,DS-ae2cd410-b7ba-4883-a71e-4cca2b301fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-7d24b316-e31b-4a79-9751-d9e4a41ef795,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43463,DS-ae2cd410-b7ba-4883-a71e-4cca2b301fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-7d24b316-e31b-4a79-9751-d9e4a41ef795,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42143,DS-910d6183-e7ac-4844-b6ea-b111af6979b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-3a685024-23d9-4df2-83e8-f6f6c3138333,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36102,DS-3a685024-23d9-4df2-83e8-f6f6c3138333,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-910d6183-e7ac-4844-b6ea-b111af6979b6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42143,DS-910d6183-e7ac-4844-b6ea-b111af6979b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-3a685024-23d9-4df2-83e8-f6f6c3138333,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36102,DS-3a685024-23d9-4df2-83e8-f6f6c3138333,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-910d6183-e7ac-4844-b6ea-b111af6979b6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34599,DS-292d9cfe-af22-45a0-8a33-b96d5ee9ac5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-bf0da042-256a-4ceb-8564-77684dc50d49,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39280,DS-bf0da042-256a-4ceb-8564-77684dc50d49,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-292d9cfe-af22-45a0-8a33-b96d5ee9ac5f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34599,DS-292d9cfe-af22-45a0-8a33-b96d5ee9ac5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-bf0da042-256a-4ceb-8564-77684dc50d49,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39280,DS-bf0da042-256a-4ceb-8564-77684dc50d49,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-292d9cfe-af22-45a0-8a33-b96d5ee9ac5f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46520,DS-5fdf5b53-66cc-4987-b0da-7d37b9609631,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-30f317d4-6c40-46d1-9e81-cf05865678b5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46520,DS-5fdf5b53-66cc-4987-b0da-7d37b9609631,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-30f317d4-6c40-46d1-9e81-cf05865678b5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46520,DS-5fdf5b53-66cc-4987-b0da-7d37b9609631,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-30f317d4-6c40-46d1-9e81-cf05865678b5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46520,DS-5fdf5b53-66cc-4987-b0da-7d37b9609631,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-30f317d4-6c40-46d1-9e81-cf05865678b5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45970,DS-7ced9b41-efbf-4df7-acdc-0f89276239dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-16ea43ac-ec53-4e5c-9dd3-9276a2904b38,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45970,DS-7ced9b41-efbf-4df7-acdc-0f89276239dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-16ea43ac-ec53-4e5c-9dd3-9276a2904b38,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45970,DS-7ced9b41-efbf-4df7-acdc-0f89276239dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-16ea43ac-ec53-4e5c-9dd3-9276a2904b38,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45970,DS-7ced9b41-efbf-4df7-acdc-0f89276239dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-16ea43ac-ec53-4e5c-9dd3-9276a2904b38,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45095,DS-25f306c5-7dd8-4304-a51b-cd5bc603b781,DISK], DatanodeInfoWithStorage[127.0.0.1:41467,DS-7d4b906e-088c-48a7-8d78-77b43911e2f8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45095,DS-25f306c5-7dd8-4304-a51b-cd5bc603b781,DISK], DatanodeInfoWithStorage[127.0.0.1:41467,DS-7d4b906e-088c-48a7-8d78-77b43911e2f8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45095,DS-25f306c5-7dd8-4304-a51b-cd5bc603b781,DISK], DatanodeInfoWithStorage[127.0.0.1:41467,DS-7d4b906e-088c-48a7-8d78-77b43911e2f8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45095,DS-25f306c5-7dd8-4304-a51b-cd5bc603b781,DISK], DatanodeInfoWithStorage[127.0.0.1:41467,DS-7d4b906e-088c-48a7-8d78-77b43911e2f8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44640,DS-024d1d3d-6544-445c-9060-06cdee778277,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-4fce0dae-a6e8-437b-86a5-063e68a57dcd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44640,DS-024d1d3d-6544-445c-9060-06cdee778277,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-4fce0dae-a6e8-437b-86a5-063e68a57dcd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44640,DS-024d1d3d-6544-445c-9060-06cdee778277,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-4fce0dae-a6e8-437b-86a5-063e68a57dcd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44640,DS-024d1d3d-6544-445c-9060-06cdee778277,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-4fce0dae-a6e8-437b-86a5-063e68a57dcd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34255,DS-855bc980-c5fe-423a-9b9a-8820b119d311,DISK], DatanodeInfoWithStorage[127.0.0.1:35879,DS-4cf5fa82-dcf6-4a87-9a6e-c3b8e8413fb3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34255,DS-855bc980-c5fe-423a-9b9a-8820b119d311,DISK], DatanodeInfoWithStorage[127.0.0.1:35879,DS-4cf5fa82-dcf6-4a87-9a6e-c3b8e8413fb3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34255,DS-855bc980-c5fe-423a-9b9a-8820b119d311,DISK], DatanodeInfoWithStorage[127.0.0.1:35879,DS-4cf5fa82-dcf6-4a87-9a6e-c3b8e8413fb3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34255,DS-855bc980-c5fe-423a-9b9a-8820b119d311,DISK], DatanodeInfoWithStorage[127.0.0.1:35879,DS-4cf5fa82-dcf6-4a87-9a6e-c3b8e8413fb3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37616,DS-37cf50b6-915d-49dc-8cb2-2e752f0ca17b,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-582f79fd-036b-4d4d-9801-1ccda68dc861,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37616,DS-37cf50b6-915d-49dc-8cb2-2e752f0ca17b,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-582f79fd-036b-4d4d-9801-1ccda68dc861,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37616,DS-37cf50b6-915d-49dc-8cb2-2e752f0ca17b,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-582f79fd-036b-4d4d-9801-1ccda68dc861,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37616,DS-37cf50b6-915d-49dc-8cb2-2e752f0ca17b,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-582f79fd-036b-4d4d-9801-1ccda68dc861,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43223,DS-3301655e-8929-42af-82cd-0ae7ba20b598,DISK], DatanodeInfoWithStorage[127.0.0.1:40504,DS-33b26084-1768-4ede-9f65-7b7d053ccf44,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43223,DS-3301655e-8929-42af-82cd-0ae7ba20b598,DISK], DatanodeInfoWithStorage[127.0.0.1:40504,DS-33b26084-1768-4ede-9f65-7b7d053ccf44,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43223,DS-3301655e-8929-42af-82cd-0ae7ba20b598,DISK], DatanodeInfoWithStorage[127.0.0.1:40504,DS-33b26084-1768-4ede-9f65-7b7d053ccf44,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43223,DS-3301655e-8929-42af-82cd-0ae7ba20b598,DISK], DatanodeInfoWithStorage[127.0.0.1:40504,DS-33b26084-1768-4ede-9f65-7b7d053ccf44,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34649,DS-4e97a8c5-db0e-460b-a686-c1c387d21e56,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-9cc57821-fcb9-4288-8487-c36aa7b0f93d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40576,DS-9cc57821-fcb9-4288-8487-c36aa7b0f93d,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-4e97a8c5-db0e-460b-a686-c1c387d21e56,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34649,DS-4e97a8c5-db0e-460b-a686-c1c387d21e56,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-9cc57821-fcb9-4288-8487-c36aa7b0f93d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40576,DS-9cc57821-fcb9-4288-8487-c36aa7b0f93d,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-4e97a8c5-db0e-460b-a686-c1c387d21e56,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42249,DS-673a663a-1dc0-4e81-afeb-7b7ba4625df8,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-6994111e-338c-4d55-893b-82bd45b51db0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42249,DS-673a663a-1dc0-4e81-afeb-7b7ba4625df8,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-6994111e-338c-4d55-893b-82bd45b51db0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42249,DS-673a663a-1dc0-4e81-afeb-7b7ba4625df8,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-6994111e-338c-4d55-893b-82bd45b51db0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42249,DS-673a663a-1dc0-4e81-afeb-7b7ba4625df8,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-6994111e-338c-4d55-893b-82bd45b51db0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36904,DS-94c77c0c-c76f-4b40-99c1-886b43097bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43004,DS-d4e4fdfb-14b9-4a6a-86d0-b17f3ee5c9a7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36904,DS-94c77c0c-c76f-4b40-99c1-886b43097bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43004,DS-d4e4fdfb-14b9-4a6a-86d0-b17f3ee5c9a7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36904,DS-94c77c0c-c76f-4b40-99c1-886b43097bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43004,DS-d4e4fdfb-14b9-4a6a-86d0-b17f3ee5c9a7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36904,DS-94c77c0c-c76f-4b40-99c1-886b43097bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43004,DS-d4e4fdfb-14b9-4a6a-86d0-b17f3ee5c9a7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46315,DS-12fb400a-4a39-4909-9060-df75286718fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-b963b774-d455-479d-ab66-b576165f0740,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46315,DS-12fb400a-4a39-4909-9060-df75286718fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-b963b774-d455-479d-ab66-b576165f0740,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46315,DS-12fb400a-4a39-4909-9060-df75286718fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-b963b774-d455-479d-ab66-b576165f0740,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46315,DS-12fb400a-4a39-4909-9060-df75286718fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-b963b774-d455-479d-ab66-b576165f0740,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 29 out of 50
v1v1v2v2 failed with probability 3 out of 50
result: might be true error
Total execution time in seconds : 5948
