reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-648033813-172.17.0.4-1597289239213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34018,DS-4e818548-7a97-43eb-b081-4ea129289a47,DISK], DatanodeInfoWithStorage[127.0.0.1:45362,DS-89f14ad6-6db9-4234-b8d7-5cc1535ee00f,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-70b78708-9888-4e3a-905e-d6c6d32ca048,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-38fb39e1-65fb-4bdb-a78c-9c3826de7b88,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-61f788ef-4a70-4728-b912-c91f50c16954,DISK], DatanodeInfoWithStorage[127.0.0.1:40087,DS-78c5ec49-30e3-4916-a406-9e4539d7cd73,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-64ea452f-a3c3-4205-9e77-52aa75412666,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-af85a479-1392-43e7-a7c3-732d8650e2b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-648033813-172.17.0.4-1597289239213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34018,DS-4e818548-7a97-43eb-b081-4ea129289a47,DISK], DatanodeInfoWithStorage[127.0.0.1:45362,DS-89f14ad6-6db9-4234-b8d7-5cc1535ee00f,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-70b78708-9888-4e3a-905e-d6c6d32ca048,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-38fb39e1-65fb-4bdb-a78c-9c3826de7b88,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-61f788ef-4a70-4728-b912-c91f50c16954,DISK], DatanodeInfoWithStorage[127.0.0.1:40087,DS-78c5ec49-30e3-4916-a406-9e4539d7cd73,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-64ea452f-a3c3-4205-9e77-52aa75412666,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-af85a479-1392-43e7-a7c3-732d8650e2b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1028381590-172.17.0.4-1597290232049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39507,DS-b9228626-e231-49b3-9fbb-df3d85b62010,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-450e447b-b78a-4016-bb56-e505fa47ef11,DISK], DatanodeInfoWithStorage[127.0.0.1:45967,DS-65280846-4e8c-4721-ad9c-8c74c5f4d39a,DISK], DatanodeInfoWithStorage[127.0.0.1:45080,DS-2c9ae6b0-5e83-422c-bc95-ad85c91ad68b,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-cb29d9c5-0d7a-4bec-9677-1ebf8fa2a02b,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-6e1e7a0c-3fbb-49cc-8f63-e6cefc3f68ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43885,DS-7f8b5af9-4458-44dc-a0f9-facd74bfc09c,DISK], DatanodeInfoWithStorage[127.0.0.1:39812,DS-b2cffff9-7b0c-4e31-b0ba-a295aa6c0395,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1028381590-172.17.0.4-1597290232049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39507,DS-b9228626-e231-49b3-9fbb-df3d85b62010,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-450e447b-b78a-4016-bb56-e505fa47ef11,DISK], DatanodeInfoWithStorage[127.0.0.1:45967,DS-65280846-4e8c-4721-ad9c-8c74c5f4d39a,DISK], DatanodeInfoWithStorage[127.0.0.1:45080,DS-2c9ae6b0-5e83-422c-bc95-ad85c91ad68b,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-cb29d9c5-0d7a-4bec-9677-1ebf8fa2a02b,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-6e1e7a0c-3fbb-49cc-8f63-e6cefc3f68ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43885,DS-7f8b5af9-4458-44dc-a0f9-facd74bfc09c,DISK], DatanodeInfoWithStorage[127.0.0.1:39812,DS-b2cffff9-7b0c-4e31-b0ba-a295aa6c0395,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-102773113-172.17.0.4-1597290270421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42111,DS-f530625f-7d16-4b28-83b9-dfb3cdc3d630,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-dc89b6eb-6fe7-4f90-aff1-5519effd9e43,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-11016aa1-156f-4ed6-8b58-9e689bd62d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45065,DS-c8148b48-0b40-4f40-ad93-fddb4959b69f,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-227617d9-dc81-42a8-9b0f-fe05495a0d41,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-273cec80-7f9a-41ca-8084-6b9de669e88a,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-6beb5b63-2e76-4607-9782-a23c7de10373,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-dccc4aca-d653-4cd2-b861-22fb43c8e0c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-102773113-172.17.0.4-1597290270421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42111,DS-f530625f-7d16-4b28-83b9-dfb3cdc3d630,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-dc89b6eb-6fe7-4f90-aff1-5519effd9e43,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-11016aa1-156f-4ed6-8b58-9e689bd62d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45065,DS-c8148b48-0b40-4f40-ad93-fddb4959b69f,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-227617d9-dc81-42a8-9b0f-fe05495a0d41,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-273cec80-7f9a-41ca-8084-6b9de669e88a,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-6beb5b63-2e76-4607-9782-a23c7de10373,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-dccc4aca-d653-4cd2-b861-22fb43c8e0c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1609246146-172.17.0.4-1597290347136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38170,DS-06cf1189-65eb-4ba4-b889-ac50e510c304,DISK], DatanodeInfoWithStorage[127.0.0.1:34081,DS-c07fae6f-4869-4313-9bc6-ba035c0a2e86,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-3396699f-9edc-49c6-8c91-e399332fb065,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-660afc2f-504d-443d-8b3e-b567d199e928,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-e5f85dd1-0e6f-4940-b3f1-6b356a7ec1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-57412bbc-fd2d-486b-a9ae-953588a3818d,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-a24e57c0-38a2-49b8-8e07-8a11a3f98057,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-20e03043-52d9-498c-abb0-21968b097d21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1609246146-172.17.0.4-1597290347136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38170,DS-06cf1189-65eb-4ba4-b889-ac50e510c304,DISK], DatanodeInfoWithStorage[127.0.0.1:34081,DS-c07fae6f-4869-4313-9bc6-ba035c0a2e86,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-3396699f-9edc-49c6-8c91-e399332fb065,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-660afc2f-504d-443d-8b3e-b567d199e928,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-e5f85dd1-0e6f-4940-b3f1-6b356a7ec1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-57412bbc-fd2d-486b-a9ae-953588a3818d,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-a24e57c0-38a2-49b8-8e07-8a11a3f98057,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-20e03043-52d9-498c-abb0-21968b097d21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1674363758-172.17.0.4-1597291202177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45181,DS-f6f02338-99a9-4597-98b0-be4ed501ed82,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-c14cc204-6d96-47c0-8189-8a9cb8d6e697,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-6ac5fe2e-7134-4151-9d8b-fd678c481ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-138287ee-4740-40c3-aa14-f16d573e31e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-528096d7-b29f-45c1-b29d-ecb46844a15e,DISK], DatanodeInfoWithStorage[127.0.0.1:40719,DS-c37386a3-d913-472c-9962-cfa2056fd23e,DISK], DatanodeInfoWithStorage[127.0.0.1:34160,DS-3fb96733-a0e8-4599-b43f-a9743e7e0bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-ed5c459c-359f-4aa3-a10e-6fa9c671c8d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1674363758-172.17.0.4-1597291202177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45181,DS-f6f02338-99a9-4597-98b0-be4ed501ed82,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-c14cc204-6d96-47c0-8189-8a9cb8d6e697,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-6ac5fe2e-7134-4151-9d8b-fd678c481ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-138287ee-4740-40c3-aa14-f16d573e31e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-528096d7-b29f-45c1-b29d-ecb46844a15e,DISK], DatanodeInfoWithStorage[127.0.0.1:40719,DS-c37386a3-d913-472c-9962-cfa2056fd23e,DISK], DatanodeInfoWithStorage[127.0.0.1:34160,DS-3fb96733-a0e8-4599-b43f-a9743e7e0bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-ed5c459c-359f-4aa3-a10e-6fa9c671c8d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2059398794-172.17.0.4-1597291692825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37302,DS-a5269460-7d4e-4854-b158-40a70655a26e,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-c12909a7-6cdf-446d-be88-b4c879a9f7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-a6bb3427-08f6-4180-8018-2f460083b981,DISK], DatanodeInfoWithStorage[127.0.0.1:37185,DS-d416c303-1338-4e7c-a398-a1a639c26f68,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-b51442bd-46c1-4087-a3e4-d82571f0d605,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-71d87d8f-8614-4143-ac42-546e39e8be66,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-4bf334b1-2e5f-4149-8e86-7e961f98b112,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-9b450812-766d-4c0b-8d4c-321d46b1c31a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2059398794-172.17.0.4-1597291692825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37302,DS-a5269460-7d4e-4854-b158-40a70655a26e,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-c12909a7-6cdf-446d-be88-b4c879a9f7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-a6bb3427-08f6-4180-8018-2f460083b981,DISK], DatanodeInfoWithStorage[127.0.0.1:37185,DS-d416c303-1338-4e7c-a398-a1a639c26f68,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-b51442bd-46c1-4087-a3e4-d82571f0d605,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-71d87d8f-8614-4143-ac42-546e39e8be66,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-4bf334b1-2e5f-4149-8e86-7e961f98b112,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-9b450812-766d-4c0b-8d4c-321d46b1c31a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1523804177-172.17.0.4-1597291762212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33636,DS-6224c590-eee9-420d-974f-c3cd4c4a6337,DISK], DatanodeInfoWithStorage[127.0.0.1:33777,DS-e43f761b-fe8a-40b4-bf22-eb062cef2b75,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-7cdf96c9-753e-4ec0-8feb-52fd7afd637e,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-e9833593-3cf3-4a4f-a3b1-46fda06b8fce,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-91c085b0-7eb6-4c0f-8e59-33dfd54d3ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-e28c01e5-6d8f-4fab-8b68-07f6ff22dc71,DISK], DatanodeInfoWithStorage[127.0.0.1:46675,DS-7d206e4c-6705-488d-b401-7bca3d25fcf4,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-93676a99-aea2-42e9-94a4-5a3f3c365983,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1523804177-172.17.0.4-1597291762212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33636,DS-6224c590-eee9-420d-974f-c3cd4c4a6337,DISK], DatanodeInfoWithStorage[127.0.0.1:33777,DS-e43f761b-fe8a-40b4-bf22-eb062cef2b75,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-7cdf96c9-753e-4ec0-8feb-52fd7afd637e,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-e9833593-3cf3-4a4f-a3b1-46fda06b8fce,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-91c085b0-7eb6-4c0f-8e59-33dfd54d3ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-e28c01e5-6d8f-4fab-8b68-07f6ff22dc71,DISK], DatanodeInfoWithStorage[127.0.0.1:46675,DS-7d206e4c-6705-488d-b401-7bca3d25fcf4,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-93676a99-aea2-42e9-94a4-5a3f3c365983,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-953710066-172.17.0.4-1597291802021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36048,DS-62cc3e66-17db-4d12-9020-f9faacaaa8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43902,DS-a1193c0c-eea9-4b2e-9520-f57b49dbad76,DISK], DatanodeInfoWithStorage[127.0.0.1:37280,DS-874dedf0-b09d-4e7c-ba46-6aaafbf0824a,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-91a9e9ae-b43c-46c5-bd29-f53b192e3360,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-bd356138-fb08-4b6a-92f9-4a5e8503f73a,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-68fc036d-47d7-4f06-947e-67b994d5449f,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-05027779-cd1c-4118-884b-4932cfcb9deb,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-977c40d9-5e6d-4fda-a63c-8bac64de1123,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-953710066-172.17.0.4-1597291802021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36048,DS-62cc3e66-17db-4d12-9020-f9faacaaa8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43902,DS-a1193c0c-eea9-4b2e-9520-f57b49dbad76,DISK], DatanodeInfoWithStorage[127.0.0.1:37280,DS-874dedf0-b09d-4e7c-ba46-6aaafbf0824a,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-91a9e9ae-b43c-46c5-bd29-f53b192e3360,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-bd356138-fb08-4b6a-92f9-4a5e8503f73a,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-68fc036d-47d7-4f06-947e-67b994d5449f,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-05027779-cd1c-4118-884b-4932cfcb9deb,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-977c40d9-5e6d-4fda-a63c-8bac64de1123,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-458816385-172.17.0.4-1597292147226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40980,DS-80229e9a-512a-4a6a-b3bf-44a2f039d225,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-b5d7ce1d-5728-41a3-99bb-17fa0da3ae91,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-c98751cf-1412-411e-9c2b-45d3d6d6be4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-8ebbf8f4-c089-4b15-8073-43d282fda5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-f7ceabcf-f91c-4f7b-a6ef-8aed929b283b,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-3a5b7df6-ac37-4dfa-95c1-b4505a4a6c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-ba275e67-109d-4140-8bae-cf8dc74a36eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36303,DS-2c7269d0-5b89-4be6-9259-89832ce2c4b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-458816385-172.17.0.4-1597292147226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40980,DS-80229e9a-512a-4a6a-b3bf-44a2f039d225,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-b5d7ce1d-5728-41a3-99bb-17fa0da3ae91,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-c98751cf-1412-411e-9c2b-45d3d6d6be4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-8ebbf8f4-c089-4b15-8073-43d282fda5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-f7ceabcf-f91c-4f7b-a6ef-8aed929b283b,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-3a5b7df6-ac37-4dfa-95c1-b4505a4a6c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-ba275e67-109d-4140-8bae-cf8dc74a36eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36303,DS-2c7269d0-5b89-4be6-9259-89832ce2c4b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1278623651-172.17.0.4-1597292253446:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41626,DS-f1a78335-0cbe-4d1d-8ba8-db87ff13d958,DISK], DatanodeInfoWithStorage[127.0.0.1:36453,DS-7e969597-9cae-4bea-8595-ae4aeec69cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-e17d0339-19cb-44c2-a631-b399d496e66b,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-06b03283-f229-4302-8996-4acffd8ea9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-1e3914cd-caaa-42d4-957d-2146b42a0139,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-0e7842cf-a45f-48d6-a68b-c5c4b4d5600e,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-cb0231db-2940-43c6-9892-af8a3dd0a215,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-2ea33080-79df-4755-85be-ff3581cdad23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1278623651-172.17.0.4-1597292253446:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41626,DS-f1a78335-0cbe-4d1d-8ba8-db87ff13d958,DISK], DatanodeInfoWithStorage[127.0.0.1:36453,DS-7e969597-9cae-4bea-8595-ae4aeec69cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-e17d0339-19cb-44c2-a631-b399d496e66b,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-06b03283-f229-4302-8996-4acffd8ea9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-1e3914cd-caaa-42d4-957d-2146b42a0139,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-0e7842cf-a45f-48d6-a68b-c5c4b4d5600e,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-cb0231db-2940-43c6-9892-af8a3dd0a215,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-2ea33080-79df-4755-85be-ff3581cdad23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-299129130-172.17.0.4-1597293477075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41465,DS-b45ddc67-85d9-49c3-a63a-c3223682fca9,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-3cceb43d-2d83-441a-9a37-3f8655cb822f,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-caf8c149-17c7-4128-b14b-1818a128f66a,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-90cf076c-123e-4979-b5fe-73820bb0014a,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-d6083881-0c38-44b6-8cb0-d72ce68128e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-63b6b24f-ef3f-4a29-aa85-144957f57dad,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-4b79dd70-b36f-4939-9cf3-1a27c2e5a139,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-06253772-201a-4703-b94a-d084b241fdd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-299129130-172.17.0.4-1597293477075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41465,DS-b45ddc67-85d9-49c3-a63a-c3223682fca9,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-3cceb43d-2d83-441a-9a37-3f8655cb822f,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-caf8c149-17c7-4128-b14b-1818a128f66a,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-90cf076c-123e-4979-b5fe-73820bb0014a,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-d6083881-0c38-44b6-8cb0-d72ce68128e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-63b6b24f-ef3f-4a29-aa85-144957f57dad,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-4b79dd70-b36f-4939-9cf3-1a27c2e5a139,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-06253772-201a-4703-b94a-d084b241fdd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1976945751-172.17.0.4-1597293554744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43521,DS-bd74bf7a-40f6-4e5a-acad-a271690f6ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-d0053fd1-9c2f-4722-bdba-ae19ae6d4451,DISK], DatanodeInfoWithStorage[127.0.0.1:36900,DS-edd9de91-69a9-4022-b38e-1e210ad05890,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-41e5b2ac-e824-445b-8daa-80d428815abf,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-d076da6c-76ae-4467-a5aa-f7493d9d118c,DISK], DatanodeInfoWithStorage[127.0.0.1:35332,DS-21da8dad-5635-41d3-bf88-d32533f16993,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-a60e270c-7572-47e2-9cc6-491ec12edfa5,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-78ebf04e-71f8-4270-b685-beb21e999fd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1976945751-172.17.0.4-1597293554744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43521,DS-bd74bf7a-40f6-4e5a-acad-a271690f6ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-d0053fd1-9c2f-4722-bdba-ae19ae6d4451,DISK], DatanodeInfoWithStorage[127.0.0.1:36900,DS-edd9de91-69a9-4022-b38e-1e210ad05890,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-41e5b2ac-e824-445b-8daa-80d428815abf,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-d076da6c-76ae-4467-a5aa-f7493d9d118c,DISK], DatanodeInfoWithStorage[127.0.0.1:35332,DS-21da8dad-5635-41d3-bf88-d32533f16993,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-a60e270c-7572-47e2-9cc6-491ec12edfa5,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-78ebf04e-71f8-4270-b685-beb21e999fd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1719538497-172.17.0.4-1597293670292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46503,DS-eb388034-889b-4cd2-b4e1-18a9689b07a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-2f06882e-18b8-4149-ac39-62e0867cc64a,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-2fb394f3-d92e-4ac6-8c94-cd24e5e57c50,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-bb55d7f3-6d6f-4297-8d57-4549daf9654c,DISK], DatanodeInfoWithStorage[127.0.0.1:42347,DS-9bcdb732-ef69-40ce-b22d-f94efb734731,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-cae1e436-c934-46be-b662-6cbeb26d06cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-d744d6a4-7b81-4378-96d8-d27b4c6d4205,DISK], DatanodeInfoWithStorage[127.0.0.1:43173,DS-6a11d43e-8f5f-452b-b046-092919ae6a85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1719538497-172.17.0.4-1597293670292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46503,DS-eb388034-889b-4cd2-b4e1-18a9689b07a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-2f06882e-18b8-4149-ac39-62e0867cc64a,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-2fb394f3-d92e-4ac6-8c94-cd24e5e57c50,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-bb55d7f3-6d6f-4297-8d57-4549daf9654c,DISK], DatanodeInfoWithStorage[127.0.0.1:42347,DS-9bcdb732-ef69-40ce-b22d-f94efb734731,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-cae1e436-c934-46be-b662-6cbeb26d06cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-d744d6a4-7b81-4378-96d8-d27b4c6d4205,DISK], DatanodeInfoWithStorage[127.0.0.1:43173,DS-6a11d43e-8f5f-452b-b046-092919ae6a85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1108240090-172.17.0.4-1597294000236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43972,DS-bb5aed38-8706-4978-9c41-4242ffeca4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-08630a3e-d6d9-4501-96e1-b535530b45c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34786,DS-50880319-b85a-4483-bf08-beae83527dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-7d30db3f-999d-4483-979a-eb57afb9387a,DISK], DatanodeInfoWithStorage[127.0.0.1:38722,DS-f1ea0c02-aca5-421e-a474-477d4bf05b13,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-3d40d679-ea40-4eb2-92fb-1897d5687003,DISK], DatanodeInfoWithStorage[127.0.0.1:43213,DS-d68f3ed7-95a8-420d-82f0-e30d3dc59a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-dff644a0-4db4-4af0-91ab-3cf394fd5d43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1108240090-172.17.0.4-1597294000236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43972,DS-bb5aed38-8706-4978-9c41-4242ffeca4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-08630a3e-d6d9-4501-96e1-b535530b45c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34786,DS-50880319-b85a-4483-bf08-beae83527dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-7d30db3f-999d-4483-979a-eb57afb9387a,DISK], DatanodeInfoWithStorage[127.0.0.1:38722,DS-f1ea0c02-aca5-421e-a474-477d4bf05b13,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-3d40d679-ea40-4eb2-92fb-1897d5687003,DISK], DatanodeInfoWithStorage[127.0.0.1:43213,DS-d68f3ed7-95a8-420d-82f0-e30d3dc59a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-dff644a0-4db4-4af0-91ab-3cf394fd5d43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: might be true error
Total execution time in seconds : 5711
