reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1053576608-172.17.0.15-1597409529067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42788,DS-1cf07ce2-c82d-4a0d-b837-9fa030569e16,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-d3e0e502-b9c2-49c6-bc48-7e2b048f530b,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-35abaa0e-9435-40cf-b735-4e515bc70059,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-44c75371-09d9-4935-a89f-618b98391f48,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-d5a7b232-ebab-4c3d-829e-30957e9e3424,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-cc05eeea-7f00-4805-877d-22ffeb86d226,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-df3a13b0-569f-4b7b-bd2a-1fc3dd87e3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-b3bec3a3-d106-490a-b86e-e97afa8b9dca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1053576608-172.17.0.15-1597409529067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42788,DS-1cf07ce2-c82d-4a0d-b837-9fa030569e16,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-d3e0e502-b9c2-49c6-bc48-7e2b048f530b,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-35abaa0e-9435-40cf-b735-4e515bc70059,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-44c75371-09d9-4935-a89f-618b98391f48,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-d5a7b232-ebab-4c3d-829e-30957e9e3424,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-cc05eeea-7f00-4805-877d-22ffeb86d226,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-df3a13b0-569f-4b7b-bd2a-1fc3dd87e3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-b3bec3a3-d106-490a-b86e-e97afa8b9dca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980785037-172.17.0.15-1597409797477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39062,DS-0d1b7ce4-23b4-413c-8329-f0bd8aea1f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-608ee5dc-8d52-4d48-a31b-f6178d5dbcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-91a13678-0775-4ea1-9226-afb8e0f154a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-c2978361-daed-44ac-93e9-874cb3753c70,DISK], DatanodeInfoWithStorage[127.0.0.1:46364,DS-b6175e3e-ef9a-48c6-9917-f20ea5966c09,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-ee8a789e-8733-4570-b520-b18b1c94f143,DISK], DatanodeInfoWithStorage[127.0.0.1:36040,DS-281b38b7-eb6d-483d-a298-5d82bda61d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-90e7e7fc-98fc-41d4-ae1a-5de302f417e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980785037-172.17.0.15-1597409797477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39062,DS-0d1b7ce4-23b4-413c-8329-f0bd8aea1f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-608ee5dc-8d52-4d48-a31b-f6178d5dbcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-91a13678-0775-4ea1-9226-afb8e0f154a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-c2978361-daed-44ac-93e9-874cb3753c70,DISK], DatanodeInfoWithStorage[127.0.0.1:46364,DS-b6175e3e-ef9a-48c6-9917-f20ea5966c09,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-ee8a789e-8733-4570-b520-b18b1c94f143,DISK], DatanodeInfoWithStorage[127.0.0.1:36040,DS-281b38b7-eb6d-483d-a298-5d82bda61d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-90e7e7fc-98fc-41d4-ae1a-5de302f417e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1375347689-172.17.0.15-1597410139206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37356,DS-40ae6c50-adf5-48a5-978d-44faae85fd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-b36042ed-3924-4d3a-a1f0-c51ef8de253e,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-86ccf304-b929-4694-a96a-d158e71c7dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-203cb7de-ce74-412f-b6df-e653b89c1208,DISK], DatanodeInfoWithStorage[127.0.0.1:39734,DS-bb48d9e0-b07d-4873-8114-83f9151e497b,DISK], DatanodeInfoWithStorage[127.0.0.1:34402,DS-cd4ebea5-d5ef-4bc6-ac6f-a052472612ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-f88fa66d-0dc2-4397-bfcc-0f9acb3a1183,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-10199a8e-3d9c-4b82-b871-d0faa722e9ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1375347689-172.17.0.15-1597410139206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37356,DS-40ae6c50-adf5-48a5-978d-44faae85fd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-b36042ed-3924-4d3a-a1f0-c51ef8de253e,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-86ccf304-b929-4694-a96a-d158e71c7dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-203cb7de-ce74-412f-b6df-e653b89c1208,DISK], DatanodeInfoWithStorage[127.0.0.1:39734,DS-bb48d9e0-b07d-4873-8114-83f9151e497b,DISK], DatanodeInfoWithStorage[127.0.0.1:34402,DS-cd4ebea5-d5ef-4bc6-ac6f-a052472612ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-f88fa66d-0dc2-4397-bfcc-0f9acb3a1183,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-10199a8e-3d9c-4b82-b871-d0faa722e9ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-10751505-172.17.0.15-1597410356138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38155,DS-6168aa6d-0eb4-423a-a4ea-12588b2df042,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-aa39a16c-2fe6-481e-8f22-a8f784bbb8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-7fdd4f40-73f1-4e2c-ab48-53562f71ef14,DISK], DatanodeInfoWithStorage[127.0.0.1:38951,DS-a0315378-1cd6-4196-8e58-bdfb251cbd00,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-24b93a2d-1f2e-4a1e-8d31-ac4b3c210d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-c61494a8-3be2-481d-8fac-d32fb3fe199d,DISK], DatanodeInfoWithStorage[127.0.0.1:34377,DS-e15539e5-5c7a-4458-9bc3-b53cb04e34c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-90cec418-47e3-494e-8702-89f717b07273,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-10751505-172.17.0.15-1597410356138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38155,DS-6168aa6d-0eb4-423a-a4ea-12588b2df042,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-aa39a16c-2fe6-481e-8f22-a8f784bbb8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-7fdd4f40-73f1-4e2c-ab48-53562f71ef14,DISK], DatanodeInfoWithStorage[127.0.0.1:38951,DS-a0315378-1cd6-4196-8e58-bdfb251cbd00,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-24b93a2d-1f2e-4a1e-8d31-ac4b3c210d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-c61494a8-3be2-481d-8fac-d32fb3fe199d,DISK], DatanodeInfoWithStorage[127.0.0.1:34377,DS-e15539e5-5c7a-4458-9bc3-b53cb04e34c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-90cec418-47e3-494e-8702-89f717b07273,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-273831910-172.17.0.15-1597410389423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43219,DS-95830620-8a5b-47a1-9c9d-a7efc51ecb38,DISK], DatanodeInfoWithStorage[127.0.0.1:38596,DS-be745a00-41ba-4438-b638-2df23245af93,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-9025a092-2e15-4341-b563-9bd2ce73f15f,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-49627abf-ecf2-418d-bb71-1981f82b4067,DISK], DatanodeInfoWithStorage[127.0.0.1:42167,DS-f45f3445-e107-439e-bf64-d9b2229ece0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-a3e1cee9-294c-44b9-b2d9-aa9de557b56e,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-db71d39b-8ee6-4fa4-b805-e7d1b7fb3e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-324ef671-6a9b-48ca-92e1-d375acf18a23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-273831910-172.17.0.15-1597410389423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43219,DS-95830620-8a5b-47a1-9c9d-a7efc51ecb38,DISK], DatanodeInfoWithStorage[127.0.0.1:38596,DS-be745a00-41ba-4438-b638-2df23245af93,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-9025a092-2e15-4341-b563-9bd2ce73f15f,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-49627abf-ecf2-418d-bb71-1981f82b4067,DISK], DatanodeInfoWithStorage[127.0.0.1:42167,DS-f45f3445-e107-439e-bf64-d9b2229ece0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-a3e1cee9-294c-44b9-b2d9-aa9de557b56e,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-db71d39b-8ee6-4fa4-b805-e7d1b7fb3e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-324ef671-6a9b-48ca-92e1-d375acf18a23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1727926019-172.17.0.15-1597410459243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37513,DS-149656cb-262a-4617-b1b7-b89f5d6ebd71,DISK], DatanodeInfoWithStorage[127.0.0.1:40454,DS-3caee145-92c6-433f-be32-c40feca6448b,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-109db8ac-5ad4-4b57-9426-be025c4d7c89,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-1019ac3c-aa50-439c-afe3-2af7585e533f,DISK], DatanodeInfoWithStorage[127.0.0.1:42890,DS-3a20ec2e-623d-4213-a1c1-430da1fc78b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-0312c7c0-e374-4275-ada6-9aeb49fb8add,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-54b6d766-9729-4d60-b70b-366f2feb6542,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-c1cd56a3-1422-405f-834d-7d01f38e0455,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1727926019-172.17.0.15-1597410459243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37513,DS-149656cb-262a-4617-b1b7-b89f5d6ebd71,DISK], DatanodeInfoWithStorage[127.0.0.1:40454,DS-3caee145-92c6-433f-be32-c40feca6448b,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-109db8ac-5ad4-4b57-9426-be025c4d7c89,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-1019ac3c-aa50-439c-afe3-2af7585e533f,DISK], DatanodeInfoWithStorage[127.0.0.1:42890,DS-3a20ec2e-623d-4213-a1c1-430da1fc78b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-0312c7c0-e374-4275-ada6-9aeb49fb8add,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-54b6d766-9729-4d60-b70b-366f2feb6542,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-c1cd56a3-1422-405f-834d-7d01f38e0455,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-319827119-172.17.0.15-1597410681778:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44054,DS-ba6679b8-ba33-4453-a179-af90d34bbd82,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-65d34ef2-d08e-4b2e-85ff-5646897216de,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-8fbad5f8-3f99-4bc4-b17d-8eb29b7731a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-96bff403-9747-44e8-a31e-a07a6abd9882,DISK], DatanodeInfoWithStorage[127.0.0.1:35235,DS-c992626a-39ea-4f5f-9619-507eb92766e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-73f01c02-c11e-4145-8b4f-5c1aa0c2887c,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-bcda186d-174b-4248-85c9-d470a3d51e43,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-34c3ab68-e54b-4429-b346-605b05b9952d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-319827119-172.17.0.15-1597410681778:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44054,DS-ba6679b8-ba33-4453-a179-af90d34bbd82,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-65d34ef2-d08e-4b2e-85ff-5646897216de,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-8fbad5f8-3f99-4bc4-b17d-8eb29b7731a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-96bff403-9747-44e8-a31e-a07a6abd9882,DISK], DatanodeInfoWithStorage[127.0.0.1:35235,DS-c992626a-39ea-4f5f-9619-507eb92766e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-73f01c02-c11e-4145-8b4f-5c1aa0c2887c,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-bcda186d-174b-4248-85c9-d470a3d51e43,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-34c3ab68-e54b-4429-b346-605b05b9952d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1724093083-172.17.0.15-1597410902595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45912,DS-c48b10e8-2de2-4409-bd6d-b0b46e34540c,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-13e7cc54-2860-4eef-b8ee-57a500faed3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36578,DS-245b66ae-7b0c-48c9-96a8-1d9b23feb942,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-f6ef002e-26d2-4288-8c84-619a7b1d2aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-07b2ea70-7dbb-418d-ba71-6a63ab1f6714,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-7ae13ffa-1a55-45a1-8c02-5745e553b46f,DISK], DatanodeInfoWithStorage[127.0.0.1:37744,DS-74153b8f-0a26-4ecd-973b-235f2a9b3873,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-d95d3884-8c05-43fa-afa0-e49bdebed605,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1724093083-172.17.0.15-1597410902595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45912,DS-c48b10e8-2de2-4409-bd6d-b0b46e34540c,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-13e7cc54-2860-4eef-b8ee-57a500faed3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36578,DS-245b66ae-7b0c-48c9-96a8-1d9b23feb942,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-f6ef002e-26d2-4288-8c84-619a7b1d2aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-07b2ea70-7dbb-418d-ba71-6a63ab1f6714,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-7ae13ffa-1a55-45a1-8c02-5745e553b46f,DISK], DatanodeInfoWithStorage[127.0.0.1:37744,DS-74153b8f-0a26-4ecd-973b-235f2a9b3873,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-d95d3884-8c05-43fa-afa0-e49bdebed605,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1966865845-172.17.0.15-1597411218540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40931,DS-f4b2dbc5-83a5-4eb6-a084-c307d8573624,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-7bcebd87-2e72-40e0-bb10-5ec174ab3336,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-9911faf0-1edc-4c2b-9c1b-1920e195023d,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-940d47c8-d75e-4c83-94ce-8c8af5180498,DISK], DatanodeInfoWithStorage[127.0.0.1:34768,DS-2772f0c8-4ae7-47bd-9bfc-d9547bfebd5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-c8a80aff-cd6b-49f9-acfc-412fdc0aeb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35926,DS-1ddadc99-9ccb-4a96-835b-8583e0a0a708,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-4a7074f4-1b8f-4981-9af2-a94ea74e381c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1966865845-172.17.0.15-1597411218540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40931,DS-f4b2dbc5-83a5-4eb6-a084-c307d8573624,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-7bcebd87-2e72-40e0-bb10-5ec174ab3336,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-9911faf0-1edc-4c2b-9c1b-1920e195023d,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-940d47c8-d75e-4c83-94ce-8c8af5180498,DISK], DatanodeInfoWithStorage[127.0.0.1:34768,DS-2772f0c8-4ae7-47bd-9bfc-d9547bfebd5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-c8a80aff-cd6b-49f9-acfc-412fdc0aeb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35926,DS-1ddadc99-9ccb-4a96-835b-8583e0a0a708,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-4a7074f4-1b8f-4981-9af2-a94ea74e381c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1385811124-172.17.0.15-1597411488561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44065,DS-ca6f8359-bedd-43d9-866d-807a441ec4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-61d6e246-88e2-4952-bd0a-c1fb09e5018a,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-a32eae06-4d10-4ad8-9bce-56196a5d56d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-d95fc933-6816-41d8-a479-742251efd2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-355392b4-2ee6-424b-9d56-6d9f43eac1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-3d722065-6120-4f5e-b956-ce4a370ec23c,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-384348c5-cb7c-4a15-b581-fdf3deb5d33f,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-0d0d3d3f-04dd-4586-940a-98e8dbe4f0b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1385811124-172.17.0.15-1597411488561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44065,DS-ca6f8359-bedd-43d9-866d-807a441ec4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-61d6e246-88e2-4952-bd0a-c1fb09e5018a,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-a32eae06-4d10-4ad8-9bce-56196a5d56d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-d95fc933-6816-41d8-a479-742251efd2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-355392b4-2ee6-424b-9d56-6d9f43eac1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-3d722065-6120-4f5e-b956-ce4a370ec23c,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-384348c5-cb7c-4a15-b581-fdf3deb5d33f,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-0d0d3d3f-04dd-4586-940a-98e8dbe4f0b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1470480474-172.17.0.15-1597411524060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40314,DS-63061115-539b-4499-a6bc-2a8af064ef62,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-fb542b37-bce7-4fd7-ba52-ef6a067c5fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-b7130702-2244-4a77-a2d0-ebeafa49979c,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-340d4e77-48ac-4c26-a935-81a498139eae,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-a49e5ef4-802d-4346-9b0b-316e4a584dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:33038,DS-f2acd14c-c108-40bd-bf85-e0bfbd47a607,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-32b74a1b-ceb7-4dc9-951b-db78253bfebb,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-84b11262-69e4-45b0-9fcc-1e15d3f8099d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1470480474-172.17.0.15-1597411524060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40314,DS-63061115-539b-4499-a6bc-2a8af064ef62,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-fb542b37-bce7-4fd7-ba52-ef6a067c5fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-b7130702-2244-4a77-a2d0-ebeafa49979c,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-340d4e77-48ac-4c26-a935-81a498139eae,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-a49e5ef4-802d-4346-9b0b-316e4a584dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:33038,DS-f2acd14c-c108-40bd-bf85-e0bfbd47a607,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-32b74a1b-ceb7-4dc9-951b-db78253bfebb,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-84b11262-69e4-45b0-9fcc-1e15d3f8099d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2025032541-172.17.0.15-1597413074610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37411,DS-78eab106-072e-472d-ac59-c95fb18ff51f,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-efc3b6cd-39bb-4e24-a358-aa592bd24850,DISK], DatanodeInfoWithStorage[127.0.0.1:44906,DS-e8815124-f579-48d5-b33b-3c19b54d6db2,DISK], DatanodeInfoWithStorage[127.0.0.1:43690,DS-70babc70-c1aa-4726-a100-14e94141c815,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-97e3bb5e-d180-44da-8ada-d8aafabf9168,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-c01d9387-5c1c-4b97-b31a-e0df001aa3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-12013ebd-b0e9-4af7-84d6-9f1812dcd274,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-52f22c1c-34cb-4416-b92b-44853603a087,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2025032541-172.17.0.15-1597413074610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37411,DS-78eab106-072e-472d-ac59-c95fb18ff51f,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-efc3b6cd-39bb-4e24-a358-aa592bd24850,DISK], DatanodeInfoWithStorage[127.0.0.1:44906,DS-e8815124-f579-48d5-b33b-3c19b54d6db2,DISK], DatanodeInfoWithStorage[127.0.0.1:43690,DS-70babc70-c1aa-4726-a100-14e94141c815,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-97e3bb5e-d180-44da-8ada-d8aafabf9168,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-c01d9387-5c1c-4b97-b31a-e0df001aa3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-12013ebd-b0e9-4af7-84d6-9f1812dcd274,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-52f22c1c-34cb-4416-b92b-44853603a087,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1021913704-172.17.0.15-1597413294465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39116,DS-3f655ddf-dd2e-4933-99b4-ff618fd1cdcc,DISK], DatanodeInfoWithStorage[127.0.0.1:42290,DS-63a3f211-9c1f-4113-a27f-e973c1cfe0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44419,DS-556d41a7-6df8-4c19-99f7-40f41c4985c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-05312718-36a8-4ca8-95f3-37bcf0c76965,DISK], DatanodeInfoWithStorage[127.0.0.1:38967,DS-7b829201-d6f8-4e39-b1ed-8c91408f331f,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-83444e36-f3b7-4eda-bdbe-e4dbc618816a,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-6df90bce-acca-4c09-bff4-33007f7b61fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33635,DS-ff873c5d-0591-4f13-9728-d5f8a83f9fcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1021913704-172.17.0.15-1597413294465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39116,DS-3f655ddf-dd2e-4933-99b4-ff618fd1cdcc,DISK], DatanodeInfoWithStorage[127.0.0.1:42290,DS-63a3f211-9c1f-4113-a27f-e973c1cfe0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44419,DS-556d41a7-6df8-4c19-99f7-40f41c4985c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-05312718-36a8-4ca8-95f3-37bcf0c76965,DISK], DatanodeInfoWithStorage[127.0.0.1:38967,DS-7b829201-d6f8-4e39-b1ed-8c91408f331f,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-83444e36-f3b7-4eda-bdbe-e4dbc618816a,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-6df90bce-acca-4c09-bff4-33007f7b61fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33635,DS-ff873c5d-0591-4f13-9728-d5f8a83f9fcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-929201378-172.17.0.15-1597413656804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44601,DS-74e71192-d1cd-4cda-a489-c0b374dcd656,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-de21a635-85e4-4ae8-986d-41d028777149,DISK], DatanodeInfoWithStorage[127.0.0.1:33163,DS-76529268-dafd-4a74-978e-66d43200b3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-6278f3ae-5456-4bb7-8e28-ec94ac205061,DISK], DatanodeInfoWithStorage[127.0.0.1:39566,DS-127388e2-f32f-4ec8-99af-fc3f4c931b33,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-375cc20f-8b5a-455c-a279-59224854fa62,DISK], DatanodeInfoWithStorage[127.0.0.1:42808,DS-606e6e86-9bd0-46d9-99da-eec6f558b42b,DISK], DatanodeInfoWithStorage[127.0.0.1:38470,DS-bf239b0a-0034-4980-8f72-7bcca16cd0bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-929201378-172.17.0.15-1597413656804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44601,DS-74e71192-d1cd-4cda-a489-c0b374dcd656,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-de21a635-85e4-4ae8-986d-41d028777149,DISK], DatanodeInfoWithStorage[127.0.0.1:33163,DS-76529268-dafd-4a74-978e-66d43200b3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-6278f3ae-5456-4bb7-8e28-ec94ac205061,DISK], DatanodeInfoWithStorage[127.0.0.1:39566,DS-127388e2-f32f-4ec8-99af-fc3f4c931b33,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-375cc20f-8b5a-455c-a279-59224854fa62,DISK], DatanodeInfoWithStorage[127.0.0.1:42808,DS-606e6e86-9bd0-46d9-99da-eec6f558b42b,DISK], DatanodeInfoWithStorage[127.0.0.1:38470,DS-bf239b0a-0034-4980-8f72-7bcca16cd0bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-102060553-172.17.0.15-1597413849593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33575,DS-3c4aaa67-e1b6-4da9-be87-6648d9dd2963,DISK], DatanodeInfoWithStorage[127.0.0.1:38595,DS-c9e0f73d-36c1-4363-bb9e-12713b85c2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-2583a9c0-c698-4c44-8d6f-fbdcbcd7c56c,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-c9e5f547-cbea-404f-a306-b9d7e4035ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:39785,DS-9865b8f5-a349-4a56-9298-a88e1d9a4bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-88023bf5-51c6-4ba6-9aa6-110eb8c4328b,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-ed1d2972-86dd-4c51-a4ba-27612a4c3dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-dfa11777-6273-46dd-93e5-c58524ff8a78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-102060553-172.17.0.15-1597413849593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33575,DS-3c4aaa67-e1b6-4da9-be87-6648d9dd2963,DISK], DatanodeInfoWithStorage[127.0.0.1:38595,DS-c9e0f73d-36c1-4363-bb9e-12713b85c2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-2583a9c0-c698-4c44-8d6f-fbdcbcd7c56c,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-c9e5f547-cbea-404f-a306-b9d7e4035ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:39785,DS-9865b8f5-a349-4a56-9298-a88e1d9a4bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-88023bf5-51c6-4ba6-9aa6-110eb8c4328b,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-ed1d2972-86dd-4c51-a4ba-27612a4c3dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-dfa11777-6273-46dd-93e5-c58524ff8a78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-863401067-172.17.0.15-1597413914391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34310,DS-4102860f-02f7-4966-ae0c-e16ae08665a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-5dde8730-7991-4063-938b-0594a676e793,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-507f18d7-bbe1-4625-8a9d-eb1919af3749,DISK], DatanodeInfoWithStorage[127.0.0.1:33171,DS-64eef73c-ec0b-4f6d-a29f-bfb3e396116b,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-c55feeb5-d5dc-4dfa-af7b-6c2847c40c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-88dbf8ac-7950-43de-8637-0982bda712a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-58e4048b-88b3-4113-b7d7-e3c0960d864a,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-54f20620-9b3c-4752-ae1b-55b71787db0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-863401067-172.17.0.15-1597413914391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34310,DS-4102860f-02f7-4966-ae0c-e16ae08665a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-5dde8730-7991-4063-938b-0594a676e793,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-507f18d7-bbe1-4625-8a9d-eb1919af3749,DISK], DatanodeInfoWithStorage[127.0.0.1:33171,DS-64eef73c-ec0b-4f6d-a29f-bfb3e396116b,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-c55feeb5-d5dc-4dfa-af7b-6c2847c40c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-88dbf8ac-7950-43de-8637-0982bda712a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-58e4048b-88b3-4113-b7d7-e3c0960d864a,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-54f20620-9b3c-4752-ae1b-55b71787db0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-315647107-172.17.0.15-1597414414932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44821,DS-28b763c1-2433-454b-9232-bf353779d7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-30e92095-55b3-456a-ab71-4be7571ef44d,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-ef8c9d27-5c81-4e59-b5cf-7e71c1589daa,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-1780d99d-344b-42f9-bb2f-58769553689c,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-058a833f-0379-4af4-8bb6-77949ef89be9,DISK], DatanodeInfoWithStorage[127.0.0.1:36209,DS-c0807291-1da9-485d-8c16-80adfc9336ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-6c649086-36b2-462b-a8e4-19df60bba790,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-c46f19f9-185d-4fb5-b2a1-89ebeb43f699,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-315647107-172.17.0.15-1597414414932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44821,DS-28b763c1-2433-454b-9232-bf353779d7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-30e92095-55b3-456a-ab71-4be7571ef44d,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-ef8c9d27-5c81-4e59-b5cf-7e71c1589daa,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-1780d99d-344b-42f9-bb2f-58769553689c,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-058a833f-0379-4af4-8bb6-77949ef89be9,DISK], DatanodeInfoWithStorage[127.0.0.1:36209,DS-c0807291-1da9-485d-8c16-80adfc9336ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-6c649086-36b2-462b-a8e4-19df60bba790,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-c46f19f9-185d-4fb5-b2a1-89ebeb43f699,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: might be true error
Total execution time in seconds : 5468
