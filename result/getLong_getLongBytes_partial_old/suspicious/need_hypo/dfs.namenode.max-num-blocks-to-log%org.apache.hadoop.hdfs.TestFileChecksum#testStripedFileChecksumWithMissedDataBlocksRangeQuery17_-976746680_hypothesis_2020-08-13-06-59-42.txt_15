reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-626830921-172.17.0.12-1597302841886:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39906,DS-b7e1e880-21c5-4fb5-8c8a-5090af588fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-8f751e52-f411-48e4-907d-8cfb543779be,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-508d497d-8e4c-4aca-991d-8ef3ff4b129e,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-f45d8c9d-3483-4b4a-8921-1a73202af4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-8bdd0423-f383-4c2d-8934-2b32b8f99a22,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-134f62d4-f31c-40e2-b286-07fb26abcb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-7ae46f20-17d7-4ad2-80e4-a7a028f88b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-23dca286-0211-4382-ab8d-44ec64c03113,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-626830921-172.17.0.12-1597302841886:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39906,DS-b7e1e880-21c5-4fb5-8c8a-5090af588fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-8f751e52-f411-48e4-907d-8cfb543779be,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-508d497d-8e4c-4aca-991d-8ef3ff4b129e,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-f45d8c9d-3483-4b4a-8921-1a73202af4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-8bdd0423-f383-4c2d-8934-2b32b8f99a22,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-134f62d4-f31c-40e2-b286-07fb26abcb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-7ae46f20-17d7-4ad2-80e4-a7a028f88b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-23dca286-0211-4382-ab8d-44ec64c03113,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1736459585-172.17.0.12-1597302870865:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38592,DS-32dd40e7-6d2d-4963-875c-8e33f20d2fce,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-ff8c0c6f-b8e1-43e5-9eb0-34fbfd1be083,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-31b10a4b-78a0-4d16-be04-63e4768b2388,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-d1c6a0ac-5b2a-4ff5-a484-6413a77848ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-cd78e1a5-631d-4612-8a0f-2b959b12da20,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-42d32628-fc00-40eb-ace8-e71646c4ca9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-16a0e6e5-7e61-4e20-99ed-e3b3fa5ed679,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-07f2a3cd-30c0-4b23-9c6a-91389c42faf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1736459585-172.17.0.12-1597302870865:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38592,DS-32dd40e7-6d2d-4963-875c-8e33f20d2fce,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-ff8c0c6f-b8e1-43e5-9eb0-34fbfd1be083,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-31b10a4b-78a0-4d16-be04-63e4768b2388,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-d1c6a0ac-5b2a-4ff5-a484-6413a77848ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-cd78e1a5-631d-4612-8a0f-2b959b12da20,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-42d32628-fc00-40eb-ace8-e71646c4ca9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-16a0e6e5-7e61-4e20-99ed-e3b3fa5ed679,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-07f2a3cd-30c0-4b23-9c6a-91389c42faf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-175061454-172.17.0.12-1597303095291:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37392,DS-c1375275-fa05-4659-a65c-57e8f9bc494b,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-2d5dd0c0-f14c-4213-9412-0590306a303e,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-7c3ab60b-d3e0-450a-91f0-a0b1541796bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-f2f81f5f-20c7-4b71-81f6-485b27eaee1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-65f3bd53-e8c4-4ed7-889d-f8d013b9b207,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-0c73d808-2436-4943-98ec-f7fa0a2d6e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-fdd62631-f314-4660-bcc5-d151aed87db5,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-9ffb9693-214f-4772-bf2d-33f9dd51e498,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-175061454-172.17.0.12-1597303095291:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37392,DS-c1375275-fa05-4659-a65c-57e8f9bc494b,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-2d5dd0c0-f14c-4213-9412-0590306a303e,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-7c3ab60b-d3e0-450a-91f0-a0b1541796bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-f2f81f5f-20c7-4b71-81f6-485b27eaee1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-65f3bd53-e8c4-4ed7-889d-f8d013b9b207,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-0c73d808-2436-4943-98ec-f7fa0a2d6e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-fdd62631-f314-4660-bcc5-d151aed87db5,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-9ffb9693-214f-4772-bf2d-33f9dd51e498,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-671832580-172.17.0.12-1597303210220:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44429,DS-73ce9958-49fc-4109-8270-c8181b07025c,DISK], DatanodeInfoWithStorage[127.0.0.1:40283,DS-55671437-743b-4ead-af70-84884cd7d885,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-c7838b2e-8bcb-47db-9a3f-0cd293be3617,DISK], DatanodeInfoWithStorage[127.0.0.1:43989,DS-6a540c93-e046-4d08-b39a-5ccd151cc536,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-8cb15d96-a0e5-4827-bbe7-bd1423fad8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-7319c559-d7aa-4f10-9769-e136da31fbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-4453e30a-f591-4759-bb72-15396205be61,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-825d2fb1-5b94-4b5c-8b24-0a7970e19a9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-671832580-172.17.0.12-1597303210220:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44429,DS-73ce9958-49fc-4109-8270-c8181b07025c,DISK], DatanodeInfoWithStorage[127.0.0.1:40283,DS-55671437-743b-4ead-af70-84884cd7d885,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-c7838b2e-8bcb-47db-9a3f-0cd293be3617,DISK], DatanodeInfoWithStorage[127.0.0.1:43989,DS-6a540c93-e046-4d08-b39a-5ccd151cc536,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-8cb15d96-a0e5-4827-bbe7-bd1423fad8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-7319c559-d7aa-4f10-9769-e136da31fbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-4453e30a-f591-4759-bb72-15396205be61,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-825d2fb1-5b94-4b5c-8b24-0a7970e19a9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2028931663-172.17.0.12-1597303328937:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41542,DS-ca28c4df-5cbf-4b3c-b46b-0d1d1e6dbe5c,DISK], DatanodeInfoWithStorage[127.0.0.1:32983,DS-562fc093-286b-44af-b20b-eb28f91709ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43226,DS-525ac4e7-ac77-4f29-8dcf-0df7fce67a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34725,DS-ba3b4ec6-9197-43f6-8334-f4aa0bc6570b,DISK], DatanodeInfoWithStorage[127.0.0.1:36565,DS-15209946-5c5a-4ec0-8d6d-8606fa81ae6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-2c4dcd77-30f0-45fb-b184-03bf10ceb639,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-dd920e02-8095-451d-935e-837654b97824,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-8a8d7861-e393-448b-961c-0e3ce292220f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2028931663-172.17.0.12-1597303328937:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41542,DS-ca28c4df-5cbf-4b3c-b46b-0d1d1e6dbe5c,DISK], DatanodeInfoWithStorage[127.0.0.1:32983,DS-562fc093-286b-44af-b20b-eb28f91709ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43226,DS-525ac4e7-ac77-4f29-8dcf-0df7fce67a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34725,DS-ba3b4ec6-9197-43f6-8334-f4aa0bc6570b,DISK], DatanodeInfoWithStorage[127.0.0.1:36565,DS-15209946-5c5a-4ec0-8d6d-8606fa81ae6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-2c4dcd77-30f0-45fb-b184-03bf10ceb639,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-dd920e02-8095-451d-935e-837654b97824,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-8a8d7861-e393-448b-961c-0e3ce292220f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-468855767-172.17.0.12-1597303660309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41459,DS-5309128e-e262-4e67-8c97-da61fdee229e,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-ca8db7e1-73b2-4542-af0a-3e3f8b9fc183,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-1cc6aca8-c1c0-45f1-8cf6-2c4ede3abdb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-e9402d6f-599b-4f33-ba30-ef42cfd3f8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-429772eb-1bcd-41fc-906d-2c775f33f926,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-2349d1c1-31c2-4057-9b0b-3dc6892b686b,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-3b031242-adca-4182-ab6f-4a54835be842,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-9a68e82a-1720-4dfd-a173-86a992d3714a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-468855767-172.17.0.12-1597303660309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41459,DS-5309128e-e262-4e67-8c97-da61fdee229e,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-ca8db7e1-73b2-4542-af0a-3e3f8b9fc183,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-1cc6aca8-c1c0-45f1-8cf6-2c4ede3abdb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-e9402d6f-599b-4f33-ba30-ef42cfd3f8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-429772eb-1bcd-41fc-906d-2c775f33f926,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-2349d1c1-31c2-4057-9b0b-3dc6892b686b,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-3b031242-adca-4182-ab6f-4a54835be842,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-9a68e82a-1720-4dfd-a173-86a992d3714a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-384651021-172.17.0.12-1597303802481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34318,DS-13dbe3be-1b8b-471f-b9ab-fc3b241f4f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-ea4ad843-a3f9-44fb-b75e-120218d71b53,DISK], DatanodeInfoWithStorage[127.0.0.1:34751,DS-25a6dd87-10a3-4aac-b8d6-ee5abdd6eb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-b9f91765-e5de-4bfb-b934-08ae4c6dfd44,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-ec205d42-a0a2-49c9-923f-c90312840e88,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-4b526f78-27af-4396-9d4c-1661f6452725,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-2c93a44e-426d-427b-8167-f87f27ee8a61,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-11327168-4683-4d1c-933d-807d8dbb6484,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-384651021-172.17.0.12-1597303802481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34318,DS-13dbe3be-1b8b-471f-b9ab-fc3b241f4f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-ea4ad843-a3f9-44fb-b75e-120218d71b53,DISK], DatanodeInfoWithStorage[127.0.0.1:34751,DS-25a6dd87-10a3-4aac-b8d6-ee5abdd6eb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-b9f91765-e5de-4bfb-b934-08ae4c6dfd44,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-ec205d42-a0a2-49c9-923f-c90312840e88,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-4b526f78-27af-4396-9d4c-1661f6452725,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-2c93a44e-426d-427b-8167-f87f27ee8a61,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-11327168-4683-4d1c-933d-807d8dbb6484,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-554813952-172.17.0.12-1597303838831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46195,DS-570170b4-2337-4a56-9e74-f17b93a75211,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-3e651a1e-a5f2-44d8-9423-f88a2efefe5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-d688570a-ecd7-4fe1-8e93-d994bb37db7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-748dc356-f06e-4016-ab4e-3d9fbd3c7034,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-135764dd-0b39-4c40-9f5c-c45ecd0a4ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:41545,DS-b24c02e1-b111-423f-b094-a215f858ca84,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-c1e2de05-8f6c-43ad-8113-d17b1ed42664,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-4c7f238f-b121-41b6-a883-ace5515ed1ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-554813952-172.17.0.12-1597303838831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46195,DS-570170b4-2337-4a56-9e74-f17b93a75211,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-3e651a1e-a5f2-44d8-9423-f88a2efefe5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-d688570a-ecd7-4fe1-8e93-d994bb37db7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-748dc356-f06e-4016-ab4e-3d9fbd3c7034,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-135764dd-0b39-4c40-9f5c-c45ecd0a4ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:41545,DS-b24c02e1-b111-423f-b094-a215f858ca84,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-c1e2de05-8f6c-43ad-8113-d17b1ed42664,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-4c7f238f-b121-41b6-a883-ace5515ed1ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2014483941-172.17.0.12-1597304438549:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42722,DS-b1f90596-f01f-44b1-9dcc-6f74ed386cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-c2be3e44-cf87-4373-904c-bb500b7c66b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-f82ab588-9b50-44a2-a6cf-9b75c87c9909,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-c0d81dc2-6adc-4d1a-a57f-601dc35d75d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-6b5e7e4c-6a2c-4276-944d-44ce6e7a7cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-6991080b-3802-4674-a14a-ad38704a707d,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-d83f6c81-5c0d-4aac-b22b-b7a10a1d5ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-9110b975-1510-4255-a6f5-0cbe00a5fc61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2014483941-172.17.0.12-1597304438549:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42722,DS-b1f90596-f01f-44b1-9dcc-6f74ed386cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-c2be3e44-cf87-4373-904c-bb500b7c66b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-f82ab588-9b50-44a2-a6cf-9b75c87c9909,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-c0d81dc2-6adc-4d1a-a57f-601dc35d75d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-6b5e7e4c-6a2c-4276-944d-44ce6e7a7cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-6991080b-3802-4674-a14a-ad38704a707d,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-d83f6c81-5c0d-4aac-b22b-b7a10a1d5ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-9110b975-1510-4255-a6f5-0cbe00a5fc61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-880915143-172.17.0.12-1597304736418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40820,DS-4a71ffc7-39d9-41c1-a402-36b927ac79a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39376,DS-f5c5b53a-9c65-4715-9fa1-a38ea4a6f8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-f76a9832-455a-4386-aff5-e4f2313ff608,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-b6aea796-e49e-46cf-a766-e881a921e346,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-971dc788-180d-4d7a-9230-ab728735af22,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-883cb858-2d92-42dc-9c5c-bf5bbd6c83d7,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-86845704-a169-4251-aabe-e02d3f3756ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-8821bad7-3470-4f3e-b311-bd688c620c60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-880915143-172.17.0.12-1597304736418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40820,DS-4a71ffc7-39d9-41c1-a402-36b927ac79a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39376,DS-f5c5b53a-9c65-4715-9fa1-a38ea4a6f8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-f76a9832-455a-4386-aff5-e4f2313ff608,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-b6aea796-e49e-46cf-a766-e881a921e346,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-971dc788-180d-4d7a-9230-ab728735af22,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-883cb858-2d92-42dc-9c5c-bf5bbd6c83d7,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-86845704-a169-4251-aabe-e02d3f3756ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-8821bad7-3470-4f3e-b311-bd688c620c60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1292772447-172.17.0.12-1597304892969:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37647,DS-e3300fc3-437e-4c3a-9cd9-d8f432aaac67,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-3dce76a6-599c-4d60-918c-496c8347d610,DISK], DatanodeInfoWithStorage[127.0.0.1:40226,DS-358314bc-5cd0-45db-beee-7a715bd27ada,DISK], DatanodeInfoWithStorage[127.0.0.1:40936,DS-a5f69d7f-2ff0-448f-bc84-67aecbb1d323,DISK], DatanodeInfoWithStorage[127.0.0.1:41842,DS-8dd41bc8-041f-4ae6-9a32-b06c6156dd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-131f4bcf-f526-466d-95eb-1f2eaad436a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-523b8bcb-25a7-42eb-996b-94009b162121,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-d430a720-c8f5-409b-90c8-fa083615ef8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1292772447-172.17.0.12-1597304892969:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37647,DS-e3300fc3-437e-4c3a-9cd9-d8f432aaac67,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-3dce76a6-599c-4d60-918c-496c8347d610,DISK], DatanodeInfoWithStorage[127.0.0.1:40226,DS-358314bc-5cd0-45db-beee-7a715bd27ada,DISK], DatanodeInfoWithStorage[127.0.0.1:40936,DS-a5f69d7f-2ff0-448f-bc84-67aecbb1d323,DISK], DatanodeInfoWithStorage[127.0.0.1:41842,DS-8dd41bc8-041f-4ae6-9a32-b06c6156dd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-131f4bcf-f526-466d-95eb-1f2eaad436a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-523b8bcb-25a7-42eb-996b-94009b162121,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-d430a720-c8f5-409b-90c8-fa083615ef8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-998466003-172.17.0.12-1597305361619:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43901,DS-dec748ac-e550-4b4c-8432-1612553c717c,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-4798e1e1-6cba-4178-a346-d16959c5b828,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-6ef3874f-745e-4545-a893-56ba59773aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-d9757787-e062-4237-bce4-260c038dc553,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-8ffc53de-5e99-4622-8c9f-ecbead62065b,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-0497e554-0351-49f8-a4a3-2410b6a1cc7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-b0a94a54-576b-43f7-9ca3-8913dfaa2a85,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-1c7ede4c-a0c2-4c0d-ba32-17044b4a8a72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-998466003-172.17.0.12-1597305361619:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43901,DS-dec748ac-e550-4b4c-8432-1612553c717c,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-4798e1e1-6cba-4178-a346-d16959c5b828,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-6ef3874f-745e-4545-a893-56ba59773aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-d9757787-e062-4237-bce4-260c038dc553,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-8ffc53de-5e99-4622-8c9f-ecbead62065b,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-0497e554-0351-49f8-a4a3-2410b6a1cc7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-b0a94a54-576b-43f7-9ca3-8913dfaa2a85,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-1c7ede4c-a0c2-4c0d-ba32-17044b4a8a72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1851699952-172.17.0.12-1597305508003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34390,DS-9b9fe440-56da-4cf5-953d-de630c626b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42990,DS-49582acc-b17d-47f5-b9f1-28bea1e89f31,DISK], DatanodeInfoWithStorage[127.0.0.1:40141,DS-d420d355-e8a6-4e58-903c-dc80cd99dcae,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-68a4eb6b-b821-4ad0-8a1c-daa247c2baec,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-cd75ef0e-ee67-44d7-ac31-be04fd13314f,DISK], DatanodeInfoWithStorage[127.0.0.1:38915,DS-b1b4fbf9-b0f0-447b-ba46-0920f8555cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-5f82c3a9-0da6-4f19-8578-f434dac15568,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-465fc72b-7194-4548-9b4d-e6fb354f1109,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1851699952-172.17.0.12-1597305508003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34390,DS-9b9fe440-56da-4cf5-953d-de630c626b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42990,DS-49582acc-b17d-47f5-b9f1-28bea1e89f31,DISK], DatanodeInfoWithStorage[127.0.0.1:40141,DS-d420d355-e8a6-4e58-903c-dc80cd99dcae,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-68a4eb6b-b821-4ad0-8a1c-daa247c2baec,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-cd75ef0e-ee67-44d7-ac31-be04fd13314f,DISK], DatanodeInfoWithStorage[127.0.0.1:38915,DS-b1b4fbf9-b0f0-447b-ba46-0920f8555cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-5f82c3a9-0da6-4f19-8578-f434dac15568,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-465fc72b-7194-4548-9b4d-e6fb354f1109,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1600330149-172.17.0.12-1597305606561:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45117,DS-d41ba086-1f64-4053-965d-82be4ac761b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-436c2590-3c47-4a55-b7f3-9d3f84b095d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38877,DS-f4ac7599-bde9-425b-83f3-1e6821b8e5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41109,DS-df1c28e5-82bc-412e-bc5c-c357f97a8a02,DISK], DatanodeInfoWithStorage[127.0.0.1:44900,DS-b2c36363-96d8-4412-bb87-ac409ddd43f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-254ef9c2-d15b-4a5a-9586-cfdfa1f13023,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-91458674-6739-435a-83db-144e5755b4a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-84400c76-3ef6-4bae-89bf-9a7428ec72b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1600330149-172.17.0.12-1597305606561:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45117,DS-d41ba086-1f64-4053-965d-82be4ac761b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-436c2590-3c47-4a55-b7f3-9d3f84b095d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38877,DS-f4ac7599-bde9-425b-83f3-1e6821b8e5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41109,DS-df1c28e5-82bc-412e-bc5c-c357f97a8a02,DISK], DatanodeInfoWithStorage[127.0.0.1:44900,DS-b2c36363-96d8-4412-bb87-ac409ddd43f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-254ef9c2-d15b-4a5a-9586-cfdfa1f13023,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-91458674-6739-435a-83db-144e5755b4a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-84400c76-3ef6-4bae-89bf-9a7428ec72b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1537033926-172.17.0.12-1597307070309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44157,DS-5222c7e5-22b9-4d0a-966f-449486b42b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-402f1a57-e578-4949-a5ff-bb898dd78a83,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-40661701-6085-486c-86c2-e96df285e754,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-4ca19ef5-8bdc-42e3-aad9-04d01b2da4da,DISK], DatanodeInfoWithStorage[127.0.0.1:36250,DS-636b7fc7-cc23-4e1d-aaa5-e7821b799bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-ccc4f6a0-6be6-4e62-a5e9-0713092fba2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38182,DS-70abed30-e4db-4e55-b675-53a8b81790f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-13300839-0b0a-4a53-a2f1-6c27d48337a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1537033926-172.17.0.12-1597307070309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44157,DS-5222c7e5-22b9-4d0a-966f-449486b42b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-402f1a57-e578-4949-a5ff-bb898dd78a83,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-40661701-6085-486c-86c2-e96df285e754,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-4ca19ef5-8bdc-42e3-aad9-04d01b2da4da,DISK], DatanodeInfoWithStorage[127.0.0.1:36250,DS-636b7fc7-cc23-4e1d-aaa5-e7821b799bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-ccc4f6a0-6be6-4e62-a5e9-0713092fba2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38182,DS-70abed30-e4db-4e55-b675-53a8b81790f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-13300839-0b0a-4a53-a2f1-6c27d48337a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: might be true error
Total execution time in seconds : 5378
