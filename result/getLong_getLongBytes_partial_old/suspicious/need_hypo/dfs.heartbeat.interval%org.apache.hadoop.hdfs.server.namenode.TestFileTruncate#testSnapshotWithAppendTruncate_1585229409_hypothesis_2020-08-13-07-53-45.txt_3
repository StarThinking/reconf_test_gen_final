reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestFileTruncate#testSnapshotWithAppendTruncate
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestFileTruncate#testSnapshotWithAppendTruncate
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43799,DS-8b4ed7b1-8f6e-427c-9139-f41a35205c55,DISK], DatanodeInfoWithStorage[127.0.0.1:39322,DS-7e457239-f638-498a-af84-f46264fd0ba7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39322,DS-7e457239-f638-498a-af84-f46264fd0ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-8b4ed7b1-8f6e-427c-9139-f41a35205c55,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43799,DS-8b4ed7b1-8f6e-427c-9139-f41a35205c55,DISK], DatanodeInfoWithStorage[127.0.0.1:39322,DS-7e457239-f638-498a-af84-f46264fd0ba7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39322,DS-7e457239-f638-498a-af84-f46264fd0ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-8b4ed7b1-8f6e-427c-9139-f41a35205c55,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestFileTruncate#testSnapshotWithAppendTruncate
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41008,DS-004cc82b-edad-4a1c-b7fe-7652522dddc4,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-4c744c3e-1936-43cb-be39-affdd17c3a27,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33429,DS-4c744c3e-1936-43cb-be39-affdd17c3a27,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-004cc82b-edad-4a1c-b7fe-7652522dddc4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41008,DS-004cc82b-edad-4a1c-b7fe-7652522dddc4,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-4c744c3e-1936-43cb-be39-affdd17c3a27,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33429,DS-4c744c3e-1936-43cb-be39-affdd17c3a27,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-004cc82b-edad-4a1c-b7fe-7652522dddc4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestFileTruncate#testSnapshotWithAppendTruncate
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39768,DS-034484ff-9c86-4c2f-8b21-66865e12ad8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-e9ae107c-78cf-4b16-acc5-2786cf0aee82,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39875,DS-e9ae107c-78cf-4b16-acc5-2786cf0aee82,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-034484ff-9c86-4c2f-8b21-66865e12ad8f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39768,DS-034484ff-9c86-4c2f-8b21-66865e12ad8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-e9ae107c-78cf-4b16-acc5-2786cf0aee82,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39875,DS-e9ae107c-78cf-4b16-acc5-2786cf0aee82,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-034484ff-9c86-4c2f-8b21-66865e12ad8f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestFileTruncate#testSnapshotWithAppendTruncate
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39567,DS-645403c7-eda6-4ff1-89fd-a0610f2a194e,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-63271ea7-da1f-47d4-8777-6c3fb201d08f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39567,DS-645403c7-eda6-4ff1-89fd-a0610f2a194e,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-63271ea7-da1f-47d4-8777-6c3fb201d08f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39567,DS-645403c7-eda6-4ff1-89fd-a0610f2a194e,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-63271ea7-da1f-47d4-8777-6c3fb201d08f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39567,DS-645403c7-eda6-4ff1-89fd-a0610f2a194e,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-63271ea7-da1f-47d4-8777-6c3fb201d08f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestFileTruncate#testSnapshotWithAppendTruncate
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33179,DS-c8b5f8ca-d53e-4bdb-bd64-412d408aff6b,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-cb7355d2-9f98-477a-a640-4d72a4226d04,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33179,DS-c8b5f8ca-d53e-4bdb-bd64-412d408aff6b,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-cb7355d2-9f98-477a-a640-4d72a4226d04,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33179,DS-c8b5f8ca-d53e-4bdb-bd64-412d408aff6b,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-cb7355d2-9f98-477a-a640-4d72a4226d04,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33179,DS-c8b5f8ca-d53e-4bdb-bd64-412d408aff6b,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-cb7355d2-9f98-477a-a640-4d72a4226d04,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestFileTruncate#testSnapshotWithAppendTruncate
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34209,DS-57662417-901f-44f1-b0ef-d10c0fb05a15,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-4bf3439d-1f07-4c4a-b61a-9e9957bbf32d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34209,DS-57662417-901f-44f1-b0ef-d10c0fb05a15,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-4bf3439d-1f07-4c4a-b61a-9e9957bbf32d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34209,DS-57662417-901f-44f1-b0ef-d10c0fb05a15,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-4bf3439d-1f07-4c4a-b61a-9e9957bbf32d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34209,DS-57662417-901f-44f1-b0ef-d10c0fb05a15,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-4bf3439d-1f07-4c4a-b61a-9e9957bbf32d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestFileTruncate#testSnapshotWithAppendTruncate
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40523,DS-195c0b3d-f06b-4628-ac01-e6101e2e7256,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-1e03e761-92d4-4021-8ba2-b35f872f3cb9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40523,DS-195c0b3d-f06b-4628-ac01-e6101e2e7256,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-1e03e761-92d4-4021-8ba2-b35f872f3cb9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40523,DS-195c0b3d-f06b-4628-ac01-e6101e2e7256,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-1e03e761-92d4-4021-8ba2-b35f872f3cb9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40523,DS-195c0b3d-f06b-4628-ac01-e6101e2e7256,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-1e03e761-92d4-4021-8ba2-b35f872f3cb9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestFileTruncate#testSnapshotWithAppendTruncate
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32948,DS-3ea9d9d4-1e4e-4a2d-a240-4f3cbca4c918,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-10fe3ff7-7e2a-4643-96c3-83685ab8845b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32948,DS-3ea9d9d4-1e4e-4a2d-a240-4f3cbca4c918,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-10fe3ff7-7e2a-4643-96c3-83685ab8845b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32948,DS-3ea9d9d4-1e4e-4a2d-a240-4f3cbca4c918,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-10fe3ff7-7e2a-4643-96c3-83685ab8845b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32948,DS-3ea9d9d4-1e4e-4a2d-a240-4f3cbca4c918,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-10fe3ff7-7e2a-4643-96c3-83685ab8845b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestFileTruncate#testSnapshotWithAppendTruncate
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39411,DS-efe34362-b5ad-419b-a3a7-6ac3dbfa42bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-49554b55-1a36-46d7-b5b9-cb2534ef2bec,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39411,DS-efe34362-b5ad-419b-a3a7-6ac3dbfa42bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-49554b55-1a36-46d7-b5b9-cb2534ef2bec,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39411,DS-efe34362-b5ad-419b-a3a7-6ac3dbfa42bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-49554b55-1a36-46d7-b5b9-cb2534ef2bec,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39411,DS-efe34362-b5ad-419b-a3a7-6ac3dbfa42bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-49554b55-1a36-46d7-b5b9-cb2534ef2bec,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestFileTruncate#testSnapshotWithAppendTruncate
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34022,DS-2d291212-b883-431d-8142-af3911d1025e,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-99630d51-487c-4081-a2a4-97c8365986b3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42491,DS-99630d51-487c-4081-a2a4-97c8365986b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-2d291212-b883-431d-8142-af3911d1025e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34022,DS-2d291212-b883-431d-8142-af3911d1025e,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-99630d51-487c-4081-a2a4-97c8365986b3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42491,DS-99630d51-487c-4081-a2a4-97c8365986b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-2d291212-b883-431d-8142-af3911d1025e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 19
v1v1v2v2 failed with probability 0 out of 19
result: might be true error
Total execution time in seconds : 5103
