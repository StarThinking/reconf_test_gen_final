reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 16384
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 16384
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-157714133-172.17.0.9-1595801503831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33541,DS-d437929d-d301-4f80-a661-a77d1485afa7,DISK], DatanodeInfoWithStorage[127.0.0.1:38302,DS-498f80ac-4a3f-4960-8126-625ce972fb80,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-11cadb2b-a52b-4edb-bd65-88467ee330c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-4ce9026a-3c61-4727-a582-cb9cba131ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-30c090a2-5bd5-4152-bd18-d4b1b3c4e4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-f523c842-2ca1-44f1-b276-ff75b5f0baa3,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-d6ce3d72-8c28-4d52-942a-93f85079fad2,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-366cafe3-055c-4811-84e1-22da886ba9fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-157714133-172.17.0.9-1595801503831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33541,DS-d437929d-d301-4f80-a661-a77d1485afa7,DISK], DatanodeInfoWithStorage[127.0.0.1:38302,DS-498f80ac-4a3f-4960-8126-625ce972fb80,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-11cadb2b-a52b-4edb-bd65-88467ee330c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-4ce9026a-3c61-4727-a582-cb9cba131ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-30c090a2-5bd5-4152-bd18-d4b1b3c4e4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-f523c842-2ca1-44f1-b276-ff75b5f0baa3,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-d6ce3d72-8c28-4d52-942a-93f85079fad2,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-366cafe3-055c-4811-84e1-22da886ba9fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 16384
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-435893371-172.17.0.9-1595802504532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33254,DS-6f6d9090-2267-416b-98a4-96cc4f6af073,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-00647d6b-8b52-434a-845c-33c8ea17fb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-c91c7b39-52ad-472d-8012-f97cc1aec2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-f7d6629a-e3b4-4b1a-ab94-ace4181c7336,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-88e092a6-83ec-4bdb-abde-fbf0472f47fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-6fbd9c83-bd38-4527-86fb-c74eae2886b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-faeff733-cb1e-46d2-a867-35e18f43dba4,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-5843a8bb-041a-4c2c-b5ca-05868a4c49e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-435893371-172.17.0.9-1595802504532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33254,DS-6f6d9090-2267-416b-98a4-96cc4f6af073,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-00647d6b-8b52-434a-845c-33c8ea17fb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-c91c7b39-52ad-472d-8012-f97cc1aec2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-f7d6629a-e3b4-4b1a-ab94-ace4181c7336,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-88e092a6-83ec-4bdb-abde-fbf0472f47fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-6fbd9c83-bd38-4527-86fb-c74eae2886b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-faeff733-cb1e-46d2-a867-35e18f43dba4,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-5843a8bb-041a-4c2c-b5ca-05868a4c49e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 16384
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-875431015-172.17.0.9-1595802608672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45845,DS-2683a2c3-d56b-4949-8d3d-a1fd7fe49eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-b8dd07ea-7d86-4ec9-bd80-aebdb7fd868b,DISK], DatanodeInfoWithStorage[127.0.0.1:35735,DS-ae3127aa-accc-4c39-bd02-ed1cfd2eada0,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-edc474eb-c694-4185-bdaf-9e0f948343ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-35347881-1983-4735-a320-b1b91ebcc222,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-073119f5-0ce7-4eed-aab7-ee823471794b,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-cc75380a-2746-432a-b843-0681bf69690b,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-ab336732-9368-4fad-9c6a-7d227495c3c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-875431015-172.17.0.9-1595802608672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45845,DS-2683a2c3-d56b-4949-8d3d-a1fd7fe49eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-b8dd07ea-7d86-4ec9-bd80-aebdb7fd868b,DISK], DatanodeInfoWithStorage[127.0.0.1:35735,DS-ae3127aa-accc-4c39-bd02-ed1cfd2eada0,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-edc474eb-c694-4185-bdaf-9e0f948343ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-35347881-1983-4735-a320-b1b91ebcc222,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-073119f5-0ce7-4eed-aab7-ee823471794b,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-cc75380a-2746-432a-b843-0681bf69690b,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-ab336732-9368-4fad-9c6a-7d227495c3c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 16384
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-894189225-172.17.0.9-1595802710943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45178,DS-71cdc912-b68e-4b8e-ad9e-decd95427620,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-16049f37-8438-4272-b791-0108af221d36,DISK], DatanodeInfoWithStorage[127.0.0.1:40358,DS-e4c2ae0e-ccdc-4d7c-818b-28a2fb408b28,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-8db42242-8afd-4b36-91d7-552e0dfce916,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-03fa961e-78ee-452e-96e9-18489a6a51c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-7f734cda-5397-4360-946b-f47d6b05f60b,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-1120043c-1dfd-415a-a812-9bbc91df41ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43593,DS-60d7f7cd-a248-49ac-a99f-692610cdaae2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-894189225-172.17.0.9-1595802710943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45178,DS-71cdc912-b68e-4b8e-ad9e-decd95427620,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-16049f37-8438-4272-b791-0108af221d36,DISK], DatanodeInfoWithStorage[127.0.0.1:40358,DS-e4c2ae0e-ccdc-4d7c-818b-28a2fb408b28,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-8db42242-8afd-4b36-91d7-552e0dfce916,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-03fa961e-78ee-452e-96e9-18489a6a51c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-7f734cda-5397-4360-946b-f47d6b05f60b,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-1120043c-1dfd-415a-a812-9bbc91df41ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43593,DS-60d7f7cd-a248-49ac-a99f-692610cdaae2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 16384
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-405052547-172.17.0.9-1595803069949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42427,DS-b78dc89f-8db3-4cbf-bb36-dc4fdeff7aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-35d5f9a9-33b9-4eca-8593-c362c411f6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-0caa8d1b-3b8b-4cf6-9769-02520513955c,DISK], DatanodeInfoWithStorage[127.0.0.1:40836,DS-857acf67-73ec-43fd-a427-84ec7c48d7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-3c2f75a1-9bd0-4df1-999a-a6c902305a16,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-126a37d3-bc99-41e7-9f44-095688b7c009,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-66c4a700-6c83-41b4-8896-3196e1b53bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-60aaf3f6-5061-469f-ba28-b6bb096d1421,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-405052547-172.17.0.9-1595803069949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42427,DS-b78dc89f-8db3-4cbf-bb36-dc4fdeff7aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-35d5f9a9-33b9-4eca-8593-c362c411f6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-0caa8d1b-3b8b-4cf6-9769-02520513955c,DISK], DatanodeInfoWithStorage[127.0.0.1:40836,DS-857acf67-73ec-43fd-a427-84ec7c48d7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-3c2f75a1-9bd0-4df1-999a-a6c902305a16,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-126a37d3-bc99-41e7-9f44-095688b7c009,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-66c4a700-6c83-41b4-8896-3196e1b53bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-60aaf3f6-5061-469f-ba28-b6bb096d1421,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 16384
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-527039049-172.17.0.9-1595803407723:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42379,DS-19b22bcb-0bc7-4428-8a6b-15f75a81d09e,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-13b0ace5-3862-4218-b75a-774f0f5c6461,DISK], DatanodeInfoWithStorage[127.0.0.1:42736,DS-4ef31e61-baec-4390-83e5-9e9e0510035c,DISK], DatanodeInfoWithStorage[127.0.0.1:43936,DS-a2d784b8-3b8c-484b-8bce-32ae7c1e7379,DISK], DatanodeInfoWithStorage[127.0.0.1:45874,DS-4f70d9ff-5e99-4965-8cf7-ac6f5ff202d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-bee70d03-c048-48a9-a939-fb32a2664b94,DISK], DatanodeInfoWithStorage[127.0.0.1:36969,DS-f9fabebe-6153-476d-9bf0-5119245faca2,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-47a579a6-10ad-4e05-b31a-63a4b799f83d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-527039049-172.17.0.9-1595803407723:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42379,DS-19b22bcb-0bc7-4428-8a6b-15f75a81d09e,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-13b0ace5-3862-4218-b75a-774f0f5c6461,DISK], DatanodeInfoWithStorage[127.0.0.1:42736,DS-4ef31e61-baec-4390-83e5-9e9e0510035c,DISK], DatanodeInfoWithStorage[127.0.0.1:43936,DS-a2d784b8-3b8c-484b-8bce-32ae7c1e7379,DISK], DatanodeInfoWithStorage[127.0.0.1:45874,DS-4f70d9ff-5e99-4965-8cf7-ac6f5ff202d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-bee70d03-c048-48a9-a939-fb32a2664b94,DISK], DatanodeInfoWithStorage[127.0.0.1:36969,DS-f9fabebe-6153-476d-9bf0-5119245faca2,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-47a579a6-10ad-4e05-b31a-63a4b799f83d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 16384
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1250256323-172.17.0.9-1595803729207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34900,DS-e3abca49-d5c7-4b3c-b2a7-9b573d227e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35514,DS-0e21cabc-1dd2-4223-8977-c9bfec74b127,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-e259527c-a62b-490d-81f0-0cb60a4a3601,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-40c72f25-fbb1-45b5-b0ef-575714da14ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-25c2a2f9-e0fe-45a6-a1b9-09e461f8d6df,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-a5910a51-db7c-4bf9-adae-7216294aa574,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-0c088d2e-5968-4d8a-84fd-f17eecd2fa3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-d83d81e2-cd36-4fab-9fed-11f2836d9627,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1250256323-172.17.0.9-1595803729207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34900,DS-e3abca49-d5c7-4b3c-b2a7-9b573d227e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35514,DS-0e21cabc-1dd2-4223-8977-c9bfec74b127,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-e259527c-a62b-490d-81f0-0cb60a4a3601,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-40c72f25-fbb1-45b5-b0ef-575714da14ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-25c2a2f9-e0fe-45a6-a1b9-09e461f8d6df,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-a5910a51-db7c-4bf9-adae-7216294aa574,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-0c088d2e-5968-4d8a-84fd-f17eecd2fa3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-d83d81e2-cd36-4fab-9fed-11f2836d9627,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 16384
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1547039582-172.17.0.9-1595803891472:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44307,DS-44f0f839-3b15-4b34-9ff7-d21d8b727270,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-3e04bcda-a0c4-4ba8-9a60-113b6e64c302,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-0ed4e2a2-30fd-43b5-8886-df77d5edf318,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-a6bf41f9-b436-4104-b112-662b4eea68eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35270,DS-ad934fdd-d1bd-4ab3-ac14-1a45d2a31592,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-12cdf2ad-41bc-4e8e-a397-76a0a1ffd20c,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-70177a8a-6f93-4add-aab8-e4a190cfdcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-ae8e58c9-50e0-4331-b9fa-a505fc20b28b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1547039582-172.17.0.9-1595803891472:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44307,DS-44f0f839-3b15-4b34-9ff7-d21d8b727270,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-3e04bcda-a0c4-4ba8-9a60-113b6e64c302,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-0ed4e2a2-30fd-43b5-8886-df77d5edf318,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-a6bf41f9-b436-4104-b112-662b4eea68eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35270,DS-ad934fdd-d1bd-4ab3-ac14-1a45d2a31592,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-12cdf2ad-41bc-4e8e-a397-76a0a1ffd20c,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-70177a8a-6f93-4add-aab8-e4a190cfdcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-ae8e58c9-50e0-4331-b9fa-a505fc20b28b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 16384
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1011496236-172.17.0.9-1595804057540:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41543,DS-fa5f413e-828c-4fb7-ac03-822af78e583e,DISK], DatanodeInfoWithStorage[127.0.0.1:46811,DS-6a8d08ab-723b-46a1-88b5-6f5f10420bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-c1a1967d-0767-44c5-93ce-12f310a651f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-6876f1d5-4dbe-4de0-9f9b-f4b0e56c18f2,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-791cca4a-ca3f-4821-b0a5-a1f2652af76f,DISK], DatanodeInfoWithStorage[127.0.0.1:37775,DS-bc2b2339-9c08-49dc-8fc6-8d1e198b6f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-ed2fddd8-76a0-408b-ac3e-a1c92b163c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-419f597f-49c1-4ae3-b484-e08d4d7161cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1011496236-172.17.0.9-1595804057540:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41543,DS-fa5f413e-828c-4fb7-ac03-822af78e583e,DISK], DatanodeInfoWithStorage[127.0.0.1:46811,DS-6a8d08ab-723b-46a1-88b5-6f5f10420bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-c1a1967d-0767-44c5-93ce-12f310a651f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-6876f1d5-4dbe-4de0-9f9b-f4b0e56c18f2,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-791cca4a-ca3f-4821-b0a5-a1f2652af76f,DISK], DatanodeInfoWithStorage[127.0.0.1:37775,DS-bc2b2339-9c08-49dc-8fc6-8d1e198b6f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-ed2fddd8-76a0-408b-ac3e-a1c92b163c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-419f597f-49c1-4ae3-b484-e08d4d7161cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 16384
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1316268835-172.17.0.9-1595804564032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46582,DS-5aa5b106-d0bb-4332-9d40-4ab2317de8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-7fcb2135-0576-4fb6-b549-0f804b32e056,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-236b97ca-ff2b-478e-a745-6b0c0db37081,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-2cecfe6b-5f6b-4744-9f16-f9c01eabb64e,DISK], DatanodeInfoWithStorage[127.0.0.1:37173,DS-7711c3ea-d67b-4e29-b423-b6e92aabc5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-fcac2178-9890-4116-a837-925afb2816bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-44cc77b9-d093-4309-a004-feb71f03c535,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-ca8ad283-e524-4991-b52a-48d1eb60e9da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1316268835-172.17.0.9-1595804564032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46582,DS-5aa5b106-d0bb-4332-9d40-4ab2317de8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-7fcb2135-0576-4fb6-b549-0f804b32e056,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-236b97ca-ff2b-478e-a745-6b0c0db37081,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-2cecfe6b-5f6b-4744-9f16-f9c01eabb64e,DISK], DatanodeInfoWithStorage[127.0.0.1:37173,DS-7711c3ea-d67b-4e29-b423-b6e92aabc5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-fcac2178-9890-4116-a837-925afb2816bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-44cc77b9-d093-4309-a004-feb71f03c535,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-ca8ad283-e524-4991-b52a-48d1eb60e9da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 16384
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1019775993-172.17.0.9-1595804887958:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37594,DS-fcf2cb82-f231-453f-9e8d-5031d2f5cf82,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-1ec3c088-146c-4d2d-b9dd-b27abd085a38,DISK], DatanodeInfoWithStorage[127.0.0.1:37938,DS-e55fa8d7-34df-47b2-a6f4-28eac5e657d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-e86cbe34-684b-44aa-898d-03f42ab8d7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-da4f3321-e12e-4c66-9810-87f4e4ce57d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43355,DS-0e415c92-d7ce-4815-a218-3493775fe711,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-f84459a8-1120-4d68-88fe-f231bb1e0d43,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-7e085f38-bf20-421e-96b9-0f6978b3d76f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1019775993-172.17.0.9-1595804887958:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37594,DS-fcf2cb82-f231-453f-9e8d-5031d2f5cf82,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-1ec3c088-146c-4d2d-b9dd-b27abd085a38,DISK], DatanodeInfoWithStorage[127.0.0.1:37938,DS-e55fa8d7-34df-47b2-a6f4-28eac5e657d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-e86cbe34-684b-44aa-898d-03f42ab8d7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-da4f3321-e12e-4c66-9810-87f4e4ce57d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43355,DS-0e415c92-d7ce-4815-a218-3493775fe711,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-f84459a8-1120-4d68-88fe-f231bb1e0d43,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-7e085f38-bf20-421e-96b9-0f6978b3d76f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 16384
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-349721245-172.17.0.9-1595805099258:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33663,DS-69c60469-29df-457e-b0aa-83aa79b2d927,DISK], DatanodeInfoWithStorage[127.0.0.1:37842,DS-9e7c8b84-0cef-4b52-8e06-023396be03f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-4131b6c9-44df-467a-8618-5eee6aeebbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-feec969c-1fc0-46a0-8c7f-801f62b4f623,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-88802c94-7e6e-4953-b06c-781fc90ad70b,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-c03c255a-f659-47cc-afcb-d1742ef2d33c,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-7bfd47cc-6eaa-4e38-a810-4b70b938e95b,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-517ca240-943f-47c4-97c3-d0fd54ebf4cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-349721245-172.17.0.9-1595805099258:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33663,DS-69c60469-29df-457e-b0aa-83aa79b2d927,DISK], DatanodeInfoWithStorage[127.0.0.1:37842,DS-9e7c8b84-0cef-4b52-8e06-023396be03f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-4131b6c9-44df-467a-8618-5eee6aeebbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-feec969c-1fc0-46a0-8c7f-801f62b4f623,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-88802c94-7e6e-4953-b06c-781fc90ad70b,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-c03c255a-f659-47cc-afcb-d1742ef2d33c,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-7bfd47cc-6eaa-4e38-a810-4b70b938e95b,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-517ca240-943f-47c4-97c3-d0fd54ebf4cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 16384
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-961248450-172.17.0.9-1595805210240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34199,DS-39b47a6e-2db3-4a2d-ad50-bf74a81cd7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-67cb406d-6e9a-4943-b82d-e896dce9f566,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-56d5ba0f-9907-41c6-8be1-aaf053404bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-44c2b60a-8bfa-4b39-8c84-96b65f912b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-7c411fcc-c08b-430e-93eb-24580469f291,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-b1045407-d811-4262-8cc0-5f33991808f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-62478b95-7d37-4cd9-9e5e-4cc21e9c5f72,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-11f2a696-d107-4d17-b2d5-a3c86e0ffefa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-961248450-172.17.0.9-1595805210240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34199,DS-39b47a6e-2db3-4a2d-ad50-bf74a81cd7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-67cb406d-6e9a-4943-b82d-e896dce9f566,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-56d5ba0f-9907-41c6-8be1-aaf053404bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-44c2b60a-8bfa-4b39-8c84-96b65f912b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-7c411fcc-c08b-430e-93eb-24580469f291,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-b1045407-d811-4262-8cc0-5f33991808f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-62478b95-7d37-4cd9-9e5e-4cc21e9c5f72,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-11f2a696-d107-4d17-b2d5-a3c86e0ffefa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 16384
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1292559814-172.17.0.9-1595805317013:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42872,DS-2741d5d3-3657-45c2-b5ba-1a4b8a90c733,DISK], DatanodeInfoWithStorage[127.0.0.1:46085,DS-eff04c19-feae-4d7e-97ee-fdbbb93df7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-d4e87753-4e3c-418d-88ee-51f675ffdd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-f5c1d701-3bfa-469f-94d2-021998278063,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-fd35b6cf-4344-4e12-86e7-f744c3164636,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-cf35be6a-c676-47e6-a8f8-8767ba18a2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-634322fd-ea10-4908-ab60-30866c7739cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33343,DS-4f297860-c448-4cac-80f9-80d439f35081,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1292559814-172.17.0.9-1595805317013:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42872,DS-2741d5d3-3657-45c2-b5ba-1a4b8a90c733,DISK], DatanodeInfoWithStorage[127.0.0.1:46085,DS-eff04c19-feae-4d7e-97ee-fdbbb93df7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-d4e87753-4e3c-418d-88ee-51f675ffdd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-f5c1d701-3bfa-469f-94d2-021998278063,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-fd35b6cf-4344-4e12-86e7-f744c3164636,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-cf35be6a-c676-47e6-a8f8-8767ba18a2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-634322fd-ea10-4908-ab60-30866c7739cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33343,DS-4f297860-c448-4cac-80f9-80d439f35081,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 16384
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-198312127-172.17.0.9-1595805348195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35816,DS-08ce525d-4d7e-4e72-b734-ad73ff797e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-ed9b6324-8285-467f-93b0-e25e46c11576,DISK], DatanodeInfoWithStorage[127.0.0.1:36635,DS-ad252713-f3f0-44bf-a541-111b9e71d060,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-99d3fbda-6f5d-451b-9fbc-a028e501a6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36390,DS-ec321776-ee85-4bd8-a789-c061274de6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-942320eb-5073-4d24-ab68-dcb7d9b86ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:44523,DS-df434cbd-4a59-4a91-8e9d-b97bd17dcf5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-a44af013-956e-46c4-9697-ba6aec0dc133,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-198312127-172.17.0.9-1595805348195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35816,DS-08ce525d-4d7e-4e72-b734-ad73ff797e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-ed9b6324-8285-467f-93b0-e25e46c11576,DISK], DatanodeInfoWithStorage[127.0.0.1:36635,DS-ad252713-f3f0-44bf-a541-111b9e71d060,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-99d3fbda-6f5d-451b-9fbc-a028e501a6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36390,DS-ec321776-ee85-4bd8-a789-c061274de6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-942320eb-5073-4d24-ab68-dcb7d9b86ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:44523,DS-df434cbd-4a59-4a91-8e9d-b97bd17dcf5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-a44af013-956e-46c4-9697-ba6aec0dc133,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 16384
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1652581530-172.17.0.9-1595806411861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36696,DS-086a0338-5590-4e5d-8632-f78d186c719f,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-24be80c1-92e5-484e-87e0-c24822fa727b,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-a5068c75-7704-4207-a868-dd4c57d85acb,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-5dccab9b-4d58-402e-85d7-f98a32e322d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43508,DS-e35f47a0-d757-4289-94df-8269c0ab1069,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-06028b00-8204-47ab-a18b-0c62c10dbf12,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-563fecb9-3dae-47b7-8329-9bd6b6540943,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-06e7899b-1469-48e9-9137-f716d22ce105,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1652581530-172.17.0.9-1595806411861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36696,DS-086a0338-5590-4e5d-8632-f78d186c719f,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-24be80c1-92e5-484e-87e0-c24822fa727b,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-a5068c75-7704-4207-a868-dd4c57d85acb,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-5dccab9b-4d58-402e-85d7-f98a32e322d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43508,DS-e35f47a0-d757-4289-94df-8269c0ab1069,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-06028b00-8204-47ab-a18b-0c62c10dbf12,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-563fecb9-3dae-47b7-8329-9bd6b6540943,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-06e7899b-1469-48e9-9137-f716d22ce105,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 16384
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1496083450-172.17.0.9-1595806554488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46159,DS-3a61670c-805a-4432-862f-111bead494fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-efd311ef-5e09-4274-8c22-b891ec33accc,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-00816d33-69d6-4e3b-9e9f-1126500146fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-510bf565-dc46-415f-b357-1396eb5167c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-3d9500c6-5caa-4e11-831f-8ca6c775b85d,DISK], DatanodeInfoWithStorage[127.0.0.1:42426,DS-653f0a12-3b89-43d9-a2dc-1e28cbc3a15e,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-6a2e2126-5025-4fc6-a47d-c1bf8e229028,DISK], DatanodeInfoWithStorage[127.0.0.1:37258,DS-9ff6407b-2235-46cd-93e4-a73c43299a66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1496083450-172.17.0.9-1595806554488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46159,DS-3a61670c-805a-4432-862f-111bead494fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-efd311ef-5e09-4274-8c22-b891ec33accc,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-00816d33-69d6-4e3b-9e9f-1126500146fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-510bf565-dc46-415f-b357-1396eb5167c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-3d9500c6-5caa-4e11-831f-8ca6c775b85d,DISK], DatanodeInfoWithStorage[127.0.0.1:42426,DS-653f0a12-3b89-43d9-a2dc-1e28cbc3a15e,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-6a2e2126-5025-4fc6-a47d-c1bf8e229028,DISK], DatanodeInfoWithStorage[127.0.0.1:37258,DS-9ff6407b-2235-46cd-93e4-a73c43299a66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5182
