reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1609404291-172.17.0.17-1595960006726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33984,DS-621b3080-92b3-46bb-9eec-7b5b4a71fcb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39651,DS-cfed5eb7-5f15-4229-9543-7ffe5e6a361e,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-977b55f9-51ca-4f32-a435-cc837509f99c,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-e963756c-8728-49b1-af48-1952da2cf281,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-1f9cb157-e951-4c4f-9c39-8fa0f414d60c,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-cc0659bb-1461-45c5-a987-0c2277131ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:38139,DS-dc92001c-cc8a-405d-8557-890f0bc7962e,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-61cdc4e8-87ae-4805-8fae-d2dfda54ba6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1609404291-172.17.0.17-1595960006726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33984,DS-621b3080-92b3-46bb-9eec-7b5b4a71fcb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39651,DS-cfed5eb7-5f15-4229-9543-7ffe5e6a361e,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-977b55f9-51ca-4f32-a435-cc837509f99c,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-e963756c-8728-49b1-af48-1952da2cf281,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-1f9cb157-e951-4c4f-9c39-8fa0f414d60c,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-cc0659bb-1461-45c5-a987-0c2277131ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:38139,DS-dc92001c-cc8a-405d-8557-890f0bc7962e,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-61cdc4e8-87ae-4805-8fae-d2dfda54ba6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1095967236-172.17.0.17-1595960483769:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33945,DS-9690d617-8cee-4dc8-9144-271290cae1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-26229499-d9ee-4ddf-b591-880cac833a34,DISK], DatanodeInfoWithStorage[127.0.0.1:46712,DS-7cec6c94-20f8-4286-b6a2-8a540d9d8a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-5f771b1b-edf4-4d70-a7be-9cad63468c91,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-56e7a164-1bb5-4529-9ca1-881c1cb8cc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42251,DS-22598781-9a35-4618-a712-fd11616747ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41100,DS-0399e812-ddfb-445b-8334-0bc56c91c241,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-d77f1d33-5479-4f58-ade9-89300765a538,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1095967236-172.17.0.17-1595960483769:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33945,DS-9690d617-8cee-4dc8-9144-271290cae1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-26229499-d9ee-4ddf-b591-880cac833a34,DISK], DatanodeInfoWithStorage[127.0.0.1:46712,DS-7cec6c94-20f8-4286-b6a2-8a540d9d8a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-5f771b1b-edf4-4d70-a7be-9cad63468c91,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-56e7a164-1bb5-4529-9ca1-881c1cb8cc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42251,DS-22598781-9a35-4618-a712-fd11616747ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41100,DS-0399e812-ddfb-445b-8334-0bc56c91c241,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-d77f1d33-5479-4f58-ade9-89300765a538,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1275512327-172.17.0.17-1595960702628:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34520,DS-36d4c06e-b2f8-4db8-ae09-301d6c1f206e,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-0dece30e-e84f-4948-acb1-197de2451429,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-c745941b-8c89-4f7b-82a9-73f6be5df485,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-5698f9ca-5bb9-47b6-82ba-c17ced8c1f68,DISK], DatanodeInfoWithStorage[127.0.0.1:38267,DS-c44e9f54-fc76-440e-85d7-a163eeb5c2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45457,DS-7643a570-bc94-4e24-990a-0588568b1058,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-eb96f3de-d0dc-4774-b2f2-5c94f2c74fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:43685,DS-c08b9afd-d9e4-4e3c-9456-8c5213132e2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1275512327-172.17.0.17-1595960702628:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34520,DS-36d4c06e-b2f8-4db8-ae09-301d6c1f206e,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-0dece30e-e84f-4948-acb1-197de2451429,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-c745941b-8c89-4f7b-82a9-73f6be5df485,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-5698f9ca-5bb9-47b6-82ba-c17ced8c1f68,DISK], DatanodeInfoWithStorage[127.0.0.1:38267,DS-c44e9f54-fc76-440e-85d7-a163eeb5c2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45457,DS-7643a570-bc94-4e24-990a-0588568b1058,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-eb96f3de-d0dc-4774-b2f2-5c94f2c74fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:43685,DS-c08b9afd-d9e4-4e3c-9456-8c5213132e2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1800182089-172.17.0.17-1595961140910:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43524,DS-f62f497b-155e-446f-a887-656fc564c36a,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-bee39853-63b2-450b-b1c9-ffc0818dc384,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-7e08b261-5c2e-4bf4-b324-5724b822b950,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-d93bb41a-7b72-4cd4-94b2-0147177b102d,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-569e0c59-a7cd-4831-a88b-2a9ac4781fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-8611e866-f15f-478f-9bd1-3332d84b6445,DISK], DatanodeInfoWithStorage[127.0.0.1:36431,DS-10893c75-ba82-44ed-b445-757c6473c61b,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-9d9ae5a8-634b-4bf8-85ae-85fc0d7e784c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1800182089-172.17.0.17-1595961140910:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43524,DS-f62f497b-155e-446f-a887-656fc564c36a,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-bee39853-63b2-450b-b1c9-ffc0818dc384,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-7e08b261-5c2e-4bf4-b324-5724b822b950,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-d93bb41a-7b72-4cd4-94b2-0147177b102d,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-569e0c59-a7cd-4831-a88b-2a9ac4781fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-8611e866-f15f-478f-9bd1-3332d84b6445,DISK], DatanodeInfoWithStorage[127.0.0.1:36431,DS-10893c75-ba82-44ed-b445-757c6473c61b,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-9d9ae5a8-634b-4bf8-85ae-85fc0d7e784c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2000488868-172.17.0.17-1595961391301:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43415,DS-3c440d91-34bd-4cc0-a46f-01956deecebc,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-7af9026f-c4f5-4dd5-be20-0df844098a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-df78c9c2-5f6a-4ed2-80be-443d5c838890,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-2b09d01c-e438-411e-8d85-dd6742ce2c90,DISK], DatanodeInfoWithStorage[127.0.0.1:40644,DS-64895d83-f68a-4c89-bcb4-9150da4d8b92,DISK], DatanodeInfoWithStorage[127.0.0.1:39057,DS-27800dc0-16ac-4fa1-8f13-e657bab4b24e,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-142c6411-7401-4568-85e4-4ec26fc502a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44624,DS-31b0754a-68df-41fa-8b88-82eef7f5cd95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2000488868-172.17.0.17-1595961391301:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43415,DS-3c440d91-34bd-4cc0-a46f-01956deecebc,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-7af9026f-c4f5-4dd5-be20-0df844098a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-df78c9c2-5f6a-4ed2-80be-443d5c838890,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-2b09d01c-e438-411e-8d85-dd6742ce2c90,DISK], DatanodeInfoWithStorage[127.0.0.1:40644,DS-64895d83-f68a-4c89-bcb4-9150da4d8b92,DISK], DatanodeInfoWithStorage[127.0.0.1:39057,DS-27800dc0-16ac-4fa1-8f13-e657bab4b24e,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-142c6411-7401-4568-85e4-4ec26fc502a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44624,DS-31b0754a-68df-41fa-8b88-82eef7f5cd95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-956251639-172.17.0.17-1595961568359:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39399,DS-13b9d38b-8bea-4433-8eee-fecde22b9d17,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-efb140ee-bead-4241-a488-f3ec01b364c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-9eecb3e3-3322-4314-89f7-af6eb7b7e89c,DISK], DatanodeInfoWithStorage[127.0.0.1:35502,DS-1afcd4e9-bf66-43fa-a7c5-7ac843e31e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-24e3c1d7-3b0b-4d20-92d8-173fce247778,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-298d0c9d-74a5-4556-a970-7e4ac9f1d25c,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-6d0af99c-4ee7-4491-9a43-f7faa22082e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-e285939c-b8b4-49ba-b3a9-fa6a7284295b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-956251639-172.17.0.17-1595961568359:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39399,DS-13b9d38b-8bea-4433-8eee-fecde22b9d17,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-efb140ee-bead-4241-a488-f3ec01b364c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-9eecb3e3-3322-4314-89f7-af6eb7b7e89c,DISK], DatanodeInfoWithStorage[127.0.0.1:35502,DS-1afcd4e9-bf66-43fa-a7c5-7ac843e31e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-24e3c1d7-3b0b-4d20-92d8-173fce247778,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-298d0c9d-74a5-4556-a970-7e4ac9f1d25c,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-6d0af99c-4ee7-4491-9a43-f7faa22082e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-e285939c-b8b4-49ba-b3a9-fa6a7284295b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-26208573-172.17.0.17-1595961781954:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33718,DS-48253cca-fb88-4239-b6d5-9c54327bc1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-61a5369a-b389-43f5-aa99-8dd18b37f56c,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-2f7c7e74-1596-44e3-8b12-8f5856944ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-36c09fcb-33ad-45cb-b9c4-1903ee23753d,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-4fb7730c-2a5f-4e2b-8935-517481fbb902,DISK], DatanodeInfoWithStorage[127.0.0.1:39698,DS-23f67d37-1a2c-48ac-8215-17b9d7db1b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36611,DS-cc2696c8-e71c-4c7a-ba72-1630879ee875,DISK], DatanodeInfoWithStorage[127.0.0.1:37519,DS-a930e155-1c52-407c-a1e2-b1d2b2f9dec3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-26208573-172.17.0.17-1595961781954:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33718,DS-48253cca-fb88-4239-b6d5-9c54327bc1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-61a5369a-b389-43f5-aa99-8dd18b37f56c,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-2f7c7e74-1596-44e3-8b12-8f5856944ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-36c09fcb-33ad-45cb-b9c4-1903ee23753d,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-4fb7730c-2a5f-4e2b-8935-517481fbb902,DISK], DatanodeInfoWithStorage[127.0.0.1:39698,DS-23f67d37-1a2c-48ac-8215-17b9d7db1b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36611,DS-cc2696c8-e71c-4c7a-ba72-1630879ee875,DISK], DatanodeInfoWithStorage[127.0.0.1:37519,DS-a930e155-1c52-407c-a1e2-b1d2b2f9dec3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1822918461-172.17.0.17-1595961864736:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46519,DS-42d715fe-7a5d-4603-9ab4-1dd9f10edc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-3f23ecaa-7aed-4eb6-b196-00de10f06fce,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-afab7783-161c-46f0-bd9e-a98c4df147e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45427,DS-f46ae817-a096-400d-a962-4c76ebb974bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-eb812b05-6b78-4ea4-941e-eb230d61b5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-b05e5f96-fcc3-4fc4-9486-2cbfcef8e15d,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-77412dbc-239c-41c9-a707-0a8b832ca1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42638,DS-7e322062-880a-4864-b244-4dc49e80a932,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1822918461-172.17.0.17-1595961864736:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46519,DS-42d715fe-7a5d-4603-9ab4-1dd9f10edc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-3f23ecaa-7aed-4eb6-b196-00de10f06fce,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-afab7783-161c-46f0-bd9e-a98c4df147e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45427,DS-f46ae817-a096-400d-a962-4c76ebb974bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-eb812b05-6b78-4ea4-941e-eb230d61b5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-b05e5f96-fcc3-4fc4-9486-2cbfcef8e15d,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-77412dbc-239c-41c9-a707-0a8b832ca1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42638,DS-7e322062-880a-4864-b244-4dc49e80a932,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-729536786-172.17.0.17-1595963377383:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34225,DS-ddecba0e-7d69-449d-a0fc-51a30356f7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-e1c9a2b9-15f8-4244-8459-03efd55f0421,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-a67baeac-b414-44ee-9b5e-d8087cdeba19,DISK], DatanodeInfoWithStorage[127.0.0.1:41025,DS-332ca7d2-aaef-4ffd-b037-1722feabcc78,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-358a41c3-2b59-439e-87f8-45a90eea7dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-d9fbe633-d60a-4fb0-a0e9-5161595915ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-73de33c6-ab44-4ea4-a0d4-fc1d2ae67315,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-db21346d-6efa-4e04-ac96-80e5fdc3ef50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-729536786-172.17.0.17-1595963377383:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34225,DS-ddecba0e-7d69-449d-a0fc-51a30356f7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-e1c9a2b9-15f8-4244-8459-03efd55f0421,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-a67baeac-b414-44ee-9b5e-d8087cdeba19,DISK], DatanodeInfoWithStorage[127.0.0.1:41025,DS-332ca7d2-aaef-4ffd-b037-1722feabcc78,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-358a41c3-2b59-439e-87f8-45a90eea7dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-d9fbe633-d60a-4fb0-a0e9-5161595915ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-73de33c6-ab44-4ea4-a0d4-fc1d2ae67315,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-db21346d-6efa-4e04-ac96-80e5fdc3ef50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-736404266-172.17.0.17-1595963747461:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41847,DS-8228c6cd-0cee-4918-9d1b-221964c37f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-728d2944-6d18-4063-ad42-df76ec144030,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-d250b915-9b58-4156-8c8b-3ee4ef962b97,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-c3a75606-d213-41e4-8af2-042e9c2ea49b,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-ec820b59-9ec4-4312-8862-0c71f139fb37,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-9efe1bd0-f089-4346-a4b9-fd90e5472db8,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-1260263c-51d6-40ae-a2b1-2af46287a810,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-4dbd6ef1-a76b-4682-a41a-35784244fa4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-736404266-172.17.0.17-1595963747461:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41847,DS-8228c6cd-0cee-4918-9d1b-221964c37f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-728d2944-6d18-4063-ad42-df76ec144030,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-d250b915-9b58-4156-8c8b-3ee4ef962b97,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-c3a75606-d213-41e4-8af2-042e9c2ea49b,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-ec820b59-9ec4-4312-8862-0c71f139fb37,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-9efe1bd0-f089-4346-a4b9-fd90e5472db8,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-1260263c-51d6-40ae-a2b1-2af46287a810,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-4dbd6ef1-a76b-4682-a41a-35784244fa4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-314070845-172.17.0.17-1595963789840:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45242,DS-10c4888d-0486-45c1-b379-0e64ccda30ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-f4adbcbe-8949-47a8-a2f7-a0a2ca3dc0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-a8b4b15e-ae3d-4d0f-98ba-7c21f00c3435,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-fbfff1db-8d6c-494c-9de1-ce58976297dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41709,DS-30f07e6f-d0f7-4092-8cf1-a31ead6e011a,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-68e7dfce-fa02-463a-b472-3705b50c5e77,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-529410cb-51ff-4fd0-ac54-ea32864350fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34657,DS-2c403282-cf42-41ad-b82b-fb992a082a3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-314070845-172.17.0.17-1595963789840:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45242,DS-10c4888d-0486-45c1-b379-0e64ccda30ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-f4adbcbe-8949-47a8-a2f7-a0a2ca3dc0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-a8b4b15e-ae3d-4d0f-98ba-7c21f00c3435,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-fbfff1db-8d6c-494c-9de1-ce58976297dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41709,DS-30f07e6f-d0f7-4092-8cf1-a31ead6e011a,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-68e7dfce-fa02-463a-b472-3705b50c5e77,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-529410cb-51ff-4fd0-ac54-ea32864350fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34657,DS-2c403282-cf42-41ad-b82b-fb992a082a3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-819556037-172.17.0.17-1595964017971:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45213,DS-bdd1feab-f872-4bcd-953b-a16136f3a685,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-3fa90e14-8fdd-47fe-b65c-2fceebbd5ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-e0efed64-53f8-44af-ba6b-7619e0080bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-cca9e074-022b-47d5-80b6-698563f95bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-774a98ca-c5dd-4b21-9bc2-ab5a082ed066,DISK], DatanodeInfoWithStorage[127.0.0.1:34787,DS-c67a1dc1-dc68-48d7-a6a2-44ae6b973f60,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-c5dbdd59-c30d-4612-86f3-fdae4c98cf2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38617,DS-53e183a5-fb1f-4b29-a063-61fea0919aa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-819556037-172.17.0.17-1595964017971:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45213,DS-bdd1feab-f872-4bcd-953b-a16136f3a685,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-3fa90e14-8fdd-47fe-b65c-2fceebbd5ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-e0efed64-53f8-44af-ba6b-7619e0080bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-cca9e074-022b-47d5-80b6-698563f95bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-774a98ca-c5dd-4b21-9bc2-ab5a082ed066,DISK], DatanodeInfoWithStorage[127.0.0.1:34787,DS-c67a1dc1-dc68-48d7-a6a2-44ae6b973f60,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-c5dbdd59-c30d-4612-86f3-fdae4c98cf2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38617,DS-53e183a5-fb1f-4b29-a063-61fea0919aa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1429497868-172.17.0.17-1595964269436:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45039,DS-10b4bc6e-95a1-44af-902b-4ea7047ae1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-b77ccfd5-22ae-475c-b472-04fa12d41967,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-30da6266-f3a3-425c-b95e-b8b851272cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-f4f96fe4-3a56-4593-9557-85163ed4b5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-9093d663-7bb2-4eef-b74f-2a7e751600c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-c5e80634-9ffe-4b29-b0f2-456c8cd9f1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-2866392e-1918-47de-a153-4fd8e7909362,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-71041b8a-5e65-4d61-b1d3-16e73ebeb61f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1429497868-172.17.0.17-1595964269436:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45039,DS-10b4bc6e-95a1-44af-902b-4ea7047ae1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-b77ccfd5-22ae-475c-b472-04fa12d41967,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-30da6266-f3a3-425c-b95e-b8b851272cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-f4f96fe4-3a56-4593-9557-85163ed4b5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-9093d663-7bb2-4eef-b74f-2a7e751600c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-c5e80634-9ffe-4b29-b0f2-456c8cd9f1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-2866392e-1918-47de-a153-4fd8e7909362,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-71041b8a-5e65-4d61-b1d3-16e73ebeb61f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1861798445-172.17.0.17-1595964404328:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46151,DS-bd533e3f-35c7-4610-8c32-c6b9d0eacf2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40210,DS-cb0f18ff-97cf-4bd0-9812-12401d9dea89,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-fa81e88d-ce05-4bb2-94f4-7aee1d6b681b,DISK], DatanodeInfoWithStorage[127.0.0.1:44445,DS-9a0c2600-13f0-4134-9170-cd66ea1e4695,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-288338b5-5a37-4d43-90c1-d3f27ee1df54,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-18b2b17b-93e9-4f4e-910d-c4b6a3aa5511,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-4e7a8290-a5e8-49c0-86bc-968fe0a249ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42887,DS-3ade2b64-8499-4076-873f-d437b633719d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1861798445-172.17.0.17-1595964404328:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46151,DS-bd533e3f-35c7-4610-8c32-c6b9d0eacf2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40210,DS-cb0f18ff-97cf-4bd0-9812-12401d9dea89,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-fa81e88d-ce05-4bb2-94f4-7aee1d6b681b,DISK], DatanodeInfoWithStorage[127.0.0.1:44445,DS-9a0c2600-13f0-4134-9170-cd66ea1e4695,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-288338b5-5a37-4d43-90c1-d3f27ee1df54,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-18b2b17b-93e9-4f4e-910d-c4b6a3aa5511,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-4e7a8290-a5e8-49c0-86bc-968fe0a249ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42887,DS-3ade2b64-8499-4076-873f-d437b633719d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1017082302-172.17.0.17-1595964609010:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42197,DS-8513c8da-67a3-41b0-a9dc-8cbed04be8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-40d4bfaa-cfde-4918-9c10-ae13de4fc2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33605,DS-6ea92e39-cb82-4743-bfd8-42792d6edd4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36165,DS-e6b71e2a-f068-405c-93b0-aae8b47b9b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33006,DS-7a759691-bf96-40f5-85f6-bced397aca64,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-73ff0f3d-e61e-4926-82b4-0c0aea7635ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40690,DS-be755664-8a83-48ae-9cbb-6e47c6187896,DISK], DatanodeInfoWithStorage[127.0.0.1:44809,DS-3e0b2b16-b284-4e6f-bd8a-08ac4141cb1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1017082302-172.17.0.17-1595964609010:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42197,DS-8513c8da-67a3-41b0-a9dc-8cbed04be8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-40d4bfaa-cfde-4918-9c10-ae13de4fc2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33605,DS-6ea92e39-cb82-4743-bfd8-42792d6edd4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36165,DS-e6b71e2a-f068-405c-93b0-aae8b47b9b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33006,DS-7a759691-bf96-40f5-85f6-bced397aca64,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-73ff0f3d-e61e-4926-82b4-0c0aea7635ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40690,DS-be755664-8a83-48ae-9cbb-6e47c6187896,DISK], DatanodeInfoWithStorage[127.0.0.1:44809,DS-3e0b2b16-b284-4e6f-bd8a-08ac4141cb1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1136816290-172.17.0.17-1595965151268:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46077,DS-72e9f910-b434-4929-9219-2b2f30352e65,DISK], DatanodeInfoWithStorage[127.0.0.1:39077,DS-6ca634d6-930e-4d6d-91e2-5b7fdf28dc93,DISK], DatanodeInfoWithStorage[127.0.0.1:40176,DS-a3d7e820-f7b2-422a-a99e-4e98bd1793bf,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-4306eaad-9d36-4e3a-bd20-a72183adc9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43585,DS-ef791bd4-19fd-4654-ac9e-6aa61d2e5b85,DISK], DatanodeInfoWithStorage[127.0.0.1:38843,DS-25d86c5c-1b1a-4c51-8dac-f4bf94d2d726,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-28a551b5-c745-4607-a7f6-aa0441cabe3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38558,DS-ba432c12-0a03-4158-b89f-ac8e4b759843,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1136816290-172.17.0.17-1595965151268:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46077,DS-72e9f910-b434-4929-9219-2b2f30352e65,DISK], DatanodeInfoWithStorage[127.0.0.1:39077,DS-6ca634d6-930e-4d6d-91e2-5b7fdf28dc93,DISK], DatanodeInfoWithStorage[127.0.0.1:40176,DS-a3d7e820-f7b2-422a-a99e-4e98bd1793bf,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-4306eaad-9d36-4e3a-bd20-a72183adc9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43585,DS-ef791bd4-19fd-4654-ac9e-6aa61d2e5b85,DISK], DatanodeInfoWithStorage[127.0.0.1:38843,DS-25d86c5c-1b1a-4c51-8dac-f4bf94d2d726,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-28a551b5-c745-4607-a7f6-aa0441cabe3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38558,DS-ba432c12-0a03-4158-b89f-ac8e4b759843,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-685388959-172.17.0.17-1595965226875:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43546,DS-36e8e0b0-d122-420d-a2cb-2eb15d2f0caa,DISK], DatanodeInfoWithStorage[127.0.0.1:43229,DS-e5579386-80fc-4f68-9689-38d94e9f8731,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-90625ac2-f642-4e53-a67e-2e708f71216b,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-b9cbfc93-1ab5-4bf1-842c-d86739b1f560,DISK], DatanodeInfoWithStorage[127.0.0.1:43497,DS-c08117b7-e0cc-4686-8185-b507ecfc6392,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-7d6cc75e-4949-42ce-9aea-fa02fe37daa9,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-11887390-1439-4975-a507-e4ab85a1f2d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-b9b2300e-0543-4694-a981-5fe1fab18609,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-685388959-172.17.0.17-1595965226875:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43546,DS-36e8e0b0-d122-420d-a2cb-2eb15d2f0caa,DISK], DatanodeInfoWithStorage[127.0.0.1:43229,DS-e5579386-80fc-4f68-9689-38d94e9f8731,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-90625ac2-f642-4e53-a67e-2e708f71216b,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-b9cbfc93-1ab5-4bf1-842c-d86739b1f560,DISK], DatanodeInfoWithStorage[127.0.0.1:43497,DS-c08117b7-e0cc-4686-8185-b507ecfc6392,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-7d6cc75e-4949-42ce-9aea-fa02fe37daa9,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-11887390-1439-4975-a507-e4ab85a1f2d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-b9b2300e-0543-4694-a981-5fe1fab18609,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1623997572-172.17.0.17-1595965315857:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33507,DS-8e2a2cbb-9599-4608-b45b-ddcf637c9e91,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-2f88e9f6-24d7-45c6-a7e5-20d453d8b8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45911,DS-7fcfb1a8-b6aa-493c-a75d-60ede1ab01fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-74fc14ee-722c-41ba-8876-92b4a6c69a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-a111ba5c-7932-41c0-8b14-c800f2febca2,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-358c9dc2-2913-4a9d-9ac4-4f67d83085b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34421,DS-7324447d-1734-4912-b1ac-f04707729ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-2f0b87ae-5a81-47a4-9c17-a4633236b7fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1623997572-172.17.0.17-1595965315857:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33507,DS-8e2a2cbb-9599-4608-b45b-ddcf637c9e91,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-2f88e9f6-24d7-45c6-a7e5-20d453d8b8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45911,DS-7fcfb1a8-b6aa-493c-a75d-60ede1ab01fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-74fc14ee-722c-41ba-8876-92b4a6c69a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-a111ba5c-7932-41c0-8b14-c800f2febca2,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-358c9dc2-2913-4a9d-9ac4-4f67d83085b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34421,DS-7324447d-1734-4912-b1ac-f04707729ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-2f0b87ae-5a81-47a4-9c17-a4633236b7fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6578
