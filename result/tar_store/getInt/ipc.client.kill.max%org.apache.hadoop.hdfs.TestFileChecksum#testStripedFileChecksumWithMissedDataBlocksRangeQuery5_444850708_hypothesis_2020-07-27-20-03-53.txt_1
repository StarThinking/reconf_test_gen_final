reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-600745457-172.17.0.17-1595880631013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41845,DS-52b0650a-c69e-4e9f-b61c-8f0dbe9fa5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44352,DS-fb8f400a-51c9-4fab-9139-07726dd28614,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-b445ec1a-2177-420d-8e2e-c607e5059597,DISK], DatanodeInfoWithStorage[127.0.0.1:32796,DS-348b125e-8a1a-4aef-a77b-e805f958814b,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-6036148f-29cd-49b0-a08c-3e2012f28971,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-17013f98-c510-4975-831f-23caafada00a,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-ebc62e44-464c-4463-9cee-ae00d37c384e,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-32bee37b-b480-4efa-9ad8-52ddcd0188f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-600745457-172.17.0.17-1595880631013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41845,DS-52b0650a-c69e-4e9f-b61c-8f0dbe9fa5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44352,DS-fb8f400a-51c9-4fab-9139-07726dd28614,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-b445ec1a-2177-420d-8e2e-c607e5059597,DISK], DatanodeInfoWithStorage[127.0.0.1:32796,DS-348b125e-8a1a-4aef-a77b-e805f958814b,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-6036148f-29cd-49b0-a08c-3e2012f28971,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-17013f98-c510-4975-831f-23caafada00a,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-ebc62e44-464c-4463-9cee-ae00d37c384e,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-32bee37b-b480-4efa-9ad8-52ddcd0188f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2096182465-172.17.0.17-1595880801421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45412,DS-61ce6dee-414c-4065-adb6-1768fb9bed1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40876,DS-58f8a9d9-0d29-4a27-890c-683eb90abcdc,DISK], DatanodeInfoWithStorage[127.0.0.1:44749,DS-caf19d29-e8ab-4688-a02f-b24cf1f8c1da,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-c7294bdd-7283-403b-b5eb-3bc706d5b41d,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-a00463e9-bb1e-45c9-8881-36f76efbbb77,DISK], DatanodeInfoWithStorage[127.0.0.1:37593,DS-b70e7b8c-5070-479f-8441-278f1746f41a,DISK], DatanodeInfoWithStorage[127.0.0.1:39913,DS-5056cb9a-f5e3-4202-acfe-d4f2059b383f,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-7537d1d1-4820-41c8-aff3-423fe7df9d6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2096182465-172.17.0.17-1595880801421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45412,DS-61ce6dee-414c-4065-adb6-1768fb9bed1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40876,DS-58f8a9d9-0d29-4a27-890c-683eb90abcdc,DISK], DatanodeInfoWithStorage[127.0.0.1:44749,DS-caf19d29-e8ab-4688-a02f-b24cf1f8c1da,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-c7294bdd-7283-403b-b5eb-3bc706d5b41d,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-a00463e9-bb1e-45c9-8881-36f76efbbb77,DISK], DatanodeInfoWithStorage[127.0.0.1:37593,DS-b70e7b8c-5070-479f-8441-278f1746f41a,DISK], DatanodeInfoWithStorage[127.0.0.1:39913,DS-5056cb9a-f5e3-4202-acfe-d4f2059b383f,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-7537d1d1-4820-41c8-aff3-423fe7df9d6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2017553251-172.17.0.17-1595880882070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35777,DS-3b2676de-be15-41f8-9612-7928c7090f72,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-c2806356-4f1a-40e9-8452-09f228efe881,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-eed74715-ba6f-4aae-b1ec-9d3afd533bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-3858ac02-71c4-44be-9722-a00e9ee370e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38595,DS-3f9267bb-c469-4dc9-8bcc-ed12c20dbdb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-ff1a6db4-7587-4509-becf-79b02e9c2ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-27e57f9f-5ac1-473b-b47a-e6d574a6aed1,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-787a8674-e163-49fd-8d60-fd1f2bd7215d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2017553251-172.17.0.17-1595880882070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35777,DS-3b2676de-be15-41f8-9612-7928c7090f72,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-c2806356-4f1a-40e9-8452-09f228efe881,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-eed74715-ba6f-4aae-b1ec-9d3afd533bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-3858ac02-71c4-44be-9722-a00e9ee370e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38595,DS-3f9267bb-c469-4dc9-8bcc-ed12c20dbdb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-ff1a6db4-7587-4509-becf-79b02e9c2ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-27e57f9f-5ac1-473b-b47a-e6d574a6aed1,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-787a8674-e163-49fd-8d60-fd1f2bd7215d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-595919119-172.17.0.17-1595880922286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35846,DS-d153df06-299a-4d80-980f-8c01307d66d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38565,DS-627017da-0f4e-4042-9c92-4ebf214007d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36984,DS-4a7ef2b8-a82c-4105-bca3-13c9eb3baa7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-98568381-4bfe-4ffa-98a2-b5df77f4a1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-6c83f157-add6-4b67-a98f-6f06824e4543,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-c7b430b2-8d02-4c62-8261-bd4a82f17a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-0a380929-ea13-4f1b-a91c-9cb33f3e23bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-f4ca3a9a-7e24-416d-88e6-28557c3066bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-595919119-172.17.0.17-1595880922286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35846,DS-d153df06-299a-4d80-980f-8c01307d66d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38565,DS-627017da-0f4e-4042-9c92-4ebf214007d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36984,DS-4a7ef2b8-a82c-4105-bca3-13c9eb3baa7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-98568381-4bfe-4ffa-98a2-b5df77f4a1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-6c83f157-add6-4b67-a98f-6f06824e4543,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-c7b430b2-8d02-4c62-8261-bd4a82f17a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-0a380929-ea13-4f1b-a91c-9cb33f3e23bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-f4ca3a9a-7e24-416d-88e6-28557c3066bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1626350623-172.17.0.17-1595881091554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33205,DS-243c6475-18d5-49f8-bf93-c97aee751be4,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-eddf78cc-f815-4833-87f9-f7608b2204c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-66b277ac-b80c-4418-8edc-a0e58296a5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-74b62958-bd0a-4d2c-be93-9fccd7ffe70b,DISK], DatanodeInfoWithStorage[127.0.0.1:33239,DS-d5b56244-e517-4e6a-9681-5564cf78a1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38993,DS-577ddbd5-ac9b-48af-babc-a72ff2e1c856,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-74bfd3a5-1ad3-48c1-a5ed-9cb62a4851ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-d796659b-a846-48d3-8826-0fc2fa7e14d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1626350623-172.17.0.17-1595881091554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33205,DS-243c6475-18d5-49f8-bf93-c97aee751be4,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-eddf78cc-f815-4833-87f9-f7608b2204c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-66b277ac-b80c-4418-8edc-a0e58296a5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-74b62958-bd0a-4d2c-be93-9fccd7ffe70b,DISK], DatanodeInfoWithStorage[127.0.0.1:33239,DS-d5b56244-e517-4e6a-9681-5564cf78a1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38993,DS-577ddbd5-ac9b-48af-babc-a72ff2e1c856,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-74bfd3a5-1ad3-48c1-a5ed-9cb62a4851ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-d796659b-a846-48d3-8826-0fc2fa7e14d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1245172465-172.17.0.17-1595881362247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38972,DS-7c57ab47-f53c-4e5e-8935-c4722222b616,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-e746f00c-23ee-4c62-b6d7-408be3a07d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-eaf265b6-7e7a-48b0-9875-890f3c711b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-e0719b4f-25ed-47f2-b332-a048cb3046da,DISK], DatanodeInfoWithStorage[127.0.0.1:37681,DS-518f848a-158e-4ded-9588-2f30390dadf1,DISK], DatanodeInfoWithStorage[127.0.0.1:36261,DS-0c0ae93b-bbb6-4966-b617-9d7f6949bd9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-ff5944f9-367f-4088-bcae-029986ce109c,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-265e81c9-6045-48ed-8405-bcadd485a044,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1245172465-172.17.0.17-1595881362247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38972,DS-7c57ab47-f53c-4e5e-8935-c4722222b616,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-e746f00c-23ee-4c62-b6d7-408be3a07d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-eaf265b6-7e7a-48b0-9875-890f3c711b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-e0719b4f-25ed-47f2-b332-a048cb3046da,DISK], DatanodeInfoWithStorage[127.0.0.1:37681,DS-518f848a-158e-4ded-9588-2f30390dadf1,DISK], DatanodeInfoWithStorage[127.0.0.1:36261,DS-0c0ae93b-bbb6-4966-b617-9d7f6949bd9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-ff5944f9-367f-4088-bcae-029986ce109c,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-265e81c9-6045-48ed-8405-bcadd485a044,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-644117226-172.17.0.17-1595882635211:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42410,DS-f4ad52fe-434a-4370-b609-7d7bd966481c,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-9681f0a5-3501-4956-9f47-766ab9415a52,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-1eeeeef1-94e1-426a-9bce-6ea63c919849,DISK], DatanodeInfoWithStorage[127.0.0.1:34382,DS-bf004712-2f08-4ef1-9665-ba03c3dde3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38261,DS-bc002096-8f82-4e5b-8904-205d5607887b,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-4a358fd1-3f7b-490b-a961-970bee2cee69,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-35cb8e10-dc46-45b3-8189-531601c94348,DISK], DatanodeInfoWithStorage[127.0.0.1:42950,DS-dc8ddc61-74e1-4235-9372-ecf8d2ca4195,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-644117226-172.17.0.17-1595882635211:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42410,DS-f4ad52fe-434a-4370-b609-7d7bd966481c,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-9681f0a5-3501-4956-9f47-766ab9415a52,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-1eeeeef1-94e1-426a-9bce-6ea63c919849,DISK], DatanodeInfoWithStorage[127.0.0.1:34382,DS-bf004712-2f08-4ef1-9665-ba03c3dde3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38261,DS-bc002096-8f82-4e5b-8904-205d5607887b,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-4a358fd1-3f7b-490b-a961-970bee2cee69,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-35cb8e10-dc46-45b3-8189-531601c94348,DISK], DatanodeInfoWithStorage[127.0.0.1:42950,DS-dc8ddc61-74e1-4235-9372-ecf8d2ca4195,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2132859715-172.17.0.17-1595882828308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42709,DS-9541be1f-3f1f-4923-ba59-d752c9664d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33528,DS-134614d9-de40-4ced-a7af-7b74a20dd2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-effb043d-6fa3-4761-9080-6886310820e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-e494f7bf-55f7-4d8c-a81b-ac9162a019a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-05200c93-a434-4e96-920c-bc1f3d02e4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44104,DS-ef3b6ac3-3ba7-4edd-b95e-d7d1d5a8368e,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-a3fbe174-b7bf-40d0-b154-4816d0918ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-09186d55-36d7-450f-a90e-df596f76852a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2132859715-172.17.0.17-1595882828308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42709,DS-9541be1f-3f1f-4923-ba59-d752c9664d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33528,DS-134614d9-de40-4ced-a7af-7b74a20dd2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-effb043d-6fa3-4761-9080-6886310820e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-e494f7bf-55f7-4d8c-a81b-ac9162a019a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-05200c93-a434-4e96-920c-bc1f3d02e4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44104,DS-ef3b6ac3-3ba7-4edd-b95e-d7d1d5a8368e,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-a3fbe174-b7bf-40d0-b154-4816d0918ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-09186d55-36d7-450f-a90e-df596f76852a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-387786701-172.17.0.17-1595883096041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40122,DS-da10daaf-28b2-46fe-812c-fc69af3f9ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-77eda469-8de2-4336-8ee4-919836209b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-3a020acc-8520-4749-986e-a74000dbd54c,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-84b70045-c7d9-450e-ae03-2840fbe3fa27,DISK], DatanodeInfoWithStorage[127.0.0.1:33473,DS-508035f6-3169-4b2c-bd96-5df24a94e1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-f721d08f-7f20-49ed-bc60-cb9e64f3abd0,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-9cc06cb3-0433-4f51-b6f6-bb8618ad0723,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-293421e1-e138-4199-abf7-84c0748d36c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-387786701-172.17.0.17-1595883096041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40122,DS-da10daaf-28b2-46fe-812c-fc69af3f9ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-77eda469-8de2-4336-8ee4-919836209b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-3a020acc-8520-4749-986e-a74000dbd54c,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-84b70045-c7d9-450e-ae03-2840fbe3fa27,DISK], DatanodeInfoWithStorage[127.0.0.1:33473,DS-508035f6-3169-4b2c-bd96-5df24a94e1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-f721d08f-7f20-49ed-bc60-cb9e64f3abd0,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-9cc06cb3-0433-4f51-b6f6-bb8618ad0723,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-293421e1-e138-4199-abf7-84c0748d36c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1843735291-172.17.0.17-1595883985034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42171,DS-11bc67ed-fa7a-4093-8d22-6186fb74e187,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-4ad6f643-75e8-4c9a-b3d1-02050523278a,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-fe5cf0b6-8ace-4e52-afdc-ae94fc45aa87,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-f0164b7b-1a22-4567-9f4c-5d3be6d97279,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-f7d9156f-703a-4097-806e-5515a60bf858,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-0a30dbfa-463c-45ea-a9ab-91ba9c1557e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41638,DS-55370598-4a70-49cc-b45d-beb242e57bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-34b8a556-9861-46d8-819b-1740a4611719,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1843735291-172.17.0.17-1595883985034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42171,DS-11bc67ed-fa7a-4093-8d22-6186fb74e187,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-4ad6f643-75e8-4c9a-b3d1-02050523278a,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-fe5cf0b6-8ace-4e52-afdc-ae94fc45aa87,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-f0164b7b-1a22-4567-9f4c-5d3be6d97279,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-f7d9156f-703a-4097-806e-5515a60bf858,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-0a30dbfa-463c-45ea-a9ab-91ba9c1557e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41638,DS-55370598-4a70-49cc-b45d-beb242e57bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-34b8a556-9861-46d8-819b-1740a4611719,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1612970018-172.17.0.17-1595884109051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36127,DS-a6088e84-78a7-40c1-a9f4-b9eb948b9691,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-44a153be-f295-4c16-bbca-e0e0f2a58e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-5cd4eb22-33b6-4cd1-8c78-a3df35ee8ead,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-75476510-36a6-4c4a-9c12-6a6dfccef14f,DISK], DatanodeInfoWithStorage[127.0.0.1:34892,DS-fb5bde18-36ea-4205-a033-8c3448da4187,DISK], DatanodeInfoWithStorage[127.0.0.1:42382,DS-774c392f-6ec0-4070-8a7d-a2aa7337deca,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-1f852643-f795-413e-ae94-7a6b3394984c,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-630d744f-b735-4b5a-9b4a-efeb67db226f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1612970018-172.17.0.17-1595884109051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36127,DS-a6088e84-78a7-40c1-a9f4-b9eb948b9691,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-44a153be-f295-4c16-bbca-e0e0f2a58e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-5cd4eb22-33b6-4cd1-8c78-a3df35ee8ead,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-75476510-36a6-4c4a-9c12-6a6dfccef14f,DISK], DatanodeInfoWithStorage[127.0.0.1:34892,DS-fb5bde18-36ea-4205-a033-8c3448da4187,DISK], DatanodeInfoWithStorage[127.0.0.1:42382,DS-774c392f-6ec0-4070-8a7d-a2aa7337deca,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-1f852643-f795-413e-ae94-7a6b3394984c,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-630d744f-b735-4b5a-9b4a-efeb67db226f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-907695184-172.17.0.17-1595884526738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36050,DS-4836edb2-9455-4eb6-b308-79a3abeacd22,DISK], DatanodeInfoWithStorage[127.0.0.1:33210,DS-f0cdedb8-1ebb-44cf-9399-d454b048a83a,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-6d209d0f-58b2-42b8-b9ca-706d192e541e,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-3a758dda-0c2a-4575-81b7-e016598bbe6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-782120ba-cafc-46d1-beb2-807547f402df,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-5cafbf4d-5364-4c7f-811d-38db7258e95d,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-231dcc00-f0fc-4f26-ae0d-744a02c58e95,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-f3d8e74b-0880-4f0f-b50f-066cbf5be40c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-907695184-172.17.0.17-1595884526738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36050,DS-4836edb2-9455-4eb6-b308-79a3abeacd22,DISK], DatanodeInfoWithStorage[127.0.0.1:33210,DS-f0cdedb8-1ebb-44cf-9399-d454b048a83a,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-6d209d0f-58b2-42b8-b9ca-706d192e541e,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-3a758dda-0c2a-4575-81b7-e016598bbe6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-782120ba-cafc-46d1-beb2-807547f402df,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-5cafbf4d-5364-4c7f-811d-38db7258e95d,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-231dcc00-f0fc-4f26-ae0d-744a02c58e95,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-f3d8e74b-0880-4f0f-b50f-066cbf5be40c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2090168180-172.17.0.17-1595884899428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44773,DS-2f5c0280-a459-4046-ba04-c436a502c030,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-6dcea0d7-67bf-4567-8a27-0448f7df247c,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-2443baa4-60d2-4e99-9389-468c3a0abf6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46820,DS-9cb79839-2ea8-44ac-8666-cc4783f43bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-31cbedbf-2c96-42f6-b178-2fc6312ce2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41068,DS-69bda5bb-2034-4824-8c8d-5134299c83ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-d8a48e81-b0a2-42f3-a56f-e33c3440534b,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-2a6e0178-d111-4ed3-ac68-7e9d1bd997b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2090168180-172.17.0.17-1595884899428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44773,DS-2f5c0280-a459-4046-ba04-c436a502c030,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-6dcea0d7-67bf-4567-8a27-0448f7df247c,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-2443baa4-60d2-4e99-9389-468c3a0abf6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46820,DS-9cb79839-2ea8-44ac-8666-cc4783f43bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-31cbedbf-2c96-42f6-b178-2fc6312ce2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41068,DS-69bda5bb-2034-4824-8c8d-5134299c83ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-d8a48e81-b0a2-42f3-a56f-e33c3440534b,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-2a6e0178-d111-4ed3-ac68-7e9d1bd997b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2082034780-172.17.0.17-1595885070701:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37255,DS-f9a658bb-421e-44c6-b785-57cd744d9e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-fe7d1e58-d28b-448a-a6ce-433104af5827,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-874b7328-2038-4105-aa79-ca96067696ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-b77fbce8-2e1f-44e2-bbc7-e2b551226d53,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-3d07a81f-510f-466d-acfe-de8cd9aa57e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-a90b5ac3-7ef4-48d3-81f1-52965929a80e,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-f1db1d75-09a3-4617-aac1-ee662f157eae,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-982412ed-c69c-4240-9c22-ef535d5a0045,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2082034780-172.17.0.17-1595885070701:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37255,DS-f9a658bb-421e-44c6-b785-57cd744d9e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-fe7d1e58-d28b-448a-a6ce-433104af5827,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-874b7328-2038-4105-aa79-ca96067696ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-b77fbce8-2e1f-44e2-bbc7-e2b551226d53,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-3d07a81f-510f-466d-acfe-de8cd9aa57e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-a90b5ac3-7ef4-48d3-81f1-52965929a80e,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-f1db1d75-09a3-4617-aac1-ee662f157eae,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-982412ed-c69c-4240-9c22-ef535d5a0045,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-719574749-172.17.0.17-1595885274429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45619,DS-0795778a-3955-435c-a675-89ff600bfad3,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-db03869b-df4b-48cc-b6e8-eb3213e6f6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-c8217c81-500e-4810-849d-2b2eb8919bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-8e855558-4925-46d7-bedd-a33c618d69e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-b6ac8206-6b97-4693-8281-e44bd1a02a62,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-0aa10f29-03d7-4834-8357-9adc70aaa093,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-1d2e0941-b1db-4028-9824-adc763bce788,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-74978bf2-855e-4490-8551-d6d9a613cab9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-719574749-172.17.0.17-1595885274429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45619,DS-0795778a-3955-435c-a675-89ff600bfad3,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-db03869b-df4b-48cc-b6e8-eb3213e6f6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-c8217c81-500e-4810-849d-2b2eb8919bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-8e855558-4925-46d7-bedd-a33c618d69e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-b6ac8206-6b97-4693-8281-e44bd1a02a62,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-0aa10f29-03d7-4834-8357-9adc70aaa093,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-1d2e0941-b1db-4028-9824-adc763bce788,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-74978bf2-855e-4490-8551-d6d9a613cab9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1278426686-172.17.0.17-1595885476082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46216,DS-2eb4459c-fb70-40cf-86e0-52ace281f78d,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-205b7583-a35c-48d6-b75a-3267f8e0542a,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-add68ccc-be5e-48ff-ab6f-4854ba09d7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-bf137a4e-b220-48d2-824d-879882fd8125,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-5f735046-93e2-4be3-899c-353eb645651e,DISK], DatanodeInfoWithStorage[127.0.0.1:46539,DS-7c343439-04ff-4604-aa4e-09be0c6f7a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-40c4e997-02ed-4c7d-ade3-7d6379b6f9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-0cda663e-a0da-4adc-be64-28b92b924dc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1278426686-172.17.0.17-1595885476082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46216,DS-2eb4459c-fb70-40cf-86e0-52ace281f78d,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-205b7583-a35c-48d6-b75a-3267f8e0542a,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-add68ccc-be5e-48ff-ab6f-4854ba09d7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-bf137a4e-b220-48d2-824d-879882fd8125,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-5f735046-93e2-4be3-899c-353eb645651e,DISK], DatanodeInfoWithStorage[127.0.0.1:46539,DS-7c343439-04ff-4604-aa4e-09be0c6f7a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-40c4e997-02ed-4c7d-ade3-7d6379b6f9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-0cda663e-a0da-4adc-be64-28b92b924dc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1804378152-172.17.0.17-1595885561419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34266,DS-8ffb4c82-891c-498b-b315-d65fb5928309,DISK], DatanodeInfoWithStorage[127.0.0.1:40530,DS-76f5a2e9-b9ca-43d2-9964-825218038db2,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-8223aa1a-f8ad-4f94-afda-d1a2b86edd39,DISK], DatanodeInfoWithStorage[127.0.0.1:42351,DS-8e5c74c9-62e3-48f3-9d6a-e87f5911ca49,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-f8d24759-058b-4975-a1d5-6a836affecb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-15511655-fe4a-4232-9bc5-363dc739796d,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-a7652c0d-8b58-43f1-a760-33e44ce9ab5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-fabe2815-22b2-46d2-b6b6-a9bee58550fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1804378152-172.17.0.17-1595885561419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34266,DS-8ffb4c82-891c-498b-b315-d65fb5928309,DISK], DatanodeInfoWithStorage[127.0.0.1:40530,DS-76f5a2e9-b9ca-43d2-9964-825218038db2,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-8223aa1a-f8ad-4f94-afda-d1a2b86edd39,DISK], DatanodeInfoWithStorage[127.0.0.1:42351,DS-8e5c74c9-62e3-48f3-9d6a-e87f5911ca49,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-f8d24759-058b-4975-a1d5-6a836affecb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-15511655-fe4a-4232-9bc5-363dc739796d,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-a7652c0d-8b58-43f1-a760-33e44ce9ab5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-fabe2815-22b2-46d2-b6b6-a9bee58550fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-628535181-172.17.0.17-1595885636008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39530,DS-12335684-4916-4f59-9d22-d19ca9e4b790,DISK], DatanodeInfoWithStorage[127.0.0.1:41505,DS-05e561d1-dee6-4918-b062-86fe4e579c15,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-d557c7fe-48d5-48aa-9e35-bed8d04996a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44038,DS-aef72425-10d1-4e39-8908-d2106f5f697c,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-881e3c13-bada-4b36-bc30-caf20b9abc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-5eeac359-9d8e-4dab-ae4b-31651cae0476,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-d80e391a-71e6-4b7d-90e2-d72ea5ae3587,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-051855d9-6f02-4481-9e0d-6f2969c61d8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-628535181-172.17.0.17-1595885636008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39530,DS-12335684-4916-4f59-9d22-d19ca9e4b790,DISK], DatanodeInfoWithStorage[127.0.0.1:41505,DS-05e561d1-dee6-4918-b062-86fe4e579c15,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-d557c7fe-48d5-48aa-9e35-bed8d04996a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44038,DS-aef72425-10d1-4e39-8908-d2106f5f697c,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-881e3c13-bada-4b36-bc30-caf20b9abc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-5eeac359-9d8e-4dab-ae4b-31651cae0476,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-d80e391a-71e6-4b7d-90e2-d72ea5ae3587,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-051855d9-6f02-4481-9e0d-6f2969c61d8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-265183237-172.17.0.17-1595886447576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38631,DS-ef74e995-6f03-4370-bd2b-da5d63d7c34a,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-b7118243-8d29-40ab-9ee5-55cd8b2fe18c,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-9125b57d-1691-46bd-9362-53fc2ff0248d,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-6533c159-abce-4656-8d02-ad3faedced04,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-7eb3f4e1-69df-405c-910b-37ebf0431ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:40555,DS-45d1bc97-689c-486e-9fdb-c57cadad33b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-32521c94-d8da-4cb6-897f-2cc8be543923,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-3345dbea-85c5-4c78-8a37-42de87192afe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-265183237-172.17.0.17-1595886447576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38631,DS-ef74e995-6f03-4370-bd2b-da5d63d7c34a,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-b7118243-8d29-40ab-9ee5-55cd8b2fe18c,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-9125b57d-1691-46bd-9362-53fc2ff0248d,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-6533c159-abce-4656-8d02-ad3faedced04,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-7eb3f4e1-69df-405c-910b-37ebf0431ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:40555,DS-45d1bc97-689c-486e-9fdb-c57cadad33b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-32521c94-d8da-4cb6-897f-2cc8be543923,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-3345dbea-85c5-4c78-8a37-42de87192afe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2119336151-172.17.0.17-1595886489664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37798,DS-9cd04fd6-24a4-42e7-968f-08cc3fdbb04b,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-73a593d3-f334-4e85-b93e-155fe695575d,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-a4e1d072-b356-43d8-bdb5-aecb227edaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-dc40fd73-a124-4e52-a01d-f7b1b8740c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-13705780-72b5-4294-9090-b2ad6c1cbe7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-90a1e045-621f-4315-a151-9dda113a65ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-ddeaac73-3ee4-4cda-9361-289c77f93a79,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-add0eb8c-0c30-4230-8375-2590048f9915,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2119336151-172.17.0.17-1595886489664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37798,DS-9cd04fd6-24a4-42e7-968f-08cc3fdbb04b,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-73a593d3-f334-4e85-b93e-155fe695575d,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-a4e1d072-b356-43d8-bdb5-aecb227edaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-dc40fd73-a124-4e52-a01d-f7b1b8740c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-13705780-72b5-4294-9090-b2ad6c1cbe7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-90a1e045-621f-4315-a151-9dda113a65ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-ddeaac73-3ee4-4cda-9361-289c77f93a79,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-add0eb8c-0c30-4230-8375-2590048f9915,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 6413
