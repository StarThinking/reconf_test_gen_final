reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-91701180-172.17.0.17-1595966453941:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32796,DS-8d5c0e9d-145f-457b-9715-0156c5450557,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-2bc42fb8-4115-436a-b9a4-0af40b55c7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38782,DS-8e12beaa-1b4e-4748-9a4a-288c248cc346,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-6ed8882a-5c91-4d21-915a-305f6fdd8547,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-4df33df1-589d-488c-90e8-e5fcf514f98a,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-a114adc9-0875-43e6-bedc-92e155d1d6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-84515108-c7c6-476e-9316-d4b8b102a13a,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-0d999294-47a5-48aa-b87d-b6150c629e8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-91701180-172.17.0.17-1595966453941:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32796,DS-8d5c0e9d-145f-457b-9715-0156c5450557,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-2bc42fb8-4115-436a-b9a4-0af40b55c7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38782,DS-8e12beaa-1b4e-4748-9a4a-288c248cc346,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-6ed8882a-5c91-4d21-915a-305f6fdd8547,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-4df33df1-589d-488c-90e8-e5fcf514f98a,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-a114adc9-0875-43e6-bedc-92e155d1d6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-84515108-c7c6-476e-9316-d4b8b102a13a,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-0d999294-47a5-48aa-b87d-b6150c629e8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1979011040-172.17.0.17-1595967721797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46304,DS-37b7b252-9ac5-46d7-afc7-4af26428d16c,DISK], DatanodeInfoWithStorage[127.0.0.1:34076,DS-b6758a8d-33e8-4dc2-8f2e-deafc805fa01,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-1407f34a-d386-435f-9062-8cff3a2138f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-bd8057fb-ee5e-4d84-a91a-6c44a1ffca36,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-288d3895-816c-43aa-afe5-23bae854928f,DISK], DatanodeInfoWithStorage[127.0.0.1:34199,DS-f1318f0e-2891-42fd-b933-15ad333af386,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-56216a6e-7fbd-466b-8fa3-09826656bd1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35252,DS-c5c47f68-e499-4519-9dd3-f22ff3b6d2d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1979011040-172.17.0.17-1595967721797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46304,DS-37b7b252-9ac5-46d7-afc7-4af26428d16c,DISK], DatanodeInfoWithStorage[127.0.0.1:34076,DS-b6758a8d-33e8-4dc2-8f2e-deafc805fa01,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-1407f34a-d386-435f-9062-8cff3a2138f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-bd8057fb-ee5e-4d84-a91a-6c44a1ffca36,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-288d3895-816c-43aa-afe5-23bae854928f,DISK], DatanodeInfoWithStorage[127.0.0.1:34199,DS-f1318f0e-2891-42fd-b933-15ad333af386,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-56216a6e-7fbd-466b-8fa3-09826656bd1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35252,DS-c5c47f68-e499-4519-9dd3-f22ff3b6d2d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1322784517-172.17.0.17-1595968230671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41283,DS-fea5e373-03bb-4159-8784-7ee26b6ca73b,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-84f35476-8a7e-4f05-8ae0-0568d47b1005,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-8a6e3d94-9af6-48e0-9aa6-0696c22b4254,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-91c8f73b-c671-47b6-8443-4b25f681ceb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-3a8d9358-62a6-4558-acb9-bfeb95613100,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-92e7b159-c683-4e4a-af13-7fa539a8a495,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-bc8ec693-2977-4f54-9ba8-e0a5625918ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34054,DS-8e242221-8ca0-4eae-ab15-60c6affca804,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1322784517-172.17.0.17-1595968230671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41283,DS-fea5e373-03bb-4159-8784-7ee26b6ca73b,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-84f35476-8a7e-4f05-8ae0-0568d47b1005,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-8a6e3d94-9af6-48e0-9aa6-0696c22b4254,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-91c8f73b-c671-47b6-8443-4b25f681ceb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-3a8d9358-62a6-4558-acb9-bfeb95613100,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-92e7b159-c683-4e4a-af13-7fa539a8a495,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-bc8ec693-2977-4f54-9ba8-e0a5625918ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34054,DS-8e242221-8ca0-4eae-ab15-60c6affca804,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1004427923-172.17.0.17-1595968264114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45132,DS-cfeb485d-ba47-468e-92d1-10557559f2ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-d4ffa8a6-7891-4521-99f6-75365da11b46,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-b16ea2d8-6ab4-4e75-a60f-e705c358478c,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-78b4fecb-bba8-4626-aa0e-fff11753d354,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-bc8b023e-87fc-492b-be59-67be2a3198ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42927,DS-e9dfb714-d4cd-4ab8-a248-9533fdf4c9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-3f78ffb0-32d6-4e23-9dab-248a1f0d8f95,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-3fb40f05-c29d-4880-9790-b472b3af290c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1004427923-172.17.0.17-1595968264114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45132,DS-cfeb485d-ba47-468e-92d1-10557559f2ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-d4ffa8a6-7891-4521-99f6-75365da11b46,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-b16ea2d8-6ab4-4e75-a60f-e705c358478c,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-78b4fecb-bba8-4626-aa0e-fff11753d354,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-bc8b023e-87fc-492b-be59-67be2a3198ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42927,DS-e9dfb714-d4cd-4ab8-a248-9533fdf4c9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-3f78ffb0-32d6-4e23-9dab-248a1f0d8f95,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-3fb40f05-c29d-4880-9790-b472b3af290c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1484222918-172.17.0.17-1595968554432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37559,DS-f08867b9-7c81-488b-9bb7-90dd115b359c,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-92229463-92fe-4a50-a16b-5eba684797ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-ec1c988a-44eb-47cf-a815-49948a33eb76,DISK], DatanodeInfoWithStorage[127.0.0.1:39166,DS-ca028dc7-eae8-45a2-b23e-fe7ef34e3037,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-e6f99db2-286c-4b95-82ed-cdb7ea92f2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-38ecf52c-4064-4268-bd4b-8744ac80eced,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-8c4d39d9-87b5-4ae6-bef8-d70e1549f76f,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-1f5199c7-348f-42c9-a18c-ef44712a8eda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1484222918-172.17.0.17-1595968554432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37559,DS-f08867b9-7c81-488b-9bb7-90dd115b359c,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-92229463-92fe-4a50-a16b-5eba684797ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-ec1c988a-44eb-47cf-a815-49948a33eb76,DISK], DatanodeInfoWithStorage[127.0.0.1:39166,DS-ca028dc7-eae8-45a2-b23e-fe7ef34e3037,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-e6f99db2-286c-4b95-82ed-cdb7ea92f2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-38ecf52c-4064-4268-bd4b-8744ac80eced,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-8c4d39d9-87b5-4ae6-bef8-d70e1549f76f,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-1f5199c7-348f-42c9-a18c-ef44712a8eda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1004365655-172.17.0.17-1595969026986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44188,DS-b464ae29-b9de-4598-b3eb-7407781af74b,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-11b00962-ada6-4b29-87d3-cd75f2da0b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-8c301c9a-d737-4876-8296-81e9088abb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-a7dbec2f-1d66-4f24-889d-d0681e386d02,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-32a3d952-2ead-4a70-83a6-552b4196f6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38546,DS-72c502c3-e924-4d21-9303-0313fe6a1c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39500,DS-b8ecc44c-0ab7-4dbf-a4b5-de75c6d9506d,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-adc0f454-3cbe-4320-9698-50bdd1b5a20f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1004365655-172.17.0.17-1595969026986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44188,DS-b464ae29-b9de-4598-b3eb-7407781af74b,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-11b00962-ada6-4b29-87d3-cd75f2da0b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-8c301c9a-d737-4876-8296-81e9088abb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-a7dbec2f-1d66-4f24-889d-d0681e386d02,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-32a3d952-2ead-4a70-83a6-552b4196f6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38546,DS-72c502c3-e924-4d21-9303-0313fe6a1c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39500,DS-b8ecc44c-0ab7-4dbf-a4b5-de75c6d9506d,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-adc0f454-3cbe-4320-9698-50bdd1b5a20f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1020395023-172.17.0.17-1595969062045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35326,DS-d28f5ffa-6e96-45de-b3d9-7747a6f966ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44238,DS-709cbebe-a42a-4aff-bf7b-e0ab10177bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-c972c080-ae6e-49de-9463-389ef022ef9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-60c8e9db-ddd9-4e48-a1c1-fc8bdea8f67f,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-9c7a4678-fc57-44cf-b8d9-79d2940772f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43232,DS-8962658d-ed71-4bd2-88c8-f81b143c0de7,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-67720e3a-61ba-48d4-beb2-bdb9d1e760f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-3e4105df-7dc2-46f6-80b7-a2ce6f6929de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1020395023-172.17.0.17-1595969062045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35326,DS-d28f5ffa-6e96-45de-b3d9-7747a6f966ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44238,DS-709cbebe-a42a-4aff-bf7b-e0ab10177bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-c972c080-ae6e-49de-9463-389ef022ef9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-60c8e9db-ddd9-4e48-a1c1-fc8bdea8f67f,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-9c7a4678-fc57-44cf-b8d9-79d2940772f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43232,DS-8962658d-ed71-4bd2-88c8-f81b143c0de7,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-67720e3a-61ba-48d4-beb2-bdb9d1e760f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-3e4105df-7dc2-46f6-80b7-a2ce6f6929de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1517528156-172.17.0.17-1595969205786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38255,DS-671837f5-4080-4e1e-a709-bcf89a581a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39679,DS-45a800ad-9dca-4cc4-bc4f-b3ea83eadc95,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-ef40ebc9-dff2-4477-a19f-2f0e1a43b8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-ef16c90d-68a3-4d36-898a-a9a14722f494,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-124fd8b4-6cbf-4741-9af9-a810db070cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-49a237eb-3fa9-421f-bdc9-e5092e4a0db5,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-87bff6f3-f19d-4405-9839-9ba7f7e1718b,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-d0729932-7ff7-4898-b2f2-8f9edfe5d480,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1517528156-172.17.0.17-1595969205786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38255,DS-671837f5-4080-4e1e-a709-bcf89a581a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39679,DS-45a800ad-9dca-4cc4-bc4f-b3ea83eadc95,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-ef40ebc9-dff2-4477-a19f-2f0e1a43b8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-ef16c90d-68a3-4d36-898a-a9a14722f494,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-124fd8b4-6cbf-4741-9af9-a810db070cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-49a237eb-3fa9-421f-bdc9-e5092e4a0db5,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-87bff6f3-f19d-4405-9839-9ba7f7e1718b,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-d0729932-7ff7-4898-b2f2-8f9edfe5d480,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-608174081-172.17.0.17-1595969889294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42018,DS-1da050d5-3134-45f7-a7b6-7415f83710ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-d24d7774-7cbb-4c22-b3e2-9e070ac973cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-b76bbde5-09da-46c6-ad17-f8b1329de04b,DISK], DatanodeInfoWithStorage[127.0.0.1:36357,DS-c10760e9-9e35-43b3-8f34-3ec06c5176b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-56c03b64-47ac-4c8c-aa2a-46cd329387b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-f41a558e-e6b3-4953-880b-02978662183a,DISK], DatanodeInfoWithStorage[127.0.0.1:43458,DS-8487e217-09b2-4999-83a4-f9ce5dd7b1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-6fc5e304-d779-414b-9375-2b7c5c7b78c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-608174081-172.17.0.17-1595969889294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42018,DS-1da050d5-3134-45f7-a7b6-7415f83710ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-d24d7774-7cbb-4c22-b3e2-9e070ac973cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-b76bbde5-09da-46c6-ad17-f8b1329de04b,DISK], DatanodeInfoWithStorage[127.0.0.1:36357,DS-c10760e9-9e35-43b3-8f34-3ec06c5176b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-56c03b64-47ac-4c8c-aa2a-46cd329387b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-f41a558e-e6b3-4953-880b-02978662183a,DISK], DatanodeInfoWithStorage[127.0.0.1:43458,DS-8487e217-09b2-4999-83a4-f9ce5dd7b1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-6fc5e304-d779-414b-9375-2b7c5c7b78c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-855034905-172.17.0.17-1595970555460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35857,DS-e57375cb-10be-40d0-96e7-e9dc8b200de5,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-5588ecf5-96a0-4ce9-bc32-d26241751eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-d648dca9-0806-4d34-8912-62eed55ab3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-fbe3810a-773b-49d5-b1d8-f3f6432a1514,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-f423d4a1-b8ca-4024-994e-c5402eb0aaec,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-d3122b83-196d-4e00-8d3d-a5a14fb0e38b,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-e7e29daa-2f68-4350-a4ac-6c98e9be9f88,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-dd1100e6-0d98-4370-b673-d9de6e8f9a41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-855034905-172.17.0.17-1595970555460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35857,DS-e57375cb-10be-40d0-96e7-e9dc8b200de5,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-5588ecf5-96a0-4ce9-bc32-d26241751eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-d648dca9-0806-4d34-8912-62eed55ab3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-fbe3810a-773b-49d5-b1d8-f3f6432a1514,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-f423d4a1-b8ca-4024-994e-c5402eb0aaec,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-d3122b83-196d-4e00-8d3d-a5a14fb0e38b,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-e7e29daa-2f68-4350-a4ac-6c98e9be9f88,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-dd1100e6-0d98-4370-b673-d9de6e8f9a41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1060970015-172.17.0.17-1595970747746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32830,DS-86216497-d4a5-4cfa-93ef-b6ed8ee42483,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-f12409b1-012b-4aac-b99a-3d04e594945e,DISK], DatanodeInfoWithStorage[127.0.0.1:38406,DS-9985802e-eac0-4882-b8f1-821c20593f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-174c006e-0856-40b0-b77f-0bbaff93ede0,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-3228865d-f861-4e05-9091-79e162ca7f04,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-de3f939e-fc65-4138-952c-e771791612a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-84f15c8e-a48a-4ccf-92ad-96193be17898,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-8703dda6-5402-4c47-b7cb-2ae7b49e259b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1060970015-172.17.0.17-1595970747746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32830,DS-86216497-d4a5-4cfa-93ef-b6ed8ee42483,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-f12409b1-012b-4aac-b99a-3d04e594945e,DISK], DatanodeInfoWithStorage[127.0.0.1:38406,DS-9985802e-eac0-4882-b8f1-821c20593f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-174c006e-0856-40b0-b77f-0bbaff93ede0,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-3228865d-f861-4e05-9091-79e162ca7f04,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-de3f939e-fc65-4138-952c-e771791612a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-84f15c8e-a48a-4ccf-92ad-96193be17898,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-8703dda6-5402-4c47-b7cb-2ae7b49e259b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1737405944-172.17.0.17-1595971291623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35969,DS-48d2f519-5240-47bf-8161-96d68be579dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-684d5ee7-aa62-4e7b-9146-d8386d5613fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-7766a8ba-2711-4a1e-a304-3e1717517c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-5585184f-bb12-4a7a-bfe1-38a8bbf69d86,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-7875ee16-f8db-47fe-b032-ac6c57440b50,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-bc843544-d41d-4ca3-91b2-8a5a431190f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36989,DS-14015249-9fc3-4dd3-816b-3a5fd96366f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-74344c05-5779-4f6d-8a47-bb5ea67f3053,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1737405944-172.17.0.17-1595971291623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35969,DS-48d2f519-5240-47bf-8161-96d68be579dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-684d5ee7-aa62-4e7b-9146-d8386d5613fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-7766a8ba-2711-4a1e-a304-3e1717517c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-5585184f-bb12-4a7a-bfe1-38a8bbf69d86,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-7875ee16-f8db-47fe-b032-ac6c57440b50,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-bc843544-d41d-4ca3-91b2-8a5a431190f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36989,DS-14015249-9fc3-4dd3-816b-3a5fd96366f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-74344c05-5779-4f6d-8a47-bb5ea67f3053,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5273
