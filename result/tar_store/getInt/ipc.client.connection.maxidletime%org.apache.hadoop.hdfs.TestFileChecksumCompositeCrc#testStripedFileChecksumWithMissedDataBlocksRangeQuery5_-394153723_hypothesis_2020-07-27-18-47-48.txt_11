reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1171895925-172.17.0.21-1595875975874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40972,DS-d3269488-d9d2-420d-9176-0dfe2bb9b9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37553,DS-1050e0dc-af0e-42d4-af6c-4714157aa145,DISK], DatanodeInfoWithStorage[127.0.0.1:37967,DS-a1fbf73c-6aee-4ab5-b6c5-07f719ea64ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-611efec9-3be2-4d0c-8365-71db7e69af9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-189fd14d-3b34-405e-8a86-6cf7f1be6ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-8c729dc5-818d-44a5-a482-7b789aef6890,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-cc7e55e5-52c3-4671-bdd0-3002eaee61e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-a622d6d7-e70e-4589-960c-c21a790fd395,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1171895925-172.17.0.21-1595875975874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40972,DS-d3269488-d9d2-420d-9176-0dfe2bb9b9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37553,DS-1050e0dc-af0e-42d4-af6c-4714157aa145,DISK], DatanodeInfoWithStorage[127.0.0.1:37967,DS-a1fbf73c-6aee-4ab5-b6c5-07f719ea64ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-611efec9-3be2-4d0c-8365-71db7e69af9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-189fd14d-3b34-405e-8a86-6cf7f1be6ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-8c729dc5-818d-44a5-a482-7b789aef6890,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-cc7e55e5-52c3-4671-bdd0-3002eaee61e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-a622d6d7-e70e-4589-960c-c21a790fd395,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934674475-172.17.0.21-1595876277456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39515,DS-d9ec5ad6-7679-415b-9c31-ce68c82e75ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-7791c5af-d8d5-49dc-a050-b27a043dafea,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-cc6d6131-faee-4e60-af6c-8df4ae267e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-ca3f1b26-8a11-468a-877b-4903858d6a64,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-3f117c5d-18eb-4a83-a477-73ce0dad3f67,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-b6bdc87b-8a15-4948-928f-200e5f832579,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-20ca160a-e3a0-4313-961d-fa6e8802986b,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-5d83860a-7320-40da-b8c7-f73117134110,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934674475-172.17.0.21-1595876277456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39515,DS-d9ec5ad6-7679-415b-9c31-ce68c82e75ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-7791c5af-d8d5-49dc-a050-b27a043dafea,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-cc6d6131-faee-4e60-af6c-8df4ae267e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-ca3f1b26-8a11-468a-877b-4903858d6a64,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-3f117c5d-18eb-4a83-a477-73ce0dad3f67,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-b6bdc87b-8a15-4948-928f-200e5f832579,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-20ca160a-e3a0-4313-961d-fa6e8802986b,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-5d83860a-7320-40da-b8c7-f73117134110,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1786153527-172.17.0.21-1595876769197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37400,DS-187b3df1-6e60-45de-9d2a-e3b704562a21,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-a37effb1-0911-4f0e-bdbc-80601d4a9c18,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-9f64638e-ea74-4b03-9976-ed3ab73314b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41469,DS-e809fcc3-83a6-4ceb-9792-78510f356a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-33fd3307-7d29-4017-94b1-f5ea3a47c8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-41fde18a-81a7-40c7-8673-203991bd679f,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-b13c0596-1ecc-4c19-868b-88fcc0acb55c,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-0f5dab85-0187-4ed2-a74d-059354a67ed4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1786153527-172.17.0.21-1595876769197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37400,DS-187b3df1-6e60-45de-9d2a-e3b704562a21,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-a37effb1-0911-4f0e-bdbc-80601d4a9c18,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-9f64638e-ea74-4b03-9976-ed3ab73314b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41469,DS-e809fcc3-83a6-4ceb-9792-78510f356a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-33fd3307-7d29-4017-94b1-f5ea3a47c8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-41fde18a-81a7-40c7-8673-203991bd679f,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-b13c0596-1ecc-4c19-868b-88fcc0acb55c,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-0f5dab85-0187-4ed2-a74d-059354a67ed4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2097935753-172.17.0.21-1595876800140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38902,DS-cdc5fffd-046b-4a85-8e71-ace515fa801c,DISK], DatanodeInfoWithStorage[127.0.0.1:46862,DS-89474806-6ae9-49e4-8730-f68000f5971a,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-3dddc8cd-fb71-419f-a46c-210ec1ac7460,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-201c41d4-42a6-4a70-a2fb-52075d8210c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-3624fae6-73b9-47c7-b357-c122553b1fac,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-77e0d0b7-15bf-4dbf-b90d-64622abc3ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-83b045f2-657c-4a92-bf03-c972d27ffcbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-94179732-cb91-4232-a0fc-331f82d150cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2097935753-172.17.0.21-1595876800140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38902,DS-cdc5fffd-046b-4a85-8e71-ace515fa801c,DISK], DatanodeInfoWithStorage[127.0.0.1:46862,DS-89474806-6ae9-49e4-8730-f68000f5971a,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-3dddc8cd-fb71-419f-a46c-210ec1ac7460,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-201c41d4-42a6-4a70-a2fb-52075d8210c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-3624fae6-73b9-47c7-b357-c122553b1fac,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-77e0d0b7-15bf-4dbf-b90d-64622abc3ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-83b045f2-657c-4a92-bf03-c972d27ffcbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-94179732-cb91-4232-a0fc-331f82d150cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-268305429-172.17.0.21-1595877338351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43078,DS-b9d5eb5a-c56f-4920-be4c-18002a393287,DISK], DatanodeInfoWithStorage[127.0.0.1:34121,DS-ea5d323a-9495-4ab9-b0c2-29cb164634a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-cc4f8e38-f3a9-4fed-a718-9862d50ccd1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-939aed3c-5457-4760-bfb6-d9bd17b15ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-98da2e70-8a60-4a85-919e-12e2bf155e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-726b112e-5b0c-4918-8623-55bd9a37ceed,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-40d81551-40e0-4f5f-81e8-cb1908227c73,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-9b83c0f9-667b-4062-9e9b-05da528ebb4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-268305429-172.17.0.21-1595877338351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43078,DS-b9d5eb5a-c56f-4920-be4c-18002a393287,DISK], DatanodeInfoWithStorage[127.0.0.1:34121,DS-ea5d323a-9495-4ab9-b0c2-29cb164634a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-cc4f8e38-f3a9-4fed-a718-9862d50ccd1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-939aed3c-5457-4760-bfb6-d9bd17b15ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-98da2e70-8a60-4a85-919e-12e2bf155e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-726b112e-5b0c-4918-8623-55bd9a37ceed,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-40d81551-40e0-4f5f-81e8-cb1908227c73,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-9b83c0f9-667b-4062-9e9b-05da528ebb4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2050871112-172.17.0.21-1595877575522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43878,DS-9b846f1a-528c-4212-8029-76f69cc23c43,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-b8278448-1541-4ba0-a03c-d573cb780297,DISK], DatanodeInfoWithStorage[127.0.0.1:41709,DS-0c9636cd-a366-4dd6-a8bc-0db89f0331a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46572,DS-ec0464d0-63fc-4c91-a5bb-ae2880969337,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-a9e01068-6695-4936-9e1e-a1ec729f27ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38126,DS-6acaf6fc-a164-4366-9dd5-a99588f53bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-ed1098e3-2168-4508-9e6f-1534534ab3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-aef5d311-e707-44d9-8d92-82eeee9e3926,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2050871112-172.17.0.21-1595877575522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43878,DS-9b846f1a-528c-4212-8029-76f69cc23c43,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-b8278448-1541-4ba0-a03c-d573cb780297,DISK], DatanodeInfoWithStorage[127.0.0.1:41709,DS-0c9636cd-a366-4dd6-a8bc-0db89f0331a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46572,DS-ec0464d0-63fc-4c91-a5bb-ae2880969337,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-a9e01068-6695-4936-9e1e-a1ec729f27ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38126,DS-6acaf6fc-a164-4366-9dd5-a99588f53bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-ed1098e3-2168-4508-9e6f-1534534ab3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-aef5d311-e707-44d9-8d92-82eeee9e3926,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-332777032-172.17.0.21-1595877660884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39260,DS-34539e24-724a-4c0b-a753-09a956708dda,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-5ec57bc7-1eca-479b-968a-a7a9b540f4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34030,DS-8012f4ce-5be9-41ee-93ba-cd9f23569b23,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-bc351adc-a995-4558-9e68-5ef33feba1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41910,DS-58888cf1-5593-4df3-9510-5ab6c8dede51,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-b90512c9-cbb9-4bd5-95d0-542e75a147f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-e85f3d70-08eb-426d-a9f2-3f0cd7592e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-2aaa82cf-0b7f-41d4-8d28-33a7baf4cf6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-332777032-172.17.0.21-1595877660884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39260,DS-34539e24-724a-4c0b-a753-09a956708dda,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-5ec57bc7-1eca-479b-968a-a7a9b540f4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34030,DS-8012f4ce-5be9-41ee-93ba-cd9f23569b23,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-bc351adc-a995-4558-9e68-5ef33feba1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41910,DS-58888cf1-5593-4df3-9510-5ab6c8dede51,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-b90512c9-cbb9-4bd5-95d0-542e75a147f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-e85f3d70-08eb-426d-a9f2-3f0cd7592e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-2aaa82cf-0b7f-41d4-8d28-33a7baf4cf6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1606771328-172.17.0.21-1595877799644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43501,DS-b2a1edb2-07d2-4b0c-9033-6790b5de221a,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-9715caf2-dd14-4549-b46f-20fc4f0fa81e,DISK], DatanodeInfoWithStorage[127.0.0.1:33081,DS-91c2236c-d78c-477a-bedc-e02a3d631fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-de340ee6-d82d-4d7f-953f-c076b6dbdfe2,DISK], DatanodeInfoWithStorage[127.0.0.1:39269,DS-e347e83f-16be-4959-becc-c8aa1da7d6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-98bbdaea-c12e-49b8-aa9f-618e31f9db4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45261,DS-278ef045-28b7-4eac-8b12-2d6a77b32eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:38831,DS-bba2c8ba-6ce1-49e0-9a11-6d1325fbeb24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1606771328-172.17.0.21-1595877799644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43501,DS-b2a1edb2-07d2-4b0c-9033-6790b5de221a,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-9715caf2-dd14-4549-b46f-20fc4f0fa81e,DISK], DatanodeInfoWithStorage[127.0.0.1:33081,DS-91c2236c-d78c-477a-bedc-e02a3d631fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-de340ee6-d82d-4d7f-953f-c076b6dbdfe2,DISK], DatanodeInfoWithStorage[127.0.0.1:39269,DS-e347e83f-16be-4959-becc-c8aa1da7d6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-98bbdaea-c12e-49b8-aa9f-618e31f9db4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45261,DS-278ef045-28b7-4eac-8b12-2d6a77b32eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:38831,DS-bba2c8ba-6ce1-49e0-9a11-6d1325fbeb24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1386422921-172.17.0.21-1595878134512:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46434,DS-33429fdf-a446-4cf9-8661-86f5b86acc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-cb4638bb-f06e-4f62-9b38-447dfad31293,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-58751748-63d5-4bb1-b654-00b95c02e86e,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-cd189c9c-302f-4826-a2ee-e4eaabd54932,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-8faf831f-ec6f-45db-bd0e-97f08585db37,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-f6f08c63-74fc-4cdd-a97a-f60a50ec12e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-984a6624-d2ab-4455-bfac-f030244afde9,DISK], DatanodeInfoWithStorage[127.0.0.1:44716,DS-357d2f84-2e64-4c10-bf08-847a3d60fcb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1386422921-172.17.0.21-1595878134512:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46434,DS-33429fdf-a446-4cf9-8661-86f5b86acc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-cb4638bb-f06e-4f62-9b38-447dfad31293,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-58751748-63d5-4bb1-b654-00b95c02e86e,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-cd189c9c-302f-4826-a2ee-e4eaabd54932,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-8faf831f-ec6f-45db-bd0e-97f08585db37,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-f6f08c63-74fc-4cdd-a97a-f60a50ec12e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-984a6624-d2ab-4455-bfac-f030244afde9,DISK], DatanodeInfoWithStorage[127.0.0.1:44716,DS-357d2f84-2e64-4c10-bf08-847a3d60fcb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1165255790-172.17.0.21-1595878432756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41629,DS-7ff1b4be-9678-410e-aad0-e6ebd9f13553,DISK], DatanodeInfoWithStorage[127.0.0.1:39798,DS-377e80f9-06ba-4ed8-b216-0f295f2f8dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-fed1560d-59b8-4ef2-9d92-dd67b2c0b58c,DISK], DatanodeInfoWithStorage[127.0.0.1:45355,DS-e8ac14a4-2430-4358-894b-67a46e8f824b,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-bd430018-aabc-47a1-ae3d-fccaeefe150d,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-82bbb5fe-83fd-43cd-9312-8337a4803a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-e4341a94-3050-4ab1-9ec4-ad65763335bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35535,DS-4a8495e9-cfac-44c9-a16e-e489ee1e371e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1165255790-172.17.0.21-1595878432756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41629,DS-7ff1b4be-9678-410e-aad0-e6ebd9f13553,DISK], DatanodeInfoWithStorage[127.0.0.1:39798,DS-377e80f9-06ba-4ed8-b216-0f295f2f8dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-fed1560d-59b8-4ef2-9d92-dd67b2c0b58c,DISK], DatanodeInfoWithStorage[127.0.0.1:45355,DS-e8ac14a4-2430-4358-894b-67a46e8f824b,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-bd430018-aabc-47a1-ae3d-fccaeefe150d,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-82bbb5fe-83fd-43cd-9312-8337a4803a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-e4341a94-3050-4ab1-9ec4-ad65763335bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35535,DS-4a8495e9-cfac-44c9-a16e-e489ee1e371e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1492758534-172.17.0.21-1595878650348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39091,DS-a5232bab-029e-471d-acca-3d669674a398,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-4209a514-11e4-4151-8cde-a9ff151c0a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33897,DS-c563344d-a615-4578-8b87-afde9736f491,DISK], DatanodeInfoWithStorage[127.0.0.1:40607,DS-d76cd391-0b64-4081-aaa2-22faa3657a57,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-706bd18c-7fc7-4aa2-9745-181e61862b75,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-35386432-d3e7-47e1-8a25-3b087eae5c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-d599a034-d2b5-4278-8082-c4f75aaef712,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-a18605f8-fe94-46dd-8c19-76f4469a3e4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1492758534-172.17.0.21-1595878650348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39091,DS-a5232bab-029e-471d-acca-3d669674a398,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-4209a514-11e4-4151-8cde-a9ff151c0a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33897,DS-c563344d-a615-4578-8b87-afde9736f491,DISK], DatanodeInfoWithStorage[127.0.0.1:40607,DS-d76cd391-0b64-4081-aaa2-22faa3657a57,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-706bd18c-7fc7-4aa2-9745-181e61862b75,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-35386432-d3e7-47e1-8a25-3b087eae5c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-d599a034-d2b5-4278-8082-c4f75aaef712,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-a18605f8-fe94-46dd-8c19-76f4469a3e4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1740738951-172.17.0.21-1595879290289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41881,DS-eb687622-ef72-47aa-867a-858a9953bf4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-c9e4bc5a-e9dc-4cb6-811f-a03f4184fd82,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-54d41e79-c204-4547-8220-51a9585312b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-c485c103-712b-46fb-8e35-2cb4ac619c49,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-e5803748-c63b-404d-a1c1-3d656a66613f,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-cd98de14-5094-41f5-8aa5-435228d99d10,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-51492b5d-bd5c-471c-878b-31cbe0a32aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-383954d5-b643-4b34-b8ce-abbef246035b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1740738951-172.17.0.21-1595879290289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41881,DS-eb687622-ef72-47aa-867a-858a9953bf4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-c9e4bc5a-e9dc-4cb6-811f-a03f4184fd82,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-54d41e79-c204-4547-8220-51a9585312b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-c485c103-712b-46fb-8e35-2cb4ac619c49,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-e5803748-c63b-404d-a1c1-3d656a66613f,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-cd98de14-5094-41f5-8aa5-435228d99d10,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-51492b5d-bd5c-471c-878b-31cbe0a32aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-383954d5-b643-4b34-b8ce-abbef246035b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1566590872-172.17.0.21-1595879323703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40145,DS-1c341a85-26ac-4077-978f-b72ed6bbda5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-159a1a56-6801-4ac3-bd7b-148dcfa5c906,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-29e14f21-de39-44e7-b63f-da089ff654cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37533,DS-cb44c146-7230-46ff-addd-2792b58e08b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-88d96759-caae-4d50-a297-c3dc9d22e634,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-93dd652c-8ef2-4272-8044-870ca65f8f17,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-3fa2fb1a-1804-4e27-8405-152a9b1ce0da,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-556e9277-c837-4f81-9adf-6b36766f1ca2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1566590872-172.17.0.21-1595879323703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40145,DS-1c341a85-26ac-4077-978f-b72ed6bbda5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-159a1a56-6801-4ac3-bd7b-148dcfa5c906,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-29e14f21-de39-44e7-b63f-da089ff654cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37533,DS-cb44c146-7230-46ff-addd-2792b58e08b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-88d96759-caae-4d50-a297-c3dc9d22e634,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-93dd652c-8ef2-4272-8044-870ca65f8f17,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-3fa2fb1a-1804-4e27-8405-152a9b1ce0da,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-556e9277-c837-4f81-9adf-6b36766f1ca2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-805353300-172.17.0.21-1595879670321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42788,DS-5e794e5a-5fc6-48c4-9baf-f5ded4f9f704,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-1bf4c597-6eb4-41d1-8d4a-114020edc99e,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-ad6d37be-bb04-429c-adf3-674c2893028d,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-f3a3f113-6102-4110-ac2c-2655a0380073,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-8617116f-a1b5-47c4-a5c4-f426e59ca1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-b6aab6cf-f267-449d-ba0e-5a1fc907dde2,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-dab992fc-519e-41c5-8836-d71c4e948e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-d606cc6d-1fbb-41c3-bf9c-e6a795d6d988,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-805353300-172.17.0.21-1595879670321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42788,DS-5e794e5a-5fc6-48c4-9baf-f5ded4f9f704,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-1bf4c597-6eb4-41d1-8d4a-114020edc99e,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-ad6d37be-bb04-429c-adf3-674c2893028d,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-f3a3f113-6102-4110-ac2c-2655a0380073,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-8617116f-a1b5-47c4-a5c4-f426e59ca1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-b6aab6cf-f267-449d-ba0e-5a1fc907dde2,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-dab992fc-519e-41c5-8836-d71c4e948e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-d606cc6d-1fbb-41c3-bf9c-e6a795d6d988,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-893748642-172.17.0.21-1595879777027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34789,DS-087bc211-d6f9-4a2f-8e1e-31aa936aaeb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-e12c46b8-393e-4542-af39-0fab4b414e04,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-2a0773b8-5020-404b-8529-ff829d7a8d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-c1c2fa36-bbbc-402a-94e3-a108a526c735,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-7f08aa79-4336-47f8-8dc3-cfcd7cdfe079,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-2c6a09a3-3d46-448b-bae4-4826f60e9fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:41856,DS-c15516e5-4620-4506-968d-7bfa18e9b7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45397,DS-821dabda-44d2-4da4-a00f-f1b330ee9986,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-893748642-172.17.0.21-1595879777027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34789,DS-087bc211-d6f9-4a2f-8e1e-31aa936aaeb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-e12c46b8-393e-4542-af39-0fab4b414e04,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-2a0773b8-5020-404b-8529-ff829d7a8d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-c1c2fa36-bbbc-402a-94e3-a108a526c735,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-7f08aa79-4336-47f8-8dc3-cfcd7cdfe079,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-2c6a09a3-3d46-448b-bae4-4826f60e9fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:41856,DS-c15516e5-4620-4506-968d-7bfa18e9b7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45397,DS-821dabda-44d2-4da4-a00f-f1b330ee9986,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-609516177-172.17.0.21-1595880291842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41007,DS-7f026d10-ce57-4832-87ce-2635fc59dc45,DISK], DatanodeInfoWithStorage[127.0.0.1:46022,DS-f4d77f4f-6dfa-4708-aa50-001b2dfc50e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37684,DS-4fc78dfe-b987-467e-816d-9850c9239943,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-13be1693-fb1f-4232-a9ae-c34e470e6e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-69abd242-9e05-4cf2-b866-f60490bd9999,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-0690f8b9-4370-4fdb-b7a2-a17c420cb712,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-b89bb404-1c7a-465b-aa6c-7ff13f8e5d62,DISK], DatanodeInfoWithStorage[127.0.0.1:42045,DS-47601a8d-7189-4d05-8184-d166bed24ce6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-609516177-172.17.0.21-1595880291842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41007,DS-7f026d10-ce57-4832-87ce-2635fc59dc45,DISK], DatanodeInfoWithStorage[127.0.0.1:46022,DS-f4d77f4f-6dfa-4708-aa50-001b2dfc50e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37684,DS-4fc78dfe-b987-467e-816d-9850c9239943,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-13be1693-fb1f-4232-a9ae-c34e470e6e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-69abd242-9e05-4cf2-b866-f60490bd9999,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-0690f8b9-4370-4fdb-b7a2-a17c420cb712,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-b89bb404-1c7a-465b-aa6c-7ff13f8e5d62,DISK], DatanodeInfoWithStorage[127.0.0.1:42045,DS-47601a8d-7189-4d05-8184-d166bed24ce6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-458527251-172.17.0.21-1595880424406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35562,DS-d54b23a7-71b9-4931-b22b-da360ac47be8,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-c499702f-d606-4c53-9058-31f43072c5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-d6b76751-3809-4818-b333-3f2f6809cc09,DISK], DatanodeInfoWithStorage[127.0.0.1:43383,DS-d3a42677-925d-4fa3-bfe2-6aa77dda3f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-31f2aa8c-5a29-441a-a2d7-8f0d1b4ee3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-a4bbe7d1-2ef5-4503-b58a-276084b75225,DISK], DatanodeInfoWithStorage[127.0.0.1:44254,DS-e31e971b-3efc-4f31-8b47-f4495bdf0ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-2e389a8c-26b3-4e2f-baff-bb5371321e4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-458527251-172.17.0.21-1595880424406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35562,DS-d54b23a7-71b9-4931-b22b-da360ac47be8,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-c499702f-d606-4c53-9058-31f43072c5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-d6b76751-3809-4818-b333-3f2f6809cc09,DISK], DatanodeInfoWithStorage[127.0.0.1:43383,DS-d3a42677-925d-4fa3-bfe2-6aa77dda3f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-31f2aa8c-5a29-441a-a2d7-8f0d1b4ee3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-a4bbe7d1-2ef5-4503-b58a-276084b75225,DISK], DatanodeInfoWithStorage[127.0.0.1:44254,DS-e31e971b-3efc-4f31-8b47-f4495bdf0ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-2e389a8c-26b3-4e2f-baff-bb5371321e4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-603850746-172.17.0.21-1595880525712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43811,DS-4dffcd59-6dd9-4f0d-b05c-ce0a800972ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-836cf2df-eba4-4e17-ba0d-efe0aaa298df,DISK], DatanodeInfoWithStorage[127.0.0.1:37547,DS-a97f6249-296e-4528-9a42-142209d0a572,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-4d1e8aaf-c939-424b-8273-52076d1ed694,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-cfd8d278-e203-40d1-9b8a-edddc08cc892,DISK], DatanodeInfoWithStorage[127.0.0.1:42022,DS-00454ebb-7f43-4e6a-a001-348068bd1f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-5c965ff3-299b-40fa-89af-e79737ed80ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-0543afac-6c0b-4c53-a2a4-cf4fbc327475,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-603850746-172.17.0.21-1595880525712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43811,DS-4dffcd59-6dd9-4f0d-b05c-ce0a800972ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-836cf2df-eba4-4e17-ba0d-efe0aaa298df,DISK], DatanodeInfoWithStorage[127.0.0.1:37547,DS-a97f6249-296e-4528-9a42-142209d0a572,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-4d1e8aaf-c939-424b-8273-52076d1ed694,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-cfd8d278-e203-40d1-9b8a-edddc08cc892,DISK], DatanodeInfoWithStorage[127.0.0.1:42022,DS-00454ebb-7f43-4e6a-a001-348068bd1f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-5c965ff3-299b-40fa-89af-e79737ed80ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-0543afac-6c0b-4c53-a2a4-cf4fbc327475,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-254925827-172.17.0.21-1595880757267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44221,DS-8c5a0b95-8007-486d-b8e5-09f60892e60d,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-0900387d-d275-487b-a9b8-e92a82d9e387,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-19a96920-7385-469d-ba57-4249ae83c3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-3bc92286-5a39-4faa-94df-7a9ce940bd39,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-2bd41411-0faf-4397-a757-bec5b36fa19d,DISK], DatanodeInfoWithStorage[127.0.0.1:46127,DS-7a961bc6-0ef5-4008-8f36-77183f868572,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-eafd2f19-c973-403e-8bad-552e9ecc627f,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-e87bf49f-df3a-431a-845f-a6ba421b876e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-254925827-172.17.0.21-1595880757267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44221,DS-8c5a0b95-8007-486d-b8e5-09f60892e60d,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-0900387d-d275-487b-a9b8-e92a82d9e387,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-19a96920-7385-469d-ba57-4249ae83c3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-3bc92286-5a39-4faa-94df-7a9ce940bd39,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-2bd41411-0faf-4397-a757-bec5b36fa19d,DISK], DatanodeInfoWithStorage[127.0.0.1:46127,DS-7a961bc6-0ef5-4008-8f36-77183f868572,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-eafd2f19-c973-403e-8bad-552e9ecc627f,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-e87bf49f-df3a-431a-845f-a6ba421b876e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1409068399-172.17.0.21-1595881026870:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45922,DS-4700debd-2926-4b93-89d9-b5b882b0685f,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-32b564b8-fc44-4058-b092-d48dc0a1eca5,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-799f1302-0cc3-46e9-8ff6-a9cdf75e7f47,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-7f4aba31-acc9-4d81-8f16-30f7bb84ab75,DISK], DatanodeInfoWithStorage[127.0.0.1:44233,DS-564d949e-60eb-4567-91bf-cc664b30cd9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-df3c92d2-82cd-42ba-85f4-13672393be33,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-578f4d39-4725-4a3d-a0d6-c0893a7d2fab,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-ca824222-dfbd-478b-bd45-9cb0d7663aa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1409068399-172.17.0.21-1595881026870:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45922,DS-4700debd-2926-4b93-89d9-b5b882b0685f,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-32b564b8-fc44-4058-b092-d48dc0a1eca5,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-799f1302-0cc3-46e9-8ff6-a9cdf75e7f47,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-7f4aba31-acc9-4d81-8f16-30f7bb84ab75,DISK], DatanodeInfoWithStorage[127.0.0.1:44233,DS-564d949e-60eb-4567-91bf-cc664b30cd9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-df3c92d2-82cd-42ba-85f4-13672393be33,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-578f4d39-4725-4a3d-a0d6-c0893a7d2fab,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-ca824222-dfbd-478b-bd45-9cb0d7663aa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1221116992-172.17.0.21-1595881067436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39609,DS-91094184-46e7-4c8f-8df6-121bb9afc63a,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-dd491991-04a5-4180-8e7d-75a1c503fb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-1af35b96-e567-4e48-b7f7-a9c1f5cbcaf1,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-455260cc-1d95-450d-a058-60337ff08fca,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-d2e1ef6e-5a20-4d53-8765-47b841290a99,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-4aedd305-0a28-4fa3-b535-bc80652c0e33,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-ae08bcd6-2f0f-4628-ba7d-6e7665bd871f,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-d27397be-135c-43ac-9663-cd31b152d2ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1221116992-172.17.0.21-1595881067436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39609,DS-91094184-46e7-4c8f-8df6-121bb9afc63a,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-dd491991-04a5-4180-8e7d-75a1c503fb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-1af35b96-e567-4e48-b7f7-a9c1f5cbcaf1,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-455260cc-1d95-450d-a058-60337ff08fca,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-d2e1ef6e-5a20-4d53-8765-47b841290a99,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-4aedd305-0a28-4fa3-b535-bc80652c0e33,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-ae08bcd6-2f0f-4628-ba7d-6e7665bd871f,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-d27397be-135c-43ac-9663-cd31b152d2ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5507
