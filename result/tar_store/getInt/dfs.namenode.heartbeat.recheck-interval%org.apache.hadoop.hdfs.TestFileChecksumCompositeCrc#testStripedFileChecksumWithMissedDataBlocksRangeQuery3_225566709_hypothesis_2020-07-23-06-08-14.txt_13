reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 3000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 3000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1043598185-172.17.0.13-1595484537273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41950,DS-5fd9603b-4b0b-4be9-9a62-f3b793d34e14,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-d56b15bd-d2e0-415e-8ba7-78e22369c1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-d64d20af-c1ce-4f15-afe9-84762693420e,DISK], DatanodeInfoWithStorage[127.0.0.1:32994,DS-d7952255-69c5-486e-85e4-8ed227c97c76,DISK], DatanodeInfoWithStorage[127.0.0.1:36435,DS-fbfba3b8-4914-4c6a-8fb3-bd744816508a,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-41f4e675-5707-4a5e-9dcc-9262d6960b81,DISK], DatanodeInfoWithStorage[127.0.0.1:42737,DS-89c6085f-464e-4cc6-a551-8883c3c3c57d,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-b427e532-ca76-4f8a-a64d-ab8ddf674cbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1043598185-172.17.0.13-1595484537273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41950,DS-5fd9603b-4b0b-4be9-9a62-f3b793d34e14,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-d56b15bd-d2e0-415e-8ba7-78e22369c1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-d64d20af-c1ce-4f15-afe9-84762693420e,DISK], DatanodeInfoWithStorage[127.0.0.1:32994,DS-d7952255-69c5-486e-85e4-8ed227c97c76,DISK], DatanodeInfoWithStorage[127.0.0.1:36435,DS-fbfba3b8-4914-4c6a-8fb3-bd744816508a,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-41f4e675-5707-4a5e-9dcc-9262d6960b81,DISK], DatanodeInfoWithStorage[127.0.0.1:42737,DS-89c6085f-464e-4cc6-a551-8883c3c3c57d,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-b427e532-ca76-4f8a-a64d-ab8ddf674cbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 3000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2082897731-172.17.0.13-1595484573342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39102,DS-fd67f594-39e8-40f5-b73d-9b14e6a753da,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-b6683a77-b23c-47db-b67c-098bc4b4ba0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-5b8bdb8d-8773-4c38-a64c-61affd46d444,DISK], DatanodeInfoWithStorage[127.0.0.1:36437,DS-96dc29ac-7d75-4dd2-88c5-69c73c9d7935,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-af1b2ffd-a628-4541-b8d6-e548f924229e,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-c380798b-8fce-4b4f-9cde-bfec9f911113,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-3d5eec7e-2c7e-4dd6-8220-9e228b08a8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-21d99f9e-4b10-44d9-af49-6dc23947204f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2082897731-172.17.0.13-1595484573342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39102,DS-fd67f594-39e8-40f5-b73d-9b14e6a753da,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-b6683a77-b23c-47db-b67c-098bc4b4ba0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-5b8bdb8d-8773-4c38-a64c-61affd46d444,DISK], DatanodeInfoWithStorage[127.0.0.1:36437,DS-96dc29ac-7d75-4dd2-88c5-69c73c9d7935,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-af1b2ffd-a628-4541-b8d6-e548f924229e,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-c380798b-8fce-4b4f-9cde-bfec9f911113,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-3d5eec7e-2c7e-4dd6-8220-9e228b08a8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-21d99f9e-4b10-44d9-af49-6dc23947204f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 3000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1527875236-172.17.0.13-1595485851632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35026,DS-6113a027-75d2-4591-856c-126d2c81e8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-7b73e2e6-eaed-488f-9c04-5de631892dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-15219ef1-c328-40f3-8633-d80f1d97b6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-3a3ff05c-8ee1-4e42-983d-f4cf2a047caf,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-c6c12256-2974-4400-be58-8af9ad459a98,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-98ba7512-80b2-4c5f-89d4-a05810749eba,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-74f74c6e-c4fa-41fa-8882-8c9fe7599916,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-73ee2cde-6122-4df4-9689-69412b4be9c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1527875236-172.17.0.13-1595485851632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35026,DS-6113a027-75d2-4591-856c-126d2c81e8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-7b73e2e6-eaed-488f-9c04-5de631892dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-15219ef1-c328-40f3-8633-d80f1d97b6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-3a3ff05c-8ee1-4e42-983d-f4cf2a047caf,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-c6c12256-2974-4400-be58-8af9ad459a98,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-98ba7512-80b2-4c5f-89d4-a05810749eba,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-74f74c6e-c4fa-41fa-8882-8c9fe7599916,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-73ee2cde-6122-4df4-9689-69412b4be9c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 3000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1054276083-172.17.0.13-1595486083442:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42310,DS-416d111b-3bfb-48c1-a5d9-cdc13ae8b912,DISK], DatanodeInfoWithStorage[127.0.0.1:40355,DS-c8870db7-1755-4966-87b4-72e4ca01bfac,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-889072d6-1f03-426c-834d-88bcea188e60,DISK], DatanodeInfoWithStorage[127.0.0.1:36748,DS-0da21279-f741-4444-b3a4-990796634346,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-66da7d37-3eb6-4bc0-92eb-ec7a91b7b787,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-cad972b0-fb04-4718-afb0-3ade187deac2,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-69846e76-79fa-47c0-946f-49473f10dcd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-1efd4ff1-85ac-4d88-8d71-7a1265c377dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1054276083-172.17.0.13-1595486083442:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42310,DS-416d111b-3bfb-48c1-a5d9-cdc13ae8b912,DISK], DatanodeInfoWithStorage[127.0.0.1:40355,DS-c8870db7-1755-4966-87b4-72e4ca01bfac,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-889072d6-1f03-426c-834d-88bcea188e60,DISK], DatanodeInfoWithStorage[127.0.0.1:36748,DS-0da21279-f741-4444-b3a4-990796634346,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-66da7d37-3eb6-4bc0-92eb-ec7a91b7b787,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-cad972b0-fb04-4718-afb0-3ade187deac2,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-69846e76-79fa-47c0-946f-49473f10dcd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-1efd4ff1-85ac-4d88-8d71-7a1265c377dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 3000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-809538634-172.17.0.13-1595486826335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44256,DS-0deaa7bd-e91e-4a8f-ab8d-cbe34302f302,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-580f6369-320f-4f6a-9323-ce3074fb8724,DISK], DatanodeInfoWithStorage[127.0.0.1:41404,DS-370c2416-1d86-46cf-9fcf-8cd24a310340,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-b1fb2a14-aa2d-4f15-a95c-96a9d5f829fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37142,DS-bc912b98-4d93-4c7e-8426-e6d9957db89f,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-4f61dd90-94d5-4da1-9e3f-9fe699f2a7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-8ec91162-559d-4f31-b569-3940a582fbfd,DISK], DatanodeInfoWithStorage[127.0.0.1:45127,DS-8db480ba-43b6-4737-9d0d-63805cf79f62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-809538634-172.17.0.13-1595486826335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44256,DS-0deaa7bd-e91e-4a8f-ab8d-cbe34302f302,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-580f6369-320f-4f6a-9323-ce3074fb8724,DISK], DatanodeInfoWithStorage[127.0.0.1:41404,DS-370c2416-1d86-46cf-9fcf-8cd24a310340,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-b1fb2a14-aa2d-4f15-a95c-96a9d5f829fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37142,DS-bc912b98-4d93-4c7e-8426-e6d9957db89f,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-4f61dd90-94d5-4da1-9e3f-9fe699f2a7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-8ec91162-559d-4f31-b569-3940a582fbfd,DISK], DatanodeInfoWithStorage[127.0.0.1:45127,DS-8db480ba-43b6-4737-9d0d-63805cf79f62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 3000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2029099700-172.17.0.13-1595487761956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41691,DS-e39c95fb-b879-4106-82fc-fae858e4ea16,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-02e14f8b-ea24-47f5-9316-5d417140d84d,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-c76a1835-1d5b-4434-82f4-64d7bd8a9223,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-e2f53d2a-ec58-4e41-bcf6-c94806afc72f,DISK], DatanodeInfoWithStorage[127.0.0.1:36089,DS-9b21e236-2e24-42c0-9277-07955da076d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-1a20bf13-2d3b-4274-ad07-fbb99c404888,DISK], DatanodeInfoWithStorage[127.0.0.1:41480,DS-4764b820-4a39-4fcd-9d20-321c291d44b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-e5c700e1-5e2c-47b9-a909-befa170db374,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2029099700-172.17.0.13-1595487761956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41691,DS-e39c95fb-b879-4106-82fc-fae858e4ea16,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-02e14f8b-ea24-47f5-9316-5d417140d84d,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-c76a1835-1d5b-4434-82f4-64d7bd8a9223,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-e2f53d2a-ec58-4e41-bcf6-c94806afc72f,DISK], DatanodeInfoWithStorage[127.0.0.1:36089,DS-9b21e236-2e24-42c0-9277-07955da076d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-1a20bf13-2d3b-4274-ad07-fbb99c404888,DISK], DatanodeInfoWithStorage[127.0.0.1:41480,DS-4764b820-4a39-4fcd-9d20-321c291d44b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-e5c700e1-5e2c-47b9-a909-befa170db374,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 3000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-278359976-172.17.0.13-1595487945504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44938,DS-88d25386-1905-4d66-83fe-792696b597f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-2228fb63-15f6-4347-b123-faaf984a383e,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-342efdef-fbfa-4f81-9361-8fcc34646a77,DISK], DatanodeInfoWithStorage[127.0.0.1:46800,DS-e7605b23-24cc-4722-a42d-99d6c84fbcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36420,DS-adc13b6a-d4f2-4977-ba0a-1ccac8123194,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-96876328-88ad-4a35-a148-bf6bd97eff26,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-81c02dc9-bd63-456b-966e-1e8f2aeb392d,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-0b6c05f1-999b-459f-b656-98368d6ff82c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-278359976-172.17.0.13-1595487945504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44938,DS-88d25386-1905-4d66-83fe-792696b597f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-2228fb63-15f6-4347-b123-faaf984a383e,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-342efdef-fbfa-4f81-9361-8fcc34646a77,DISK], DatanodeInfoWithStorage[127.0.0.1:46800,DS-e7605b23-24cc-4722-a42d-99d6c84fbcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36420,DS-adc13b6a-d4f2-4977-ba0a-1ccac8123194,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-96876328-88ad-4a35-a148-bf6bd97eff26,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-81c02dc9-bd63-456b-966e-1e8f2aeb392d,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-0b6c05f1-999b-459f-b656-98368d6ff82c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 3000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-547653919-172.17.0.13-1595488432959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39921,DS-cbca4b2b-a537-452e-ae1e-3aa9076ba1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-9635f784-c4ad-4e9f-ab80-22895704c910,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-706388a4-170c-470d-9c9f-3af296ea081f,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-1c4f153b-a7ee-45f6-b2f8-ce5d28c36a38,DISK], DatanodeInfoWithStorage[127.0.0.1:41996,DS-7573da32-c35a-4b77-8563-49864124ab8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33030,DS-03f65259-2352-405f-8ca0-50e5b91bc6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-ac1f1daf-2dc5-4673-8cdd-620e7f869653,DISK], DatanodeInfoWithStorage[127.0.0.1:38395,DS-0fa2fe4e-925f-43dc-8a0d-8818512a8ae3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-547653919-172.17.0.13-1595488432959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39921,DS-cbca4b2b-a537-452e-ae1e-3aa9076ba1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-9635f784-c4ad-4e9f-ab80-22895704c910,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-706388a4-170c-470d-9c9f-3af296ea081f,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-1c4f153b-a7ee-45f6-b2f8-ce5d28c36a38,DISK], DatanodeInfoWithStorage[127.0.0.1:41996,DS-7573da32-c35a-4b77-8563-49864124ab8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33030,DS-03f65259-2352-405f-8ca0-50e5b91bc6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-ac1f1daf-2dc5-4673-8cdd-620e7f869653,DISK], DatanodeInfoWithStorage[127.0.0.1:38395,DS-0fa2fe4e-925f-43dc-8a0d-8818512a8ae3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 3000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1888441818-172.17.0.13-1595489201867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38444,DS-aaa5ea19-e1ad-422a-b1bf-9560ea6f1887,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-b0525431-a797-4b40-ba88-9e194011e3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-befb1803-fe01-4c84-a52a-e3ba96dd53e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-91ca3a1b-0349-496b-ad54-925b6f705de0,DISK], DatanodeInfoWithStorage[127.0.0.1:45118,DS-8e1e1d48-50fa-44fa-8fe9-6e754476b10c,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-728ea23a-427f-458c-bf48-06f656c79fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-9483548c-00aa-45d2-9d44-6717dce5da40,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-3b36556f-d9bd-4902-b9d9-41462916fdfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1888441818-172.17.0.13-1595489201867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38444,DS-aaa5ea19-e1ad-422a-b1bf-9560ea6f1887,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-b0525431-a797-4b40-ba88-9e194011e3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-befb1803-fe01-4c84-a52a-e3ba96dd53e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-91ca3a1b-0349-496b-ad54-925b6f705de0,DISK], DatanodeInfoWithStorage[127.0.0.1:45118,DS-8e1e1d48-50fa-44fa-8fe9-6e754476b10c,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-728ea23a-427f-458c-bf48-06f656c79fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-9483548c-00aa-45d2-9d44-6717dce5da40,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-3b36556f-d9bd-4902-b9d9-41462916fdfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 3000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1072377867-172.17.0.13-1595489345533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34455,DS-0885e5d3-0864-4131-8296-12b62bd7546b,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-088cbf88-84bf-4bcd-b860-fa832be8b9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44236,DS-967c459b-8269-4a53-aae0-baa9e08e1abc,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-b217f8cb-ace9-4d89-82c4-a1f36713f16e,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-4f67b43d-f787-4027-8408-e89538da4c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33603,DS-b6cc6a5e-2266-473a-bab8-0e5c997d1c87,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-915946c3-b8fc-4f38-939a-558d7402bdce,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-f3243e1f-7787-441f-a2f8-ad9dba19046c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1072377867-172.17.0.13-1595489345533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34455,DS-0885e5d3-0864-4131-8296-12b62bd7546b,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-088cbf88-84bf-4bcd-b860-fa832be8b9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44236,DS-967c459b-8269-4a53-aae0-baa9e08e1abc,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-b217f8cb-ace9-4d89-82c4-a1f36713f16e,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-4f67b43d-f787-4027-8408-e89538da4c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33603,DS-b6cc6a5e-2266-473a-bab8-0e5c997d1c87,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-915946c3-b8fc-4f38-939a-558d7402bdce,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-f3243e1f-7787-441f-a2f8-ad9dba19046c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 3000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-703991410-172.17.0.13-1595489385938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35190,DS-7195a334-0a52-4ba3-aa28-686f983714af,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-c767042a-2606-4ce0-b795-e882f8145de6,DISK], DatanodeInfoWithStorage[127.0.0.1:40510,DS-e29846cb-5038-450b-a0f9-db2c8e9756d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-467ae677-3630-4a41-85e3-1b2373de652c,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-fc0bb834-78cb-4554-8299-ed1bf54fdea4,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-aef373c1-12bc-4fb7-b01a-4f870380c79b,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-6b9ddee7-fa9f-4a3b-b700-35e72f76b7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-a1271396-7fd5-4258-879e-f87e1fd745b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-703991410-172.17.0.13-1595489385938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35190,DS-7195a334-0a52-4ba3-aa28-686f983714af,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-c767042a-2606-4ce0-b795-e882f8145de6,DISK], DatanodeInfoWithStorage[127.0.0.1:40510,DS-e29846cb-5038-450b-a0f9-db2c8e9756d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-467ae677-3630-4a41-85e3-1b2373de652c,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-fc0bb834-78cb-4554-8299-ed1bf54fdea4,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-aef373c1-12bc-4fb7-b01a-4f870380c79b,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-6b9ddee7-fa9f-4a3b-b700-35e72f76b7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-a1271396-7fd5-4258-879e-f87e1fd745b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 3000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1770504339-172.17.0.13-1595489781113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32848,DS-9b0d20a5-21e0-48d9-a124-e3360c157de7,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-f594b0c9-e641-433f-ae0d-8d51f6cc50bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-c0b58de1-032e-4c44-a601-a01bd28973ee,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-f2fbe3a3-533f-40f5-b061-0d775323566c,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-3799fba7-3bda-4e28-967a-6b2ec998ec03,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-d1daf729-ed8f-4b84-9c45-86dc41da2875,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-7c00a610-af54-4ef8-bd95-9182f8523d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-3c83e54a-500f-4fb1-83b9-26d4398d2809,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1770504339-172.17.0.13-1595489781113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32848,DS-9b0d20a5-21e0-48d9-a124-e3360c157de7,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-f594b0c9-e641-433f-ae0d-8d51f6cc50bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-c0b58de1-032e-4c44-a601-a01bd28973ee,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-f2fbe3a3-533f-40f5-b061-0d775323566c,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-3799fba7-3bda-4e28-967a-6b2ec998ec03,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-d1daf729-ed8f-4b84-9c45-86dc41da2875,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-7c00a610-af54-4ef8-bd95-9182f8523d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-3c83e54a-500f-4fb1-83b9-26d4398d2809,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 3000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-661164180-172.17.0.13-1595489853774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44306,DS-8ddda993-0c0b-4c37-8ca7-8bb34ca7b2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-8e32916d-a960-4c04-bb33-7b7cc0b6e81b,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-0f5a7fa9-035a-45e9-bd23-42f0c9529b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-2312332f-a4ec-4b6f-8978-bae46422e530,DISK], DatanodeInfoWithStorage[127.0.0.1:35525,DS-75d3ec4d-d62e-4391-9809-1649a5b6642b,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-88a483c2-ab41-4079-9868-2e436a9efcff,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-5652be7a-3810-431d-9b16-a7994e52e7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-e4b8f6a9-d20a-4e14-8d3e-d51f380ec38f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-661164180-172.17.0.13-1595489853774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44306,DS-8ddda993-0c0b-4c37-8ca7-8bb34ca7b2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-8e32916d-a960-4c04-bb33-7b7cc0b6e81b,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-0f5a7fa9-035a-45e9-bd23-42f0c9529b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-2312332f-a4ec-4b6f-8978-bae46422e530,DISK], DatanodeInfoWithStorage[127.0.0.1:35525,DS-75d3ec4d-d62e-4391-9809-1649a5b6642b,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-88a483c2-ab41-4079-9868-2e436a9efcff,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-5652be7a-3810-431d-9b16-a7994e52e7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-e4b8f6a9-d20a-4e14-8d3e-d51f380ec38f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 3000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1699512805-172.17.0.13-1595489994298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43435,DS-08a95dcd-c313-431c-83e9-3d69b55e4de8,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-b339e401-6b85-42a9-a5d9-97547ba9a8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-24506946-b60b-4710-a5bb-0bd4d4fc2097,DISK], DatanodeInfoWithStorage[127.0.0.1:37811,DS-ad4c2105-3d1c-41c0-aa98-ce32b816af0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-65dca6e9-c411-453c-8437-484cf4374078,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-ba51a411-8871-4dd9-82be-4d18001fd488,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-03d6957a-af6c-47f2-8846-af052fed9e42,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-6883bd8b-73ec-4088-acb8-89ff5c9385bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1699512805-172.17.0.13-1595489994298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43435,DS-08a95dcd-c313-431c-83e9-3d69b55e4de8,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-b339e401-6b85-42a9-a5d9-97547ba9a8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-24506946-b60b-4710-a5bb-0bd4d4fc2097,DISK], DatanodeInfoWithStorage[127.0.0.1:37811,DS-ad4c2105-3d1c-41c0-aa98-ce32b816af0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-65dca6e9-c411-453c-8437-484cf4374078,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-ba51a411-8871-4dd9-82be-4d18001fd488,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-03d6957a-af6c-47f2-8846-af052fed9e42,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-6883bd8b-73ec-4088-acb8-89ff5c9385bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5702
