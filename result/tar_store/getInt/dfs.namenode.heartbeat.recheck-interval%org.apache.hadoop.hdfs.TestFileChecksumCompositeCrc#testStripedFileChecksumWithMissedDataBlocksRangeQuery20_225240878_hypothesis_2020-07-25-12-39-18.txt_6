reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-443996579-172.17.0.8-1595680944840:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36952,DS-c297b49a-b16a-4542-b1d8-ab67baf84839,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-3ad227b9-f233-45ed-b580-e1de7cf4f4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-3e2c1048-fc74-4d6a-ba2b-84467763fa5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-6c2f9129-bc78-484a-aaf1-7abdeb874e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36047,DS-52bb4374-745d-4227-b959-f89618965783,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-094c4620-1cd3-45fb-af46-975aa5813000,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-5013d6c2-4eb3-4fc1-a38e-f586d026bcf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-b983cf05-4980-43ce-baf8-32d508f9fda3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-443996579-172.17.0.8-1595680944840:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36952,DS-c297b49a-b16a-4542-b1d8-ab67baf84839,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-3ad227b9-f233-45ed-b580-e1de7cf4f4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-3e2c1048-fc74-4d6a-ba2b-84467763fa5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-6c2f9129-bc78-484a-aaf1-7abdeb874e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36047,DS-52bb4374-745d-4227-b959-f89618965783,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-094c4620-1cd3-45fb-af46-975aa5813000,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-5013d6c2-4eb3-4fc1-a38e-f586d026bcf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-b983cf05-4980-43ce-baf8-32d508f9fda3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-753937063-172.17.0.8-1595681551799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37069,DS-9e4d81d2-aa7f-4883-bc08-7176918c347c,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-523432ac-6c7b-4e66-a502-57135aab8c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-d3c9c19a-1b10-413c-961e-c3674a9b201b,DISK], DatanodeInfoWithStorage[127.0.0.1:45353,DS-190d873c-941f-44ca-85c2-768a043b8e97,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-6c4929d3-7305-46ab-acb6-ce4c6cb10820,DISK], DatanodeInfoWithStorage[127.0.0.1:46235,DS-27648b24-0de9-4217-a91e-1f0c9f0cffb0,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-a859abee-df7c-46c9-b6a9-076027b8c43d,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-fb3da582-4a19-45ed-b37c-a3271fc24db6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-753937063-172.17.0.8-1595681551799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37069,DS-9e4d81d2-aa7f-4883-bc08-7176918c347c,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-523432ac-6c7b-4e66-a502-57135aab8c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-d3c9c19a-1b10-413c-961e-c3674a9b201b,DISK], DatanodeInfoWithStorage[127.0.0.1:45353,DS-190d873c-941f-44ca-85c2-768a043b8e97,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-6c4929d3-7305-46ab-acb6-ce4c6cb10820,DISK], DatanodeInfoWithStorage[127.0.0.1:46235,DS-27648b24-0de9-4217-a91e-1f0c9f0cffb0,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-a859abee-df7c-46c9-b6a9-076027b8c43d,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-fb3da582-4a19-45ed-b37c-a3271fc24db6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-101321246-172.17.0.8-1595681592182:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36993,DS-ee9aaf70-15ee-449d-a90c-6145987548c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-49f7d717-f9f7-4d96-a212-3ae642d55669,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-f25fab47-f73e-4742-a50a-2257077c5dab,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-e309c9b0-844e-43da-8a95-8fef6b662ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-610c148f-a39a-47fa-9257-f5b9ad328812,DISK], DatanodeInfoWithStorage[127.0.0.1:34725,DS-d718cb25-cc92-4a76-b9ac-ce480ae4af2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-c20d2c6b-b2a2-4f56-86d8-d77b3895fd34,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-4cc0ed6d-dccd-4354-a56b-3220b2fe2a92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-101321246-172.17.0.8-1595681592182:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36993,DS-ee9aaf70-15ee-449d-a90c-6145987548c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-49f7d717-f9f7-4d96-a212-3ae642d55669,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-f25fab47-f73e-4742-a50a-2257077c5dab,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-e309c9b0-844e-43da-8a95-8fef6b662ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-610c148f-a39a-47fa-9257-f5b9ad328812,DISK], DatanodeInfoWithStorage[127.0.0.1:34725,DS-d718cb25-cc92-4a76-b9ac-ce480ae4af2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-c20d2c6b-b2a2-4f56-86d8-d77b3895fd34,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-4cc0ed6d-dccd-4354-a56b-3220b2fe2a92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1413824843-172.17.0.8-1595682104783:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41894,DS-03673f94-1abd-4533-93bd-99145c1479ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-2e0609b8-dbf9-487e-9100-9471c179a903,DISK], DatanodeInfoWithStorage[127.0.0.1:42403,DS-7f061bbc-b786-46db-868a-c02f3a9674d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-64356713-de51-4cce-b769-75c75b614d21,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-002dbf9e-e748-4b3a-a44e-228186561e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-666ade21-8be8-4b81-ad22-2a6d188e16f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45375,DS-3bf0559c-ee7b-4af3-a2cd-a6e3c0dfe9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-f9c22d5d-0ede-41e6-9c3f-7691e06c0692,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1413824843-172.17.0.8-1595682104783:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41894,DS-03673f94-1abd-4533-93bd-99145c1479ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-2e0609b8-dbf9-487e-9100-9471c179a903,DISK], DatanodeInfoWithStorage[127.0.0.1:42403,DS-7f061bbc-b786-46db-868a-c02f3a9674d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-64356713-de51-4cce-b769-75c75b614d21,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-002dbf9e-e748-4b3a-a44e-228186561e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-666ade21-8be8-4b81-ad22-2a6d188e16f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45375,DS-3bf0559c-ee7b-4af3-a2cd-a6e3c0dfe9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-f9c22d5d-0ede-41e6-9c3f-7691e06c0692,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1667859480-172.17.0.8-1595682280658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45880,DS-34369bbb-0106-424c-8991-9f39f54f3988,DISK], DatanodeInfoWithStorage[127.0.0.1:45046,DS-0bd603c4-f043-4efb-9223-1aea37300b78,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-aafdf21d-ec3e-450f-bb9f-f98766a44f19,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-223f1aa5-29c5-4234-ab52-e795706590da,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-acf0d145-e09d-4991-9d4d-50c79feb9dac,DISK], DatanodeInfoWithStorage[127.0.0.1:45788,DS-3ee575d6-8c46-42ce-a6e0-75416d4d50ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-b552d87b-b629-4268-a748-78c67b238e52,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-85fd82d4-36ec-45f2-8561-73e46cfe93c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1667859480-172.17.0.8-1595682280658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45880,DS-34369bbb-0106-424c-8991-9f39f54f3988,DISK], DatanodeInfoWithStorage[127.0.0.1:45046,DS-0bd603c4-f043-4efb-9223-1aea37300b78,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-aafdf21d-ec3e-450f-bb9f-f98766a44f19,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-223f1aa5-29c5-4234-ab52-e795706590da,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-acf0d145-e09d-4991-9d4d-50c79feb9dac,DISK], DatanodeInfoWithStorage[127.0.0.1:45788,DS-3ee575d6-8c46-42ce-a6e0-75416d4d50ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-b552d87b-b629-4268-a748-78c67b238e52,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-85fd82d4-36ec-45f2-8561-73e46cfe93c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-329261190-172.17.0.8-1595682486350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41213,DS-10d97927-6d03-4b3f-bc6d-7b3c742a74ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40659,DS-8b5f7baa-8abc-4515-bc85-61409d847cab,DISK], DatanodeInfoWithStorage[127.0.0.1:40856,DS-cc9528bd-064c-4ac0-8002-3b38e15521f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-967ee7a8-07f5-439b-809e-c603fe4e111a,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-af8c2cb4-ff32-49ff-b3e4-99f8eaf765a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-ea11112e-72d2-4fc4-8a1e-4318bc9fbe50,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-242931a0-37e3-44d7-9aa0-10d3bb3b0f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-bfaad963-d81c-4a74-8767-e0845bc9d4c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-329261190-172.17.0.8-1595682486350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41213,DS-10d97927-6d03-4b3f-bc6d-7b3c742a74ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40659,DS-8b5f7baa-8abc-4515-bc85-61409d847cab,DISK], DatanodeInfoWithStorage[127.0.0.1:40856,DS-cc9528bd-064c-4ac0-8002-3b38e15521f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-967ee7a8-07f5-439b-809e-c603fe4e111a,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-af8c2cb4-ff32-49ff-b3e4-99f8eaf765a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-ea11112e-72d2-4fc4-8a1e-4318bc9fbe50,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-242931a0-37e3-44d7-9aa0-10d3bb3b0f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-bfaad963-d81c-4a74-8767-e0845bc9d4c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1841574841-172.17.0.8-1595682621777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36035,DS-87bcfc37-1472-4fac-97a0-bb49a1c933b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-ce4973e4-69f4-41f4-8acb-d5ff63a4d40e,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-c42c77f1-3986-4747-b0ef-e8b150998dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-6aab9248-ad05-4bec-bb20-7d76777ad56c,DISK], DatanodeInfoWithStorage[127.0.0.1:36540,DS-1196e18c-74de-40eb-a12f-f8f2dbcba507,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-7d2bc746-3c63-4cd8-964e-913c364df77d,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-1ec7377d-6423-415a-820d-1c1e37780401,DISK], DatanodeInfoWithStorage[127.0.0.1:42168,DS-8940801c-7426-4371-b2ab-0708a09325a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1841574841-172.17.0.8-1595682621777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36035,DS-87bcfc37-1472-4fac-97a0-bb49a1c933b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-ce4973e4-69f4-41f4-8acb-d5ff63a4d40e,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-c42c77f1-3986-4747-b0ef-e8b150998dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-6aab9248-ad05-4bec-bb20-7d76777ad56c,DISK], DatanodeInfoWithStorage[127.0.0.1:36540,DS-1196e18c-74de-40eb-a12f-f8f2dbcba507,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-7d2bc746-3c63-4cd8-964e-913c364df77d,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-1ec7377d-6423-415a-820d-1c1e37780401,DISK], DatanodeInfoWithStorage[127.0.0.1:42168,DS-8940801c-7426-4371-b2ab-0708a09325a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-808974533-172.17.0.8-1595682773712:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43956,DS-f18ac2a3-4b30-41e5-9184-2b9c4e08f081,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-92c223cc-4573-4daa-9901-d94c1fbc69dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-7b8643ca-4a5e-431a-bd15-67505320fb27,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-b8ff4b67-ff81-400d-adfd-c8f1cf54caf7,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-07d36157-9384-489f-abb9-edef00238b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33487,DS-bb356479-18fe-4798-943e-3e5fbb399bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-6277343b-e927-4219-b9e3-93e63f571a74,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-3fa351ca-cf8a-4e99-ac97-0a03f08f6f85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-808974533-172.17.0.8-1595682773712:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43956,DS-f18ac2a3-4b30-41e5-9184-2b9c4e08f081,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-92c223cc-4573-4daa-9901-d94c1fbc69dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-7b8643ca-4a5e-431a-bd15-67505320fb27,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-b8ff4b67-ff81-400d-adfd-c8f1cf54caf7,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-07d36157-9384-489f-abb9-edef00238b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33487,DS-bb356479-18fe-4798-943e-3e5fbb399bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-6277343b-e927-4219-b9e3-93e63f571a74,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-3fa351ca-cf8a-4e99-ac97-0a03f08f6f85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1041939099-172.17.0.8-1595682929575:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46765,DS-a3181de5-dc81-49e0-967d-8f89e9ed7ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-b9c0f3d8-99a6-49d4-9247-27192eb91470,DISK], DatanodeInfoWithStorage[127.0.0.1:42202,DS-037cb37f-ce9b-417d-b690-ecf61d5f0dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-1976c79f-5a2c-4459-a512-986bab4e9ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-c9a4d4f7-642f-47e0-b4b1-6dd796b8a1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41539,DS-41a7220e-30d1-40fc-8148-c1fcc68d8147,DISK], DatanodeInfoWithStorage[127.0.0.1:39618,DS-baa9264a-77c8-4807-96cb-cf48576c4124,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-cb2169c0-5387-4ef6-af13-f531a2fd8241,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1041939099-172.17.0.8-1595682929575:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46765,DS-a3181de5-dc81-49e0-967d-8f89e9ed7ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-b9c0f3d8-99a6-49d4-9247-27192eb91470,DISK], DatanodeInfoWithStorage[127.0.0.1:42202,DS-037cb37f-ce9b-417d-b690-ecf61d5f0dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-1976c79f-5a2c-4459-a512-986bab4e9ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-c9a4d4f7-642f-47e0-b4b1-6dd796b8a1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41539,DS-41a7220e-30d1-40fc-8148-c1fcc68d8147,DISK], DatanodeInfoWithStorage[127.0.0.1:39618,DS-baa9264a-77c8-4807-96cb-cf48576c4124,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-cb2169c0-5387-4ef6-af13-f531a2fd8241,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2132412276-172.17.0.8-1595683579763:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45020,DS-17e1bc34-6334-4330-bc29-f5c3852a36de,DISK], DatanodeInfoWithStorage[127.0.0.1:35984,DS-340ccc45-aadd-47ed-9e76-fbc90055c6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-3cdeb567-2126-4770-9a1d-dc131931f00d,DISK], DatanodeInfoWithStorage[127.0.0.1:43678,DS-4807bc6e-eb27-4736-bf69-31b3c300f89e,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-b860785a-e0c2-45b4-8f15-d16f65a5e64e,DISK], DatanodeInfoWithStorage[127.0.0.1:36671,DS-1b614bc1-6203-43b1-9799-296725013057,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-b821c85a-d575-4619-8415-86fc14a54c32,DISK], DatanodeInfoWithStorage[127.0.0.1:42348,DS-978b83a2-6bbd-4842-9d80-6f6d1964ec27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2132412276-172.17.0.8-1595683579763:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45020,DS-17e1bc34-6334-4330-bc29-f5c3852a36de,DISK], DatanodeInfoWithStorage[127.0.0.1:35984,DS-340ccc45-aadd-47ed-9e76-fbc90055c6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-3cdeb567-2126-4770-9a1d-dc131931f00d,DISK], DatanodeInfoWithStorage[127.0.0.1:43678,DS-4807bc6e-eb27-4736-bf69-31b3c300f89e,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-b860785a-e0c2-45b4-8f15-d16f65a5e64e,DISK], DatanodeInfoWithStorage[127.0.0.1:36671,DS-1b614bc1-6203-43b1-9799-296725013057,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-b821c85a-d575-4619-8415-86fc14a54c32,DISK], DatanodeInfoWithStorage[127.0.0.1:42348,DS-978b83a2-6bbd-4842-9d80-6f6d1964ec27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1070913774-172.17.0.8-1595683794692:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36160,DS-5cfe0b82-2601-45fa-8979-cf98f63440a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37552,DS-75f28883-db43-4c55-a49a-8ad7123823b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-aac4f443-92ed-47e1-9d20-f081f95d9018,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-50877983-a599-4b3c-9a00-9b010f2a947a,DISK], DatanodeInfoWithStorage[127.0.0.1:32898,DS-37e5772f-303d-47b9-a93b-795b90361c04,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-320fe361-2c2b-46cc-bbf0-149efb8177a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-6549059c-1331-4960-97cb-6db9a40bcdaf,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-68d95d35-3de0-497a-9784-b0e2166c410e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1070913774-172.17.0.8-1595683794692:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36160,DS-5cfe0b82-2601-45fa-8979-cf98f63440a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37552,DS-75f28883-db43-4c55-a49a-8ad7123823b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-aac4f443-92ed-47e1-9d20-f081f95d9018,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-50877983-a599-4b3c-9a00-9b010f2a947a,DISK], DatanodeInfoWithStorage[127.0.0.1:32898,DS-37e5772f-303d-47b9-a93b-795b90361c04,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-320fe361-2c2b-46cc-bbf0-149efb8177a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-6549059c-1331-4960-97cb-6db9a40bcdaf,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-68d95d35-3de0-497a-9784-b0e2166c410e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-835784112-172.17.0.8-1595683937777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36552,DS-c3c8f48d-4240-409e-a411-211186e0db02,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-bd1068be-5094-4da4-9988-65e6dc029c19,DISK], DatanodeInfoWithStorage[127.0.0.1:37675,DS-79663076-a6ab-428b-a12c-6bb56f1d81ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-42355c7a-f39d-4f92-9c47-d128f029f9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-2a816a6e-2a3f-4e8a-afbb-bb3bed947ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-4f341dd1-d457-4fef-a97a-0a960fd7341d,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-f179228a-803a-4e69-b43e-faffb10f3536,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-93771353-18ad-40e3-b3ec-ca0a817c4448,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-835784112-172.17.0.8-1595683937777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36552,DS-c3c8f48d-4240-409e-a411-211186e0db02,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-bd1068be-5094-4da4-9988-65e6dc029c19,DISK], DatanodeInfoWithStorage[127.0.0.1:37675,DS-79663076-a6ab-428b-a12c-6bb56f1d81ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-42355c7a-f39d-4f92-9c47-d128f029f9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-2a816a6e-2a3f-4e8a-afbb-bb3bed947ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-4f341dd1-d457-4fef-a97a-0a960fd7341d,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-f179228a-803a-4e69-b43e-faffb10f3536,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-93771353-18ad-40e3-b3ec-ca0a817c4448,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1569706458-172.17.0.8-1595684110906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46055,DS-fb61bc2a-1fdf-479c-9e60-d85c9df28d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39658,DS-38a7c614-62f4-4cfe-a953-59db587d9151,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-3795969d-2f28-425c-ba70-e3d7dd5f4aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-be8c4969-04b8-4cbe-9308-b17f3b5a4140,DISK], DatanodeInfoWithStorage[127.0.0.1:44298,DS-16e65b13-311d-43c8-804e-648633b717ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-2fa9a761-d470-4db3-a65a-c9079dd88d91,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-bb8c2328-166e-4da1-9230-0b84cac85b36,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-a748f1e6-625c-4845-9870-cf3a80e85e8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1569706458-172.17.0.8-1595684110906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46055,DS-fb61bc2a-1fdf-479c-9e60-d85c9df28d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39658,DS-38a7c614-62f4-4cfe-a953-59db587d9151,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-3795969d-2f28-425c-ba70-e3d7dd5f4aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-be8c4969-04b8-4cbe-9308-b17f3b5a4140,DISK], DatanodeInfoWithStorage[127.0.0.1:44298,DS-16e65b13-311d-43c8-804e-648633b717ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-2fa9a761-d470-4db3-a65a-c9079dd88d91,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-bb8c2328-166e-4da1-9230-0b84cac85b36,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-a748f1e6-625c-4845-9870-cf3a80e85e8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-267654247-172.17.0.8-1595684569645:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38350,DS-e8c915df-9ce4-49e1-9f50-ac8d45462731,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-d0bca4c0-e0f6-48e5-9941-fa5aa5849d30,DISK], DatanodeInfoWithStorage[127.0.0.1:40707,DS-e1598265-a0dc-4237-a76f-dd83d1e36eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-ebad9b48-d205-4cb6-850f-02ec74bc2e22,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-0ddfc5f4-d4b1-4467-b7f8-7b77112ef724,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-3405f618-dfef-4eb8-91da-879fdfd94d62,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-12cbf313-5e71-42ba-bfd3-9be98b3c07e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-acadf5fe-c78d-40fa-9a9a-0fafe2c89156,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-267654247-172.17.0.8-1595684569645:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38350,DS-e8c915df-9ce4-49e1-9f50-ac8d45462731,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-d0bca4c0-e0f6-48e5-9941-fa5aa5849d30,DISK], DatanodeInfoWithStorage[127.0.0.1:40707,DS-e1598265-a0dc-4237-a76f-dd83d1e36eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-ebad9b48-d205-4cb6-850f-02ec74bc2e22,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-0ddfc5f4-d4b1-4467-b7f8-7b77112ef724,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-3405f618-dfef-4eb8-91da-879fdfd94d62,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-12cbf313-5e71-42ba-bfd3-9be98b3c07e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-acadf5fe-c78d-40fa-9a9a-0fafe2c89156,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2854833-172.17.0.8-1595684906802:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41810,DS-37fdfff4-614c-4300-b7e1-1b623482038b,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-876f6ebd-7598-475d-8525-19a006f7de64,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-fd07f247-ca4c-4b4f-8024-c238d8b581d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46531,DS-7ce4d81c-9c13-46a5-bcf5-99efaa74f7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-166c8188-16b6-43fd-ad5d-1a3937753a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-b653c4c9-199e-4cd6-9e9f-d7f95e78c940,DISK], DatanodeInfoWithStorage[127.0.0.1:42737,DS-adc52123-bb9f-4932-b356-df1612138e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46483,DS-6fe86411-baca-46f3-88c6-441bd49d1d1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2854833-172.17.0.8-1595684906802:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41810,DS-37fdfff4-614c-4300-b7e1-1b623482038b,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-876f6ebd-7598-475d-8525-19a006f7de64,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-fd07f247-ca4c-4b4f-8024-c238d8b581d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46531,DS-7ce4d81c-9c13-46a5-bcf5-99efaa74f7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-166c8188-16b6-43fd-ad5d-1a3937753a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-b653c4c9-199e-4cd6-9e9f-d7f95e78c940,DISK], DatanodeInfoWithStorage[127.0.0.1:42737,DS-adc52123-bb9f-4932-b356-df1612138e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46483,DS-6fe86411-baca-46f3-88c6-441bd49d1d1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1596673888-172.17.0.8-1595685035360:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46522,DS-470b6810-1c5f-4e70-9a02-17c556283ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:41716,DS-d796c3fc-f95c-4e0c-8fb0-04c156de0f60,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-353b386b-f7f6-4082-9d39-fd8c96484eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-74cfafce-c4a2-4c11-87b3-100e42de9a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-c32e87c2-1b78-4914-96f7-166e9f3776b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-4935272a-33cc-4a45-b284-737e2add9711,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-d1fa0baf-4145-4be2-80cb-7ebdc37a5503,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-b3605a01-fc75-4b2a-9e37-6a6003b08c35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1596673888-172.17.0.8-1595685035360:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46522,DS-470b6810-1c5f-4e70-9a02-17c556283ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:41716,DS-d796c3fc-f95c-4e0c-8fb0-04c156de0f60,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-353b386b-f7f6-4082-9d39-fd8c96484eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-74cfafce-c4a2-4c11-87b3-100e42de9a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-c32e87c2-1b78-4914-96f7-166e9f3776b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-4935272a-33cc-4a45-b284-737e2add9711,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-d1fa0baf-4145-4be2-80cb-7ebdc37a5503,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-b3605a01-fc75-4b2a-9e37-6a6003b08c35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1171592706-172.17.0.8-1595685100704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37022,DS-505b2580-076d-4e93-85fb-29b63dc1ed65,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-4aca9cb8-5271-4ed9-baca-e183d27b20a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-c09ee2d4-a5c2-4a5c-ada2-ba747f9e8e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-a2eb7935-f2cd-4e86-b910-1b8402b0cf41,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-c6ec47e6-9ac8-4bc5-95dc-a828baceca50,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-1cd0fe1a-c7e1-4e88-9b0f-8df37592ebb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-98c2edc9-a60a-44e8-be28-514b614b87cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-bde0004c-8432-42ea-afc1-3318c0f7f015,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1171592706-172.17.0.8-1595685100704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37022,DS-505b2580-076d-4e93-85fb-29b63dc1ed65,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-4aca9cb8-5271-4ed9-baca-e183d27b20a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-c09ee2d4-a5c2-4a5c-ada2-ba747f9e8e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-a2eb7935-f2cd-4e86-b910-1b8402b0cf41,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-c6ec47e6-9ac8-4bc5-95dc-a828baceca50,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-1cd0fe1a-c7e1-4e88-9b0f-8df37592ebb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-98c2edc9-a60a-44e8-be28-514b614b87cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-bde0004c-8432-42ea-afc1-3318c0f7f015,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-850144978-172.17.0.8-1595685418472:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39408,DS-72a63008-3097-451e-a557-3547c86e6b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-bf677b25-1893-4c61-a64e-22d80195f0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37218,DS-32e1c123-b73b-40e3-84fe-51a95f2d37db,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-0295979e-46e9-4a97-b195-493bf054969f,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-b02a1c8c-091d-494f-9a89-28b475806975,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-f3f7564f-f48f-4dc4-ab7f-4d9161723f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-9870c49a-b80d-4b34-8e3d-9bd10cc90c45,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-b49b33cb-e0c4-4fc4-a8e2-ee0cf3b84909,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-850144978-172.17.0.8-1595685418472:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39408,DS-72a63008-3097-451e-a557-3547c86e6b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-bf677b25-1893-4c61-a64e-22d80195f0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37218,DS-32e1c123-b73b-40e3-84fe-51a95f2d37db,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-0295979e-46e9-4a97-b195-493bf054969f,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-b02a1c8c-091d-494f-9a89-28b475806975,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-f3f7564f-f48f-4dc4-ab7f-4d9161723f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-9870c49a-b80d-4b34-8e3d-9bd10cc90c45,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-b49b33cb-e0c4-4fc4-a8e2-ee0cf3b84909,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-673515718-172.17.0.8-1595685524445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41985,DS-15a42704-9334-4286-838d-0f483f961b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-ce5a310e-2bec-4318-87ed-85cebafd94ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-3c30150a-f9ee-4310-b0bb-265fa734b8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-4a277fec-e4c2-48ff-b77f-bef7ee90d8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-5606dc2b-ca64-4f29-88e7-2cc6f5621184,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-3791771c-4b36-4578-ae12-1afe01fccf9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-cfe618c4-2668-4b0d-9b82-d95c4763a2af,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-77d737bc-34ec-48e3-9a6d-f571e2b71539,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-673515718-172.17.0.8-1595685524445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41985,DS-15a42704-9334-4286-838d-0f483f961b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-ce5a310e-2bec-4318-87ed-85cebafd94ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-3c30150a-f9ee-4310-b0bb-265fa734b8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-4a277fec-e4c2-48ff-b77f-bef7ee90d8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-5606dc2b-ca64-4f29-88e7-2cc6f5621184,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-3791771c-4b36-4578-ae12-1afe01fccf9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-cfe618c4-2668-4b0d-9b82-d95c4763a2af,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-77d737bc-34ec-48e3-9a6d-f571e2b71539,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2006885559-172.17.0.8-1595685740658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43251,DS-d54b4da4-8351-4fd9-b084-5de505802cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-161d8009-ebe0-4f1e-977b-a1634a783bba,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-29888e0d-dbad-462c-9c34-4bc6980821ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-fbf3f5bf-ba57-4897-acab-97a8995e1444,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-3361cbec-c9cb-45fb-83a6-2059dcb2658d,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-9c1a1dee-77f4-4086-9174-c84da825a789,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-043f64be-3772-489c-8577-e1c3f6236e90,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-fc0c24e9-1dad-4d59-942b-9746b0460e6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2006885559-172.17.0.8-1595685740658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43251,DS-d54b4da4-8351-4fd9-b084-5de505802cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-161d8009-ebe0-4f1e-977b-a1634a783bba,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-29888e0d-dbad-462c-9c34-4bc6980821ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-fbf3f5bf-ba57-4897-acab-97a8995e1444,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-3361cbec-c9cb-45fb-83a6-2059dcb2658d,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-9c1a1dee-77f4-4086-9174-c84da825a789,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-043f64be-3772-489c-8577-e1c3f6236e90,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-fc0c24e9-1dad-4d59-942b-9746b0460e6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1708473955-172.17.0.8-1595685851805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37754,DS-4de9058b-e02c-4d49-bd4f-460ff7c9b3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39834,DS-c76628fa-5ff3-4349-88ba-248be404c8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-130cfa0e-bf64-4882-9501-156636d8c768,DISK], DatanodeInfoWithStorage[127.0.0.1:36443,DS-a4d75a4a-b657-483d-a99f-aa197e46e73a,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-69c211e1-f607-48d8-a278-5a691816335e,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-185dcaca-2030-4dd9-8c0b-19ea88e7d770,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-ac94806f-5996-4d94-a236-3b52add47a98,DISK], DatanodeInfoWithStorage[127.0.0.1:44819,DS-7a2d7e97-8cf1-4515-820b-d2f7c9911ff3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1708473955-172.17.0.8-1595685851805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37754,DS-4de9058b-e02c-4d49-bd4f-460ff7c9b3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39834,DS-c76628fa-5ff3-4349-88ba-248be404c8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-130cfa0e-bf64-4882-9501-156636d8c768,DISK], DatanodeInfoWithStorage[127.0.0.1:36443,DS-a4d75a4a-b657-483d-a99f-aa197e46e73a,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-69c211e1-f607-48d8-a278-5a691816335e,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-185dcaca-2030-4dd9-8c0b-19ea88e7d770,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-ac94806f-5996-4d94-a236-3b52add47a98,DISK], DatanodeInfoWithStorage[127.0.0.1:44819,DS-7a2d7e97-8cf1-4515-820b-d2f7c9911ff3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-594467113-172.17.0.8-1595685922904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46127,DS-af56cf70-2ea5-4e7e-8097-ac957766b406,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-20dbeafb-e149-4fed-b270-9c4054a7d395,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-6bf5a791-b0cf-4f71-8811-f450e95359ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-7af50f59-904a-4632-b047-d80ed303db97,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-1cc4069c-b321-455f-bf54-23d2a75cfebb,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-d44852df-5e8d-4e48-a92c-74be55f6f23b,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-60d25f97-217c-456c-93ac-fe7d89380cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-bc1f8f0c-738d-4936-8ee9-76724b6318d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-594467113-172.17.0.8-1595685922904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46127,DS-af56cf70-2ea5-4e7e-8097-ac957766b406,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-20dbeafb-e149-4fed-b270-9c4054a7d395,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-6bf5a791-b0cf-4f71-8811-f450e95359ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-7af50f59-904a-4632-b047-d80ed303db97,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-1cc4069c-b321-455f-bf54-23d2a75cfebb,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-d44852df-5e8d-4e48-a92c-74be55f6f23b,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-60d25f97-217c-456c-93ac-fe7d89380cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-bc1f8f0c-738d-4936-8ee9-76724b6318d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5292
