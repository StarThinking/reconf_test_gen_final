reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-962129943-172.17.0.10-1595977940776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39861,DS-f9bf8543-6170-40b2-9d45-9f343afe4229,DISK], DatanodeInfoWithStorage[127.0.0.1:35522,DS-fcf95a66-9039-44b6-86fc-35a5e40ced40,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-4ab797be-d975-4e89-a9f7-7dfc9e3ed77d,DISK], DatanodeInfoWithStorage[127.0.0.1:41649,DS-3e82620c-bda6-4684-b58e-adcc59a2366c,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-0adbca80-d25a-4245-af61-60434f7ff867,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-2303d49a-fa93-48b7-a767-2c9ef7a8cb22,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-be2d4323-8b61-4c6e-aeeb-947f133b9fac,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-05bb62ad-297b-492e-95e1-547c72543898,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-962129943-172.17.0.10-1595977940776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39861,DS-f9bf8543-6170-40b2-9d45-9f343afe4229,DISK], DatanodeInfoWithStorage[127.0.0.1:35522,DS-fcf95a66-9039-44b6-86fc-35a5e40ced40,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-4ab797be-d975-4e89-a9f7-7dfc9e3ed77d,DISK], DatanodeInfoWithStorage[127.0.0.1:41649,DS-3e82620c-bda6-4684-b58e-adcc59a2366c,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-0adbca80-d25a-4245-af61-60434f7ff867,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-2303d49a-fa93-48b7-a767-2c9ef7a8cb22,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-be2d4323-8b61-4c6e-aeeb-947f133b9fac,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-05bb62ad-297b-492e-95e1-547c72543898,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-809932081-172.17.0.10-1595978471199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41253,DS-1b568846-8c25-4567-8084-36b1bbc2547a,DISK], DatanodeInfoWithStorage[127.0.0.1:43692,DS-10b3d187-3fec-4852-bdfb-c2bca1beb859,DISK], DatanodeInfoWithStorage[127.0.0.1:38726,DS-5cb545f0-0251-405a-889d-efb13c710092,DISK], DatanodeInfoWithStorage[127.0.0.1:37248,DS-a42e081a-13f1-481f-a384-6ad190cec9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33264,DS-f18a2095-64b5-4057-8abd-845688e3062b,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-fb836a1f-eac5-49bb-8ac1-3c6703b108b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-e31c3668-0db2-4199-9f7e-940631558c38,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-d5dc0615-fccd-4845-b7db-6dadadc4c799,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-809932081-172.17.0.10-1595978471199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41253,DS-1b568846-8c25-4567-8084-36b1bbc2547a,DISK], DatanodeInfoWithStorage[127.0.0.1:43692,DS-10b3d187-3fec-4852-bdfb-c2bca1beb859,DISK], DatanodeInfoWithStorage[127.0.0.1:38726,DS-5cb545f0-0251-405a-889d-efb13c710092,DISK], DatanodeInfoWithStorage[127.0.0.1:37248,DS-a42e081a-13f1-481f-a384-6ad190cec9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33264,DS-f18a2095-64b5-4057-8abd-845688e3062b,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-fb836a1f-eac5-49bb-8ac1-3c6703b108b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-e31c3668-0db2-4199-9f7e-940631558c38,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-d5dc0615-fccd-4845-b7db-6dadadc4c799,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1071239175-172.17.0.10-1595978705238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40836,DS-6898c3cf-a1b6-45f8-9a94-38f976b5874d,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-120499e5-b8a0-4797-9142-a8ee4e4cf6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-08321436-36a9-4344-9991-b0aab6d156d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46484,DS-120c3e03-b241-41e5-a5e1-b5aa3f90904c,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-c0af4c7a-d988-465d-977a-4a785a83755a,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-1d3502d8-3d09-46b3-82e0-5d61858520c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-e2fa261b-c8a1-4544-98a2-382156b45df2,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-d554188e-9c69-4e28-8387-d3445dbbfdcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1071239175-172.17.0.10-1595978705238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40836,DS-6898c3cf-a1b6-45f8-9a94-38f976b5874d,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-120499e5-b8a0-4797-9142-a8ee4e4cf6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-08321436-36a9-4344-9991-b0aab6d156d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46484,DS-120c3e03-b241-41e5-a5e1-b5aa3f90904c,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-c0af4c7a-d988-465d-977a-4a785a83755a,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-1d3502d8-3d09-46b3-82e0-5d61858520c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-e2fa261b-c8a1-4544-98a2-382156b45df2,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-d554188e-9c69-4e28-8387-d3445dbbfdcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-500984831-172.17.0.10-1595979222293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36123,DS-c5451431-cae7-45e6-a5bd-dbfd93f0e6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-8e661fa0-1ed4-4b53-bac5-bef2439cdab7,DISK], DatanodeInfoWithStorage[127.0.0.1:43816,DS-cef21a34-c134-4fbf-a9b3-7d9187391acb,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-facd8055-c797-4439-9522-33fd637ad411,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-f6cfe4c1-a311-47a9-b907-cbc36add5600,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-0c08dca1-8dc8-4dbf-b1db-48d617027a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36579,DS-4f9b473f-9fde-456b-a6a3-c18bd163dfb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-4b2beebf-3fa9-4a3e-beae-2d1fdc979d6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-500984831-172.17.0.10-1595979222293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36123,DS-c5451431-cae7-45e6-a5bd-dbfd93f0e6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-8e661fa0-1ed4-4b53-bac5-bef2439cdab7,DISK], DatanodeInfoWithStorage[127.0.0.1:43816,DS-cef21a34-c134-4fbf-a9b3-7d9187391acb,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-facd8055-c797-4439-9522-33fd637ad411,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-f6cfe4c1-a311-47a9-b907-cbc36add5600,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-0c08dca1-8dc8-4dbf-b1db-48d617027a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36579,DS-4f9b473f-9fde-456b-a6a3-c18bd163dfb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-4b2beebf-3fa9-4a3e-beae-2d1fdc979d6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1917814275-172.17.0.10-1595979252521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32855,DS-e7558ad4-53de-41ff-8c04-112a6c6476f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-c5dfaf52-08ad-490e-ab0b-fb90c7530894,DISK], DatanodeInfoWithStorage[127.0.0.1:39351,DS-caede475-e5ed-4e7b-a4ca-86184f6648c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-1699e0f7-f384-4707-afe4-ffc884d4103f,DISK], DatanodeInfoWithStorage[127.0.0.1:39877,DS-e77c5bf8-7711-4574-b268-c8b2c6afab12,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-1b75d3c8-314b-4f5f-b981-441c60e3e2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34414,DS-0d4986db-12fa-48fe-b194-ce0e1be37187,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-dd244b34-d1b0-4d01-b486-1e73a1619cef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1917814275-172.17.0.10-1595979252521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32855,DS-e7558ad4-53de-41ff-8c04-112a6c6476f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-c5dfaf52-08ad-490e-ab0b-fb90c7530894,DISK], DatanodeInfoWithStorage[127.0.0.1:39351,DS-caede475-e5ed-4e7b-a4ca-86184f6648c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-1699e0f7-f384-4707-afe4-ffc884d4103f,DISK], DatanodeInfoWithStorage[127.0.0.1:39877,DS-e77c5bf8-7711-4574-b268-c8b2c6afab12,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-1b75d3c8-314b-4f5f-b981-441c60e3e2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34414,DS-0d4986db-12fa-48fe-b194-ce0e1be37187,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-dd244b34-d1b0-4d01-b486-1e73a1619cef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1571459232-172.17.0.10-1595979385107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44665,DS-814cc087-6b60-42cb-a195-8248395c5940,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-10f3c912-eb81-475f-bfaf-de7c37b3efcd,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-793be011-ef43-413d-b9ea-7afff5d7437f,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-6c68c37c-925e-4289-ad85-edfb026ae54f,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-46970810-9b3d-4449-8046-0b72beec6cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:41965,DS-704b27df-ffc3-4f66-b878-2fb7e5676f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-dad3a8ef-aaff-44fc-bce3-855a2be79fde,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-82314b8c-9884-4fd8-aa1a-542092345442,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1571459232-172.17.0.10-1595979385107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44665,DS-814cc087-6b60-42cb-a195-8248395c5940,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-10f3c912-eb81-475f-bfaf-de7c37b3efcd,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-793be011-ef43-413d-b9ea-7afff5d7437f,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-6c68c37c-925e-4289-ad85-edfb026ae54f,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-46970810-9b3d-4449-8046-0b72beec6cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:41965,DS-704b27df-ffc3-4f66-b878-2fb7e5676f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-dad3a8ef-aaff-44fc-bce3-855a2be79fde,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-82314b8c-9884-4fd8-aa1a-542092345442,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-125925677-172.17.0.10-1595979979920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46158,DS-a29c1006-86f8-485b-9b45-ee1aa06da7da,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-6e7ad1ef-0968-427e-9a4a-618249e1cb03,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-963224b3-e5e3-4b85-bd68-bf9a82695822,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-a3c7ce3a-4e12-4138-86d4-3fc98c3a7c58,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-210a9ff6-7f97-4110-8338-6258a33c4082,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-6720c743-9b5c-44fe-9758-a67bae9b6e18,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-284d4644-1df8-4c99-85af-fcc6bf30f645,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-b59e3977-f100-4aca-9b9f-919409568357,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-125925677-172.17.0.10-1595979979920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46158,DS-a29c1006-86f8-485b-9b45-ee1aa06da7da,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-6e7ad1ef-0968-427e-9a4a-618249e1cb03,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-963224b3-e5e3-4b85-bd68-bf9a82695822,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-a3c7ce3a-4e12-4138-86d4-3fc98c3a7c58,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-210a9ff6-7f97-4110-8338-6258a33c4082,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-6720c743-9b5c-44fe-9758-a67bae9b6e18,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-284d4644-1df8-4c99-85af-fcc6bf30f645,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-b59e3977-f100-4aca-9b9f-919409568357,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258746661-172.17.0.10-1595980052639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35202,DS-b7a727dd-41be-497f-be41-c86d612120e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-eb6a1682-5f7b-44d7-bc30-2db7829f97a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-f5b82bd4-2955-4a7e-9776-1d22eab7fc84,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-b9da83d8-d50f-4c9b-9ecb-e04e7590d57f,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-19a65f5d-c65a-41b5-b69b-73a51f5f03f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-42d76552-a6cc-4db8-8480-479b20220aae,DISK], DatanodeInfoWithStorage[127.0.0.1:36561,DS-627ed88a-60b3-4e1d-b794-4fe7b3a88281,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-8f16fb81-7292-4fe0-af89-695c24238aa4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258746661-172.17.0.10-1595980052639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35202,DS-b7a727dd-41be-497f-be41-c86d612120e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-eb6a1682-5f7b-44d7-bc30-2db7829f97a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-f5b82bd4-2955-4a7e-9776-1d22eab7fc84,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-b9da83d8-d50f-4c9b-9ecb-e04e7590d57f,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-19a65f5d-c65a-41b5-b69b-73a51f5f03f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-42d76552-a6cc-4db8-8480-479b20220aae,DISK], DatanodeInfoWithStorage[127.0.0.1:36561,DS-627ed88a-60b3-4e1d-b794-4fe7b3a88281,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-8f16fb81-7292-4fe0-af89-695c24238aa4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1345782421-172.17.0.10-1595980537026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41221,DS-7c3bcdc0-9b15-466b-a755-7f3f79b809c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38818,DS-e2421ff3-680a-4a02-a002-e0cab934c89d,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-5b5d025c-f8cd-46c4-8391-446f4bb84596,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-89aabbf3-5ef0-4333-adfd-f11f0deca238,DISK], DatanodeInfoWithStorage[127.0.0.1:42617,DS-ca2a6b8f-022a-4aad-8488-bcbbedd20d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-1549630a-5794-4358-8e08-5eeed98c5943,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-e74d39fb-a1b4-4a1a-9bf7-78a832a477ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-3c5758c6-1dba-45af-b518-aa5529dfcade,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1345782421-172.17.0.10-1595980537026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41221,DS-7c3bcdc0-9b15-466b-a755-7f3f79b809c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38818,DS-e2421ff3-680a-4a02-a002-e0cab934c89d,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-5b5d025c-f8cd-46c4-8391-446f4bb84596,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-89aabbf3-5ef0-4333-adfd-f11f0deca238,DISK], DatanodeInfoWithStorage[127.0.0.1:42617,DS-ca2a6b8f-022a-4aad-8488-bcbbedd20d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-1549630a-5794-4358-8e08-5eeed98c5943,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-e74d39fb-a1b4-4a1a-9bf7-78a832a477ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-3c5758c6-1dba-45af-b518-aa5529dfcade,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-268949383-172.17.0.10-1595980689868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33277,DS-3ce16e8e-4f50-4e69-a59d-dc1e5b07a7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-aef7eae5-ed84-4532-bc03-a22104c4eb27,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-d289e09a-aac7-4068-a0d2-1927c1d7b240,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-045b1cc1-5914-494c-aea7-85215e6c46b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-67a3ab37-043f-40ca-bcf8-72edc367d8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-41e2f315-9609-459b-b509-71ea02ab80ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-47485a16-7ebc-40d4-ab0e-397b0b317b24,DISK], DatanodeInfoWithStorage[127.0.0.1:36900,DS-d9cf541c-8ecd-45e6-b20d-70a9ae86d86e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-268949383-172.17.0.10-1595980689868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33277,DS-3ce16e8e-4f50-4e69-a59d-dc1e5b07a7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-aef7eae5-ed84-4532-bc03-a22104c4eb27,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-d289e09a-aac7-4068-a0d2-1927c1d7b240,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-045b1cc1-5914-494c-aea7-85215e6c46b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-67a3ab37-043f-40ca-bcf8-72edc367d8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-41e2f315-9609-459b-b509-71ea02ab80ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-47485a16-7ebc-40d4-ab0e-397b0b317b24,DISK], DatanodeInfoWithStorage[127.0.0.1:36900,DS-d9cf541c-8ecd-45e6-b20d-70a9ae86d86e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1877047394-172.17.0.10-1595981446094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34036,DS-5a1ebfea-eedf-4c2f-bb10-8cc4fac002b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-9fbd5cc6-e5dc-4a5f-9a8f-d73855e3fb88,DISK], DatanodeInfoWithStorage[127.0.0.1:34115,DS-7657e8ba-e907-465c-a868-36369b94a460,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-62a68fec-cef3-47fd-897d-123842f97930,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-35c5846d-e6cf-44f7-9e1a-137e67cfdb81,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-df28b556-a880-4d44-bda5-ed2552a5ad38,DISK], DatanodeInfoWithStorage[127.0.0.1:33264,DS-99144b92-ee76-4b50-a556-666981902874,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-91ef3ae3-03d8-440d-bbc7-21afd8504a64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1877047394-172.17.0.10-1595981446094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34036,DS-5a1ebfea-eedf-4c2f-bb10-8cc4fac002b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-9fbd5cc6-e5dc-4a5f-9a8f-d73855e3fb88,DISK], DatanodeInfoWithStorage[127.0.0.1:34115,DS-7657e8ba-e907-465c-a868-36369b94a460,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-62a68fec-cef3-47fd-897d-123842f97930,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-35c5846d-e6cf-44f7-9e1a-137e67cfdb81,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-df28b556-a880-4d44-bda5-ed2552a5ad38,DISK], DatanodeInfoWithStorage[127.0.0.1:33264,DS-99144b92-ee76-4b50-a556-666981902874,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-91ef3ae3-03d8-440d-bbc7-21afd8504a64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-724383003-172.17.0.10-1595981581611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36731,DS-a4deff67-b38f-42fa-82b7-aae95f6c4d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-3ed71020-c9f6-44fe-bb8e-f4dbbbd5cac7,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-f9ecee80-f836-49f2-9711-1a1c1a3df8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-52064451-5756-4747-8852-f6c4a57d6e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-ff30e9d6-89bf-4b18-96d5-942ce776f98f,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-d32e02a1-8727-4237-8240-56283ad11637,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-1e9b1235-394b-4718-bf9b-6fe7f0972146,DISK], DatanodeInfoWithStorage[127.0.0.1:46268,DS-1df2c8d1-ef41-49bf-99f5-8e9885a9d04c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-724383003-172.17.0.10-1595981581611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36731,DS-a4deff67-b38f-42fa-82b7-aae95f6c4d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-3ed71020-c9f6-44fe-bb8e-f4dbbbd5cac7,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-f9ecee80-f836-49f2-9711-1a1c1a3df8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-52064451-5756-4747-8852-f6c4a57d6e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-ff30e9d6-89bf-4b18-96d5-942ce776f98f,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-d32e02a1-8727-4237-8240-56283ad11637,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-1e9b1235-394b-4718-bf9b-6fe7f0972146,DISK], DatanodeInfoWithStorage[127.0.0.1:46268,DS-1df2c8d1-ef41-49bf-99f5-8e9885a9d04c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1728358128-172.17.0.10-1595982315138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34371,DS-192ce885-ba39-4dc8-8e6b-2cdc2b52dc4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-ab3d44ff-8554-45c5-bac9-5c34b0e9fade,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-91b06f18-237e-46fb-b9ec-99822110f45f,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-571e6225-8273-46c6-bed1-01a265adda04,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-845cc4de-393c-4c7e-8461-8f16ff2b687b,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-11a33c6d-aa25-4788-b2e1-e58b3df99bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-ca773786-d9f1-4aa3-8483-3a82eb21c140,DISK], DatanodeInfoWithStorage[127.0.0.1:41728,DS-9cc78070-de9c-46cc-9acd-902a5416b81b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1728358128-172.17.0.10-1595982315138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34371,DS-192ce885-ba39-4dc8-8e6b-2cdc2b52dc4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-ab3d44ff-8554-45c5-bac9-5c34b0e9fade,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-91b06f18-237e-46fb-b9ec-99822110f45f,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-571e6225-8273-46c6-bed1-01a265adda04,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-845cc4de-393c-4c7e-8461-8f16ff2b687b,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-11a33c6d-aa25-4788-b2e1-e58b3df99bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-ca773786-d9f1-4aa3-8483-3a82eb21c140,DISK], DatanodeInfoWithStorage[127.0.0.1:41728,DS-9cc78070-de9c-46cc-9acd-902a5416b81b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2053359729-172.17.0.10-1595982395800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37068,DS-34df4edb-82c4-4d84-8919-43b560ebf121,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-db566291-c105-4c22-83ce-c5c6eba14493,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-4285440b-08ab-4f6e-839a-0176115d2705,DISK], DatanodeInfoWithStorage[127.0.0.1:35092,DS-fdd05c3d-124e-40b5-be10-e4ac5da1aa8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45757,DS-e1b65ae1-0c51-4730-93c6-ab423f80e8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-474800cd-d01f-41ad-816b-d7397d22e899,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-2c4d7160-dbc5-4917-b210-19e08463d412,DISK], DatanodeInfoWithStorage[127.0.0.1:44851,DS-aee7334e-4156-47cf-8f13-029b520e369b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2053359729-172.17.0.10-1595982395800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37068,DS-34df4edb-82c4-4d84-8919-43b560ebf121,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-db566291-c105-4c22-83ce-c5c6eba14493,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-4285440b-08ab-4f6e-839a-0176115d2705,DISK], DatanodeInfoWithStorage[127.0.0.1:35092,DS-fdd05c3d-124e-40b5-be10-e4ac5da1aa8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45757,DS-e1b65ae1-0c51-4730-93c6-ab423f80e8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-474800cd-d01f-41ad-816b-d7397d22e899,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-2c4d7160-dbc5-4917-b210-19e08463d412,DISK], DatanodeInfoWithStorage[127.0.0.1:44851,DS-aee7334e-4156-47cf-8f13-029b520e369b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5386
