reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1819998652-172.17.0.12-1595846524114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40196,DS-7beb98d7-42a4-4d15-bd10-73cc8a5a9df1,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-7b053eab-35bc-4dc9-9345-1a5e634c5a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-a46f0d36-39b4-448b-b225-4b66d2ff63cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43653,DS-f77e2681-2e3d-4569-926b-8570a81635fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34326,DS-538f5b5e-afda-4bb1-b9f4-40c6d111ed40,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-24e8e600-7655-4282-9203-ca892ad6717f,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-f9ce371c-6534-44b6-b8e0-fcec309f697c,DISK], DatanodeInfoWithStorage[127.0.0.1:44792,DS-784f5bec-04f5-490d-82fe-02173ca21816,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1819998652-172.17.0.12-1595846524114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40196,DS-7beb98d7-42a4-4d15-bd10-73cc8a5a9df1,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-7b053eab-35bc-4dc9-9345-1a5e634c5a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-a46f0d36-39b4-448b-b225-4b66d2ff63cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43653,DS-f77e2681-2e3d-4569-926b-8570a81635fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34326,DS-538f5b5e-afda-4bb1-b9f4-40c6d111ed40,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-24e8e600-7655-4282-9203-ca892ad6717f,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-f9ce371c-6534-44b6-b8e0-fcec309f697c,DISK], DatanodeInfoWithStorage[127.0.0.1:44792,DS-784f5bec-04f5-490d-82fe-02173ca21816,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1753401398-172.17.0.12-1595846635691:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44521,DS-05902988-36a6-4bb2-9056-e0ed8d81d886,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-b4ea4e56-d605-4e2d-8d36-98e7de48a8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-997bab20-8097-41de-9857-c86287d6c2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38596,DS-f5837a64-614d-43ff-b71d-45b250cd0a64,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-3abe8f05-6cc8-4a3f-9914-35c5992b37d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35106,DS-82ddde97-f0f0-44e9-a863-0d804b632211,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-830c4219-cd67-44c3-b33e-394543aa8096,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-9dc9d9b2-92c4-443b-9ce6-e1c26fed842f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1753401398-172.17.0.12-1595846635691:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44521,DS-05902988-36a6-4bb2-9056-e0ed8d81d886,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-b4ea4e56-d605-4e2d-8d36-98e7de48a8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-997bab20-8097-41de-9857-c86287d6c2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38596,DS-f5837a64-614d-43ff-b71d-45b250cd0a64,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-3abe8f05-6cc8-4a3f-9914-35c5992b37d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35106,DS-82ddde97-f0f0-44e9-a863-0d804b632211,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-830c4219-cd67-44c3-b33e-394543aa8096,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-9dc9d9b2-92c4-443b-9ce6-e1c26fed842f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-864243777-172.17.0.12-1595846711889:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46449,DS-d0061326-8b27-40ae-96a8-2cb724b916fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-d2363f9e-7218-43af-bc0f-62e60fba294a,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-2d3f7536-ae67-4199-ab8a-a8bf1ddf6dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:34355,DS-4cc455a1-0d9a-467f-bc2f-d3f1bc35cc59,DISK], DatanodeInfoWithStorage[127.0.0.1:34929,DS-e3470063-68a0-42ce-9b65-b7087b63e136,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-d49b967c-130d-4224-873a-6a26fc4189c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36200,DS-03e06500-56a2-4de1-828a-8780a7fce0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-56b755ef-9032-473a-8b92-de342a789e4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-864243777-172.17.0.12-1595846711889:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46449,DS-d0061326-8b27-40ae-96a8-2cb724b916fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-d2363f9e-7218-43af-bc0f-62e60fba294a,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-2d3f7536-ae67-4199-ab8a-a8bf1ddf6dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:34355,DS-4cc455a1-0d9a-467f-bc2f-d3f1bc35cc59,DISK], DatanodeInfoWithStorage[127.0.0.1:34929,DS-e3470063-68a0-42ce-9b65-b7087b63e136,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-d49b967c-130d-4224-873a-6a26fc4189c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36200,DS-03e06500-56a2-4de1-828a-8780a7fce0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-56b755ef-9032-473a-8b92-de342a789e4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1393587189-172.17.0.12-1595846996525:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37670,DS-1e27e0f9-a539-4256-9e5d-afe192039b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45868,DS-828a3b51-b429-442b-b882-caed87ea27ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-40985c42-4cc1-491d-a087-e8dae2e926a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-a436e47f-d62d-40df-9972-7763dffda95a,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-7ea8c910-a0da-40aa-8a02-dd5368a6d9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-fa7ccb87-629d-485c-a0e9-6134c9c4a985,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-f1da981d-438f-4e0a-be55-4916e1b00676,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-aef9c4d0-3c63-4eb8-814f-93d2f70d31fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1393587189-172.17.0.12-1595846996525:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37670,DS-1e27e0f9-a539-4256-9e5d-afe192039b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45868,DS-828a3b51-b429-442b-b882-caed87ea27ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-40985c42-4cc1-491d-a087-e8dae2e926a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-a436e47f-d62d-40df-9972-7763dffda95a,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-7ea8c910-a0da-40aa-8a02-dd5368a6d9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-fa7ccb87-629d-485c-a0e9-6134c9c4a985,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-f1da981d-438f-4e0a-be55-4916e1b00676,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-aef9c4d0-3c63-4eb8-814f-93d2f70d31fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1156289858-172.17.0.12-1595847133352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33968,DS-e8ec7a6c-0e38-4ad2-860f-a33467401b15,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-6d1c3f44-a6e9-4b8f-8039-348b74854287,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-cde42719-13da-4d5d-8627-56e9f87ffcc9,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-f55f85ae-088b-4a98-8252-d09724d1aa20,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-f8d4ddf3-a27b-4f52-a748-1c036e0bfd88,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-d7581f3c-12bf-43be-8164-5dfcd2082293,DISK], DatanodeInfoWithStorage[127.0.0.1:37676,DS-74e3a856-ca26-49dc-906e-eed7813be841,DISK], DatanodeInfoWithStorage[127.0.0.1:39397,DS-871e350a-6b7b-4255-a164-4c016331ec04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1156289858-172.17.0.12-1595847133352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33968,DS-e8ec7a6c-0e38-4ad2-860f-a33467401b15,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-6d1c3f44-a6e9-4b8f-8039-348b74854287,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-cde42719-13da-4d5d-8627-56e9f87ffcc9,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-f55f85ae-088b-4a98-8252-d09724d1aa20,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-f8d4ddf3-a27b-4f52-a748-1c036e0bfd88,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-d7581f3c-12bf-43be-8164-5dfcd2082293,DISK], DatanodeInfoWithStorage[127.0.0.1:37676,DS-74e3a856-ca26-49dc-906e-eed7813be841,DISK], DatanodeInfoWithStorage[127.0.0.1:39397,DS-871e350a-6b7b-4255-a164-4c016331ec04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-263975939-172.17.0.12-1595848126611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34373,DS-0fcbd55f-0e52-4a22-b559-bcedf65ab86e,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-0883f707-00ab-4097-bdc2-6a51013b1590,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-94e6c28d-062b-45b0-bba9-e79f056f0d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-0cbfa651-85bd-487f-8ea3-52a5772c7dde,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-d3034434-9fe4-45e0-a724-57338afceb47,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-125cb093-9d72-4dbf-b17d-b84d0e8836e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44995,DS-35de80d8-087e-40ed-909d-b99845950ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-d3d0e9c8-1c3c-4668-a632-2efbc3b00cce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-263975939-172.17.0.12-1595848126611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34373,DS-0fcbd55f-0e52-4a22-b559-bcedf65ab86e,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-0883f707-00ab-4097-bdc2-6a51013b1590,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-94e6c28d-062b-45b0-bba9-e79f056f0d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-0cbfa651-85bd-487f-8ea3-52a5772c7dde,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-d3034434-9fe4-45e0-a724-57338afceb47,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-125cb093-9d72-4dbf-b17d-b84d0e8836e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44995,DS-35de80d8-087e-40ed-909d-b99845950ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-d3d0e9c8-1c3c-4668-a632-2efbc3b00cce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1079671369-172.17.0.12-1595849332980:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33529,DS-db43859a-abf7-4224-a1a6-2cbe61c228e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-bd40a008-a0ac-4b56-98d0-1d0b330f7089,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-8a16668e-8079-4d04-a945-fc423ba2af32,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-6530116e-441e-461d-81bb-c46a9812f4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-fbbba8f0-6195-4c12-a9f3-f92943087c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-627ab863-5261-4471-9765-7f746f63af1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-babd03fb-a34a-4a16-a82b-36ef07be2cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-258523f0-71fd-4204-a294-dcd2cb4603ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1079671369-172.17.0.12-1595849332980:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33529,DS-db43859a-abf7-4224-a1a6-2cbe61c228e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-bd40a008-a0ac-4b56-98d0-1d0b330f7089,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-8a16668e-8079-4d04-a945-fc423ba2af32,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-6530116e-441e-461d-81bb-c46a9812f4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-fbbba8f0-6195-4c12-a9f3-f92943087c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-627ab863-5261-4471-9765-7f746f63af1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-babd03fb-a34a-4a16-a82b-36ef07be2cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-258523f0-71fd-4204-a294-dcd2cb4603ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1774005112-172.17.0.12-1595849427240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39602,DS-487ef4eb-6a2b-400e-a069-f75e6302419e,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-c0aef682-b8f4-4647-ac50-c931882bcfc1,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-b37b59ea-05d4-45c5-a789-7e7e9a79336a,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-fbfee86f-51ad-4035-887f-42dfd1885a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-75f2d497-2631-4bda-bc2f-56826144acf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-185221df-439e-4403-82e1-14801f863828,DISK], DatanodeInfoWithStorage[127.0.0.1:46308,DS-10ab0f37-cb7c-430a-a7c0-fc17fe1e958d,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-11839092-c97b-4692-b68c-fff15ca72078,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1774005112-172.17.0.12-1595849427240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39602,DS-487ef4eb-6a2b-400e-a069-f75e6302419e,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-c0aef682-b8f4-4647-ac50-c931882bcfc1,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-b37b59ea-05d4-45c5-a789-7e7e9a79336a,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-fbfee86f-51ad-4035-887f-42dfd1885a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-75f2d497-2631-4bda-bc2f-56826144acf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-185221df-439e-4403-82e1-14801f863828,DISK], DatanodeInfoWithStorage[127.0.0.1:46308,DS-10ab0f37-cb7c-430a-a7c0-fc17fe1e958d,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-11839092-c97b-4692-b68c-fff15ca72078,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1792174623-172.17.0.12-1595850423920:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36092,DS-caa4b7c6-03df-4128-98f9-de9a33907c39,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-1deed57a-30a5-46b1-a0f9-8964ea2b2af9,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-7bd3ef82-131a-4a10-8639-fe6f127fd242,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-6bbda857-7b3d-4454-b57c-dc2e72ea6389,DISK], DatanodeInfoWithStorage[127.0.0.1:42667,DS-f57293fe-826c-4be9-bb95-33835cffd887,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-3182af02-6e8f-4d28-a327-261df1568e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34728,DS-f68ac283-d95a-445b-bb36-63889783ab59,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-f41fe7d3-c6cd-4541-a4b1-4e4f41fda947,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1792174623-172.17.0.12-1595850423920:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36092,DS-caa4b7c6-03df-4128-98f9-de9a33907c39,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-1deed57a-30a5-46b1-a0f9-8964ea2b2af9,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-7bd3ef82-131a-4a10-8639-fe6f127fd242,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-6bbda857-7b3d-4454-b57c-dc2e72ea6389,DISK], DatanodeInfoWithStorage[127.0.0.1:42667,DS-f57293fe-826c-4be9-bb95-33835cffd887,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-3182af02-6e8f-4d28-a327-261df1568e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34728,DS-f68ac283-d95a-445b-bb36-63889783ab59,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-f41fe7d3-c6cd-4541-a4b1-4e4f41fda947,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1137658703-172.17.0.12-1595850510934:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40748,DS-0cdf76fe-886b-4a02-bc92-f21ee405ff46,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-a0d538bc-9f6c-4cc1-a0b4-e82e58d06193,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-2d4b1c5a-4d98-4c70-8882-2a2d8ea49a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-928fc846-07f8-4c36-90ca-6015287da60e,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-cd3daa1b-8c42-4464-8ec6-b939d2cb0b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-264bb94e-2143-43cd-9597-d45c078207c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-ea49ed07-d06f-40ad-883b-f7c3afb7fd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-62dfb1ac-7fd1-41ce-ab53-842bfe75b52c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1137658703-172.17.0.12-1595850510934:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40748,DS-0cdf76fe-886b-4a02-bc92-f21ee405ff46,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-a0d538bc-9f6c-4cc1-a0b4-e82e58d06193,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-2d4b1c5a-4d98-4c70-8882-2a2d8ea49a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-928fc846-07f8-4c36-90ca-6015287da60e,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-cd3daa1b-8c42-4464-8ec6-b939d2cb0b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-264bb94e-2143-43cd-9597-d45c078207c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-ea49ed07-d06f-40ad-883b-f7c3afb7fd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-62dfb1ac-7fd1-41ce-ab53-842bfe75b52c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2096527717-172.17.0.12-1595850821737:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46106,DS-15ae4780-ebe4-4cf0-a3ff-9daaedc7be3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-fc1c28cb-f939-40fa-9c2b-9b5328e9925d,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-2192a580-14ed-4b3f-84e2-31914f40e196,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-12251f48-9f65-40d1-a75b-59de7fa9fc72,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-9698b4fc-3a60-47d2-a2d9-d7272fc0d607,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-dc93f6c4-0b1b-4a3a-adc6-6656623a93f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-03e8d546-5133-4bae-a291-cf7432099919,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-29d895be-fe77-4b15-a9e8-bf11b8d79e3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2096527717-172.17.0.12-1595850821737:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46106,DS-15ae4780-ebe4-4cf0-a3ff-9daaedc7be3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-fc1c28cb-f939-40fa-9c2b-9b5328e9925d,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-2192a580-14ed-4b3f-84e2-31914f40e196,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-12251f48-9f65-40d1-a75b-59de7fa9fc72,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-9698b4fc-3a60-47d2-a2d9-d7272fc0d607,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-dc93f6c4-0b1b-4a3a-adc6-6656623a93f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-03e8d546-5133-4bae-a291-cf7432099919,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-29d895be-fe77-4b15-a9e8-bf11b8d79e3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1399453503-172.17.0.12-1595850984407:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44365,DS-f7fa6961-da13-430f-aaf5-a29b875fc168,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-b067ce1b-c6f8-4925-9fe4-afeafe5c022a,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-5b57b4c6-398c-4683-810a-513ba5007579,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-81f16f23-4e35-4bef-a8bb-e68ef22b793b,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-7421e630-35fd-4649-8c44-652c1f5dd5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-82f4727b-54a4-4fc7-bda8-5db5ec29a0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-ac1b20e3-6940-4de3-91ab-f77380dae4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40308,DS-64631143-de50-4f31-810a-8e60499346e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1399453503-172.17.0.12-1595850984407:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44365,DS-f7fa6961-da13-430f-aaf5-a29b875fc168,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-b067ce1b-c6f8-4925-9fe4-afeafe5c022a,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-5b57b4c6-398c-4683-810a-513ba5007579,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-81f16f23-4e35-4bef-a8bb-e68ef22b793b,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-7421e630-35fd-4649-8c44-652c1f5dd5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-82f4727b-54a4-4fc7-bda8-5db5ec29a0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-ac1b20e3-6940-4de3-91ab-f77380dae4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40308,DS-64631143-de50-4f31-810a-8e60499346e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1453189647-172.17.0.12-1595851069692:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37412,DS-abf87014-0b72-4a7e-af87-a399c226e4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-f3597c0c-3843-44f1-b337-bc134417f01c,DISK], DatanodeInfoWithStorage[127.0.0.1:39621,DS-50a63491-a2be-43a1-bee4-1d797c16a744,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-dd78af94-e625-4c61-980a-15e900387c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-abc4c93f-6040-4d19-87fc-1b51ee19795e,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-580389eb-a5e1-4f40-971d-589fa514b226,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-64a9cbc7-fc7f-4596-bec6-ee099d5ce638,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-6c4f3ea7-581d-496e-96f3-f83156069d37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1453189647-172.17.0.12-1595851069692:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37412,DS-abf87014-0b72-4a7e-af87-a399c226e4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-f3597c0c-3843-44f1-b337-bc134417f01c,DISK], DatanodeInfoWithStorage[127.0.0.1:39621,DS-50a63491-a2be-43a1-bee4-1d797c16a744,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-dd78af94-e625-4c61-980a-15e900387c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-abc4c93f-6040-4d19-87fc-1b51ee19795e,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-580389eb-a5e1-4f40-971d-589fa514b226,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-64a9cbc7-fc7f-4596-bec6-ee099d5ce638,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-6c4f3ea7-581d-496e-96f3-f83156069d37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1664776920-172.17.0.12-1595851238657:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33472,DS-668e07b2-f334-4c64-9f4b-a3baba0ba534,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-23b193bf-bdc4-4890-9743-550af1bab8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-5c79b41c-4684-4ff6-9efa-9d03e73cdcc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-23b3dd0c-33d0-499a-9a7d-2b62e6584c88,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-0ea373b8-f4c5-4cf4-acf6-c25054b1a9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-691e2a3f-6812-4abf-beab-b3a5b3293092,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-7b14cdd1-1848-4bd0-a207-3bf306f6c2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-9d6dbaf5-d7ac-4dc8-965d-59947cbd2fef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1664776920-172.17.0.12-1595851238657:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33472,DS-668e07b2-f334-4c64-9f4b-a3baba0ba534,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-23b193bf-bdc4-4890-9743-550af1bab8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-5c79b41c-4684-4ff6-9efa-9d03e73cdcc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-23b3dd0c-33d0-499a-9a7d-2b62e6584c88,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-0ea373b8-f4c5-4cf4-acf6-c25054b1a9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-691e2a3f-6812-4abf-beab-b3a5b3293092,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-7b14cdd1-1848-4bd0-a207-3bf306f6c2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-9d6dbaf5-d7ac-4dc8-965d-59947cbd2fef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1810313106-172.17.0.12-1595851417347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40057,DS-b4499d74-6f9a-4be3-bf0b-96bb056340ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-303666ca-5cd2-4096-80a3-30ce6fb2de80,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-0e1753ee-ae19-4a65-9ded-9082bec05a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-f376e671-cf02-4dbf-a973-4fee3d46b58a,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-bf7b81ac-76f4-4321-8c3b-7233691fff3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-067ae4c8-f32a-4b51-a1b3-7b6a52824b53,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-967a1216-2a04-40d6-b133-f3fcbf98950a,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-2154f5cd-c1b9-4629-a91f-64027b16ed2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1810313106-172.17.0.12-1595851417347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40057,DS-b4499d74-6f9a-4be3-bf0b-96bb056340ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-303666ca-5cd2-4096-80a3-30ce6fb2de80,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-0e1753ee-ae19-4a65-9ded-9082bec05a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-f376e671-cf02-4dbf-a973-4fee3d46b58a,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-bf7b81ac-76f4-4321-8c3b-7233691fff3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-067ae4c8-f32a-4b51-a1b3-7b6a52824b53,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-967a1216-2a04-40d6-b133-f3fcbf98950a,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-2154f5cd-c1b9-4629-a91f-64027b16ed2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-67853527-172.17.0.12-1595852062025:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46477,DS-91936b84-c1fc-4361-97ea-5f10ac1d79e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-e8ff5d0a-e96c-43d0-9767-03e483b7de4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-4488fbbb-45a5-424d-87aa-5c5e6014f7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-dd130cb4-0a99-4498-aea4-12ed9656992f,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-d09d53a2-9363-42be-9baa-2842c7848b50,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-1e1f8b0f-3004-48b7-a567-7b6313df8d57,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-0998994b-e144-4ec8-be48-2d4e0ddf057e,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-221ee0a7-e208-47d6-b15e-ba4a6881cde0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-67853527-172.17.0.12-1595852062025:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46477,DS-91936b84-c1fc-4361-97ea-5f10ac1d79e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-e8ff5d0a-e96c-43d0-9767-03e483b7de4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-4488fbbb-45a5-424d-87aa-5c5e6014f7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-dd130cb4-0a99-4498-aea4-12ed9656992f,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-d09d53a2-9363-42be-9baa-2842c7848b50,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-1e1f8b0f-3004-48b7-a567-7b6313df8d57,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-0998994b-e144-4ec8-be48-2d4e0ddf057e,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-221ee0a7-e208-47d6-b15e-ba4a6881cde0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1806275529-172.17.0.12-1595852968342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45981,DS-860fa381-93d0-4f75-8615-3979f3313f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-57590c50-005b-46ba-9183-6a2ddb9506e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-2726db1b-5e85-4661-a16a-29450cb7667c,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-fee8002c-1376-409c-a882-8ff9b62a9503,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-13e66dd9-0b5c-4412-9030-dda513a05cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-b5dbcc0b-6801-4a8b-8c04-a5fe37a3f51f,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-78b6b20b-e6d6-4fab-8762-3fe962e969c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36272,DS-42c41e70-63b1-446c-8249-a2c72868235a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1806275529-172.17.0.12-1595852968342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45981,DS-860fa381-93d0-4f75-8615-3979f3313f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-57590c50-005b-46ba-9183-6a2ddb9506e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-2726db1b-5e85-4661-a16a-29450cb7667c,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-fee8002c-1376-409c-a882-8ff9b62a9503,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-13e66dd9-0b5c-4412-9030-dda513a05cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-b5dbcc0b-6801-4a8b-8c04-a5fe37a3f51f,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-78b6b20b-e6d6-4fab-8762-3fe962e969c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36272,DS-42c41e70-63b1-446c-8249-a2c72868235a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 6557
