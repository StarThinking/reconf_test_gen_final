reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1690723911-172.17.0.9-1595896731114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44982,DS-6dadd044-c554-4fce-9b65-c23c6089a76b,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-cc34d698-283e-4c28-b70d-83363705ad6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-9cf9e561-bdae-4d3a-804a-5f0c30a0c322,DISK], DatanodeInfoWithStorage[127.0.0.1:39623,DS-89e5a829-f966-4443-901d-0de37baefeb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34695,DS-3f2846b7-1696-4ac0-81ae-681290cb5772,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-6a896ebf-9b81-4999-8af4-53e5e547b7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-82a05517-bdeb-409f-8749-230e2f3938f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-45d42659-bee4-456e-a193-5372c17a5edd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1690723911-172.17.0.9-1595896731114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44982,DS-6dadd044-c554-4fce-9b65-c23c6089a76b,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-cc34d698-283e-4c28-b70d-83363705ad6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-9cf9e561-bdae-4d3a-804a-5f0c30a0c322,DISK], DatanodeInfoWithStorage[127.0.0.1:39623,DS-89e5a829-f966-4443-901d-0de37baefeb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34695,DS-3f2846b7-1696-4ac0-81ae-681290cb5772,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-6a896ebf-9b81-4999-8af4-53e5e547b7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-82a05517-bdeb-409f-8749-230e2f3938f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-45d42659-bee4-456e-a193-5372c17a5edd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1180181705-172.17.0.9-1595896836698:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43256,DS-8dbbb02c-edf3-4d75-876a-aa553bea368f,DISK], DatanodeInfoWithStorage[127.0.0.1:37192,DS-65955b08-21c8-4201-8e6f-98c1cee2bb21,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-8c482cd5-d9ad-41b8-a1aa-8f097dd9cc65,DISK], DatanodeInfoWithStorage[127.0.0.1:38696,DS-9f8b0a83-1ce7-4c6b-be08-c39a4477f822,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-ed14bca3-8a2b-48ea-8bc9-2d537cf1ff79,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-a952077f-d83c-4bf6-88a8-3ac0feaaba4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45837,DS-e0b096b4-2247-4367-a326-8a1b135572b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-4e25e469-35bc-42bb-b157-054193cfd2e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1180181705-172.17.0.9-1595896836698:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43256,DS-8dbbb02c-edf3-4d75-876a-aa553bea368f,DISK], DatanodeInfoWithStorage[127.0.0.1:37192,DS-65955b08-21c8-4201-8e6f-98c1cee2bb21,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-8c482cd5-d9ad-41b8-a1aa-8f097dd9cc65,DISK], DatanodeInfoWithStorage[127.0.0.1:38696,DS-9f8b0a83-1ce7-4c6b-be08-c39a4477f822,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-ed14bca3-8a2b-48ea-8bc9-2d537cf1ff79,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-a952077f-d83c-4bf6-88a8-3ac0feaaba4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45837,DS-e0b096b4-2247-4367-a326-8a1b135572b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-4e25e469-35bc-42bb-b157-054193cfd2e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1488104195-172.17.0.9-1595897063381:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36408,DS-d48aa854-3d8a-41c3-8d0a-c6c28ea7ab22,DISK], DatanodeInfoWithStorage[127.0.0.1:42382,DS-b241af35-0d54-4569-a8ef-dd62fa8c47ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-1e1ca521-235e-4926-b7c2-ab671deb1d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-39e845f4-84b4-4635-8f8c-be279befd2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-0ff6add2-0f3e-4705-a77a-c3cc90f8f462,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-096b74a3-0b6d-4b4d-9abb-92c7dfdb3d46,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-d56eb08d-86a1-45ba-a129-3f774353485a,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-8d3d4a8d-8224-434a-aa45-3fd20e2d4d82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1488104195-172.17.0.9-1595897063381:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36408,DS-d48aa854-3d8a-41c3-8d0a-c6c28ea7ab22,DISK], DatanodeInfoWithStorage[127.0.0.1:42382,DS-b241af35-0d54-4569-a8ef-dd62fa8c47ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-1e1ca521-235e-4926-b7c2-ab671deb1d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-39e845f4-84b4-4635-8f8c-be279befd2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-0ff6add2-0f3e-4705-a77a-c3cc90f8f462,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-096b74a3-0b6d-4b4d-9abb-92c7dfdb3d46,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-d56eb08d-86a1-45ba-a129-3f774353485a,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-8d3d4a8d-8224-434a-aa45-3fd20e2d4d82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1699482517-172.17.0.9-1595897252217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34205,DS-873cece4-ed33-42bc-8ea1-82101ee5f79b,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-e01b319d-9647-40eb-8701-b209ca9e81c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46234,DS-bbdde30b-b0c7-4257-a004-712896fad377,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-4c583ace-6117-44f0-88de-e380ec3d4fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:45719,DS-02f82f13-3dc9-4141-9c86-95ea3192e849,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-462ecd15-da30-469f-8515-eecdccd5ab32,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-cf0023ba-c506-4961-acd1-6fe53da1b0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-0a2236f0-1706-48d9-bcce-50ae78c9ddbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1699482517-172.17.0.9-1595897252217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34205,DS-873cece4-ed33-42bc-8ea1-82101ee5f79b,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-e01b319d-9647-40eb-8701-b209ca9e81c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46234,DS-bbdde30b-b0c7-4257-a004-712896fad377,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-4c583ace-6117-44f0-88de-e380ec3d4fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:45719,DS-02f82f13-3dc9-4141-9c86-95ea3192e849,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-462ecd15-da30-469f-8515-eecdccd5ab32,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-cf0023ba-c506-4961-acd1-6fe53da1b0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-0a2236f0-1706-48d9-bcce-50ae78c9ddbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-473724492-172.17.0.9-1595897366561:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43574,DS-1e9603e0-9666-4062-82b6-82e4ad552163,DISK], DatanodeInfoWithStorage[127.0.0.1:44934,DS-32096fb0-cb2f-4c8c-887d-7d2300d58029,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-60cf2aa8-bdf3-4f6e-8ec5-77a2bb8a6935,DISK], DatanodeInfoWithStorage[127.0.0.1:46117,DS-59bd6853-7b98-4ec9-97b9-6f1c7e11f52f,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-2ce50a96-d7be-41b1-bf33-17082ea06c08,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-36263460-0f12-49b2-be2f-483bad38988a,DISK], DatanodeInfoWithStorage[127.0.0.1:46517,DS-7a87c40e-b634-46fb-bc29-c81b0d4e07b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-5b5df9ca-23a2-46f1-a7f0-3a7f5dfc5ad4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-473724492-172.17.0.9-1595897366561:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43574,DS-1e9603e0-9666-4062-82b6-82e4ad552163,DISK], DatanodeInfoWithStorage[127.0.0.1:44934,DS-32096fb0-cb2f-4c8c-887d-7d2300d58029,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-60cf2aa8-bdf3-4f6e-8ec5-77a2bb8a6935,DISK], DatanodeInfoWithStorage[127.0.0.1:46117,DS-59bd6853-7b98-4ec9-97b9-6f1c7e11f52f,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-2ce50a96-d7be-41b1-bf33-17082ea06c08,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-36263460-0f12-49b2-be2f-483bad38988a,DISK], DatanodeInfoWithStorage[127.0.0.1:46517,DS-7a87c40e-b634-46fb-bc29-c81b0d4e07b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-5b5df9ca-23a2-46f1-a7f0-3a7f5dfc5ad4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1620250984-172.17.0.9-1595897463462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39139,DS-f22508a8-9cf8-476b-9ced-25fe46291e45,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-c9db314d-4e96-4020-9bd0-8016e0ea3b90,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-57274956-a948-4cea-ac9c-cb6e246f49c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-27874897-6ee4-49c8-931a-a6638e1c8508,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-7d47c07a-a761-4ccb-b474-d38676261e26,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-66ed18c6-ec91-4290-bec1-651affb6041a,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-3a44a91b-04a4-4fa1-8a60-8d57666411ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-7379b340-90e6-4bd4-85f5-fe858744e9bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1620250984-172.17.0.9-1595897463462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39139,DS-f22508a8-9cf8-476b-9ced-25fe46291e45,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-c9db314d-4e96-4020-9bd0-8016e0ea3b90,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-57274956-a948-4cea-ac9c-cb6e246f49c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-27874897-6ee4-49c8-931a-a6638e1c8508,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-7d47c07a-a761-4ccb-b474-d38676261e26,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-66ed18c6-ec91-4290-bec1-651affb6041a,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-3a44a91b-04a4-4fa1-8a60-8d57666411ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-7379b340-90e6-4bd4-85f5-fe858744e9bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-970293741-172.17.0.9-1595897596531:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42945,DS-ee923c75-56bf-4061-81c9-6e439e9ef43d,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-04df92fb-e879-4341-a4a1-0e091d59c6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-3aad2f68-b814-4bed-ba28-1194a0b914e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34594,DS-b2a66dc8-9d08-4bd5-a3c7-e34b173e80aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-df105624-898f-4437-a986-3a615499a24e,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-8968d2d3-8c1c-472d-8861-a3ea25a4053a,DISK], DatanodeInfoWithStorage[127.0.0.1:35724,DS-e6036ae0-2f7b-4542-a9d6-a1166ac3fbbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-7630001d-6425-48c8-ad46-13e395e68309,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-970293741-172.17.0.9-1595897596531:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42945,DS-ee923c75-56bf-4061-81c9-6e439e9ef43d,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-04df92fb-e879-4341-a4a1-0e091d59c6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-3aad2f68-b814-4bed-ba28-1194a0b914e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34594,DS-b2a66dc8-9d08-4bd5-a3c7-e34b173e80aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-df105624-898f-4437-a986-3a615499a24e,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-8968d2d3-8c1c-472d-8861-a3ea25a4053a,DISK], DatanodeInfoWithStorage[127.0.0.1:35724,DS-e6036ae0-2f7b-4542-a9d6-a1166ac3fbbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-7630001d-6425-48c8-ad46-13e395e68309,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-214269330-172.17.0.9-1595898367520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41984,DS-2a31a6d8-1c29-4437-ab63-bbf147cd8f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-59bc9d42-c1cc-4c6d-8f15-e1bc9c1f3631,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-cbbb4dc1-6845-4b1b-85ee-1518f3d2b1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-476c15d6-f2b2-428d-8ba8-74dc86c250ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-211c2f4b-5b0d-40ce-9ade-a26594da5a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-c3fa4aa1-c85f-433e-8def-4c15207bd0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-c1a7b291-7c6d-4aa6-9618-2a596c2c5ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-1f72b59d-2976-446d-893a-61f7bebd0512,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-214269330-172.17.0.9-1595898367520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41984,DS-2a31a6d8-1c29-4437-ab63-bbf147cd8f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-59bc9d42-c1cc-4c6d-8f15-e1bc9c1f3631,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-cbbb4dc1-6845-4b1b-85ee-1518f3d2b1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-476c15d6-f2b2-428d-8ba8-74dc86c250ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-211c2f4b-5b0d-40ce-9ade-a26594da5a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-c3fa4aa1-c85f-433e-8def-4c15207bd0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-c1a7b291-7c6d-4aa6-9618-2a596c2c5ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-1f72b59d-2976-446d-893a-61f7bebd0512,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-783647460-172.17.0.9-1595898860965:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39612,DS-10440228-864c-4b61-88e7-dcd7a64f9dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-d1184c3d-e1a7-4bf1-9b15-974a96dfbc72,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-805b5314-cc7c-4590-b5f5-2b60f30e6634,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-399bb2cc-65eb-40fe-a736-29dbcebe419f,DISK], DatanodeInfoWithStorage[127.0.0.1:40194,DS-d2e4891f-fe8e-4a86-8568-86b63590ab5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-8f35133f-e59c-495a-8fb7-2df16a6782a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-2eb87e58-d9b8-4fc9-ac51-8e4a58437278,DISK], DatanodeInfoWithStorage[127.0.0.1:45369,DS-5fe17f75-3e3b-4877-8757-04de17f78be2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-783647460-172.17.0.9-1595898860965:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39612,DS-10440228-864c-4b61-88e7-dcd7a64f9dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-d1184c3d-e1a7-4bf1-9b15-974a96dfbc72,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-805b5314-cc7c-4590-b5f5-2b60f30e6634,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-399bb2cc-65eb-40fe-a736-29dbcebe419f,DISK], DatanodeInfoWithStorage[127.0.0.1:40194,DS-d2e4891f-fe8e-4a86-8568-86b63590ab5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-8f35133f-e59c-495a-8fb7-2df16a6782a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-2eb87e58-d9b8-4fc9-ac51-8e4a58437278,DISK], DatanodeInfoWithStorage[127.0.0.1:45369,DS-5fe17f75-3e3b-4877-8757-04de17f78be2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-904593994-172.17.0.9-1595899238765:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35019,DS-c8cf9421-62c4-475f-b809-fbc934650735,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-c783d05f-54bc-4af1-89e9-e0e5c643467c,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-245e8018-d559-44b7-b8c7-52e7b1e53f33,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-ecf00cc2-825e-406c-a973-5dede396cf08,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-b89f94b9-54c0-4df8-9a17-ed6eea6e4c76,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-3114fd51-7e34-4f1d-bf9b-00f6cb37ccf3,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-85ab692e-95ec-42eb-8ae9-0db5b09b7e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-0f07a2ff-7570-4c50-aa45-29b79e5c2e3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-904593994-172.17.0.9-1595899238765:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35019,DS-c8cf9421-62c4-475f-b809-fbc934650735,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-c783d05f-54bc-4af1-89e9-e0e5c643467c,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-245e8018-d559-44b7-b8c7-52e7b1e53f33,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-ecf00cc2-825e-406c-a973-5dede396cf08,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-b89f94b9-54c0-4df8-9a17-ed6eea6e4c76,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-3114fd51-7e34-4f1d-bf9b-00f6cb37ccf3,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-85ab692e-95ec-42eb-8ae9-0db5b09b7e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-0f07a2ff-7570-4c50-aa45-29b79e5c2e3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-335538588-172.17.0.9-1595899275759:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40070,DS-912332cb-49be-4145-827f-582f55343a37,DISK], DatanodeInfoWithStorage[127.0.0.1:41932,DS-a435a9b1-f2cc-4399-bfa1-0113804a12b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-4f45f84e-7614-4cf2-a7c6-c8e07ca22911,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-65e27912-9056-4a28-afda-8f296d5ec9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-ac3446ef-52cc-407c-a325-d18d44cfc027,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-b0669486-b716-4365-8bbf-e9253397ef4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-854db669-9e68-435c-9703-13d730ef0123,DISK], DatanodeInfoWithStorage[127.0.0.1:33666,DS-924b37d9-e84f-47c2-8c21-133c8edc61db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-335538588-172.17.0.9-1595899275759:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40070,DS-912332cb-49be-4145-827f-582f55343a37,DISK], DatanodeInfoWithStorage[127.0.0.1:41932,DS-a435a9b1-f2cc-4399-bfa1-0113804a12b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-4f45f84e-7614-4cf2-a7c6-c8e07ca22911,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-65e27912-9056-4a28-afda-8f296d5ec9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-ac3446ef-52cc-407c-a325-d18d44cfc027,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-b0669486-b716-4365-8bbf-e9253397ef4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-854db669-9e68-435c-9703-13d730ef0123,DISK], DatanodeInfoWithStorage[127.0.0.1:33666,DS-924b37d9-e84f-47c2-8c21-133c8edc61db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1800360002-172.17.0.9-1595899601285:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39017,DS-f4ce871f-9f17-4c4b-a2bc-db7da7dd306c,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-7ec8e799-51be-45a8-8c41-3c5e1bb2bc9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40333,DS-117dd70d-f188-44e3-bc96-eb2e38cfc7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-e2cbaa07-efff-4194-a6a0-2044f4888ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-d38f8f5a-fcf5-4662-80c2-4674ff6cd260,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-26092633-4db3-42c5-9721-75d0398bc562,DISK], DatanodeInfoWithStorage[127.0.0.1:41140,DS-4441876e-b83a-4865-89b3-b90ed9716f26,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-5e9513df-c6ac-4de0-be67-6bad938a3d59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1800360002-172.17.0.9-1595899601285:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39017,DS-f4ce871f-9f17-4c4b-a2bc-db7da7dd306c,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-7ec8e799-51be-45a8-8c41-3c5e1bb2bc9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40333,DS-117dd70d-f188-44e3-bc96-eb2e38cfc7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-e2cbaa07-efff-4194-a6a0-2044f4888ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-d38f8f5a-fcf5-4662-80c2-4674ff6cd260,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-26092633-4db3-42c5-9721-75d0398bc562,DISK], DatanodeInfoWithStorage[127.0.0.1:41140,DS-4441876e-b83a-4865-89b3-b90ed9716f26,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-5e9513df-c6ac-4de0-be67-6bad938a3d59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-531909652-172.17.0.9-1595900143872:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33602,DS-26aec875-e877-4111-9c3b-5961331547e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-0cf2f1b5-f356-4758-a0f5-aa8288516156,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-1fc6f03f-b760-4b8a-94c9-701fba292576,DISK], DatanodeInfoWithStorage[127.0.0.1:36911,DS-1d9a5848-947e-437f-92da-fdbc67131942,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-b8a54981-2687-44ca-b46a-40d8ee19a29a,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-ea8c7091-4c4c-4822-937c-fdfd06b8a367,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-029de2ee-9fa8-48a3-b8c1-a6b4229eabaf,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-e9af215c-4bca-4a88-8a3e-f10432aef662,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-531909652-172.17.0.9-1595900143872:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33602,DS-26aec875-e877-4111-9c3b-5961331547e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-0cf2f1b5-f356-4758-a0f5-aa8288516156,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-1fc6f03f-b760-4b8a-94c9-701fba292576,DISK], DatanodeInfoWithStorage[127.0.0.1:36911,DS-1d9a5848-947e-437f-92da-fdbc67131942,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-b8a54981-2687-44ca-b46a-40d8ee19a29a,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-ea8c7091-4c4c-4822-937c-fdfd06b8a367,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-029de2ee-9fa8-48a3-b8c1-a6b4229eabaf,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-e9af215c-4bca-4a88-8a3e-f10432aef662,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-306221074-172.17.0.9-1595900212635:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46377,DS-01b65d2a-bf18-47bb-97cb-37a6021c49e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-c55f3ca4-8722-4c78-be17-3aa435b7cbe7,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-e1c3b02a-f9bd-4511-8bfa-eea93b8d10b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-ea71914c-79e5-4918-aea2-9ac7750e675b,DISK], DatanodeInfoWithStorage[127.0.0.1:42596,DS-4e08d38f-cd2e-4b06-91b5-325dedede440,DISK], DatanodeInfoWithStorage[127.0.0.1:37953,DS-8a48a31b-2abf-4ae8-b610-72794c22fa4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34724,DS-0ba9ead6-a010-4620-8913-4aee0297eaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-be1dd579-fc43-4085-b9e9-a21bd8dabf0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-306221074-172.17.0.9-1595900212635:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46377,DS-01b65d2a-bf18-47bb-97cb-37a6021c49e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-c55f3ca4-8722-4c78-be17-3aa435b7cbe7,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-e1c3b02a-f9bd-4511-8bfa-eea93b8d10b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-ea71914c-79e5-4918-aea2-9ac7750e675b,DISK], DatanodeInfoWithStorage[127.0.0.1:42596,DS-4e08d38f-cd2e-4b06-91b5-325dedede440,DISK], DatanodeInfoWithStorage[127.0.0.1:37953,DS-8a48a31b-2abf-4ae8-b610-72794c22fa4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34724,DS-0ba9ead6-a010-4620-8913-4aee0297eaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-be1dd579-fc43-4085-b9e9-a21bd8dabf0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1330776917-172.17.0.9-1595900544276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44224,DS-eacce798-bb40-4227-a00c-271c8bb804e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-21a4bba3-4fae-400c-a42c-9cffe29f0c44,DISK], DatanodeInfoWithStorage[127.0.0.1:40781,DS-24847073-43b6-4320-87f8-34e6557c1c03,DISK], DatanodeInfoWithStorage[127.0.0.1:36108,DS-4d9a4cbd-9e29-43fb-881d-9175ca0ed68d,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-cde009ce-1a8c-44d2-85ca-92e42e1a11a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-02a846e6-8d6f-4eca-95b7-c6c1c0e6ce7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-3e257ddf-b220-41d0-a537-12b61f678f86,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-2de77efc-f3a3-4e44-8c22-f10b40dbf93d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1330776917-172.17.0.9-1595900544276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44224,DS-eacce798-bb40-4227-a00c-271c8bb804e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-21a4bba3-4fae-400c-a42c-9cffe29f0c44,DISK], DatanodeInfoWithStorage[127.0.0.1:40781,DS-24847073-43b6-4320-87f8-34e6557c1c03,DISK], DatanodeInfoWithStorage[127.0.0.1:36108,DS-4d9a4cbd-9e29-43fb-881d-9175ca0ed68d,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-cde009ce-1a8c-44d2-85ca-92e42e1a11a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-02a846e6-8d6f-4eca-95b7-c6c1c0e6ce7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-3e257ddf-b220-41d0-a537-12b61f678f86,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-2de77efc-f3a3-4e44-8c22-f10b40dbf93d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1097102772-172.17.0.9-1595900618227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44616,DS-71db9671-933f-42c4-b92e-6e946fbcbd88,DISK], DatanodeInfoWithStorage[127.0.0.1:37999,DS-e406eacf-9f15-4e28-aedb-8fd6dca9954d,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-0dfa6ae5-7b35-422c-a917-96cce0e62e81,DISK], DatanodeInfoWithStorage[127.0.0.1:42751,DS-937eed03-a971-4ccd-8697-a77276200b32,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-24baad02-a53f-43e1-b519-88563e49c1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34311,DS-f96d488f-85e2-4856-b793-873f33c53b67,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-bca85170-90b0-452e-b7f9-ae97e571b503,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-fd19cd4c-f8bc-4730-954e-5f591d414ce2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1097102772-172.17.0.9-1595900618227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44616,DS-71db9671-933f-42c4-b92e-6e946fbcbd88,DISK], DatanodeInfoWithStorage[127.0.0.1:37999,DS-e406eacf-9f15-4e28-aedb-8fd6dca9954d,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-0dfa6ae5-7b35-422c-a917-96cce0e62e81,DISK], DatanodeInfoWithStorage[127.0.0.1:42751,DS-937eed03-a971-4ccd-8697-a77276200b32,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-24baad02-a53f-43e1-b519-88563e49c1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34311,DS-f96d488f-85e2-4856-b793-873f33c53b67,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-bca85170-90b0-452e-b7f9-ae97e571b503,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-fd19cd4c-f8bc-4730-954e-5f591d414ce2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1645168789-172.17.0.9-1595901475235:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44388,DS-f9e9d692-0f5a-41ae-add7-7042f5471355,DISK], DatanodeInfoWithStorage[127.0.0.1:35875,DS-e54d9d14-28d8-46ba-91f2-cb74d655ac85,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-92e91395-740e-4a6c-b428-f66bc31d3a96,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-2e869860-f94f-451b-9d84-5a3b4cc46dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-e3257b54-fc27-4a7c-9f13-f15c263784ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-031b91e5-d875-4435-8b59-660abc1c8748,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-604058ba-e254-4b97-9686-54aa6b9cd102,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-ad1f8661-7e01-47e4-a801-0ce416c197b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1645168789-172.17.0.9-1595901475235:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44388,DS-f9e9d692-0f5a-41ae-add7-7042f5471355,DISK], DatanodeInfoWithStorage[127.0.0.1:35875,DS-e54d9d14-28d8-46ba-91f2-cb74d655ac85,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-92e91395-740e-4a6c-b428-f66bc31d3a96,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-2e869860-f94f-451b-9d84-5a3b4cc46dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-e3257b54-fc27-4a7c-9f13-f15c263784ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-031b91e5-d875-4435-8b59-660abc1c8748,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-604058ba-e254-4b97-9686-54aa6b9cd102,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-ad1f8661-7e01-47e4-a801-0ce416c197b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-938311423-172.17.0.9-1595901711001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35399,DS-f6740cc9-dca1-4c74-9be0-c08185fb5075,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-eeab004d-cf81-4152-880a-9d0e1b318a51,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-4183d333-1e86-4082-8da9-8655d76fecf2,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-e84a014f-6a06-404d-b7d2-b18e7ad9601a,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-3157837f-66d4-40f3-bbf1-937026c806a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-7be88c86-632f-4740-ad40-22b72ca7cbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-462131a7-aebe-4afa-a527-6388f9751433,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-d39e3cfd-6c6b-43e7-9b50-d1b08aa15f0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-938311423-172.17.0.9-1595901711001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35399,DS-f6740cc9-dca1-4c74-9be0-c08185fb5075,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-eeab004d-cf81-4152-880a-9d0e1b318a51,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-4183d333-1e86-4082-8da9-8655d76fecf2,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-e84a014f-6a06-404d-b7d2-b18e7ad9601a,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-3157837f-66d4-40f3-bbf1-937026c806a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-7be88c86-632f-4740-ad40-22b72ca7cbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-462131a7-aebe-4afa-a527-6388f9751433,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-d39e3cfd-6c6b-43e7-9b50-d1b08aa15f0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5353
