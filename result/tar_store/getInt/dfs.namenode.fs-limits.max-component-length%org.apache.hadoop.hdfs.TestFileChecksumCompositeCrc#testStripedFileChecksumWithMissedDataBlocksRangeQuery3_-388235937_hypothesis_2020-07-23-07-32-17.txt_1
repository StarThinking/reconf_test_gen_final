reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 255
v2: 262143
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 255
v2: 262143
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1812827793-172.17.0.7-1595491633104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42600,DS-1a9694f4-2ef5-40dd-b66b-34f040dd927c,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-b06360be-a664-492a-8bd9-63065bcbb955,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-b3f56061-22ad-488a-8660-ec3108c6eca3,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-65bae0a9-2644-4203-8ffc-60aff8858ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-958e3004-1728-4878-8d5a-96a01bc89287,DISK], DatanodeInfoWithStorage[127.0.0.1:42777,DS-d0fdf974-f835-4306-9da6-266eddf8a4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-4494006c-3f8b-4a1d-be13-ff7b08acf814,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-e121a4af-fc40-4c71-8898-bd3a5ed62549,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1812827793-172.17.0.7-1595491633104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42600,DS-1a9694f4-2ef5-40dd-b66b-34f040dd927c,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-b06360be-a664-492a-8bd9-63065bcbb955,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-b3f56061-22ad-488a-8660-ec3108c6eca3,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-65bae0a9-2644-4203-8ffc-60aff8858ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-958e3004-1728-4878-8d5a-96a01bc89287,DISK], DatanodeInfoWithStorage[127.0.0.1:42777,DS-d0fdf974-f835-4306-9da6-266eddf8a4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-4494006c-3f8b-4a1d-be13-ff7b08acf814,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-e121a4af-fc40-4c71-8898-bd3a5ed62549,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 255
v2: 262143
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-135273397-172.17.0.7-1595491880101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44578,DS-baf33a60-0fc0-435b-b899-989fa1cb13b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33546,DS-9cf7e6aa-40f6-4767-a9e9-f879cabc82b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-40280c81-8cfa-49b6-96d0-cebbc454a611,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-1992f331-fff5-45aa-a2f7-396d29038035,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-9bdb53d1-a0d5-4c6a-be4e-9d213919bf20,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-3099949b-7755-4ae1-b679-05efeea63d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-dbd9db1b-118a-4b85-8c5a-35fe0c854be9,DISK], DatanodeInfoWithStorage[127.0.0.1:33200,DS-340631fd-0089-4b7b-adee-00b550092957,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-135273397-172.17.0.7-1595491880101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44578,DS-baf33a60-0fc0-435b-b899-989fa1cb13b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33546,DS-9cf7e6aa-40f6-4767-a9e9-f879cabc82b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-40280c81-8cfa-49b6-96d0-cebbc454a611,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-1992f331-fff5-45aa-a2f7-396d29038035,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-9bdb53d1-a0d5-4c6a-be4e-9d213919bf20,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-3099949b-7755-4ae1-b679-05efeea63d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-dbd9db1b-118a-4b85-8c5a-35fe0c854be9,DISK], DatanodeInfoWithStorage[127.0.0.1:33200,DS-340631fd-0089-4b7b-adee-00b550092957,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 255
v2: 262143
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008755333-172.17.0.7-1595492359847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42059,DS-b299144a-6779-442a-8ebd-e4b1c3f1cd04,DISK], DatanodeInfoWithStorage[127.0.0.1:45605,DS-98e3e290-b950-4cec-9111-d0c68f4cdd35,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-edea65df-18cb-45d8-bced-43c7dc4b4727,DISK], DatanodeInfoWithStorage[127.0.0.1:40199,DS-77cd5b9b-2a9f-425a-ab0e-accd2a4f6f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-faebd6c1-54d4-46b1-8024-7e1f1d552929,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-9d2230db-7e9b-4c45-b9d9-5edd6303b66d,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-69e3cbc2-e73a-4ebf-91e7-e7f171ed1d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-a4d3a9fc-22a1-4c4f-9256-e19dbdcde56f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008755333-172.17.0.7-1595492359847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42059,DS-b299144a-6779-442a-8ebd-e4b1c3f1cd04,DISK], DatanodeInfoWithStorage[127.0.0.1:45605,DS-98e3e290-b950-4cec-9111-d0c68f4cdd35,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-edea65df-18cb-45d8-bced-43c7dc4b4727,DISK], DatanodeInfoWithStorage[127.0.0.1:40199,DS-77cd5b9b-2a9f-425a-ab0e-accd2a4f6f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-faebd6c1-54d4-46b1-8024-7e1f1d552929,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-9d2230db-7e9b-4c45-b9d9-5edd6303b66d,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-69e3cbc2-e73a-4ebf-91e7-e7f171ed1d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-a4d3a9fc-22a1-4c4f-9256-e19dbdcde56f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 255
v2: 262143
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1399521253-172.17.0.7-1595492668179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37168,DS-3e988c6f-7d79-406f-bfc7-94f017211430,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-8e8b0d68-2c1b-45da-ba08-9ee816b85f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-d05ad93c-6d64-4a1e-9166-a06f0b00a82b,DISK], DatanodeInfoWithStorage[127.0.0.1:40688,DS-4fea5bde-8427-4033-b402-887330d397df,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-e540376b-dfd2-44f3-b89f-03d9e86a82ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-405ab83c-3ba8-4d6a-be67-7f8a4011cda6,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-dfc8b1d4-eb93-4e0d-b283-2d3e63687893,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-09f5c979-0a7e-4d09-8c4c-b9e845c590ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1399521253-172.17.0.7-1595492668179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37168,DS-3e988c6f-7d79-406f-bfc7-94f017211430,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-8e8b0d68-2c1b-45da-ba08-9ee816b85f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-d05ad93c-6d64-4a1e-9166-a06f0b00a82b,DISK], DatanodeInfoWithStorage[127.0.0.1:40688,DS-4fea5bde-8427-4033-b402-887330d397df,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-e540376b-dfd2-44f3-b89f-03d9e86a82ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-405ab83c-3ba8-4d6a-be67-7f8a4011cda6,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-dfc8b1d4-eb93-4e0d-b283-2d3e63687893,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-09f5c979-0a7e-4d09-8c4c-b9e845c590ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 255
v2: 262143
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-707834365-172.17.0.7-1595492965620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36286,DS-b9308cf5-ef60-4e86-99a3-f8f82e43efec,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-f257ef2b-750b-4784-914e-0e654ceb86d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-0e5e3fc6-6e75-45fe-a485-662e47bb8960,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-28536b89-4e4d-4211-8137-86a7e1cbcd16,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-a6df2faf-7513-495b-a639-4ba2a06a60bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-0848f49e-21ee-40ce-848e-7e30093597de,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-3a449629-66ea-40c9-868c-f7b4cd22055c,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-f323e706-422e-4d65-98e7-ef1436b95722,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-707834365-172.17.0.7-1595492965620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36286,DS-b9308cf5-ef60-4e86-99a3-f8f82e43efec,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-f257ef2b-750b-4784-914e-0e654ceb86d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-0e5e3fc6-6e75-45fe-a485-662e47bb8960,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-28536b89-4e4d-4211-8137-86a7e1cbcd16,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-a6df2faf-7513-495b-a639-4ba2a06a60bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-0848f49e-21ee-40ce-848e-7e30093597de,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-3a449629-66ea-40c9-868c-f7b4cd22055c,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-f323e706-422e-4d65-98e7-ef1436b95722,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 255
v2: 262143
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1983697423-172.17.0.7-1595493212972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33763,DS-77d6f0d3-5cae-4f81-99af-26fabe44812a,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-e0f81bff-21b4-4e1b-bb0b-722a275be905,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-aad69089-3303-4f2c-9cdf-e0a355ba44c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-b89b66de-4761-49bf-be82-a06008c9d654,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-eeff3ecd-3c6b-46c6-abdf-da6177375905,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-4755bcb8-0497-44db-9999-d99124a9ba60,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-8bda6945-c9bf-49e6-9e66-5554d7c141d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-ec04f0aa-4277-4495-87f8-8f8245ffa253,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1983697423-172.17.0.7-1595493212972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33763,DS-77d6f0d3-5cae-4f81-99af-26fabe44812a,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-e0f81bff-21b4-4e1b-bb0b-722a275be905,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-aad69089-3303-4f2c-9cdf-e0a355ba44c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-b89b66de-4761-49bf-be82-a06008c9d654,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-eeff3ecd-3c6b-46c6-abdf-da6177375905,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-4755bcb8-0497-44db-9999-d99124a9ba60,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-8bda6945-c9bf-49e6-9e66-5554d7c141d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-ec04f0aa-4277-4495-87f8-8f8245ffa253,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 255
v2: 262143
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-811523835-172.17.0.7-1595493559350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35703,DS-e2e5e1c9-8412-4367-ab80-52d710e0d609,DISK], DatanodeInfoWithStorage[127.0.0.1:40555,DS-66773feb-6e32-4680-8e33-5cd018a11578,DISK], DatanodeInfoWithStorage[127.0.0.1:46070,DS-3cfe6abb-5e40-4303-97a8-3de536313c38,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-721f93bd-7c29-4745-b2e9-b2d4e805a2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-11a907e8-a27e-4a3a-8689-38beccadd234,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-2395968f-eae6-44f4-961b-478111e692a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-b013aad5-a027-41c7-938b-9f77707a71c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-2b652c0e-c272-4ffa-94cd-132405e4b8eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-811523835-172.17.0.7-1595493559350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35703,DS-e2e5e1c9-8412-4367-ab80-52d710e0d609,DISK], DatanodeInfoWithStorage[127.0.0.1:40555,DS-66773feb-6e32-4680-8e33-5cd018a11578,DISK], DatanodeInfoWithStorage[127.0.0.1:46070,DS-3cfe6abb-5e40-4303-97a8-3de536313c38,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-721f93bd-7c29-4745-b2e9-b2d4e805a2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-11a907e8-a27e-4a3a-8689-38beccadd234,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-2395968f-eae6-44f4-961b-478111e692a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-b013aad5-a027-41c7-938b-9f77707a71c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-2b652c0e-c272-4ffa-94cd-132405e4b8eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 255
v2: 262143
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-515392873-172.17.0.7-1595493591584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40803,DS-23cb99e2-12bb-47b5-9f78-0764ff6bc163,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-fc421833-e48c-4222-8e54-a5e10e7c9ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-01299a1e-3e83-467c-8d88-766e844a8212,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-2a04321a-3d74-4a49-b12a-e360a0ad1ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-c4d57a50-d252-4f22-b673-fbf550769fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-df710d44-910e-442c-aab3-19847a20fb17,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-d1f24d84-a5af-46c0-8df7-6113351226d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-8f167794-2e70-41ce-a058-bb65b0f21470,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-515392873-172.17.0.7-1595493591584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40803,DS-23cb99e2-12bb-47b5-9f78-0764ff6bc163,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-fc421833-e48c-4222-8e54-a5e10e7c9ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-01299a1e-3e83-467c-8d88-766e844a8212,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-2a04321a-3d74-4a49-b12a-e360a0ad1ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-c4d57a50-d252-4f22-b673-fbf550769fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-df710d44-910e-442c-aab3-19847a20fb17,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-d1f24d84-a5af-46c0-8df7-6113351226d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-8f167794-2e70-41ce-a058-bb65b0f21470,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 255
v2: 262143
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-146616140-172.17.0.7-1595493801584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35843,DS-f159f0be-a3d1-4990-a68b-b3b8a0bc8a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-a5177907-47bd-4d0d-8a6c-07aa6ef16c95,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-db6364f2-f950-4625-a014-2185074ef21b,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-dd03e5e8-782f-4820-adf4-9ac9f0cbbbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-76a920d2-eae7-4e79-91b9-1a4d4b6625ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-1989fb8e-026c-4bca-a09c-3e471e7d6aee,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-85672218-884b-456c-98e6-a048a321afcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-0b63372a-4964-4574-9cf6-89f757deecb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-146616140-172.17.0.7-1595493801584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35843,DS-f159f0be-a3d1-4990-a68b-b3b8a0bc8a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-a5177907-47bd-4d0d-8a6c-07aa6ef16c95,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-db6364f2-f950-4625-a014-2185074ef21b,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-dd03e5e8-782f-4820-adf4-9ac9f0cbbbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-76a920d2-eae7-4e79-91b9-1a4d4b6625ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-1989fb8e-026c-4bca-a09c-3e471e7d6aee,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-85672218-884b-456c-98e6-a048a321afcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-0b63372a-4964-4574-9cf6-89f757deecb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 255
v2: 262143
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1483203458-172.17.0.7-1595494694325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34020,DS-65646516-a61c-4505-bdd5-47e4328bcd92,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-296e1529-633e-49c0-955a-81f0ba2d64bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-0bab176b-b1de-4d62-975f-f8b5acebbe65,DISK], DatanodeInfoWithStorage[127.0.0.1:41711,DS-f20bd137-49e0-463d-b6d1-3d3e9f7ad8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-f67af7fc-834f-496d-88ad-59c7133e42ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34648,DS-860db8b9-fb70-468c-b2ef-ecfadc207415,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-5f3e9416-6ffa-4491-bba6-94e678581b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-b9400a1f-7c13-4f5f-962e-d95724a84692,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1483203458-172.17.0.7-1595494694325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34020,DS-65646516-a61c-4505-bdd5-47e4328bcd92,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-296e1529-633e-49c0-955a-81f0ba2d64bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-0bab176b-b1de-4d62-975f-f8b5acebbe65,DISK], DatanodeInfoWithStorage[127.0.0.1:41711,DS-f20bd137-49e0-463d-b6d1-3d3e9f7ad8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-f67af7fc-834f-496d-88ad-59c7133e42ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34648,DS-860db8b9-fb70-468c-b2ef-ecfadc207415,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-5f3e9416-6ffa-4491-bba6-94e678581b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-b9400a1f-7c13-4f5f-962e-d95724a84692,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 255
v2: 262143
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1434897012-172.17.0.7-1595494846806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40856,DS-588f18cd-09c1-49b3-8a28-6fb038e7f55e,DISK], DatanodeInfoWithStorage[127.0.0.1:35284,DS-1edde5ac-a750-47eb-8008-13b365465230,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-762ca771-a333-4ba3-b6a5-6948b7932a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-d6fcb4bc-83a5-4c4e-a9b8-6da744aeebe0,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-021a2161-a155-42b9-afdd-6d5bc6ad579d,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-7b044f2d-7925-490c-937e-edaba8c51049,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-e9470fdb-6cef-4044-ab0e-ad985fef5367,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-2b5add0b-7bf2-47c1-bc66-8e7e53b34acf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1434897012-172.17.0.7-1595494846806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40856,DS-588f18cd-09c1-49b3-8a28-6fb038e7f55e,DISK], DatanodeInfoWithStorage[127.0.0.1:35284,DS-1edde5ac-a750-47eb-8008-13b365465230,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-762ca771-a333-4ba3-b6a5-6948b7932a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-d6fcb4bc-83a5-4c4e-a9b8-6da744aeebe0,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-021a2161-a155-42b9-afdd-6d5bc6ad579d,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-7b044f2d-7925-490c-937e-edaba8c51049,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-e9470fdb-6cef-4044-ab0e-ad985fef5367,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-2b5add0b-7bf2-47c1-bc66-8e7e53b34acf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5451
