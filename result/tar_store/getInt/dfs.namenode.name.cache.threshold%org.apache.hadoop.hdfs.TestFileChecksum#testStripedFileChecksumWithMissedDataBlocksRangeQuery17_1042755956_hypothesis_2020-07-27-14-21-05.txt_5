reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-627386483-172.17.0.10-1595860119948:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42618,DS-6ce86b4f-a2df-4342-ab07-fdd534e67da2,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-7bdc4541-f1a0-4c69-8eba-4d8c54ed9360,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-15ecde6d-8a81-463b-85c4-c73acf8139f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-270c7e38-8998-4482-a0a9-4d3bee142b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-084e7abe-2d8e-46fb-a12b-69d6b4b14548,DISK], DatanodeInfoWithStorage[127.0.0.1:39231,DS-d69bc0c3-8431-482f-914a-90f861c90205,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-e82177a5-4a5b-422e-b0c9-29b1c402c4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-32064798-5d82-4a8d-8b70-6b9fe54aba4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-627386483-172.17.0.10-1595860119948:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42618,DS-6ce86b4f-a2df-4342-ab07-fdd534e67da2,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-7bdc4541-f1a0-4c69-8eba-4d8c54ed9360,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-15ecde6d-8a81-463b-85c4-c73acf8139f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-270c7e38-8998-4482-a0a9-4d3bee142b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-084e7abe-2d8e-46fb-a12b-69d6b4b14548,DISK], DatanodeInfoWithStorage[127.0.0.1:39231,DS-d69bc0c3-8431-482f-914a-90f861c90205,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-e82177a5-4a5b-422e-b0c9-29b1c402c4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-32064798-5d82-4a8d-8b70-6b9fe54aba4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1393888937-172.17.0.10-1595860193032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45480,DS-dce943c8-f46f-476e-9991-f2c2238aea4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-197beac9-4378-4416-8fce-76f94da69372,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-bf865bfa-4dce-495f-96f7-e0fd60a0553d,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-b43e35a9-5656-4c1b-8da1-bad5114c0db1,DISK], DatanodeInfoWithStorage[127.0.0.1:40685,DS-c90acf05-d453-4133-9e45-2c105b0d3f33,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-892106e6-591f-4c03-acda-0fad28626f45,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-0b076d3d-4213-403d-8ef1-08ab3dd7856a,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-29313fa4-b9b8-45f1-8e2b-5224e560f076,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1393888937-172.17.0.10-1595860193032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45480,DS-dce943c8-f46f-476e-9991-f2c2238aea4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-197beac9-4378-4416-8fce-76f94da69372,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-bf865bfa-4dce-495f-96f7-e0fd60a0553d,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-b43e35a9-5656-4c1b-8da1-bad5114c0db1,DISK], DatanodeInfoWithStorage[127.0.0.1:40685,DS-c90acf05-d453-4133-9e45-2c105b0d3f33,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-892106e6-591f-4c03-acda-0fad28626f45,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-0b076d3d-4213-403d-8ef1-08ab3dd7856a,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-29313fa4-b9b8-45f1-8e2b-5224e560f076,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1949109610-172.17.0.10-1595860266238:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35587,DS-df556c7f-c45c-4a9a-a3fc-f075a65d54ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-4d97e67a-37fc-4d3d-af9c-6d7f25ecccd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-6e75a8d2-85a8-48ec-b9a3-996aab9a0aac,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-83ff5e0d-f349-4e94-973a-fac6e499f029,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-a086e88f-df7d-4421-8cf5-64892de8bfd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42457,DS-09b2aa17-8336-4165-89f0-73e64b6f2355,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-46324b7e-48cf-4bcb-9ae1-ec8cf19e0d85,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-d598a6bc-8d24-4100-9da5-53d7a5b3aede,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1949109610-172.17.0.10-1595860266238:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35587,DS-df556c7f-c45c-4a9a-a3fc-f075a65d54ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-4d97e67a-37fc-4d3d-af9c-6d7f25ecccd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-6e75a8d2-85a8-48ec-b9a3-996aab9a0aac,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-83ff5e0d-f349-4e94-973a-fac6e499f029,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-a086e88f-df7d-4421-8cf5-64892de8bfd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42457,DS-09b2aa17-8336-4165-89f0-73e64b6f2355,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-46324b7e-48cf-4bcb-9ae1-ec8cf19e0d85,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-d598a6bc-8d24-4100-9da5-53d7a5b3aede,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1148698876-172.17.0.10-1595860377031:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37812,DS-a92fbfe5-31e4-454c-9e41-4ac80e477d30,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-b6c04f97-f4a2-4ebb-b9dc-24481bdf8e23,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-a4a99164-4f62-4b6c-a64a-13ed07130465,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-d73329b1-04a9-40e4-bacb-cdb4351b8083,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-824cee63-dd12-4dfa-8d44-57fa3cf634d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-b155f1d4-3bc4-4ed3-8044-1e13cf22797e,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-de61366d-ad60-4668-b7cf-6ee0cc7b683b,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-b3d87e65-6609-4ef6-9976-6e88a4c31107,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1148698876-172.17.0.10-1595860377031:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37812,DS-a92fbfe5-31e4-454c-9e41-4ac80e477d30,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-b6c04f97-f4a2-4ebb-b9dc-24481bdf8e23,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-a4a99164-4f62-4b6c-a64a-13ed07130465,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-d73329b1-04a9-40e4-bacb-cdb4351b8083,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-824cee63-dd12-4dfa-8d44-57fa3cf634d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-b155f1d4-3bc4-4ed3-8044-1e13cf22797e,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-de61366d-ad60-4668-b7cf-6ee0cc7b683b,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-b3d87e65-6609-4ef6-9976-6e88a4c31107,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2042108165-172.17.0.10-1595860753944:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45763,DS-af7be19e-e148-4347-b276-7f526fd1893e,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-18eb56e8-06a8-42e1-a41b-bda96e2745fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-a36fd6fb-0597-4398-a374-440a3215b687,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-03a6c64b-6f65-4f2e-9fad-b86dfe9f1291,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-3ce665e7-8b71-4c03-ab02-dedfd6eb17f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-db475728-dd19-4d79-a4f1-c92309d28dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45871,DS-a599e8f3-22b5-4e17-8ab0-149e329fbd17,DISK], DatanodeInfoWithStorage[127.0.0.1:35630,DS-0dd30795-a994-494d-8069-d8c0a4972081,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2042108165-172.17.0.10-1595860753944:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45763,DS-af7be19e-e148-4347-b276-7f526fd1893e,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-18eb56e8-06a8-42e1-a41b-bda96e2745fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-a36fd6fb-0597-4398-a374-440a3215b687,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-03a6c64b-6f65-4f2e-9fad-b86dfe9f1291,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-3ce665e7-8b71-4c03-ab02-dedfd6eb17f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-db475728-dd19-4d79-a4f1-c92309d28dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45871,DS-a599e8f3-22b5-4e17-8ab0-149e329fbd17,DISK], DatanodeInfoWithStorage[127.0.0.1:35630,DS-0dd30795-a994-494d-8069-d8c0a4972081,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-497137846-172.17.0.10-1595860861843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42852,DS-ea5daa91-2e0e-4227-a8f6-61866aabbde4,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-03656402-2ad2-4681-bfdf-d59325209ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-19457e67-d1df-408d-85b5-232ffe0ee934,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-2797252a-1c5d-403d-aa69-61f1d26464c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-ae79eadd-b80e-40f2-8672-2e9ee3b549fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38745,DS-275373e4-8556-418c-9704-39964fd585af,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-c6498020-b711-41dd-a780-d8b9fcc362c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-7c7fd22d-f71b-455e-81d3-5b65808bcf30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-497137846-172.17.0.10-1595860861843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42852,DS-ea5daa91-2e0e-4227-a8f6-61866aabbde4,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-03656402-2ad2-4681-bfdf-d59325209ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-19457e67-d1df-408d-85b5-232ffe0ee934,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-2797252a-1c5d-403d-aa69-61f1d26464c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-ae79eadd-b80e-40f2-8672-2e9ee3b549fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38745,DS-275373e4-8556-418c-9704-39964fd585af,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-c6498020-b711-41dd-a780-d8b9fcc362c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-7c7fd22d-f71b-455e-81d3-5b65808bcf30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1590450958-172.17.0.10-1595861469515:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37134,DS-7a142100-517f-4582-bf0a-d8fc9d01e1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-26a6ba5f-62ea-4952-88c2-dfbb74379f75,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-46591f96-86e2-4649-a356-e213b7df7250,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-7f07f694-af75-424d-aaba-80f33591505f,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-ba4a7e3c-34d0-4bb8-b040-64ff4578f8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-eb3719bf-4e52-46f3-b48d-1fe6d63dbbce,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-65ce18c7-6754-40dd-9f90-04f2650ef0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37205,DS-f2f884c9-0199-4421-bb90-0ed2e5573a6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1590450958-172.17.0.10-1595861469515:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37134,DS-7a142100-517f-4582-bf0a-d8fc9d01e1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-26a6ba5f-62ea-4952-88c2-dfbb74379f75,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-46591f96-86e2-4649-a356-e213b7df7250,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-7f07f694-af75-424d-aaba-80f33591505f,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-ba4a7e3c-34d0-4bb8-b040-64ff4578f8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-eb3719bf-4e52-46f3-b48d-1fe6d63dbbce,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-65ce18c7-6754-40dd-9f90-04f2650ef0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37205,DS-f2f884c9-0199-4421-bb90-0ed2e5573a6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1592567846-172.17.0.10-1595861609325:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40971,DS-56a7a1dc-ead2-46d6-af43-36aa0175caf1,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-a4f19e4b-fbc6-403a-8e05-6e5b2e5ada33,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-99ec5730-68b4-4bc3-b215-3ec3f4c8eb33,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-46063b0b-d281-4124-af85-5c84cb4b459a,DISK], DatanodeInfoWithStorage[127.0.0.1:46428,DS-20b4555d-1c18-491c-b4c4-5cad413d94ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-61131127-ebf1-4490-9122-31c4e3661855,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-8ba4a7a2-1422-46ee-9f0d-fd7fde59a083,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-98049f1e-7749-4233-ae37-1d1013ee7b80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1592567846-172.17.0.10-1595861609325:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40971,DS-56a7a1dc-ead2-46d6-af43-36aa0175caf1,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-a4f19e4b-fbc6-403a-8e05-6e5b2e5ada33,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-99ec5730-68b4-4bc3-b215-3ec3f4c8eb33,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-46063b0b-d281-4124-af85-5c84cb4b459a,DISK], DatanodeInfoWithStorage[127.0.0.1:46428,DS-20b4555d-1c18-491c-b4c4-5cad413d94ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-61131127-ebf1-4490-9122-31c4e3661855,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-8ba4a7a2-1422-46ee-9f0d-fd7fde59a083,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-98049f1e-7749-4233-ae37-1d1013ee7b80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-879392279-172.17.0.10-1595861654643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45807,DS-77cace05-13f3-4ac3-bdb2-ddda7391abee,DISK], DatanodeInfoWithStorage[127.0.0.1:39024,DS-9ae824a3-9922-4c18-acb3-106d6ef24c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-a5cd80f3-d432-4dac-9a88-25aff4b58792,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-ddcefc04-5c02-4f5f-b5e5-c9845fd68c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37390,DS-90a21d44-6975-4787-8626-97a3fdc236e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-49af2908-121e-4857-99a3-81b28fbfdde6,DISK], DatanodeInfoWithStorage[127.0.0.1:41509,DS-7774dc3a-5eaa-454f-a0d1-b0690792203e,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-f751d534-3e0c-4d15-a08c-88accb63ed17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-879392279-172.17.0.10-1595861654643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45807,DS-77cace05-13f3-4ac3-bdb2-ddda7391abee,DISK], DatanodeInfoWithStorage[127.0.0.1:39024,DS-9ae824a3-9922-4c18-acb3-106d6ef24c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-a5cd80f3-d432-4dac-9a88-25aff4b58792,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-ddcefc04-5c02-4f5f-b5e5-c9845fd68c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37390,DS-90a21d44-6975-4787-8626-97a3fdc236e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-49af2908-121e-4857-99a3-81b28fbfdde6,DISK], DatanodeInfoWithStorage[127.0.0.1:41509,DS-7774dc3a-5eaa-454f-a0d1-b0690792203e,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-f751d534-3e0c-4d15-a08c-88accb63ed17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-105599363-172.17.0.10-1595861763959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42123,DS-6a5759a9-dd3a-4fdc-aefa-dcb08c427da2,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-b9fd36c1-e503-4a25-9733-a33e4ef56bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39418,DS-efe9ec2b-2807-4029-b96c-d829da607cda,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-5ca9cb1e-2cf9-49f5-95be-616a95b9b9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-e71b3d0d-c17f-4e47-a3b7-db5df07f6569,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-1dc541bc-914d-4fb7-b452-7cefb7767793,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-365c848e-71e0-4588-b86e-84b51695928e,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-4c2664c3-40db-432e-9ee5-ad570501b025,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-105599363-172.17.0.10-1595861763959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42123,DS-6a5759a9-dd3a-4fdc-aefa-dcb08c427da2,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-b9fd36c1-e503-4a25-9733-a33e4ef56bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39418,DS-efe9ec2b-2807-4029-b96c-d829da607cda,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-5ca9cb1e-2cf9-49f5-95be-616a95b9b9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-e71b3d0d-c17f-4e47-a3b7-db5df07f6569,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-1dc541bc-914d-4fb7-b452-7cefb7767793,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-365c848e-71e0-4588-b86e-84b51695928e,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-4c2664c3-40db-432e-9ee5-ad570501b025,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-373286808-172.17.0.10-1595862083231:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34582,DS-72785f7e-3eed-4a2f-8790-90b547da68b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-346cbb36-14e8-4f61-9e6a-3dd6b1a174f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35297,DS-2983d629-6893-4442-b742-62c92adee0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-92be0721-cc03-43c7-bb5b-a2e257d2357a,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-36c5f1eb-8ef0-4cc6-8beb-332350440aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-24940bb4-2d66-4bf1-b963-630bbf428f52,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-85c7df95-bd1d-46e3-a9fb-71e182f2828d,DISK], DatanodeInfoWithStorage[127.0.0.1:43448,DS-6054ea61-c106-4abb-a322-fb7638fd0784,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-373286808-172.17.0.10-1595862083231:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34582,DS-72785f7e-3eed-4a2f-8790-90b547da68b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-346cbb36-14e8-4f61-9e6a-3dd6b1a174f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35297,DS-2983d629-6893-4442-b742-62c92adee0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-92be0721-cc03-43c7-bb5b-a2e257d2357a,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-36c5f1eb-8ef0-4cc6-8beb-332350440aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-24940bb4-2d66-4bf1-b963-630bbf428f52,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-85c7df95-bd1d-46e3-a9fb-71e182f2828d,DISK], DatanodeInfoWithStorage[127.0.0.1:43448,DS-6054ea61-c106-4abb-a322-fb7638fd0784,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-986445571-172.17.0.10-1595862424551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39256,DS-1368dcf6-ee86-49fb-b5ec-4e20601aa240,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-2bdb1adb-2ebc-490b-889d-08f0381d017d,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-d496868b-ed59-4455-b0d7-5f21ff03c292,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-58e41aab-d107-496f-97b3-60897b35ed48,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-adb41c17-2017-4c2f-ad13-4f56623635fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36156,DS-c8623eaf-3757-45c8-b15b-78c35c350d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-9f33de65-2efc-483b-b951-8e8247dcf92c,DISK], DatanodeInfoWithStorage[127.0.0.1:34128,DS-002ff31f-591c-4f67-8c8c-7bfb62468978,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-986445571-172.17.0.10-1595862424551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39256,DS-1368dcf6-ee86-49fb-b5ec-4e20601aa240,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-2bdb1adb-2ebc-490b-889d-08f0381d017d,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-d496868b-ed59-4455-b0d7-5f21ff03c292,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-58e41aab-d107-496f-97b3-60897b35ed48,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-adb41c17-2017-4c2f-ad13-4f56623635fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36156,DS-c8623eaf-3757-45c8-b15b-78c35c350d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-9f33de65-2efc-483b-b951-8e8247dcf92c,DISK], DatanodeInfoWithStorage[127.0.0.1:34128,DS-002ff31f-591c-4f67-8c8c-7bfb62468978,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1043990246-172.17.0.10-1595862461559:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33192,DS-36cc39d1-fd23-4ffe-a131-7876cedbb4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-cc7ddea0-0b94-4fbf-b781-9ca25a83b448,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-6ddc1465-c140-4caa-8c7f-90d9ed1a9dde,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-37002de2-e4e3-42d9-933e-ac18e8da3e80,DISK], DatanodeInfoWithStorage[127.0.0.1:38189,DS-ffc78e8c-e7d4-41a2-985f-84da30ee51d0,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-cfe82188-e129-498d-977c-84941eadc936,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-31a52796-d211-4ec9-9a80-8e10d8ac0efd,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-f9220010-e745-4b9d-8523-0240b6834c2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1043990246-172.17.0.10-1595862461559:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33192,DS-36cc39d1-fd23-4ffe-a131-7876cedbb4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-cc7ddea0-0b94-4fbf-b781-9ca25a83b448,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-6ddc1465-c140-4caa-8c7f-90d9ed1a9dde,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-37002de2-e4e3-42d9-933e-ac18e8da3e80,DISK], DatanodeInfoWithStorage[127.0.0.1:38189,DS-ffc78e8c-e7d4-41a2-985f-84da30ee51d0,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-cfe82188-e129-498d-977c-84941eadc936,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-31a52796-d211-4ec9-9a80-8e10d8ac0efd,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-f9220010-e745-4b9d-8523-0240b6834c2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2125653136-172.17.0.10-1595862633840:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34975,DS-e5d36b16-a13b-4419-a5d6-5915d23e1423,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-5a683d5a-be57-437b-aaac-49429fe6195d,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-727cb5a1-4041-4d1b-8717-b065aa2dee7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41925,DS-becca3e3-12f9-470d-9944-51d3c5a0f3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-8feec974-80f5-4367-b81c-90a952b15376,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-8526bdbc-b7d8-4c5e-989e-c501e577e445,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-b339e8bc-6183-45f8-b787-2637f88755e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39250,DS-2ffbe08f-7199-4fe3-99d4-e1feded73d28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2125653136-172.17.0.10-1595862633840:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34975,DS-e5d36b16-a13b-4419-a5d6-5915d23e1423,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-5a683d5a-be57-437b-aaac-49429fe6195d,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-727cb5a1-4041-4d1b-8717-b065aa2dee7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41925,DS-becca3e3-12f9-470d-9944-51d3c5a0f3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-8feec974-80f5-4367-b81c-90a952b15376,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-8526bdbc-b7d8-4c5e-989e-c501e577e445,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-b339e8bc-6183-45f8-b787-2637f88755e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39250,DS-2ffbe08f-7199-4fe3-99d4-e1feded73d28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-273499358-172.17.0.10-1595863029748:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36292,DS-66ea8212-06f6-409e-b627-57c26b78665f,DISK], DatanodeInfoWithStorage[127.0.0.1:44566,DS-58c54679-4ea6-4ac4-a54e-9a2fa2f3bd96,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-d58cf90f-d434-4648-a1a6-ff5a8fca877d,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-cc416125-0eed-4770-b385-1e291511cc98,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-4e8c4efd-d710-45a2-a4a2-342cb11a6a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-372fce2f-d8f6-4793-9551-1b9619e25f05,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-830edde0-79ac-4e76-b6ab-a54c2bc4a0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-c8c1fddb-1d9b-4960-ba6e-3888693f7dfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-273499358-172.17.0.10-1595863029748:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36292,DS-66ea8212-06f6-409e-b627-57c26b78665f,DISK], DatanodeInfoWithStorage[127.0.0.1:44566,DS-58c54679-4ea6-4ac4-a54e-9a2fa2f3bd96,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-d58cf90f-d434-4648-a1a6-ff5a8fca877d,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-cc416125-0eed-4770-b385-1e291511cc98,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-4e8c4efd-d710-45a2-a4a2-342cb11a6a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-372fce2f-d8f6-4793-9551-1b9619e25f05,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-830edde0-79ac-4e76-b6ab-a54c2bc4a0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-c8c1fddb-1d9b-4960-ba6e-3888693f7dfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1758069075-172.17.0.10-1595863370947:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42665,DS-3d63df43-62a9-43d5-85e1-c13492edd71c,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-4b3bfd1f-5ba3-497e-ba38-4334ba2fe9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-9becbde0-32d6-4ccf-9363-b83e7757d4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-e14581d0-0110-400e-8660-3d7e1c886050,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-d502bd8a-5ae8-4a45-925e-b250bf6661ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-a220d50b-57a9-43e7-b11c-6a3f25d4d9df,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-f7427be6-768a-4cfd-a433-325c65d68606,DISK], DatanodeInfoWithStorage[127.0.0.1:33612,DS-bc3ff741-8f6c-4c8f-91fe-adc6119d974b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1758069075-172.17.0.10-1595863370947:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42665,DS-3d63df43-62a9-43d5-85e1-c13492edd71c,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-4b3bfd1f-5ba3-497e-ba38-4334ba2fe9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-9becbde0-32d6-4ccf-9363-b83e7757d4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-e14581d0-0110-400e-8660-3d7e1c886050,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-d502bd8a-5ae8-4a45-925e-b250bf6661ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-a220d50b-57a9-43e7-b11c-6a3f25d4d9df,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-f7427be6-768a-4cfd-a433-325c65d68606,DISK], DatanodeInfoWithStorage[127.0.0.1:33612,DS-bc3ff741-8f6c-4c8f-91fe-adc6119d974b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1704876117-172.17.0.10-1595863442700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42435,DS-3e779648-5ab0-4b4c-b192-fce8ec8dd1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-261fa23a-a20d-42ee-9955-dc7f2688a4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-1e5ae1a8-d381-4aea-9cca-1f4d1a5ecc37,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-adcbf7b2-ce83-47ef-8c9b-615c0a1b6dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-894fd77d-3932-4117-aff4-4f2738e4e88b,DISK], DatanodeInfoWithStorage[127.0.0.1:44954,DS-93665ff9-ed8c-4701-b1c7-43b41e58b416,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-c48379e6-7275-434f-b16e-25d80418b649,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-69d1c1c8-5795-4627-b97f-9b9fb542685d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1704876117-172.17.0.10-1595863442700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42435,DS-3e779648-5ab0-4b4c-b192-fce8ec8dd1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-261fa23a-a20d-42ee-9955-dc7f2688a4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-1e5ae1a8-d381-4aea-9cca-1f4d1a5ecc37,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-adcbf7b2-ce83-47ef-8c9b-615c0a1b6dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-894fd77d-3932-4117-aff4-4f2738e4e88b,DISK], DatanodeInfoWithStorage[127.0.0.1:44954,DS-93665ff9-ed8c-4701-b1c7-43b41e58b416,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-c48379e6-7275-434f-b16e-25d80418b649,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-69d1c1c8-5795-4627-b97f-9b9fb542685d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2056098447-172.17.0.10-1595863931179:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32775,DS-6c9ec2e4-f105-4045-b774-fb10b7e269c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-c6299d40-88f3-4204-94b2-6168f7e55f57,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-d0e6459f-865a-4a9a-b930-8d009b2d2561,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-bf464315-1135-4920-9604-dc73a1662243,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-236293f8-73ca-4f38-a110-6f339cb6e8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-01365e20-0283-4b80-8c05-10a82553d362,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-a1d7cc0f-c85e-4800-a02f-849cd3122a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-3992bd5a-47e1-4985-8f75-8d16bc3fc6a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2056098447-172.17.0.10-1595863931179:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32775,DS-6c9ec2e4-f105-4045-b774-fb10b7e269c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-c6299d40-88f3-4204-94b2-6168f7e55f57,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-d0e6459f-865a-4a9a-b930-8d009b2d2561,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-bf464315-1135-4920-9604-dc73a1662243,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-236293f8-73ca-4f38-a110-6f339cb6e8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-01365e20-0283-4b80-8c05-10a82553d362,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-a1d7cc0f-c85e-4800-a02f-849cd3122a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-3992bd5a-47e1-4985-8f75-8d16bc3fc6a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1078703456-172.17.0.10-1595864033748:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38092,DS-30ae8b39-f1f6-4c96-bff8-16a43166197f,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-0ba1527a-47c4-40da-a0bc-cc2f04e77864,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-d8d3ef51-7417-4adc-88c8-74534d16408f,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-5f6c3e83-9b29-4f8e-b8e3-fa5da7082687,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-eae8e548-33ea-47a6-8aa5-7b851d7778e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-0f941dd7-6b03-45fa-8403-53c6e1d27f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-2213562d-67f2-41fe-a4e1-c490acc9779d,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-124f0da9-e1fe-4396-b9b6-1d1e3c2b2a14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1078703456-172.17.0.10-1595864033748:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38092,DS-30ae8b39-f1f6-4c96-bff8-16a43166197f,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-0ba1527a-47c4-40da-a0bc-cc2f04e77864,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-d8d3ef51-7417-4adc-88c8-74534d16408f,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-5f6c3e83-9b29-4f8e-b8e3-fa5da7082687,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-eae8e548-33ea-47a6-8aa5-7b851d7778e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-0f941dd7-6b03-45fa-8403-53c6e1d27f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-2213562d-67f2-41fe-a4e1-c490acc9779d,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-124f0da9-e1fe-4396-b9b6-1d1e3c2b2a14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-901368128-172.17.0.10-1595864269668:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45120,DS-508b1c17-e346-4ff7-b7df-a45edebe7fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-73614a72-6df4-46e5-b5a7-9028838a2efc,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-ec8fc806-25a0-4437-bbfc-37fc14817bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-4b4cac10-a463-4174-803a-e8259ce575f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-d5598717-160f-4105-80ea-b4187c50423c,DISK], DatanodeInfoWithStorage[127.0.0.1:45719,DS-536a03ad-af9c-4e90-b8e4-4248a54cb4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34646,DS-d220754a-4be1-4c6a-ab32-179f931cb859,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-253adc93-e1e6-4d91-ba06-6a3e86764a7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-901368128-172.17.0.10-1595864269668:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45120,DS-508b1c17-e346-4ff7-b7df-a45edebe7fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-73614a72-6df4-46e5-b5a7-9028838a2efc,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-ec8fc806-25a0-4437-bbfc-37fc14817bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-4b4cac10-a463-4174-803a-e8259ce575f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-d5598717-160f-4105-80ea-b4187c50423c,DISK], DatanodeInfoWithStorage[127.0.0.1:45719,DS-536a03ad-af9c-4e90-b8e4-4248a54cb4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34646,DS-d220754a-4be1-4c6a-ab32-179f931cb859,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-253adc93-e1e6-4d91-ba06-6a3e86764a7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1340467888-172.17.0.10-1595864309150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35920,DS-5e8c64ec-c707-4b49-b114-2f35597c0e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45978,DS-8516da3e-e531-4140-8b32-dfdb5b50c5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44639,DS-e7176372-aff3-4c07-a8ba-011f8f4f5cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-a8d21516-ff36-4823-9049-50861a5257f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-8ff646ed-18ba-44b9-bdf5-08b2ad0981c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-04732ced-522c-49bb-99b1-576d83a30530,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-280a8a03-b3fc-47d9-9f31-414ac3ad6aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-a198918c-1a8f-4f9f-9c38-4897e53a1831,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1340467888-172.17.0.10-1595864309150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35920,DS-5e8c64ec-c707-4b49-b114-2f35597c0e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45978,DS-8516da3e-e531-4140-8b32-dfdb5b50c5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44639,DS-e7176372-aff3-4c07-a8ba-011f8f4f5cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-a8d21516-ff36-4823-9049-50861a5257f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-8ff646ed-18ba-44b9-bdf5-08b2ad0981c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-04732ced-522c-49bb-99b1-576d83a30530,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-280a8a03-b3fc-47d9-9f31-414ac3ad6aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-a198918c-1a8f-4f9f-9c38-4897e53a1831,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1621207019-172.17.0.10-1595864661880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35100,DS-7aa41d26-049c-49c8-9eee-d88207616727,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-a12bba3c-6baa-46f9-98bd-8edda2c68803,DISK], DatanodeInfoWithStorage[127.0.0.1:42007,DS-9c24443b-e37a-40c6-b3ad-d66c2ced5e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39021,DS-b04db9ba-fcd4-45f6-ac51-1cf93002706b,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-5509d945-d113-4e88-8fea-1e56425c88e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-9a9ad6e5-f77a-4928-8718-f5a1c4b11cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-9a7deada-4408-4314-9a6f-8b3b1b184b09,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-a38aca50-bf6f-41e7-92d7-d03aa07411d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1621207019-172.17.0.10-1595864661880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35100,DS-7aa41d26-049c-49c8-9eee-d88207616727,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-a12bba3c-6baa-46f9-98bd-8edda2c68803,DISK], DatanodeInfoWithStorage[127.0.0.1:42007,DS-9c24443b-e37a-40c6-b3ad-d66c2ced5e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39021,DS-b04db9ba-fcd4-45f6-ac51-1cf93002706b,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-5509d945-d113-4e88-8fea-1e56425c88e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-9a9ad6e5-f77a-4928-8718-f5a1c4b11cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-9a7deada-4408-4314-9a6f-8b3b1b184b09,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-a38aca50-bf6f-41e7-92d7-d03aa07411d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-109186384-172.17.0.10-1595864806917:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46622,DS-9a0a0fe8-1ac5-4f41-9c2f-b5a1915a4110,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-08422d8d-b1cf-45b6-ae3f-8ac7e47b3479,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-505b0aef-33c4-4121-b3c3-72a2903b7632,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-fbb9f7d8-40d1-44c1-8456-588c76bb2a36,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-f81ec318-2be0-4d57-980d-bb050c70ae23,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-90721a94-7d08-431f-b0e0-937aad3385d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-cae0c888-1d82-4033-b0d4-1fd10092c00a,DISK], DatanodeInfoWithStorage[127.0.0.1:36303,DS-fad25bcc-0224-4ed4-9310-916de4f34e7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-109186384-172.17.0.10-1595864806917:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46622,DS-9a0a0fe8-1ac5-4f41-9c2f-b5a1915a4110,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-08422d8d-b1cf-45b6-ae3f-8ac7e47b3479,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-505b0aef-33c4-4121-b3c3-72a2903b7632,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-fbb9f7d8-40d1-44c1-8456-588c76bb2a36,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-f81ec318-2be0-4d57-980d-bb050c70ae23,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-90721a94-7d08-431f-b0e0-937aad3385d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-cae0c888-1d82-4033-b0d4-1fd10092c00a,DISK], DatanodeInfoWithStorage[127.0.0.1:36303,DS-fad25bcc-0224-4ed4-9310-916de4f34e7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1104560892-172.17.0.10-1595864946880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41869,DS-36e50627-3e61-4178-9f25-d9b8623dd1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-56bf5728-3c8b-4a12-bf72-307eb31f1da7,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-30e417ac-cd91-4d1c-b2ca-54f0d8d2e999,DISK], DatanodeInfoWithStorage[127.0.0.1:35291,DS-dbbd2bfc-e9ee-451a-a233-6ac2e9437dda,DISK], DatanodeInfoWithStorage[127.0.0.1:44291,DS-589acfed-3f9c-4e55-b6ca-957edab487c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-6e35c81f-859a-49e1-b4c4-59a86a17d93f,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-cb0dd35d-275b-4e2f-9b02-7000c43e7bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-b1c9519a-328e-414c-9013-7beb4592ad27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1104560892-172.17.0.10-1595864946880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41869,DS-36e50627-3e61-4178-9f25-d9b8623dd1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-56bf5728-3c8b-4a12-bf72-307eb31f1da7,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-30e417ac-cd91-4d1c-b2ca-54f0d8d2e999,DISK], DatanodeInfoWithStorage[127.0.0.1:35291,DS-dbbd2bfc-e9ee-451a-a233-6ac2e9437dda,DISK], DatanodeInfoWithStorage[127.0.0.1:44291,DS-589acfed-3f9c-4e55-b6ca-957edab487c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-6e35c81f-859a-49e1-b4c4-59a86a17d93f,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-cb0dd35d-275b-4e2f-9b02-7000c43e7bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-b1c9519a-328e-414c-9013-7beb4592ad27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5373
