reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1847358251-172.17.0.8-1595997876290:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38941,DS-40447473-10a3-4040-a8e6-20f08708c637,DISK], DatanodeInfoWithStorage[127.0.0.1:38558,DS-7ae9c34b-24c1-498d-ad76-7f5577db99d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-ef7fe365-ccdc-4f47-a5b8-175b0fa1e02e,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-4a63d806-ba78-469e-81db-7d4dd93fe586,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-22cf4d1a-dd19-452d-a35c-6138adddf479,DISK], DatanodeInfoWithStorage[127.0.0.1:34564,DS-094b97c4-2f9e-4388-a4e3-e3c1763b5eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-344f0c73-e52e-453e-b4cc-cbab92ea8291,DISK], DatanodeInfoWithStorage[127.0.0.1:39006,DS-59b61c34-2447-4f94-a4a2-26b168961928,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1847358251-172.17.0.8-1595997876290:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38941,DS-40447473-10a3-4040-a8e6-20f08708c637,DISK], DatanodeInfoWithStorage[127.0.0.1:38558,DS-7ae9c34b-24c1-498d-ad76-7f5577db99d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-ef7fe365-ccdc-4f47-a5b8-175b0fa1e02e,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-4a63d806-ba78-469e-81db-7d4dd93fe586,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-22cf4d1a-dd19-452d-a35c-6138adddf479,DISK], DatanodeInfoWithStorage[127.0.0.1:34564,DS-094b97c4-2f9e-4388-a4e3-e3c1763b5eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-344f0c73-e52e-453e-b4cc-cbab92ea8291,DISK], DatanodeInfoWithStorage[127.0.0.1:39006,DS-59b61c34-2447-4f94-a4a2-26b168961928,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1579869950-172.17.0.8-1595998533050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43267,DS-3864e686-818a-4152-88f6-db5671e222ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-11f9b03d-59c8-4036-9b3d-cec9ac411d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45065,DS-3ac3b0db-207d-4508-862c-a11110b0705e,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-02e60679-7743-4d34-89f7-6f41dc79aea7,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-aad50a64-2ed3-470f-a821-101183553d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-3b263002-25a2-4d80-8410-a2259ad35d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-85be4c55-ffb8-497c-8c99-8514191ef920,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-500ef4e4-bc22-4dc9-ae93-dc21753adb0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1579869950-172.17.0.8-1595998533050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43267,DS-3864e686-818a-4152-88f6-db5671e222ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-11f9b03d-59c8-4036-9b3d-cec9ac411d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45065,DS-3ac3b0db-207d-4508-862c-a11110b0705e,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-02e60679-7743-4d34-89f7-6f41dc79aea7,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-aad50a64-2ed3-470f-a821-101183553d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-3b263002-25a2-4d80-8410-a2259ad35d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-85be4c55-ffb8-497c-8c99-8514191ef920,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-500ef4e4-bc22-4dc9-ae93-dc21753adb0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1229912179-172.17.0.8-1595999188477:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36253,DS-01668e77-3fd8-4e48-a7ad-4eba11a69873,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-b6f4d4f3-2935-444c-89db-f401e0f40ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-4ce3d02c-639e-4956-8ae8-1913dcb3176d,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-69f0c915-1cd4-494e-996c-b6387b67d6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34365,DS-85ae8808-7b81-4d18-9d39-05fb9f2b1cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-b61f081e-2be5-4188-b018-7426a8f633a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-40c8c24c-7945-4842-9d71-e5b33c2a4fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-2b01322a-243b-43ce-a088-4d9c9c3cea0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1229912179-172.17.0.8-1595999188477:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36253,DS-01668e77-3fd8-4e48-a7ad-4eba11a69873,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-b6f4d4f3-2935-444c-89db-f401e0f40ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-4ce3d02c-639e-4956-8ae8-1913dcb3176d,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-69f0c915-1cd4-494e-996c-b6387b67d6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34365,DS-85ae8808-7b81-4d18-9d39-05fb9f2b1cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-b61f081e-2be5-4188-b018-7426a8f633a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-40c8c24c-7945-4842-9d71-e5b33c2a4fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-2b01322a-243b-43ce-a088-4d9c9c3cea0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1835378950-172.17.0.8-1595999476399:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36645,DS-21f7e93b-fa49-4353-8960-46c2507a947d,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-f1d66abf-4e9f-4d7a-82a5-baa8a6c78eef,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-2802ffcd-3ad9-4af9-954c-24308269a7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-61fa2280-e0e5-4495-9501-c98508ecb8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-27fc60ae-1b41-4799-97b6-6cb38725d4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-03e7caca-7cc2-4032-a835-68e134928ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-19f5b657-1e31-473e-ba0d-9033b0282461,DISK], DatanodeInfoWithStorage[127.0.0.1:38126,DS-548440c0-dda8-4bae-8908-b7b06eb525ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1835378950-172.17.0.8-1595999476399:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36645,DS-21f7e93b-fa49-4353-8960-46c2507a947d,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-f1d66abf-4e9f-4d7a-82a5-baa8a6c78eef,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-2802ffcd-3ad9-4af9-954c-24308269a7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-61fa2280-e0e5-4495-9501-c98508ecb8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-27fc60ae-1b41-4799-97b6-6cb38725d4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-03e7caca-7cc2-4032-a835-68e134928ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-19f5b657-1e31-473e-ba0d-9033b0282461,DISK], DatanodeInfoWithStorage[127.0.0.1:38126,DS-548440c0-dda8-4bae-8908-b7b06eb525ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-621833348-172.17.0.8-1595999768623:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38899,DS-29415817-07dc-4104-9dff-f45c61f9f7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-1680e52a-9e0c-47a7-ae15-d4557602c826,DISK], DatanodeInfoWithStorage[127.0.0.1:45068,DS-bacee48a-3d0c-4b7c-91c6-2abc14650e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-2b19a940-36fd-46c8-ad62-7c621416480c,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-6e2ff7e3-d351-4b63-9ebf-51de9d720285,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-4bb91b60-6d6d-4ef6-b72c-edbc5cb34491,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-843ff8dc-1b91-42fa-96df-c4281a78b23e,DISK], DatanodeInfoWithStorage[127.0.0.1:40407,DS-4330867c-fe4a-49d4-aa4e-179bcdefab35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-621833348-172.17.0.8-1595999768623:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38899,DS-29415817-07dc-4104-9dff-f45c61f9f7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-1680e52a-9e0c-47a7-ae15-d4557602c826,DISK], DatanodeInfoWithStorage[127.0.0.1:45068,DS-bacee48a-3d0c-4b7c-91c6-2abc14650e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-2b19a940-36fd-46c8-ad62-7c621416480c,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-6e2ff7e3-d351-4b63-9ebf-51de9d720285,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-4bb91b60-6d6d-4ef6-b72c-edbc5cb34491,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-843ff8dc-1b91-42fa-96df-c4281a78b23e,DISK], DatanodeInfoWithStorage[127.0.0.1:40407,DS-4330867c-fe4a-49d4-aa4e-179bcdefab35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-544200055-172.17.0.8-1595999837739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43973,DS-7b82391f-bcd2-4c13-98df-165572b5ea8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-a9e0e904-5af3-4a70-9dec-5d505586dafc,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-34c8ca4f-cc94-416d-a037-a749b2fa88ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-ff02bc77-c224-4d86-afb7-4371964564d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-09c032ce-dd6d-4106-b733-353b14b747bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-82351b76-408a-47ae-b24d-8374269566d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-816decee-e366-494f-866a-e2bbb4443ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-e75972e2-168e-44e8-b9b3-bd575bb546ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-544200055-172.17.0.8-1595999837739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43973,DS-7b82391f-bcd2-4c13-98df-165572b5ea8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-a9e0e904-5af3-4a70-9dec-5d505586dafc,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-34c8ca4f-cc94-416d-a037-a749b2fa88ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-ff02bc77-c224-4d86-afb7-4371964564d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-09c032ce-dd6d-4106-b733-353b14b747bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-82351b76-408a-47ae-b24d-8374269566d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-816decee-e366-494f-866a-e2bbb4443ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-e75972e2-168e-44e8-b9b3-bd575bb546ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1673080291-172.17.0.8-1596000020627:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39707,DS-d5c6fe0a-84d9-4e64-bae0-51482a8c4b30,DISK], DatanodeInfoWithStorage[127.0.0.1:33742,DS-862ef933-1ed9-4b11-b8c3-0e92057082e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40836,DS-8b179212-db19-4e59-82ae-c371711ed304,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-50bc708c-4325-4af5-97fb-b065d8f5c2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-74eec0a6-e9b4-4ca2-9ab4-e4b37f05c663,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-b64a151e-f528-489b-8442-a7a5f3ca059b,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-7ffcfaeb-2433-484e-885b-ee54ba69cf16,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-55bac76b-61c2-4402-821b-8c4856478c7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1673080291-172.17.0.8-1596000020627:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39707,DS-d5c6fe0a-84d9-4e64-bae0-51482a8c4b30,DISK], DatanodeInfoWithStorage[127.0.0.1:33742,DS-862ef933-1ed9-4b11-b8c3-0e92057082e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40836,DS-8b179212-db19-4e59-82ae-c371711ed304,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-50bc708c-4325-4af5-97fb-b065d8f5c2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-74eec0a6-e9b4-4ca2-9ab4-e4b37f05c663,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-b64a151e-f528-489b-8442-a7a5f3ca059b,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-7ffcfaeb-2433-484e-885b-ee54ba69cf16,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-55bac76b-61c2-4402-821b-8c4856478c7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1662150399-172.17.0.8-1596001007624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36116,DS-58f8116c-4e5c-4540-8ab4-afc0e950b846,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-5ae3310e-6aa4-4f51-ae35-cd1a6c9dac9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-34ec9687-3ebe-44f0-9c29-d562c95726d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-795e6092-18d2-4e01-a7a2-2d3a0b250492,DISK], DatanodeInfoWithStorage[127.0.0.1:38012,DS-17e6ff82-455c-41a2-9859-4bd40e477c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42610,DS-b6be78f6-bda6-4669-a403-43585e3c0a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:32780,DS-4fb71cf8-486a-4992-b7b9-48875e82e1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34199,DS-3e1b2289-200f-4148-9811-97f61f2d5862,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1662150399-172.17.0.8-1596001007624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36116,DS-58f8116c-4e5c-4540-8ab4-afc0e950b846,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-5ae3310e-6aa4-4f51-ae35-cd1a6c9dac9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-34ec9687-3ebe-44f0-9c29-d562c95726d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-795e6092-18d2-4e01-a7a2-2d3a0b250492,DISK], DatanodeInfoWithStorage[127.0.0.1:38012,DS-17e6ff82-455c-41a2-9859-4bd40e477c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42610,DS-b6be78f6-bda6-4669-a403-43585e3c0a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:32780,DS-4fb71cf8-486a-4992-b7b9-48875e82e1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34199,DS-3e1b2289-200f-4148-9811-97f61f2d5862,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1451394423-172.17.0.8-1596001286342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36911,DS-371da9b4-b3a8-4393-aca8-ddd1a97c81dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-1f926aa5-22c3-4012-8710-4ab8494842b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-c9c78db0-b554-4d2f-a9da-7af6910017a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-00b05e8e-b46e-45a2-8331-74cc6b671e85,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-ab28433b-b0ea-4759-8682-68c2bffaf578,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-2e6f7928-9c8b-4b71-b8c4-ee6f87797d87,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-36c74049-dd0a-4697-873c-5661be4fc061,DISK], DatanodeInfoWithStorage[127.0.0.1:44906,DS-489e3464-4067-445b-9bca-3feb81c42dff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1451394423-172.17.0.8-1596001286342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36911,DS-371da9b4-b3a8-4393-aca8-ddd1a97c81dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-1f926aa5-22c3-4012-8710-4ab8494842b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-c9c78db0-b554-4d2f-a9da-7af6910017a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-00b05e8e-b46e-45a2-8331-74cc6b671e85,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-ab28433b-b0ea-4759-8682-68c2bffaf578,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-2e6f7928-9c8b-4b71-b8c4-ee6f87797d87,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-36c74049-dd0a-4697-873c-5661be4fc061,DISK], DatanodeInfoWithStorage[127.0.0.1:44906,DS-489e3464-4067-445b-9bca-3feb81c42dff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1880939893-172.17.0.8-1596001498713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40976,DS-13bf3e55-a823-46bd-935b-2a05ce789582,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-ce083d69-ae6e-4d03-991c-3b08ef2e4d96,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-04008dca-4d6f-49ed-8fa8-e87d18b1be3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-90c20394-ed10-48ee-92f0-806f663f0502,DISK], DatanodeInfoWithStorage[127.0.0.1:43716,DS-4e9fe3d6-82c1-4c25-802c-41d3c8ecbbd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39474,DS-5d9256ba-3b51-46d5-90c5-82128cd680ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35505,DS-319e96b0-eb7a-4e63-a33d-d841c19ea51d,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-a181629a-f30e-4b59-b0bc-77944af91ea5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1880939893-172.17.0.8-1596001498713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40976,DS-13bf3e55-a823-46bd-935b-2a05ce789582,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-ce083d69-ae6e-4d03-991c-3b08ef2e4d96,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-04008dca-4d6f-49ed-8fa8-e87d18b1be3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-90c20394-ed10-48ee-92f0-806f663f0502,DISK], DatanodeInfoWithStorage[127.0.0.1:43716,DS-4e9fe3d6-82c1-4c25-802c-41d3c8ecbbd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39474,DS-5d9256ba-3b51-46d5-90c5-82128cd680ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35505,DS-319e96b0-eb7a-4e63-a33d-d841c19ea51d,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-a181629a-f30e-4b59-b0bc-77944af91ea5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1791623701-172.17.0.8-1596001683814:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38046,DS-9e495a43-92cf-46b7-acc2-048d93cc0bad,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-dd4cc0d0-f9eb-4b73-94b1-29476fe4a37e,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-1314ead2-dab5-45bd-a9d6-724797445c39,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-2980888d-001a-4cdd-b42d-c9420d6803a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-0e10d0a3-aad9-44dc-bf13-6dd4e74c675d,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-c84330c5-219b-4338-8ded-52efbbc43119,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-017b74e7-05f4-47fe-8e70-36e5ba305e32,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-c6a1cc12-6db3-4b1e-a266-da506de3f287,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1791623701-172.17.0.8-1596001683814:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38046,DS-9e495a43-92cf-46b7-acc2-048d93cc0bad,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-dd4cc0d0-f9eb-4b73-94b1-29476fe4a37e,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-1314ead2-dab5-45bd-a9d6-724797445c39,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-2980888d-001a-4cdd-b42d-c9420d6803a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-0e10d0a3-aad9-44dc-bf13-6dd4e74c675d,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-c84330c5-219b-4338-8ded-52efbbc43119,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-017b74e7-05f4-47fe-8e70-36e5ba305e32,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-c6a1cc12-6db3-4b1e-a266-da506de3f287,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-828571850-172.17.0.8-1596001783181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43083,DS-cd8f9652-8ed0-4879-a771-7a7297eef11d,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-56f88e4e-bf5e-43c4-b88d-83d0aa3d8535,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-1179b909-059d-4df2-9095-2dccaa1f64fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-eba56223-598b-49ef-b50f-93969881985d,DISK], DatanodeInfoWithStorage[127.0.0.1:34786,DS-67f3c8fb-088f-41ce-9a22-b93974a01c87,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-f6be5135-4505-4564-86ba-56ec3f060331,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-b61e2d58-fe84-4d91-b255-fe8a32c192fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-a1e116d0-dc9b-407a-aec8-f5405ed57113,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-828571850-172.17.0.8-1596001783181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43083,DS-cd8f9652-8ed0-4879-a771-7a7297eef11d,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-56f88e4e-bf5e-43c4-b88d-83d0aa3d8535,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-1179b909-059d-4df2-9095-2dccaa1f64fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-eba56223-598b-49ef-b50f-93969881985d,DISK], DatanodeInfoWithStorage[127.0.0.1:34786,DS-67f3c8fb-088f-41ce-9a22-b93974a01c87,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-f6be5135-4505-4564-86ba-56ec3f060331,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-b61e2d58-fe84-4d91-b255-fe8a32c192fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-a1e116d0-dc9b-407a-aec8-f5405ed57113,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5406
