reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1654179952-172.17.0.11-1595576891717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32970,DS-204d544e-fe30-4e5a-9260-72be00d51deb,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-ea3d2660-55d3-478c-ba0d-99865fec52a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-bc3cd2ec-8425-41b7-9c2f-a617216ac060,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-92b06171-e928-4f49-a456-d6a60bd4297b,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-eb936d6a-11f9-4280-bbaa-681c846ed91f,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-c0233e9f-a78c-4813-ae33-da18790772c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44674,DS-a224812a-4f78-47bd-bc4c-f37dd650b50c,DISK], DatanodeInfoWithStorage[127.0.0.1:35797,DS-0b25cb4c-9e82-4202-aafd-b620423f6fd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1654179952-172.17.0.11-1595576891717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32970,DS-204d544e-fe30-4e5a-9260-72be00d51deb,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-ea3d2660-55d3-478c-ba0d-99865fec52a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-bc3cd2ec-8425-41b7-9c2f-a617216ac060,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-92b06171-e928-4f49-a456-d6a60bd4297b,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-eb936d6a-11f9-4280-bbaa-681c846ed91f,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-c0233e9f-a78c-4813-ae33-da18790772c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44674,DS-a224812a-4f78-47bd-bc4c-f37dd650b50c,DISK], DatanodeInfoWithStorage[127.0.0.1:35797,DS-0b25cb4c-9e82-4202-aafd-b620423f6fd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1705200863-172.17.0.11-1595577604248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39254,DS-2dff095e-8849-44d1-a4bc-25986660cac4,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-e168266f-9d00-4574-82d4-5b91bd947b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44195,DS-edd0505f-995d-4265-a337-300a7af47183,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-068d9eb1-ca1f-482b-a8bc-ba750a2161ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-08cacce2-4da6-4321-b789-22ac51a7b29f,DISK], DatanodeInfoWithStorage[127.0.0.1:34305,DS-b8d4f8a5-0306-431d-bc73-eeefa1c7e75b,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-b4db1c1d-e053-40e7-a932-d3302d407202,DISK], DatanodeInfoWithStorage[127.0.0.1:45471,DS-40257561-5a4c-47ba-8d92-3a25d79b798f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1705200863-172.17.0.11-1595577604248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39254,DS-2dff095e-8849-44d1-a4bc-25986660cac4,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-e168266f-9d00-4574-82d4-5b91bd947b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44195,DS-edd0505f-995d-4265-a337-300a7af47183,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-068d9eb1-ca1f-482b-a8bc-ba750a2161ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-08cacce2-4da6-4321-b789-22ac51a7b29f,DISK], DatanodeInfoWithStorage[127.0.0.1:34305,DS-b8d4f8a5-0306-431d-bc73-eeefa1c7e75b,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-b4db1c1d-e053-40e7-a932-d3302d407202,DISK], DatanodeInfoWithStorage[127.0.0.1:45471,DS-40257561-5a4c-47ba-8d92-3a25d79b798f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-398203004-172.17.0.11-1595577775359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39108,DS-13531973-bbdb-48ca-915d-b8f7ee642319,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-ecc60fd8-4ab8-4174-87c5-e3aee01b97d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-a79f3544-6672-474d-8aaa-8a3bf33f13de,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-28a6f2ee-1e9e-4490-b595-3f04b5a95bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-242e41eb-4cd9-4fc5-9bfd-52cfe1608018,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-36d98031-ec07-49c1-af9d-c614dfbb44e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-58b965be-166a-48f8-8f51-7b2a8f26117a,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-f8661be0-e069-4ce4-bab4-fe4388a48e38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-398203004-172.17.0.11-1595577775359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39108,DS-13531973-bbdb-48ca-915d-b8f7ee642319,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-ecc60fd8-4ab8-4174-87c5-e3aee01b97d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-a79f3544-6672-474d-8aaa-8a3bf33f13de,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-28a6f2ee-1e9e-4490-b595-3f04b5a95bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-242e41eb-4cd9-4fc5-9bfd-52cfe1608018,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-36d98031-ec07-49c1-af9d-c614dfbb44e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-58b965be-166a-48f8-8f51-7b2a8f26117a,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-f8661be0-e069-4ce4-bab4-fe4388a48e38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1138511354-172.17.0.11-1595577851687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38227,DS-affdf285-884a-4aaf-a68d-6c032b47b0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35919,DS-3c5b4595-e3aa-4e26-a4d0-d5b9ae7bba9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-8ccb90fa-8383-4e58-bafe-25f29a11ff23,DISK], DatanodeInfoWithStorage[127.0.0.1:38041,DS-4c960135-47c6-4b6b-b153-f52d88119b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-c40ee15c-237a-4e7c-a19b-8607b6687417,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-2d7bc499-b409-4332-8a1a-7a8ac2ee1f60,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-911f6dd1-9015-4efe-85c6-5fad2db29944,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-0cf1bfc6-dfee-4e20-bb2b-e34cb52efc89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1138511354-172.17.0.11-1595577851687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38227,DS-affdf285-884a-4aaf-a68d-6c032b47b0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35919,DS-3c5b4595-e3aa-4e26-a4d0-d5b9ae7bba9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-8ccb90fa-8383-4e58-bafe-25f29a11ff23,DISK], DatanodeInfoWithStorage[127.0.0.1:38041,DS-4c960135-47c6-4b6b-b153-f52d88119b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-c40ee15c-237a-4e7c-a19b-8607b6687417,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-2d7bc499-b409-4332-8a1a-7a8ac2ee1f60,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-911f6dd1-9015-4efe-85c6-5fad2db29944,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-0cf1bfc6-dfee-4e20-bb2b-e34cb52efc89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-714126034-172.17.0.11-1595577988582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37557,DS-3a332846-1f23-4334-ac84-d47bf14d0d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-ae5180d8-378c-428b-95d0-6b12d20d4b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-ed38aa73-4205-4ca3-a70d-d099331be516,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-15821bb1-6c72-4f06-9fc3-ea10c21f4637,DISK], DatanodeInfoWithStorage[127.0.0.1:46787,DS-6474b05a-be75-422a-9372-ccf0ab00cf5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34118,DS-2d3be14e-e7e6-46e4-844f-0afd69fed2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-f37ebbcd-9b47-43f0-9151-515b14a178ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-8b191a2a-1167-41d7-820a-b664685d2144,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-714126034-172.17.0.11-1595577988582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37557,DS-3a332846-1f23-4334-ac84-d47bf14d0d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-ae5180d8-378c-428b-95d0-6b12d20d4b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-ed38aa73-4205-4ca3-a70d-d099331be516,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-15821bb1-6c72-4f06-9fc3-ea10c21f4637,DISK], DatanodeInfoWithStorage[127.0.0.1:46787,DS-6474b05a-be75-422a-9372-ccf0ab00cf5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34118,DS-2d3be14e-e7e6-46e4-844f-0afd69fed2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-f37ebbcd-9b47-43f0-9151-515b14a178ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-8b191a2a-1167-41d7-820a-b664685d2144,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1330645899-172.17.0.11-1595578158503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34778,DS-7657c748-59fb-4558-af98-2374e1d4a794,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-c9c22218-3fd8-4911-800b-67766918beec,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-5deb037c-90d8-4a17-b783-3f5f87bf1640,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-b605c294-6374-481f-8de3-e80031df1b79,DISK], DatanodeInfoWithStorage[127.0.0.1:44539,DS-a67ec087-f5eb-4b21-bd2d-38cd1b60642c,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-6e01106c-b37d-42ea-9ed8-8a68964710d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-7d9f4f80-35e9-4317-9c38-a2552297463f,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-e3bf970e-345f-4878-9e44-9a60ea272272,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1330645899-172.17.0.11-1595578158503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34778,DS-7657c748-59fb-4558-af98-2374e1d4a794,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-c9c22218-3fd8-4911-800b-67766918beec,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-5deb037c-90d8-4a17-b783-3f5f87bf1640,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-b605c294-6374-481f-8de3-e80031df1b79,DISK], DatanodeInfoWithStorage[127.0.0.1:44539,DS-a67ec087-f5eb-4b21-bd2d-38cd1b60642c,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-6e01106c-b37d-42ea-9ed8-8a68964710d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-7d9f4f80-35e9-4317-9c38-a2552297463f,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-e3bf970e-345f-4878-9e44-9a60ea272272,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-648340335-172.17.0.11-1595578697062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41060,DS-15862994-406a-41c6-aeed-bb0b7608a624,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-a7a448f7-01c6-4fad-b1e9-c7f788a43561,DISK], DatanodeInfoWithStorage[127.0.0.1:37411,DS-19c5828c-19da-455c-9210-d86e0b1779eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45952,DS-1741fa63-50f1-43a0-bcca-789830c23878,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-62d42757-eea1-45c6-81f6-0fe2f239f1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-a0ae2cda-a2f0-4ade-9e7c-f28fa842fdf2,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-99ef4974-e116-40f3-9be1-53607a230439,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-efc54c46-cac3-4ba4-88c9-f5ba58d0f525,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-648340335-172.17.0.11-1595578697062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41060,DS-15862994-406a-41c6-aeed-bb0b7608a624,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-a7a448f7-01c6-4fad-b1e9-c7f788a43561,DISK], DatanodeInfoWithStorage[127.0.0.1:37411,DS-19c5828c-19da-455c-9210-d86e0b1779eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45952,DS-1741fa63-50f1-43a0-bcca-789830c23878,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-62d42757-eea1-45c6-81f6-0fe2f239f1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-a0ae2cda-a2f0-4ade-9e7c-f28fa842fdf2,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-99ef4974-e116-40f3-9be1-53607a230439,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-efc54c46-cac3-4ba4-88c9-f5ba58d0f525,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1745446336-172.17.0.11-1595578769752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45221,DS-bacc1e92-4484-41e4-ad17-a4f5f42f50d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-278956f6-9b51-4378-878e-af04caebe6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45198,DS-a1fe77ce-0c57-4e21-a90b-f4ff9fdcaa8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-c15c9c62-f071-4752-b056-6022ecc34e85,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-3537b741-1dd4-46d1-a48f-2c84af2fe13c,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-45dc700c-e3b9-4d8c-ae2e-528c240d99c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-49367453-e5a1-432c-a7ef-bdbedd5d36f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-4ed774ff-9b3f-494e-b283-8f1c96198be2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1745446336-172.17.0.11-1595578769752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45221,DS-bacc1e92-4484-41e4-ad17-a4f5f42f50d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-278956f6-9b51-4378-878e-af04caebe6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45198,DS-a1fe77ce-0c57-4e21-a90b-f4ff9fdcaa8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-c15c9c62-f071-4752-b056-6022ecc34e85,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-3537b741-1dd4-46d1-a48f-2c84af2fe13c,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-45dc700c-e3b9-4d8c-ae2e-528c240d99c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-49367453-e5a1-432c-a7ef-bdbedd5d36f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-4ed774ff-9b3f-494e-b283-8f1c96198be2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1153371724-172.17.0.11-1595578971346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36698,DS-c28abd81-09f6-44c7-b9d2-1e58debed511,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-ee735d3c-4d38-464a-a9fe-f2b52e6b7ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-cb2e4662-b6af-40a2-96ac-d98fbeb260f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38580,DS-19cb8f90-c499-40bf-904d-77a8d161ca42,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-c2ba0b35-1e0a-4e8a-95c2-60d4f270b5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44654,DS-bdf6a840-9744-4daf-a698-58421af98fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-fdf5efff-4acb-448d-8e0a-274ead34b00d,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-aa59f218-89bb-4323-91e4-0cd4808d5ca7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1153371724-172.17.0.11-1595578971346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36698,DS-c28abd81-09f6-44c7-b9d2-1e58debed511,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-ee735d3c-4d38-464a-a9fe-f2b52e6b7ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-cb2e4662-b6af-40a2-96ac-d98fbeb260f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38580,DS-19cb8f90-c499-40bf-904d-77a8d161ca42,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-c2ba0b35-1e0a-4e8a-95c2-60d4f270b5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44654,DS-bdf6a840-9744-4daf-a698-58421af98fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-fdf5efff-4acb-448d-8e0a-274ead34b00d,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-aa59f218-89bb-4323-91e4-0cd4808d5ca7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-194965103-172.17.0.11-1595579438626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37346,DS-6312109c-6e8c-4b47-aa80-d87d3a094fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-b54a7f9f-47db-4f18-a171-99ab794cd08f,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-1a62209b-63a6-4662-8580-b8115cbda1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-9370b1cf-fb2e-49ea-9eea-727470e5f19d,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-20eeceb6-a864-48fe-b7fe-05fc03a84a42,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-8409295a-b2e7-4bcb-8f3a-47fa8343d00e,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-15fb6261-4cbc-4687-b158-c4a5e8476e59,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-208f5702-b391-40ca-b596-b35b0ffcea58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-194965103-172.17.0.11-1595579438626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37346,DS-6312109c-6e8c-4b47-aa80-d87d3a094fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-b54a7f9f-47db-4f18-a171-99ab794cd08f,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-1a62209b-63a6-4662-8580-b8115cbda1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-9370b1cf-fb2e-49ea-9eea-727470e5f19d,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-20eeceb6-a864-48fe-b7fe-05fc03a84a42,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-8409295a-b2e7-4bcb-8f3a-47fa8343d00e,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-15fb6261-4cbc-4687-b158-c4a5e8476e59,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-208f5702-b391-40ca-b596-b35b0ffcea58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1763459932-172.17.0.11-1595579723825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37339,DS-cc8db87e-6dc1-4b00-bc9e-dcf564aae7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-817a7966-5bcd-4d2c-a95c-e3966afa16be,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-193fcf3e-d9d9-4e9a-b109-3a7ea863a909,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-a8697135-c3f7-4d87-8d7d-2dde670accb9,DISK], DatanodeInfoWithStorage[127.0.0.1:35281,DS-da5c272e-53b7-4b61-8a4f-deeb0f60b4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35476,DS-708b2b12-f281-451b-9636-0043f7de164d,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-30083ef6-5e28-4d77-9908-ee1bfa9ab59c,DISK], DatanodeInfoWithStorage[127.0.0.1:42396,DS-7ce728a9-34ae-4d08-8718-29860d483e3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1763459932-172.17.0.11-1595579723825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37339,DS-cc8db87e-6dc1-4b00-bc9e-dcf564aae7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-817a7966-5bcd-4d2c-a95c-e3966afa16be,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-193fcf3e-d9d9-4e9a-b109-3a7ea863a909,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-a8697135-c3f7-4d87-8d7d-2dde670accb9,DISK], DatanodeInfoWithStorage[127.0.0.1:35281,DS-da5c272e-53b7-4b61-8a4f-deeb0f60b4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35476,DS-708b2b12-f281-451b-9636-0043f7de164d,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-30083ef6-5e28-4d77-9908-ee1bfa9ab59c,DISK], DatanodeInfoWithStorage[127.0.0.1:42396,DS-7ce728a9-34ae-4d08-8718-29860d483e3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-493455137-172.17.0.11-1595580244848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46289,DS-dca5386c-66e8-42ff-b9f9-b08c1816cf61,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-608a2790-fce3-4ba2-90e5-87ab3254ecb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-d7f8504c-7182-4cdb-8e84-6ce44f75318d,DISK], DatanodeInfoWithStorage[127.0.0.1:34216,DS-21234734-e6f4-43f3-b1ff-ca4705bec592,DISK], DatanodeInfoWithStorage[127.0.0.1:43110,DS-ebb7c801-8f7f-4edb-befe-40cf4f309c80,DISK], DatanodeInfoWithStorage[127.0.0.1:38227,DS-ec7a6ead-d711-478b-be49-aa62588e2afb,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-edfd72b0-fcc6-41eb-b68d-87b9eb9ad928,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-45d80998-bb1b-441e-9b70-d6cc7c945232,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-493455137-172.17.0.11-1595580244848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46289,DS-dca5386c-66e8-42ff-b9f9-b08c1816cf61,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-608a2790-fce3-4ba2-90e5-87ab3254ecb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-d7f8504c-7182-4cdb-8e84-6ce44f75318d,DISK], DatanodeInfoWithStorage[127.0.0.1:34216,DS-21234734-e6f4-43f3-b1ff-ca4705bec592,DISK], DatanodeInfoWithStorage[127.0.0.1:43110,DS-ebb7c801-8f7f-4edb-befe-40cf4f309c80,DISK], DatanodeInfoWithStorage[127.0.0.1:38227,DS-ec7a6ead-d711-478b-be49-aa62588e2afb,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-edfd72b0-fcc6-41eb-b68d-87b9eb9ad928,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-45d80998-bb1b-441e-9b70-d6cc7c945232,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-994392529-172.17.0.11-1595580762089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42820,DS-3e92b0d6-356a-4e74-a45f-8a40b0188059,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-4ecc22bb-ecbb-4da5-b6ac-a825a5a4bed1,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-bf6a8b9b-5cd5-4e26-8b16-283826cfbb20,DISK], DatanodeInfoWithStorage[127.0.0.1:43011,DS-afc2c0f0-9726-46a6-a1df-fa23db9027dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-1b4efe35-8090-45fa-8a88-283ad111f73a,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-5839e75e-a7d6-4010-95d4-691554f5fd99,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-e5ed2de3-83bc-49a0-8b46-408120b05f92,DISK], DatanodeInfoWithStorage[127.0.0.1:44186,DS-1e155ea1-8126-43db-b466-a9bc0fd60255,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-994392529-172.17.0.11-1595580762089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42820,DS-3e92b0d6-356a-4e74-a45f-8a40b0188059,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-4ecc22bb-ecbb-4da5-b6ac-a825a5a4bed1,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-bf6a8b9b-5cd5-4e26-8b16-283826cfbb20,DISK], DatanodeInfoWithStorage[127.0.0.1:43011,DS-afc2c0f0-9726-46a6-a1df-fa23db9027dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-1b4efe35-8090-45fa-8a88-283ad111f73a,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-5839e75e-a7d6-4010-95d4-691554f5fd99,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-e5ed2de3-83bc-49a0-8b46-408120b05f92,DISK], DatanodeInfoWithStorage[127.0.0.1:44186,DS-1e155ea1-8126-43db-b466-a9bc0fd60255,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1430977723-172.17.0.11-1595580943061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39697,DS-14031c90-6d4f-4cec-98f8-3b0750d06105,DISK], DatanodeInfoWithStorage[127.0.0.1:33757,DS-4cabf181-7d0f-44f5-b758-87912628f325,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-54c0004f-e845-4ab9-bffd-8a9cf78951d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-c0e25b32-c03c-4872-8382-273eb3a4f044,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-8a5b59e2-c067-478a-8888-eac56560a1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-4bad8124-b196-4e27-b752-bdc154306f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46501,DS-d76d27ae-53fc-405e-9f1b-8bf554114bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-8796fcde-ac3e-4af7-a185-fbd7ccbef4cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1430977723-172.17.0.11-1595580943061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39697,DS-14031c90-6d4f-4cec-98f8-3b0750d06105,DISK], DatanodeInfoWithStorage[127.0.0.1:33757,DS-4cabf181-7d0f-44f5-b758-87912628f325,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-54c0004f-e845-4ab9-bffd-8a9cf78951d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-c0e25b32-c03c-4872-8382-273eb3a4f044,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-8a5b59e2-c067-478a-8888-eac56560a1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-4bad8124-b196-4e27-b752-bdc154306f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46501,DS-d76d27ae-53fc-405e-9f1b-8bf554114bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-8796fcde-ac3e-4af7-a185-fbd7ccbef4cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-392566476-172.17.0.11-1595581124609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46565,DS-b7633354-e60b-4e61-a935-88ef095be94d,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-324d0050-1675-47b3-8378-f961857b15b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-abb2784f-e92d-4cc9-b904-b92020e906e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-c5329e23-8916-4aaf-9ac9-9201c166fb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-4f857395-1688-4480-9b0f-3e2cf58ff38b,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-5aff12cf-9994-4aa6-a905-003baad0534a,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-f3366109-407c-48fa-b360-983cdb14061b,DISK], DatanodeInfoWithStorage[127.0.0.1:34444,DS-647ccf12-1b46-42ba-9588-857d76ca23de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-392566476-172.17.0.11-1595581124609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46565,DS-b7633354-e60b-4e61-a935-88ef095be94d,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-324d0050-1675-47b3-8378-f961857b15b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-abb2784f-e92d-4cc9-b904-b92020e906e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-c5329e23-8916-4aaf-9ac9-9201c166fb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-4f857395-1688-4480-9b0f-3e2cf58ff38b,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-5aff12cf-9994-4aa6-a905-003baad0534a,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-f3366109-407c-48fa-b360-983cdb14061b,DISK], DatanodeInfoWithStorage[127.0.0.1:34444,DS-647ccf12-1b46-42ba-9588-857d76ca23de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2128865671-172.17.0.11-1595581358034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36505,DS-2a3173d6-d360-4801-8a83-dcdb37fb10b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33003,DS-be9677c4-5139-46f0-b714-2271e58f34b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-0402b0c0-1afd-4f83-bf57-8b28a11e1c44,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-9b4692f7-435d-45ee-bc77-0e8907c94453,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-b063d882-12f8-49bc-a1cc-26a0c70b6aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-4de9ddfe-092f-424b-bee7-2b5efe561528,DISK], DatanodeInfoWithStorage[127.0.0.1:42412,DS-05a0833b-b1a6-4f9b-8cdc-acb30a5fb93a,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-0786502c-0e11-4d02-82b1-9fcd5f77e27b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2128865671-172.17.0.11-1595581358034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36505,DS-2a3173d6-d360-4801-8a83-dcdb37fb10b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33003,DS-be9677c4-5139-46f0-b714-2271e58f34b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-0402b0c0-1afd-4f83-bf57-8b28a11e1c44,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-9b4692f7-435d-45ee-bc77-0e8907c94453,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-b063d882-12f8-49bc-a1cc-26a0c70b6aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-4de9ddfe-092f-424b-bee7-2b5efe561528,DISK], DatanodeInfoWithStorage[127.0.0.1:42412,DS-05a0833b-b1a6-4f9b-8cdc-acb30a5fb93a,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-0786502c-0e11-4d02-82b1-9fcd5f77e27b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1496210191-172.17.0.11-1595581423508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46789,DS-a46be840-d7ef-4ce5-800a-99906b2d6bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-405076ee-a342-4f2b-931c-4b16eba94d77,DISK], DatanodeInfoWithStorage[127.0.0.1:43080,DS-643d421b-4d61-4929-b33a-e286557706e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-472f3246-dac2-4bb0-8868-8c640d79e4da,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-baae8c33-5238-419e-9c65-987b33bea200,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-ea2217f3-7626-4a71-9a10-f9989592b588,DISK], DatanodeInfoWithStorage[127.0.0.1:37637,DS-c8e7c592-8ab3-43f5-ac5d-6817111b5402,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-95fa537e-465a-4593-a671-e72c689c6e58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1496210191-172.17.0.11-1595581423508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46789,DS-a46be840-d7ef-4ce5-800a-99906b2d6bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-405076ee-a342-4f2b-931c-4b16eba94d77,DISK], DatanodeInfoWithStorage[127.0.0.1:43080,DS-643d421b-4d61-4929-b33a-e286557706e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-472f3246-dac2-4bb0-8868-8c640d79e4da,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-baae8c33-5238-419e-9c65-987b33bea200,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-ea2217f3-7626-4a71-9a10-f9989592b588,DISK], DatanodeInfoWithStorage[127.0.0.1:37637,DS-c8e7c592-8ab3-43f5-ac5d-6817111b5402,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-95fa537e-465a-4593-a671-e72c689c6e58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5066
