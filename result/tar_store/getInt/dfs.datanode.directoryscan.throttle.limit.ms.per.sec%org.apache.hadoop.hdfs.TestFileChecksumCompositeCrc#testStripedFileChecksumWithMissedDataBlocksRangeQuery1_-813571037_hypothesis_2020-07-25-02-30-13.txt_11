reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1418411197-172.17.0.12-1595644228310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36508,DS-c0c3dce6-72d7-4435-9754-56957e1c0702,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-08064461-7717-4ee7-b285-b4e2f0529271,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-8456b972-ccc1-4169-a6f4-15bfdc0f0c91,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-053c9943-aaa1-4a83-b6e9-e6906bb3da02,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-14af3f54-59a6-407c-a203-98c339d1f761,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-f13265cf-edfb-43cb-8b39-8e58b1f3649d,DISK], DatanodeInfoWithStorage[127.0.0.1:44636,DS-81924cc3-6c56-47e5-b2c8-e6be707e8cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-5a34aa0f-ce69-4cb6-8b02-de4ca762a6ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1418411197-172.17.0.12-1595644228310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36508,DS-c0c3dce6-72d7-4435-9754-56957e1c0702,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-08064461-7717-4ee7-b285-b4e2f0529271,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-8456b972-ccc1-4169-a6f4-15bfdc0f0c91,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-053c9943-aaa1-4a83-b6e9-e6906bb3da02,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-14af3f54-59a6-407c-a203-98c339d1f761,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-f13265cf-edfb-43cb-8b39-8e58b1f3649d,DISK], DatanodeInfoWithStorage[127.0.0.1:44636,DS-81924cc3-6c56-47e5-b2c8-e6be707e8cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-5a34aa0f-ce69-4cb6-8b02-de4ca762a6ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-418078509-172.17.0.12-1595644260388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36271,DS-3ee15011-c574-491a-a54e-4a55af804fee,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-f31e157f-c57b-45dc-8b5d-d27385012c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-2055fa19-b18a-49a1-8702-e6d447500f20,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-efeb455f-89a0-4409-b670-ce13c2b5bfdf,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-5fab9298-d135-46e2-9f02-757e749c394c,DISK], DatanodeInfoWithStorage[127.0.0.1:37922,DS-9fc248f7-f8b7-4900-97f4-c3c8bf02a3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42907,DS-2d99fbd2-8d77-4ecf-9e57-4a0d493d5c13,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-ed7d9d8e-2b1e-47a3-8d4a-52c8ccdaa12a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-418078509-172.17.0.12-1595644260388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36271,DS-3ee15011-c574-491a-a54e-4a55af804fee,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-f31e157f-c57b-45dc-8b5d-d27385012c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-2055fa19-b18a-49a1-8702-e6d447500f20,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-efeb455f-89a0-4409-b670-ce13c2b5bfdf,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-5fab9298-d135-46e2-9f02-757e749c394c,DISK], DatanodeInfoWithStorage[127.0.0.1:37922,DS-9fc248f7-f8b7-4900-97f4-c3c8bf02a3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42907,DS-2d99fbd2-8d77-4ecf-9e57-4a0d493d5c13,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-ed7d9d8e-2b1e-47a3-8d4a-52c8ccdaa12a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1344701061-172.17.0.12-1595644405856:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39784,DS-398e97f6-96fa-445e-bfc9-f24e030349f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-021fc55f-890f-40d9-8edd-e14e820fa5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-9b80d707-5c49-4e81-b8a5-4efbf5dcc290,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-2898a099-420a-475e-9807-168213fe81dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-81d42f07-2587-40b8-9a3d-712bb954fe07,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-abca45dc-0e92-4bad-90a0-35b1334727f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-7b547446-cde7-414b-8003-615600ee15c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-d4b59239-e9ab-42c5-853e-302bcd44f32e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1344701061-172.17.0.12-1595644405856:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39784,DS-398e97f6-96fa-445e-bfc9-f24e030349f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-021fc55f-890f-40d9-8edd-e14e820fa5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-9b80d707-5c49-4e81-b8a5-4efbf5dcc290,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-2898a099-420a-475e-9807-168213fe81dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-81d42f07-2587-40b8-9a3d-712bb954fe07,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-abca45dc-0e92-4bad-90a0-35b1334727f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-7b547446-cde7-414b-8003-615600ee15c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-d4b59239-e9ab-42c5-853e-302bcd44f32e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1380684475-172.17.0.12-1595644544911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42061,DS-29f272e0-307c-4b4c-88d7-88faaa76aed7,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-80fc40b8-1af9-4af0-ad7f-31bb9f9e9541,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-16eea779-e354-4a51-8ca5-e6d3ce5d6fff,DISK], DatanodeInfoWithStorage[127.0.0.1:45397,DS-960c0263-f033-4f64-b9d4-65b414615258,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-a1eb9c54-c775-452e-be81-dcb5dcf8f454,DISK], DatanodeInfoWithStorage[127.0.0.1:42035,DS-e45c3e5e-f042-46f7-ae1d-dbe388a59c62,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-ce24d307-c054-4fc2-b7f4-4fa3707bb6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-ffb86c3b-c692-47ca-ab26-a790a01f2e8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1380684475-172.17.0.12-1595644544911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42061,DS-29f272e0-307c-4b4c-88d7-88faaa76aed7,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-80fc40b8-1af9-4af0-ad7f-31bb9f9e9541,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-16eea779-e354-4a51-8ca5-e6d3ce5d6fff,DISK], DatanodeInfoWithStorage[127.0.0.1:45397,DS-960c0263-f033-4f64-b9d4-65b414615258,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-a1eb9c54-c775-452e-be81-dcb5dcf8f454,DISK], DatanodeInfoWithStorage[127.0.0.1:42035,DS-e45c3e5e-f042-46f7-ae1d-dbe388a59c62,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-ce24d307-c054-4fc2-b7f4-4fa3707bb6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-ffb86c3b-c692-47ca-ab26-a790a01f2e8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2029773779-172.17.0.12-1595644882333:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44536,DS-19263897-3942-455a-8789-67aec2ff27a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46081,DS-eae56dbf-8d65-434f-b817-9a1c400e505b,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-ab520f41-d88a-4c9a-b85a-7599bdc77601,DISK], DatanodeInfoWithStorage[127.0.0.1:41558,DS-93b7c065-fee3-4f12-9110-b767fe7b4c33,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-60777517-f92b-4acc-bb31-a0a826b9701e,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-1c87ae84-73f8-4f04-8713-5ee615551edd,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-55801e39-0f6f-4672-a04a-360f9b6cb257,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-8b509d41-dae4-48e5-b789-11f9ecb6d485,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2029773779-172.17.0.12-1595644882333:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44536,DS-19263897-3942-455a-8789-67aec2ff27a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46081,DS-eae56dbf-8d65-434f-b817-9a1c400e505b,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-ab520f41-d88a-4c9a-b85a-7599bdc77601,DISK], DatanodeInfoWithStorage[127.0.0.1:41558,DS-93b7c065-fee3-4f12-9110-b767fe7b4c33,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-60777517-f92b-4acc-bb31-a0a826b9701e,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-1c87ae84-73f8-4f04-8713-5ee615551edd,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-55801e39-0f6f-4672-a04a-360f9b6cb257,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-8b509d41-dae4-48e5-b789-11f9ecb6d485,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1310459905-172.17.0.12-1595645155412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33543,DS-b13314f6-0c82-4951-bfd9-4ad50942b471,DISK], DatanodeInfoWithStorage[127.0.0.1:33954,DS-f184c2ad-da31-4815-872b-3bd53b669000,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-215da331-f6ad-4dbf-927c-96d9d863ecd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-e5039e48-5f36-437f-9fa2-a00e687bc659,DISK], DatanodeInfoWithStorage[127.0.0.1:41139,DS-f63e26cc-0e7e-4862-9c6b-a6278dbdc099,DISK], DatanodeInfoWithStorage[127.0.0.1:43664,DS-63e7cf03-dad9-4adc-a2d9-da54c8c2c018,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-291f25b7-bb38-4f38-98b1-cdf1bbf0000a,DISK], DatanodeInfoWithStorage[127.0.0.1:34446,DS-888d6b98-0534-482b-9566-2e0baa72f7ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1310459905-172.17.0.12-1595645155412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33543,DS-b13314f6-0c82-4951-bfd9-4ad50942b471,DISK], DatanodeInfoWithStorage[127.0.0.1:33954,DS-f184c2ad-da31-4815-872b-3bd53b669000,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-215da331-f6ad-4dbf-927c-96d9d863ecd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-e5039e48-5f36-437f-9fa2-a00e687bc659,DISK], DatanodeInfoWithStorage[127.0.0.1:41139,DS-f63e26cc-0e7e-4862-9c6b-a6278dbdc099,DISK], DatanodeInfoWithStorage[127.0.0.1:43664,DS-63e7cf03-dad9-4adc-a2d9-da54c8c2c018,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-291f25b7-bb38-4f38-98b1-cdf1bbf0000a,DISK], DatanodeInfoWithStorage[127.0.0.1:34446,DS-888d6b98-0534-482b-9566-2e0baa72f7ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1430227392-172.17.0.12-1595645584507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40245,DS-b347713a-54d4-4ae2-920a-97cf816e91a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-1ad15a2c-1b0d-4080-954c-70b486ceeb44,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-cef180fe-2c12-45d7-a4a8-4740336a7cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-52128e34-0fd7-4be9-9697-c676ce9a07be,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-8fb38b74-9656-4cec-addc-3476a1660445,DISK], DatanodeInfoWithStorage[127.0.0.1:38214,DS-10e71f23-ffe7-4ae0-9d14-1d8dd88ce6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-8c9dd84b-3a96-4090-91d3-a781f96b51e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-efd8b8c4-f491-4188-88e2-64a681d79b80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1430227392-172.17.0.12-1595645584507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40245,DS-b347713a-54d4-4ae2-920a-97cf816e91a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-1ad15a2c-1b0d-4080-954c-70b486ceeb44,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-cef180fe-2c12-45d7-a4a8-4740336a7cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-52128e34-0fd7-4be9-9697-c676ce9a07be,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-8fb38b74-9656-4cec-addc-3476a1660445,DISK], DatanodeInfoWithStorage[127.0.0.1:38214,DS-10e71f23-ffe7-4ae0-9d14-1d8dd88ce6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-8c9dd84b-3a96-4090-91d3-a781f96b51e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-efd8b8c4-f491-4188-88e2-64a681d79b80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1674396265-172.17.0.12-1595646082209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36885,DS-717f1dff-29d7-4fcb-8a0e-e9e510118f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-4faf9e99-a5f2-436b-8f2f-28e5e5ca925b,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-9469098a-13d8-46f1-bfbd-9f776a6c3e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-890802f8-ad89-48a8-bf9f-961dd2717885,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-c54c9284-8b69-4042-b6e1-fa3228c97c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37482,DS-af705a76-f5a7-44a2-bdb6-5de1438c9b70,DISK], DatanodeInfoWithStorage[127.0.0.1:43966,DS-968bcd45-5ea1-47b0-a610-3e8a28d00905,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-429e491a-a4e5-4c75-87b6-8de3b8a64a4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1674396265-172.17.0.12-1595646082209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36885,DS-717f1dff-29d7-4fcb-8a0e-e9e510118f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-4faf9e99-a5f2-436b-8f2f-28e5e5ca925b,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-9469098a-13d8-46f1-bfbd-9f776a6c3e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-890802f8-ad89-48a8-bf9f-961dd2717885,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-c54c9284-8b69-4042-b6e1-fa3228c97c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37482,DS-af705a76-f5a7-44a2-bdb6-5de1438c9b70,DISK], DatanodeInfoWithStorage[127.0.0.1:43966,DS-968bcd45-5ea1-47b0-a610-3e8a28d00905,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-429e491a-a4e5-4c75-87b6-8de3b8a64a4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1800003807-172.17.0.12-1595646163858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42821,DS-b8d604d4-6cbc-4cef-baf0-4698957aeee8,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-84db26b0-32b3-41da-8c9e-35ca56d4b019,DISK], DatanodeInfoWithStorage[127.0.0.1:45399,DS-06c0ab3b-db26-43b1-870f-c4fe22ca4999,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-f3480afe-eeff-4657-a8ab-f6131e184119,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-64209380-ec51-4ef5-a3d1-c43dae18e14e,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-b2f39863-5410-4b1f-b52d-40d839b01a37,DISK], DatanodeInfoWithStorage[127.0.0.1:39161,DS-d71ff4f8-5646-4614-a6ab-f7d00414c478,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-3d50911f-d501-42f3-ae60-b616c95c2688,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1800003807-172.17.0.12-1595646163858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42821,DS-b8d604d4-6cbc-4cef-baf0-4698957aeee8,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-84db26b0-32b3-41da-8c9e-35ca56d4b019,DISK], DatanodeInfoWithStorage[127.0.0.1:45399,DS-06c0ab3b-db26-43b1-870f-c4fe22ca4999,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-f3480afe-eeff-4657-a8ab-f6131e184119,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-64209380-ec51-4ef5-a3d1-c43dae18e14e,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-b2f39863-5410-4b1f-b52d-40d839b01a37,DISK], DatanodeInfoWithStorage[127.0.0.1:39161,DS-d71ff4f8-5646-4614-a6ab-f7d00414c478,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-3d50911f-d501-42f3-ae60-b616c95c2688,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1771441874-172.17.0.12-1595646312263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41920,DS-406df885-b170-40c2-8cf8-b0845b720534,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-c7243e06-bb24-48f7-a70e-20464b5bfd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-964a1848-9e71-48cd-9b62-8bd72a9cdd96,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-ae0e92d0-6f7b-48d1-b2cb-25cf5d2849c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39019,DS-1df202d1-48f8-4d0e-875a-335ad2661f24,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-5ef5dd80-0fc6-46e3-9715-3533112ef5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-fcb58df5-1e1d-4fd2-a983-5e378c62e4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-200b6cfc-0667-485a-b088-ee55d7b89b87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1771441874-172.17.0.12-1595646312263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41920,DS-406df885-b170-40c2-8cf8-b0845b720534,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-c7243e06-bb24-48f7-a70e-20464b5bfd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-964a1848-9e71-48cd-9b62-8bd72a9cdd96,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-ae0e92d0-6f7b-48d1-b2cb-25cf5d2849c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39019,DS-1df202d1-48f8-4d0e-875a-335ad2661f24,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-5ef5dd80-0fc6-46e3-9715-3533112ef5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-fcb58df5-1e1d-4fd2-a983-5e378c62e4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-200b6cfc-0667-485a-b088-ee55d7b89b87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-896286625-172.17.0.12-1595646413556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33762,DS-c8cb7d85-8b30-45c3-af1d-889363686b58,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-39e4c2db-06f8-4b5a-89cc-c102c6514134,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-550185c2-f51e-442b-978a-e46a0fa81e63,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-e6aa2045-4d44-460d-a597-905e3e4eed6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-75635f0e-9ab9-45b9-865a-8c118815d4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-9332571a-b20c-4ff5-b9d2-e2a288e3fd77,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-2c860b46-c4e1-49b3-8fb6-04ce5ed4d30a,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-dcc76a3a-60ec-4b50-be3f-05a4b19d71b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-896286625-172.17.0.12-1595646413556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33762,DS-c8cb7d85-8b30-45c3-af1d-889363686b58,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-39e4c2db-06f8-4b5a-89cc-c102c6514134,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-550185c2-f51e-442b-978a-e46a0fa81e63,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-e6aa2045-4d44-460d-a597-905e3e4eed6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-75635f0e-9ab9-45b9-865a-8c118815d4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-9332571a-b20c-4ff5-b9d2-e2a288e3fd77,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-2c860b46-c4e1-49b3-8fb6-04ce5ed4d30a,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-dcc76a3a-60ec-4b50-be3f-05a4b19d71b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1724509318-172.17.0.12-1595646870532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35345,DS-9eee0da7-46ff-408b-bad3-6dbde7478c42,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-f400bbf7-3772-4972-9caa-b612428cbece,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-9d8b3c5f-bd12-4e46-9549-3cccab5aec8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42927,DS-8bc81880-6b95-4ad7-8f6f-64a6e8b8ca82,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-81b22c1e-a6f0-4d96-8637-beafc1cda09c,DISK], DatanodeInfoWithStorage[127.0.0.1:38406,DS-2c359d56-ab76-4430-8c8a-dbecf6f87ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-4e188317-c76c-4d94-b706-c42af9c30b11,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-fe4b8de3-0621-455e-992d-294113265c0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1724509318-172.17.0.12-1595646870532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35345,DS-9eee0da7-46ff-408b-bad3-6dbde7478c42,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-f400bbf7-3772-4972-9caa-b612428cbece,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-9d8b3c5f-bd12-4e46-9549-3cccab5aec8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42927,DS-8bc81880-6b95-4ad7-8f6f-64a6e8b8ca82,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-81b22c1e-a6f0-4d96-8637-beafc1cda09c,DISK], DatanodeInfoWithStorage[127.0.0.1:38406,DS-2c359d56-ab76-4430-8c8a-dbecf6f87ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-4e188317-c76c-4d94-b706-c42af9c30b11,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-fe4b8de3-0621-455e-992d-294113265c0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-354368090-172.17.0.12-1595646908317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38539,DS-d53973ef-84ff-45a6-8330-797f9df345d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-89e639b0-73ea-4062-a6dc-8c0e45bdceff,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-adb6c8b2-1294-4fbe-9b90-210a370d5b33,DISK], DatanodeInfoWithStorage[127.0.0.1:46231,DS-0c37cde3-61d6-4698-97cc-7b61d7e732a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-4ac47fce-b9e0-4502-88ba-d95567d7c540,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-942d26d4-5e55-4e37-928c-f0077f09618d,DISK], DatanodeInfoWithStorage[127.0.0.1:34068,DS-fd5ed44e-a4d2-40bf-a055-647606dc1ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-c531f2df-fc37-4036-9a90-66695036a008,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-354368090-172.17.0.12-1595646908317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38539,DS-d53973ef-84ff-45a6-8330-797f9df345d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-89e639b0-73ea-4062-a6dc-8c0e45bdceff,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-adb6c8b2-1294-4fbe-9b90-210a370d5b33,DISK], DatanodeInfoWithStorage[127.0.0.1:46231,DS-0c37cde3-61d6-4698-97cc-7b61d7e732a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-4ac47fce-b9e0-4502-88ba-d95567d7c540,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-942d26d4-5e55-4e37-928c-f0077f09618d,DISK], DatanodeInfoWithStorage[127.0.0.1:34068,DS-fd5ed44e-a4d2-40bf-a055-647606dc1ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-c531f2df-fc37-4036-9a90-66695036a008,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1467917126-172.17.0.12-1595646950926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36368,DS-d03ebe4b-ab34-4c2c-a280-cd36ae8ee579,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-3dfa614e-fdb8-4fb8-b73c-c18444163d26,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-59a17d38-c49e-410e-9a46-761244aa31e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-31df6dd7-3a1b-45a2-9fd9-17d0264d4b83,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-ddf32d8d-d7a6-45a6-be19-efdd53114e75,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-6545e000-35d5-48a6-b7dc-cb81f89f9dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-e3540548-cd10-4515-9c4e-53e4a675bc05,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-c794843f-1c2c-45ef-9313-d7426fc79663,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1467917126-172.17.0.12-1595646950926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36368,DS-d03ebe4b-ab34-4c2c-a280-cd36ae8ee579,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-3dfa614e-fdb8-4fb8-b73c-c18444163d26,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-59a17d38-c49e-410e-9a46-761244aa31e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-31df6dd7-3a1b-45a2-9fd9-17d0264d4b83,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-ddf32d8d-d7a6-45a6-be19-efdd53114e75,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-6545e000-35d5-48a6-b7dc-cb81f89f9dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-e3540548-cd10-4515-9c4e-53e4a675bc05,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-c794843f-1c2c-45ef-9313-d7426fc79663,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1775093696-172.17.0.12-1595647096049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38083,DS-b301f0cf-6414-4b88-83f0-34ab6ae7630c,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-2ae8bc8f-9f02-4889-8a52-bc84f272c2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-a204451b-e2a6-44ce-8c06-189835ea4fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-e85ba337-2602-43ff-9387-8034f733afb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-0f1d746e-c64f-4afb-95d8-bf25b2ea071a,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-49b03ee0-14f4-4a49-944e-2117b04ea0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39952,DS-bb9de1c7-1882-4a79-ab30-c4d5f4cd6141,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-94ab4508-49ef-4d75-b4d5-c8a6fc162f68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1775093696-172.17.0.12-1595647096049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38083,DS-b301f0cf-6414-4b88-83f0-34ab6ae7630c,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-2ae8bc8f-9f02-4889-8a52-bc84f272c2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-a204451b-e2a6-44ce-8c06-189835ea4fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-e85ba337-2602-43ff-9387-8034f733afb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-0f1d746e-c64f-4afb-95d8-bf25b2ea071a,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-49b03ee0-14f4-4a49-944e-2117b04ea0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39952,DS-bb9de1c7-1882-4a79-ab30-c4d5f4cd6141,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-94ab4508-49ef-4d75-b4d5-c8a6fc162f68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-106997809-172.17.0.12-1595647132220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32785,DS-7ccd3f7d-8893-4280-b7df-60945a72d6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-b9c3d724-c0a1-4906-855e-bd14cff286f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-da0fa8d5-6e35-4508-88f3-116b5b1dd1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-0b3f3068-77bd-4ca9-a048-e8e07048b3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-9789fe41-5eff-4ca1-bc80-c38a3c8c02b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36919,DS-026cedc4-9758-4f6d-af3b-55aeac11fab1,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-fa392b15-5e66-411c-98ff-0c6c3b2d5d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37199,DS-c3dc31f2-1db1-471a-bc09-7c2aad223600,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-106997809-172.17.0.12-1595647132220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32785,DS-7ccd3f7d-8893-4280-b7df-60945a72d6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-b9c3d724-c0a1-4906-855e-bd14cff286f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-da0fa8d5-6e35-4508-88f3-116b5b1dd1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-0b3f3068-77bd-4ca9-a048-e8e07048b3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-9789fe41-5eff-4ca1-bc80-c38a3c8c02b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36919,DS-026cedc4-9758-4f6d-af3b-55aeac11fab1,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-fa392b15-5e66-411c-98ff-0c6c3b2d5d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37199,DS-c3dc31f2-1db1-471a-bc09-7c2aad223600,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1762632301-172.17.0.12-1595647642600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44979,DS-4c781fda-86e5-4168-9ce8-98145f20f4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-3615b22c-97c4-48b2-8e55-88857237e18c,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-315d47c4-51d1-4ce9-b8d0-3aba7df3536e,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-53456c41-11cd-4558-aca4-4f5fc37adb39,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-da424327-d1b1-4416-ab0f-9669a23d0cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-4cf60a66-4091-4832-93db-b21c1211be35,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-6905d684-ff62-4151-a71a-45c53276b9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46173,DS-f473bac7-2ce7-475d-b1ed-be8935579c32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1762632301-172.17.0.12-1595647642600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44979,DS-4c781fda-86e5-4168-9ce8-98145f20f4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-3615b22c-97c4-48b2-8e55-88857237e18c,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-315d47c4-51d1-4ce9-b8d0-3aba7df3536e,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-53456c41-11cd-4558-aca4-4f5fc37adb39,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-da424327-d1b1-4416-ab0f-9669a23d0cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-4cf60a66-4091-4832-93db-b21c1211be35,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-6905d684-ff62-4151-a71a-45c53276b9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46173,DS-f473bac7-2ce7-475d-b1ed-be8935579c32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1259253109-172.17.0.12-1595647715415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36835,DS-bf27d632-311c-4baa-90da-5d73a27360e1,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-ec7c4a81-2598-4677-b8a7-048e686375c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40748,DS-b5ec74ee-bcc7-405c-9b0c-4b3574bc47af,DISK], DatanodeInfoWithStorage[127.0.0.1:41756,DS-32c1bbca-0f5b-410b-adfb-39ff152741a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45081,DS-abe9254d-c5ba-4fe2-8e52-67d5ce42a7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-a96ec99c-2de3-46d0-98ed-e7988ae0f318,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-07949b91-2221-48a1-8370-4ea37b0edfa1,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-3da3439c-fead-47db-b0f7-675d1726fc78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1259253109-172.17.0.12-1595647715415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36835,DS-bf27d632-311c-4baa-90da-5d73a27360e1,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-ec7c4a81-2598-4677-b8a7-048e686375c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40748,DS-b5ec74ee-bcc7-405c-9b0c-4b3574bc47af,DISK], DatanodeInfoWithStorage[127.0.0.1:41756,DS-32c1bbca-0f5b-410b-adfb-39ff152741a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45081,DS-abe9254d-c5ba-4fe2-8e52-67d5ce42a7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-a96ec99c-2de3-46d0-98ed-e7988ae0f318,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-07949b91-2221-48a1-8370-4ea37b0edfa1,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-3da3439c-fead-47db-b0f7-675d1726fc78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-644363514-172.17.0.12-1595647751604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37395,DS-508fcbd9-46e1-40f3-ae3c-5f52ff15ccd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-7c08d0b5-7f0c-4bf4-8747-edb01ff4177e,DISK], DatanodeInfoWithStorage[127.0.0.1:34695,DS-ae15530a-c47b-40ef-8c22-a81300f0e590,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-e5dea6ca-f594-448c-919c-5c6276191204,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-46e28c7f-f5bf-442a-8567-0e3f5d929bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42981,DS-4218a988-d5c3-42e3-9810-8db97003ecc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-92b27c47-2de7-4460-bd55-6f29531c35ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-4388ba8e-7743-461b-8675-08124a3a74ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-644363514-172.17.0.12-1595647751604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37395,DS-508fcbd9-46e1-40f3-ae3c-5f52ff15ccd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-7c08d0b5-7f0c-4bf4-8747-edb01ff4177e,DISK], DatanodeInfoWithStorage[127.0.0.1:34695,DS-ae15530a-c47b-40ef-8c22-a81300f0e590,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-e5dea6ca-f594-448c-919c-5c6276191204,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-46e28c7f-f5bf-442a-8567-0e3f5d929bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42981,DS-4218a988-d5c3-42e3-9810-8db97003ecc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-92b27c47-2de7-4460-bd55-6f29531c35ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-4388ba8e-7743-461b-8675-08124a3a74ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-362981735-172.17.0.12-1595647951349:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33463,DS-990f0330-2bca-4a58-8bef-7343eb27919b,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-78f34322-9a03-4e37-bccc-1fa471227783,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-4d0e8698-5312-4eee-9f2e-6032e9b71354,DISK], DatanodeInfoWithStorage[127.0.0.1:42923,DS-8a931288-2a8f-4ba1-8e61-cf375b456031,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-191de7ac-d8fa-41fa-8108-84f21a7b46cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44159,DS-2c472b67-b833-4bcc-84bf-04dd1c7d4957,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-1ed61896-93e3-43ee-9535-7a01b285e243,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-b025a6c8-9bf8-4b6f-87d7-d4621cd34032,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-362981735-172.17.0.12-1595647951349:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33463,DS-990f0330-2bca-4a58-8bef-7343eb27919b,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-78f34322-9a03-4e37-bccc-1fa471227783,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-4d0e8698-5312-4eee-9f2e-6032e9b71354,DISK], DatanodeInfoWithStorage[127.0.0.1:42923,DS-8a931288-2a8f-4ba1-8e61-cf375b456031,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-191de7ac-d8fa-41fa-8108-84f21a7b46cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44159,DS-2c472b67-b833-4bcc-84bf-04dd1c7d4957,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-1ed61896-93e3-43ee-9535-7a01b285e243,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-b025a6c8-9bf8-4b6f-87d7-d4621cd34032,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1414889686-172.17.0.12-1595648063876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44813,DS-23b05858-1c63-42ab-ae32-2f08233f0496,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-a53082fe-5865-4eda-8032-ad9ee2f88ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:36832,DS-f6c366e5-1e45-4e21-ad57-19eea2d45f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44238,DS-30ff2986-4d24-4c3c-bc91-076a7765627e,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-a03d3914-7ca4-42c2-8964-9ab8abcc943a,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-5684ea4f-0a61-4457-8dba-85a049aa699f,DISK], DatanodeInfoWithStorage[127.0.0.1:39358,DS-5327ff0b-f793-4927-9644-70af6043f10d,DISK], DatanodeInfoWithStorage[127.0.0.1:45140,DS-a4d47981-e9b9-4df2-97fb-cc6b70d9c861,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1414889686-172.17.0.12-1595648063876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44813,DS-23b05858-1c63-42ab-ae32-2f08233f0496,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-a53082fe-5865-4eda-8032-ad9ee2f88ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:36832,DS-f6c366e5-1e45-4e21-ad57-19eea2d45f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44238,DS-30ff2986-4d24-4c3c-bc91-076a7765627e,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-a03d3914-7ca4-42c2-8964-9ab8abcc943a,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-5684ea4f-0a61-4457-8dba-85a049aa699f,DISK], DatanodeInfoWithStorage[127.0.0.1:39358,DS-5327ff0b-f793-4927-9644-70af6043f10d,DISK], DatanodeInfoWithStorage[127.0.0.1:45140,DS-a4d47981-e9b9-4df2-97fb-cc6b70d9c861,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1178389997-172.17.0.12-1595648530836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33589,DS-ad3486de-7aa5-405c-b826-c78a7d320a89,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-036a44c6-73da-4d29-896c-ff8a2bff0da9,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-400d515a-6fc3-4e3f-a2a5-c05d3540245f,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-cdfdac7e-bc04-4ce2-8bda-368656cc9c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-84e579ee-1f35-42bf-bb0b-e9db6c8736df,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-e68f7e3a-8c98-4173-8b70-aff66d134ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-be68746d-2bec-4c28-bce0-25fe8c60cb68,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-ec8bf4fd-500d-4e13-bd35-6b747545d6c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1178389997-172.17.0.12-1595648530836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33589,DS-ad3486de-7aa5-405c-b826-c78a7d320a89,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-036a44c6-73da-4d29-896c-ff8a2bff0da9,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-400d515a-6fc3-4e3f-a2a5-c05d3540245f,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-cdfdac7e-bc04-4ce2-8bda-368656cc9c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-84e579ee-1f35-42bf-bb0b-e9db6c8736df,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-e68f7e3a-8c98-4173-8b70-aff66d134ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-be68746d-2bec-4c28-bce0-25fe8c60cb68,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-ec8bf4fd-500d-4e13-bd35-6b747545d6c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1601551077-172.17.0.12-1595648749360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39861,DS-9d3593b7-d9e2-4449-88db-72f542be3fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33303,DS-ca5c526b-3990-4791-9ec0-3a9cec0598e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46202,DS-1c28a8fc-0f84-476d-b831-6186caf3743e,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-54cca474-e4a0-40b9-b11b-e9595608c21d,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-db1461b4-9133-4856-b3ac-d8d3cbd18a60,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-8bbfa130-82d8-4554-afd4-b41dec14c281,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-8b22bf1b-a1d9-468e-bce8-111351247e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39752,DS-19dd8cfe-ac7f-4df4-9eab-fd406a4f1b30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1601551077-172.17.0.12-1595648749360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39861,DS-9d3593b7-d9e2-4449-88db-72f542be3fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33303,DS-ca5c526b-3990-4791-9ec0-3a9cec0598e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46202,DS-1c28a8fc-0f84-476d-b831-6186caf3743e,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-54cca474-e4a0-40b9-b11b-e9595608c21d,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-db1461b4-9133-4856-b3ac-d8d3cbd18a60,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-8bbfa130-82d8-4554-afd4-b41dec14c281,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-8b22bf1b-a1d9-468e-bce8-111351247e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39752,DS-19dd8cfe-ac7f-4df4-9eab-fd406a4f1b30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1377894920-172.17.0.12-1595648946324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42359,DS-65780f77-ed62-4143-aed0-97dd34e4d245,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-06bb30fe-2866-4cb0-b3f1-369bc7c84925,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-d3709ad8-73dd-4c7f-8dc7-0a38900c3f77,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-4245a1f9-4afa-49b6-a953-1f8c64d9ece9,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-0d2e940f-1a09-4152-af18-e6d12534b1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42147,DS-9b3e4475-46e9-4c70-9fc4-1b72546e1f30,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-793e2669-24ab-4573-93ef-ff2c95cfec1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-6955cfab-95b1-4e37-badd-042b2952a2fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1377894920-172.17.0.12-1595648946324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42359,DS-65780f77-ed62-4143-aed0-97dd34e4d245,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-06bb30fe-2866-4cb0-b3f1-369bc7c84925,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-d3709ad8-73dd-4c7f-8dc7-0a38900c3f77,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-4245a1f9-4afa-49b6-a953-1f8c64d9ece9,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-0d2e940f-1a09-4152-af18-e6d12534b1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42147,DS-9b3e4475-46e9-4c70-9fc4-1b72546e1f30,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-793e2669-24ab-4573-93ef-ff2c95cfec1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-6955cfab-95b1-4e37-badd-042b2952a2fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-558627864-172.17.0.12-1595649742417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34666,DS-35755ead-8709-40d1-bb01-54ec84db27d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37984,DS-e9ab2b06-3bd8-4142-9847-2eb5f9875c96,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-2161f93d-abe5-47ff-a41f-6a3e7da76377,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-1ea4d179-25a6-4700-80d8-0ff4cc5398e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-0b506471-afbc-434c-923f-297df05a1b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-159ffc4e-7789-4b7a-bd14-039d2192b717,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-7c5eb17a-48e1-4819-a534-2b95255e15c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33762,DS-2c42007b-6649-4b7a-a71b-f961d334be83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-558627864-172.17.0.12-1595649742417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34666,DS-35755ead-8709-40d1-bb01-54ec84db27d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37984,DS-e9ab2b06-3bd8-4142-9847-2eb5f9875c96,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-2161f93d-abe5-47ff-a41f-6a3e7da76377,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-1ea4d179-25a6-4700-80d8-0ff4cc5398e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-0b506471-afbc-434c-923f-297df05a1b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-159ffc4e-7789-4b7a-bd14-039d2192b717,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-7c5eb17a-48e1-4819-a534-2b95255e15c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33762,DS-2c42007b-6649-4b7a-a71b-f961d334be83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 5586
