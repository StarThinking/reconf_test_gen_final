reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-193370250-172.17.0.5-1595881079555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45492,DS-4ec05ec7-4634-413d-9e32-0c23ef18aba7,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-624256a2-fdfe-47ed-abd6-85c476fa2edb,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-fb8e9510-1fce-4f5f-9369-584108c4c8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-d26fca2a-c1b9-42bb-b03f-dde324c628a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-a7ac3bc0-5f66-4885-a813-d799e1de7d34,DISK], DatanodeInfoWithStorage[127.0.0.1:39896,DS-49c66dd4-de46-432f-af93-e23ba06d31ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-a88a7790-03a9-4ab0-abfa-5d74d0d0e962,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-da4ebf47-667b-4c5b-b800-620223bdf0a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-193370250-172.17.0.5-1595881079555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45492,DS-4ec05ec7-4634-413d-9e32-0c23ef18aba7,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-624256a2-fdfe-47ed-abd6-85c476fa2edb,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-fb8e9510-1fce-4f5f-9369-584108c4c8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-d26fca2a-c1b9-42bb-b03f-dde324c628a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-a7ac3bc0-5f66-4885-a813-d799e1de7d34,DISK], DatanodeInfoWithStorage[127.0.0.1:39896,DS-49c66dd4-de46-432f-af93-e23ba06d31ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-a88a7790-03a9-4ab0-abfa-5d74d0d0e962,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-da4ebf47-667b-4c5b-b800-620223bdf0a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1777832561-172.17.0.5-1595881515399:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38750,DS-c3fc01ec-5713-4383-ba89-0f7d7500b658,DISK], DatanodeInfoWithStorage[127.0.0.1:42777,DS-11ad1393-f2c8-4534-8b1f-f1054d4b5e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-f51083e0-b35d-41c3-9cf2-6efe505b16bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44792,DS-25de2a79-08e4-450d-a3ea-2b29a2ef0f40,DISK], DatanodeInfoWithStorage[127.0.0.1:43009,DS-4becd16c-dd45-4f6a-b7a9-c3a9d4f9d9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-30d6d57f-97f4-4a60-a8da-9aeb86aec1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-4f0c8607-b7de-4e52-beeb-880297db48e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46374,DS-e9b68745-b58b-42f0-b9df-af4b3cfd0dee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1777832561-172.17.0.5-1595881515399:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38750,DS-c3fc01ec-5713-4383-ba89-0f7d7500b658,DISK], DatanodeInfoWithStorage[127.0.0.1:42777,DS-11ad1393-f2c8-4534-8b1f-f1054d4b5e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-f51083e0-b35d-41c3-9cf2-6efe505b16bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44792,DS-25de2a79-08e4-450d-a3ea-2b29a2ef0f40,DISK], DatanodeInfoWithStorage[127.0.0.1:43009,DS-4becd16c-dd45-4f6a-b7a9-c3a9d4f9d9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-30d6d57f-97f4-4a60-a8da-9aeb86aec1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-4f0c8607-b7de-4e52-beeb-880297db48e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46374,DS-e9b68745-b58b-42f0-b9df-af4b3cfd0dee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-470852487-172.17.0.5-1595881941727:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33254,DS-010694c6-2961-41a1-aba3-9c46ceeed085,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-50fd6351-e4ce-43bd-8d19-460af1064f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-303f5a7c-b5ff-49c6-ba59-fd35d4af94c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-79427d78-e68f-42f2-9064-5e1ba2d7b66e,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-c1acd66f-cbc8-4916-9707-e1724ef67d62,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-4efaa772-ca4a-422b-a2e0-591f59038760,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-8f021401-8b74-4cda-b5bc-89018e4a79dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-8c85fea9-410a-4775-9af6-acb915ec58b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-470852487-172.17.0.5-1595881941727:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33254,DS-010694c6-2961-41a1-aba3-9c46ceeed085,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-50fd6351-e4ce-43bd-8d19-460af1064f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-303f5a7c-b5ff-49c6-ba59-fd35d4af94c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-79427d78-e68f-42f2-9064-5e1ba2d7b66e,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-c1acd66f-cbc8-4916-9707-e1724ef67d62,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-4efaa772-ca4a-422b-a2e0-591f59038760,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-8f021401-8b74-4cda-b5bc-89018e4a79dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-8c85fea9-410a-4775-9af6-acb915ec58b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1941153336-172.17.0.5-1595881973845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44854,DS-5225b919-9ae2-49e1-8773-f843bdf2b5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-53d2a8eb-47ab-4418-837f-78d1cd7f4ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-a1566ee3-dd8c-4574-aa49-4e94e73b7425,DISK], DatanodeInfoWithStorage[127.0.0.1:38794,DS-848502c1-8c5c-4b73-b02d-1737ee7d48a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39303,DS-8f7118fb-4b13-45c4-9b92-29f2e245e048,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-182cc11b-f3b1-450c-83aa-74590c5cd0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-50c2fbf9-df04-4878-af57-866e18a6cbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-2a00e765-4c10-43af-8fee-17849b95fd8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1941153336-172.17.0.5-1595881973845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44854,DS-5225b919-9ae2-49e1-8773-f843bdf2b5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-53d2a8eb-47ab-4418-837f-78d1cd7f4ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-a1566ee3-dd8c-4574-aa49-4e94e73b7425,DISK], DatanodeInfoWithStorage[127.0.0.1:38794,DS-848502c1-8c5c-4b73-b02d-1737ee7d48a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39303,DS-8f7118fb-4b13-45c4-9b92-29f2e245e048,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-182cc11b-f3b1-450c-83aa-74590c5cd0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-50c2fbf9-df04-4878-af57-866e18a6cbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-2a00e765-4c10-43af-8fee-17849b95fd8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1109792225-172.17.0.5-1595882003801:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35609,DS-bf9f6127-a3b9-42d5-9429-84bdc769b4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-29a7d142-76a1-4d03-9da5-3014efa82b50,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-023e35ed-20bf-4986-b58a-9c0b0a4a4130,DISK], DatanodeInfoWithStorage[127.0.0.1:40595,DS-3875a2f4-5779-4d81-b18b-75c52fa9f713,DISK], DatanodeInfoWithStorage[127.0.0.1:38002,DS-704d2d10-6ee9-4e99-a61b-4ccd1f75e123,DISK], DatanodeInfoWithStorage[127.0.0.1:34743,DS-865ca6de-abab-4dfe-8335-ace75c734b20,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-2e3c5a97-1b10-4e0d-b882-90d61628cf12,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-43ddb677-8af9-48ed-b51d-4fb672562f30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1109792225-172.17.0.5-1595882003801:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35609,DS-bf9f6127-a3b9-42d5-9429-84bdc769b4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-29a7d142-76a1-4d03-9da5-3014efa82b50,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-023e35ed-20bf-4986-b58a-9c0b0a4a4130,DISK], DatanodeInfoWithStorage[127.0.0.1:40595,DS-3875a2f4-5779-4d81-b18b-75c52fa9f713,DISK], DatanodeInfoWithStorage[127.0.0.1:38002,DS-704d2d10-6ee9-4e99-a61b-4ccd1f75e123,DISK], DatanodeInfoWithStorage[127.0.0.1:34743,DS-865ca6de-abab-4dfe-8335-ace75c734b20,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-2e3c5a97-1b10-4e0d-b882-90d61628cf12,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-43ddb677-8af9-48ed-b51d-4fb672562f30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1249669917-172.17.0.5-1595882216611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34082,DS-7965a671-43c1-4d62-bb52-18e984d8f68a,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-dc327b85-b49c-4855-89a9-0e3a9583b989,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-823d472e-f177-4207-91ec-2a19f301eb2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-d37735c8-10b0-4569-8277-959f650f3ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-266f9c71-04f2-44a8-8c09-4c685f9a520c,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-6312343a-dfcc-4768-a3b5-09872a866e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-5d6e76cf-8c2b-4c66-8643-1fb6d731f5de,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-b526a28f-403d-4bc6-abfe-49dfec7b261a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1249669917-172.17.0.5-1595882216611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34082,DS-7965a671-43c1-4d62-bb52-18e984d8f68a,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-dc327b85-b49c-4855-89a9-0e3a9583b989,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-823d472e-f177-4207-91ec-2a19f301eb2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-d37735c8-10b0-4569-8277-959f650f3ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-266f9c71-04f2-44a8-8c09-4c685f9a520c,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-6312343a-dfcc-4768-a3b5-09872a866e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-5d6e76cf-8c2b-4c66-8643-1fb6d731f5de,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-b526a28f-403d-4bc6-abfe-49dfec7b261a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1309149142-172.17.0.5-1595882701316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40677,DS-01b7278a-e162-47fb-ac5c-c75a2b250916,DISK], DatanodeInfoWithStorage[127.0.0.1:35870,DS-64846160-aab1-4e41-9a24-e09b3c837be4,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-3d7aa56c-12d6-4417-81d5-84859fea03d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-710f648b-db26-4711-9caf-32b0bfe20cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-c8f39589-702a-4c91-885c-fcc847a9c1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44304,DS-8b363acc-d00f-4701-a44e-e70b8cb60bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38647,DS-8d85f7fd-a1d0-42db-b28a-5eef9e82750a,DISK], DatanodeInfoWithStorage[127.0.0.1:46390,DS-47b1ada3-6c2f-48c7-9e1c-083e4e323514,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1309149142-172.17.0.5-1595882701316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40677,DS-01b7278a-e162-47fb-ac5c-c75a2b250916,DISK], DatanodeInfoWithStorage[127.0.0.1:35870,DS-64846160-aab1-4e41-9a24-e09b3c837be4,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-3d7aa56c-12d6-4417-81d5-84859fea03d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-710f648b-db26-4711-9caf-32b0bfe20cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-c8f39589-702a-4c91-885c-fcc847a9c1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44304,DS-8b363acc-d00f-4701-a44e-e70b8cb60bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38647,DS-8d85f7fd-a1d0-42db-b28a-5eef9e82750a,DISK], DatanodeInfoWithStorage[127.0.0.1:46390,DS-47b1ada3-6c2f-48c7-9e1c-083e4e323514,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-65270182-172.17.0.5-1595882874530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42169,DS-b68dbd6a-dbe2-4fe2-a7ef-35a158416429,DISK], DatanodeInfoWithStorage[127.0.0.1:43834,DS-ffb6838f-dd9f-4a40-a894-0ef55e4d0a00,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-c04e39e8-a1a4-40fa-b00a-cf495be78f65,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-6c275412-a551-4522-a7fc-d91507e0f2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-95ad5965-63c2-4a2e-a026-f415f3ff31c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-fb2f9fb4-9076-4134-b4d6-6ff698285a80,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-2e835e1d-0f1b-4df4-b84e-c94336baef59,DISK], DatanodeInfoWithStorage[127.0.0.1:38578,DS-ec8bc0e2-8748-482f-a33f-8c63b9438b36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-65270182-172.17.0.5-1595882874530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42169,DS-b68dbd6a-dbe2-4fe2-a7ef-35a158416429,DISK], DatanodeInfoWithStorage[127.0.0.1:43834,DS-ffb6838f-dd9f-4a40-a894-0ef55e4d0a00,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-c04e39e8-a1a4-40fa-b00a-cf495be78f65,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-6c275412-a551-4522-a7fc-d91507e0f2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-95ad5965-63c2-4a2e-a026-f415f3ff31c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-fb2f9fb4-9076-4134-b4d6-6ff698285a80,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-2e835e1d-0f1b-4df4-b84e-c94336baef59,DISK], DatanodeInfoWithStorage[127.0.0.1:38578,DS-ec8bc0e2-8748-482f-a33f-8c63b9438b36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1873204196-172.17.0.5-1595884698719:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36280,DS-2eaeb57b-d0c4-4492-84f3-8394f6e6310f,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-419ba177-c80d-4518-b92e-4e18acc9c019,DISK], DatanodeInfoWithStorage[127.0.0.1:43700,DS-c15d89fb-31dc-4eff-99db-4a9013a903a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-71512ee7-53f8-4e30-9fa3-fda42850be48,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-6c50c1a8-3777-4864-894d-14beb96fda2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-0edd7d92-cd4a-4654-a2fb-56996d589067,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-177f45e4-8790-4e6a-b6ae-00747e04e3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-6c7c99c4-96f2-474f-ba02-1e8412274d29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1873204196-172.17.0.5-1595884698719:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36280,DS-2eaeb57b-d0c4-4492-84f3-8394f6e6310f,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-419ba177-c80d-4518-b92e-4e18acc9c019,DISK], DatanodeInfoWithStorage[127.0.0.1:43700,DS-c15d89fb-31dc-4eff-99db-4a9013a903a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-71512ee7-53f8-4e30-9fa3-fda42850be48,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-6c50c1a8-3777-4864-894d-14beb96fda2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-0edd7d92-cd4a-4654-a2fb-56996d589067,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-177f45e4-8790-4e6a-b6ae-00747e04e3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-6c7c99c4-96f2-474f-ba02-1e8412274d29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1621580316-172.17.0.5-1595884801693:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42870,DS-bdaae5d2-3ae5-4b96-8cb1-e6f8d9332c46,DISK], DatanodeInfoWithStorage[127.0.0.1:43863,DS-987d402d-efc3-4054-a9f4-b1fde9d01a00,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-5c5c40d0-5e51-4c7d-be10-d58482f91fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-a3035ec7-9209-4d9c-8128-82fbe8ae88be,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-f248a7bb-6636-4465-84bc-0ac2fbd87a96,DISK], DatanodeInfoWithStorage[127.0.0.1:34767,DS-3cf757e6-42ee-4942-8012-8c17ea5f6a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-21e1a12e-19df-4ce1-9313-d08b27185c34,DISK], DatanodeInfoWithStorage[127.0.0.1:45749,DS-197b8d7b-9d67-4b33-bf6e-b9ce36246b7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1621580316-172.17.0.5-1595884801693:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42870,DS-bdaae5d2-3ae5-4b96-8cb1-e6f8d9332c46,DISK], DatanodeInfoWithStorage[127.0.0.1:43863,DS-987d402d-efc3-4054-a9f4-b1fde9d01a00,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-5c5c40d0-5e51-4c7d-be10-d58482f91fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-a3035ec7-9209-4d9c-8128-82fbe8ae88be,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-f248a7bb-6636-4465-84bc-0ac2fbd87a96,DISK], DatanodeInfoWithStorage[127.0.0.1:34767,DS-3cf757e6-42ee-4942-8012-8c17ea5f6a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-21e1a12e-19df-4ce1-9313-d08b27185c34,DISK], DatanodeInfoWithStorage[127.0.0.1:45749,DS-197b8d7b-9d67-4b33-bf6e-b9ce36246b7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-184147252-172.17.0.5-1595884834476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44227,DS-44058bce-53a0-4fea-8513-e9223fec69a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-10c5819b-083f-45d7-8b5c-1864ec67b301,DISK], DatanodeInfoWithStorage[127.0.0.1:41326,DS-34dc61eb-e1bb-4afe-931d-2d655a13ee6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37023,DS-69803f89-dbe1-4d86-926a-fce976e15a84,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-c19274fd-972c-479a-8ae2-8bf26cf8ee0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-e7eee676-4f6c-4b9a-9952-4f0e8382f96b,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-202b4f1c-edcc-46f4-8117-358889506add,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-8f437d6b-9c4c-4635-b4db-f4fbc65b5dc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-184147252-172.17.0.5-1595884834476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44227,DS-44058bce-53a0-4fea-8513-e9223fec69a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-10c5819b-083f-45d7-8b5c-1864ec67b301,DISK], DatanodeInfoWithStorage[127.0.0.1:41326,DS-34dc61eb-e1bb-4afe-931d-2d655a13ee6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37023,DS-69803f89-dbe1-4d86-926a-fce976e15a84,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-c19274fd-972c-479a-8ae2-8bf26cf8ee0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-e7eee676-4f6c-4b9a-9952-4f0e8382f96b,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-202b4f1c-edcc-46f4-8117-358889506add,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-8f437d6b-9c4c-4635-b4db-f4fbc65b5dc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1637719940-172.17.0.5-1595885194838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34323,DS-5ea708ef-a199-4dd0-a826-b83a943f16fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-968a9e84-774f-423f-a661-a991ba0831f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-5b95b5d8-73c9-48c1-8051-49bc0e535a24,DISK], DatanodeInfoWithStorage[127.0.0.1:34375,DS-c03484a5-82d5-4d6a-a99e-348749a54cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-8c506688-3c8d-448d-a0cc-c9f6b196c446,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-0d1f81e7-dd39-4601-95cf-2001471cd357,DISK], DatanodeInfoWithStorage[127.0.0.1:35743,DS-b1a23c99-6c0f-40e7-abdb-dbefdb637e11,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-4c28e793-f1dd-4879-b51a-815478a1e910,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1637719940-172.17.0.5-1595885194838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34323,DS-5ea708ef-a199-4dd0-a826-b83a943f16fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-968a9e84-774f-423f-a661-a991ba0831f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-5b95b5d8-73c9-48c1-8051-49bc0e535a24,DISK], DatanodeInfoWithStorage[127.0.0.1:34375,DS-c03484a5-82d5-4d6a-a99e-348749a54cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-8c506688-3c8d-448d-a0cc-c9f6b196c446,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-0d1f81e7-dd39-4601-95cf-2001471cd357,DISK], DatanodeInfoWithStorage[127.0.0.1:35743,DS-b1a23c99-6c0f-40e7-abdb-dbefdb637e11,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-4c28e793-f1dd-4879-b51a-815478a1e910,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5337
