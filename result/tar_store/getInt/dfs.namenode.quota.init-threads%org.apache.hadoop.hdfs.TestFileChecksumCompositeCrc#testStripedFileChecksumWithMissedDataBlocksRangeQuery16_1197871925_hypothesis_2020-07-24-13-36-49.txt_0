reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1526664880-172.17.0.10-1595598009900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40332,DS-a8e1d8be-fdb5-48f5-85ae-545a0afa6aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:46351,DS-6c9e883f-dcb8-4f3b-b215-77b6f5027883,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-4be4487d-72f4-42bb-a04b-9239b256b147,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-73384a59-b2f0-468e-bec8-b02b442a57ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-8d41c400-6f82-4918-af85-88ce71c53bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-15a6c462-c38f-4c3b-954a-eb46a5f32bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-ffe380b5-fed8-4df4-b1e5-c922286545cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-9b5dcd8b-26bb-473e-85cd-f85942947d72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1526664880-172.17.0.10-1595598009900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40332,DS-a8e1d8be-fdb5-48f5-85ae-545a0afa6aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:46351,DS-6c9e883f-dcb8-4f3b-b215-77b6f5027883,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-4be4487d-72f4-42bb-a04b-9239b256b147,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-73384a59-b2f0-468e-bec8-b02b442a57ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-8d41c400-6f82-4918-af85-88ce71c53bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-15a6c462-c38f-4c3b-954a-eb46a5f32bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-ffe380b5-fed8-4df4-b1e5-c922286545cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-9b5dcd8b-26bb-473e-85cd-f85942947d72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-10580341-172.17.0.10-1595598123461:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36530,DS-914edfbc-acd8-4e43-8d33-ace8e314168f,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-e9afe90c-d4fc-4bc7-9d61-e5a80038a826,DISK], DatanodeInfoWithStorage[127.0.0.1:41568,DS-63abded5-82ca-491c-b102-0e327576d9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-a9a11d13-fc4f-445c-8b51-204c8191cd48,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-1d3d5730-f951-4553-bfe1-0f336b32792a,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-f187bb60-d952-4f56-9b4f-d7f1d060a43c,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-c66e4516-b783-43a9-840b-3765cfc5da37,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-da304f53-b30b-4223-9b75-696e16941b14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-10580341-172.17.0.10-1595598123461:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36530,DS-914edfbc-acd8-4e43-8d33-ace8e314168f,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-e9afe90c-d4fc-4bc7-9d61-e5a80038a826,DISK], DatanodeInfoWithStorage[127.0.0.1:41568,DS-63abded5-82ca-491c-b102-0e327576d9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-a9a11d13-fc4f-445c-8b51-204c8191cd48,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-1d3d5730-f951-4553-bfe1-0f336b32792a,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-f187bb60-d952-4f56-9b4f-d7f1d060a43c,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-c66e4516-b783-43a9-840b-3765cfc5da37,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-da304f53-b30b-4223-9b75-696e16941b14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-741092828-172.17.0.10-1595598469431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45733,DS-4123491b-ea59-4712-af08-9da598b9e912,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-34ce2049-2c8b-4d2d-badc-4c617f22bd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-ff52bc0f-e2eb-4b89-9013-d6399429b39a,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-bbc493ec-52a8-4201-affe-9e41de5b0c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-03150c2a-0535-40a7-8246-cc5e6ff57695,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-93d9124c-016a-44ae-8c9d-c1015333d161,DISK], DatanodeInfoWithStorage[127.0.0.1:34239,DS-da04a99a-d8d7-4696-b6e3-42653f9e7c29,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-379168d9-fd04-4c7d-a636-a4226093dd57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-741092828-172.17.0.10-1595598469431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45733,DS-4123491b-ea59-4712-af08-9da598b9e912,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-34ce2049-2c8b-4d2d-badc-4c617f22bd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-ff52bc0f-e2eb-4b89-9013-d6399429b39a,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-bbc493ec-52a8-4201-affe-9e41de5b0c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-03150c2a-0535-40a7-8246-cc5e6ff57695,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-93d9124c-016a-44ae-8c9d-c1015333d161,DISK], DatanodeInfoWithStorage[127.0.0.1:34239,DS-da04a99a-d8d7-4696-b6e3-42653f9e7c29,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-379168d9-fd04-4c7d-a636-a4226093dd57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1414339061-172.17.0.10-1595598577545:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45009,DS-73ff4c38-fc7b-406a-8336-895eeb1004a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41189,DS-006134a6-225c-4b7b-92c3-df3364503ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-d7c81134-0df4-4cab-8704-bdd05d34e9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41411,DS-90259b35-e552-44b5-b2d0-45466b830ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-6dcdf1db-f1d4-4708-9d14-b40a96100a10,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-63b7ea38-943c-4410-a92e-136d0c41594f,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-5ecae723-2783-4c66-904a-a805750b5378,DISK], DatanodeInfoWithStorage[127.0.0.1:39265,DS-54212905-e7e6-4f51-8296-aae8ae3dae0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1414339061-172.17.0.10-1595598577545:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45009,DS-73ff4c38-fc7b-406a-8336-895eeb1004a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41189,DS-006134a6-225c-4b7b-92c3-df3364503ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-d7c81134-0df4-4cab-8704-bdd05d34e9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41411,DS-90259b35-e552-44b5-b2d0-45466b830ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-6dcdf1db-f1d4-4708-9d14-b40a96100a10,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-63b7ea38-943c-4410-a92e-136d0c41594f,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-5ecae723-2783-4c66-904a-a805750b5378,DISK], DatanodeInfoWithStorage[127.0.0.1:39265,DS-54212905-e7e6-4f51-8296-aae8ae3dae0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-676727157-172.17.0.10-1595598842389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40670,DS-f6af1623-3a91-4828-b47e-9b3a4f201693,DISK], DatanodeInfoWithStorage[127.0.0.1:41568,DS-36fbd300-1982-4188-924a-5d1af0c8805a,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-3525bc98-dfc7-4645-911a-1b85d74bb579,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-93d11fe1-d3d4-496b-93a7-c4fb94e7f5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36365,DS-76871aed-170b-440f-8e2f-1675b77b1568,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-d1fff06c-87d0-4c09-8635-46483897dcb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-e7eb13d4-b80d-49d1-aee3-fc789a780fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42556,DS-4efe4936-6691-451f-aafd-9e95c92e2c01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-676727157-172.17.0.10-1595598842389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40670,DS-f6af1623-3a91-4828-b47e-9b3a4f201693,DISK], DatanodeInfoWithStorage[127.0.0.1:41568,DS-36fbd300-1982-4188-924a-5d1af0c8805a,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-3525bc98-dfc7-4645-911a-1b85d74bb579,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-93d11fe1-d3d4-496b-93a7-c4fb94e7f5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36365,DS-76871aed-170b-440f-8e2f-1675b77b1568,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-d1fff06c-87d0-4c09-8635-46483897dcb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-e7eb13d4-b80d-49d1-aee3-fc789a780fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42556,DS-4efe4936-6691-451f-aafd-9e95c92e2c01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1451353009-172.17.0.10-1595598935432:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35121,DS-f580c626-6c61-49c9-a52e-22258cf772db,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-07aa5353-37ee-47b5-8bf1-972354115e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-b1cc9dbb-3f66-4cfa-bbdb-076ad8ea3079,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-3bf25c00-ce15-4692-9c53-fe5cbcc73395,DISK], DatanodeInfoWithStorage[127.0.0.1:43143,DS-0525c281-f9cc-4939-9d8e-4fb1aa2a615e,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-b71e314e-5dbe-41b0-ae20-8df6622a1e53,DISK], DatanodeInfoWithStorage[127.0.0.1:42189,DS-7576118d-f8fb-47f8-b275-a4971f13a4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-61736366-122b-4559-b3a0-61808439e7b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1451353009-172.17.0.10-1595598935432:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35121,DS-f580c626-6c61-49c9-a52e-22258cf772db,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-07aa5353-37ee-47b5-8bf1-972354115e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-b1cc9dbb-3f66-4cfa-bbdb-076ad8ea3079,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-3bf25c00-ce15-4692-9c53-fe5cbcc73395,DISK], DatanodeInfoWithStorage[127.0.0.1:43143,DS-0525c281-f9cc-4939-9d8e-4fb1aa2a615e,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-b71e314e-5dbe-41b0-ae20-8df6622a1e53,DISK], DatanodeInfoWithStorage[127.0.0.1:42189,DS-7576118d-f8fb-47f8-b275-a4971f13a4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-61736366-122b-4559-b3a0-61808439e7b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2112767742-172.17.0.10-1595599044312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40793,DS-a61e1453-c348-4b87-a8e2-25a9668fd6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40193,DS-2cfb2324-fe1b-4105-a0b7-bcde166b1463,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-512f9f80-2b27-4198-b8b4-90abf4a11949,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-3777eb4b-fe61-4d8c-8332-c95533422d38,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-fc5d307d-57ed-41b2-ab10-a58491cb3d69,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-fa8a9495-a242-4b7e-a1c9-5c7b288e3343,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-ac6a2a50-1a3f-4f0a-b066-efa7e13e8947,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-4f44ec70-65db-4eff-aad1-f5d4ddbb4f07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2112767742-172.17.0.10-1595599044312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40793,DS-a61e1453-c348-4b87-a8e2-25a9668fd6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40193,DS-2cfb2324-fe1b-4105-a0b7-bcde166b1463,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-512f9f80-2b27-4198-b8b4-90abf4a11949,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-3777eb4b-fe61-4d8c-8332-c95533422d38,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-fc5d307d-57ed-41b2-ab10-a58491cb3d69,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-fa8a9495-a242-4b7e-a1c9-5c7b288e3343,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-ac6a2a50-1a3f-4f0a-b066-efa7e13e8947,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-4f44ec70-65db-4eff-aad1-f5d4ddbb4f07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1466416813-172.17.0.10-1595599207743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39232,DS-0ffd1e7a-347b-4aa3-83c2-11de64cdfec3,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-cc0879cf-5dad-4886-b29a-07062f3790d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-6e4e7584-4517-4c21-8cb2-8f3b54046627,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-8d5e7ee0-c760-40b3-b3c8-8eb21174da9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43053,DS-02fd4bef-853c-4186-8612-e26cf397e12c,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-dbe99724-730f-437c-be1e-54471276458c,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-1fd3b1c4-1e36-469e-88ef-fb4daab13a50,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-fa0609ba-fbba-4036-8f40-b29040160d68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1466416813-172.17.0.10-1595599207743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39232,DS-0ffd1e7a-347b-4aa3-83c2-11de64cdfec3,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-cc0879cf-5dad-4886-b29a-07062f3790d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-6e4e7584-4517-4c21-8cb2-8f3b54046627,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-8d5e7ee0-c760-40b3-b3c8-8eb21174da9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43053,DS-02fd4bef-853c-4186-8612-e26cf397e12c,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-dbe99724-730f-437c-be1e-54471276458c,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-1fd3b1c4-1e36-469e-88ef-fb4daab13a50,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-fa0609ba-fbba-4036-8f40-b29040160d68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-188330978-172.17.0.10-1595599241170:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46083,DS-a278756f-17b5-403a-b932-a129dff65018,DISK], DatanodeInfoWithStorage[127.0.0.1:38546,DS-aae0feea-704d-43de-bc95-dd6415c20c85,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-bf928bfc-804c-42b0-8013-5e3c45d72104,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-6d34fd6f-e922-412d-af64-2d0ac557847b,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-942d66c1-e1a6-45e5-b3d1-c37d404dd332,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-0076f681-6d58-4296-8806-e9c7418e95f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-e2eadd64-b381-463b-ba2c-4c75534e968c,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-853587ce-fe3c-45f3-b063-e8b31b12fb1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-188330978-172.17.0.10-1595599241170:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46083,DS-a278756f-17b5-403a-b932-a129dff65018,DISK], DatanodeInfoWithStorage[127.0.0.1:38546,DS-aae0feea-704d-43de-bc95-dd6415c20c85,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-bf928bfc-804c-42b0-8013-5e3c45d72104,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-6d34fd6f-e922-412d-af64-2d0ac557847b,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-942d66c1-e1a6-45e5-b3d1-c37d404dd332,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-0076f681-6d58-4296-8806-e9c7418e95f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-e2eadd64-b381-463b-ba2c-4c75534e968c,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-853587ce-fe3c-45f3-b063-e8b31b12fb1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1955458853-172.17.0.10-1595599507144:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35131,DS-3d0d70f1-7b43-457e-9bb8-57b49bafaf2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-e2905158-ea43-4f6d-ba61-9e338e516c51,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-806601e1-94db-4249-81f6-7a693c052b60,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-8e504294-22bb-465f-91b5-ccb0f117c86d,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-fd9c03a0-30f7-4a30-af3a-dcb6e5820e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-a856b60e-2e47-436d-a0db-515daea29266,DISK], DatanodeInfoWithStorage[127.0.0.1:40205,DS-740e6850-40ed-4e4d-a785-00d28dd8f85e,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-4b774780-c6da-4b56-95dc-0d01ba75cb4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1955458853-172.17.0.10-1595599507144:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35131,DS-3d0d70f1-7b43-457e-9bb8-57b49bafaf2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-e2905158-ea43-4f6d-ba61-9e338e516c51,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-806601e1-94db-4249-81f6-7a693c052b60,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-8e504294-22bb-465f-91b5-ccb0f117c86d,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-fd9c03a0-30f7-4a30-af3a-dcb6e5820e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-a856b60e-2e47-436d-a0db-515daea29266,DISK], DatanodeInfoWithStorage[127.0.0.1:40205,DS-740e6850-40ed-4e4d-a785-00d28dd8f85e,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-4b774780-c6da-4b56-95dc-0d01ba75cb4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-45674847-172.17.0.10-1595599686196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36607,DS-0c092197-d5e6-463c-bd21-a3d308545183,DISK], DatanodeInfoWithStorage[127.0.0.1:38962,DS-3576808b-a7d0-42f0-9897-67f81e8ae0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37937,DS-010bfcf3-d82e-42f6-b254-937adad0ce44,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-845220b3-6f4e-42cd-ae8a-5861694a30b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-fc813303-ed22-4e64-a209-a5e9b98bc153,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-c498a234-4473-4339-bdb4-463bfab39018,DISK], DatanodeInfoWithStorage[127.0.0.1:35473,DS-0322775c-9595-42e8-a3ca-93f8902eea07,DISK], DatanodeInfoWithStorage[127.0.0.1:38582,DS-10cbc6ea-25ab-42f0-b1ea-a9d9de6ff40b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-45674847-172.17.0.10-1595599686196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36607,DS-0c092197-d5e6-463c-bd21-a3d308545183,DISK], DatanodeInfoWithStorage[127.0.0.1:38962,DS-3576808b-a7d0-42f0-9897-67f81e8ae0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37937,DS-010bfcf3-d82e-42f6-b254-937adad0ce44,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-845220b3-6f4e-42cd-ae8a-5861694a30b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-fc813303-ed22-4e64-a209-a5e9b98bc153,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-c498a234-4473-4339-bdb4-463bfab39018,DISK], DatanodeInfoWithStorage[127.0.0.1:35473,DS-0322775c-9595-42e8-a3ca-93f8902eea07,DISK], DatanodeInfoWithStorage[127.0.0.1:38582,DS-10cbc6ea-25ab-42f0-b1ea-a9d9de6ff40b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-350779443-172.17.0.10-1595600288661:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46744,DS-ae497ac0-4bc1-4cdc-9ba3-2269d4b0f34f,DISK], DatanodeInfoWithStorage[127.0.0.1:34285,DS-ec634532-7f7e-4e3a-aba3-4cf908bdef85,DISK], DatanodeInfoWithStorage[127.0.0.1:42183,DS-3925e6c4-73b2-400d-bbe8-5f51d4ea75d7,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-8016789b-2d21-4b57-9929-5b8a5904645b,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-e556e856-3d1a-449a-acd6-8cc05880289a,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-4257ee8a-0bf1-4bd8-b052-da5eafa401e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-877e9eb1-e07d-4546-90e2-1bd0afe4dd97,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-34a5181e-2678-46d7-aa41-b88945ba55af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-350779443-172.17.0.10-1595600288661:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46744,DS-ae497ac0-4bc1-4cdc-9ba3-2269d4b0f34f,DISK], DatanodeInfoWithStorage[127.0.0.1:34285,DS-ec634532-7f7e-4e3a-aba3-4cf908bdef85,DISK], DatanodeInfoWithStorage[127.0.0.1:42183,DS-3925e6c4-73b2-400d-bbe8-5f51d4ea75d7,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-8016789b-2d21-4b57-9929-5b8a5904645b,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-e556e856-3d1a-449a-acd6-8cc05880289a,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-4257ee8a-0bf1-4bd8-b052-da5eafa401e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-877e9eb1-e07d-4546-90e2-1bd0afe4dd97,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-34a5181e-2678-46d7-aa41-b88945ba55af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1856755652-172.17.0.10-1595601433413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39034,DS-2894895d-f66c-4e10-a92f-9433e8bf8d12,DISK], DatanodeInfoWithStorage[127.0.0.1:43397,DS-b17c80a9-1f4d-4498-a262-8e46a9cf5561,DISK], DatanodeInfoWithStorage[127.0.0.1:41101,DS-829cb75b-ce8d-4acf-9c50-2dc1e4900991,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-84006eda-7801-4d6a-8334-06260d62cf7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-de77949b-dda6-4fce-b035-6cb69669a48d,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-3605e545-55a9-42e9-ad2b-8e0d08a84029,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-5988945a-fad7-487a-bc13-dcc1f7288313,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-5f1f1c71-4d6e-40ef-bb04-ed820abf614b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1856755652-172.17.0.10-1595601433413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39034,DS-2894895d-f66c-4e10-a92f-9433e8bf8d12,DISK], DatanodeInfoWithStorage[127.0.0.1:43397,DS-b17c80a9-1f4d-4498-a262-8e46a9cf5561,DISK], DatanodeInfoWithStorage[127.0.0.1:41101,DS-829cb75b-ce8d-4acf-9c50-2dc1e4900991,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-84006eda-7801-4d6a-8334-06260d62cf7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-de77949b-dda6-4fce-b035-6cb69669a48d,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-3605e545-55a9-42e9-ad2b-8e0d08a84029,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-5988945a-fad7-487a-bc13-dcc1f7288313,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-5f1f1c71-4d6e-40ef-bb04-ed820abf614b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-453677183-172.17.0.10-1595601503455:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37590,DS-b0746a8b-21c6-4992-8484-983770e4687f,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-10db65d2-68c9-4758-a874-17680fbfc734,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-b16b5a14-3117-46e1-9979-f9ec104a956e,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-9a064f8f-8609-4089-8d63-8bd9d4ef23d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-67d9697f-b622-4d0d-a824-9d9cdf2053c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-effd23cf-6f11-4486-9258-48b64bb7e7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-a51130ea-dc39-4183-a2e3-d72b2881454b,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-784a5081-d1ec-4925-98e8-a9e89db6675a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-453677183-172.17.0.10-1595601503455:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37590,DS-b0746a8b-21c6-4992-8484-983770e4687f,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-10db65d2-68c9-4758-a874-17680fbfc734,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-b16b5a14-3117-46e1-9979-f9ec104a956e,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-9a064f8f-8609-4089-8d63-8bd9d4ef23d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-67d9697f-b622-4d0d-a824-9d9cdf2053c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-effd23cf-6f11-4486-9258-48b64bb7e7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-a51130ea-dc39-4183-a2e3-d72b2881454b,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-784a5081-d1ec-4925-98e8-a9e89db6675a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1999733716-172.17.0.10-1595601860915:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40910,DS-342be7db-d942-41e2-a435-a9d2e6fcb816,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-76955edb-3073-4135-849a-e4644fb2fba8,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-9e26ea54-6467-4fba-976a-7cdf432e2287,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-2c71f71b-533c-4d65-8ad2-6d20cbed2cce,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-75126824-587b-4896-b6ba-7806da37dd97,DISK], DatanodeInfoWithStorage[127.0.0.1:45946,DS-f8c7d3bf-0427-4af9-82ce-e95d08e41c81,DISK], DatanodeInfoWithStorage[127.0.0.1:43476,DS-07d7f33c-63e6-4a5b-b253-a6ece77753de,DISK], DatanodeInfoWithStorage[127.0.0.1:38332,DS-64577035-57c9-49fd-9712-c8dc96a2eb6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1999733716-172.17.0.10-1595601860915:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40910,DS-342be7db-d942-41e2-a435-a9d2e6fcb816,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-76955edb-3073-4135-849a-e4644fb2fba8,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-9e26ea54-6467-4fba-976a-7cdf432e2287,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-2c71f71b-533c-4d65-8ad2-6d20cbed2cce,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-75126824-587b-4896-b6ba-7806da37dd97,DISK], DatanodeInfoWithStorage[127.0.0.1:45946,DS-f8c7d3bf-0427-4af9-82ce-e95d08e41c81,DISK], DatanodeInfoWithStorage[127.0.0.1:43476,DS-07d7f33c-63e6-4a5b-b253-a6ece77753de,DISK], DatanodeInfoWithStorage[127.0.0.1:38332,DS-64577035-57c9-49fd-9712-c8dc96a2eb6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1676792560-172.17.0.10-1595602440711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38959,DS-49230850-36fa-4730-8bb8-2755ae9e8ece,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-72ab65fe-8671-40be-837f-f57c114afaa9,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-3d0c4da2-908f-4680-b316-3bf6b3772912,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-fe2d8368-779a-4f6e-9c00-46950975bc52,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-0b8e06d3-3ca9-416a-bacb-57146200bb26,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-9a9153f3-52a0-474e-b2d0-4fc20595bcad,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-922c6ee6-0f3f-4e59-b868-c0bebab56055,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-ee1522c3-50cc-4e8c-9093-2b0131f6db54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1676792560-172.17.0.10-1595602440711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38959,DS-49230850-36fa-4730-8bb8-2755ae9e8ece,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-72ab65fe-8671-40be-837f-f57c114afaa9,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-3d0c4da2-908f-4680-b316-3bf6b3772912,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-fe2d8368-779a-4f6e-9c00-46950975bc52,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-0b8e06d3-3ca9-416a-bacb-57146200bb26,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-9a9153f3-52a0-474e-b2d0-4fc20595bcad,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-922c6ee6-0f3f-4e59-b868-c0bebab56055,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-ee1522c3-50cc-4e8c-9093-2b0131f6db54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1179246126-172.17.0.10-1595602553741:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33106,DS-d44b4ff2-5aeb-4195-a9d0-0739e4a14893,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-d4fe04f6-3489-4497-87f6-a1d143387364,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-e6d45226-211a-4dc1-b3af-7599d11acf42,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-88cc139d-6101-461e-adad-5cc603bd0898,DISK], DatanodeInfoWithStorage[127.0.0.1:34051,DS-213876fb-e7e0-4751-a58e-fbe3e6bc7f10,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-11266da6-bb32-42b7-bdbf-1810a16b7d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-5d9d6267-18b0-4697-aa83-aecc87b87b06,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-72d74ce3-b2ca-499d-b132-a87834faf613,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1179246126-172.17.0.10-1595602553741:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33106,DS-d44b4ff2-5aeb-4195-a9d0-0739e4a14893,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-d4fe04f6-3489-4497-87f6-a1d143387364,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-e6d45226-211a-4dc1-b3af-7599d11acf42,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-88cc139d-6101-461e-adad-5cc603bd0898,DISK], DatanodeInfoWithStorage[127.0.0.1:34051,DS-213876fb-e7e0-4751-a58e-fbe3e6bc7f10,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-11266da6-bb32-42b7-bdbf-1810a16b7d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-5d9d6267-18b0-4697-aa83-aecc87b87b06,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-72d74ce3-b2ca-499d-b132-a87834faf613,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-6011767-172.17.0.10-1595602756778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44211,DS-62071bdb-a28c-4709-a787-5feb611e509f,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-6e3ec281-1079-4da0-83e1-04dec41f1ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-0ce553ab-3a40-4459-929b-ad1e2b118f46,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-bde56855-fa3c-4495-a0d6-fb81dbf36822,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-4d2d0dca-b395-40b3-9795-f4592290756b,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-96899014-89d5-48e2-9c84-5616948d2f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-1371eb53-81f1-49b3-8c35-48f1b3b876e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-fea8f09a-9d6d-45b1-b113-831ca6968de6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-6011767-172.17.0.10-1595602756778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44211,DS-62071bdb-a28c-4709-a787-5feb611e509f,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-6e3ec281-1079-4da0-83e1-04dec41f1ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-0ce553ab-3a40-4459-929b-ad1e2b118f46,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-bde56855-fa3c-4495-a0d6-fb81dbf36822,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-4d2d0dca-b395-40b3-9795-f4592290756b,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-96899014-89d5-48e2-9c84-5616948d2f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-1371eb53-81f1-49b3-8c35-48f1b3b876e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-fea8f09a-9d6d-45b1-b113-831ca6968de6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-891033126-172.17.0.10-1595602962486:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44607,DS-2e72412c-6929-4c31-a732-ca84dddeeba4,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-4ce3dbb1-4ccc-4b5d-b6fa-1ffa736c98f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41391,DS-ccf358dd-ac11-41e5-bb48-00dce43a212b,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-999a2c33-8471-4cde-958d-00d2d947d002,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-ec8409e3-4f0c-4f64-b274-9a32a130e1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-4519dcf1-e44d-41d7-a3c5-fbb5494d04d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-db3ef784-8be2-45b3-8ff8-e3be28e6c3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-7fad8ad7-96c9-49d3-a9ad-23a68b4ad072,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-891033126-172.17.0.10-1595602962486:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44607,DS-2e72412c-6929-4c31-a732-ca84dddeeba4,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-4ce3dbb1-4ccc-4b5d-b6fa-1ffa736c98f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41391,DS-ccf358dd-ac11-41e5-bb48-00dce43a212b,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-999a2c33-8471-4cde-958d-00d2d947d002,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-ec8409e3-4f0c-4f64-b274-9a32a130e1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-4519dcf1-e44d-41d7-a3c5-fbb5494d04d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-db3ef784-8be2-45b3-8ff8-e3be28e6c3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-7fad8ad7-96c9-49d3-a9ad-23a68b4ad072,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5368
