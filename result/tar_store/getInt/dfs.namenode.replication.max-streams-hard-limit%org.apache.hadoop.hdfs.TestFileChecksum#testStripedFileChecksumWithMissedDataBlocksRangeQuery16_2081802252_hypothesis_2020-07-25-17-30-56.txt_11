reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1245262381-172.17.0.8-1595698271853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36231,DS-283e71cb-fc04-4b35-a558-cf30e03c0de8,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-0664fc24-323c-4e00-9e08-6cf1b60d0c12,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-aa79de10-b225-4e0a-a80b-5958a293e9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-598e8b6f-0e8c-4a47-aa5f-42f1757974fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-316cf8c0-b1dd-4d11-b328-783854a5917c,DISK], DatanodeInfoWithStorage[127.0.0.1:40290,DS-63ca9833-d447-4e70-91a9-250a82f6f6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42477,DS-ae75d5d4-93cf-4185-b6d3-5a3395383da3,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-4d0a09ff-2f01-4e8c-99cb-2d2d5c6c46d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1245262381-172.17.0.8-1595698271853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36231,DS-283e71cb-fc04-4b35-a558-cf30e03c0de8,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-0664fc24-323c-4e00-9e08-6cf1b60d0c12,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-aa79de10-b225-4e0a-a80b-5958a293e9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-598e8b6f-0e8c-4a47-aa5f-42f1757974fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-316cf8c0-b1dd-4d11-b328-783854a5917c,DISK], DatanodeInfoWithStorage[127.0.0.1:40290,DS-63ca9833-d447-4e70-91a9-250a82f6f6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42477,DS-ae75d5d4-93cf-4185-b6d3-5a3395383da3,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-4d0a09ff-2f01-4e8c-99cb-2d2d5c6c46d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2099917944-172.17.0.8-1595698474578:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33795,DS-7a3b984a-5c70-4c52-851c-2a367d25335f,DISK], DatanodeInfoWithStorage[127.0.0.1:34227,DS-14f5502e-d045-4fe8-9fea-3dcef78ce54a,DISK], DatanodeInfoWithStorage[127.0.0.1:44995,DS-c7c4a4c8-d97e-43bb-9319-b2d10e63647a,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-2d469241-edee-41a4-aa79-2d7324838ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-72bd81ab-56ec-41b2-8637-bf1df3882921,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-5729295d-0e1d-4282-bab2-c3764073d266,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-cc8dfb4d-313a-4780-8dfc-77a5e037d56f,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-716b22bb-f0d5-4512-92f7-096fa80cd48c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2099917944-172.17.0.8-1595698474578:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33795,DS-7a3b984a-5c70-4c52-851c-2a367d25335f,DISK], DatanodeInfoWithStorage[127.0.0.1:34227,DS-14f5502e-d045-4fe8-9fea-3dcef78ce54a,DISK], DatanodeInfoWithStorage[127.0.0.1:44995,DS-c7c4a4c8-d97e-43bb-9319-b2d10e63647a,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-2d469241-edee-41a4-aa79-2d7324838ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-72bd81ab-56ec-41b2-8637-bf1df3882921,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-5729295d-0e1d-4282-bab2-c3764073d266,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-cc8dfb4d-313a-4780-8dfc-77a5e037d56f,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-716b22bb-f0d5-4512-92f7-096fa80cd48c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-8535448-172.17.0.8-1595698601382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39104,DS-15f74e89-b4e8-4798-bd73-274155cfc2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-3fa91eb6-6894-49d2-ac6c-a2c9702253a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-4f230b14-b5e7-46f8-9a1d-d8218af67484,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-a8a1195e-a8bf-4fc9-99ba-a79ab0f46984,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-d91ccf5b-5d9b-436c-bb3b-51f219410141,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-0b43e11f-21e5-420a-a078-ea68b19cc3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-189489cc-5f72-442a-bf0a-86ab2ffa9d51,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-a44e39b4-5cae-42d6-9000-d7adbe799ba3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-8535448-172.17.0.8-1595698601382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39104,DS-15f74e89-b4e8-4798-bd73-274155cfc2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-3fa91eb6-6894-49d2-ac6c-a2c9702253a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-4f230b14-b5e7-46f8-9a1d-d8218af67484,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-a8a1195e-a8bf-4fc9-99ba-a79ab0f46984,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-d91ccf5b-5d9b-436c-bb3b-51f219410141,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-0b43e11f-21e5-420a-a078-ea68b19cc3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-189489cc-5f72-442a-bf0a-86ab2ffa9d51,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-a44e39b4-5cae-42d6-9000-d7adbe799ba3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1911932303-172.17.0.8-1595698813046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34231,DS-3061900f-315a-4570-8516-aedba475ebb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-f122c031-2083-44f6-9758-c3d443f4050d,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-1b8ffc54-24ac-4282-ab1d-ac11efa3eb47,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-c9348790-8429-4538-92fa-919476433e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-0bf74889-bed3-48ba-90c0-504ef14f68fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-cb7615c3-6554-4e97-a149-1ac467bf15f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-0f652b6e-e0b1-419c-8181-48602e3ac5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-21fd9aab-56f3-4971-b4f5-d9acabef17fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1911932303-172.17.0.8-1595698813046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34231,DS-3061900f-315a-4570-8516-aedba475ebb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-f122c031-2083-44f6-9758-c3d443f4050d,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-1b8ffc54-24ac-4282-ab1d-ac11efa3eb47,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-c9348790-8429-4538-92fa-919476433e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-0bf74889-bed3-48ba-90c0-504ef14f68fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-cb7615c3-6554-4e97-a149-1ac467bf15f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-0f652b6e-e0b1-419c-8181-48602e3ac5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-21fd9aab-56f3-4971-b4f5-d9acabef17fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-87495938-172.17.0.8-1595698961176:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43849,DS-586ce7ce-605f-4ecd-9b8e-ae95986cf2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-26859a2d-61a4-418e-856f-65965f7bf7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-8feca227-1a60-4b2d-80ad-dfc491c00d56,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-e93591e0-aec6-4174-92f4-f3c25f4a6838,DISK], DatanodeInfoWithStorage[127.0.0.1:43891,DS-05b8ab1b-9da0-4c46-a0a4-837436959a00,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-239b7d89-1075-4882-b6db-c69a172119a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43508,DS-3cce9ba7-6b97-4e72-95f0-ffdbfbfb6c24,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-818dcb46-6470-4df6-936d-09c5238aa1b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-87495938-172.17.0.8-1595698961176:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43849,DS-586ce7ce-605f-4ecd-9b8e-ae95986cf2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-26859a2d-61a4-418e-856f-65965f7bf7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-8feca227-1a60-4b2d-80ad-dfc491c00d56,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-e93591e0-aec6-4174-92f4-f3c25f4a6838,DISK], DatanodeInfoWithStorage[127.0.0.1:43891,DS-05b8ab1b-9da0-4c46-a0a4-837436959a00,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-239b7d89-1075-4882-b6db-c69a172119a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43508,DS-3cce9ba7-6b97-4e72-95f0-ffdbfbfb6c24,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-818dcb46-6470-4df6-936d-09c5238aa1b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-267613419-172.17.0.8-1595698992181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35299,DS-8682d43c-661e-49b8-a3b4-69da01b776db,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-9eb0c6aa-89d6-40bb-95c7-97f64a5855e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-735bb85c-de06-4570-91c4-eadd3cd244d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-8847614c-96e4-45ef-bef6-dc51bb13a621,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-7ad4e0ee-db57-4c6e-8a41-b2cd246de9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35902,DS-753555cd-f1db-4a93-a91c-72f7ed2015f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-fd647cb4-306c-434e-8398-a6a2cb48df6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-8e9dc2e0-55fc-45f4-815a-58f77ada3431,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-267613419-172.17.0.8-1595698992181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35299,DS-8682d43c-661e-49b8-a3b4-69da01b776db,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-9eb0c6aa-89d6-40bb-95c7-97f64a5855e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-735bb85c-de06-4570-91c4-eadd3cd244d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-8847614c-96e4-45ef-bef6-dc51bb13a621,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-7ad4e0ee-db57-4c6e-8a41-b2cd246de9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35902,DS-753555cd-f1db-4a93-a91c-72f7ed2015f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-fd647cb4-306c-434e-8398-a6a2cb48df6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-8e9dc2e0-55fc-45f4-815a-58f77ada3431,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1478889347-172.17.0.8-1595699031680:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39485,DS-a4291bc5-bd5c-44a7-8c68-fdc17a30fc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-0bb13990-c9ff-48ec-bdb5-19bc874b4727,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-cf239295-6f36-4ffa-ab6d-cc6ad7d74e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34946,DS-41d24f0c-3455-4436-b913-6d2c410466ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-bf691ec7-6342-458d-9f5b-448e983bd1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-103d3498-633f-451d-bf94-ed9aa17e6add,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-2b5ee8b5-b226-4163-903c-688fbc0c1ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-fa05ea1b-dca6-4876-b3d3-2051a0d3138e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1478889347-172.17.0.8-1595699031680:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39485,DS-a4291bc5-bd5c-44a7-8c68-fdc17a30fc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-0bb13990-c9ff-48ec-bdb5-19bc874b4727,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-cf239295-6f36-4ffa-ab6d-cc6ad7d74e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34946,DS-41d24f0c-3455-4436-b913-6d2c410466ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-bf691ec7-6342-458d-9f5b-448e983bd1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-103d3498-633f-451d-bf94-ed9aa17e6add,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-2b5ee8b5-b226-4163-903c-688fbc0c1ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-fa05ea1b-dca6-4876-b3d3-2051a0d3138e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1425897337-172.17.0.8-1595699126367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45122,DS-b13b6bab-d795-4ac5-a03b-0f6db8da59d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-28fa3be6-6b80-46c6-808f-37e39474997a,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-0fd83f24-787a-4715-8fac-e30aabcfbaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-2cd7119e-2147-442c-a782-9dcd69b11523,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-0ba8a1c3-4936-40ff-98d4-16728032161b,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-866507be-efcf-4d12-8ebd-ff8f56c2c60c,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-9055ff69-817a-45ad-b084-458a80178dab,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-9bf8e2b7-3f77-48fb-ab7b-b07853352e42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1425897337-172.17.0.8-1595699126367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45122,DS-b13b6bab-d795-4ac5-a03b-0f6db8da59d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-28fa3be6-6b80-46c6-808f-37e39474997a,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-0fd83f24-787a-4715-8fac-e30aabcfbaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-2cd7119e-2147-442c-a782-9dcd69b11523,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-0ba8a1c3-4936-40ff-98d4-16728032161b,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-866507be-efcf-4d12-8ebd-ff8f56c2c60c,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-9055ff69-817a-45ad-b084-458a80178dab,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-9bf8e2b7-3f77-48fb-ab7b-b07853352e42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-955172060-172.17.0.8-1595699265375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35107,DS-dc7eebfd-e725-4b0e-9366-6f0048915ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-f125ff1b-819a-4fa3-8efe-ad6c77d477a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-87959337-85e5-45c5-94cc-ad1c30902236,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-67dca940-a2f9-41f4-855e-4e9994ed1d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-f6050343-d5e2-4ba2-be11-83f71e145e11,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-4dc0098c-5eda-4294-a40e-b88a93a8af1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-e79432f5-87a0-4fc5-a206-170e52274611,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-f94d0d5b-1eef-41ff-8739-32dfdd3f9c0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-955172060-172.17.0.8-1595699265375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35107,DS-dc7eebfd-e725-4b0e-9366-6f0048915ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-f125ff1b-819a-4fa3-8efe-ad6c77d477a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-87959337-85e5-45c5-94cc-ad1c30902236,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-67dca940-a2f9-41f4-855e-4e9994ed1d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-f6050343-d5e2-4ba2-be11-83f71e145e11,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-4dc0098c-5eda-4294-a40e-b88a93a8af1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-e79432f5-87a0-4fc5-a206-170e52274611,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-f94d0d5b-1eef-41ff-8739-32dfdd3f9c0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1017700680-172.17.0.8-1595700248801:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35187,DS-ed52bd6e-bc94-47b6-a319-62e5b0a133f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-6334e841-d29a-4c09-9ff8-4ceac388e3be,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-521d6fe2-02f5-47b3-8f22-6740f466356f,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-9172c3f0-115a-4f24-bfd7-7196235ee0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-de7b8d75-ac5b-41e1-8b58-aad0907c7302,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-5b22b9c5-2605-426f-b0bd-c6ffb57061d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-d5b3094b-3790-4adc-bd30-157a82ee17c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-f489a88f-8975-46a6-af6f-0729e0843682,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1017700680-172.17.0.8-1595700248801:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35187,DS-ed52bd6e-bc94-47b6-a319-62e5b0a133f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-6334e841-d29a-4c09-9ff8-4ceac388e3be,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-521d6fe2-02f5-47b3-8f22-6740f466356f,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-9172c3f0-115a-4f24-bfd7-7196235ee0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-de7b8d75-ac5b-41e1-8b58-aad0907c7302,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-5b22b9c5-2605-426f-b0bd-c6ffb57061d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-d5b3094b-3790-4adc-bd30-157a82ee17c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-f489a88f-8975-46a6-af6f-0729e0843682,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1601859255-172.17.0.8-1595700725216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39042,DS-d7fd0734-1173-40d6-9c5d-5b2be5e00b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-84d794d1-a333-402b-b8c5-d26adf43e351,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-27fb1213-8621-4bc2-b2ea-acac892dd34e,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-39827fad-e04f-4cc2-a423-62e17cc0f7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-7173198b-3bec-4d38-a0fd-0dcd4dd5a209,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-dde2c49f-6251-4a42-99ea-6d06da20a613,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-594197b7-e5f8-49fb-a980-182bc62b38e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-1745e7ac-2557-49c6-8dfa-8a04e864ee2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1601859255-172.17.0.8-1595700725216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39042,DS-d7fd0734-1173-40d6-9c5d-5b2be5e00b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-84d794d1-a333-402b-b8c5-d26adf43e351,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-27fb1213-8621-4bc2-b2ea-acac892dd34e,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-39827fad-e04f-4cc2-a423-62e17cc0f7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-7173198b-3bec-4d38-a0fd-0dcd4dd5a209,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-dde2c49f-6251-4a42-99ea-6d06da20a613,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-594197b7-e5f8-49fb-a980-182bc62b38e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-1745e7ac-2557-49c6-8dfa-8a04e864ee2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-667655315-172.17.0.8-1595701858119:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46538,DS-aafb1421-5f44-4cd3-aeb0-e9e62b44b987,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-759ffc9c-3666-43f1-9a76-85706fcb86f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-35622b1b-6ae3-48c5-a870-06818fc1a722,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-27d7acaa-0fcf-483e-a0e1-2983e3182d43,DISK], DatanodeInfoWithStorage[127.0.0.1:41609,DS-b67071ed-05c0-4dd5-be79-87ec80b0c055,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-31cf9271-01b5-4ec1-a342-23345a3dfc41,DISK], DatanodeInfoWithStorage[127.0.0.1:38227,DS-66e234b8-2984-4601-9352-cdb277c498b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-ec63c07f-f797-41c7-b3b7-59deeb3e4f20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-667655315-172.17.0.8-1595701858119:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46538,DS-aafb1421-5f44-4cd3-aeb0-e9e62b44b987,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-759ffc9c-3666-43f1-9a76-85706fcb86f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-35622b1b-6ae3-48c5-a870-06818fc1a722,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-27d7acaa-0fcf-483e-a0e1-2983e3182d43,DISK], DatanodeInfoWithStorage[127.0.0.1:41609,DS-b67071ed-05c0-4dd5-be79-87ec80b0c055,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-31cf9271-01b5-4ec1-a342-23345a3dfc41,DISK], DatanodeInfoWithStorage[127.0.0.1:38227,DS-66e234b8-2984-4601-9352-cdb277c498b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-ec63c07f-f797-41c7-b3b7-59deeb3e4f20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1231217399-172.17.0.8-1595702090350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42465,DS-7b935998-80e6-47dc-84ce-dc17ea912484,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-a9e35cb4-b9ec-484d-b90a-e4a4ef3849dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-baf8b228-1a97-4754-ba05-7e98676ec0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-e32c1e34-337a-4e99-bd1c-df0f4b2565e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-62fa2f15-e612-4e5b-bc71-8e50f3029cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-f8247824-246e-4f5f-8241-a76224918afa,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-bb9deaa9-dba4-44c7-a86a-15334ed3b204,DISK], DatanodeInfoWithStorage[127.0.0.1:41505,DS-d0736596-5fd3-432b-affb-ff961c2295f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1231217399-172.17.0.8-1595702090350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42465,DS-7b935998-80e6-47dc-84ce-dc17ea912484,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-a9e35cb4-b9ec-484d-b90a-e4a4ef3849dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-baf8b228-1a97-4754-ba05-7e98676ec0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-e32c1e34-337a-4e99-bd1c-df0f4b2565e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-62fa2f15-e612-4e5b-bc71-8e50f3029cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-f8247824-246e-4f5f-8241-a76224918afa,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-bb9deaa9-dba4-44c7-a86a-15334ed3b204,DISK], DatanodeInfoWithStorage[127.0.0.1:41505,DS-d0736596-5fd3-432b-affb-ff961c2295f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1121943948-172.17.0.8-1595702598426:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32912,DS-96447372-e44b-4349-a275-23e8e07b409e,DISK], DatanodeInfoWithStorage[127.0.0.1:34698,DS-b99eb55f-247a-4ef0-af79-778d43572874,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-b4cc5348-6f10-4e69-a25e-8b3dc90b5225,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-436b41ac-69d2-455f-8870-49fbcd6475a0,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-1b1d6559-eb49-4356-a8ed-fe174b354d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33272,DS-2c957aa6-b630-495b-ba9f-c1b4f36c4597,DISK], DatanodeInfoWithStorage[127.0.0.1:43879,DS-07f62480-cb78-4b21-b06d-d0e64513e4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-af384186-ea00-4758-a8cf-0076256a84da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1121943948-172.17.0.8-1595702598426:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32912,DS-96447372-e44b-4349-a275-23e8e07b409e,DISK], DatanodeInfoWithStorage[127.0.0.1:34698,DS-b99eb55f-247a-4ef0-af79-778d43572874,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-b4cc5348-6f10-4e69-a25e-8b3dc90b5225,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-436b41ac-69d2-455f-8870-49fbcd6475a0,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-1b1d6559-eb49-4356-a8ed-fe174b354d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33272,DS-2c957aa6-b630-495b-ba9f-c1b4f36c4597,DISK], DatanodeInfoWithStorage[127.0.0.1:43879,DS-07f62480-cb78-4b21-b06d-d0e64513e4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-af384186-ea00-4758-a8cf-0076256a84da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1721031062-172.17.0.8-1595703294936:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39723,DS-b0440087-6192-411a-8e1b-6aecf439d663,DISK], DatanodeInfoWithStorage[127.0.0.1:36634,DS-6e1cd03a-a56f-44bf-a300-88bb7600a5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-659d62ea-2b95-4c35-9356-e5dd022d67f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39609,DS-d86fb16f-bfc6-47ee-98f6-7463f4c428ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-f0459447-1226-4253-8b53-6249432508f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34674,DS-fb2f8b18-5f6f-45a0-ab08-0768a9d2e06b,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-033fc793-5205-4c8c-b0a4-ac081a454afd,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-a292243c-ba76-4972-8e62-3a1b66d02cd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1721031062-172.17.0.8-1595703294936:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39723,DS-b0440087-6192-411a-8e1b-6aecf439d663,DISK], DatanodeInfoWithStorage[127.0.0.1:36634,DS-6e1cd03a-a56f-44bf-a300-88bb7600a5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-659d62ea-2b95-4c35-9356-e5dd022d67f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39609,DS-d86fb16f-bfc6-47ee-98f6-7463f4c428ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-f0459447-1226-4253-8b53-6249432508f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34674,DS-fb2f8b18-5f6f-45a0-ab08-0768a9d2e06b,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-033fc793-5205-4c8c-b0a4-ac081a454afd,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-a292243c-ba76-4972-8e62-3a1b66d02cd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams-hard-limit
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-40118229-172.17.0.8-1595703366704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35969,DS-c47c8eb4-bbbd-470a-9351-3b2995cd61b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-4a61fc3a-b61c-45bc-9dfa-be94a2cf2fae,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-05e49c8c-f334-41ce-9647-f67a63ab78af,DISK], DatanodeInfoWithStorage[127.0.0.1:43847,DS-d72254a4-617f-4ab6-9d4b-f488c73b3fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-ba17adb9-e45a-41eb-b8e0-39e108a41739,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-82976696-8355-4586-b29c-129834e807f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-ef78209e-9041-4427-9353-c43dc0decf63,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-79db70e0-c7be-4117-8f07-822d05c903a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-40118229-172.17.0.8-1595703366704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35969,DS-c47c8eb4-bbbd-470a-9351-3b2995cd61b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-4a61fc3a-b61c-45bc-9dfa-be94a2cf2fae,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-05e49c8c-f334-41ce-9647-f67a63ab78af,DISK], DatanodeInfoWithStorage[127.0.0.1:43847,DS-d72254a4-617f-4ab6-9d4b-f488c73b3fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-ba17adb9-e45a-41eb-b8e0-39e108a41739,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-82976696-8355-4586-b29c-129834e807f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-ef78209e-9041-4427-9353-c43dc0decf63,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-79db70e0-c7be-4117-8f07-822d05c903a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5197
