reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1932142361-172.17.0.21-1595599253787:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35961,DS-4423a936-185e-41c3-947e-9446ca88576d,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-30b54ab2-54e5-497c-b95c-9de4196bfa38,DISK], DatanodeInfoWithStorage[127.0.0.1:45655,DS-ef6a2745-842c-4974-b921-0eb7b1d1b206,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-36f050d9-2091-4e0c-9f76-15190cf481f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-e4acb348-17ce-47a1-bbe8-b957d8c2857c,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-17140a70-3727-435d-bdee-b22687c7cf0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-3acefe5d-7e4e-4887-a116-74e3d1b57e63,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-3a59880e-7ab1-413d-803e-b6be8aa56873,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1932142361-172.17.0.21-1595599253787:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35961,DS-4423a936-185e-41c3-947e-9446ca88576d,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-30b54ab2-54e5-497c-b95c-9de4196bfa38,DISK], DatanodeInfoWithStorage[127.0.0.1:45655,DS-ef6a2745-842c-4974-b921-0eb7b1d1b206,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-36f050d9-2091-4e0c-9f76-15190cf481f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-e4acb348-17ce-47a1-bbe8-b957d8c2857c,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-17140a70-3727-435d-bdee-b22687c7cf0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-3acefe5d-7e4e-4887-a116-74e3d1b57e63,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-3a59880e-7ab1-413d-803e-b6be8aa56873,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-692441427-172.17.0.21-1595599358655:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45248,DS-3d3a27ee-8dcc-471a-8239-566a41346f04,DISK], DatanodeInfoWithStorage[127.0.0.1:41942,DS-9c977ec7-e71f-4cb7-8d25-6e873c61b028,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-cf194bd3-311a-4da1-9390-1d9b7d0523f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43172,DS-ff9b95a9-e672-4b51-b867-c3de030d1bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-1fe73076-201f-4403-abfc-418f8c73c97a,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-4de36551-76ef-4e72-9b4b-ab9c0dfe01f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-671c4fec-a9d5-44ac-a97e-753c33fd2ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-00469a96-ec99-4f8b-afbf-4ba28b60e5c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-692441427-172.17.0.21-1595599358655:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45248,DS-3d3a27ee-8dcc-471a-8239-566a41346f04,DISK], DatanodeInfoWithStorage[127.0.0.1:41942,DS-9c977ec7-e71f-4cb7-8d25-6e873c61b028,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-cf194bd3-311a-4da1-9390-1d9b7d0523f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43172,DS-ff9b95a9-e672-4b51-b867-c3de030d1bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-1fe73076-201f-4403-abfc-418f8c73c97a,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-4de36551-76ef-4e72-9b4b-ab9c0dfe01f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-671c4fec-a9d5-44ac-a97e-753c33fd2ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-00469a96-ec99-4f8b-afbf-4ba28b60e5c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1467515781-172.17.0.21-1595599470142:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46567,DS-103595d7-a6b3-4fc2-a1a3-fd0d58dd1ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:38706,DS-2bffed02-90bc-4a65-8ac9-3d75b357b36a,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-f372ee86-8b61-4d63-a64e-4796d05745c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-b9c9a229-c2ac-4af0-a6b9-e8c10ee1adf4,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-d71cfe43-7c30-44eb-b50f-c8383290b97d,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-8fe5c4e9-584b-4e21-b3fb-a518f3bc75f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-0cae284c-31a5-4a34-b56e-aab5191a1564,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-17d394a4-6c4e-4533-ae95-b29542dbf486,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1467515781-172.17.0.21-1595599470142:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46567,DS-103595d7-a6b3-4fc2-a1a3-fd0d58dd1ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:38706,DS-2bffed02-90bc-4a65-8ac9-3d75b357b36a,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-f372ee86-8b61-4d63-a64e-4796d05745c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-b9c9a229-c2ac-4af0-a6b9-e8c10ee1adf4,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-d71cfe43-7c30-44eb-b50f-c8383290b97d,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-8fe5c4e9-584b-4e21-b3fb-a518f3bc75f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-0cae284c-31a5-4a34-b56e-aab5191a1564,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-17d394a4-6c4e-4533-ae95-b29542dbf486,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-189059652-172.17.0.21-1595599698056:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40855,DS-e3d2b6dc-5b85-4c75-9404-04d10620b8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-a1a8cb15-3881-416e-96fc-dd478d1a9048,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-1dc18991-8b18-40b4-897d-1fc9f28fe1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-e89144c4-e9ee-45fd-b872-5967dfdc5d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-2105b3d5-2af5-4191-84dc-7202aa2be283,DISK], DatanodeInfoWithStorage[127.0.0.1:41015,DS-aaa6eed1-2466-4d7c-9f18-89217ae5609f,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-674fae47-8ca8-4aab-a82d-b4e2d92e6360,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-7580e857-164c-4fe6-9d0d-1a55b661d1d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-189059652-172.17.0.21-1595599698056:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40855,DS-e3d2b6dc-5b85-4c75-9404-04d10620b8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-a1a8cb15-3881-416e-96fc-dd478d1a9048,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-1dc18991-8b18-40b4-897d-1fc9f28fe1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-e89144c4-e9ee-45fd-b872-5967dfdc5d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-2105b3d5-2af5-4191-84dc-7202aa2be283,DISK], DatanodeInfoWithStorage[127.0.0.1:41015,DS-aaa6eed1-2466-4d7c-9f18-89217ae5609f,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-674fae47-8ca8-4aab-a82d-b4e2d92e6360,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-7580e857-164c-4fe6-9d0d-1a55b661d1d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-155228458-172.17.0.21-1595600609040:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36817,DS-ec3b493b-7c7d-41fc-acad-29c00e92562f,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-844eeddb-beaa-46db-81f6-a2f16da43da9,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-a90f2bf2-4ab3-4dfd-b52f-ae4fdb3c5bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-5bcf404b-dce7-4ac7-b128-71dafd8d4ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-8db54f14-b0fb-450d-b252-b674b8d72d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-bbd78a3e-8527-486e-8d87-cb6f9ef6999d,DISK], DatanodeInfoWithStorage[127.0.0.1:44631,DS-90b8e4f3-e9d9-4bcb-932c-6c19bb540ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:40587,DS-0de8663f-f2e0-47ec-8c28-fb371360e550,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-155228458-172.17.0.21-1595600609040:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36817,DS-ec3b493b-7c7d-41fc-acad-29c00e92562f,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-844eeddb-beaa-46db-81f6-a2f16da43da9,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-a90f2bf2-4ab3-4dfd-b52f-ae4fdb3c5bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-5bcf404b-dce7-4ac7-b128-71dafd8d4ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-8db54f14-b0fb-450d-b252-b674b8d72d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-bbd78a3e-8527-486e-8d87-cb6f9ef6999d,DISK], DatanodeInfoWithStorage[127.0.0.1:44631,DS-90b8e4f3-e9d9-4bcb-932c-6c19bb540ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:40587,DS-0de8663f-f2e0-47ec-8c28-fb371360e550,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-611922352-172.17.0.21-1595600824370:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34206,DS-8c35a7d9-acd3-406b-8638-d2a2b4738eff,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-69076c9a-d104-4ac5-8205-8af79cea6372,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-201b2a78-0a0a-4b8d-91a6-2330a8194052,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-f4f795a1-3f01-4535-990e-b388858429fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-900533f3-f4a9-4cc3-be9e-4fcc1a2e10dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-1b205328-e4f7-41b2-a75f-a67fbdc12929,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-0ef15c6b-9ec3-4c59-8a64-ae54f05e0260,DISK], DatanodeInfoWithStorage[127.0.0.1:35087,DS-7e29d367-3f34-42d9-b25a-41513e097783,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-611922352-172.17.0.21-1595600824370:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34206,DS-8c35a7d9-acd3-406b-8638-d2a2b4738eff,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-69076c9a-d104-4ac5-8205-8af79cea6372,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-201b2a78-0a0a-4b8d-91a6-2330a8194052,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-f4f795a1-3f01-4535-990e-b388858429fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-900533f3-f4a9-4cc3-be9e-4fcc1a2e10dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-1b205328-e4f7-41b2-a75f-a67fbdc12929,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-0ef15c6b-9ec3-4c59-8a64-ae54f05e0260,DISK], DatanodeInfoWithStorage[127.0.0.1:35087,DS-7e29d367-3f34-42d9-b25a-41513e097783,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1606579486-172.17.0.21-1595601191406:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41808,DS-f8a978db-7ece-467a-8172-9bc90426b678,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-fb299572-4d07-4933-8a79-0a03a6899dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-c591af07-3006-4ee9-b73d-66089dfa5614,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-b62219f7-2268-43b9-a813-a7e1121fac35,DISK], DatanodeInfoWithStorage[127.0.0.1:38427,DS-902ed211-083f-475e-89d9-3a1bfe78246d,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-8109d473-999a-4b0d-b2f8-c21441c301a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-41a918df-b864-46d0-a660-8e32cfed699f,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-60921319-1842-4984-b1c2-2e66968da771,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1606579486-172.17.0.21-1595601191406:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41808,DS-f8a978db-7ece-467a-8172-9bc90426b678,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-fb299572-4d07-4933-8a79-0a03a6899dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-c591af07-3006-4ee9-b73d-66089dfa5614,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-b62219f7-2268-43b9-a813-a7e1121fac35,DISK], DatanodeInfoWithStorage[127.0.0.1:38427,DS-902ed211-083f-475e-89d9-3a1bfe78246d,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-8109d473-999a-4b0d-b2f8-c21441c301a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-41a918df-b864-46d0-a660-8e32cfed699f,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-60921319-1842-4984-b1c2-2e66968da771,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1537351217-172.17.0.21-1595601258044:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44329,DS-373ce94a-9c01-4181-b039-722808ee40aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-e75ca97c-b8d3-43c3-9781-64b2952e5164,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-1a619d20-1ffe-4928-9a69-b8daa1bee3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-9ed2c42f-ce92-4549-808b-0234033fa682,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-384efac2-bbbe-42fb-a057-16b3bda6ffcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45164,DS-09dbab1c-d4eb-43a5-a22e-5241a6431ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-7014eae2-b671-424d-9d0d-592e8c3e2d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-c6c3f900-82ee-4970-b0ab-b6960d3ce74d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1537351217-172.17.0.21-1595601258044:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44329,DS-373ce94a-9c01-4181-b039-722808ee40aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-e75ca97c-b8d3-43c3-9781-64b2952e5164,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-1a619d20-1ffe-4928-9a69-b8daa1bee3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-9ed2c42f-ce92-4549-808b-0234033fa682,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-384efac2-bbbe-42fb-a057-16b3bda6ffcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45164,DS-09dbab1c-d4eb-43a5-a22e-5241a6431ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-7014eae2-b671-424d-9d0d-592e8c3e2d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-c6c3f900-82ee-4970-b0ab-b6960d3ce74d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1325175921-172.17.0.21-1595601326519:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33757,DS-8025d925-9010-4ef6-9dde-279999187be3,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-0d0170ea-a0e9-4bcc-9daa-813045cd354c,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-484f08f0-f86b-4564-8f8f-7d5d3fe7ecc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-ab632028-c26f-46d6-adec-af84235ad584,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-deedb3cd-5ba6-4b01-8298-6b1f3b057562,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-9ee64786-a075-4c76-a512-fb7261d1e2d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-114f0623-e124-480c-b10f-c404362623ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-4c51f0f9-c2bc-4adc-9e0e-8c92434cae56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1325175921-172.17.0.21-1595601326519:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33757,DS-8025d925-9010-4ef6-9dde-279999187be3,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-0d0170ea-a0e9-4bcc-9daa-813045cd354c,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-484f08f0-f86b-4564-8f8f-7d5d3fe7ecc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-ab632028-c26f-46d6-adec-af84235ad584,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-deedb3cd-5ba6-4b01-8298-6b1f3b057562,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-9ee64786-a075-4c76-a512-fb7261d1e2d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-114f0623-e124-480c-b10f-c404362623ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-4c51f0f9-c2bc-4adc-9e0e-8c92434cae56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-673381670-172.17.0.21-1595601422737:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32841,DS-adc729e8-fd68-484e-b1c0-3bb6c391e648,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-aa4d1c96-c518-4f10-ab01-43adf2dd4811,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-60637b79-0f25-49bf-a5e3-073b1cae9176,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-b589b38d-52a1-466c-bcd7-54d27a319270,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-b42408e6-6909-4a09-bb37-df581c0b3e45,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-652f21aa-01ff-4022-8e31-3dfee4a159a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-a5602bcd-1e0f-4d5b-b031-7167fd3d0773,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-58c499a0-a95e-4fae-b656-7b4abe6313a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-673381670-172.17.0.21-1595601422737:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32841,DS-adc729e8-fd68-484e-b1c0-3bb6c391e648,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-aa4d1c96-c518-4f10-ab01-43adf2dd4811,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-60637b79-0f25-49bf-a5e3-073b1cae9176,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-b589b38d-52a1-466c-bcd7-54d27a319270,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-b42408e6-6909-4a09-bb37-df581c0b3e45,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-652f21aa-01ff-4022-8e31-3dfee4a159a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-a5602bcd-1e0f-4d5b-b031-7167fd3d0773,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-58c499a0-a95e-4fae-b656-7b4abe6313a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1392679687-172.17.0.21-1595601667717:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33102,DS-ca8ee9cf-7747-42cd-83f8-7100d2039272,DISK], DatanodeInfoWithStorage[127.0.0.1:41942,DS-8f7d16a7-ad9c-4919-bd26-6dbfb1c23f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-c913858b-3a3c-4c81-91a9-fa1c16ee32d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-cc5e35e5-12c1-4493-ae04-fd00acf44c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-68f4ba9f-6353-4055-8002-0c2f63da17bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43098,DS-e43f686e-6c65-4979-9cf6-69130db8ac62,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-9452351a-0f7f-417f-9148-f4c94f477f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40393,DS-c00bbd1c-642b-4562-9bd4-b4d6aa78ebeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1392679687-172.17.0.21-1595601667717:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33102,DS-ca8ee9cf-7747-42cd-83f8-7100d2039272,DISK], DatanodeInfoWithStorage[127.0.0.1:41942,DS-8f7d16a7-ad9c-4919-bd26-6dbfb1c23f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-c913858b-3a3c-4c81-91a9-fa1c16ee32d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-cc5e35e5-12c1-4493-ae04-fd00acf44c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-68f4ba9f-6353-4055-8002-0c2f63da17bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43098,DS-e43f686e-6c65-4979-9cf6-69130db8ac62,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-9452351a-0f7f-417f-9148-f4c94f477f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40393,DS-c00bbd1c-642b-4562-9bd4-b4d6aa78ebeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1084877427-172.17.0.21-1595602180725:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44054,DS-ced15152-435b-4f63-8778-bd318b8afb14,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-f6fd2382-2882-4357-bdf4-42850f72fed2,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-8a2d4dba-1df5-4183-b244-d8174a6a035f,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-efc2f837-1071-4e57-9b24-bb748b0d7b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38190,DS-cb86ecbe-9837-4cb7-810c-c18282e86b94,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-61110b3c-bb24-4c5f-9be0-822e88c1bb45,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-1a3a69a7-4cfb-4ca8-a0d0-9e6a4d3c616c,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-f20e1ffd-08d4-4752-9b70-f292eea19a5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1084877427-172.17.0.21-1595602180725:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44054,DS-ced15152-435b-4f63-8778-bd318b8afb14,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-f6fd2382-2882-4357-bdf4-42850f72fed2,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-8a2d4dba-1df5-4183-b244-d8174a6a035f,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-efc2f837-1071-4e57-9b24-bb748b0d7b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38190,DS-cb86ecbe-9837-4cb7-810c-c18282e86b94,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-61110b3c-bb24-4c5f-9be0-822e88c1bb45,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-1a3a69a7-4cfb-4ca8-a0d0-9e6a4d3c616c,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-f20e1ffd-08d4-4752-9b70-f292eea19a5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1042667336-172.17.0.21-1595602738272:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44424,DS-1ddd6702-e8d1-4012-a3ec-658ba1e10e83,DISK], DatanodeInfoWithStorage[127.0.0.1:34596,DS-ca267fd4-d8ac-4741-bcbf-1c16be56b22b,DISK], DatanodeInfoWithStorage[127.0.0.1:37790,DS-c7aa5046-d41c-4ac8-9030-ce8adb959ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-212ced3a-6000-42d8-b894-84649902b3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-ca00dbf6-88ce-4149-8a77-ae56330132a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-6d127e07-ed29-4e5c-8978-2c5e75717b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41728,DS-3fcc7bf7-7468-494e-acdf-b48cc7237328,DISK], DatanodeInfoWithStorage[127.0.0.1:44482,DS-554ba517-17cc-465e-a26f-71282710c56c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1042667336-172.17.0.21-1595602738272:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44424,DS-1ddd6702-e8d1-4012-a3ec-658ba1e10e83,DISK], DatanodeInfoWithStorage[127.0.0.1:34596,DS-ca267fd4-d8ac-4741-bcbf-1c16be56b22b,DISK], DatanodeInfoWithStorage[127.0.0.1:37790,DS-c7aa5046-d41c-4ac8-9030-ce8adb959ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-212ced3a-6000-42d8-b894-84649902b3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-ca00dbf6-88ce-4149-8a77-ae56330132a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-6d127e07-ed29-4e5c-8978-2c5e75717b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41728,DS-3fcc7bf7-7468-494e-acdf-b48cc7237328,DISK], DatanodeInfoWithStorage[127.0.0.1:44482,DS-554ba517-17cc-465e-a26f-71282710c56c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-82000059-172.17.0.21-1595603047146:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36317,DS-c9bcc60c-defe-43c0-b645-697f8941a557,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-2d8ede5b-7d1b-4506-bfa1-3debde36c23b,DISK], DatanodeInfoWithStorage[127.0.0.1:46449,DS-51ba813f-ede3-47a6-babd-910c3902a545,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-a90d5133-2acf-4ed6-b906-7a6c5147ce61,DISK], DatanodeInfoWithStorage[127.0.0.1:44514,DS-1c431901-5fd5-476b-bed0-3895fe9976e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46430,DS-be31c937-8eff-46aa-95d9-a629b4c721b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-34e997e2-7e78-483b-b2b2-c311c349b81a,DISK], DatanodeInfoWithStorage[127.0.0.1:41862,DS-a9a6396a-f2f8-4bc9-88f5-90e3a64e0d66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-82000059-172.17.0.21-1595603047146:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36317,DS-c9bcc60c-defe-43c0-b645-697f8941a557,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-2d8ede5b-7d1b-4506-bfa1-3debde36c23b,DISK], DatanodeInfoWithStorage[127.0.0.1:46449,DS-51ba813f-ede3-47a6-babd-910c3902a545,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-a90d5133-2acf-4ed6-b906-7a6c5147ce61,DISK], DatanodeInfoWithStorage[127.0.0.1:44514,DS-1c431901-5fd5-476b-bed0-3895fe9976e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46430,DS-be31c937-8eff-46aa-95d9-a629b4c721b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-34e997e2-7e78-483b-b2b2-c311c349b81a,DISK], DatanodeInfoWithStorage[127.0.0.1:41862,DS-a9a6396a-f2f8-4bc9-88f5-90e3a64e0d66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-42161599-172.17.0.21-1595603220112:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40686,DS-797c89e6-b332-477b-bcd7-1dd1d184649a,DISK], DatanodeInfoWithStorage[127.0.0.1:38706,DS-b792da10-ab51-45b0-a2ee-1f1c8484632d,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-12a6202d-8eb8-4050-91d7-56ee5d442d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-3338606c-867e-4476-9575-bf36a0ed8ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-2b1eba44-ff06-4e7f-823b-aca18e7f2669,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-374100f7-5f2f-45e9-9608-042eab93c0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-1df8120f-3ea9-4060-bacb-a5cb02dc2bef,DISK], DatanodeInfoWithStorage[127.0.0.1:37108,DS-c0942cba-3d36-41bd-8555-d9a4ec4abd3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-42161599-172.17.0.21-1595603220112:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40686,DS-797c89e6-b332-477b-bcd7-1dd1d184649a,DISK], DatanodeInfoWithStorage[127.0.0.1:38706,DS-b792da10-ab51-45b0-a2ee-1f1c8484632d,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-12a6202d-8eb8-4050-91d7-56ee5d442d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-3338606c-867e-4476-9575-bf36a0ed8ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-2b1eba44-ff06-4e7f-823b-aca18e7f2669,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-374100f7-5f2f-45e9-9608-042eab93c0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-1df8120f-3ea9-4060-bacb-a5cb02dc2bef,DISK], DatanodeInfoWithStorage[127.0.0.1:37108,DS-c0942cba-3d36-41bd-8555-d9a4ec4abd3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-103083562-172.17.0.21-1595603603075:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42936,DS-8fd9edda-7823-45f5-ac79-9c1760cdd3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-661e8d4b-53c3-45e2-884d-be10d1fd0852,DISK], DatanodeInfoWithStorage[127.0.0.1:45065,DS-69cc9eb8-97de-44d2-893c-f4ffec8da7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44542,DS-818fd40c-a430-43d4-9d45-ffd40e760e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-2a738566-67a5-4c4a-928c-45588a6dcd06,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-41e8dc70-b750-4885-af67-b317a09072f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-1c61a8a0-150d-42a1-951a-2485909ebe1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-9b659034-ffa1-4725-b8f3-0d8f73296c2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-103083562-172.17.0.21-1595603603075:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42936,DS-8fd9edda-7823-45f5-ac79-9c1760cdd3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-661e8d4b-53c3-45e2-884d-be10d1fd0852,DISK], DatanodeInfoWithStorage[127.0.0.1:45065,DS-69cc9eb8-97de-44d2-893c-f4ffec8da7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44542,DS-818fd40c-a430-43d4-9d45-ffd40e760e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-2a738566-67a5-4c4a-928c-45588a6dcd06,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-41e8dc70-b750-4885-af67-b317a09072f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-1c61a8a0-150d-42a1-951a-2485909ebe1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-9b659034-ffa1-4725-b8f3-0d8f73296c2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-308368282-172.17.0.21-1595603710383:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44172,DS-4e957111-00b1-4126-9325-e96ee5bf9be7,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-3ff34b76-d599-4de7-9df3-c456f3acdd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-f0dddd87-158a-4de1-895c-0e16abb79cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-2955a2e5-d868-46c6-ac36-0f5a8dcd3d37,DISK], DatanodeInfoWithStorage[127.0.0.1:43980,DS-f26a656d-1436-4745-b473-0208a7c468bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38745,DS-33b55d78-6878-49ae-ace7-3323b2867e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-31d83be6-b5ab-4911-bd57-df50ee73cf29,DISK], DatanodeInfoWithStorage[127.0.0.1:34199,DS-2be18eca-8623-4d85-867c-af9d164bd2f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-308368282-172.17.0.21-1595603710383:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44172,DS-4e957111-00b1-4126-9325-e96ee5bf9be7,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-3ff34b76-d599-4de7-9df3-c456f3acdd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-f0dddd87-158a-4de1-895c-0e16abb79cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-2955a2e5-d868-46c6-ac36-0f5a8dcd3d37,DISK], DatanodeInfoWithStorage[127.0.0.1:43980,DS-f26a656d-1436-4745-b473-0208a7c468bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38745,DS-33b55d78-6878-49ae-ace7-3323b2867e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-31d83be6-b5ab-4911-bd57-df50ee73cf29,DISK], DatanodeInfoWithStorage[127.0.0.1:34199,DS-2be18eca-8623-4d85-867c-af9d164bd2f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-166287742-172.17.0.21-1595603749716:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41368,DS-fdd2d6cc-ac10-4102-bf24-9a48ba9e964a,DISK], DatanodeInfoWithStorage[127.0.0.1:37420,DS-3739cd38-c632-4f06-bbbd-e35879ab34e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-dea33348-4702-4f2d-8060-dec2a190daf7,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-7eb8c7a1-db1e-4d83-a579-4704ea775ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-e0e2592e-e55f-42db-84c1-79998301b407,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-a8135fb5-b5db-493d-a4bf-cc08c376b9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-0c5f080e-8848-4bf9-b121-8ba659cb0f44,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-773d0af1-af9a-4521-84f3-8fd1d884754c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-166287742-172.17.0.21-1595603749716:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41368,DS-fdd2d6cc-ac10-4102-bf24-9a48ba9e964a,DISK], DatanodeInfoWithStorage[127.0.0.1:37420,DS-3739cd38-c632-4f06-bbbd-e35879ab34e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-dea33348-4702-4f2d-8060-dec2a190daf7,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-7eb8c7a1-db1e-4d83-a579-4704ea775ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-e0e2592e-e55f-42db-84c1-79998301b407,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-a8135fb5-b5db-493d-a4bf-cc08c376b9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-0c5f080e-8848-4bf9-b121-8ba659cb0f44,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-773d0af1-af9a-4521-84f3-8fd1d884754c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1678078169-172.17.0.21-1595603856717:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33918,DS-171de038-eec3-4083-a137-956df8b13809,DISK], DatanodeInfoWithStorage[127.0.0.1:44069,DS-66bcc522-9a28-4050-bf99-b8365e63d359,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-16a5387e-f38d-44b0-a660-beb04db54015,DISK], DatanodeInfoWithStorage[127.0.0.1:43981,DS-9a567c13-91a8-4563-bc4d-c9239d428f39,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-38d0c62f-b85e-4b48-a112-bed09266f480,DISK], DatanodeInfoWithStorage[127.0.0.1:43383,DS-2dad42dc-6d49-4604-8f51-4e2ff21933ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-2e1d0f6a-6785-4dad-b48e-c1332b2e1856,DISK], DatanodeInfoWithStorage[127.0.0.1:46828,DS-07daf642-e26f-47be-ba58-f63c6cf51523,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1678078169-172.17.0.21-1595603856717:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33918,DS-171de038-eec3-4083-a137-956df8b13809,DISK], DatanodeInfoWithStorage[127.0.0.1:44069,DS-66bcc522-9a28-4050-bf99-b8365e63d359,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-16a5387e-f38d-44b0-a660-beb04db54015,DISK], DatanodeInfoWithStorage[127.0.0.1:43981,DS-9a567c13-91a8-4563-bc4d-c9239d428f39,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-38d0c62f-b85e-4b48-a112-bed09266f480,DISK], DatanodeInfoWithStorage[127.0.0.1:43383,DS-2dad42dc-6d49-4604-8f51-4e2ff21933ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-2e1d0f6a-6785-4dad-b48e-c1332b2e1856,DISK], DatanodeInfoWithStorage[127.0.0.1:46828,DS-07daf642-e26f-47be-ba58-f63c6cf51523,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5098
