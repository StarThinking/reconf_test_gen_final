reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1953970752-172.17.0.6-1595701941578:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43690,DS-6e435ed8-9f88-4eb7-9006-71e9df2d402e,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-a0382e26-b70b-42cb-8bff-66e6e5700c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-6c80cd1a-b68e-4832-8d5d-b9a0a6964b19,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-c3ae8c41-cf9e-495e-b9bf-e20f01094f29,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-cff9b2c6-8113-40d8-9e29-114476655896,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-bbc4b73c-0c15-428b-90ca-3662e3f8387f,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-75492e74-7cb6-46e5-b970-d60a8fd54a55,DISK], DatanodeInfoWithStorage[127.0.0.1:35284,DS-4c75d8d2-3466-446d-be18-3d3201e7fd8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1953970752-172.17.0.6-1595701941578:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43690,DS-6e435ed8-9f88-4eb7-9006-71e9df2d402e,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-a0382e26-b70b-42cb-8bff-66e6e5700c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-6c80cd1a-b68e-4832-8d5d-b9a0a6964b19,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-c3ae8c41-cf9e-495e-b9bf-e20f01094f29,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-cff9b2c6-8113-40d8-9e29-114476655896,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-bbc4b73c-0c15-428b-90ca-3662e3f8387f,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-75492e74-7cb6-46e5-b970-d60a8fd54a55,DISK], DatanodeInfoWithStorage[127.0.0.1:35284,DS-4c75d8d2-3466-446d-be18-3d3201e7fd8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1646814225-172.17.0.6-1595702143850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43631,DS-37aa54d2-bdab-48a7-abab-b9117ba4af72,DISK], DatanodeInfoWithStorage[127.0.0.1:41515,DS-d4bedd2c-88ea-4a99-b845-76119872f7de,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-5a23f65a-1b9e-412e-b1d6-5124fe8c4258,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-698ba923-d583-4604-8c81-86c2adc32827,DISK], DatanodeInfoWithStorage[127.0.0.1:41288,DS-ae34686f-b39b-4eb3-817d-548b20e2bd6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-738a39ac-cd6d-4a5e-a78c-0e5d7ed6d069,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-09eda956-93f1-4176-bf75-6d91cbdb6169,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-e7dca9de-3f3c-42cd-92b9-0b868f57e29c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1646814225-172.17.0.6-1595702143850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43631,DS-37aa54d2-bdab-48a7-abab-b9117ba4af72,DISK], DatanodeInfoWithStorage[127.0.0.1:41515,DS-d4bedd2c-88ea-4a99-b845-76119872f7de,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-5a23f65a-1b9e-412e-b1d6-5124fe8c4258,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-698ba923-d583-4604-8c81-86c2adc32827,DISK], DatanodeInfoWithStorage[127.0.0.1:41288,DS-ae34686f-b39b-4eb3-817d-548b20e2bd6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-738a39ac-cd6d-4a5e-a78c-0e5d7ed6d069,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-09eda956-93f1-4176-bf75-6d91cbdb6169,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-e7dca9de-3f3c-42cd-92b9-0b868f57e29c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-626370779-172.17.0.6-1595702277717:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39422,DS-ccd33822-b55e-4f4e-a17b-980d37d752a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42855,DS-ef0249b5-d1d6-4ada-afe1-e7885e0a403a,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-34d55c70-9b98-40a8-ba37-79ef941c410b,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-834323b3-ee16-4663-94e5-a73ebf3d88a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-cb08250f-8a31-4833-95a0-712b9b463441,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-8e00cece-f503-46a3-8983-c39562d94011,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-bd34b9c9-0428-499b-9878-9ecbcbd232e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-373711fa-bed8-49a8-aa7d-16ee4bae0c38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-626370779-172.17.0.6-1595702277717:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39422,DS-ccd33822-b55e-4f4e-a17b-980d37d752a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42855,DS-ef0249b5-d1d6-4ada-afe1-e7885e0a403a,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-34d55c70-9b98-40a8-ba37-79ef941c410b,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-834323b3-ee16-4663-94e5-a73ebf3d88a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-cb08250f-8a31-4833-95a0-712b9b463441,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-8e00cece-f503-46a3-8983-c39562d94011,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-bd34b9c9-0428-499b-9878-9ecbcbd232e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-373711fa-bed8-49a8-aa7d-16ee4bae0c38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-190798421-172.17.0.6-1595702576648:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40726,DS-a5e5d958-7c84-4dc0-a2f8-a962fbee7664,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-1307021c-a980-4204-b31b-91034a32af5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-8b356426-3a41-45f2-a527-4c42449d8d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-4cc48695-e246-4e5c-8256-bb499f4d2def,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-25cd7a62-050b-4b41-b874-0e5abc5d81f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-fe39b40d-adc9-4f98-bff8-6897db01b18f,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-5eea757c-c6b0-4cc3-a8f7-10dc74969131,DISK], DatanodeInfoWithStorage[127.0.0.1:33663,DS-98223057-c8c3-403f-b357-a9be46675642,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-190798421-172.17.0.6-1595702576648:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40726,DS-a5e5d958-7c84-4dc0-a2f8-a962fbee7664,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-1307021c-a980-4204-b31b-91034a32af5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-8b356426-3a41-45f2-a527-4c42449d8d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-4cc48695-e246-4e5c-8256-bb499f4d2def,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-25cd7a62-050b-4b41-b874-0e5abc5d81f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-fe39b40d-adc9-4f98-bff8-6897db01b18f,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-5eea757c-c6b0-4cc3-a8f7-10dc74969131,DISK], DatanodeInfoWithStorage[127.0.0.1:33663,DS-98223057-c8c3-403f-b357-a9be46675642,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-67390935-172.17.0.6-1595702901498:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42195,DS-6ed1784e-6d7a-49e4-90db-775c5884f495,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-78824650-fc21-40a1-b46a-c08e77e50964,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-34f3ba58-49a6-4724-acff-572ae6993804,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-d26ed374-f283-4669-86d7-de80d21cdb59,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-0deb8a8f-c6ef-4e91-b9c6-7f908a3d39f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-e49570ba-f13e-4ba0-8017-ccaba62482bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-b18ad066-029a-4286-aadf-29a025fb83a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36366,DS-eda35f55-3bc8-4f54-84a0-f7c66a5d3eb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-67390935-172.17.0.6-1595702901498:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42195,DS-6ed1784e-6d7a-49e4-90db-775c5884f495,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-78824650-fc21-40a1-b46a-c08e77e50964,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-34f3ba58-49a6-4724-acff-572ae6993804,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-d26ed374-f283-4669-86d7-de80d21cdb59,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-0deb8a8f-c6ef-4e91-b9c6-7f908a3d39f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-e49570ba-f13e-4ba0-8017-ccaba62482bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-b18ad066-029a-4286-aadf-29a025fb83a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36366,DS-eda35f55-3bc8-4f54-84a0-f7c66a5d3eb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1614796539-172.17.0.6-1595702936430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40342,DS-c93ef167-bd1a-4634-b592-1719a05d5962,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-5bf832cf-281e-4401-88b2-131c539fb79d,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-92e183cd-6761-456f-b445-388080b39332,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-59eb8eab-2e4e-44a7-964e-67eb607a82fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-e4de1a56-a9d5-4aea-ba8d-c752c317c216,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-764a6064-85b5-40e4-93d3-d58f0bb9225e,DISK], DatanodeInfoWithStorage[127.0.0.1:36175,DS-348d4edd-a266-4d08-8f5a-61facbd13408,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-40766d69-2f72-4996-bbcc-d3e118d7af51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1614796539-172.17.0.6-1595702936430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40342,DS-c93ef167-bd1a-4634-b592-1719a05d5962,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-5bf832cf-281e-4401-88b2-131c539fb79d,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-92e183cd-6761-456f-b445-388080b39332,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-59eb8eab-2e4e-44a7-964e-67eb607a82fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-e4de1a56-a9d5-4aea-ba8d-c752c317c216,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-764a6064-85b5-40e4-93d3-d58f0bb9225e,DISK], DatanodeInfoWithStorage[127.0.0.1:36175,DS-348d4edd-a266-4d08-8f5a-61facbd13408,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-40766d69-2f72-4996-bbcc-d3e118d7af51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1668401384-172.17.0.6-1595702967342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41147,DS-c28fb7f7-0adb-4aad-8997-a0a3e9a79faf,DISK], DatanodeInfoWithStorage[127.0.0.1:33340,DS-a853e11a-4fce-42d5-855b-38bda2d8e98c,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-cfa9b6eb-22d4-4bde-85c6-b855e0775e86,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-f680bf5b-0e3b-4c8e-83fd-37115fa5004d,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-ee8c4692-3668-4105-a5fe-31160858c0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45822,DS-e9122950-099a-4dd1-9764-185e742b2c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-1254d07b-c9b2-4802-b5fa-bab4ba79d383,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-13b77070-8cf6-4ca4-a24a-0daa3b4bd505,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1668401384-172.17.0.6-1595702967342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41147,DS-c28fb7f7-0adb-4aad-8997-a0a3e9a79faf,DISK], DatanodeInfoWithStorage[127.0.0.1:33340,DS-a853e11a-4fce-42d5-855b-38bda2d8e98c,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-cfa9b6eb-22d4-4bde-85c6-b855e0775e86,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-f680bf5b-0e3b-4c8e-83fd-37115fa5004d,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-ee8c4692-3668-4105-a5fe-31160858c0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45822,DS-e9122950-099a-4dd1-9764-185e742b2c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-1254d07b-c9b2-4802-b5fa-bab4ba79d383,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-13b77070-8cf6-4ca4-a24a-0daa3b4bd505,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2110214193-172.17.0.6-1595703335181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41401,DS-b2a2a172-1a63-4818-8442-f42e530875ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-7983114a-37a9-4c62-b762-001b55ae4470,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-87b3be8b-c189-48af-8878-4394e7d2705e,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-961a4ccb-0c86-429c-852b-024a36a488ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39309,DS-ac15938b-2977-4767-aca9-5a25dfb36a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35186,DS-4c3fa6f3-e7fb-4776-9058-1eaeecaec1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-21d74a94-6d29-4f78-9ee3-e253a37ac28c,DISK], DatanodeInfoWithStorage[127.0.0.1:44304,DS-dcce985a-8342-4f7e-a785-abf9fb2bf5d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2110214193-172.17.0.6-1595703335181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41401,DS-b2a2a172-1a63-4818-8442-f42e530875ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-7983114a-37a9-4c62-b762-001b55ae4470,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-87b3be8b-c189-48af-8878-4394e7d2705e,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-961a4ccb-0c86-429c-852b-024a36a488ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39309,DS-ac15938b-2977-4767-aca9-5a25dfb36a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35186,DS-4c3fa6f3-e7fb-4776-9058-1eaeecaec1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-21d74a94-6d29-4f78-9ee3-e253a37ac28c,DISK], DatanodeInfoWithStorage[127.0.0.1:44304,DS-dcce985a-8342-4f7e-a785-abf9fb2bf5d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-572406708-172.17.0.6-1595703466460:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39557,DS-b74580da-b7d6-4bcd-93b9-a12299b82b44,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-1ecc42a2-ff7a-4a67-b8c3-e5e915d0c1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-2f228896-7f14-4cce-8ebc-92ea04f3950f,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-026f34c6-1e62-4e15-a715-ed7fa8402d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-53ed433b-0a5c-4da1-8440-e2fe004ee8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-e5fb85ed-ee60-473a-9dab-ed4d5dbba74d,DISK], DatanodeInfoWithStorage[127.0.0.1:44874,DS-c63f7da5-bd90-4cc1-982b-2512e55e28a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-70c1db66-5bc9-4149-bd72-f3bd2e8feaa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-572406708-172.17.0.6-1595703466460:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39557,DS-b74580da-b7d6-4bcd-93b9-a12299b82b44,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-1ecc42a2-ff7a-4a67-b8c3-e5e915d0c1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-2f228896-7f14-4cce-8ebc-92ea04f3950f,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-026f34c6-1e62-4e15-a715-ed7fa8402d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-53ed433b-0a5c-4da1-8440-e2fe004ee8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-e5fb85ed-ee60-473a-9dab-ed4d5dbba74d,DISK], DatanodeInfoWithStorage[127.0.0.1:44874,DS-c63f7da5-bd90-4cc1-982b-2512e55e28a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-70c1db66-5bc9-4149-bd72-f3bd2e8feaa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1976396316-172.17.0.6-1595703646895:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38198,DS-f6ae0cc3-a442-4c5e-9c24-841354132546,DISK], DatanodeInfoWithStorage[127.0.0.1:34094,DS-73706d82-f2cd-4d96-94b4-1ebb684d48ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-31c427fe-d72d-4a19-8be1-3fb32dd22d88,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-adaab4e1-ce4e-46fc-816b-faa59b710c71,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-3bcb042e-b5f3-4589-8975-ec7aa3c5d4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-31de7cf9-12a5-4c13-bde3-c8ccdc930f49,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-190afbbf-d993-4efe-8340-3fdb26987f24,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-58aa1eba-25e7-47b9-9f45-11c91d885faa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1976396316-172.17.0.6-1595703646895:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38198,DS-f6ae0cc3-a442-4c5e-9c24-841354132546,DISK], DatanodeInfoWithStorage[127.0.0.1:34094,DS-73706d82-f2cd-4d96-94b4-1ebb684d48ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-31c427fe-d72d-4a19-8be1-3fb32dd22d88,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-adaab4e1-ce4e-46fc-816b-faa59b710c71,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-3bcb042e-b5f3-4589-8975-ec7aa3c5d4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-31de7cf9-12a5-4c13-bde3-c8ccdc930f49,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-190afbbf-d993-4efe-8340-3fdb26987f24,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-58aa1eba-25e7-47b9-9f45-11c91d885faa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2126451899-172.17.0.6-1595704130894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41784,DS-75d66e30-e013-4a20-aa29-6ad03985baee,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-5b88f1df-56ff-469e-9f7e-120da556f125,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-9b0e3aec-0ab9-4bba-9118-04cb8ddcbef3,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-f0725e22-e6f5-4f1b-96b2-b8c314d75203,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-37e7c8b9-6082-48fe-ae48-4f40fd9874f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-ffd4431f-0f48-4bae-83db-0abb035ce4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40280,DS-c8ce6450-b749-47fa-a7e4-223de68a5911,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-3edadafa-d659-4f6d-a703-65f7ad8ff61b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2126451899-172.17.0.6-1595704130894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41784,DS-75d66e30-e013-4a20-aa29-6ad03985baee,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-5b88f1df-56ff-469e-9f7e-120da556f125,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-9b0e3aec-0ab9-4bba-9118-04cb8ddcbef3,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-f0725e22-e6f5-4f1b-96b2-b8c314d75203,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-37e7c8b9-6082-48fe-ae48-4f40fd9874f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-ffd4431f-0f48-4bae-83db-0abb035ce4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40280,DS-c8ce6450-b749-47fa-a7e4-223de68a5911,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-3edadafa-d659-4f6d-a703-65f7ad8ff61b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-79921406-172.17.0.6-1595704199784:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37281,DS-a200930c-f317-4929-9b5d-cb06450fa143,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-79fe0e6f-66e3-465f-9362-6fc25285bdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41755,DS-2223987c-2d9e-49c3-89ec-d0e5f696bbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-473f5df0-0b28-47c1-8602-fc1dc3e38eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-33f4c1b4-5e49-462f-88fc-1aba97b91af9,DISK], DatanodeInfoWithStorage[127.0.0.1:44615,DS-394c20a0-b5df-4349-85ed-b5c86662efed,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-9b497c1f-e0d9-46ce-85b2-4da477bef7da,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-d27620b4-c98d-42f4-ae2b-90fb2d7e52a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-79921406-172.17.0.6-1595704199784:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37281,DS-a200930c-f317-4929-9b5d-cb06450fa143,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-79fe0e6f-66e3-465f-9362-6fc25285bdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41755,DS-2223987c-2d9e-49c3-89ec-d0e5f696bbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-473f5df0-0b28-47c1-8602-fc1dc3e38eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-33f4c1b4-5e49-462f-88fc-1aba97b91af9,DISK], DatanodeInfoWithStorage[127.0.0.1:44615,DS-394c20a0-b5df-4349-85ed-b5c86662efed,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-9b497c1f-e0d9-46ce-85b2-4da477bef7da,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-d27620b4-c98d-42f4-ae2b-90fb2d7e52a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1794414036-172.17.0.6-1595704308939:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33887,DS-157209ef-dcb9-4e46-aa1e-cdedd074c2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-1a53def0-5032-4c53-8a30-28a621883d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-2c9a8d26-a366-48bd-9c80-63f55a70cf27,DISK], DatanodeInfoWithStorage[127.0.0.1:34158,DS-bb182c87-064f-44a4-8a94-9cd73c310abd,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-f113a5b0-f59d-4b79-9837-587cc2b7a799,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-4d04f558-f3e4-4f53-a7d0-14a6de00a479,DISK], DatanodeInfoWithStorage[127.0.0.1:33305,DS-0c9202db-3514-4980-bff9-023adb092384,DISK], DatanodeInfoWithStorage[127.0.0.1:38578,DS-a9083e94-effa-43ad-bec2-ae525f4184fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1794414036-172.17.0.6-1595704308939:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33887,DS-157209ef-dcb9-4e46-aa1e-cdedd074c2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-1a53def0-5032-4c53-8a30-28a621883d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-2c9a8d26-a366-48bd-9c80-63f55a70cf27,DISK], DatanodeInfoWithStorage[127.0.0.1:34158,DS-bb182c87-064f-44a4-8a94-9cd73c310abd,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-f113a5b0-f59d-4b79-9837-587cc2b7a799,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-4d04f558-f3e4-4f53-a7d0-14a6de00a479,DISK], DatanodeInfoWithStorage[127.0.0.1:33305,DS-0c9202db-3514-4980-bff9-023adb092384,DISK], DatanodeInfoWithStorage[127.0.0.1:38578,DS-a9083e94-effa-43ad-bec2-ae525f4184fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1370310886-172.17.0.6-1595704903665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34370,DS-26a77f8d-c621-4a8a-8000-5b6542a2377b,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-0254595f-b6e3-4ac2-b5f0-5143dde369f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-d43d372b-3ca2-4b72-9937-dcad909c0b48,DISK], DatanodeInfoWithStorage[127.0.0.1:37935,DS-3f9f45be-e3db-43b8-b9e3-5b3fbed5e5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-cae1640b-be2c-42dd-b7b3-ec192cfd7950,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-e73307f4-779c-4c56-a963-4b0e1978a343,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-ca4d9a70-4698-4917-ad61-47c456814072,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-4dc0f25c-aa10-4618-b59d-eb993d98689f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1370310886-172.17.0.6-1595704903665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34370,DS-26a77f8d-c621-4a8a-8000-5b6542a2377b,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-0254595f-b6e3-4ac2-b5f0-5143dde369f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-d43d372b-3ca2-4b72-9937-dcad909c0b48,DISK], DatanodeInfoWithStorage[127.0.0.1:37935,DS-3f9f45be-e3db-43b8-b9e3-5b3fbed5e5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-cae1640b-be2c-42dd-b7b3-ec192cfd7950,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-e73307f4-779c-4c56-a963-4b0e1978a343,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-ca4d9a70-4698-4917-ad61-47c456814072,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-4dc0f25c-aa10-4618-b59d-eb993d98689f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-885418625-172.17.0.6-1595704940032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46759,DS-5e6d827f-b749-4fb7-bbc8-3a3cc1b91447,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-f81df0af-a580-4b7c-910b-ab78924b7176,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-a1799dc5-3b34-4942-a1fc-cf66b3873454,DISK], DatanodeInfoWithStorage[127.0.0.1:46046,DS-1286b7e4-ba1f-4355-a71a-766caa5b09d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40421,DS-db46bebc-84e4-491d-a77e-bf78c44edcb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-63e2e025-0129-4d0c-889a-51f8bc3e2a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-27729518-7620-4136-933c-34bac4464b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-8c60cbd9-e578-4516-abb5-14076a2025a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-885418625-172.17.0.6-1595704940032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46759,DS-5e6d827f-b749-4fb7-bbc8-3a3cc1b91447,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-f81df0af-a580-4b7c-910b-ab78924b7176,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-a1799dc5-3b34-4942-a1fc-cf66b3873454,DISK], DatanodeInfoWithStorage[127.0.0.1:46046,DS-1286b7e4-ba1f-4355-a71a-766caa5b09d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40421,DS-db46bebc-84e4-491d-a77e-bf78c44edcb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-63e2e025-0129-4d0c-889a-51f8bc3e2a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-27729518-7620-4136-933c-34bac4464b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-8c60cbd9-e578-4516-abb5-14076a2025a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1324050103-172.17.0.6-1595705054568:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45280,DS-7552de5d-9d7a-477e-9b30-21f561937063,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-df87e448-5327-4723-bbd7-06ca6c9a9a53,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-b734d847-a12b-4a4e-9ff8-80a93016fe20,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-7926924f-a7cc-4369-b659-80f094b3fa73,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-9b904bb6-7e04-4945-93e9-f0385565b794,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-5c97a3e5-b099-40f9-bf7c-634587f8efca,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-7291cadd-555b-4568-b36e-3f78beaa8506,DISK], DatanodeInfoWithStorage[127.0.0.1:38243,DS-7b548113-dcbd-48c2-94b3-aef6ea091afd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1324050103-172.17.0.6-1595705054568:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45280,DS-7552de5d-9d7a-477e-9b30-21f561937063,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-df87e448-5327-4723-bbd7-06ca6c9a9a53,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-b734d847-a12b-4a4e-9ff8-80a93016fe20,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-7926924f-a7cc-4369-b659-80f094b3fa73,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-9b904bb6-7e04-4945-93e9-f0385565b794,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-5c97a3e5-b099-40f9-bf7c-634587f8efca,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-7291cadd-555b-4568-b36e-3f78beaa8506,DISK], DatanodeInfoWithStorage[127.0.0.1:38243,DS-7b548113-dcbd-48c2-94b3-aef6ea091afd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-373667565-172.17.0.6-1595705452335:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37767,DS-9a637771-01df-45f8-8274-08726b2b410b,DISK], DatanodeInfoWithStorage[127.0.0.1:44986,DS-6c6cf3c1-eef5-4367-86fc-3852ca4099e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-624c5150-ef51-4d31-916e-ea13d335c8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-7e036f57-534a-4f0e-8b2f-f4f1f8867d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-7f1420bb-c091-496c-81fb-12f42ccf224d,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-e3811113-1313-4468-98fa-c9648e4ba031,DISK], DatanodeInfoWithStorage[127.0.0.1:38862,DS-40d80bd3-6f4a-4a0a-a2cb-518cbc49691c,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-ee11a0ee-31b5-440a-a997-d25aef142eb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-373667565-172.17.0.6-1595705452335:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37767,DS-9a637771-01df-45f8-8274-08726b2b410b,DISK], DatanodeInfoWithStorage[127.0.0.1:44986,DS-6c6cf3c1-eef5-4367-86fc-3852ca4099e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-624c5150-ef51-4d31-916e-ea13d335c8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-7e036f57-534a-4f0e-8b2f-f4f1f8867d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-7f1420bb-c091-496c-81fb-12f42ccf224d,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-e3811113-1313-4468-98fa-c9648e4ba031,DISK], DatanodeInfoWithStorage[127.0.0.1:38862,DS-40d80bd3-6f4a-4a0a-a2cb-518cbc49691c,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-ee11a0ee-31b5-440a-a997-d25aef142eb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1975114822-172.17.0.6-1595705513514:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46619,DS-a73ba8f7-799d-4688-ae39-9df85f0e5d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-46be5cc4-9c45-4f7f-bb3c-8f8cf7e6758a,DISK], DatanodeInfoWithStorage[127.0.0.1:33676,DS-afd626a3-112f-4383-94da-98c25f6a9e81,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-959ceb2e-655e-45d6-ba1d-db2b09fb04d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-11ecd212-effc-4726-b1c1-2b2ec74c273e,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-deaad82d-f1df-49ad-bd19-f9e9bfb9507b,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-37dedc85-e0d2-4740-a475-056ed3cebb99,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-47d11db5-08cb-4094-9e00-4257304be4f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1975114822-172.17.0.6-1595705513514:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46619,DS-a73ba8f7-799d-4688-ae39-9df85f0e5d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-46be5cc4-9c45-4f7f-bb3c-8f8cf7e6758a,DISK], DatanodeInfoWithStorage[127.0.0.1:33676,DS-afd626a3-112f-4383-94da-98c25f6a9e81,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-959ceb2e-655e-45d6-ba1d-db2b09fb04d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-11ecd212-effc-4726-b1c1-2b2ec74c273e,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-deaad82d-f1df-49ad-bd19-f9e9bfb9507b,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-37dedc85-e0d2-4740-a475-056ed3cebb99,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-47d11db5-08cb-4094-9e00-4257304be4f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-572495689-172.17.0.6-1595706202104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34501,DS-f6e410ae-4aa4-4023-953a-d3355f794d27,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-8d78fcb4-c5bb-454d-9929-01f414a21419,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-1d112230-bd87-434b-88e7-bbc0895e01e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-10c30e55-18ec-42e5-a2fc-8b85dca7d703,DISK], DatanodeInfoWithStorage[127.0.0.1:35429,DS-f2943197-fc4e-4325-9214-d64724361cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-ef2522cf-8b96-461c-9a43-0ae72ea20864,DISK], DatanodeInfoWithStorage[127.0.0.1:34077,DS-540ab5b6-f3ec-4a60-908f-82707204d6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-020a27da-faee-4b20-b4fe-bb1a3df5afe5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-572495689-172.17.0.6-1595706202104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34501,DS-f6e410ae-4aa4-4023-953a-d3355f794d27,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-8d78fcb4-c5bb-454d-9929-01f414a21419,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-1d112230-bd87-434b-88e7-bbc0895e01e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-10c30e55-18ec-42e5-a2fc-8b85dca7d703,DISK], DatanodeInfoWithStorage[127.0.0.1:35429,DS-f2943197-fc4e-4325-9214-d64724361cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-ef2522cf-8b96-461c-9a43-0ae72ea20864,DISK], DatanodeInfoWithStorage[127.0.0.1:34077,DS-540ab5b6-f3ec-4a60-908f-82707204d6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-020a27da-faee-4b20-b4fe-bb1a3df5afe5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-798070387-172.17.0.6-1595706590305:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39372,DS-97018657-6fba-4be0-bfc8-adfd90ee414c,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-edf8c49a-f592-47ed-9666-6ab03447179e,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-b7c7a46b-5a42-4914-a33e-e576279d69de,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-ee5633ad-34dd-45eb-bc0d-57ed00ba485f,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-9b75aa3a-f275-45a7-8ae6-a50889bfeed1,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-b8cd5893-d689-4dcb-acc3-cccc297af8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-1c2d620d-7580-4706-b1ba-9e3533ae5e37,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-b3be4b6a-28fd-45f3-b056-00e2fc8a523f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-798070387-172.17.0.6-1595706590305:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39372,DS-97018657-6fba-4be0-bfc8-adfd90ee414c,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-edf8c49a-f592-47ed-9666-6ab03447179e,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-b7c7a46b-5a42-4914-a33e-e576279d69de,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-ee5633ad-34dd-45eb-bc0d-57ed00ba485f,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-9b75aa3a-f275-45a7-8ae6-a50889bfeed1,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-b8cd5893-d689-4dcb-acc3-cccc297af8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-1c2d620d-7580-4706-b1ba-9e3533ae5e37,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-b3be4b6a-28fd-45f3-b056-00e2fc8a523f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5102
