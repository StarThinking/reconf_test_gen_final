reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-217562037-172.17.0.20-1595562573775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46625,DS-2b21d38f-1231-412b-b815-6f8de05bca76,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-2d0527ec-5827-4c1e-acb6-0fa0b7530a26,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-cae92977-3cce-45ac-b452-10ab443c403c,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-94927722-d42d-4286-980f-95b68be91c90,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-5a98035e-ee80-44a2-8e01-cd7221abe108,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-33ae72c1-9edd-4691-835a-0e628d4960ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45512,DS-f5694261-a0e2-470f-b47e-d657e712f404,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-3235a065-00ef-4471-81e5-a9ba05304fd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-217562037-172.17.0.20-1595562573775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46625,DS-2b21d38f-1231-412b-b815-6f8de05bca76,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-2d0527ec-5827-4c1e-acb6-0fa0b7530a26,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-cae92977-3cce-45ac-b452-10ab443c403c,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-94927722-d42d-4286-980f-95b68be91c90,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-5a98035e-ee80-44a2-8e01-cd7221abe108,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-33ae72c1-9edd-4691-835a-0e628d4960ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45512,DS-f5694261-a0e2-470f-b47e-d657e712f404,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-3235a065-00ef-4471-81e5-a9ba05304fd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-131713200-172.17.0.20-1595562889449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32973,DS-7d26b6d4-f125-403f-a35a-abd3e8b21770,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-872483f5-c71f-420b-86d6-051d2f246d07,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-52045ff5-933f-4545-95ec-682ada93e128,DISK], DatanodeInfoWithStorage[127.0.0.1:39180,DS-81a0ccc0-632a-4ccc-b9a9-77728793c07a,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-0c3be276-8094-48de-a64d-89b10bd96599,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-213c6a5d-ab8f-49de-8369-8588fc60160d,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-d77b931a-5572-4466-a2a9-40b73a5cda96,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-562e51d7-6046-40b4-903b-b43dd05396d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-131713200-172.17.0.20-1595562889449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32973,DS-7d26b6d4-f125-403f-a35a-abd3e8b21770,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-872483f5-c71f-420b-86d6-051d2f246d07,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-52045ff5-933f-4545-95ec-682ada93e128,DISK], DatanodeInfoWithStorage[127.0.0.1:39180,DS-81a0ccc0-632a-4ccc-b9a9-77728793c07a,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-0c3be276-8094-48de-a64d-89b10bd96599,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-213c6a5d-ab8f-49de-8369-8588fc60160d,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-d77b931a-5572-4466-a2a9-40b73a5cda96,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-562e51d7-6046-40b4-903b-b43dd05396d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2016423593-172.17.0.20-1595563142754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33540,DS-de1e7d9b-76e9-4595-abf6-38ff874e5406,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-beb2cd6b-3be6-4cbb-951d-09d7cf6f0f52,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-ebe3ea77-a6da-4564-96ee-c66c10cf7ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-544b9000-8991-41da-a5c3-e35299f7ea29,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-e97df26b-998e-48f7-8eef-02cf3256fbb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-6f4c55d8-d879-4b31-b09a-93f3c1a511f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-dddf490f-1052-4d80-a13b-0ec372d06e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-2661ca2b-0301-4b65-a06b-9ff6bcd47fa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2016423593-172.17.0.20-1595563142754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33540,DS-de1e7d9b-76e9-4595-abf6-38ff874e5406,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-beb2cd6b-3be6-4cbb-951d-09d7cf6f0f52,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-ebe3ea77-a6da-4564-96ee-c66c10cf7ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-544b9000-8991-41da-a5c3-e35299f7ea29,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-e97df26b-998e-48f7-8eef-02cf3256fbb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-6f4c55d8-d879-4b31-b09a-93f3c1a511f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-dddf490f-1052-4d80-a13b-0ec372d06e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-2661ca2b-0301-4b65-a06b-9ff6bcd47fa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-925907821-172.17.0.20-1595563495466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43612,DS-4953306f-37d2-4617-9d0e-acf2d3901068,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-66bb0837-0456-47f7-8bea-03635628f579,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-a0c0f35c-5b28-47d8-8433-1e5770e9fffc,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-a59ae1c6-7316-4e19-a2f2-985530a5ace4,DISK], DatanodeInfoWithStorage[127.0.0.1:44555,DS-513f7bed-6564-41eb-8333-ab9a18856458,DISK], DatanodeInfoWithStorage[127.0.0.1:40946,DS-191d3f27-d230-4b5a-b736-88ff5f12f69d,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-2feabd15-b84a-4e8f-ac1f-f543e3a1f79f,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-c9e99b57-14bb-4f55-a5fc-d7d429299e28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-925907821-172.17.0.20-1595563495466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43612,DS-4953306f-37d2-4617-9d0e-acf2d3901068,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-66bb0837-0456-47f7-8bea-03635628f579,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-a0c0f35c-5b28-47d8-8433-1e5770e9fffc,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-a59ae1c6-7316-4e19-a2f2-985530a5ace4,DISK], DatanodeInfoWithStorage[127.0.0.1:44555,DS-513f7bed-6564-41eb-8333-ab9a18856458,DISK], DatanodeInfoWithStorage[127.0.0.1:40946,DS-191d3f27-d230-4b5a-b736-88ff5f12f69d,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-2feabd15-b84a-4e8f-ac1f-f543e3a1f79f,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-c9e99b57-14bb-4f55-a5fc-d7d429299e28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-425596580-172.17.0.20-1595563862368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44182,DS-7ba833ba-7db2-4692-a574-91bb1181e014,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-7fd3cd86-bd7e-42af-8aa4-a5e20ef58bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-1e9ec121-291d-4b94-9951-c19b8f6de98b,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-23168370-1b0e-4206-a3cc-828e13640aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:42501,DS-a9db201b-87e6-4d7e-8444-d5817b0063a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-6cff9c18-ae47-4bfa-bb40-31360ff2d224,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-0570fcbc-0d71-4631-b709-0776a2e7b40e,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-46bca944-9114-4e97-adb1-c481277d60c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-425596580-172.17.0.20-1595563862368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44182,DS-7ba833ba-7db2-4692-a574-91bb1181e014,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-7fd3cd86-bd7e-42af-8aa4-a5e20ef58bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-1e9ec121-291d-4b94-9951-c19b8f6de98b,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-23168370-1b0e-4206-a3cc-828e13640aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:42501,DS-a9db201b-87e6-4d7e-8444-d5817b0063a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-6cff9c18-ae47-4bfa-bb40-31360ff2d224,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-0570fcbc-0d71-4631-b709-0776a2e7b40e,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-46bca944-9114-4e97-adb1-c481277d60c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1306140243-172.17.0.20-1595564114234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44731,DS-756449a9-1c7d-422c-8c0c-868fbdb853da,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-d6774779-d61e-415f-8e34-089327323f64,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-d55116f4-afae-44d6-b999-708dc4b70706,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-0b935550-04e3-4675-b27a-6ecf57a7c76c,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-b3aca596-df8a-4a23-9688-a23447c55a61,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-9f80c561-a39c-4561-bd9d-abc52a579f41,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-daca6d07-a535-40dc-875e-ac0a147028c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33483,DS-7f936659-7a40-48e5-85c5-0070aad753e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1306140243-172.17.0.20-1595564114234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44731,DS-756449a9-1c7d-422c-8c0c-868fbdb853da,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-d6774779-d61e-415f-8e34-089327323f64,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-d55116f4-afae-44d6-b999-708dc4b70706,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-0b935550-04e3-4675-b27a-6ecf57a7c76c,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-b3aca596-df8a-4a23-9688-a23447c55a61,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-9f80c561-a39c-4561-bd9d-abc52a579f41,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-daca6d07-a535-40dc-875e-ac0a147028c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33483,DS-7f936659-7a40-48e5-85c5-0070aad753e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-696698155-172.17.0.20-1595564606247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34608,DS-9fa09814-144b-4348-bce9-fc2b1b60571e,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-ab1ad80c-6e26-4928-a51f-d0a0074d1f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-cae1679b-a51a-4b29-88c3-e521acc31c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-2bb7aa70-e28d-4d61-8a30-c698ec393495,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-3a1824fa-d5ac-4765-acf8-5bd797cde9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37325,DS-44328d08-0469-477c-8fd2-34f363b10646,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-c14e8c0d-b694-420d-81ae-c9ca82b22098,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-65faf802-9670-48d7-847d-1467a3f4360e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-696698155-172.17.0.20-1595564606247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34608,DS-9fa09814-144b-4348-bce9-fc2b1b60571e,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-ab1ad80c-6e26-4928-a51f-d0a0074d1f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-cae1679b-a51a-4b29-88c3-e521acc31c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-2bb7aa70-e28d-4d61-8a30-c698ec393495,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-3a1824fa-d5ac-4765-acf8-5bd797cde9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37325,DS-44328d08-0469-477c-8fd2-34f363b10646,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-c14e8c0d-b694-420d-81ae-c9ca82b22098,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-65faf802-9670-48d7-847d-1467a3f4360e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1181588222-172.17.0.20-1595564739295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39089,DS-9a9b1713-0509-4ec7-869d-cd3926daed10,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-b02a27b7-6999-4150-a0bf-3364ffaa9a34,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-f088078b-d436-41c9-bb31-14498e394aea,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-11e16c0b-d902-4a3f-842f-dedb199c37d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-8b622f45-377c-4b78-a913-6d1b64967cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-5483c9c5-f756-488c-b163-13379dba4671,DISK], DatanodeInfoWithStorage[127.0.0.1:40564,DS-bb2d6e07-d46b-43b3-bdf8-68f30b396f71,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-f8172572-c47e-4fd0-b93f-9e188297a133,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1181588222-172.17.0.20-1595564739295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39089,DS-9a9b1713-0509-4ec7-869d-cd3926daed10,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-b02a27b7-6999-4150-a0bf-3364ffaa9a34,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-f088078b-d436-41c9-bb31-14498e394aea,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-11e16c0b-d902-4a3f-842f-dedb199c37d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-8b622f45-377c-4b78-a913-6d1b64967cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-5483c9c5-f756-488c-b163-13379dba4671,DISK], DatanodeInfoWithStorage[127.0.0.1:40564,DS-bb2d6e07-d46b-43b3-bdf8-68f30b396f71,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-f8172572-c47e-4fd0-b93f-9e188297a133,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1282472191-172.17.0.20-1595564918753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42708,DS-066f31d4-2308-4b8d-b67c-e13c4be63201,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-9b97fed0-d462-478e-9e88-ffb7b84997fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-0150128c-0ad4-450d-a8be-90fc667f59f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-a4466d9f-5cc3-4fa1-9d9e-2cfaf839e286,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-39c333b2-28c9-4752-a43d-7ddba1cdce12,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-072c2e32-17da-45bf-a9f9-c8ebc602c405,DISK], DatanodeInfoWithStorage[127.0.0.1:35243,DS-2dfbcbc6-8304-4947-8e36-bcfc5abd4d69,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-b4b4d68d-1ccb-4935-955c-3723048d740a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1282472191-172.17.0.20-1595564918753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42708,DS-066f31d4-2308-4b8d-b67c-e13c4be63201,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-9b97fed0-d462-478e-9e88-ffb7b84997fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-0150128c-0ad4-450d-a8be-90fc667f59f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-a4466d9f-5cc3-4fa1-9d9e-2cfaf839e286,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-39c333b2-28c9-4752-a43d-7ddba1cdce12,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-072c2e32-17da-45bf-a9f9-c8ebc602c405,DISK], DatanodeInfoWithStorage[127.0.0.1:35243,DS-2dfbcbc6-8304-4947-8e36-bcfc5abd4d69,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-b4b4d68d-1ccb-4935-955c-3723048d740a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1310510027-172.17.0.20-1595564993468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41398,DS-5b6fe4a7-cb34-4557-a377-2df83f4c07f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-1e85475f-708a-4071-97c1-3bfbffe75164,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-47fb4823-2026-4c76-9d4c-65ff2f9ad02c,DISK], DatanodeInfoWithStorage[127.0.0.1:37395,DS-6b1d9b4c-ba18-4d06-bcc7-f266bda6f667,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-5c8dd3d4-8de3-4727-b97b-c5ab9fcc698f,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-6e1b7185-c528-4bd8-89de-ea363562f436,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-53021661-f29a-4f1c-a49d-ba3ab6923893,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-527e1e96-4e66-43c8-a504-3925ef4e6e9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1310510027-172.17.0.20-1595564993468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41398,DS-5b6fe4a7-cb34-4557-a377-2df83f4c07f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-1e85475f-708a-4071-97c1-3bfbffe75164,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-47fb4823-2026-4c76-9d4c-65ff2f9ad02c,DISK], DatanodeInfoWithStorage[127.0.0.1:37395,DS-6b1d9b4c-ba18-4d06-bcc7-f266bda6f667,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-5c8dd3d4-8de3-4727-b97b-c5ab9fcc698f,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-6e1b7185-c528-4bd8-89de-ea363562f436,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-53021661-f29a-4f1c-a49d-ba3ab6923893,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-527e1e96-4e66-43c8-a504-3925ef4e6e9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-381943778-172.17.0.20-1595565023107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35488,DS-415f3065-9cad-44d1-8047-c56dfe843674,DISK], DatanodeInfoWithStorage[127.0.0.1:43338,DS-65df1cc7-4909-4f33-8563-029e068af949,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-c46948e0-1c2b-41c7-af41-eeca09cae41d,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-eaed3b90-530f-4bfe-b6b9-27ad0eecd0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46071,DS-26365e27-fd62-4109-84d0-c545c9bf1674,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-ce38a1b7-8479-47a9-a1b8-9091f27a319c,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-c7aa8777-4a39-4b16-bfc9-83a9fae5329a,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-cc0d0ac4-1318-4d17-91f8-0ff8e73294cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-381943778-172.17.0.20-1595565023107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35488,DS-415f3065-9cad-44d1-8047-c56dfe843674,DISK], DatanodeInfoWithStorage[127.0.0.1:43338,DS-65df1cc7-4909-4f33-8563-029e068af949,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-c46948e0-1c2b-41c7-af41-eeca09cae41d,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-eaed3b90-530f-4bfe-b6b9-27ad0eecd0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46071,DS-26365e27-fd62-4109-84d0-c545c9bf1674,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-ce38a1b7-8479-47a9-a1b8-9091f27a319c,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-c7aa8777-4a39-4b16-bfc9-83a9fae5329a,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-cc0d0ac4-1318-4d17-91f8-0ff8e73294cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1508221517-172.17.0.20-1595565271831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35465,DS-fcc11515-2c42-44c2-b4f7-a450b20a9d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42614,DS-41fe6216-597c-4215-a119-825815ed2ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:40393,DS-aa0810aa-ccbc-4b55-bb9f-eee56f31e323,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-ba288885-c997-40af-bd23-0935bb699a53,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-307a679e-ca1f-4dd1-b75e-54e1876c82bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-9117353e-5acd-4d4e-ab51-28cf1ed15ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:43020,DS-6766cbfa-691f-4942-9e00-107be945e2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-22429104-be6c-419a-9846-18e8473ac589,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1508221517-172.17.0.20-1595565271831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35465,DS-fcc11515-2c42-44c2-b4f7-a450b20a9d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42614,DS-41fe6216-597c-4215-a119-825815ed2ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:40393,DS-aa0810aa-ccbc-4b55-bb9f-eee56f31e323,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-ba288885-c997-40af-bd23-0935bb699a53,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-307a679e-ca1f-4dd1-b75e-54e1876c82bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-9117353e-5acd-4d4e-ab51-28cf1ed15ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:43020,DS-6766cbfa-691f-4942-9e00-107be945e2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-22429104-be6c-419a-9846-18e8473ac589,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1806808715-172.17.0.20-1595565563760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38920,DS-7704f65a-debb-4070-b308-82de3931a22b,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-10660baf-c034-41b0-b213-ad1a2352ec7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-fd1bfbeb-ea1c-41c4-854d-a0f401b3911b,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-d8f8127c-d9ab-4d98-a2e8-d815f8a3eb37,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-61063d68-2a68-48db-8899-1909a03e2bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-c4b14078-7aeb-4109-8847-6497c6528d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35051,DS-d602c5a4-a548-4b3e-9b76-ebc46ed10802,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-d0127eca-2eb8-4e34-a771-030ac4af2881,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1806808715-172.17.0.20-1595565563760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38920,DS-7704f65a-debb-4070-b308-82de3931a22b,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-10660baf-c034-41b0-b213-ad1a2352ec7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-fd1bfbeb-ea1c-41c4-854d-a0f401b3911b,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-d8f8127c-d9ab-4d98-a2e8-d815f8a3eb37,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-61063d68-2a68-48db-8899-1909a03e2bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-c4b14078-7aeb-4109-8847-6497c6528d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35051,DS-d602c5a4-a548-4b3e-9b76-ebc46ed10802,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-d0127eca-2eb8-4e34-a771-030ac4af2881,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1037212073-172.17.0.20-1595565966186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39835,DS-f64aa7a2-808a-41ec-96a7-ff82ff4514e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-38889c3e-3cab-45bc-8cd3-61f660d7d978,DISK], DatanodeInfoWithStorage[127.0.0.1:38340,DS-94e3272f-909b-430f-8ed5-c36c42139cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42758,DS-ab637ad8-2257-4209-8985-065719698707,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-7eeb50c8-e88c-4fc7-bfdd-7416f73aa687,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-e411d684-320d-4cfb-8bf3-67e97cd54610,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-9123ad0f-8b08-4bf5-a7d2-965385d3f7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-6d3d79d9-ee47-4893-969a-c055f6fc5970,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1037212073-172.17.0.20-1595565966186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39835,DS-f64aa7a2-808a-41ec-96a7-ff82ff4514e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-38889c3e-3cab-45bc-8cd3-61f660d7d978,DISK], DatanodeInfoWithStorage[127.0.0.1:38340,DS-94e3272f-909b-430f-8ed5-c36c42139cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42758,DS-ab637ad8-2257-4209-8985-065719698707,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-7eeb50c8-e88c-4fc7-bfdd-7416f73aa687,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-e411d684-320d-4cfb-8bf3-67e97cd54610,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-9123ad0f-8b08-4bf5-a7d2-965385d3f7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-6d3d79d9-ee47-4893-969a-c055f6fc5970,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-486869617-172.17.0.20-1595566196750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41278,DS-8e9bac79-1eaa-4242-b74a-fd7c4dec4f11,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-be15a0d1-a6a4-4802-938e-3179f12ba2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-ef9e631f-f778-4831-b204-d7d914549388,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-02150a85-b783-4c32-ada5-7f7ad855390e,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-d3550ba9-2805-4396-a523-8836e3f0938b,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-97e0bf3d-e52a-4945-a038-320043894bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-552ba749-6b07-44cf-9a27-76ac4bc6828c,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-fddcc07e-931f-436e-a548-0d783b472ee1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-486869617-172.17.0.20-1595566196750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41278,DS-8e9bac79-1eaa-4242-b74a-fd7c4dec4f11,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-be15a0d1-a6a4-4802-938e-3179f12ba2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-ef9e631f-f778-4831-b204-d7d914549388,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-02150a85-b783-4c32-ada5-7f7ad855390e,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-d3550ba9-2805-4396-a523-8836e3f0938b,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-97e0bf3d-e52a-4945-a038-320043894bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-552ba749-6b07-44cf-9a27-76ac4bc6828c,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-fddcc07e-931f-436e-a548-0d783b472ee1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-165248241-172.17.0.20-1595566451085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45367,DS-846a7509-7d3c-44b4-8905-c3f9e6f9d4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-09d2b7d1-4e4d-4e35-98fe-a19f6eba64eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-96efc8c2-ce00-41b6-a440-17ef130cbe7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-8f8beecd-4807-4d06-8a34-3da7f889f99b,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-1a4306b8-27c1-489d-9101-7bf7ad31daa0,DISK], DatanodeInfoWithStorage[127.0.0.1:46467,DS-49242b26-f2e9-4ac4-8404-27c5c3648c75,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-51a31331-6284-4ed4-87dd-c1f6d57549f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-bc417b1f-ab6c-4d20-94bc-24969e5ba103,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-165248241-172.17.0.20-1595566451085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45367,DS-846a7509-7d3c-44b4-8905-c3f9e6f9d4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-09d2b7d1-4e4d-4e35-98fe-a19f6eba64eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-96efc8c2-ce00-41b6-a440-17ef130cbe7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-8f8beecd-4807-4d06-8a34-3da7f889f99b,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-1a4306b8-27c1-489d-9101-7bf7ad31daa0,DISK], DatanodeInfoWithStorage[127.0.0.1:46467,DS-49242b26-f2e9-4ac4-8404-27c5c3648c75,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-51a31331-6284-4ed4-87dd-c1f6d57549f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-bc417b1f-ab6c-4d20-94bc-24969e5ba103,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1513257057-172.17.0.20-1595566670159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44516,DS-bb9f8c36-3bb6-465d-a966-4999304f6c77,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-d214273a-4d03-42fc-a1a1-5a63354a6f46,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-ca9d7229-0628-4de6-a1b3-f1c4c58884c4,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-187e9d8d-f5b3-4b1a-b3fc-ac8488b7f04f,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-126641e8-1e87-48c0-ab12-1e7670b60daf,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-ae7926ab-6b6d-4e17-94ee-e679ccd0e8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-5ab4ef26-bc82-4eff-aaa7-780afa787d13,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-067577cb-1a1c-4cb1-8596-7c2870067b4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1513257057-172.17.0.20-1595566670159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44516,DS-bb9f8c36-3bb6-465d-a966-4999304f6c77,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-d214273a-4d03-42fc-a1a1-5a63354a6f46,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-ca9d7229-0628-4de6-a1b3-f1c4c58884c4,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-187e9d8d-f5b3-4b1a-b3fc-ac8488b7f04f,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-126641e8-1e87-48c0-ab12-1e7670b60daf,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-ae7926ab-6b6d-4e17-94ee-e679ccd0e8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-5ab4ef26-bc82-4eff-aaa7-780afa787d13,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-067577cb-1a1c-4cb1-8596-7c2870067b4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-427906602-172.17.0.20-1595566784277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35711,DS-c9a489ca-8b3e-41f2-9bb0-17f96c7baf39,DISK], DatanodeInfoWithStorage[127.0.0.1:34638,DS-ca519010-8510-426f-836c-8ef0cd36ba4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-6d4c3b13-eb7e-464c-b70e-7d960b27de03,DISK], DatanodeInfoWithStorage[127.0.0.1:36381,DS-3cd934b7-8cf9-44bd-a200-d2a902d958b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-1ce0c67c-4306-46ff-af24-6bafc9cce61f,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-092789ee-f393-4a23-825b-32fbffff4b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-e99d41cc-b9e5-4db8-9fbd-785bfefe0a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-6799cfbd-a6c1-48cf-86e0-faecce1f4e14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-427906602-172.17.0.20-1595566784277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35711,DS-c9a489ca-8b3e-41f2-9bb0-17f96c7baf39,DISK], DatanodeInfoWithStorage[127.0.0.1:34638,DS-ca519010-8510-426f-836c-8ef0cd36ba4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-6d4c3b13-eb7e-464c-b70e-7d960b27de03,DISK], DatanodeInfoWithStorage[127.0.0.1:36381,DS-3cd934b7-8cf9-44bd-a200-d2a902d958b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-1ce0c67c-4306-46ff-af24-6bafc9cce61f,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-092789ee-f393-4a23-825b-32fbffff4b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-e99d41cc-b9e5-4db8-9fbd-785bfefe0a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-6799cfbd-a6c1-48cf-86e0-faecce1f4e14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-716561798-172.17.0.20-1595566826379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33590,DS-e6463d97-301c-44e0-842d-00036b4d8546,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-404d6b19-64ef-4038-a499-b7a3f920d993,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-b96e2ec4-499f-417d-88ac-01b6a5dcc798,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-71aa6e17-5fc7-4336-91d8-9ef905c51db2,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-2434cfa7-7375-4cd5-a43d-49ed983b4c84,DISK], DatanodeInfoWithStorage[127.0.0.1:34918,DS-7205ff36-bd6e-4c0c-8002-65023a4ad2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-94b38ffe-1304-4d3c-b849-458f9bcfa9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-0d279901-5363-4395-8e87-7d8db0f3df2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-716561798-172.17.0.20-1595566826379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33590,DS-e6463d97-301c-44e0-842d-00036b4d8546,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-404d6b19-64ef-4038-a499-b7a3f920d993,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-b96e2ec4-499f-417d-88ac-01b6a5dcc798,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-71aa6e17-5fc7-4336-91d8-9ef905c51db2,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-2434cfa7-7375-4cd5-a43d-49ed983b4c84,DISK], DatanodeInfoWithStorage[127.0.0.1:34918,DS-7205ff36-bd6e-4c0c-8002-65023a4ad2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-94b38ffe-1304-4d3c-b849-458f9bcfa9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-0d279901-5363-4395-8e87-7d8db0f3df2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1087487463-172.17.0.20-1595567107927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40288,DS-861c99d7-b1dd-44a3-adb2-6c967add617e,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-2eeb5701-6539-458f-95d0-03c9b4dde520,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-dc6928e3-58ac-48f8-91c1-f4e1ae0991d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-148d581b-4983-4abf-b821-53034b920ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-9a4fc332-6c68-46aa-b360-aa268c2d0e80,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-2a78c0b7-b00a-4a94-adc2-9bfa7393cdcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-bc6409b2-10bc-4246-b8b0-fba6fdb66e44,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-6f8464b6-d875-4e8c-a2e4-11756af7dfb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1087487463-172.17.0.20-1595567107927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40288,DS-861c99d7-b1dd-44a3-adb2-6c967add617e,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-2eeb5701-6539-458f-95d0-03c9b4dde520,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-dc6928e3-58ac-48f8-91c1-f4e1ae0991d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-148d581b-4983-4abf-b821-53034b920ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-9a4fc332-6c68-46aa-b360-aa268c2d0e80,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-2a78c0b7-b00a-4a94-adc2-9bfa7393cdcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-bc6409b2-10bc-4246-b8b0-fba6fdb66e44,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-6f8464b6-d875-4e8c-a2e4-11756af7dfb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1307615700-172.17.0.20-1595567431750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41173,DS-6f3a58df-6b5e-445f-9b49-c6f0e27d5e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34280,DS-184f2f87-8250-435d-acb3-c9c6f778907e,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-806bcf3d-d89d-404f-81f9-aa96605f2244,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-0cd3f055-9e48-469b-92c0-7e61d0f6ed05,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-6489a142-b5ef-430e-a2e1-b85064cc112f,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-03fbdaa5-fb3f-40a2-9191-2e37a0d9e8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-b71e1596-0dc2-43be-94e8-c84243de76e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-379b9191-6a5e-4d4d-8fdc-62452ea655df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1307615700-172.17.0.20-1595567431750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41173,DS-6f3a58df-6b5e-445f-9b49-c6f0e27d5e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34280,DS-184f2f87-8250-435d-acb3-c9c6f778907e,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-806bcf3d-d89d-404f-81f9-aa96605f2244,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-0cd3f055-9e48-469b-92c0-7e61d0f6ed05,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-6489a142-b5ef-430e-a2e1-b85064cc112f,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-03fbdaa5-fb3f-40a2-9191-2e37a0d9e8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-b71e1596-0dc2-43be-94e8-c84243de76e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-379b9191-6a5e-4d4d-8fdc-62452ea655df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: might be true error
Total execution time in seconds : 5382
