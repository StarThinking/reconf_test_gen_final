reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-857652421-172.17.0.2-1595910283423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38561,DS-4b9f3e20-8f36-4829-9c65-bf94e62c6626,DISK], DatanodeInfoWithStorage[127.0.0.1:37051,DS-6f25dac9-9fb5-4775-b208-66284095fde6,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-3918231b-1475-4c5e-a70b-5bbb9bb0fd8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-cfbac6bc-7e53-4daf-8fb2-169bea48ab6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-b11c415c-90bd-445c-a2b9-32ed098eb449,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-faa5e1a7-622c-46e5-9f80-3a5c36ad544d,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-dfe66f18-a3e7-4f61-8957-44ea46c44cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-1cfb5e60-1167-481c-a32e-de0b9d945c2c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-857652421-172.17.0.2-1595910283423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38561,DS-4b9f3e20-8f36-4829-9c65-bf94e62c6626,DISK], DatanodeInfoWithStorage[127.0.0.1:37051,DS-6f25dac9-9fb5-4775-b208-66284095fde6,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-3918231b-1475-4c5e-a70b-5bbb9bb0fd8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-cfbac6bc-7e53-4daf-8fb2-169bea48ab6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-b11c415c-90bd-445c-a2b9-32ed098eb449,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-faa5e1a7-622c-46e5-9f80-3a5c36ad544d,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-dfe66f18-a3e7-4f61-8957-44ea46c44cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-1cfb5e60-1167-481c-a32e-de0b9d945c2c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1468827707-172.17.0.2-1595910349709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41188,DS-ca38e993-b8b9-4806-a46d-04863b665253,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-aad8a81a-cbde-42b6-a6f3-6b4ce0efde95,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-f2fb61ae-35a6-4402-9dcf-f82be1c03e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-e3bf6e91-e068-4528-ad0e-edb1d4d7266d,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-ff7861e9-76f9-4710-8e72-31979307056c,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-f5d01eb2-4f63-40b3-95de-fec14be55397,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-3e378570-265e-4a74-a0ce-aa4a3b8039c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-d8e962a9-0f21-4861-b4c6-b435fcbf6cd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1468827707-172.17.0.2-1595910349709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41188,DS-ca38e993-b8b9-4806-a46d-04863b665253,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-aad8a81a-cbde-42b6-a6f3-6b4ce0efde95,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-f2fb61ae-35a6-4402-9dcf-f82be1c03e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-e3bf6e91-e068-4528-ad0e-edb1d4d7266d,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-ff7861e9-76f9-4710-8e72-31979307056c,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-f5d01eb2-4f63-40b3-95de-fec14be55397,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-3e378570-265e-4a74-a0ce-aa4a3b8039c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-d8e962a9-0f21-4861-b4c6-b435fcbf6cd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-193828117-172.17.0.2-1595910590158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35695,DS-906d3e18-ed04-4869-a5c0-cccfebe1c50b,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-3c6dc3c2-ac92-4df7-9f91-ded14a92212d,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-86090f84-9a4b-4d3f-895c-7d2a085c9369,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-eba3f8e5-1081-4399-bd78-2f932b2c15c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-948c6569-3f6b-4cd9-8dd1-e70651057ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-166336f0-d9f1-4c70-8850-0884371f9752,DISK], DatanodeInfoWithStorage[127.0.0.1:37032,DS-b48ad610-031f-4d0f-86d7-7d9b7aada847,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-e4082c58-dc0f-454b-80b3-51b46f8c46e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-193828117-172.17.0.2-1595910590158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35695,DS-906d3e18-ed04-4869-a5c0-cccfebe1c50b,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-3c6dc3c2-ac92-4df7-9f91-ded14a92212d,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-86090f84-9a4b-4d3f-895c-7d2a085c9369,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-eba3f8e5-1081-4399-bd78-2f932b2c15c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-948c6569-3f6b-4cd9-8dd1-e70651057ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-166336f0-d9f1-4c70-8850-0884371f9752,DISK], DatanodeInfoWithStorage[127.0.0.1:37032,DS-b48ad610-031f-4d0f-86d7-7d9b7aada847,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-e4082c58-dc0f-454b-80b3-51b46f8c46e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-361481633-172.17.0.2-1595910620770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42730,DS-af35ea1c-f01f-49e3-ab30-b111ec475541,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-8124f047-6197-4bb6-a357-89916786e7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-9a446e35-456c-45ef-acc8-91da98439012,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-507f69bf-7ff5-494e-a098-e4818127f67e,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-7e41a4cb-0ed6-4d34-b57c-55d576fc9fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:37720,DS-08fbc1ce-9863-4d94-8dd6-962cf7b3e6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-e632ab67-5ec3-4159-a84e-a9fa7aef5a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-c415c265-e3d3-44ac-9c81-157b4599cd32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-361481633-172.17.0.2-1595910620770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42730,DS-af35ea1c-f01f-49e3-ab30-b111ec475541,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-8124f047-6197-4bb6-a357-89916786e7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-9a446e35-456c-45ef-acc8-91da98439012,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-507f69bf-7ff5-494e-a098-e4818127f67e,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-7e41a4cb-0ed6-4d34-b57c-55d576fc9fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:37720,DS-08fbc1ce-9863-4d94-8dd6-962cf7b3e6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-e632ab67-5ec3-4159-a84e-a9fa7aef5a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-c415c265-e3d3-44ac-9c81-157b4599cd32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-828421788-172.17.0.2-1595910687453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40681,DS-3278c11c-58f2-4e1c-818c-95a53b66c357,DISK], DatanodeInfoWithStorage[127.0.0.1:45362,DS-2e94f786-d08b-4bf9-ba6b-ee76b5b96c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-da294cdf-bbd2-4da6-8831-93819607b101,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-5b2aa1e9-d3a6-4d74-b148-65de5988b7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-3a394d86-6955-442f-afdc-6ff3a5ec7d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-a4e0f318-c80a-4e6b-a420-5b0e5735f00b,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-2a756eb3-2ca1-4dfe-87d9-06627c26d5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-14b3efea-862a-425d-be1a-11d8e791fddf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-828421788-172.17.0.2-1595910687453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40681,DS-3278c11c-58f2-4e1c-818c-95a53b66c357,DISK], DatanodeInfoWithStorage[127.0.0.1:45362,DS-2e94f786-d08b-4bf9-ba6b-ee76b5b96c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-da294cdf-bbd2-4da6-8831-93819607b101,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-5b2aa1e9-d3a6-4d74-b148-65de5988b7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-3a394d86-6955-442f-afdc-6ff3a5ec7d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-a4e0f318-c80a-4e6b-a420-5b0e5735f00b,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-2a756eb3-2ca1-4dfe-87d9-06627c26d5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-14b3efea-862a-425d-be1a-11d8e791fddf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1884616647-172.17.0.2-1595910846920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42563,DS-0196e7cf-effd-4bdf-b65c-26da982b07b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-e8af8270-5be8-4520-937b-9c5a0ba97b00,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-d5980c76-212e-4cae-a6d1-81188971e579,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-f3e5fb73-8304-4e09-8afd-14c99c9a4642,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-b74567d6-5926-4eda-b1fb-6684a0cd43c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-b93aca1b-7ef9-4d7a-8cdd-1a87cc70c4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41519,DS-adceea48-b060-4bd1-9c76-f1a6bc3fff28,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-d7169015-75eb-4cbe-9332-612c5a8dc051,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1884616647-172.17.0.2-1595910846920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42563,DS-0196e7cf-effd-4bdf-b65c-26da982b07b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-e8af8270-5be8-4520-937b-9c5a0ba97b00,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-d5980c76-212e-4cae-a6d1-81188971e579,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-f3e5fb73-8304-4e09-8afd-14c99c9a4642,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-b74567d6-5926-4eda-b1fb-6684a0cd43c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-b93aca1b-7ef9-4d7a-8cdd-1a87cc70c4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41519,DS-adceea48-b060-4bd1-9c76-f1a6bc3fff28,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-d7169015-75eb-4cbe-9332-612c5a8dc051,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2038679083-172.17.0.2-1595911584020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42075,DS-b3134ca9-39af-4f74-af0d-675b152301ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-3dce335d-1772-44b3-9e35-34075b38c670,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-14abd6ae-f8b1-4867-a4b2-8c9d1e56886b,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-6fca7f1a-0928-4975-8404-c09fc7a8b7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-d8e22740-1949-460c-b057-dbe25bb16373,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-709f94a1-5625-42c3-adc0-158c444c0461,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-2c65a6d6-5722-4a67-82f4-e11d35811537,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-d1d6e17a-eebb-41ce-98fa-412de7e14062,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2038679083-172.17.0.2-1595911584020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42075,DS-b3134ca9-39af-4f74-af0d-675b152301ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-3dce335d-1772-44b3-9e35-34075b38c670,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-14abd6ae-f8b1-4867-a4b2-8c9d1e56886b,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-6fca7f1a-0928-4975-8404-c09fc7a8b7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-d8e22740-1949-460c-b057-dbe25bb16373,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-709f94a1-5625-42c3-adc0-158c444c0461,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-2c65a6d6-5722-4a67-82f4-e11d35811537,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-d1d6e17a-eebb-41ce-98fa-412de7e14062,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2069870031-172.17.0.2-1595911691478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42785,DS-02ed2768-7a82-43d0-a4a7-95ec1f406c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45978,DS-8c28a51b-7375-4c00-8737-50e0706084bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-70b3fe21-4b55-416f-a28b-37621348eb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-de3a20e4-7510-4f74-90e1-feeb162b64a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34467,DS-9079c68a-1d69-4106-a7ac-9fbe1ece6297,DISK], DatanodeInfoWithStorage[127.0.0.1:46529,DS-6996a0ce-5300-4bcf-8fc1-18e372797e77,DISK], DatanodeInfoWithStorage[127.0.0.1:38643,DS-7b6d9d77-271e-4399-aca4-6e15aba50529,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-c5cb9a3c-0ecb-42b3-845f-8210e1031780,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2069870031-172.17.0.2-1595911691478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42785,DS-02ed2768-7a82-43d0-a4a7-95ec1f406c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45978,DS-8c28a51b-7375-4c00-8737-50e0706084bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-70b3fe21-4b55-416f-a28b-37621348eb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-de3a20e4-7510-4f74-90e1-feeb162b64a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34467,DS-9079c68a-1d69-4106-a7ac-9fbe1ece6297,DISK], DatanodeInfoWithStorage[127.0.0.1:46529,DS-6996a0ce-5300-4bcf-8fc1-18e372797e77,DISK], DatanodeInfoWithStorage[127.0.0.1:38643,DS-7b6d9d77-271e-4399-aca4-6e15aba50529,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-c5cb9a3c-0ecb-42b3-845f-8210e1031780,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-643704500-172.17.0.2-1595911726012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43381,DS-fd893755-b985-469c-9194-3c852c370ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-fcff08af-9da3-4739-b19b-633d0487dce7,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-921f3f08-20f3-41e8-9a37-0cfdbbd3af5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-762ac029-30f1-45f0-8ed1-6df0ada30376,DISK], DatanodeInfoWithStorage[127.0.0.1:32774,DS-9a9c7eb6-6492-43ca-adc0-998c1286a9cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-75aeb5cc-16a1-4379-9ab5-f84298c457cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-5d6c6cc4-a5b8-4961-bc4c-c529dd7a7a37,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-79991e87-931e-4b3e-813d-f60a9bdb92b7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-643704500-172.17.0.2-1595911726012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43381,DS-fd893755-b985-469c-9194-3c852c370ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-fcff08af-9da3-4739-b19b-633d0487dce7,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-921f3f08-20f3-41e8-9a37-0cfdbbd3af5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-762ac029-30f1-45f0-8ed1-6df0ada30376,DISK], DatanodeInfoWithStorage[127.0.0.1:32774,DS-9a9c7eb6-6492-43ca-adc0-998c1286a9cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-75aeb5cc-16a1-4379-9ab5-f84298c457cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-5d6c6cc4-a5b8-4961-bc4c-c529dd7a7a37,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-79991e87-931e-4b3e-813d-f60a9bdb92b7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-460374627-172.17.0.2-1595912122437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38040,DS-08cf879b-f1bc-420d-a293-882bd078b5af,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-cf89696b-5e34-4559-aab8-6a3cda16fbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-f2d39704-f15b-4511-8f9b-f6efdece21d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43228,DS-0b3d13d0-8a80-4fa3-b9bb-ea2aa2dbc523,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-36393228-f9d6-41b0-9d50-596a159db511,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-3df9defb-a8d8-451c-8dfd-4b994f7d79bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-6a4e246d-85c7-4110-bb1a-31425a16f27d,DISK], DatanodeInfoWithStorage[127.0.0.1:46856,DS-23b7782d-a1aa-4c9e-92dd-8aae14467ea5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-460374627-172.17.0.2-1595912122437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38040,DS-08cf879b-f1bc-420d-a293-882bd078b5af,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-cf89696b-5e34-4559-aab8-6a3cda16fbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-f2d39704-f15b-4511-8f9b-f6efdece21d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43228,DS-0b3d13d0-8a80-4fa3-b9bb-ea2aa2dbc523,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-36393228-f9d6-41b0-9d50-596a159db511,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-3df9defb-a8d8-451c-8dfd-4b994f7d79bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-6a4e246d-85c7-4110-bb1a-31425a16f27d,DISK], DatanodeInfoWithStorage[127.0.0.1:46856,DS-23b7782d-a1aa-4c9e-92dd-8aae14467ea5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1960359738-172.17.0.2-1595912339049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43721,DS-a86286fb-9b85-486d-bd6e-65b1429fbac2,DISK], DatanodeInfoWithStorage[127.0.0.1:42990,DS-944e18f8-06ed-4cd4-a736-9415b17879dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-625fd212-67c0-4393-8cbd-2d923595c370,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-8c200abf-b60a-49b7-b35c-1d783ecd901c,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-f9b9ef01-4693-4059-ba85-86e57e9c37d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45168,DS-27ab24af-8da5-4b78-a6e2-9a3dce5a7a99,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-006b66fe-66df-40ca-8970-e03cfd162d29,DISK], DatanodeInfoWithStorage[127.0.0.1:44782,DS-369cf78c-7c19-465d-9c65-6d38177879a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1960359738-172.17.0.2-1595912339049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43721,DS-a86286fb-9b85-486d-bd6e-65b1429fbac2,DISK], DatanodeInfoWithStorage[127.0.0.1:42990,DS-944e18f8-06ed-4cd4-a736-9415b17879dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-625fd212-67c0-4393-8cbd-2d923595c370,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-8c200abf-b60a-49b7-b35c-1d783ecd901c,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-f9b9ef01-4693-4059-ba85-86e57e9c37d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45168,DS-27ab24af-8da5-4b78-a6e2-9a3dce5a7a99,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-006b66fe-66df-40ca-8970-e03cfd162d29,DISK], DatanodeInfoWithStorage[127.0.0.1:44782,DS-369cf78c-7c19-465d-9c65-6d38177879a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1641122143-172.17.0.2-1595912376346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45685,DS-88b19d67-74a6-46d2-8f03-40672dcb62d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-06151054-ee84-43df-9809-3e89b1046804,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-824ff110-c3d4-458c-9ec0-0289b6b68eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-27ea39b4-c799-424f-9e10-88f22b69ad70,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-bc443ad5-6058-4983-a7f8-1530f2ccfeda,DISK], DatanodeInfoWithStorage[127.0.0.1:44847,DS-49321e9b-a0bc-4bd5-90f7-9c4e45ec002d,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-7cb1f237-7426-4864-8812-942f2c5733ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-7a1697c6-3156-488b-9e6c-c91502933e7f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1641122143-172.17.0.2-1595912376346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45685,DS-88b19d67-74a6-46d2-8f03-40672dcb62d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-06151054-ee84-43df-9809-3e89b1046804,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-824ff110-c3d4-458c-9ec0-0289b6b68eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-27ea39b4-c799-424f-9e10-88f22b69ad70,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-bc443ad5-6058-4983-a7f8-1530f2ccfeda,DISK], DatanodeInfoWithStorage[127.0.0.1:44847,DS-49321e9b-a0bc-4bd5-90f7-9c4e45ec002d,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-7cb1f237-7426-4864-8812-942f2c5733ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-7a1697c6-3156-488b-9e6c-c91502933e7f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1581660189-172.17.0.2-1595912638558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33997,DS-c983c238-bce0-418d-b237-22b4d0479687,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-daa3efbc-2b68-4ee8-89f7-07ec3f767d55,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-c8afc23d-e95e-4dce-bcc6-cd91c11fad44,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-d12b1d08-ca61-4c36-85dd-dea3a5f9f899,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-36f0ee5a-a466-4fb9-b69e-d50338e3655d,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-a4011d8f-d09f-4fea-afad-e7f3371e1db9,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-54c69a68-06a7-4b42-99d3-61fc2fe42edb,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-c5c329b4-bdbe-48f3-98ec-12dda1c56fb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1581660189-172.17.0.2-1595912638558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33997,DS-c983c238-bce0-418d-b237-22b4d0479687,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-daa3efbc-2b68-4ee8-89f7-07ec3f767d55,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-c8afc23d-e95e-4dce-bcc6-cd91c11fad44,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-d12b1d08-ca61-4c36-85dd-dea3a5f9f899,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-36f0ee5a-a466-4fb9-b69e-d50338e3655d,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-a4011d8f-d09f-4fea-afad-e7f3371e1db9,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-54c69a68-06a7-4b42-99d3-61fc2fe42edb,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-c5c329b4-bdbe-48f3-98ec-12dda1c56fb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-566985731-172.17.0.2-1595912742089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37057,DS-5a7fcd2e-d0d8-4015-a1d1-f5552c81d02b,DISK], DatanodeInfoWithStorage[127.0.0.1:37892,DS-fbf1a398-a5b2-461f-b26e-d6940cc5e1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45141,DS-db5a5545-f653-4735-a936-0c29ff77f86a,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-a41c0524-9c1e-4ff0-94a0-4cc18cf343b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-3094d38c-e39e-4302-aa8f-2429fffd6c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-7964675c-1318-4ef0-92e6-64670afbd314,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-0c8556d3-db9a-40b8-903e-5c4363461b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-d4e76ad4-268c-47ee-9888-4ff1f3731a89,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-566985731-172.17.0.2-1595912742089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37057,DS-5a7fcd2e-d0d8-4015-a1d1-f5552c81d02b,DISK], DatanodeInfoWithStorage[127.0.0.1:37892,DS-fbf1a398-a5b2-461f-b26e-d6940cc5e1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45141,DS-db5a5545-f653-4735-a936-0c29ff77f86a,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-a41c0524-9c1e-4ff0-94a0-4cc18cf343b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-3094d38c-e39e-4302-aa8f-2429fffd6c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-7964675c-1318-4ef0-92e6-64670afbd314,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-0c8556d3-db9a-40b8-903e-5c4363461b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-d4e76ad4-268c-47ee-9888-4ff1f3731a89,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-289263932-172.17.0.2-1595912911075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42691,DS-1ee93ffa-701a-48eb-9fd6-db30edaedf2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-060248d0-6837-4583-bb58-fed76848af33,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-37218244-50d3-4902-abca-9ed7a627da8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-7cdc7ba7-65ca-4a2c-86a6-8922e25a3897,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-d6393e56-f6ad-47e4-8b6f-b8978ba70f30,DISK], DatanodeInfoWithStorage[127.0.0.1:38993,DS-d892ec3a-d479-499b-a84f-e4b4435152d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-5b1f566f-3b3d-400c-8ded-7a47b606cfae,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-f3dc473e-61cb-4225-a73e-99f37d430f90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-289263932-172.17.0.2-1595912911075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42691,DS-1ee93ffa-701a-48eb-9fd6-db30edaedf2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-060248d0-6837-4583-bb58-fed76848af33,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-37218244-50d3-4902-abca-9ed7a627da8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-7cdc7ba7-65ca-4a2c-86a6-8922e25a3897,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-d6393e56-f6ad-47e4-8b6f-b8978ba70f30,DISK], DatanodeInfoWithStorage[127.0.0.1:38993,DS-d892ec3a-d479-499b-a84f-e4b4435152d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-5b1f566f-3b3d-400c-8ded-7a47b606cfae,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-f3dc473e-61cb-4225-a73e-99f37d430f90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1741834230-172.17.0.2-1595913097928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42178,DS-58c576e2-7c06-48d6-b619-e59ed9f05a91,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-21ccde90-e165-458a-bf39-c75e8b783a25,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-cedba106-0c4e-40cb-9fe7-08134ca3023d,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-5fb224a6-34d7-47c3-993a-9b9e154fa804,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-8889b048-cede-4574-9392-2556e737e998,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-cea73e3d-c88f-4042-8c79-69f69bf27739,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-09202359-66ce-4a3b-9690-96912999f0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-d41ec34a-d1a6-45b0-88f1-2aeff3e846da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1741834230-172.17.0.2-1595913097928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42178,DS-58c576e2-7c06-48d6-b619-e59ed9f05a91,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-21ccde90-e165-458a-bf39-c75e8b783a25,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-cedba106-0c4e-40cb-9fe7-08134ca3023d,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-5fb224a6-34d7-47c3-993a-9b9e154fa804,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-8889b048-cede-4574-9392-2556e737e998,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-cea73e3d-c88f-4042-8c79-69f69bf27739,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-09202359-66ce-4a3b-9690-96912999f0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-d41ec34a-d1a6-45b0-88f1-2aeff3e846da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1423190686-172.17.0.2-1595913140125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33281,DS-cb81d215-fbe7-4f2d-8e2a-88718b140a19,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-2f0890a8-97db-4dc0-b6e6-e9b70f7c6a74,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-e5e96645-5a0a-4d74-b010-e153937579e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33725,DS-1bd0d258-992d-4643-b64a-f5d8763dae8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-c64b5d0c-1225-45e3-aed5-a33f8ba55be6,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-9d9a8de9-c896-4344-a20e-9831cad258d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-3e057d02-60e5-473b-b673-a0142e6653d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41109,DS-0e3b438f-faec-445b-9ce7-ad0ce219090d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1423190686-172.17.0.2-1595913140125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33281,DS-cb81d215-fbe7-4f2d-8e2a-88718b140a19,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-2f0890a8-97db-4dc0-b6e6-e9b70f7c6a74,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-e5e96645-5a0a-4d74-b010-e153937579e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33725,DS-1bd0d258-992d-4643-b64a-f5d8763dae8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-c64b5d0c-1225-45e3-aed5-a33f8ba55be6,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-9d9a8de9-c896-4344-a20e-9831cad258d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-3e057d02-60e5-473b-b673-a0142e6653d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41109,DS-0e3b438f-faec-445b-9ce7-ad0ce219090d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1717852124-172.17.0.2-1595913171316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44387,DS-666f274a-4af2-4454-9849-95db9163e4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-71d1acfe-be44-40d3-85ef-5b761a8679db,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-11b71ab2-d332-4f8f-b566-fbf273bc94da,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-8a36e147-7446-4b26-aaf5-dd402e9d9bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-e30bfef3-c8cd-4232-8c8b-9ef1d63cb0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-26bbad35-1987-4cbf-9e90-da0a4a70744e,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-7f872c78-0570-42ed-9001-e3f032192ded,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-d446e175-81ad-4e43-87bc-3d89a9ba20be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1717852124-172.17.0.2-1595913171316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44387,DS-666f274a-4af2-4454-9849-95db9163e4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-71d1acfe-be44-40d3-85ef-5b761a8679db,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-11b71ab2-d332-4f8f-b566-fbf273bc94da,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-8a36e147-7446-4b26-aaf5-dd402e9d9bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-e30bfef3-c8cd-4232-8c8b-9ef1d63cb0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-26bbad35-1987-4cbf-9e90-da0a4a70744e,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-7f872c78-0570-42ed-9001-e3f032192ded,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-d446e175-81ad-4e43-87bc-3d89a9ba20be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-756377852-172.17.0.2-1595913247400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32986,DS-fdac1353-a358-4009-bb10-469850ebf3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42071,DS-102496ac-00bd-4f96-ba22-7fac3cc1a061,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-e8e33da6-95ed-4072-bf33-69afc9e2ea9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-8d15a0bb-732a-4d8d-9843-616d79d305aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-734ca162-d619-44ff-8fe2-972512c2cccf,DISK], DatanodeInfoWithStorage[127.0.0.1:46362,DS-487bf0c4-73be-43cb-ba0c-2cb43b163be1,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-35e9ba26-785e-45dd-a40e-5a939e8d679a,DISK], DatanodeInfoWithStorage[127.0.0.1:33464,DS-120b2fb2-da68-4e00-a946-62f0076dedbb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-756377852-172.17.0.2-1595913247400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32986,DS-fdac1353-a358-4009-bb10-469850ebf3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42071,DS-102496ac-00bd-4f96-ba22-7fac3cc1a061,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-e8e33da6-95ed-4072-bf33-69afc9e2ea9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-8d15a0bb-732a-4d8d-9843-616d79d305aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-734ca162-d619-44ff-8fe2-972512c2cccf,DISK], DatanodeInfoWithStorage[127.0.0.1:46362,DS-487bf0c4-73be-43cb-ba0c-2cb43b163be1,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-35e9ba26-785e-45dd-a40e-5a939e8d679a,DISK], DatanodeInfoWithStorage[127.0.0.1:33464,DS-120b2fb2-da68-4e00-a946-62f0076dedbb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-41573315-172.17.0.2-1595913316382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33165,DS-390bcab0-fc5b-4870-83e7-9386bc19a85e,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-7540146e-efcc-4680-880f-82aa66bfd59e,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-020f5d4d-7028-473d-9f04-d39c315979ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-42748ce0-4bf4-46f4-b471-cab8fcfc4323,DISK], DatanodeInfoWithStorage[127.0.0.1:40772,DS-a5ef23c4-8660-49dc-96ba-f021559f8290,DISK], DatanodeInfoWithStorage[127.0.0.1:42970,DS-d4c11f0d-3e0c-4011-9ce8-b0dbca75513a,DISK], DatanodeInfoWithStorage[127.0.0.1:36802,DS-47e3a9af-cf17-4051-938a-43e487323eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-ee8c0925-fbd4-497e-9f68-3053ca846f30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-41573315-172.17.0.2-1595913316382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33165,DS-390bcab0-fc5b-4870-83e7-9386bc19a85e,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-7540146e-efcc-4680-880f-82aa66bfd59e,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-020f5d4d-7028-473d-9f04-d39c315979ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-42748ce0-4bf4-46f4-b471-cab8fcfc4323,DISK], DatanodeInfoWithStorage[127.0.0.1:40772,DS-a5ef23c4-8660-49dc-96ba-f021559f8290,DISK], DatanodeInfoWithStorage[127.0.0.1:42970,DS-d4c11f0d-3e0c-4011-9ce8-b0dbca75513a,DISK], DatanodeInfoWithStorage[127.0.0.1:36802,DS-47e3a9af-cf17-4051-938a-43e487323eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-ee8c0925-fbd4-497e-9f68-3053ca846f30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-448904709-172.17.0.2-1595913434849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39845,DS-83c36c6c-75e3-4bc9-b715-456f2a25e890,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-7d132d46-c5ad-4daa-bac5-8529b795dcdb,DISK], DatanodeInfoWithStorage[127.0.0.1:36222,DS-67edc47a-5528-4d48-af27-8d083de159fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-ddbde8d9-6699-4251-a5b1-c1db9b42607f,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-a5885e5f-42d6-4fe4-b9ea-54d793e99bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-92b863c6-97c2-4427-b7fa-af0fabe65aba,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-2271c0ad-8324-48d3-bb4d-04b31ac81dff,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-658421d5-7856-4f45-b4c0-b9783c672a71,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-448904709-172.17.0.2-1595913434849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39845,DS-83c36c6c-75e3-4bc9-b715-456f2a25e890,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-7d132d46-c5ad-4daa-bac5-8529b795dcdb,DISK], DatanodeInfoWithStorage[127.0.0.1:36222,DS-67edc47a-5528-4d48-af27-8d083de159fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-ddbde8d9-6699-4251-a5b1-c1db9b42607f,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-a5885e5f-42d6-4fe4-b9ea-54d793e99bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-92b863c6-97c2-4427-b7fa-af0fabe65aba,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-2271c0ad-8324-48d3-bb4d-04b31ac81dff,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-658421d5-7856-4f45-b4c0-b9783c672a71,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-571317620-172.17.0.2-1595913469718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42673,DS-50114abc-2fcd-4756-986f-d7dd25eb8848,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-1caa3f8e-87a3-476f-b81c-14036b890720,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-eca02818-2a7b-4ecd-a1a0-d4d750aac957,DISK], DatanodeInfoWithStorage[127.0.0.1:39350,DS-a5a8e67f-b181-4f24-9e20-1b7f34aad049,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-aa055246-12ad-4783-a420-3fa1b19643fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-b5611b7d-0162-42f9-9c05-a9c9a381ea3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-a3eaf16d-3d3d-4e79-8f9a-89b6ccba002e,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-a3dc5e7e-5e3b-4da9-ad93-94ed14a68a9f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-571317620-172.17.0.2-1595913469718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42673,DS-50114abc-2fcd-4756-986f-d7dd25eb8848,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-1caa3f8e-87a3-476f-b81c-14036b890720,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-eca02818-2a7b-4ecd-a1a0-d4d750aac957,DISK], DatanodeInfoWithStorage[127.0.0.1:39350,DS-a5a8e67f-b181-4f24-9e20-1b7f34aad049,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-aa055246-12ad-4783-a420-3fa1b19643fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-b5611b7d-0162-42f9-9c05-a9c9a381ea3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-a3eaf16d-3d3d-4e79-8f9a-89b6ccba002e,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-a3dc5e7e-5e3b-4da9-ad93-94ed14a68a9f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-946582429-172.17.0.2-1595913499945:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36083,DS-6d662f03-a6bb-44d3-82d2-bbd91232493b,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-e30d9947-e8d3-48ed-be3d-e894e93a879e,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-86133623-d55e-453a-9bcb-bf811c7eabe3,DISK], DatanodeInfoWithStorage[127.0.0.1:40664,DS-f4d88597-3ec4-44c3-a0c3-14f6fc766a35,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-46e79cfe-31a6-44da-9eb8-1c423907b613,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-c0c420eb-8e8d-499b-a7ce-45d6cc706533,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-e38eefb3-05ce-44fb-8fd3-37ccb24bfa1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-27abe61d-73c9-4bb5-8287-b0ed8eb7df06,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-946582429-172.17.0.2-1595913499945:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36083,DS-6d662f03-a6bb-44d3-82d2-bbd91232493b,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-e30d9947-e8d3-48ed-be3d-e894e93a879e,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-86133623-d55e-453a-9bcb-bf811c7eabe3,DISK], DatanodeInfoWithStorage[127.0.0.1:40664,DS-f4d88597-3ec4-44c3-a0c3-14f6fc766a35,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-46e79cfe-31a6-44da-9eb8-1c423907b613,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-c0c420eb-8e8d-499b-a7ce-45d6cc706533,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-e38eefb3-05ce-44fb-8fd3-37ccb24bfa1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-27abe61d-73c9-4bb5-8287-b0ed8eb7df06,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457045282-172.17.0.2-1595913539596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38428,DS-8cc6a1be-d038-401c-87b4-310705daf911,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-e02e93d2-197e-4395-a10a-0d1cb3550182,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-d78f7a38-67f0-4e18-a503-bc9c23953759,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-8a296295-bda3-46c3-955d-9a45737e4fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-c261c9a0-3fba-4731-96c8-944f5a9010b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-fd3889f8-d422-47ed-b196-0db09f897bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-07567c31-458a-468c-a0c9-8450b81e388f,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-dbc57250-4277-4362-baea-57cbd393fb1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457045282-172.17.0.2-1595913539596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38428,DS-8cc6a1be-d038-401c-87b4-310705daf911,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-e02e93d2-197e-4395-a10a-0d1cb3550182,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-d78f7a38-67f0-4e18-a503-bc9c23953759,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-8a296295-bda3-46c3-955d-9a45737e4fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-c261c9a0-3fba-4731-96c8-944f5a9010b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-fd3889f8-d422-47ed-b196-0db09f897bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-07567c31-458a-468c-a0c9-8450b81e388f,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-dbc57250-4277-4362-baea-57cbd393fb1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-505590919-172.17.0.2-1595914158621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37858,DS-a7367d13-7d43-41a3-a187-16b386e50f86,DISK], DatanodeInfoWithStorage[127.0.0.1:38415,DS-c9ff2e3b-5881-4505-ba7b-1ba7f94bdb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-aa2862fe-ee68-4461-91f5-0feffd0faf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-140a8b48-de3e-4753-af97-f8610ad976df,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-75dc73fb-b8b0-440a-85a0-28c12f5ced9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-def29a6f-502d-43af-9f72-5e316f9aecd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41515,DS-c5d6d377-666d-409a-bcd6-f23e778409bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-82c788a0-0e78-498d-8b93-e610fcf069f1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-505590919-172.17.0.2-1595914158621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37858,DS-a7367d13-7d43-41a3-a187-16b386e50f86,DISK], DatanodeInfoWithStorage[127.0.0.1:38415,DS-c9ff2e3b-5881-4505-ba7b-1ba7f94bdb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-aa2862fe-ee68-4461-91f5-0feffd0faf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-140a8b48-de3e-4753-af97-f8610ad976df,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-75dc73fb-b8b0-440a-85a0-28c12f5ced9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-def29a6f-502d-43af-9f72-5e316f9aecd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41515,DS-c5d6d377-666d-409a-bcd6-f23e778409bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-82c788a0-0e78-498d-8b93-e610fcf069f1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-356024082-172.17.0.2-1595914300474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35922,DS-145a06d6-e133-41d4-91a0-e9c38fa57acf,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-b8dabee1-2e8a-415c-8cf3-c9505a9ee3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-ea9940b6-d004-40cd-9af7-3aa3ba29518b,DISK], DatanodeInfoWithStorage[127.0.0.1:43142,DS-12daa93a-10a1-4cb5-9b25-90ada3fdd200,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-0fa9aa82-13d3-4315-b804-e15ed854cfd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-9db7bce6-745b-457e-81bd-7dfed819cf63,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-8bea8fd8-94df-42cd-84d9-abe7fc4105db,DISK], DatanodeInfoWithStorage[127.0.0.1:35056,DS-5de67d9f-6114-425d-bd59-c93b77dbf3a5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-356024082-172.17.0.2-1595914300474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35922,DS-145a06d6-e133-41d4-91a0-e9c38fa57acf,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-b8dabee1-2e8a-415c-8cf3-c9505a9ee3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-ea9940b6-d004-40cd-9af7-3aa3ba29518b,DISK], DatanodeInfoWithStorage[127.0.0.1:43142,DS-12daa93a-10a1-4cb5-9b25-90ada3fdd200,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-0fa9aa82-13d3-4315-b804-e15ed854cfd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-9db7bce6-745b-457e-81bd-7dfed819cf63,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-8bea8fd8-94df-42cd-84d9-abe7fc4105db,DISK], DatanodeInfoWithStorage[127.0.0.1:35056,DS-5de67d9f-6114-425d-bd59-c93b77dbf3a5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1037477162-172.17.0.2-1595914462456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32961,DS-0dd0d704-e1c8-4ce7-be5f-35b1a7aabc2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-3e85c528-69b4-4dd0-bf1c-ca8c6df2a7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-9c9f90aa-b764-4db9-8364-9dbba8c0bb35,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-e408d87c-bcd8-430a-8692-5988083db9af,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-21863cef-b0c6-418c-a0b2-7f470cc6b15e,DISK], DatanodeInfoWithStorage[127.0.0.1:33380,DS-05e453a4-2eef-44f1-b592-7da4d2727937,DISK], DatanodeInfoWithStorage[127.0.0.1:35866,DS-1a863146-5dd2-4174-b317-d2b255281add,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-8370d6bd-efff-43b7-a77f-83cda1bc9e66,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1037477162-172.17.0.2-1595914462456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32961,DS-0dd0d704-e1c8-4ce7-be5f-35b1a7aabc2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-3e85c528-69b4-4dd0-bf1c-ca8c6df2a7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-9c9f90aa-b764-4db9-8364-9dbba8c0bb35,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-e408d87c-bcd8-430a-8692-5988083db9af,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-21863cef-b0c6-418c-a0b2-7f470cc6b15e,DISK], DatanodeInfoWithStorage[127.0.0.1:33380,DS-05e453a4-2eef-44f1-b592-7da4d2727937,DISK], DatanodeInfoWithStorage[127.0.0.1:35866,DS-1a863146-5dd2-4174-b317-d2b255281add,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-8370d6bd-efff-43b7-a77f-83cda1bc9e66,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1982280465-172.17.0.2-1595914494299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42899,DS-db6006ec-9241-4052-9209-8d140ac9ee07,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-171d7dd7-5fbe-4247-a853-e11de86b788a,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-fe3e01e5-5d41-4b8d-95aa-41c1552245a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-dd1c6a71-74dc-4901-88a0-4a138776ffbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38141,DS-ecabcbfb-e224-4184-ac3c-563a3756c171,DISK], DatanodeInfoWithStorage[127.0.0.1:46268,DS-ccb6605f-6e06-4615-bb6d-261161587770,DISK], DatanodeInfoWithStorage[127.0.0.1:41605,DS-aea656c2-c325-46fb-9973-3d186c28ea5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-1e04238b-8d7d-4ce6-9d0f-8b9dc0020b67,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1982280465-172.17.0.2-1595914494299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42899,DS-db6006ec-9241-4052-9209-8d140ac9ee07,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-171d7dd7-5fbe-4247-a853-e11de86b788a,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-fe3e01e5-5d41-4b8d-95aa-41c1552245a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-dd1c6a71-74dc-4901-88a0-4a138776ffbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38141,DS-ecabcbfb-e224-4184-ac3c-563a3756c171,DISK], DatanodeInfoWithStorage[127.0.0.1:46268,DS-ccb6605f-6e06-4615-bb6d-261161587770,DISK], DatanodeInfoWithStorage[127.0.0.1:41605,DS-aea656c2-c325-46fb-9973-3d186c28ea5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-1e04238b-8d7d-4ce6-9d0f-8b9dc0020b67,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1920752902-172.17.0.2-1595914525343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36914,DS-bc5cb2ba-b55e-4252-a4aa-3c9834353ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-bca33eb4-94c9-46bb-bcde-af832df8faf6,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-905f46e2-75d0-46e4-bf67-a79374df8ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-6f749d12-2aac-4eac-92a5-119e7205b6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-3159a82d-6e82-49d5-a585-707f697c2469,DISK], DatanodeInfoWithStorage[127.0.0.1:38974,DS-be421258-4cd9-42a1-a1b6-46c2bf587b08,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-0ebc02f8-8c94-44fe-9c90-d1d7056649f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34545,DS-604520d4-163c-4aa3-ad21-ba02de1757f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1920752902-172.17.0.2-1595914525343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36914,DS-bc5cb2ba-b55e-4252-a4aa-3c9834353ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-bca33eb4-94c9-46bb-bcde-af832df8faf6,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-905f46e2-75d0-46e4-bf67-a79374df8ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-6f749d12-2aac-4eac-92a5-119e7205b6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-3159a82d-6e82-49d5-a585-707f697c2469,DISK], DatanodeInfoWithStorage[127.0.0.1:38974,DS-be421258-4cd9-42a1-a1b6-46c2bf587b08,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-0ebc02f8-8c94-44fe-9c90-d1d7056649f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34545,DS-604520d4-163c-4aa3-ad21-ba02de1757f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1804444770-172.17.0.2-1595914744976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37050,DS-6a5083b3-0fda-48c8-bad8-380d8e55a90a,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-ade37d95-253c-496b-8a41-2cdd92bc2d78,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-9bee3179-1aac-4086-9363-3fddca1041a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-920d65a9-2351-4064-b272-44ce8d23ce2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-c3e9f210-0871-4ebb-80ef-78de866f4c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-cf56fc12-2e6c-4cee-bf0f-1834e80ebfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38775,DS-eb4b557a-285b-4931-87ed-9d7bd4e54aae,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-2e69dfcf-8b57-4fb3-903c-8b2b8d6ae7c5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1804444770-172.17.0.2-1595914744976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37050,DS-6a5083b3-0fda-48c8-bad8-380d8e55a90a,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-ade37d95-253c-496b-8a41-2cdd92bc2d78,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-9bee3179-1aac-4086-9363-3fddca1041a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-920d65a9-2351-4064-b272-44ce8d23ce2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-c3e9f210-0871-4ebb-80ef-78de866f4c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-cf56fc12-2e6c-4cee-bf0f-1834e80ebfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38775,DS-eb4b557a-285b-4931-87ed-9d7bd4e54aae,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-2e69dfcf-8b57-4fb3-903c-8b2b8d6ae7c5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-92980742-172.17.0.2-1595914836688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44729,DS-a20970b7-b17d-4809-adf6-3f657551c3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-ce469583-adc5-46ed-bed5-3e1768951acf,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-cbd33797-7489-4029-83c2-17dd74544a23,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-ceae5248-fe43-46e0-8836-c401b96bcb04,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-c5c84ba4-be16-4e40-a736-10510201dc8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-3d71c4dd-e200-4b61-9225-45bf179fd530,DISK], DatanodeInfoWithStorage[127.0.0.1:35998,DS-64db1f0d-1d08-46b2-828c-c63745a392c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-b7a0bd78-2314-4ba1-8f08-a7b7d50a6383,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-92980742-172.17.0.2-1595914836688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44729,DS-a20970b7-b17d-4809-adf6-3f657551c3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-ce469583-adc5-46ed-bed5-3e1768951acf,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-cbd33797-7489-4029-83c2-17dd74544a23,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-ceae5248-fe43-46e0-8836-c401b96bcb04,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-c5c84ba4-be16-4e40-a736-10510201dc8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-3d71c4dd-e200-4b61-9225-45bf179fd530,DISK], DatanodeInfoWithStorage[127.0.0.1:35998,DS-64db1f0d-1d08-46b2-828c-c63745a392c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-b7a0bd78-2314-4ba1-8f08-a7b7d50a6383,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1768500417-172.17.0.2-1595914904096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32856,DS-f00e0197-638f-45e5-b69c-55be659b724f,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-16dde823-ded4-422a-98f2-7bfe3c80cfc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-353a5abe-1313-4a98-8036-e0f4ee0627a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-de8f4e62-c218-465d-b1d9-bfab41f7cff7,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-d163773a-af40-4324-8bd8-b1f2aac84448,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-dfded661-f5a7-4b1f-bed6-5d552469834e,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-704f4d55-b713-4a8f-8d80-d38c5ebe41c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-a2e2e552-d428-41ad-9dfd-a3e7b2c5d52a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1768500417-172.17.0.2-1595914904096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32856,DS-f00e0197-638f-45e5-b69c-55be659b724f,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-16dde823-ded4-422a-98f2-7bfe3c80cfc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-353a5abe-1313-4a98-8036-e0f4ee0627a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-de8f4e62-c218-465d-b1d9-bfab41f7cff7,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-d163773a-af40-4324-8bd8-b1f2aac84448,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-dfded661-f5a7-4b1f-bed6-5d552469834e,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-704f4d55-b713-4a8f-8d80-d38c5ebe41c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-a2e2e552-d428-41ad-9dfd-a3e7b2c5d52a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1232266168-172.17.0.2-1595915103492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34333,DS-e96614c6-169f-4da6-b51d-e217d38d12ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-229620a9-0b5a-4438-828e-3113a62b86ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-9a9eefa2-8cf1-49f2-93f0-5de852f5a426,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-68a06092-6309-4874-a1fb-e7e54348c96c,DISK], DatanodeInfoWithStorage[127.0.0.1:34725,DS-fbd09781-1284-451d-915b-b0b688c072e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-cc387a92-8372-4f34-af2c-ca37ff7ff958,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-a5634a21-1c78-4f66-afd2-e225a0700939,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-3bda4817-12ad-4e54-8976-b1f15dfa13fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1232266168-172.17.0.2-1595915103492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34333,DS-e96614c6-169f-4da6-b51d-e217d38d12ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-229620a9-0b5a-4438-828e-3113a62b86ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-9a9eefa2-8cf1-49f2-93f0-5de852f5a426,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-68a06092-6309-4874-a1fb-e7e54348c96c,DISK], DatanodeInfoWithStorage[127.0.0.1:34725,DS-fbd09781-1284-451d-915b-b0b688c072e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-cc387a92-8372-4f34-af2c-ca37ff7ff958,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-a5634a21-1c78-4f66-afd2-e225a0700939,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-3bda4817-12ad-4e54-8976-b1f15dfa13fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1845258996-172.17.0.2-1595915138514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44792,DS-32865ebe-373d-4668-86dc-751650cb2a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-6a988312-e59f-46f3-b704-c0c0a12c01d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-27b59d36-c8c9-4639-897e-daa492e302be,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-3c3ffb5b-9875-413b-977b-601591255383,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-47c54116-ca4a-4019-94ae-20f1b19536e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-46362c93-ee8f-4b02-a41b-ee17ed9ba984,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-864b6c68-7259-4e94-9c91-4f7ac2956a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-65882572-39f6-46a8-9a67-8dd47b6993b1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1845258996-172.17.0.2-1595915138514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44792,DS-32865ebe-373d-4668-86dc-751650cb2a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-6a988312-e59f-46f3-b704-c0c0a12c01d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-27b59d36-c8c9-4639-897e-daa492e302be,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-3c3ffb5b-9875-413b-977b-601591255383,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-47c54116-ca4a-4019-94ae-20f1b19536e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-46362c93-ee8f-4b02-a41b-ee17ed9ba984,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-864b6c68-7259-4e94-9c91-4f7ac2956a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-65882572-39f6-46a8-9a67-8dd47b6993b1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2069716001-172.17.0.2-1595915341637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46387,DS-3e30a112-dba2-4219-aaeb-88a39d6ba1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-5f3dd71b-5d92-4286-a00e-ec01b8d250df,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-c7f445b8-db15-4289-a655-43de699d567b,DISK], DatanodeInfoWithStorage[127.0.0.1:33950,DS-27edfe88-7539-4147-af4c-375614b54435,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-5668c616-b673-489b-b257-d17f8b3ce427,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-22c1ec6b-ad55-43d5-8987-ba2c371ca402,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-be07f4ea-a3e9-4218-b147-4df5647bc8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33473,DS-b5b140ee-3237-4101-afe7-6b6e8d10fd27,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2069716001-172.17.0.2-1595915341637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46387,DS-3e30a112-dba2-4219-aaeb-88a39d6ba1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-5f3dd71b-5d92-4286-a00e-ec01b8d250df,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-c7f445b8-db15-4289-a655-43de699d567b,DISK], DatanodeInfoWithStorage[127.0.0.1:33950,DS-27edfe88-7539-4147-af4c-375614b54435,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-5668c616-b673-489b-b257-d17f8b3ce427,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-22c1ec6b-ad55-43d5-8987-ba2c371ca402,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-be07f4ea-a3e9-4218-b147-4df5647bc8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33473,DS-b5b140ee-3237-4101-afe7-6b6e8d10fd27,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1482139345-172.17.0.2-1595915373244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39483,DS-030b936f-15f2-4527-9677-a087f3a699ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35348,DS-92b8f552-670b-49aa-beb9-83d6ed54ed54,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-93b3e1a2-39ab-4fb0-9b54-f72ca7de4bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-508ae942-5160-43d3-aa3c-6f66aee916c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-e895bb50-df5a-435c-9730-6a07864a3067,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-5b029950-3c0c-44a9-ab5c-33ef3a050d29,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-97180122-adef-40b6-b9ee-a9589f98e4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-55a809de-c368-4ba2-a4ec-d4cf2784f097,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1482139345-172.17.0.2-1595915373244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39483,DS-030b936f-15f2-4527-9677-a087f3a699ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35348,DS-92b8f552-670b-49aa-beb9-83d6ed54ed54,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-93b3e1a2-39ab-4fb0-9b54-f72ca7de4bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-508ae942-5160-43d3-aa3c-6f66aee916c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-e895bb50-df5a-435c-9730-6a07864a3067,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-5b029950-3c0c-44a9-ab5c-33ef3a050d29,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-97180122-adef-40b6-b9ee-a9589f98e4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-55a809de-c368-4ba2-a4ec-d4cf2784f097,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-227354931-172.17.0.2-1595915434878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41721,DS-9bac5947-765d-4f34-ab03-68208d5df533,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-66ed8689-733e-4873-869f-5c704eda84fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-8bdbaab5-9d9f-4181-9d84-f76327b3a0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-d1eef805-56aa-40fe-acab-e6c801a4f56d,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-e0977da6-12b3-4eac-ae4c-b78fa17ef926,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-6fa6cd8a-6f0d-402c-b7f1-be8ae7ea591a,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-c5f09958-03f5-45db-abdd-156c8da0a7be,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-d5cfaba2-6ffe-424b-93f4-87652003ae1d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-227354931-172.17.0.2-1595915434878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41721,DS-9bac5947-765d-4f34-ab03-68208d5df533,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-66ed8689-733e-4873-869f-5c704eda84fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-8bdbaab5-9d9f-4181-9d84-f76327b3a0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-d1eef805-56aa-40fe-acab-e6c801a4f56d,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-e0977da6-12b3-4eac-ae4c-b78fa17ef926,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-6fa6cd8a-6f0d-402c-b7f1-be8ae7ea591a,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-c5f09958-03f5-45db-abdd-156c8da0a7be,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-d5cfaba2-6ffe-424b-93f4-87652003ae1d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 23 out of 50
result: false positive !!!
Total execution time in seconds : 5185
