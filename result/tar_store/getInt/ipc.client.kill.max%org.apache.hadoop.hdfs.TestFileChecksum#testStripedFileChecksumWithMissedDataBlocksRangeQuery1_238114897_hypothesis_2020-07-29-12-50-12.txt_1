reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2018877972-172.17.0.21-1596027293010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34380,DS-c7058d3f-8233-475a-8cd1-9495add8f63c,DISK], DatanodeInfoWithStorage[127.0.0.1:37340,DS-b04408d0-d80d-4221-9631-7083e787abee,DISK], DatanodeInfoWithStorage[127.0.0.1:33407,DS-3113d822-986f-4a0b-8b55-34ef6ae94caa,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-544bdc81-72d5-41c2-8aa2-af7f9f63199c,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-82788cd5-937a-4e0f-8251-a2fa913c5765,DISK], DatanodeInfoWithStorage[127.0.0.1:35503,DS-6e929aee-595d-443a-8842-53dd36fda56f,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-07c10c74-f36b-49fb-87ec-ee5e42a46a24,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-5b7d6c48-3de2-4bf0-a016-22b0aa362644,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2018877972-172.17.0.21-1596027293010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34380,DS-c7058d3f-8233-475a-8cd1-9495add8f63c,DISK], DatanodeInfoWithStorage[127.0.0.1:37340,DS-b04408d0-d80d-4221-9631-7083e787abee,DISK], DatanodeInfoWithStorage[127.0.0.1:33407,DS-3113d822-986f-4a0b-8b55-34ef6ae94caa,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-544bdc81-72d5-41c2-8aa2-af7f9f63199c,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-82788cd5-937a-4e0f-8251-a2fa913c5765,DISK], DatanodeInfoWithStorage[127.0.0.1:35503,DS-6e929aee-595d-443a-8842-53dd36fda56f,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-07c10c74-f36b-49fb-87ec-ee5e42a46a24,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-5b7d6c48-3de2-4bf0-a016-22b0aa362644,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-991894907-172.17.0.21-1596027544165:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42430,DS-89ae726f-ab30-401f-93db-ba78d3ac018d,DISK], DatanodeInfoWithStorage[127.0.0.1:36787,DS-ee7b2323-0c39-433a-ba94-0e9b8c0ee95d,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-7a97cf54-e2fe-4b70-8546-5e65dd1153c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-02d56132-4a29-4480-9428-1f7101fdb4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-2e96194b-2757-423d-adb9-9e6aaa2e98e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-760dca48-60c9-453e-b7b1-326793e991c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-c2349ad3-adf2-4b97-85a5-28cbf3144257,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-1479f5ed-1f4a-45ae-ae14-a58d6bad53a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-991894907-172.17.0.21-1596027544165:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42430,DS-89ae726f-ab30-401f-93db-ba78d3ac018d,DISK], DatanodeInfoWithStorage[127.0.0.1:36787,DS-ee7b2323-0c39-433a-ba94-0e9b8c0ee95d,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-7a97cf54-e2fe-4b70-8546-5e65dd1153c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-02d56132-4a29-4480-9428-1f7101fdb4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-2e96194b-2757-423d-adb9-9e6aaa2e98e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-760dca48-60c9-453e-b7b1-326793e991c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-c2349ad3-adf2-4b97-85a5-28cbf3144257,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-1479f5ed-1f4a-45ae-ae14-a58d6bad53a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1729385005-172.17.0.21-1596027788983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44579,DS-f1be3cd8-a290-4a3b-925b-fefe7a550b63,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-2217b5ce-3f40-4dad-89a1-d0d492dfdae1,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-4e32f20e-f917-4798-8029-684fe8b9ef11,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-855c55c1-8c54-44f7-8fd0-3da25fdffe47,DISK], DatanodeInfoWithStorage[127.0.0.1:35560,DS-647fb826-4efc-4501-8b91-ee57f4306c77,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-79c82dba-1dc9-4fe8-9cf1-ee6002ddf5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35090,DS-2a3b9d61-d53a-4831-9f35-75f27c411bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34446,DS-d7ab05ff-4ee5-4170-8a2d-1182b6c445c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1729385005-172.17.0.21-1596027788983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44579,DS-f1be3cd8-a290-4a3b-925b-fefe7a550b63,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-2217b5ce-3f40-4dad-89a1-d0d492dfdae1,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-4e32f20e-f917-4798-8029-684fe8b9ef11,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-855c55c1-8c54-44f7-8fd0-3da25fdffe47,DISK], DatanodeInfoWithStorage[127.0.0.1:35560,DS-647fb826-4efc-4501-8b91-ee57f4306c77,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-79c82dba-1dc9-4fe8-9cf1-ee6002ddf5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35090,DS-2a3b9d61-d53a-4831-9f35-75f27c411bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34446,DS-d7ab05ff-4ee5-4170-8a2d-1182b6c445c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-903551314-172.17.0.21-1596028154767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40498,DS-f089ad25-8459-4aff-8333-b4a57fc9e550,DISK], DatanodeInfoWithStorage[127.0.0.1:40117,DS-fb3609ae-99b2-476b-85f5-4e210384ace7,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-cc40e3e7-b138-48dc-91e4-c5a3e9840119,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-498fe97f-54f2-41f8-b3a1-d2535787c9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-f60c3b9c-d9a9-453a-9a2e-4b5fda423a22,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-de45c9e0-16c9-47f6-bcb7-068376a6a71a,DISK], DatanodeInfoWithStorage[127.0.0.1:36804,DS-69dbdd52-2166-4b42-a48b-384bb4f94b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-ff9d5372-3005-4d63-b91d-21bb1de0b305,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-903551314-172.17.0.21-1596028154767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40498,DS-f089ad25-8459-4aff-8333-b4a57fc9e550,DISK], DatanodeInfoWithStorage[127.0.0.1:40117,DS-fb3609ae-99b2-476b-85f5-4e210384ace7,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-cc40e3e7-b138-48dc-91e4-c5a3e9840119,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-498fe97f-54f2-41f8-b3a1-d2535787c9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-f60c3b9c-d9a9-453a-9a2e-4b5fda423a22,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-de45c9e0-16c9-47f6-bcb7-068376a6a71a,DISK], DatanodeInfoWithStorage[127.0.0.1:36804,DS-69dbdd52-2166-4b42-a48b-384bb4f94b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-ff9d5372-3005-4d63-b91d-21bb1de0b305,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1914613116-172.17.0.21-1596028376569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33416,DS-5145d51a-2f20-4d9b-9060-b4d8865f73cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-66a2d138-e4a9-4e36-8e3c-274df9dc8da0,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-72d03e34-f5a1-4df9-93b8-4ccf648d6b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-0de545bb-395a-44d4-94c2-66c1b84f0365,DISK], DatanodeInfoWithStorage[127.0.0.1:45528,DS-3519c6eb-a7a3-45b3-90cf-d84859e663d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-474a73df-2f15-48db-b45c-46f40d0549e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-01fe708f-df49-40b7-b13f-1fcd3b238dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38236,DS-259f6e0d-e0f2-4fbc-b34b-b2916c4b5cde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1914613116-172.17.0.21-1596028376569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33416,DS-5145d51a-2f20-4d9b-9060-b4d8865f73cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-66a2d138-e4a9-4e36-8e3c-274df9dc8da0,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-72d03e34-f5a1-4df9-93b8-4ccf648d6b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-0de545bb-395a-44d4-94c2-66c1b84f0365,DISK], DatanodeInfoWithStorage[127.0.0.1:45528,DS-3519c6eb-a7a3-45b3-90cf-d84859e663d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-474a73df-2f15-48db-b45c-46f40d0549e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-01fe708f-df49-40b7-b13f-1fcd3b238dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38236,DS-259f6e0d-e0f2-4fbc-b34b-b2916c4b5cde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-850857836-172.17.0.21-1596028631886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34591,DS-29b19e5e-4623-4ffb-8f37-8eebaa050ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-5ce95d31-5e0e-43f9-a6c6-c08b00dcecb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-b06181e9-cfd2-4dac-be73-d8d558852581,DISK], DatanodeInfoWithStorage[127.0.0.1:42057,DS-851172bd-d313-4cb0-9e7f-471a84d03e42,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-f684f3a7-2f37-4f57-813e-6bcefb80e055,DISK], DatanodeInfoWithStorage[127.0.0.1:38182,DS-caa842e0-779f-4e71-be6f-80400461ab21,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-7fa5841c-dee6-44b8-a5c1-183bd48853d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-49529f16-1a3f-45e1-ae61-5c5a15ddfab5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-850857836-172.17.0.21-1596028631886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34591,DS-29b19e5e-4623-4ffb-8f37-8eebaa050ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-5ce95d31-5e0e-43f9-a6c6-c08b00dcecb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-b06181e9-cfd2-4dac-be73-d8d558852581,DISK], DatanodeInfoWithStorage[127.0.0.1:42057,DS-851172bd-d313-4cb0-9e7f-471a84d03e42,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-f684f3a7-2f37-4f57-813e-6bcefb80e055,DISK], DatanodeInfoWithStorage[127.0.0.1:38182,DS-caa842e0-779f-4e71-be6f-80400461ab21,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-7fa5841c-dee6-44b8-a5c1-183bd48853d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-49529f16-1a3f-45e1-ae61-5c5a15ddfab5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-619312987-172.17.0.21-1596028812140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36521,DS-6b5b39bc-aa8b-41c0-940d-6538b6d3486c,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-53db9501-1c3d-417a-a950-a43328205832,DISK], DatanodeInfoWithStorage[127.0.0.1:37807,DS-3d4945bd-3e31-44ea-ae1e-3859147fad53,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-e0936cab-414f-41e8-af9c-11219d011ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-adfeb678-6e19-4cc1-96d8-2c45e2c78058,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-4311e99d-64cc-4bc8-b1ff-72fce08d8d08,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-a5b04bcc-7e67-4568-9e67-32a5508cd56e,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-9dd76cb9-6b0a-4440-99aa-7bb748aac3d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-619312987-172.17.0.21-1596028812140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36521,DS-6b5b39bc-aa8b-41c0-940d-6538b6d3486c,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-53db9501-1c3d-417a-a950-a43328205832,DISK], DatanodeInfoWithStorage[127.0.0.1:37807,DS-3d4945bd-3e31-44ea-ae1e-3859147fad53,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-e0936cab-414f-41e8-af9c-11219d011ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-adfeb678-6e19-4cc1-96d8-2c45e2c78058,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-4311e99d-64cc-4bc8-b1ff-72fce08d8d08,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-a5b04bcc-7e67-4568-9e67-32a5508cd56e,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-9dd76cb9-6b0a-4440-99aa-7bb748aac3d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-346124437-172.17.0.21-1596028885941:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42908,DS-ab359fc6-e6cf-4761-8415-ba803e516a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-7c93dcc3-8af1-463c-9b7e-20a56d4041c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-afd1f29c-1f94-46bb-9777-2c26483cfc33,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-35da652e-87c4-4c27-8cbb-75407c06a548,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-5879c4e2-f0a4-4dfc-8216-2d82dc5eb562,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-e077c7e0-6bca-4cde-ba70-3d1c5624c652,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-6884664a-89d0-4d2b-9bc3-dcdf7736fddd,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-d129c9ee-bf3e-4a6f-b297-6c6f097b244c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-346124437-172.17.0.21-1596028885941:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42908,DS-ab359fc6-e6cf-4761-8415-ba803e516a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-7c93dcc3-8af1-463c-9b7e-20a56d4041c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-afd1f29c-1f94-46bb-9777-2c26483cfc33,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-35da652e-87c4-4c27-8cbb-75407c06a548,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-5879c4e2-f0a4-4dfc-8216-2d82dc5eb562,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-e077c7e0-6bca-4cde-ba70-3d1c5624c652,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-6884664a-89d0-4d2b-9bc3-dcdf7736fddd,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-d129c9ee-bf3e-4a6f-b297-6c6f097b244c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-73067233-172.17.0.21-1596028918604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36744,DS-fa2725ad-19c6-4468-b429-c22403b31223,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-5ee0927f-3e7d-432e-9010-717d4d95c17d,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-67780738-46eb-4cd0-99b6-34aa173d9cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40828,DS-abe01cec-7350-48ab-aa05-6f6d047f277c,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-9265362a-11f0-4ff7-aab9-aa50a145d581,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-b500e2ad-a2ef-4007-a7dd-52510576260b,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-3e811319-43ea-4114-b4e9-f278364ef432,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-9c02f3f4-f8e8-45c7-b46a-a02c476515ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-73067233-172.17.0.21-1596028918604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36744,DS-fa2725ad-19c6-4468-b429-c22403b31223,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-5ee0927f-3e7d-432e-9010-717d4d95c17d,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-67780738-46eb-4cd0-99b6-34aa173d9cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40828,DS-abe01cec-7350-48ab-aa05-6f6d047f277c,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-9265362a-11f0-4ff7-aab9-aa50a145d581,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-b500e2ad-a2ef-4007-a7dd-52510576260b,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-3e811319-43ea-4114-b4e9-f278364ef432,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-9c02f3f4-f8e8-45c7-b46a-a02c476515ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1502716641-172.17.0.21-1596029557020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42462,DS-c965979a-9aa1-44ec-a89d-f5c5ded4b07e,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-7d4eebea-b2fc-4bbf-a87b-7666ac83dd59,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-f5bd7451-8c30-4201-91c5-84aa8d6d2b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-2f9c4b78-3b8f-427b-9e57-b7e87cba59ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-0e38e938-2926-4274-af17-965cf357a526,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-ba2617ce-a659-4954-9ffd-fbc44f1f90c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-6b487340-721b-4192-a7b8-4e19ad3ddf10,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-fa0c55b8-7460-467d-a1c2-afbb33867e55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1502716641-172.17.0.21-1596029557020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42462,DS-c965979a-9aa1-44ec-a89d-f5c5ded4b07e,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-7d4eebea-b2fc-4bbf-a87b-7666ac83dd59,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-f5bd7451-8c30-4201-91c5-84aa8d6d2b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-2f9c4b78-3b8f-427b-9e57-b7e87cba59ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-0e38e938-2926-4274-af17-965cf357a526,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-ba2617ce-a659-4954-9ffd-fbc44f1f90c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-6b487340-721b-4192-a7b8-4e19ad3ddf10,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-fa0c55b8-7460-467d-a1c2-afbb33867e55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1889009141-172.17.0.21-1596029996576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37481,DS-4de76210-573c-481c-8af2-fce4606bffe8,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-1763c348-89bc-4831-be27-dce99d388c96,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-0bba86ea-24cd-45d7-9458-75b9334d4e97,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-e0b476a1-00a6-4ce0-8929-b42011e5661f,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-1e99689a-6517-45b7-a868-2f8c3e7977d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-a981dd88-e35c-44a3-b3aa-9d72f49f403b,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-8e660ac6-d9f5-4f7f-8b12-ad1e13221a40,DISK], DatanodeInfoWithStorage[127.0.0.1:39219,DS-1b9fe273-476a-45e6-973a-968deac5af92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1889009141-172.17.0.21-1596029996576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37481,DS-4de76210-573c-481c-8af2-fce4606bffe8,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-1763c348-89bc-4831-be27-dce99d388c96,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-0bba86ea-24cd-45d7-9458-75b9334d4e97,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-e0b476a1-00a6-4ce0-8929-b42011e5661f,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-1e99689a-6517-45b7-a868-2f8c3e7977d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-a981dd88-e35c-44a3-b3aa-9d72f49f403b,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-8e660ac6-d9f5-4f7f-8b12-ad1e13221a40,DISK], DatanodeInfoWithStorage[127.0.0.1:39219,DS-1b9fe273-476a-45e6-973a-968deac5af92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-897159400-172.17.0.21-1596030032838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37425,DS-07e6ac8a-fdbc-43be-b82b-2f1970ccb5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-24d0cfde-b9dd-4910-8bc0-d02c7609fb22,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-9f44426b-a783-450e-9d54-5045aee614e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-328eb7ba-e601-4c13-9422-2630a53fd442,DISK], DatanodeInfoWithStorage[127.0.0.1:46359,DS-8278e571-1059-4318-a7e2-7760e8f77991,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-63f9672d-b227-44c2-baae-f30036dc21b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-c6421264-7e4b-4043-871b-7bbe3665b03f,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-45fb15b0-07a2-4888-ab3d-76e0e86912c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-897159400-172.17.0.21-1596030032838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37425,DS-07e6ac8a-fdbc-43be-b82b-2f1970ccb5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-24d0cfde-b9dd-4910-8bc0-d02c7609fb22,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-9f44426b-a783-450e-9d54-5045aee614e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-328eb7ba-e601-4c13-9422-2630a53fd442,DISK], DatanodeInfoWithStorage[127.0.0.1:46359,DS-8278e571-1059-4318-a7e2-7760e8f77991,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-63f9672d-b227-44c2-baae-f30036dc21b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-c6421264-7e4b-4043-871b-7bbe3665b03f,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-45fb15b0-07a2-4888-ab3d-76e0e86912c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1563731124-172.17.0.21-1596030178160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38854,DS-df083db9-da69-4bb6-9b54-28cf6ae05c92,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-b1cbae4f-31a9-4d00-997b-fc7bf40b7504,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-e85adf3d-7ca5-4be8-b977-85bcc0412750,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-c2770f23-059a-4549-bc6f-fa6fb6b16a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-c52fa6dd-9dfe-436b-9642-747a27618dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-794d5c90-a830-47f0-b9fd-27104e0e2657,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-349d2281-172f-4f04-badc-8b5b1e9f1bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38915,DS-bea3a662-b096-4a9a-9e40-f8cb5ef136c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1563731124-172.17.0.21-1596030178160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38854,DS-df083db9-da69-4bb6-9b54-28cf6ae05c92,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-b1cbae4f-31a9-4d00-997b-fc7bf40b7504,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-e85adf3d-7ca5-4be8-b977-85bcc0412750,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-c2770f23-059a-4549-bc6f-fa6fb6b16a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-c52fa6dd-9dfe-436b-9642-747a27618dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-794d5c90-a830-47f0-b9fd-27104e0e2657,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-349d2281-172f-4f04-badc-8b5b1e9f1bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38915,DS-bea3a662-b096-4a9a-9e40-f8cb5ef136c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1219403451-172.17.0.21-1596030245954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42777,DS-fb548b26-6dea-401d-bd8d-1ebeba801022,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-9f4eff53-9bde-42fd-a6fb-680b0a77a72f,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-657e4fef-5dcd-4be9-95d9-0806784f64a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-9491c08f-27fb-4819-afba-3ae5cd0e68e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39809,DS-8f69a6c7-8491-41ba-b5df-15157f3f30f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34214,DS-3b5a0ab8-5219-49d2-84f6-922624311ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-4f3ef2e4-013a-49b7-808c-90c1abe88933,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-791e455a-1613-423a-81eb-abb1807a7057,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1219403451-172.17.0.21-1596030245954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42777,DS-fb548b26-6dea-401d-bd8d-1ebeba801022,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-9f4eff53-9bde-42fd-a6fb-680b0a77a72f,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-657e4fef-5dcd-4be9-95d9-0806784f64a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-9491c08f-27fb-4819-afba-3ae5cd0e68e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39809,DS-8f69a6c7-8491-41ba-b5df-15157f3f30f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34214,DS-3b5a0ab8-5219-49d2-84f6-922624311ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-4f3ef2e4-013a-49b7-808c-90c1abe88933,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-791e455a-1613-423a-81eb-abb1807a7057,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1058646958-172.17.0.21-1596030981536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46013,DS-523af948-2bb3-495b-9add-c6383a740649,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-42976711-40f4-4adc-895d-56ee8f738498,DISK], DatanodeInfoWithStorage[127.0.0.1:45697,DS-f246b386-d3d3-4cd7-a4f9-4ee49d8894d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-6f3aaca5-bcfb-49ca-8141-eb6f303352cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-a0f660dd-2638-4626-8941-dd3b908c6cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38792,DS-b262ee8c-7b14-4985-a117-9e56fffec1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-8359d148-7ab2-422e-8aa4-12c1b202743e,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-d2cf85ab-11d2-4114-b218-97f673b7d45f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1058646958-172.17.0.21-1596030981536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46013,DS-523af948-2bb3-495b-9add-c6383a740649,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-42976711-40f4-4adc-895d-56ee8f738498,DISK], DatanodeInfoWithStorage[127.0.0.1:45697,DS-f246b386-d3d3-4cd7-a4f9-4ee49d8894d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-6f3aaca5-bcfb-49ca-8141-eb6f303352cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-a0f660dd-2638-4626-8941-dd3b908c6cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38792,DS-b262ee8c-7b14-4985-a117-9e56fffec1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-8359d148-7ab2-422e-8aa4-12c1b202743e,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-d2cf85ab-11d2-4114-b218-97f673b7d45f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-525014916-172.17.0.21-1596031131340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32981,DS-ade3818b-135a-4f6b-ac3c-8e66be6ef08b,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-d2692d11-cf58-46a4-b041-c75241042c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-18e344e2-21ab-48e8-942a-f5c88e417cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:45354,DS-fe862f98-f3c8-4287-8f08-05c4acbf1658,DISK], DatanodeInfoWithStorage[127.0.0.1:43772,DS-1184780f-1bae-424e-bbd7-f9b1d1fecdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-3667872b-ae20-448d-b9f7-ca8a0c487d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37724,DS-c9123c9c-4cc4-4ce9-8084-c67e7d849cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-dc9182e3-a7ec-4f5a-94fd-a5b2b902f8cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-525014916-172.17.0.21-1596031131340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32981,DS-ade3818b-135a-4f6b-ac3c-8e66be6ef08b,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-d2692d11-cf58-46a4-b041-c75241042c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-18e344e2-21ab-48e8-942a-f5c88e417cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:45354,DS-fe862f98-f3c8-4287-8f08-05c4acbf1658,DISK], DatanodeInfoWithStorage[127.0.0.1:43772,DS-1184780f-1bae-424e-bbd7-f9b1d1fecdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-3667872b-ae20-448d-b9f7-ca8a0c487d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37724,DS-c9123c9c-4cc4-4ce9-8084-c67e7d849cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-dc9182e3-a7ec-4f5a-94fd-a5b2b902f8cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2003887454-172.17.0.21-1596031426752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42411,DS-ba8d7aa6-663a-4f11-9b4c-7ae19e7d096c,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-21df6a01-2d1a-4d9e-9148-21b35060ba34,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-6b9e1ba3-418c-444e-b6cf-bee7df0ff727,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-5278b8f5-63df-4c46-adce-e630faa96e04,DISK], DatanodeInfoWithStorage[127.0.0.1:39026,DS-17193e83-a113-4703-93ab-f9ec9df387f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38948,DS-7f7f99cd-2369-441e-9503-d41908a93822,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-eab7362e-6378-49dc-b2aa-a4d5626918ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39169,DS-0b232570-65eb-4bf5-923f-883d977c3093,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2003887454-172.17.0.21-1596031426752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42411,DS-ba8d7aa6-663a-4f11-9b4c-7ae19e7d096c,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-21df6a01-2d1a-4d9e-9148-21b35060ba34,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-6b9e1ba3-418c-444e-b6cf-bee7df0ff727,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-5278b8f5-63df-4c46-adce-e630faa96e04,DISK], DatanodeInfoWithStorage[127.0.0.1:39026,DS-17193e83-a113-4703-93ab-f9ec9df387f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38948,DS-7f7f99cd-2369-441e-9503-d41908a93822,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-eab7362e-6378-49dc-b2aa-a4d5626918ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39169,DS-0b232570-65eb-4bf5-923f-883d977c3093,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-857149003-172.17.0.21-1596031852808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36210,DS-4dd54fa7-2eb6-4f54-b580-3faa55fdb62b,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-ac8c6b10-7878-48d4-9a38-80ddd1670200,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-8cc9e5cf-e349-4dd9-8b9f-6e1fcbe6c111,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-25fc9664-b3f3-4426-a9ff-5a8443c0799f,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-964f7d46-d543-4a18-b7af-46a84ff297f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-b0f34ef8-2e59-4fba-b76f-8728e4891ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-a9692dd0-931a-468e-8b7e-76d4ccdf1646,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-453c1dd6-a630-4f0d-a42a-5e2b118672fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-857149003-172.17.0.21-1596031852808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36210,DS-4dd54fa7-2eb6-4f54-b580-3faa55fdb62b,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-ac8c6b10-7878-48d4-9a38-80ddd1670200,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-8cc9e5cf-e349-4dd9-8b9f-6e1fcbe6c111,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-25fc9664-b3f3-4426-a9ff-5a8443c0799f,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-964f7d46-d543-4a18-b7af-46a84ff297f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-b0f34ef8-2e59-4fba-b76f-8728e4891ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-a9692dd0-931a-468e-8b7e-76d4ccdf1646,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-453c1dd6-a630-4f0d-a42a-5e2b118672fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 4992
