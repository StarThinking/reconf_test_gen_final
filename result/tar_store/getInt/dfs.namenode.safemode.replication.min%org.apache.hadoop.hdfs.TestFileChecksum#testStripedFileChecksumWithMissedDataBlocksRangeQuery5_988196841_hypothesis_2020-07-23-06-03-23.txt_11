reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1425696363-172.17.0.3-1595484327666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32845,DS-61638231-bbd9-4c81-b197-a8b7a2f94465,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-10582fe7-f183-4d89-a7fd-12eb009ada55,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-64f5842c-83e9-4bf8-b1c7-47eca1d107f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35462,DS-a45d9b81-bf8e-4b51-ba44-8417ffe848cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-1a0faa93-94f8-45c2-b4c5-4c7d8234f8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-31b4f994-c95f-4de9-a864-1373c32a6dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39873,DS-20950bff-28c7-4b3e-91d3-52a20a62e589,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-b4cea604-bcd8-4212-a81b-929376058af5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1425696363-172.17.0.3-1595484327666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32845,DS-61638231-bbd9-4c81-b197-a8b7a2f94465,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-10582fe7-f183-4d89-a7fd-12eb009ada55,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-64f5842c-83e9-4bf8-b1c7-47eca1d107f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35462,DS-a45d9b81-bf8e-4b51-ba44-8417ffe848cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-1a0faa93-94f8-45c2-b4c5-4c7d8234f8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-31b4f994-c95f-4de9-a864-1373c32a6dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39873,DS-20950bff-28c7-4b3e-91d3-52a20a62e589,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-b4cea604-bcd8-4212-a81b-929376058af5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1507478852-172.17.0.3-1595484625421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45808,DS-4e555f39-208a-42c1-8ef4-4d94ab91108b,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-6b47e3cf-6628-4903-be4c-8d17ffa79422,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-c8443051-ea02-4fd5-92a1-743b16ce8aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-6fb7ada6-b237-4aea-bad1-1eea1b84ad56,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-d762403b-23b8-4a52-ac91-c41765268016,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-428c2518-e610-4f9a-a474-caabe6ba22af,DISK], DatanodeInfoWithStorage[127.0.0.1:34568,DS-a474bf2f-885b-4063-862a-f29603939cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-046f71e1-ed24-4931-804c-24d292d00e71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1507478852-172.17.0.3-1595484625421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45808,DS-4e555f39-208a-42c1-8ef4-4d94ab91108b,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-6b47e3cf-6628-4903-be4c-8d17ffa79422,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-c8443051-ea02-4fd5-92a1-743b16ce8aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-6fb7ada6-b237-4aea-bad1-1eea1b84ad56,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-d762403b-23b8-4a52-ac91-c41765268016,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-428c2518-e610-4f9a-a474-caabe6ba22af,DISK], DatanodeInfoWithStorage[127.0.0.1:34568,DS-a474bf2f-885b-4063-862a-f29603939cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-046f71e1-ed24-4931-804c-24d292d00e71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1702887973-172.17.0.3-1595485575458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45428,DS-3a4b394d-92fe-4b9b-84d9-d01962536eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-9d6ce5fa-8bb7-487c-8e9a-aa4b7f121b11,DISK], DatanodeInfoWithStorage[127.0.0.1:44594,DS-d924f980-07bf-43a2-9eea-8207f1f9a176,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-b1cb5916-60b5-4d2e-9d4b-0bafff1fa2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-a5a07ca0-d5dc-46df-b72b-f1d43fe0d4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-6c3bb3e8-d3d9-4e57-a032-ffc2c3cfe03f,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-5baea406-a94e-4beb-b86d-8f64176761b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-873cd9a2-5b36-44a5-a170-4132f3413eb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1702887973-172.17.0.3-1595485575458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45428,DS-3a4b394d-92fe-4b9b-84d9-d01962536eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-9d6ce5fa-8bb7-487c-8e9a-aa4b7f121b11,DISK], DatanodeInfoWithStorage[127.0.0.1:44594,DS-d924f980-07bf-43a2-9eea-8207f1f9a176,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-b1cb5916-60b5-4d2e-9d4b-0bafff1fa2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-a5a07ca0-d5dc-46df-b72b-f1d43fe0d4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-6c3bb3e8-d3d9-4e57-a032-ffc2c3cfe03f,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-5baea406-a94e-4beb-b86d-8f64176761b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-873cd9a2-5b36-44a5-a170-4132f3413eb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1040666152-172.17.0.3-1595485735678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38680,DS-b9376e83-1c45-4da3-8108-59f61ff51788,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-c819ef89-8122-46ee-9af1-d0c81ed4cd27,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-95a35158-83fe-4846-886b-49c14e9459b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-9f6ba78d-abc4-4c95-9112-7cddf4e5b4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-229db5bc-3716-4d05-b048-44e1e43cee5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-35dfaae4-29d6-4cf3-9f40-a827c2414abc,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-cba0e39e-2e81-467c-99c5-2e57fb7e7a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-517aca7a-35a8-4b85-8348-7b6c26fe9961,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1040666152-172.17.0.3-1595485735678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38680,DS-b9376e83-1c45-4da3-8108-59f61ff51788,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-c819ef89-8122-46ee-9af1-d0c81ed4cd27,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-95a35158-83fe-4846-886b-49c14e9459b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-9f6ba78d-abc4-4c95-9112-7cddf4e5b4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-229db5bc-3716-4d05-b048-44e1e43cee5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-35dfaae4-29d6-4cf3-9f40-a827c2414abc,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-cba0e39e-2e81-467c-99c5-2e57fb7e7a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-517aca7a-35a8-4b85-8348-7b6c26fe9961,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1944014451-172.17.0.3-1595485929126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38321,DS-1923e9b6-aac6-4769-b39f-229b2c9c823f,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-54d7c57a-6525-4107-8dfe-c1d0df0313a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-467ece6c-140d-46c3-948e-75d41ff76900,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-e3863fa1-eef1-4ef1-b7db-a07c6979573b,DISK], DatanodeInfoWithStorage[127.0.0.1:41173,DS-59979162-7932-41dd-a7aa-94ea8cfe8657,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-9b403432-a4e8-4e7c-ba9b-3b3408a4d5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40258,DS-ce177d56-c9de-465f-ab17-f270c091391a,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-49dbd6e4-7cd3-407e-b929-bc5611630935,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1944014451-172.17.0.3-1595485929126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38321,DS-1923e9b6-aac6-4769-b39f-229b2c9c823f,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-54d7c57a-6525-4107-8dfe-c1d0df0313a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-467ece6c-140d-46c3-948e-75d41ff76900,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-e3863fa1-eef1-4ef1-b7db-a07c6979573b,DISK], DatanodeInfoWithStorage[127.0.0.1:41173,DS-59979162-7932-41dd-a7aa-94ea8cfe8657,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-9b403432-a4e8-4e7c-ba9b-3b3408a4d5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40258,DS-ce177d56-c9de-465f-ab17-f270c091391a,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-49dbd6e4-7cd3-407e-b929-bc5611630935,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-326672623-172.17.0.3-1595486345292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42480,DS-860ea886-ec89-4b33-8a46-0661e4049636,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-354e209b-2167-4adf-b0af-54de67815d61,DISK], DatanodeInfoWithStorage[127.0.0.1:34293,DS-9188e2a6-1b15-4b8c-ad38-75f2f6ed9d64,DISK], DatanodeInfoWithStorage[127.0.0.1:46236,DS-0a0584df-1fb5-4fe1-9aa1-71a85d4705d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-0af066f6-a405-49ec-a053-b512b1abce80,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-54088316-6405-4db0-8b2f-52df653a4bab,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-303af269-e63d-4fb6-97b9-75b1bd21c9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-91adfdba-da1e-42cb-8273-3ea6580f1ba3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-326672623-172.17.0.3-1595486345292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42480,DS-860ea886-ec89-4b33-8a46-0661e4049636,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-354e209b-2167-4adf-b0af-54de67815d61,DISK], DatanodeInfoWithStorage[127.0.0.1:34293,DS-9188e2a6-1b15-4b8c-ad38-75f2f6ed9d64,DISK], DatanodeInfoWithStorage[127.0.0.1:46236,DS-0a0584df-1fb5-4fe1-9aa1-71a85d4705d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-0af066f6-a405-49ec-a053-b512b1abce80,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-54088316-6405-4db0-8b2f-52df653a4bab,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-303af269-e63d-4fb6-97b9-75b1bd21c9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-91adfdba-da1e-42cb-8273-3ea6580f1ba3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1792746446-172.17.0.3-1595486654534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46612,DS-929fb44e-88b5-4424-89e3-2b9a497f526f,DISK], DatanodeInfoWithStorage[127.0.0.1:46522,DS-e19a6734-46f5-4756-babd-f570450b0498,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-04e1eb4c-76e1-47ec-9a96-b125ba2538fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-5a82a449-f7e3-4b87-aed3-b781c727bd98,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-0e735364-0a95-4131-a11a-b93f7c67a4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-f5592f81-ca45-4d25-bb37-3d2cbe3cda2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-75065ea0-9cc9-4f81-85aa-ace44170d31f,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-45e8e4b9-393b-4ff3-b745-7c17b3db0562,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1792746446-172.17.0.3-1595486654534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46612,DS-929fb44e-88b5-4424-89e3-2b9a497f526f,DISK], DatanodeInfoWithStorage[127.0.0.1:46522,DS-e19a6734-46f5-4756-babd-f570450b0498,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-04e1eb4c-76e1-47ec-9a96-b125ba2538fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-5a82a449-f7e3-4b87-aed3-b781c727bd98,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-0e735364-0a95-4131-a11a-b93f7c67a4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-f5592f81-ca45-4d25-bb37-3d2cbe3cda2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-75065ea0-9cc9-4f81-85aa-ace44170d31f,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-45e8e4b9-393b-4ff3-b745-7c17b3db0562,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-819675632-172.17.0.3-1595487823300:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41041,DS-5e0f6de4-db09-4779-be74-8c69388ce64c,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-c9331e3e-94e0-4ca0-b606-0893dab58693,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-e7755b35-89d4-4f14-80e4-7687d26a49bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-e154f720-58b4-4ad8-afde-55cf16dfb8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-11b43c9a-ebc3-43ef-9021-c77c625800c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-a14ac188-f8bb-44a9-880a-212a7b4b9558,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-ddcbcb7f-bda1-4b60-9293-3da5da68a8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-e009d910-6b3b-4eaa-b48b-7db42989ec3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-819675632-172.17.0.3-1595487823300:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41041,DS-5e0f6de4-db09-4779-be74-8c69388ce64c,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-c9331e3e-94e0-4ca0-b606-0893dab58693,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-e7755b35-89d4-4f14-80e4-7687d26a49bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-e154f720-58b4-4ad8-afde-55cf16dfb8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-11b43c9a-ebc3-43ef-9021-c77c625800c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-a14ac188-f8bb-44a9-880a-212a7b4b9558,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-ddcbcb7f-bda1-4b60-9293-3da5da68a8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-e009d910-6b3b-4eaa-b48b-7db42989ec3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2079268498-172.17.0.3-1595488120613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44766,DS-b33f77e8-863f-40aa-8211-c54bb5d13cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-01f7dfcb-f5b3-4e48-9fdd-a20468e9d52e,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-b8108dd3-3f11-4427-87f2-a25d0cc9b09a,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-6c5c22b6-8f8a-4355-ba58-f4b1b905d3de,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-1ef06630-fa22-42b7-be74-75d4d44d4377,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-a831b8da-9c43-4e40-9c6a-e81c07dd7666,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-98b82d09-eab7-4a9c-9876-02d5c93edcdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-1035b67f-0aaf-4f67-896b-c6553522bb21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2079268498-172.17.0.3-1595488120613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44766,DS-b33f77e8-863f-40aa-8211-c54bb5d13cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-01f7dfcb-f5b3-4e48-9fdd-a20468e9d52e,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-b8108dd3-3f11-4427-87f2-a25d0cc9b09a,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-6c5c22b6-8f8a-4355-ba58-f4b1b905d3de,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-1ef06630-fa22-42b7-be74-75d4d44d4377,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-a831b8da-9c43-4e40-9c6a-e81c07dd7666,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-98b82d09-eab7-4a9c-9876-02d5c93edcdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-1035b67f-0aaf-4f67-896b-c6553522bb21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-287847347-172.17.0.3-1595488281193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42990,DS-82ce327b-98cf-4e81-a89c-8a7ef91ff25c,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-891c1954-a33f-4547-abfa-4022ea794879,DISK], DatanodeInfoWithStorage[127.0.0.1:45486,DS-fcaac7bc-920f-4b6f-8efe-cd14e349f43d,DISK], DatanodeInfoWithStorage[127.0.0.1:37683,DS-76b3486a-91b0-4b7c-b94b-2cd8b8107566,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-13f7b8f4-31e4-408a-a512-d7e3173e6590,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-0600dcd0-6093-4e7e-ae66-15048249383c,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-57ce1502-6657-4773-8adf-4c9b78bdb816,DISK], DatanodeInfoWithStorage[127.0.0.1:39807,DS-f4b8c1a8-e377-4993-96b0-d5a517c4ecca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-287847347-172.17.0.3-1595488281193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42990,DS-82ce327b-98cf-4e81-a89c-8a7ef91ff25c,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-891c1954-a33f-4547-abfa-4022ea794879,DISK], DatanodeInfoWithStorage[127.0.0.1:45486,DS-fcaac7bc-920f-4b6f-8efe-cd14e349f43d,DISK], DatanodeInfoWithStorage[127.0.0.1:37683,DS-76b3486a-91b0-4b7c-b94b-2cd8b8107566,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-13f7b8f4-31e4-408a-a512-d7e3173e6590,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-0600dcd0-6093-4e7e-ae66-15048249383c,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-57ce1502-6657-4773-8adf-4c9b78bdb816,DISK], DatanodeInfoWithStorage[127.0.0.1:39807,DS-f4b8c1a8-e377-4993-96b0-d5a517c4ecca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-256771391-172.17.0.3-1595488441155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43778,DS-d0dad3fa-a4c8-4ab0-a626-c2a361ac6e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34724,DS-f4acb5a6-5bf3-444f-9144-f1f30c991946,DISK], DatanodeInfoWithStorage[127.0.0.1:40182,DS-89f35e8f-15c6-4712-aeb9-b42752ef4cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-dc1e521f-43d4-4335-bec8-856321f707a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-f3da5319-7439-4412-a3f9-371987308da3,DISK], DatanodeInfoWithStorage[127.0.0.1:46559,DS-ae1e1019-69fd-4ff2-bb10-744f9ffc71a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-cae300b4-f03b-4376-87a5-2c1e93de20db,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-c87daee4-f5c7-46b0-a60f-c6166b1ebb6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-256771391-172.17.0.3-1595488441155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43778,DS-d0dad3fa-a4c8-4ab0-a626-c2a361ac6e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34724,DS-f4acb5a6-5bf3-444f-9144-f1f30c991946,DISK], DatanodeInfoWithStorage[127.0.0.1:40182,DS-89f35e8f-15c6-4712-aeb9-b42752ef4cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-dc1e521f-43d4-4335-bec8-856321f707a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-f3da5319-7439-4412-a3f9-371987308da3,DISK], DatanodeInfoWithStorage[127.0.0.1:46559,DS-ae1e1019-69fd-4ff2-bb10-744f9ffc71a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-cae300b4-f03b-4376-87a5-2c1e93de20db,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-c87daee4-f5c7-46b0-a60f-c6166b1ebb6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1450248247-172.17.0.3-1595488684362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40163,DS-519d231b-4d74-454e-8b9c-d4b4982aa1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-bf641aa7-1cbc-446b-96e9-34263c287636,DISK], DatanodeInfoWithStorage[127.0.0.1:43179,DS-b7738870-7b58-42ea-b57b-ff90854d5f49,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-f5486878-81a8-46a4-acb6-589c374afee9,DISK], DatanodeInfoWithStorage[127.0.0.1:37811,DS-426f738b-ca7e-461b-a104-7bfe3a279ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-8891240c-15fd-44d4-bb3a-d42206cf8eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38478,DS-dbac3792-f5af-4d6f-9af4-7562637c3e88,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-fb002e48-d7f1-4ff2-bc2d-49cf94952722,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1450248247-172.17.0.3-1595488684362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40163,DS-519d231b-4d74-454e-8b9c-d4b4982aa1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-bf641aa7-1cbc-446b-96e9-34263c287636,DISK], DatanodeInfoWithStorage[127.0.0.1:43179,DS-b7738870-7b58-42ea-b57b-ff90854d5f49,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-f5486878-81a8-46a4-acb6-589c374afee9,DISK], DatanodeInfoWithStorage[127.0.0.1:37811,DS-426f738b-ca7e-461b-a104-7bfe3a279ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-8891240c-15fd-44d4-bb3a-d42206cf8eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38478,DS-dbac3792-f5af-4d6f-9af4-7562637c3e88,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-fb002e48-d7f1-4ff2-bc2d-49cf94952722,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1611513824-172.17.0.3-1595489251818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43557,DS-0515c6ac-7f13-4c6f-85c5-80238f9ca873,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-04ea880c-73c4-4e11-9215-9fb6eca37619,DISK], DatanodeInfoWithStorage[127.0.0.1:42737,DS-a392c930-6005-405d-a216-97e73df87a46,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-4c390fa4-4898-4d69-8545-259bf7f12a06,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-f1b13687-98e6-4b4d-8ee6-77d653772744,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-57e5e8ef-0cc7-42c0-af1b-cbfbf48af27c,DISK], DatanodeInfoWithStorage[127.0.0.1:33635,DS-c53ab237-49dd-4160-8c19-096fbdb2621f,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-40a62c21-3900-440d-a6af-c0517bd06f99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1611513824-172.17.0.3-1595489251818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43557,DS-0515c6ac-7f13-4c6f-85c5-80238f9ca873,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-04ea880c-73c4-4e11-9215-9fb6eca37619,DISK], DatanodeInfoWithStorage[127.0.0.1:42737,DS-a392c930-6005-405d-a216-97e73df87a46,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-4c390fa4-4898-4d69-8545-259bf7f12a06,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-f1b13687-98e6-4b4d-8ee6-77d653772744,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-57e5e8ef-0cc7-42c0-af1b-cbfbf48af27c,DISK], DatanodeInfoWithStorage[127.0.0.1:33635,DS-c53ab237-49dd-4160-8c19-096fbdb2621f,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-40a62c21-3900-440d-a6af-c0517bd06f99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1671096217-172.17.0.3-1595489286131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39085,DS-ec4bdc1c-4594-4b3d-b558-1c9c5d3957ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-87b78b70-8fe8-4a03-ac31-b094513272f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-6160ca8d-50b7-4ad4-8270-bbe42e65441a,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-70cf2645-fe74-46da-b413-9c35414c4fab,DISK], DatanodeInfoWithStorage[127.0.0.1:33176,DS-f109e18a-610a-4821-a80f-7aa4fc95fe65,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-c7ef3a2e-757c-48a0-aab0-10a37f21d394,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-790ed56a-b30b-460c-9165-44083ba14347,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-b781977f-a49e-4de5-942b-8501dfc711c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1671096217-172.17.0.3-1595489286131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39085,DS-ec4bdc1c-4594-4b3d-b558-1c9c5d3957ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-87b78b70-8fe8-4a03-ac31-b094513272f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-6160ca8d-50b7-4ad4-8270-bbe42e65441a,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-70cf2645-fe74-46da-b413-9c35414c4fab,DISK], DatanodeInfoWithStorage[127.0.0.1:33176,DS-f109e18a-610a-4821-a80f-7aa4fc95fe65,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-c7ef3a2e-757c-48a0-aab0-10a37f21d394,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-790ed56a-b30b-460c-9165-44083ba14347,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-b781977f-a49e-4de5-942b-8501dfc711c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1974425187-172.17.0.3-1595489630958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45107,DS-e42a0d15-30b5-4922-a0d6-68fb062152ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-76ce29d1-ed72-40f6-9002-1d4ae13aa961,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-6bc5f6d2-67cd-4491-9027-f1a71f636ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:45551,DS-79ad0456-9f34-4099-b941-132ccb9fe8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-6cc269e9-308b-47e6-b685-00446f383292,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-7b5d6ee3-b983-4fac-b623-2b1d2590eec0,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-8e00e3ff-1734-4aae-b0a1-98d35b509243,DISK], DatanodeInfoWithStorage[127.0.0.1:42328,DS-7278443a-82d1-4f63-a999-fb031ac4b445,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1974425187-172.17.0.3-1595489630958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45107,DS-e42a0d15-30b5-4922-a0d6-68fb062152ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-76ce29d1-ed72-40f6-9002-1d4ae13aa961,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-6bc5f6d2-67cd-4491-9027-f1a71f636ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:45551,DS-79ad0456-9f34-4099-b941-132ccb9fe8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-6cc269e9-308b-47e6-b685-00446f383292,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-7b5d6ee3-b983-4fac-b623-2b1d2590eec0,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-8e00e3ff-1734-4aae-b0a1-98d35b509243,DISK], DatanodeInfoWithStorage[127.0.0.1:42328,DS-7278443a-82d1-4f63-a999-fb031ac4b445,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5563
