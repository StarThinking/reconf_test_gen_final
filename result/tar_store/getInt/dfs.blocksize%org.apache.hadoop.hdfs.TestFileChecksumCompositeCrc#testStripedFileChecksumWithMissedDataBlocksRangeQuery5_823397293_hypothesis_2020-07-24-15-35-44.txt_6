reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-188331769-172.17.0.3-1595605327751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42031,DS-876e8a14-fb01-4a7c-abe1-c910a61ae9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-c8dbe63d-501a-4d31-b26d-6d615fcc3bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-c619f477-a1e7-4f46-8706-ef0a8ba984eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-2e2d7cbc-1038-486b-a7a6-7d2027d829a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38781,DS-97e54a32-dcca-4596-82d8-cd553adfdf86,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-a4c36ca2-ebb1-4f42-9e22-20e16205e8db,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-90a21872-94f1-423f-8983-5f13163045cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-80f86151-034e-4e6b-be93-ea996ab19abd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-188331769-172.17.0.3-1595605327751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42031,DS-876e8a14-fb01-4a7c-abe1-c910a61ae9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-c8dbe63d-501a-4d31-b26d-6d615fcc3bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-c619f477-a1e7-4f46-8706-ef0a8ba984eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-2e2d7cbc-1038-486b-a7a6-7d2027d829a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38781,DS-97e54a32-dcca-4596-82d8-cd553adfdf86,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-a4c36ca2-ebb1-4f42-9e22-20e16205e8db,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-90a21872-94f1-423f-8983-5f13163045cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-80f86151-034e-4e6b-be93-ea996ab19abd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1528394487-172.17.0.3-1595605894492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37989,DS-d9082844-c058-4374-994d-65104c4517a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-4405bd4e-6968-4ca6-8ba6-265de94afccb,DISK], DatanodeInfoWithStorage[127.0.0.1:41244,DS-a389c242-1aa9-4113-80aa-7a73208b649f,DISK], DatanodeInfoWithStorage[127.0.0.1:45186,DS-d77a57b7-4f81-4b7d-92c2-ea7b3ff33c54,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-403b5855-6c84-4719-b78c-57cbbc614809,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-ca09d308-624f-4ca4-b904-f694dd36766b,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-401aed06-f031-4766-83a8-4f56131e28e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-85ec8757-a200-4d8c-9ea7-6d267356d5e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1528394487-172.17.0.3-1595605894492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37989,DS-d9082844-c058-4374-994d-65104c4517a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-4405bd4e-6968-4ca6-8ba6-265de94afccb,DISK], DatanodeInfoWithStorage[127.0.0.1:41244,DS-a389c242-1aa9-4113-80aa-7a73208b649f,DISK], DatanodeInfoWithStorage[127.0.0.1:45186,DS-d77a57b7-4f81-4b7d-92c2-ea7b3ff33c54,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-403b5855-6c84-4719-b78c-57cbbc614809,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-ca09d308-624f-4ca4-b904-f694dd36766b,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-401aed06-f031-4766-83a8-4f56131e28e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-85ec8757-a200-4d8c-9ea7-6d267356d5e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1269821881-172.17.0.3-1595606026012:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46203,DS-0f7c25fd-2c5e-4d9c-8af4-7e2be44616a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-9d705f65-630c-426d-87ba-6bf04ff9d8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-91666e8e-5ebb-4c3d-9062-a6c9d9c55d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-0273b43d-37fd-4784-8d0d-6e5a7e970a55,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-e1cbd57d-bef4-412b-bd1e-581e5c97fb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-e1bc2af0-4738-4fcf-8aeb-e5a1f83e2c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-b0a45b0d-005f-4616-a0be-f2ff8e4dfd06,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-a79d5ed4-a2f7-454d-a7f2-c490da5323b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1269821881-172.17.0.3-1595606026012:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46203,DS-0f7c25fd-2c5e-4d9c-8af4-7e2be44616a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-9d705f65-630c-426d-87ba-6bf04ff9d8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-91666e8e-5ebb-4c3d-9062-a6c9d9c55d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-0273b43d-37fd-4784-8d0d-6e5a7e970a55,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-e1cbd57d-bef4-412b-bd1e-581e5c97fb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-e1bc2af0-4738-4fcf-8aeb-e5a1f83e2c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-b0a45b0d-005f-4616-a0be-f2ff8e4dfd06,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-a79d5ed4-a2f7-454d-a7f2-c490da5323b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-378261992-172.17.0.3-1595606090831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45904,DS-1f5544f6-5c05-4400-845a-94ccc7bd9acc,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-d3962662-1b53-48f9-9ad1-36e81f5d7c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43772,DS-f011467e-0153-4461-b576-c43fc8a2d0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-61aa6c74-0bf2-4203-9c54-6650315218bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-42c77957-6a3f-4994-8943-193126475c25,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-6649a16c-b2c8-4cce-9c98-a5f777400fde,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-8f54c07b-cdc7-47ca-9bf7-86b7a61d1f40,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-c38cb574-44d4-4b48-ae96-9af122229536,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-378261992-172.17.0.3-1595606090831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45904,DS-1f5544f6-5c05-4400-845a-94ccc7bd9acc,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-d3962662-1b53-48f9-9ad1-36e81f5d7c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43772,DS-f011467e-0153-4461-b576-c43fc8a2d0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-61aa6c74-0bf2-4203-9c54-6650315218bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-42c77957-6a3f-4994-8943-193126475c25,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-6649a16c-b2c8-4cce-9c98-a5f777400fde,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-8f54c07b-cdc7-47ca-9bf7-86b7a61d1f40,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-c38cb574-44d4-4b48-ae96-9af122229536,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-304508505-172.17.0.3-1595607613184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36208,DS-87e722e9-b4ff-4fdb-bacc-437a7521b380,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-77ee5921-ec46-4dfd-8679-2e579e636717,DISK], DatanodeInfoWithStorage[127.0.0.1:33877,DS-4150f976-e807-4ab2-876c-1546e2906726,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-accf703d-ba9d-4f4c-b430-279598e6fbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-e54e59d3-4f6f-429f-a963-7922b04988f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39278,DS-cecbb6ad-1285-466a-97e8-80fa64a9b117,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-2b56b68f-c3d7-4803-9e9b-82f6c2e572a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-9e5a7c16-186f-42c8-a278-996410275d2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-304508505-172.17.0.3-1595607613184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36208,DS-87e722e9-b4ff-4fdb-bacc-437a7521b380,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-77ee5921-ec46-4dfd-8679-2e579e636717,DISK], DatanodeInfoWithStorage[127.0.0.1:33877,DS-4150f976-e807-4ab2-876c-1546e2906726,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-accf703d-ba9d-4f4c-b430-279598e6fbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-e54e59d3-4f6f-429f-a963-7922b04988f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39278,DS-cecbb6ad-1285-466a-97e8-80fa64a9b117,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-2b56b68f-c3d7-4803-9e9b-82f6c2e572a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-9e5a7c16-186f-42c8-a278-996410275d2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1362964416-172.17.0.3-1595607874718:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39366,DS-3b17333d-3fd9-4f0b-b221-963cfd74a230,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-36555a28-2442-4ddc-838a-df2de5b65ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-d591e44b-103a-4bd1-be72-73d0f3a615a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-8dec348e-af24-472a-a548-3a2f8bd63b20,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-557b231c-712a-42dc-86c0-26f3772324ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-a2fbbe96-6537-467f-9673-452c17646fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-ec30fbd9-6ff1-4f7c-9eb7-11221840c73e,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-cde57399-698a-4299-be3b-5a2d9769aed4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1362964416-172.17.0.3-1595607874718:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39366,DS-3b17333d-3fd9-4f0b-b221-963cfd74a230,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-36555a28-2442-4ddc-838a-df2de5b65ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-d591e44b-103a-4bd1-be72-73d0f3a615a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-8dec348e-af24-472a-a548-3a2f8bd63b20,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-557b231c-712a-42dc-86c0-26f3772324ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-a2fbbe96-6537-467f-9673-452c17646fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-ec30fbd9-6ff1-4f7c-9eb7-11221840c73e,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-cde57399-698a-4299-be3b-5a2d9769aed4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1401468890-172.17.0.3-1595608581746:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40075,DS-64406b8d-eced-4f3a-8cc8-c1d062373365,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-0e435818-7070-4bf3-ad57-effae50d1116,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-9316b8d4-4857-4709-abe9-6cc849bfffc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-5a4ee2cb-cc8f-4eba-9e2e-f78da1de8764,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-1c921d50-7095-4414-b738-b789f048ce35,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-eab98b53-f1a3-44d5-96dc-7dbf5adcfbc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-1749ec4e-817d-4935-883d-5f7f5fe4742a,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-41240a4c-6765-4066-9c89-93b7798aa68f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1401468890-172.17.0.3-1595608581746:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40075,DS-64406b8d-eced-4f3a-8cc8-c1d062373365,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-0e435818-7070-4bf3-ad57-effae50d1116,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-9316b8d4-4857-4709-abe9-6cc849bfffc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-5a4ee2cb-cc8f-4eba-9e2e-f78da1de8764,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-1c921d50-7095-4414-b738-b789f048ce35,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-eab98b53-f1a3-44d5-96dc-7dbf5adcfbc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-1749ec4e-817d-4935-883d-5f7f5fe4742a,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-41240a4c-6765-4066-9c89-93b7798aa68f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1043553939-172.17.0.3-1595608815579:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35144,DS-032b6935-661c-4c3f-b7d2-4241f8df8d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-c29284cd-d060-46d2-bbe7-7e83cae0231f,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-3d8cc749-27d2-4cd8-a024-2c50a40ca4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42189,DS-216c1a3d-c59a-4105-a2e5-0478aa21168a,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-f181df33-963d-4968-baab-4d5c97d3cb3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-e426ad50-a443-4164-a8b2-7dda526d5296,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-80d6ed13-142c-48d1-a8f0-a4815abae4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-334d4eed-63fb-4244-a407-ef755d78299a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1043553939-172.17.0.3-1595608815579:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35144,DS-032b6935-661c-4c3f-b7d2-4241f8df8d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-c29284cd-d060-46d2-bbe7-7e83cae0231f,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-3d8cc749-27d2-4cd8-a024-2c50a40ca4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42189,DS-216c1a3d-c59a-4105-a2e5-0478aa21168a,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-f181df33-963d-4968-baab-4d5c97d3cb3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-e426ad50-a443-4164-a8b2-7dda526d5296,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-80d6ed13-142c-48d1-a8f0-a4815abae4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-334d4eed-63fb-4244-a407-ef755d78299a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-514420769-172.17.0.3-1595609070245:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40840,DS-b1d50420-ae3c-45c4-ad47-6b4949b35ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-a31e436a-0939-4dac-80fa-ca427cf1256c,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-14187803-35e5-4bd2-b3bc-dd2e962fcef9,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-57019623-05bf-468c-ae6f-39f8415274cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-beb9f9c6-dbdb-4abc-b8f5-d554e8ecb6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35888,DS-78f9c55e-5037-4afd-85c0-faba21ebed08,DISK], DatanodeInfoWithStorage[127.0.0.1:39716,DS-2eb5cc7b-3e5d-49df-9c52-8de2eb54d143,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-8e1dd3b7-42c9-430e-868e-7d8ec7c6f6c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-514420769-172.17.0.3-1595609070245:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40840,DS-b1d50420-ae3c-45c4-ad47-6b4949b35ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-a31e436a-0939-4dac-80fa-ca427cf1256c,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-14187803-35e5-4bd2-b3bc-dd2e962fcef9,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-57019623-05bf-468c-ae6f-39f8415274cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-beb9f9c6-dbdb-4abc-b8f5-d554e8ecb6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35888,DS-78f9c55e-5037-4afd-85c0-faba21ebed08,DISK], DatanodeInfoWithStorage[127.0.0.1:39716,DS-2eb5cc7b-3e5d-49df-9c52-8de2eb54d143,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-8e1dd3b7-42c9-430e-868e-7d8ec7c6f6c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-182144223-172.17.0.3-1595609450570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44600,DS-acd561f6-0a24-4bde-9ef2-81605fcd2224,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-0dbb7318-f519-4005-a357-28d51f0d82cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-49f47022-43bf-4f39-b5ac-7c90ba6f66cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-4feef6d4-290e-4ead-b017-496367a78ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-b4c3bed4-b27d-4696-a75f-3cd1d58f128a,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-9a980910-d92f-4471-a44c-514dee547816,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-ee37e72a-60f6-4205-a19f-25f57b19b196,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-c70560ab-92c9-4552-b5c0-cb1d3f2b265c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-182144223-172.17.0.3-1595609450570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44600,DS-acd561f6-0a24-4bde-9ef2-81605fcd2224,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-0dbb7318-f519-4005-a357-28d51f0d82cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-49f47022-43bf-4f39-b5ac-7c90ba6f66cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-4feef6d4-290e-4ead-b017-496367a78ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-b4c3bed4-b27d-4696-a75f-3cd1d58f128a,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-9a980910-d92f-4471-a44c-514dee547816,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-ee37e72a-60f6-4205-a19f-25f57b19b196,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-c70560ab-92c9-4552-b5c0-cb1d3f2b265c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-721321198-172.17.0.3-1595609565482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37503,DS-cdaa0332-c9b9-4a7e-9bb1-d92cf43d6b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-886be5eb-5a5f-4c8a-8134-dae52df291b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-a674bc20-7338-49bb-ae92-8b3d52f54c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-24909241-5ce9-4d5a-ac01-9023f3f8ef78,DISK], DatanodeInfoWithStorage[127.0.0.1:36502,DS-246307cf-5002-4130-bd33-43b163da8692,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-570922f6-93c2-415e-a005-0f7a4f7cd584,DISK], DatanodeInfoWithStorage[127.0.0.1:34309,DS-602f47f9-ebfb-4d9c-9a01-b78139b195fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-cf26db2d-4e25-4814-aa68-8a3da32491ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-721321198-172.17.0.3-1595609565482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37503,DS-cdaa0332-c9b9-4a7e-9bb1-d92cf43d6b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-886be5eb-5a5f-4c8a-8134-dae52df291b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-a674bc20-7338-49bb-ae92-8b3d52f54c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-24909241-5ce9-4d5a-ac01-9023f3f8ef78,DISK], DatanodeInfoWithStorage[127.0.0.1:36502,DS-246307cf-5002-4130-bd33-43b163da8692,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-570922f6-93c2-415e-a005-0f7a4f7cd584,DISK], DatanodeInfoWithStorage[127.0.0.1:34309,DS-602f47f9-ebfb-4d9c-9a01-b78139b195fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-cf26db2d-4e25-4814-aa68-8a3da32491ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-756969562-172.17.0.3-1595610031273:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39001,DS-f89f5b2b-3325-4f5c-9d78-1a59c4f2bb30,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-fcded902-a5e7-4345-9625-4dc5bc67bce2,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-caa29f26-07da-46bd-87c3-97e468b965bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-ccf7aa4c-f588-42d6-9a66-4df37b2cc127,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-1ae9f3a8-f047-4434-9ac2-0445ada7d941,DISK], DatanodeInfoWithStorage[127.0.0.1:36093,DS-97db5540-e6e2-4458-b08f-03b1d65c0e10,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-63957307-01c6-44a0-8e07-3cfca643be15,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-7c51f35f-0afd-4e58-923c-0bf37a8602e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-756969562-172.17.0.3-1595610031273:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39001,DS-f89f5b2b-3325-4f5c-9d78-1a59c4f2bb30,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-fcded902-a5e7-4345-9625-4dc5bc67bce2,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-caa29f26-07da-46bd-87c3-97e468b965bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-ccf7aa4c-f588-42d6-9a66-4df37b2cc127,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-1ae9f3a8-f047-4434-9ac2-0445ada7d941,DISK], DatanodeInfoWithStorage[127.0.0.1:36093,DS-97db5540-e6e2-4458-b08f-03b1d65c0e10,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-63957307-01c6-44a0-8e07-3cfca643be15,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-7c51f35f-0afd-4e58-923c-0bf37a8602e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 1 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5427
