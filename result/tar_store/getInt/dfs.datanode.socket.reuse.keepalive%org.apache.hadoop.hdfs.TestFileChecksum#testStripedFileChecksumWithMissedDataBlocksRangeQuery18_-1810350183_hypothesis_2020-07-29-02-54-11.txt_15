reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1646355426-172.17.0.15-1595991265426:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42666,DS-5113077b-a160-4917-ba56-f9e532a73ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-1ada645f-fc5e-4020-8962-9d1306e2e943,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-089abf25-2ba4-4897-a178-3bd5e13e269b,DISK], DatanodeInfoWithStorage[127.0.0.1:40093,DS-906b98a6-e54c-4219-a466-594a756c6ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-7615137b-42d0-4c7e-a2ee-0c91de0baeea,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-ad23ab28-2ae7-47b6-bf8f-75deb7cf9aac,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-1d8a3ef8-8e99-4775-8b71-c7af3a2845e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-2b23c7f8-a123-4511-a91f-d68642777021,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1646355426-172.17.0.15-1595991265426:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42666,DS-5113077b-a160-4917-ba56-f9e532a73ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-1ada645f-fc5e-4020-8962-9d1306e2e943,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-089abf25-2ba4-4897-a178-3bd5e13e269b,DISK], DatanodeInfoWithStorage[127.0.0.1:40093,DS-906b98a6-e54c-4219-a466-594a756c6ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-7615137b-42d0-4c7e-a2ee-0c91de0baeea,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-ad23ab28-2ae7-47b6-bf8f-75deb7cf9aac,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-1d8a3ef8-8e99-4775-8b71-c7af3a2845e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-2b23c7f8-a123-4511-a91f-d68642777021,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-103676976-172.17.0.15-1595991304140:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39720,DS-93bd5e17-df7b-41fd-a3e3-b7bbcef454cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-249cca37-eda1-4fbf-b3ef-1d82292dd8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-91dba2dc-114f-4fe9-938d-f6ce2dff63e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-c6103f90-370c-4014-a2e2-902d73f64e01,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-7f7909d7-6f87-49a2-93fc-0f504cefb001,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-6c987beb-2a89-4bb6-bb47-1f344026935b,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-8d2b4a93-257f-4b69-af63-ab8f7e27c017,DISK], DatanodeInfoWithStorage[127.0.0.1:33086,DS-d1dba1b3-8b06-4d54-b965-ac1981e72574,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-103676976-172.17.0.15-1595991304140:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39720,DS-93bd5e17-df7b-41fd-a3e3-b7bbcef454cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-249cca37-eda1-4fbf-b3ef-1d82292dd8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-91dba2dc-114f-4fe9-938d-f6ce2dff63e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-c6103f90-370c-4014-a2e2-902d73f64e01,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-7f7909d7-6f87-49a2-93fc-0f504cefb001,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-6c987beb-2a89-4bb6-bb47-1f344026935b,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-8d2b4a93-257f-4b69-af63-ab8f7e27c017,DISK], DatanodeInfoWithStorage[127.0.0.1:33086,DS-d1dba1b3-8b06-4d54-b965-ac1981e72574,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1826638696-172.17.0.15-1595991644314:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35875,DS-7ed59140-38c7-4522-a61a-5313038fd991,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-f34e95e8-8af3-4842-946c-7000c248db77,DISK], DatanodeInfoWithStorage[127.0.0.1:37533,DS-7c1f924f-7104-4cb6-86fc-53fbd3c76410,DISK], DatanodeInfoWithStorage[127.0.0.1:39072,DS-d89d09b7-7d76-4761-b921-94e48ad7aec2,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-ea0941a2-69bf-45cc-91fb-ce79feb1af0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-bff4145d-c145-4878-8126-8f330b4dbc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39538,DS-4a844110-8484-4f2f-8032-d1809d9e67ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-c3d2b7a4-bafc-4833-8dd6-7a0768168713,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1826638696-172.17.0.15-1595991644314:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35875,DS-7ed59140-38c7-4522-a61a-5313038fd991,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-f34e95e8-8af3-4842-946c-7000c248db77,DISK], DatanodeInfoWithStorage[127.0.0.1:37533,DS-7c1f924f-7104-4cb6-86fc-53fbd3c76410,DISK], DatanodeInfoWithStorage[127.0.0.1:39072,DS-d89d09b7-7d76-4761-b921-94e48ad7aec2,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-ea0941a2-69bf-45cc-91fb-ce79feb1af0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-bff4145d-c145-4878-8126-8f330b4dbc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39538,DS-4a844110-8484-4f2f-8032-d1809d9e67ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-c3d2b7a4-bafc-4833-8dd6-7a0768168713,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-991112444-172.17.0.15-1595991820890:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36627,DS-1164ab61-9324-4cf6-868d-dc5b7c5c19a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45798,DS-49a68c3a-0924-436b-9a44-af6d769ae7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45303,DS-c2f67358-23eb-4afe-b3e9-22d7364ba079,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-3567f076-9053-4a93-992c-2307ea0f01ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42567,DS-7dfd75dd-f714-422a-9d72-5d0945d93548,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-e755ecbe-3b17-4bef-b5b0-87df94c057e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-ded87531-b970-4b83-badc-8f12a3cca70b,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-f6687907-f65c-4ce0-97e6-b590d8453b47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-991112444-172.17.0.15-1595991820890:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36627,DS-1164ab61-9324-4cf6-868d-dc5b7c5c19a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45798,DS-49a68c3a-0924-436b-9a44-af6d769ae7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45303,DS-c2f67358-23eb-4afe-b3e9-22d7364ba079,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-3567f076-9053-4a93-992c-2307ea0f01ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42567,DS-7dfd75dd-f714-422a-9d72-5d0945d93548,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-e755ecbe-3b17-4bef-b5b0-87df94c057e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-ded87531-b970-4b83-badc-8f12a3cca70b,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-f6687907-f65c-4ce0-97e6-b590d8453b47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-28179931-172.17.0.15-1595991923739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46541,DS-bd8a8a56-df0e-4624-aeea-1928b4248e93,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-e3bdb975-4477-43e2-a809-72eee2357e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-150dfec7-6a72-4ac5-9950-cc5a50b25662,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-8bcd59a4-c79e-41c7-abd2-15cf1b84771b,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-b7e4298b-3352-46fe-93da-fd43574cfa35,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-f029b2b1-07fa-49b8-83c6-477e900626c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-44eacb1c-85f7-4c9c-8981-da47105535d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-7825e999-95a6-4518-af77-8cf6585bc624,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-28179931-172.17.0.15-1595991923739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46541,DS-bd8a8a56-df0e-4624-aeea-1928b4248e93,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-e3bdb975-4477-43e2-a809-72eee2357e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-150dfec7-6a72-4ac5-9950-cc5a50b25662,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-8bcd59a4-c79e-41c7-abd2-15cf1b84771b,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-b7e4298b-3352-46fe-93da-fd43574cfa35,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-f029b2b1-07fa-49b8-83c6-477e900626c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-44eacb1c-85f7-4c9c-8981-da47105535d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-7825e999-95a6-4518-af77-8cf6585bc624,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-504290756-172.17.0.15-1595991959611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42479,DS-471a0173-f108-4e01-87e6-fd02d9fb7492,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-4b2e053e-8b66-4c9c-8251-87a839c66899,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-71f70e52-76f0-4f9d-9010-b8a19a6fd875,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-b145dd8b-710b-4399-bbf7-454cba3c1e60,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-ca389d0b-399e-44e6-a89e-84a588e82d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-9edafff4-8335-48dc-b37f-37d8d80d4929,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-8b23bade-2362-4aa5-8d59-5db0d7d0540c,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-e017461b-5322-4a8f-aacd-502cdcef9c03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-504290756-172.17.0.15-1595991959611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42479,DS-471a0173-f108-4e01-87e6-fd02d9fb7492,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-4b2e053e-8b66-4c9c-8251-87a839c66899,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-71f70e52-76f0-4f9d-9010-b8a19a6fd875,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-b145dd8b-710b-4399-bbf7-454cba3c1e60,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-ca389d0b-399e-44e6-a89e-84a588e82d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-9edafff4-8335-48dc-b37f-37d8d80d4929,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-8b23bade-2362-4aa5-8d59-5db0d7d0540c,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-e017461b-5322-4a8f-aacd-502cdcef9c03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2067989427-172.17.0.15-1595992023282:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38494,DS-363b30b3-a37a-44de-bab8-e1cc2f178e38,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-549cea8e-27f1-44ae-8ef0-2866d88b9838,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-1972c4e4-907c-4854-9e56-bccbbf9aef51,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-ce10ef21-fca7-4b36-8fb4-ff1823426125,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-e6bfd7cf-0627-495c-b984-92e8c3254d40,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-c4efd0a7-6fdc-4bb9-928f-91e65cbfc876,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-af0f71ab-20d9-47f8-a667-80621aa7c994,DISK], DatanodeInfoWithStorage[127.0.0.1:33906,DS-582580af-4df4-4eae-9126-69d6d243a6c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2067989427-172.17.0.15-1595992023282:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38494,DS-363b30b3-a37a-44de-bab8-e1cc2f178e38,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-549cea8e-27f1-44ae-8ef0-2866d88b9838,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-1972c4e4-907c-4854-9e56-bccbbf9aef51,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-ce10ef21-fca7-4b36-8fb4-ff1823426125,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-e6bfd7cf-0627-495c-b984-92e8c3254d40,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-c4efd0a7-6fdc-4bb9-928f-91e65cbfc876,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-af0f71ab-20d9-47f8-a667-80621aa7c994,DISK], DatanodeInfoWithStorage[127.0.0.1:33906,DS-582580af-4df4-4eae-9126-69d6d243a6c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1779022204-172.17.0.15-1595992307188:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33830,DS-879dd86a-dfea-482c-b0f1-4a51e14d73d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-14a30752-2562-416f-97b6-90fce0cfcabe,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-fb93823c-9ae4-4a06-9099-92425c02e2d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-b66d6d24-6391-46dd-93d5-278f63ec521f,DISK], DatanodeInfoWithStorage[127.0.0.1:40643,DS-00683548-5e89-4e7d-98db-d99a80e0d78c,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-ffdca6f4-89bc-4b4b-ae25-1b099f649db8,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-87e218c1-0c5e-4b03-ae3e-79672de41be0,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-e54dfccb-f775-4ab8-a693-5318ee7a9496,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1779022204-172.17.0.15-1595992307188:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33830,DS-879dd86a-dfea-482c-b0f1-4a51e14d73d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-14a30752-2562-416f-97b6-90fce0cfcabe,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-fb93823c-9ae4-4a06-9099-92425c02e2d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-b66d6d24-6391-46dd-93d5-278f63ec521f,DISK], DatanodeInfoWithStorage[127.0.0.1:40643,DS-00683548-5e89-4e7d-98db-d99a80e0d78c,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-ffdca6f4-89bc-4b4b-ae25-1b099f649db8,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-87e218c1-0c5e-4b03-ae3e-79672de41be0,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-e54dfccb-f775-4ab8-a693-5318ee7a9496,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1065010795-172.17.0.15-1595992500624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46420,DS-c54dd49e-2df6-43d0-aa73-6631e78007e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-2f740033-32c9-4daa-a3f1-b8a3e98377f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37552,DS-91155aad-6d7a-4077-ba1c-1956e5950833,DISK], DatanodeInfoWithStorage[127.0.0.1:34767,DS-b347af4e-af81-4603-a2c2-201857af1525,DISK], DatanodeInfoWithStorage[127.0.0.1:41606,DS-505ccca1-07bc-4610-af33-ef4810502f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-940d8681-076b-4abf-8612-38d0892670e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-e23fcef0-26d7-4dcc-90df-90f017339f93,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-1d3e8c1a-a0dc-4165-92b6-326db91e236b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1065010795-172.17.0.15-1595992500624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46420,DS-c54dd49e-2df6-43d0-aa73-6631e78007e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-2f740033-32c9-4daa-a3f1-b8a3e98377f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37552,DS-91155aad-6d7a-4077-ba1c-1956e5950833,DISK], DatanodeInfoWithStorage[127.0.0.1:34767,DS-b347af4e-af81-4603-a2c2-201857af1525,DISK], DatanodeInfoWithStorage[127.0.0.1:41606,DS-505ccca1-07bc-4610-af33-ef4810502f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-940d8681-076b-4abf-8612-38d0892670e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-e23fcef0-26d7-4dcc-90df-90f017339f93,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-1d3e8c1a-a0dc-4165-92b6-326db91e236b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2039330320-172.17.0.15-1595993294749:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43828,DS-13aa864e-19f1-4481-857f-dcb185a7ee13,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-90965433-f8b4-408e-96b7-e3d0c3130ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-99d16d5d-0a64-49d6-b334-c0b0b2e2e6df,DISK], DatanodeInfoWithStorage[127.0.0.1:42298,DS-39a1c87c-9285-41cd-acdc-74aaff69fef1,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-fc3379ea-3dd4-4270-87af-875bc07f18ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-4ecbdf57-01ca-4544-9407-62d70dc57d17,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-56195913-5ceb-43f6-bf2d-8a8ccb6396e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-084d3211-6f33-4598-bbe6-5e2d99d8a306,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2039330320-172.17.0.15-1595993294749:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43828,DS-13aa864e-19f1-4481-857f-dcb185a7ee13,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-90965433-f8b4-408e-96b7-e3d0c3130ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-99d16d5d-0a64-49d6-b334-c0b0b2e2e6df,DISK], DatanodeInfoWithStorage[127.0.0.1:42298,DS-39a1c87c-9285-41cd-acdc-74aaff69fef1,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-fc3379ea-3dd4-4270-87af-875bc07f18ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-4ecbdf57-01ca-4544-9407-62d70dc57d17,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-56195913-5ceb-43f6-bf2d-8a8ccb6396e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-084d3211-6f33-4598-bbe6-5e2d99d8a306,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1028335375-172.17.0.15-1595993604446:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36143,DS-2fd8c91c-7790-48ae-94e9-44ee9b9d613f,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-4a367a35-0f9e-4d1c-a3c7-39d09511ef24,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-6c933249-b0de-4c20-bf00-0f78f9815c14,DISK], DatanodeInfoWithStorage[127.0.0.1:38782,DS-37568553-9b0f-43e0-8e3e-faf37ddfbbbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43851,DS-f36353b5-f1da-46c0-95ce-ecf64c9986a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-06f8ab0f-a966-4298-9110-fcf96a413019,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-a9120781-92b5-43db-8bca-92d14b3b7489,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-2a1f9529-4e74-4873-93f1-16f5613cacb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1028335375-172.17.0.15-1595993604446:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36143,DS-2fd8c91c-7790-48ae-94e9-44ee9b9d613f,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-4a367a35-0f9e-4d1c-a3c7-39d09511ef24,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-6c933249-b0de-4c20-bf00-0f78f9815c14,DISK], DatanodeInfoWithStorage[127.0.0.1:38782,DS-37568553-9b0f-43e0-8e3e-faf37ddfbbbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43851,DS-f36353b5-f1da-46c0-95ce-ecf64c9986a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-06f8ab0f-a966-4298-9110-fcf96a413019,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-a9120781-92b5-43db-8bca-92d14b3b7489,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-2a1f9529-4e74-4873-93f1-16f5613cacb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-110549680-172.17.0.15-1595994324270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38078,DS-92236c76-5571-447e-8304-e9e6e33584be,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-3d1622a3-9835-4f31-b51e-9c76e7e8fee5,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-8a82e454-3fb4-4a8c-aee0-ef295796f408,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-60f4f572-0563-4f75-9a2b-d232685a71d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-d50bc024-a903-4973-bda4-ee202f8b0f54,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-9f4ea9b2-28ad-4ae0-821e-4b3b7f5b6aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-ec7b305a-43b6-4fa4-8a8c-11a2588ed5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-9ff32e43-8728-49f1-b763-3887154d6a59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-110549680-172.17.0.15-1595994324270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38078,DS-92236c76-5571-447e-8304-e9e6e33584be,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-3d1622a3-9835-4f31-b51e-9c76e7e8fee5,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-8a82e454-3fb4-4a8c-aee0-ef295796f408,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-60f4f572-0563-4f75-9a2b-d232685a71d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-d50bc024-a903-4973-bda4-ee202f8b0f54,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-9f4ea9b2-28ad-4ae0-821e-4b3b7f5b6aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-ec7b305a-43b6-4fa4-8a8c-11a2588ed5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-9ff32e43-8728-49f1-b763-3887154d6a59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-474174230-172.17.0.15-1595994804621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36572,DS-5aeff620-8b17-449d-91db-551a2552e335,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-8ab18482-4742-4541-9dd5-d3e54cfd5bad,DISK], DatanodeInfoWithStorage[127.0.0.1:34860,DS-cef3a55b-436a-46fc-9178-a05cfbbf6c91,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-a0142139-83fe-4654-879e-1958bdb50725,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-b5c59d34-4439-4fc7-8da7-e8f359b3c9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-41001bc2-528f-4ea4-a7dd-00c9be00def6,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-50de83bb-12d7-4306-9005-f91ca920f518,DISK], DatanodeInfoWithStorage[127.0.0.1:35750,DS-c26dd7fe-554b-4083-8adc-393f0a30aa98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-474174230-172.17.0.15-1595994804621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36572,DS-5aeff620-8b17-449d-91db-551a2552e335,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-8ab18482-4742-4541-9dd5-d3e54cfd5bad,DISK], DatanodeInfoWithStorage[127.0.0.1:34860,DS-cef3a55b-436a-46fc-9178-a05cfbbf6c91,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-a0142139-83fe-4654-879e-1958bdb50725,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-b5c59d34-4439-4fc7-8da7-e8f359b3c9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-41001bc2-528f-4ea4-a7dd-00c9be00def6,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-50de83bb-12d7-4306-9005-f91ca920f518,DISK], DatanodeInfoWithStorage[127.0.0.1:35750,DS-c26dd7fe-554b-4083-8adc-393f0a30aa98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-313314880-172.17.0.15-1595995385587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37669,DS-60454823-b1cd-4508-9e3c-cf6a770f505c,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-3482717d-126e-4e74-9cab-2dff1fcdce38,DISK], DatanodeInfoWithStorage[127.0.0.1:33272,DS-d45d0d0c-504c-4149-b137-626338e020af,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-c3ad5b2a-8067-40d7-84a1-adfdca60b5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-8fec429c-c7c2-4f03-961b-15b8ac8b19e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-30bc328c-8191-45b2-b87d-91252e3cdee8,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-6f49cf03-bf34-4e4f-ba60-819bd87f61b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-154b557d-a74b-402f-827e-cc8baf53914f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-313314880-172.17.0.15-1595995385587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37669,DS-60454823-b1cd-4508-9e3c-cf6a770f505c,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-3482717d-126e-4e74-9cab-2dff1fcdce38,DISK], DatanodeInfoWithStorage[127.0.0.1:33272,DS-d45d0d0c-504c-4149-b137-626338e020af,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-c3ad5b2a-8067-40d7-84a1-adfdca60b5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-8fec429c-c7c2-4f03-961b-15b8ac8b19e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-30bc328c-8191-45b2-b87d-91252e3cdee8,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-6f49cf03-bf34-4e4f-ba60-819bd87f61b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-154b557d-a74b-402f-827e-cc8baf53914f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-816483413-172.17.0.15-1595995489576:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43834,DS-62c9af5e-e386-4b79-b099-315be0c7b3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40314,DS-2159c2c6-4e39-441c-b28c-01e6e9b0531f,DISK], DatanodeInfoWithStorage[127.0.0.1:45585,DS-e77ab608-90e4-4f6c-9289-73c383ad3fff,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-a34f3145-1106-47c8-bd68-90caccc79883,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-b9645c1e-3ec0-4c00-b98e-7eb185085161,DISK], DatanodeInfoWithStorage[127.0.0.1:45140,DS-5e9f9f7b-f3c7-44bb-9179-ca7212e4269b,DISK], DatanodeInfoWithStorage[127.0.0.1:36901,DS-d27e3da7-31a8-4d03-b61f-ee387504bed5,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-807c9825-9a78-4cfb-b08f-893bb97bb26d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-816483413-172.17.0.15-1595995489576:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43834,DS-62c9af5e-e386-4b79-b099-315be0c7b3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40314,DS-2159c2c6-4e39-441c-b28c-01e6e9b0531f,DISK], DatanodeInfoWithStorage[127.0.0.1:45585,DS-e77ab608-90e4-4f6c-9289-73c383ad3fff,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-a34f3145-1106-47c8-bd68-90caccc79883,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-b9645c1e-3ec0-4c00-b98e-7eb185085161,DISK], DatanodeInfoWithStorage[127.0.0.1:45140,DS-5e9f9f7b-f3c7-44bb-9179-ca7212e4269b,DISK], DatanodeInfoWithStorage[127.0.0.1:36901,DS-d27e3da7-31a8-4d03-b61f-ee387504bed5,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-807c9825-9a78-4cfb-b08f-893bb97bb26d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1004575763-172.17.0.15-1595995584252:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34358,DS-abcc2c77-59fc-425e-b44e-5ba3c7e69bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-079748f1-2350-49d7-9592-cd6c6c9014ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-273a93c7-ed63-482d-9ec6-1a58d20ae761,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-f084aa18-21f9-493b-b8bf-50021e071660,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-a47b8fb8-6c32-43de-9fca-d850a4098b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-cae078e9-488a-4ac0-93fb-596745440c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36288,DS-cce5a29d-eb9e-4dea-9615-1c509c85eeac,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-4be16572-e7b1-4f41-a116-b58107ee7b19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1004575763-172.17.0.15-1595995584252:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34358,DS-abcc2c77-59fc-425e-b44e-5ba3c7e69bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-079748f1-2350-49d7-9592-cd6c6c9014ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-273a93c7-ed63-482d-9ec6-1a58d20ae761,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-f084aa18-21f9-493b-b8bf-50021e071660,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-a47b8fb8-6c32-43de-9fca-d850a4098b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-cae078e9-488a-4ac0-93fb-596745440c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36288,DS-cce5a29d-eb9e-4dea-9615-1c509c85eeac,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-4be16572-e7b1-4f41-a116-b58107ee7b19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-686210814-172.17.0.15-1595995998147:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46186,DS-83cc6e5f-2255-4a0e-b4f9-d022ae11df8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-b4003e57-2351-4bcb-b507-0294f512a0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42938,DS-f847ef53-fe90-4cd1-9917-08b8fa1a30c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-42448719-5c0b-45e6-94b8-4e6795e5ec56,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-455e0d08-09e3-4d1c-931e-aedd0a967df9,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-a115cc61-c67e-4502-a6ef-b36027820a30,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-ef6efe30-b0c6-4815-8d24-cb4d724d6dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-220a7ecb-df1b-4859-83e3-879babce2ca6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-686210814-172.17.0.15-1595995998147:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46186,DS-83cc6e5f-2255-4a0e-b4f9-d022ae11df8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-b4003e57-2351-4bcb-b507-0294f512a0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42938,DS-f847ef53-fe90-4cd1-9917-08b8fa1a30c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-42448719-5c0b-45e6-94b8-4e6795e5ec56,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-455e0d08-09e3-4d1c-931e-aedd0a967df9,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-a115cc61-c67e-4502-a6ef-b36027820a30,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-ef6efe30-b0c6-4815-8d24-cb4d724d6dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-220a7ecb-df1b-4859-83e3-879babce2ca6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 4875
