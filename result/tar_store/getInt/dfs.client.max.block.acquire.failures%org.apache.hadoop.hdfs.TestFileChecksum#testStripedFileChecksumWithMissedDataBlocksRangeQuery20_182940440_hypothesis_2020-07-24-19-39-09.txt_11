reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1989170490-172.17.0.6-1595620376842:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45363,DS-58f418b4-51d0-41e5-948a-e453ff075c04,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-545af8ad-ceb6-4f7d-9ade-c4308ea10363,DISK], DatanodeInfoWithStorage[127.0.0.1:46594,DS-723814f9-6b47-4ca7-8935-e7abddbde751,DISK], DatanodeInfoWithStorage[127.0.0.1:44180,DS-193d774b-e728-4b3a-961c-1d5e04eb0f75,DISK], DatanodeInfoWithStorage[127.0.0.1:45911,DS-c2981c5d-57ba-4de7-8efd-30fc9a1326ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-8300b55b-7343-4e1f-bfdf-97155565a83b,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-f77e70fb-4795-4f99-8047-a4e0d8f57cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-7cfee4ff-adc6-4d8e-bf81-82047dfec2d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1989170490-172.17.0.6-1595620376842:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45363,DS-58f418b4-51d0-41e5-948a-e453ff075c04,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-545af8ad-ceb6-4f7d-9ade-c4308ea10363,DISK], DatanodeInfoWithStorage[127.0.0.1:46594,DS-723814f9-6b47-4ca7-8935-e7abddbde751,DISK], DatanodeInfoWithStorage[127.0.0.1:44180,DS-193d774b-e728-4b3a-961c-1d5e04eb0f75,DISK], DatanodeInfoWithStorage[127.0.0.1:45911,DS-c2981c5d-57ba-4de7-8efd-30fc9a1326ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-8300b55b-7343-4e1f-bfdf-97155565a83b,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-f77e70fb-4795-4f99-8047-a4e0d8f57cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-7cfee4ff-adc6-4d8e-bf81-82047dfec2d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-740837076-172.17.0.6-1595620545662:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32885,DS-b01c3e08-cb38-4eec-9085-94bb4b08cd90,DISK], DatanodeInfoWithStorage[127.0.0.1:37511,DS-108144f7-6c37-4340-86b8-748b9489db6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40198,DS-37e6c2ac-9520-4f25-a128-543587ed5670,DISK], DatanodeInfoWithStorage[127.0.0.1:43988,DS-4450a5e4-c053-4058-bd0a-1753e170bff9,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-9d1930b5-02ff-4657-9b10-354f212b826c,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-51aabcdc-0780-4e61-92aa-62ef8f2a90ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-fedc5a8b-a4a9-439e-8c78-271ffd4f1340,DISK], DatanodeInfoWithStorage[127.0.0.1:46342,DS-4942a6d9-721b-44ef-bb7f-d4491cd82e72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-740837076-172.17.0.6-1595620545662:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32885,DS-b01c3e08-cb38-4eec-9085-94bb4b08cd90,DISK], DatanodeInfoWithStorage[127.0.0.1:37511,DS-108144f7-6c37-4340-86b8-748b9489db6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40198,DS-37e6c2ac-9520-4f25-a128-543587ed5670,DISK], DatanodeInfoWithStorage[127.0.0.1:43988,DS-4450a5e4-c053-4058-bd0a-1753e170bff9,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-9d1930b5-02ff-4657-9b10-354f212b826c,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-51aabcdc-0780-4e61-92aa-62ef8f2a90ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-fedc5a8b-a4a9-439e-8c78-271ffd4f1340,DISK], DatanodeInfoWithStorage[127.0.0.1:46342,DS-4942a6d9-721b-44ef-bb7f-d4491cd82e72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1904335307-172.17.0.6-1595620894756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38463,DS-4a2e38dd-aa3a-4eac-95ad-acde166875ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-e6986866-1f46-4306-850d-369d7649b801,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-6d75b873-5034-439e-8af7-7ce89e4a3264,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-af3e0bc2-b84e-47ce-bf0a-9ba587cd22a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-7f6551cf-1e4d-4fda-bdd9-2182a311431d,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-10783020-a74d-4aea-b3c9-bfb4c5710b67,DISK], DatanodeInfoWithStorage[127.0.0.1:46739,DS-b80d37ce-3b14-42d0-89b9-fdf14ff15d65,DISK], DatanodeInfoWithStorage[127.0.0.1:42354,DS-cced0849-797b-4b7c-82cc-c8c613fbbcf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1904335307-172.17.0.6-1595620894756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38463,DS-4a2e38dd-aa3a-4eac-95ad-acde166875ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-e6986866-1f46-4306-850d-369d7649b801,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-6d75b873-5034-439e-8af7-7ce89e4a3264,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-af3e0bc2-b84e-47ce-bf0a-9ba587cd22a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-7f6551cf-1e4d-4fda-bdd9-2182a311431d,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-10783020-a74d-4aea-b3c9-bfb4c5710b67,DISK], DatanodeInfoWithStorage[127.0.0.1:46739,DS-b80d37ce-3b14-42d0-89b9-fdf14ff15d65,DISK], DatanodeInfoWithStorage[127.0.0.1:42354,DS-cced0849-797b-4b7c-82cc-c8c613fbbcf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-759035957-172.17.0.6-1595620999945:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34859,DS-583e48ab-4541-46aa-91d9-1d17ec8fceb0,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-b86b1d5a-c228-4cb6-a1db-4ba231fb69f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40367,DS-6ae30a9d-7960-421a-a911-fd717d6db177,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-04312203-8dfe-4b75-9761-d802416accc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-ed34a48e-3912-4fbb-adae-da75bb3a01c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-8560c463-0fad-4bdf-a0d7-c55c82637051,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-9e1adf04-3e5a-4428-85b3-c7843dfb1018,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-479a0cd8-3dec-400a-a9e1-472929ddcbf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-759035957-172.17.0.6-1595620999945:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34859,DS-583e48ab-4541-46aa-91d9-1d17ec8fceb0,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-b86b1d5a-c228-4cb6-a1db-4ba231fb69f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40367,DS-6ae30a9d-7960-421a-a911-fd717d6db177,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-04312203-8dfe-4b75-9761-d802416accc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-ed34a48e-3912-4fbb-adae-da75bb3a01c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-8560c463-0fad-4bdf-a0d7-c55c82637051,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-9e1adf04-3e5a-4428-85b3-c7843dfb1018,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-479a0cd8-3dec-400a-a9e1-472929ddcbf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1419221143-172.17.0.6-1595621495589:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33205,DS-08f9ecb1-eb47-47db-9591-4ca5ed7b721c,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-f2ec9602-3502-4572-8553-8da1559a9b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40667,DS-c371cc70-dbbe-4cfd-af34-9a8879df216a,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-032a9166-c7cc-497a-9f8e-dc90035d406f,DISK], DatanodeInfoWithStorage[127.0.0.1:46218,DS-4caf0e42-604e-4830-9b10-dad9cea30df0,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-60253186-fe90-41b9-83a5-9d62b6137361,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-3d17ef88-933a-4902-987d-d89d6d8dcda3,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-709107d6-84ca-4f83-8436-1b4405e84a10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1419221143-172.17.0.6-1595621495589:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33205,DS-08f9ecb1-eb47-47db-9591-4ca5ed7b721c,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-f2ec9602-3502-4572-8553-8da1559a9b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40667,DS-c371cc70-dbbe-4cfd-af34-9a8879df216a,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-032a9166-c7cc-497a-9f8e-dc90035d406f,DISK], DatanodeInfoWithStorage[127.0.0.1:46218,DS-4caf0e42-604e-4830-9b10-dad9cea30df0,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-60253186-fe90-41b9-83a5-9d62b6137361,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-3d17ef88-933a-4902-987d-d89d6d8dcda3,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-709107d6-84ca-4f83-8436-1b4405e84a10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-493079443-172.17.0.6-1595621879231:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35610,DS-b2e3e4bb-b293-49eb-afb8-0027fd180bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-4b7758cc-dd8a-4541-941f-4edcb30ca5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-98c3a611-4942-4736-8713-db138dfb1d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34326,DS-c35c5b20-ef90-456a-a7b0-2529c09c1f19,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-a8be3a71-9d45-4aa3-900e-bb71d43917ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35082,DS-d7a83957-b16e-451a-a030-4a532224cefd,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-7dbb7d73-a5e9-4315-803b-38f9fd62c525,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-f6ffdf86-1b44-4692-b190-cab1747424cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-493079443-172.17.0.6-1595621879231:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35610,DS-b2e3e4bb-b293-49eb-afb8-0027fd180bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-4b7758cc-dd8a-4541-941f-4edcb30ca5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-98c3a611-4942-4736-8713-db138dfb1d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34326,DS-c35c5b20-ef90-456a-a7b0-2529c09c1f19,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-a8be3a71-9d45-4aa3-900e-bb71d43917ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35082,DS-d7a83957-b16e-451a-a030-4a532224cefd,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-7dbb7d73-a5e9-4315-803b-38f9fd62c525,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-f6ffdf86-1b44-4692-b190-cab1747424cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-937169086-172.17.0.6-1595622232419:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36651,DS-3d908b65-a0a7-4719-b48a-b0508fd75d37,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-47e2e2d2-fa00-4663-813e-b482fdc76689,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-1a3b5ef7-5afe-4dc4-b5b5-ff6ea71ef449,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-b7b0c150-a88d-4d7a-9a8a-87ca38994396,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-f2719e9e-fb22-4a15-9fbe-f46ddb8bdd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-1ab42051-ff17-4bb8-993a-c7f85bddd7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-10071eef-aa0c-4e30-8414-f4cadb23c31c,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-c1dd1311-e0b2-4955-8a73-25c1b55109a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-937169086-172.17.0.6-1595622232419:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36651,DS-3d908b65-a0a7-4719-b48a-b0508fd75d37,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-47e2e2d2-fa00-4663-813e-b482fdc76689,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-1a3b5ef7-5afe-4dc4-b5b5-ff6ea71ef449,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-b7b0c150-a88d-4d7a-9a8a-87ca38994396,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-f2719e9e-fb22-4a15-9fbe-f46ddb8bdd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-1ab42051-ff17-4bb8-993a-c7f85bddd7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-10071eef-aa0c-4e30-8414-f4cadb23c31c,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-c1dd1311-e0b2-4955-8a73-25c1b55109a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-365186938-172.17.0.6-1595622270409:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39785,DS-c3868de0-cbed-4905-bb43-385695ca3f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-d5ae8a2c-35ce-41b0-9bde-a9f7a9929ada,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-237dea2f-ebc4-419c-9c9a-231b10955762,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-82f4de79-1a3d-4dc1-ae37-1cb1bb787de8,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-a7110e7a-325f-47bb-9178-1584893aa47e,DISK], DatanodeInfoWithStorage[127.0.0.1:39955,DS-c39bee21-4e1b-40ba-b030-820fb28bf692,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-2f995a6b-f69b-4a4e-8954-58125c0a9fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-01dcf7e5-b3f3-442e-a770-92059af37bb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-365186938-172.17.0.6-1595622270409:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39785,DS-c3868de0-cbed-4905-bb43-385695ca3f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-d5ae8a2c-35ce-41b0-9bde-a9f7a9929ada,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-237dea2f-ebc4-419c-9c9a-231b10955762,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-82f4de79-1a3d-4dc1-ae37-1cb1bb787de8,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-a7110e7a-325f-47bb-9178-1584893aa47e,DISK], DatanodeInfoWithStorage[127.0.0.1:39955,DS-c39bee21-4e1b-40ba-b030-820fb28bf692,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-2f995a6b-f69b-4a4e-8954-58125c0a9fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-01dcf7e5-b3f3-442e-a770-92059af37bb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-414334832-172.17.0.6-1595622409715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37632,DS-082b3ff9-728d-410c-a918-13d5d22ba1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-cd66ca21-2c68-4149-9686-6ea95c27c297,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-edbe4d96-cdf5-4546-9061-151a45abe237,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-e81dd8d1-67ff-40e6-8569-b1b9eb218cea,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-daa3e176-1dae-48c9-b766-68cb18691219,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-7a303234-7713-43f3-8c3a-21cdbabc2fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-801073f5-96bb-4940-ae3e-07ace407228e,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-835ed8ac-fb0b-4f2e-8f7b-44292e76a0b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-414334832-172.17.0.6-1595622409715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37632,DS-082b3ff9-728d-410c-a918-13d5d22ba1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-cd66ca21-2c68-4149-9686-6ea95c27c297,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-edbe4d96-cdf5-4546-9061-151a45abe237,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-e81dd8d1-67ff-40e6-8569-b1b9eb218cea,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-daa3e176-1dae-48c9-b766-68cb18691219,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-7a303234-7713-43f3-8c3a-21cdbabc2fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-801073f5-96bb-4940-ae3e-07ace407228e,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-835ed8ac-fb0b-4f2e-8f7b-44292e76a0b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-882529640-172.17.0.6-1595622450304:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40921,DS-d529e136-2fdb-4035-b7fd-4a9ff3de2702,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-754d1802-a4d6-4d1f-8978-3cdb401068cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44045,DS-38c16c9b-f0b4-4754-8d9d-3daad9ca42d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-4e901a08-6c0b-44d1-8d61-2a640e85933a,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-8bd50306-e71c-4b37-800a-fcd5da4c205e,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-01b76115-21dc-4570-98f5-f56c022a033a,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-7e32d071-2bb4-46f3-9641-2d7a539fc9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34371,DS-1479a2ea-c9c6-49a9-8d38-49b318a64231,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-882529640-172.17.0.6-1595622450304:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40921,DS-d529e136-2fdb-4035-b7fd-4a9ff3de2702,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-754d1802-a4d6-4d1f-8978-3cdb401068cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44045,DS-38c16c9b-f0b4-4754-8d9d-3daad9ca42d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-4e901a08-6c0b-44d1-8d61-2a640e85933a,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-8bd50306-e71c-4b37-800a-fcd5da4c205e,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-01b76115-21dc-4570-98f5-f56c022a033a,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-7e32d071-2bb4-46f3-9641-2d7a539fc9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34371,DS-1479a2ea-c9c6-49a9-8d38-49b318a64231,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1464467240-172.17.0.6-1595622486938:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34999,DS-fa560b43-70b3-4998-afeb-38ae59015448,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-808f329d-52fd-41aa-82d5-5c33653d7faf,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-b6152980-1ea3-46c6-a765-79c4902d0ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-b08a3e22-85d1-4e86-b88e-a90f704e1f47,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-9f3c8e79-9429-4917-8129-38f52453b3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-1d00ed43-569d-4caa-8f42-e51a3ebe45a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-24d5a539-0143-4f4f-9af8-5f71c438b6b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39271,DS-7f6a4819-1e68-48b0-a1c0-08ef0662536f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1464467240-172.17.0.6-1595622486938:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34999,DS-fa560b43-70b3-4998-afeb-38ae59015448,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-808f329d-52fd-41aa-82d5-5c33653d7faf,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-b6152980-1ea3-46c6-a765-79c4902d0ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-b08a3e22-85d1-4e86-b88e-a90f704e1f47,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-9f3c8e79-9429-4917-8129-38f52453b3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-1d00ed43-569d-4caa-8f42-e51a3ebe45a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-24d5a539-0143-4f4f-9af8-5f71c438b6b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39271,DS-7f6a4819-1e68-48b0-a1c0-08ef0662536f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-917325691-172.17.0.6-1595622699438:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42940,DS-858268a2-1354-4f67-9d11-c67600bf3d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36964,DS-0707aea7-aa62-426c-9f7d-c5012c9bf1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41935,DS-5ce048f5-5f07-41ae-8e22-c74237d31061,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-40384a4f-d083-411a-b1b2-518aec589669,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-66e67244-60b6-44e2-9d4a-832671f8efb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-ef1c5f9b-fca7-4b2a-adf4-16330afe5410,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-844d54eb-0da8-40fe-b42c-d2d172f351c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-5c9d54e1-82b8-457e-812f-67f11c194a73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-917325691-172.17.0.6-1595622699438:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42940,DS-858268a2-1354-4f67-9d11-c67600bf3d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36964,DS-0707aea7-aa62-426c-9f7d-c5012c9bf1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41935,DS-5ce048f5-5f07-41ae-8e22-c74237d31061,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-40384a4f-d083-411a-b1b2-518aec589669,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-66e67244-60b6-44e2-9d4a-832671f8efb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-ef1c5f9b-fca7-4b2a-adf4-16330afe5410,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-844d54eb-0da8-40fe-b42c-d2d172f351c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-5c9d54e1-82b8-457e-812f-67f11c194a73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1172503616-172.17.0.6-1595622973471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42778,DS-f923a1eb-d357-490b-8ec2-da9ad75f4a62,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-2283b56a-84cf-444a-a411-abe4228a84ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-f50da2f0-7177-4717-8fca-3d0a78d071f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-ee31ed48-1266-4784-a874-348e11a48864,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-dbf5a6dd-78ff-47fe-a154-a5e39cdc2bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-019116a8-5f00-42c1-83ec-2dfdb84f35a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-e5e89966-32df-4343-9339-41346e343b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33313,DS-3ac2b747-2c7a-4dce-a20b-3ea3fe5ccb89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1172503616-172.17.0.6-1595622973471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42778,DS-f923a1eb-d357-490b-8ec2-da9ad75f4a62,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-2283b56a-84cf-444a-a411-abe4228a84ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-f50da2f0-7177-4717-8fca-3d0a78d071f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-ee31ed48-1266-4784-a874-348e11a48864,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-dbf5a6dd-78ff-47fe-a154-a5e39cdc2bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-019116a8-5f00-42c1-83ec-2dfdb84f35a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-e5e89966-32df-4343-9339-41346e343b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33313,DS-3ac2b747-2c7a-4dce-a20b-3ea3fe5ccb89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-288811849-172.17.0.6-1595623046461:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38075,DS-b62758b0-3369-4715-8f76-27b889d3ef1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-fe739db4-62ad-4208-a4de-db09ea25ad00,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-9024233f-c4c4-4874-a53f-886f541634c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-599a4585-1120-4263-a5ab-11efb644e441,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-06fb393a-b909-4200-b44e-8061991c8adc,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-73208ea7-cac0-4e2f-b2d0-f4e4a587ce70,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-586d2986-556b-416b-b6bf-955e5f0cb72f,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-f07ca966-2d52-435c-a8e0-e02a62650d93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-288811849-172.17.0.6-1595623046461:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38075,DS-b62758b0-3369-4715-8f76-27b889d3ef1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-fe739db4-62ad-4208-a4de-db09ea25ad00,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-9024233f-c4c4-4874-a53f-886f541634c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-599a4585-1120-4263-a5ab-11efb644e441,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-06fb393a-b909-4200-b44e-8061991c8adc,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-73208ea7-cac0-4e2f-b2d0-f4e4a587ce70,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-586d2986-556b-416b-b6bf-955e5f0cb72f,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-f07ca966-2d52-435c-a8e0-e02a62650d93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-442363106-172.17.0.6-1595623480301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44654,DS-8cd732eb-8aba-488a-8137-74fe96112ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-6ed10e89-1146-4b2e-aabc-ee8dac8a54a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-a3310b98-66eb-412d-ba45-aaee7add7325,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-c7ed2607-13b9-48f6-aa6d-5644a2c89a36,DISK], DatanodeInfoWithStorage[127.0.0.1:40781,DS-dc85dbb6-bfde-424e-b4dd-f7985d504fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-e9551766-7860-42a6-8d55-66f4ba45eddc,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-b9204701-c3c4-46a3-919b-75881458ef92,DISK], DatanodeInfoWithStorage[127.0.0.1:42042,DS-bb271a64-1236-46bc-8cd2-c4b48e531eba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-442363106-172.17.0.6-1595623480301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44654,DS-8cd732eb-8aba-488a-8137-74fe96112ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-6ed10e89-1146-4b2e-aabc-ee8dac8a54a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-a3310b98-66eb-412d-ba45-aaee7add7325,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-c7ed2607-13b9-48f6-aa6d-5644a2c89a36,DISK], DatanodeInfoWithStorage[127.0.0.1:40781,DS-dc85dbb6-bfde-424e-b4dd-f7985d504fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-e9551766-7860-42a6-8d55-66f4ba45eddc,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-b9204701-c3c4-46a3-919b-75881458ef92,DISK], DatanodeInfoWithStorage[127.0.0.1:42042,DS-bb271a64-1236-46bc-8cd2-c4b48e531eba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-218167434-172.17.0.6-1595623554504:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46783,DS-95e472e8-f170-4264-bdc2-d8cfa80cee27,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-26d280b0-292b-4f4d-95a7-c1f466942acf,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-463663fa-9123-4efa-ae16-3ca4e11540b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-389ee988-531a-4887-8732-40d1c980c9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-6b2fdbc2-4fc6-4fa8-9023-bcf8517069fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44082,DS-48963f15-09c1-43a6-95c9-64eda4e6df68,DISK], DatanodeInfoWithStorage[127.0.0.1:35988,DS-89ae4bbb-7ebb-48ed-a798-8e4dac932bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:32960,DS-128308a0-5d7c-44ed-b11a-889c82ccc46f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-218167434-172.17.0.6-1595623554504:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46783,DS-95e472e8-f170-4264-bdc2-d8cfa80cee27,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-26d280b0-292b-4f4d-95a7-c1f466942acf,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-463663fa-9123-4efa-ae16-3ca4e11540b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-389ee988-531a-4887-8732-40d1c980c9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-6b2fdbc2-4fc6-4fa8-9023-bcf8517069fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44082,DS-48963f15-09c1-43a6-95c9-64eda4e6df68,DISK], DatanodeInfoWithStorage[127.0.0.1:35988,DS-89ae4bbb-7ebb-48ed-a798-8e4dac932bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:32960,DS-128308a0-5d7c-44ed-b11a-889c82ccc46f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1814305980-172.17.0.6-1595624771197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41311,DS-4f485ad0-8a28-4697-b6c9-7e6be4aca696,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-85bc8bc3-1f0d-458f-b342-42e28aecb60d,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-e8ed83fc-034f-4974-b028-3e520b89d020,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-63845f5b-adbb-41c8-b540-c1075dc213cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-abd82193-20e4-43be-ab9b-8e9e081bc148,DISK], DatanodeInfoWithStorage[127.0.0.1:41017,DS-6d9ef753-c143-426b-a588-b30ef94cb337,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-c964b937-8e4c-48c2-b62a-01a9ddf4ae8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-b811e323-0369-4981-a23e-635a50aca8f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1814305980-172.17.0.6-1595624771197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41311,DS-4f485ad0-8a28-4697-b6c9-7e6be4aca696,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-85bc8bc3-1f0d-458f-b342-42e28aecb60d,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-e8ed83fc-034f-4974-b028-3e520b89d020,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-63845f5b-adbb-41c8-b540-c1075dc213cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-abd82193-20e4-43be-ab9b-8e9e081bc148,DISK], DatanodeInfoWithStorage[127.0.0.1:41017,DS-6d9ef753-c143-426b-a588-b30ef94cb337,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-c964b937-8e4c-48c2-b62a-01a9ddf4ae8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-b811e323-0369-4981-a23e-635a50aca8f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1522619063-172.17.0.6-1595624921096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41086,DS-2a645d16-4ac7-4002-ae8c-f04777bf3edf,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-4036243b-4379-4030-9686-c397cd786293,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-fb9d91da-5424-44c8-8af6-217a3380b00d,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-61775ae5-2070-493d-990a-cbc15717f562,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-9557022a-1597-4dcb-bfdb-be1713cfe3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-467ac539-1506-4f6c-986b-40e787a2d538,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-dd165c6e-24d1-4a22-bfd1-5a341b15a842,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-92a031e6-07fe-465b-ac42-5bef1f19f7d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1522619063-172.17.0.6-1595624921096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41086,DS-2a645d16-4ac7-4002-ae8c-f04777bf3edf,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-4036243b-4379-4030-9686-c397cd786293,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-fb9d91da-5424-44c8-8af6-217a3380b00d,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-61775ae5-2070-493d-990a-cbc15717f562,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-9557022a-1597-4dcb-bfdb-be1713cfe3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-467ac539-1506-4f6c-986b-40e787a2d538,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-dd165c6e-24d1-4a22-bfd1-5a341b15a842,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-92a031e6-07fe-465b-ac42-5bef1f19f7d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5391
