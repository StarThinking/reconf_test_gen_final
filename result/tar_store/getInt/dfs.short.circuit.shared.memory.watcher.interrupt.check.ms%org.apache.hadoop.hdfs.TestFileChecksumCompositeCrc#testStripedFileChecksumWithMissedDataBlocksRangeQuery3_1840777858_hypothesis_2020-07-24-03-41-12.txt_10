reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 120000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 120000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-30072979-172.17.0.21-1595562278938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33906,DS-f09dfb33-aa47-4dc6-acf2-6cdb661ea981,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-b8b38d5c-7728-4d2a-a4bd-18e82b502bab,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-9efa80fb-680b-46a9-af89-a310e287fe68,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-28b25ec6-a07e-46d2-8eb2-0407709ac072,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-8b4e9cec-5a84-47e8-b9de-439ce27aa387,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-17d1d450-664a-4572-938f-f34ed9185e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-4e98eaaf-cea4-425e-9dea-7cf4195cf17a,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-11b83bea-6b6d-41dc-99cf-c8c3bc838781,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-30072979-172.17.0.21-1595562278938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33906,DS-f09dfb33-aa47-4dc6-acf2-6cdb661ea981,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-b8b38d5c-7728-4d2a-a4bd-18e82b502bab,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-9efa80fb-680b-46a9-af89-a310e287fe68,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-28b25ec6-a07e-46d2-8eb2-0407709ac072,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-8b4e9cec-5a84-47e8-b9de-439ce27aa387,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-17d1d450-664a-4572-938f-f34ed9185e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-4e98eaaf-cea4-425e-9dea-7cf4195cf17a,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-11b83bea-6b6d-41dc-99cf-c8c3bc838781,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 120000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1708640043-172.17.0.21-1595562768551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44086,DS-e96b1a1b-73f9-4a18-ad25-781100ce4994,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-c592d576-dca8-4b58-a439-adfd1f92d2db,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-bbcd32f8-666c-47c5-8ec2-e092588f2e23,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-1f8b517f-e019-4c9c-b39e-400c239b6bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-7f400774-dbf0-4fa1-a138-3ebe8d808ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:46428,DS-72326989-2e5c-4289-b8bd-ddf7225829a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-1f813655-237a-4224-b37d-92a0fe5fcc62,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-907b1e52-5108-4978-9639-462b2bd565d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1708640043-172.17.0.21-1595562768551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44086,DS-e96b1a1b-73f9-4a18-ad25-781100ce4994,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-c592d576-dca8-4b58-a439-adfd1f92d2db,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-bbcd32f8-666c-47c5-8ec2-e092588f2e23,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-1f8b517f-e019-4c9c-b39e-400c239b6bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-7f400774-dbf0-4fa1-a138-3ebe8d808ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:46428,DS-72326989-2e5c-4289-b8bd-ddf7225829a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-1f813655-237a-4224-b37d-92a0fe5fcc62,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-907b1e52-5108-4978-9639-462b2bd565d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 120000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1866324338-172.17.0.21-1595562904890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33951,DS-1ec19a68-c03e-4d9a-ae18-0f31076699ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-2bfa8dc7-ea8d-4fce-95d3-9a7248382f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-aa54c276-3307-4c6f-a51d-9c0c3485f3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-d7b675b8-d81c-45a7-b296-6d21f87afacc,DISK], DatanodeInfoWithStorage[127.0.0.1:41648,DS-b955b20e-4e22-47f5-b48d-d4b9bb087b60,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-f26c6d5c-9271-4cf6-95fa-d752fdde4432,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-5905c67a-da65-4706-ad02-b1da9dc33a76,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-ff7cdd55-f1d5-49dd-ba07-4ee526d33946,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1866324338-172.17.0.21-1595562904890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33951,DS-1ec19a68-c03e-4d9a-ae18-0f31076699ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-2bfa8dc7-ea8d-4fce-95d3-9a7248382f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-aa54c276-3307-4c6f-a51d-9c0c3485f3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-d7b675b8-d81c-45a7-b296-6d21f87afacc,DISK], DatanodeInfoWithStorage[127.0.0.1:41648,DS-b955b20e-4e22-47f5-b48d-d4b9bb087b60,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-f26c6d5c-9271-4cf6-95fa-d752fdde4432,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-5905c67a-da65-4706-ad02-b1da9dc33a76,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-ff7cdd55-f1d5-49dd-ba07-4ee526d33946,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 120000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-757519518-172.17.0.21-1595562945502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36954,DS-fa863541-23ee-435d-a3ad-e7e29479cef8,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-ffef9457-f180-44a3-8c79-c7190a9b21e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45955,DS-cb4c9a92-9c20-42ef-86c0-945a0c445601,DISK], DatanodeInfoWithStorage[127.0.0.1:37505,DS-13a22b80-b174-4be7-8e8d-ea8738a4f6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-1f5ff92d-f03e-46b6-abdd-c510f80a6835,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-39d4ba9c-da49-46c1-a541-9bf60839d045,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-9a42e527-64a0-4763-a43e-c5536775b7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-1acc0796-2c6b-49a1-8e6a-17d31261d162,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-757519518-172.17.0.21-1595562945502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36954,DS-fa863541-23ee-435d-a3ad-e7e29479cef8,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-ffef9457-f180-44a3-8c79-c7190a9b21e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45955,DS-cb4c9a92-9c20-42ef-86c0-945a0c445601,DISK], DatanodeInfoWithStorage[127.0.0.1:37505,DS-13a22b80-b174-4be7-8e8d-ea8738a4f6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-1f5ff92d-f03e-46b6-abdd-c510f80a6835,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-39d4ba9c-da49-46c1-a541-9bf60839d045,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-9a42e527-64a0-4763-a43e-c5536775b7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-1acc0796-2c6b-49a1-8e6a-17d31261d162,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 120000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-932121112-172.17.0.21-1595563050024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46725,DS-84bfce77-d164-4884-8320-aaf007c0ab22,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-292039b6-c837-4f3e-917f-372a1f02aced,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-4084094b-7426-48da-b4e5-7d1ba6b91951,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-088ccc43-4178-4166-b6e5-b08e7ac0c215,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-ca45e7b9-99f7-4d2a-8e9e-2648e049c4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-f7df0b9d-010c-4432-95c5-1d4f808343b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40034,DS-de4f73e1-d534-42db-9069-9ca18d615f09,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-7a30e34f-7293-477f-a516-c33c33725334,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-932121112-172.17.0.21-1595563050024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46725,DS-84bfce77-d164-4884-8320-aaf007c0ab22,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-292039b6-c837-4f3e-917f-372a1f02aced,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-4084094b-7426-48da-b4e5-7d1ba6b91951,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-088ccc43-4178-4166-b6e5-b08e7ac0c215,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-ca45e7b9-99f7-4d2a-8e9e-2648e049c4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-f7df0b9d-010c-4432-95c5-1d4f808343b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40034,DS-de4f73e1-d534-42db-9069-9ca18d615f09,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-7a30e34f-7293-477f-a516-c33c33725334,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 120000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-793210548-172.17.0.21-1595563111718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43406,DS-f9ebc94c-9954-41bc-88da-e2bebe289606,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-9e7eb8d2-29a6-4bd2-bd2e-6ba2600770b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37350,DS-2587f732-e16c-4d8a-9ca3-cbe3f485902b,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-6e8829b7-4ad0-4d9a-96b0-efecbb0bd9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-118f64a1-f6ee-45b6-8d2e-60c3ad22a846,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-0d9b0c90-13fd-4179-83d4-878541024e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-36beef23-89d4-4c61-aa5c-d59d2b4b46c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-7f4829c3-65df-4c17-8472-46870db8d130,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-793210548-172.17.0.21-1595563111718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43406,DS-f9ebc94c-9954-41bc-88da-e2bebe289606,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-9e7eb8d2-29a6-4bd2-bd2e-6ba2600770b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37350,DS-2587f732-e16c-4d8a-9ca3-cbe3f485902b,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-6e8829b7-4ad0-4d9a-96b0-efecbb0bd9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-118f64a1-f6ee-45b6-8d2e-60c3ad22a846,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-0d9b0c90-13fd-4179-83d4-878541024e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-36beef23-89d4-4c61-aa5c-d59d2b4b46c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-7f4829c3-65df-4c17-8472-46870db8d130,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 120000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1728291324-172.17.0.21-1595563177967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35348,DS-b7119ee8-c031-452e-9de8-92b222dd4fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-0128b451-80d2-47fb-940f-26804b2d67ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36235,DS-606b9ca5-fc0b-49f0-85fc-04b7e6dc0fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:42000,DS-44357890-502e-40c4-b463-3f310a5f5e24,DISK], DatanodeInfoWithStorage[127.0.0.1:36165,DS-45de7571-0343-4f9d-8579-5c85c4b9f5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-80953da0-ad9f-4c32-8cb4-e4a31f64dbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-fc05f959-ee36-43d5-a522-7332590e5777,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-d0000aeb-8401-43df-bc5f-f3c73a583d21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1728291324-172.17.0.21-1595563177967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35348,DS-b7119ee8-c031-452e-9de8-92b222dd4fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-0128b451-80d2-47fb-940f-26804b2d67ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36235,DS-606b9ca5-fc0b-49f0-85fc-04b7e6dc0fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:42000,DS-44357890-502e-40c4-b463-3f310a5f5e24,DISK], DatanodeInfoWithStorage[127.0.0.1:36165,DS-45de7571-0343-4f9d-8579-5c85c4b9f5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-80953da0-ad9f-4c32-8cb4-e4a31f64dbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-fc05f959-ee36-43d5-a522-7332590e5777,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-d0000aeb-8401-43df-bc5f-f3c73a583d21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 120000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1384291025-172.17.0.21-1595563703970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38937,DS-097d1f00-ef08-426e-bd3a-9f742ed90a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43941,DS-c8245d3e-bda9-43fa-bf18-f2e4e21b66a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40226,DS-f7aadffd-54c2-4338-90a3-cb5c1aa75343,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-ff68b63e-ed38-40c8-85c1-badcb7f63b87,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-ceb8a1e0-797c-426f-87af-58220968ae6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-ce2b0c94-387c-490b-bd43-51ac2fb4386f,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-7b694620-6da1-4e99-b0fc-437b0b903af3,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-bb694cee-5bc3-4c36-bbc4-b41e0ded880f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1384291025-172.17.0.21-1595563703970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38937,DS-097d1f00-ef08-426e-bd3a-9f742ed90a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43941,DS-c8245d3e-bda9-43fa-bf18-f2e4e21b66a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40226,DS-f7aadffd-54c2-4338-90a3-cb5c1aa75343,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-ff68b63e-ed38-40c8-85c1-badcb7f63b87,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-ceb8a1e0-797c-426f-87af-58220968ae6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-ce2b0c94-387c-490b-bd43-51ac2fb4386f,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-7b694620-6da1-4e99-b0fc-437b0b903af3,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-bb694cee-5bc3-4c36-bbc4-b41e0ded880f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 120000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1621921459-172.17.0.21-1595564273869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33931,DS-f4bb2e1b-ea8e-4059-b25c-0da9f07b7959,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-52e0d264-6d00-4bd3-b4ae-4b204374b7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34138,DS-e6b7321b-2d47-44b3-9863-53d0f56a7593,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-abfdff9d-bb1d-45a9-9833-3cdc0ffabb70,DISK], DatanodeInfoWithStorage[127.0.0.1:35399,DS-68905c87-7900-4fc6-8d50-141c4e6bfc57,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-4cc30996-b3ad-4d02-8013-84cc16a9a3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39817,DS-043e13f9-8cee-44c6-b626-60480be28dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-ccd5347a-3f92-4855-9555-623a5b264682,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1621921459-172.17.0.21-1595564273869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33931,DS-f4bb2e1b-ea8e-4059-b25c-0da9f07b7959,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-52e0d264-6d00-4bd3-b4ae-4b204374b7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34138,DS-e6b7321b-2d47-44b3-9863-53d0f56a7593,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-abfdff9d-bb1d-45a9-9833-3cdc0ffabb70,DISK], DatanodeInfoWithStorage[127.0.0.1:35399,DS-68905c87-7900-4fc6-8d50-141c4e6bfc57,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-4cc30996-b3ad-4d02-8013-84cc16a9a3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39817,DS-043e13f9-8cee-44c6-b626-60480be28dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-ccd5347a-3f92-4855-9555-623a5b264682,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 120000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1755368901-172.17.0.21-1595564345210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38323,DS-20867a5b-ce64-439e-82f3-d225a46a57bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-36f1dcfd-abc2-4657-a875-cff62011277d,DISK], DatanodeInfoWithStorage[127.0.0.1:44846,DS-338a3613-635e-4573-a5cb-433339b932e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-17225fbb-30e1-4a12-94cd-78fc8d8fc1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-92d18599-ca9b-4ec7-98a6-52b11e49fd33,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-405cf403-d2d4-43c3-81c0-fcdabde93598,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-b0c0a4a1-8830-4ab2-9a1a-d88c7429079d,DISK], DatanodeInfoWithStorage[127.0.0.1:44240,DS-e638e219-8175-4118-a597-2f145be21fd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1755368901-172.17.0.21-1595564345210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38323,DS-20867a5b-ce64-439e-82f3-d225a46a57bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-36f1dcfd-abc2-4657-a875-cff62011277d,DISK], DatanodeInfoWithStorage[127.0.0.1:44846,DS-338a3613-635e-4573-a5cb-433339b932e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-17225fbb-30e1-4a12-94cd-78fc8d8fc1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-92d18599-ca9b-4ec7-98a6-52b11e49fd33,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-405cf403-d2d4-43c3-81c0-fcdabde93598,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-b0c0a4a1-8830-4ab2-9a1a-d88c7429079d,DISK], DatanodeInfoWithStorage[127.0.0.1:44240,DS-e638e219-8175-4118-a597-2f145be21fd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 120000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2082143192-172.17.0.21-1595565517711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40004,DS-94acf249-85e4-4263-8bf0-e76c0f349e19,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-db5a3c8b-785d-4bea-bdd3-743a3772a9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-f8874cb4-bda5-4820-8b08-2df69b3cab83,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-30f6525b-3451-4055-8908-bae402c0843c,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-e0dddd36-de34-456e-bfee-208bc74c2abb,DISK], DatanodeInfoWithStorage[127.0.0.1:37940,DS-88311c52-c9ab-4b75-9d2b-893c3119fa5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37205,DS-7dfe7d67-61ac-4823-af82-d699001f09c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-2389462b-a0e5-40b2-a9e5-a0f32f22644c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2082143192-172.17.0.21-1595565517711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40004,DS-94acf249-85e4-4263-8bf0-e76c0f349e19,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-db5a3c8b-785d-4bea-bdd3-743a3772a9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-f8874cb4-bda5-4820-8b08-2df69b3cab83,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-30f6525b-3451-4055-8908-bae402c0843c,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-e0dddd36-de34-456e-bfee-208bc74c2abb,DISK], DatanodeInfoWithStorage[127.0.0.1:37940,DS-88311c52-c9ab-4b75-9d2b-893c3119fa5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37205,DS-7dfe7d67-61ac-4823-af82-d699001f09c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-2389462b-a0e5-40b2-a9e5-a0f32f22644c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 120000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1037708391-172.17.0.21-1595565804535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34737,DS-ca7d5bf1-2173-454b-8814-876bd8111373,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-babe4eaa-2709-4152-99b2-e110bf7cd2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-0f914bfd-fb94-4618-9ce4-7ba3adc67e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-a303cf5a-d6af-443e-835d-5b924d6c389f,DISK], DatanodeInfoWithStorage[127.0.0.1:40570,DS-4aa82bb6-1589-4b5a-89b0-00f3e12d2006,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-a8b605d6-9323-4511-9e09-f8f564000749,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-8170d7f2-e412-419b-8bdf-dff20027ad82,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-4ce7edca-4700-49b1-bc37-8f9536fe414c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1037708391-172.17.0.21-1595565804535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34737,DS-ca7d5bf1-2173-454b-8814-876bd8111373,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-babe4eaa-2709-4152-99b2-e110bf7cd2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-0f914bfd-fb94-4618-9ce4-7ba3adc67e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-a303cf5a-d6af-443e-835d-5b924d6c389f,DISK], DatanodeInfoWithStorage[127.0.0.1:40570,DS-4aa82bb6-1589-4b5a-89b0-00f3e12d2006,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-a8b605d6-9323-4511-9e09-f8f564000749,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-8170d7f2-e412-419b-8bdf-dff20027ad82,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-4ce7edca-4700-49b1-bc37-8f9536fe414c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 120000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1317320053-172.17.0.21-1595565848549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42348,DS-91ee96df-0152-4933-b233-8246130331de,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-1574bd1e-0035-42bb-8eb5-5b217d47fd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45164,DS-d8e4123b-4ce2-4777-bf1d-203811bab1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-101265ce-ec3f-4c03-8898-15c76f706546,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-1d797143-0d6c-41c0-846c-7e3b8f588d09,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-fe92abc0-1d74-46fa-af49-4575d15552d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-1f842dc6-5183-42fe-bceb-c9a5fe6fe55f,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-f8c8dbb5-3c63-47d6-aa52-c6c3edf95922,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1317320053-172.17.0.21-1595565848549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42348,DS-91ee96df-0152-4933-b233-8246130331de,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-1574bd1e-0035-42bb-8eb5-5b217d47fd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45164,DS-d8e4123b-4ce2-4777-bf1d-203811bab1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-101265ce-ec3f-4c03-8898-15c76f706546,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-1d797143-0d6c-41c0-846c-7e3b8f588d09,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-fe92abc0-1d74-46fa-af49-4575d15552d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-1f842dc6-5183-42fe-bceb-c9a5fe6fe55f,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-f8c8dbb5-3c63-47d6-aa52-c6c3edf95922,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 120000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1616865588-172.17.0.21-1595566106694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37929,DS-ee0806fe-61f9-4bcf-a213-4045574a2d05,DISK], DatanodeInfoWithStorage[127.0.0.1:34822,DS-33022d6c-9a46-4033-9907-bcb8ee22f574,DISK], DatanodeInfoWithStorage[127.0.0.1:35755,DS-016ba30f-2244-4268-b4d8-aeb62855ec6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-b20b14c3-7dca-4c19-b94f-59537c11401a,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-29036f69-e780-445d-935a-30a2d86fa093,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-fa8a4a0f-6dba-4989-b072-c3ccf70167f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-84965240-f2b1-477f-b225-aa66a43d6759,DISK], DatanodeInfoWithStorage[127.0.0.1:44957,DS-07695906-3012-4d7e-9016-3abc1d5f04ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1616865588-172.17.0.21-1595566106694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37929,DS-ee0806fe-61f9-4bcf-a213-4045574a2d05,DISK], DatanodeInfoWithStorage[127.0.0.1:34822,DS-33022d6c-9a46-4033-9907-bcb8ee22f574,DISK], DatanodeInfoWithStorage[127.0.0.1:35755,DS-016ba30f-2244-4268-b4d8-aeb62855ec6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-b20b14c3-7dca-4c19-b94f-59537c11401a,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-29036f69-e780-445d-935a-30a2d86fa093,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-fa8a4a0f-6dba-4989-b072-c3ccf70167f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-84965240-f2b1-477f-b225-aa66a43d6759,DISK], DatanodeInfoWithStorage[127.0.0.1:44957,DS-07695906-3012-4d7e-9016-3abc1d5f04ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 120000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1788625092-172.17.0.21-1595566839577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32906,DS-12d85855-962c-4a0f-81a9-c1876ecdf1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-2c11f9d5-ad41-4ea4-a647-64d9114870fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-79ab6bac-5005-4339-8046-8cf386caa4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39350,DS-21907f77-1688-461f-8980-6fd929ec3aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-37b4798a-0f97-4cee-ad08-6a067ec729d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-4360e897-1b7a-41a4-8795-a83b9eccdbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46224,DS-87251081-b84b-45b6-a479-ef7682b7dd97,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-d9b49337-e2c3-4b79-8b9c-aef06860b7d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1788625092-172.17.0.21-1595566839577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32906,DS-12d85855-962c-4a0f-81a9-c1876ecdf1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-2c11f9d5-ad41-4ea4-a647-64d9114870fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-79ab6bac-5005-4339-8046-8cf386caa4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39350,DS-21907f77-1688-461f-8980-6fd929ec3aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-37b4798a-0f97-4cee-ad08-6a067ec729d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-4360e897-1b7a-41a4-8795-a83b9eccdbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46224,DS-87251081-b84b-45b6-a479-ef7682b7dd97,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-d9b49337-e2c3-4b79-8b9c-aef06860b7d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5409
