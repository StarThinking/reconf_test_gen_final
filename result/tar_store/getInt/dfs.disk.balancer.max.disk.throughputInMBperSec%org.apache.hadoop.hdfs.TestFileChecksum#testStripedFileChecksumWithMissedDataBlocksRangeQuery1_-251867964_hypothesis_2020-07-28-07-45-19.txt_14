reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-85852292-172.17.0.20-1595922335365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40544,DS-7f95e216-017d-47bb-8798-8519cf1594db,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-84654679-3463-4aa9-a434-6fdddf3a46d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38911,DS-2bac91e8-f2c3-4961-843d-916f26015d28,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-be872d64-27a5-43e2-8113-5cd605bf9caa,DISK], DatanodeInfoWithStorage[127.0.0.1:40259,DS-e778cf94-d052-4cbd-8e2b-1f4a9da9fdee,DISK], DatanodeInfoWithStorage[127.0.0.1:36588,DS-4b13cd82-ade8-4455-b3ba-ff426a563af7,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-48636054-8645-49c2-b251-71649e6508e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-b62bb12d-d847-45fc-b031-9bb46e003ad5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-85852292-172.17.0.20-1595922335365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40544,DS-7f95e216-017d-47bb-8798-8519cf1594db,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-84654679-3463-4aa9-a434-6fdddf3a46d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38911,DS-2bac91e8-f2c3-4961-843d-916f26015d28,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-be872d64-27a5-43e2-8113-5cd605bf9caa,DISK], DatanodeInfoWithStorage[127.0.0.1:40259,DS-e778cf94-d052-4cbd-8e2b-1f4a9da9fdee,DISK], DatanodeInfoWithStorage[127.0.0.1:36588,DS-4b13cd82-ade8-4455-b3ba-ff426a563af7,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-48636054-8645-49c2-b251-71649e6508e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-b62bb12d-d847-45fc-b031-9bb46e003ad5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1826489784-172.17.0.20-1595922375035:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35343,DS-c55c8ba0-78d4-4885-ada7-36fe3470a1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41170,DS-46ee153d-c038-4ea5-b75b-f97e9693edc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-0a6ef579-609d-42e2-a0d8-345733ba68a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-8a0f1fd5-ade6-44f6-b15b-18f103e116db,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-d6326531-5ac9-4390-93c3-904911512e38,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-08ba9b56-08dc-4194-b171-b25b615b7c68,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-2a105662-d5be-4d4a-bae2-ec3648715b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-1f3112d7-6b1e-465f-91b6-3991f849793c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1826489784-172.17.0.20-1595922375035:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35343,DS-c55c8ba0-78d4-4885-ada7-36fe3470a1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41170,DS-46ee153d-c038-4ea5-b75b-f97e9693edc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-0a6ef579-609d-42e2-a0d8-345733ba68a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-8a0f1fd5-ade6-44f6-b15b-18f103e116db,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-d6326531-5ac9-4390-93c3-904911512e38,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-08ba9b56-08dc-4194-b171-b25b615b7c68,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-2a105662-d5be-4d4a-bae2-ec3648715b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-1f3112d7-6b1e-465f-91b6-3991f849793c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-464012041-172.17.0.20-1595922777600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35277,DS-6f9b302c-b513-4ee4-adac-8cea7921ffa1,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-68446b65-ae96-4e23-aa9e-857b82e8535f,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-efeab922-060a-4668-97f7-3952ebad683f,DISK], DatanodeInfoWithStorage[127.0.0.1:43341,DS-248341ba-e1ef-460a-8498-d32b6a367a63,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-9cfe6634-70c8-446c-84ac-15a7059d5c70,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-2a6c56a8-823a-4d04-9854-7af9e5c13f63,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-64e9dac4-6aa8-4a43-96b3-50a972f6c4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33236,DS-92cecc8f-71bf-4f97-8fd6-ec5d023d4058,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-464012041-172.17.0.20-1595922777600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35277,DS-6f9b302c-b513-4ee4-adac-8cea7921ffa1,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-68446b65-ae96-4e23-aa9e-857b82e8535f,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-efeab922-060a-4668-97f7-3952ebad683f,DISK], DatanodeInfoWithStorage[127.0.0.1:43341,DS-248341ba-e1ef-460a-8498-d32b6a367a63,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-9cfe6634-70c8-446c-84ac-15a7059d5c70,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-2a6c56a8-823a-4d04-9854-7af9e5c13f63,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-64e9dac4-6aa8-4a43-96b3-50a972f6c4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33236,DS-92cecc8f-71bf-4f97-8fd6-ec5d023d4058,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-761718747-172.17.0.20-1595922851123:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35469,DS-f0bdd3cd-7b7d-437e-b194-c1ede2a7a5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41678,DS-0eb4d7de-b212-4395-95ef-99cb49c33503,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-83ae38e8-1a85-462a-b0a7-c89f867e7390,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-e6f11c11-8d45-4e80-804f-11f90ba9b04f,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-ee1eb4ef-8547-4e2b-bd52-aabcbe2dcc93,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-49c7399d-6f46-41c0-a0e3-ed34b49a5e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-eeca0e37-fe05-43e2-b648-11a298b1fc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-16b0dba6-653e-4983-a4bc-f79aeb7e7157,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-761718747-172.17.0.20-1595922851123:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35469,DS-f0bdd3cd-7b7d-437e-b194-c1ede2a7a5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41678,DS-0eb4d7de-b212-4395-95ef-99cb49c33503,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-83ae38e8-1a85-462a-b0a7-c89f867e7390,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-e6f11c11-8d45-4e80-804f-11f90ba9b04f,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-ee1eb4ef-8547-4e2b-bd52-aabcbe2dcc93,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-49c7399d-6f46-41c0-a0e3-ed34b49a5e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-eeca0e37-fe05-43e2-b648-11a298b1fc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-16b0dba6-653e-4983-a4bc-f79aeb7e7157,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008255486-172.17.0.20-1595923098556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33132,DS-a81c82b3-5390-4e85-be59-d9d1020d877d,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-6f8c9a26-8b65-4a79-bfe1-0f3e88ed4a86,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-4f36e264-57eb-4825-9e8d-a5694574696a,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-a15f1be3-4395-47e7-87ca-9e948b16e4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37074,DS-13015531-2344-46fd-a930-010461d75f88,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-7f71aa83-97a3-4873-beb6-2690a4f56ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:45790,DS-a25f429a-43a4-49e2-b2c3-bbd3b8b11c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-505f272c-2a0d-415a-a652-76cedb604cf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008255486-172.17.0.20-1595923098556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33132,DS-a81c82b3-5390-4e85-be59-d9d1020d877d,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-6f8c9a26-8b65-4a79-bfe1-0f3e88ed4a86,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-4f36e264-57eb-4825-9e8d-a5694574696a,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-a15f1be3-4395-47e7-87ca-9e948b16e4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37074,DS-13015531-2344-46fd-a930-010461d75f88,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-7f71aa83-97a3-4873-beb6-2690a4f56ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:45790,DS-a25f429a-43a4-49e2-b2c3-bbd3b8b11c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-505f272c-2a0d-415a-a652-76cedb604cf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1353230387-172.17.0.20-1595923426132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37709,DS-73aa0cf9-f8b6-4317-8c03-f1ec2da19c06,DISK], DatanodeInfoWithStorage[127.0.0.1:34921,DS-983ad1f0-57cf-4b96-979f-00bf02b02040,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-677d56fc-8f0e-491b-93a2-54b006338c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-74d846cc-ed87-47bf-9c02-734b029cc66a,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-dea0706f-76bf-459a-9436-454a93fcfdf5,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-017885b2-d0fc-42af-80de-bc9c6b0a7835,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-978a5e61-9f77-4a6f-a95a-a725f4b18923,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-b14c3841-d1f8-4096-b9f1-f5b6a5e1ed44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1353230387-172.17.0.20-1595923426132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37709,DS-73aa0cf9-f8b6-4317-8c03-f1ec2da19c06,DISK], DatanodeInfoWithStorage[127.0.0.1:34921,DS-983ad1f0-57cf-4b96-979f-00bf02b02040,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-677d56fc-8f0e-491b-93a2-54b006338c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-74d846cc-ed87-47bf-9c02-734b029cc66a,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-dea0706f-76bf-459a-9436-454a93fcfdf5,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-017885b2-d0fc-42af-80de-bc9c6b0a7835,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-978a5e61-9f77-4a6f-a95a-a725f4b18923,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-b14c3841-d1f8-4096-b9f1-f5b6a5e1ed44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1330731454-172.17.0.20-1595923586096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46813,DS-63e0eefc-0e23-479e-bb8f-8d01aa1a8b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-e61473ed-4fbd-4109-8bd3-da93581fa003,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-b6150f16-2ec3-4444-8510-42c42212b4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40376,DS-0972d692-4b71-43f7-9443-effd6186bb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38342,DS-303b3210-72c8-4082-877f-fad8abed7e21,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-023b577c-4db0-444c-98e6-52fb7831c36e,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-2fccbd89-74e7-486a-b4cf-6c048856274b,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-9752c3a7-5279-492f-945d-cc9b416e51fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1330731454-172.17.0.20-1595923586096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46813,DS-63e0eefc-0e23-479e-bb8f-8d01aa1a8b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-e61473ed-4fbd-4109-8bd3-da93581fa003,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-b6150f16-2ec3-4444-8510-42c42212b4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40376,DS-0972d692-4b71-43f7-9443-effd6186bb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38342,DS-303b3210-72c8-4082-877f-fad8abed7e21,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-023b577c-4db0-444c-98e6-52fb7831c36e,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-2fccbd89-74e7-486a-b4cf-6c048856274b,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-9752c3a7-5279-492f-945d-cc9b416e51fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1397787190-172.17.0.20-1595924015733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35683,DS-69909523-1b43-4159-8544-cbca3b2ba7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-c72a6903-615e-4bb5-aae1-b6619e969df8,DISK], DatanodeInfoWithStorage[127.0.0.1:37680,DS-60a66f93-1ffc-4912-838b-6b86e1721798,DISK], DatanodeInfoWithStorage[127.0.0.1:35553,DS-8b4560df-86f0-4d26-86fc-fa2c16f18f54,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-1012bf14-bb2b-436f-ac03-8c0c16ebb228,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-e3955c59-e4cd-4503-95b5-06d58bad1324,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-7b0e86a6-6746-48a2-9233-5724afb30be4,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-3c12db6e-9a70-4475-9c00-12a2f92f7c5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1397787190-172.17.0.20-1595924015733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35683,DS-69909523-1b43-4159-8544-cbca3b2ba7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-c72a6903-615e-4bb5-aae1-b6619e969df8,DISK], DatanodeInfoWithStorage[127.0.0.1:37680,DS-60a66f93-1ffc-4912-838b-6b86e1721798,DISK], DatanodeInfoWithStorage[127.0.0.1:35553,DS-8b4560df-86f0-4d26-86fc-fa2c16f18f54,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-1012bf14-bb2b-436f-ac03-8c0c16ebb228,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-e3955c59-e4cd-4503-95b5-06d58bad1324,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-7b0e86a6-6746-48a2-9233-5724afb30be4,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-3c12db6e-9a70-4475-9c00-12a2f92f7c5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-384012865-172.17.0.20-1595924350223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37657,DS-91f8e2f5-4da7-481d-9af6-89f13c793778,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-ead61df7-26c7-4e10-a598-231edadad2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37304,DS-2679d401-c04a-489d-ae9b-091cc9e41b05,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-c1484841-ee7e-4b30-8350-5bb2e0528c27,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-eedd17b1-1a3a-464b-84d8-4a0bc78344c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-e06381ac-0466-497e-b819-66183c921443,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-3d941bb2-c7ee-429b-9583-b04f11702f07,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-e21cdfd3-dcf7-4e9e-8f1e-611b2bf1d6a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-384012865-172.17.0.20-1595924350223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37657,DS-91f8e2f5-4da7-481d-9af6-89f13c793778,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-ead61df7-26c7-4e10-a598-231edadad2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37304,DS-2679d401-c04a-489d-ae9b-091cc9e41b05,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-c1484841-ee7e-4b30-8350-5bb2e0528c27,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-eedd17b1-1a3a-464b-84d8-4a0bc78344c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-e06381ac-0466-497e-b819-66183c921443,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-3d941bb2-c7ee-429b-9583-b04f11702f07,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-e21cdfd3-dcf7-4e9e-8f1e-611b2bf1d6a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1279100353-172.17.0.20-1595924995114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38520,DS-39253f22-cd95-42a4-83f6-cc42f1537f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-6a0cbc41-9465-4e04-bd50-e5532d24745f,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-420467ce-1094-4dfc-856b-a93a71564b33,DISK], DatanodeInfoWithStorage[127.0.0.1:43125,DS-c4c31afc-8483-407f-8fdb-aea7d8466b10,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-a3c29b75-5e2e-4443-a76a-69354851f5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45688,DS-1bf4116c-ea74-4e48-b128-900b7b75eb26,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-00c576d7-0d5b-44dc-b1a6-29b3e327000c,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-a10a59d8-9455-43f0-9fa2-a8b43884ed90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1279100353-172.17.0.20-1595924995114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38520,DS-39253f22-cd95-42a4-83f6-cc42f1537f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-6a0cbc41-9465-4e04-bd50-e5532d24745f,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-420467ce-1094-4dfc-856b-a93a71564b33,DISK], DatanodeInfoWithStorage[127.0.0.1:43125,DS-c4c31afc-8483-407f-8fdb-aea7d8466b10,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-a3c29b75-5e2e-4443-a76a-69354851f5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45688,DS-1bf4116c-ea74-4e48-b128-900b7b75eb26,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-00c576d7-0d5b-44dc-b1a6-29b3e327000c,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-a10a59d8-9455-43f0-9fa2-a8b43884ed90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1354862729-172.17.0.20-1595925589463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38477,DS-7c45732e-d5ae-489f-ae1c-cc24c6e6094a,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-59385687-d546-416a-aa9d-d534e6624172,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-49913c90-64bc-4b77-a740-39f927775442,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-1872f766-c64c-4b67-97c0-7eede848a675,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-c090cd27-cb1f-48d4-926d-867670fca54d,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-e0ab5552-7ae3-40bf-b884-7dadfca0de46,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-a1fc3fb0-2533-4107-abea-61c09d16df13,DISK], DatanodeInfoWithStorage[127.0.0.1:33555,DS-50982089-e30a-4ee1-9c62-cd026e49c51d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1354862729-172.17.0.20-1595925589463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38477,DS-7c45732e-d5ae-489f-ae1c-cc24c6e6094a,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-59385687-d546-416a-aa9d-d534e6624172,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-49913c90-64bc-4b77-a740-39f927775442,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-1872f766-c64c-4b67-97c0-7eede848a675,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-c090cd27-cb1f-48d4-926d-867670fca54d,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-e0ab5552-7ae3-40bf-b884-7dadfca0de46,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-a1fc3fb0-2533-4107-abea-61c09d16df13,DISK], DatanodeInfoWithStorage[127.0.0.1:33555,DS-50982089-e30a-4ee1-9c62-cd026e49c51d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1426313710-172.17.0.20-1595925921483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45233,DS-69653835-3bc9-4846-847b-f2ddd7e54534,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-e4e65d06-bfb7-4b25-b7dc-c07bb8e987f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-fc3964ed-d27d-4955-a2ed-7c625eee5581,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-c7d0e61a-9fa1-4bec-814d-6285b699174f,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-e3f91116-b801-4119-b663-d8ba891a9ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-59383ebe-16a1-4216-a24c-552c9a9fa00a,DISK], DatanodeInfoWithStorage[127.0.0.1:34453,DS-02c0ab3d-34d2-4c2f-b32e-65337fab52ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-cfacd448-be7c-407a-acbc-076c33940e30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1426313710-172.17.0.20-1595925921483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45233,DS-69653835-3bc9-4846-847b-f2ddd7e54534,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-e4e65d06-bfb7-4b25-b7dc-c07bb8e987f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-fc3964ed-d27d-4955-a2ed-7c625eee5581,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-c7d0e61a-9fa1-4bec-814d-6285b699174f,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-e3f91116-b801-4119-b663-d8ba891a9ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-59383ebe-16a1-4216-a24c-552c9a9fa00a,DISK], DatanodeInfoWithStorage[127.0.0.1:34453,DS-02c0ab3d-34d2-4c2f-b32e-65337fab52ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-cfacd448-be7c-407a-acbc-076c33940e30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-663540031-172.17.0.20-1595926072907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46570,DS-ce7f8c23-93d2-4564-b482-16debaf103de,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-2b8f2dad-ec62-4176-bbef-47fd4967943f,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-86381b41-4d98-48b4-ba55-931f47df286e,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-7c0d31d5-e731-477d-be1d-bb4fb67e4e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-165cb306-9173-408d-96eb-a6703c99cdf0,DISK], DatanodeInfoWithStorage[127.0.0.1:45577,DS-61c98929-6d98-40bd-8b19-e243c5d35a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-f1e848f7-5956-48bb-9ad6-355549087b21,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-b41fc6ac-83c9-42ac-8312-a07b6cfa9c18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-663540031-172.17.0.20-1595926072907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46570,DS-ce7f8c23-93d2-4564-b482-16debaf103de,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-2b8f2dad-ec62-4176-bbef-47fd4967943f,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-86381b41-4d98-48b4-ba55-931f47df286e,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-7c0d31d5-e731-477d-be1d-bb4fb67e4e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-165cb306-9173-408d-96eb-a6703c99cdf0,DISK], DatanodeInfoWithStorage[127.0.0.1:45577,DS-61c98929-6d98-40bd-8b19-e243c5d35a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-f1e848f7-5956-48bb-9ad6-355549087b21,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-b41fc6ac-83c9-42ac-8312-a07b6cfa9c18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-499838252-172.17.0.20-1595926108136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43314,DS-0c82b0dc-b384-45f3-8b2c-53f3ca0c969e,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-92220cef-462c-4bda-920c-aa0ec8ae0eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44364,DS-7c087fec-f699-4bc2-ab27-591ff33f7347,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-18c91a26-3116-4917-a885-018770340ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-a11d7955-0f46-404a-a993-46412eee8cde,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-f9a8298f-1508-4ba6-8a64-5513b9c3b41a,DISK], DatanodeInfoWithStorage[127.0.0.1:36047,DS-68642659-c35d-4859-b20a-ff37f3fd7745,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-17d64d7f-7e89-4a76-a121-90a11c03257e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-499838252-172.17.0.20-1595926108136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43314,DS-0c82b0dc-b384-45f3-8b2c-53f3ca0c969e,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-92220cef-462c-4bda-920c-aa0ec8ae0eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44364,DS-7c087fec-f699-4bc2-ab27-591ff33f7347,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-18c91a26-3116-4917-a885-018770340ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-a11d7955-0f46-404a-a993-46412eee8cde,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-f9a8298f-1508-4ba6-8a64-5513b9c3b41a,DISK], DatanodeInfoWithStorage[127.0.0.1:36047,DS-68642659-c35d-4859-b20a-ff37f3fd7745,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-17d64d7f-7e89-4a76-a121-90a11c03257e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-244970636-172.17.0.20-1595926146407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43546,DS-3f9aab1b-6a7a-470b-8023-06ac1d38d720,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-3c8cfb09-ddd8-4275-b694-1fc194cc05b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-82e31e15-678d-4908-8439-df365de69a92,DISK], DatanodeInfoWithStorage[127.0.0.1:35440,DS-0fd6cbf6-6871-4981-981c-4918cfaa1212,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-8fc9b4f2-73b1-49cb-b529-fb43a17cba7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-ee544a8c-87cd-45aa-8aaa-3fe61557c9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-09c69867-907a-4d85-962e-336f2604c584,DISK], DatanodeInfoWithStorage[127.0.0.1:37285,DS-83846050-c86e-4501-8d5a-1ad327d6974d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-244970636-172.17.0.20-1595926146407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43546,DS-3f9aab1b-6a7a-470b-8023-06ac1d38d720,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-3c8cfb09-ddd8-4275-b694-1fc194cc05b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-82e31e15-678d-4908-8439-df365de69a92,DISK], DatanodeInfoWithStorage[127.0.0.1:35440,DS-0fd6cbf6-6871-4981-981c-4918cfaa1212,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-8fc9b4f2-73b1-49cb-b529-fb43a17cba7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-ee544a8c-87cd-45aa-8aaa-3fe61557c9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-09c69867-907a-4d85-962e-336f2604c584,DISK], DatanodeInfoWithStorage[127.0.0.1:37285,DS-83846050-c86e-4501-8d5a-1ad327d6974d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1111136023-172.17.0.20-1595926548328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38780,DS-1e389999-bea6-4086-8772-e46812b2467f,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-3b20179c-079a-431c-845c-06ea6a143d50,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-95741078-4b86-47d7-b618-fb4c2180d0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-fcccbf83-952d-4846-915b-3e25210174dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-14ff5ec3-1f9c-49a7-b541-cb697cb6eb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-0a29afb9-1666-4ed9-b0c1-eb4188d40dac,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-be8dbd55-0066-4177-bd46-1cdae85e88a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-9e27cb57-d6bc-444d-8948-747465a315bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1111136023-172.17.0.20-1595926548328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38780,DS-1e389999-bea6-4086-8772-e46812b2467f,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-3b20179c-079a-431c-845c-06ea6a143d50,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-95741078-4b86-47d7-b618-fb4c2180d0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-fcccbf83-952d-4846-915b-3e25210174dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-14ff5ec3-1f9c-49a7-b541-cb697cb6eb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-0a29afb9-1666-4ed9-b0c1-eb4188d40dac,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-be8dbd55-0066-4177-bd46-1cdae85e88a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-9e27cb57-d6bc-444d-8948-747465a315bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1305084473-172.17.0.20-1595927288153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41610,DS-e9b9d9a1-e6ca-47b6-aa7f-898f949e355e,DISK], DatanodeInfoWithStorage[127.0.0.1:39322,DS-e4c7d708-b091-4427-92ea-cc150c373454,DISK], DatanodeInfoWithStorage[127.0.0.1:43837,DS-8ab57ba9-f499-4eb8-bb58-109c6840a5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-0dc573e1-2dc4-4ffd-8eb3-bc305d66037e,DISK], DatanodeInfoWithStorage[127.0.0.1:40607,DS-674c296a-d50f-4da6-bcfb-c96fcd6dbf4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-7a60453b-563b-44f1-9c82-e87d4e450c54,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-6f789754-9f80-4f37-9da2-5dbd3e5ab484,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-87534d8c-0ba5-4f69-b0d1-e7df759854c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1305084473-172.17.0.20-1595927288153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41610,DS-e9b9d9a1-e6ca-47b6-aa7f-898f949e355e,DISK], DatanodeInfoWithStorage[127.0.0.1:39322,DS-e4c7d708-b091-4427-92ea-cc150c373454,DISK], DatanodeInfoWithStorage[127.0.0.1:43837,DS-8ab57ba9-f499-4eb8-bb58-109c6840a5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-0dc573e1-2dc4-4ffd-8eb3-bc305d66037e,DISK], DatanodeInfoWithStorage[127.0.0.1:40607,DS-674c296a-d50f-4da6-bcfb-c96fcd6dbf4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-7a60453b-563b-44f1-9c82-e87d4e450c54,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-6f789754-9f80-4f37-9da2-5dbd3e5ab484,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-87534d8c-0ba5-4f69-b0d1-e7df759854c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1134774750-172.17.0.20-1595927559654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44502,DS-d57bcef9-fdb5-4a22-a680-2ffb3d8ed595,DISK], DatanodeInfoWithStorage[127.0.0.1:40000,DS-4cbb8caf-4437-40ff-8bc8-92b3405aa99f,DISK], DatanodeInfoWithStorage[127.0.0.1:40290,DS-8242bb97-edbe-49af-a602-775ca981a747,DISK], DatanodeInfoWithStorage[127.0.0.1:43641,DS-5ab662ea-944c-4a5b-8801-4408ab8463a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-61f5e15b-ffcd-4bc0-af35-41e549562992,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-51626d3b-df00-47c1-ae04-57c0e6fd0a53,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-75982c00-07ca-4f46-ac59-ab2adf65718b,DISK], DatanodeInfoWithStorage[127.0.0.1:38266,DS-ded5e0f7-de94-470a-8015-2d13ca7c9b0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1134774750-172.17.0.20-1595927559654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44502,DS-d57bcef9-fdb5-4a22-a680-2ffb3d8ed595,DISK], DatanodeInfoWithStorage[127.0.0.1:40000,DS-4cbb8caf-4437-40ff-8bc8-92b3405aa99f,DISK], DatanodeInfoWithStorage[127.0.0.1:40290,DS-8242bb97-edbe-49af-a602-775ca981a747,DISK], DatanodeInfoWithStorage[127.0.0.1:43641,DS-5ab662ea-944c-4a5b-8801-4408ab8463a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-61f5e15b-ffcd-4bc0-af35-41e549562992,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-51626d3b-df00-47c1-ae04-57c0e6fd0a53,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-75982c00-07ca-4f46-ac59-ab2adf65718b,DISK], DatanodeInfoWithStorage[127.0.0.1:38266,DS-ded5e0f7-de94-470a-8015-2d13ca7c9b0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5562
