reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-354740813-172.17.0.16-1595638682517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41236,DS-a80e1ea5-d6cf-465d-b5c2-edcc6c4ab18f,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-976d8fa2-2657-426e-bedc-067b82b397c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-f6a3460e-b744-40a3-bbe3-0c8b68dd21bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-4a387191-502f-48d9-8aba-401b637bdfd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-6bd1a069-84a0-4eaf-9c06-e29e891918bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-95e0ad8b-e1b0-49a2-8701-62c19367122b,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-eb0fe04a-8f91-4006-b6ce-60ad84e6f9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-ed004af7-c981-4c71-bd25-9f4a2e353807,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-354740813-172.17.0.16-1595638682517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41236,DS-a80e1ea5-d6cf-465d-b5c2-edcc6c4ab18f,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-976d8fa2-2657-426e-bedc-067b82b397c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-f6a3460e-b744-40a3-bbe3-0c8b68dd21bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-4a387191-502f-48d9-8aba-401b637bdfd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-6bd1a069-84a0-4eaf-9c06-e29e891918bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-95e0ad8b-e1b0-49a2-8701-62c19367122b,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-eb0fe04a-8f91-4006-b6ce-60ad84e6f9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-ed004af7-c981-4c71-bd25-9f4a2e353807,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1252179884-172.17.0.16-1595638754773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45810,DS-b73a350e-fff7-4b1c-bb69-fde12405df8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-f6028f74-6b6f-482a-85ce-b2e22ed93b21,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-6901658f-8cf4-4485-acf9-abe74b2c8cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35379,DS-a95b09fe-b1ae-42ea-892d-62e67d93fe87,DISK], DatanodeInfoWithStorage[127.0.0.1:44909,DS-076bce86-cf8e-4bab-9dc8-02eedff62c45,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-f3acfba8-288c-4ab5-8019-4152b350a880,DISK], DatanodeInfoWithStorage[127.0.0.1:40181,DS-593c9449-f515-4c4b-a8cf-473840773802,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-d385c058-13ad-49f2-ace9-1aaff751aace,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1252179884-172.17.0.16-1595638754773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45810,DS-b73a350e-fff7-4b1c-bb69-fde12405df8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-f6028f74-6b6f-482a-85ce-b2e22ed93b21,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-6901658f-8cf4-4485-acf9-abe74b2c8cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35379,DS-a95b09fe-b1ae-42ea-892d-62e67d93fe87,DISK], DatanodeInfoWithStorage[127.0.0.1:44909,DS-076bce86-cf8e-4bab-9dc8-02eedff62c45,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-f3acfba8-288c-4ab5-8019-4152b350a880,DISK], DatanodeInfoWithStorage[127.0.0.1:40181,DS-593c9449-f515-4c4b-a8cf-473840773802,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-d385c058-13ad-49f2-ace9-1aaff751aace,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-515167994-172.17.0.16-1595639058382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40526,DS-e80d44ee-098a-48d4-93d6-f59af75973b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41392,DS-ae5a5dfe-fb96-4e7f-a3e9-44ec19b3e81d,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-059ce815-6943-4d55-8213-255deb60afe2,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-f84dfa32-a690-4640-8fb6-13216323aea2,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-ea170bb8-caeb-4e50-b458-07a56b379a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-66e5f24b-4e33-48f8-9256-655aa0f7d4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-10d739ee-1bd2-4dfc-955f-1ad2adc0e957,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-7dc4294b-1412-4fa1-9132-86554571025f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-515167994-172.17.0.16-1595639058382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40526,DS-e80d44ee-098a-48d4-93d6-f59af75973b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41392,DS-ae5a5dfe-fb96-4e7f-a3e9-44ec19b3e81d,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-059ce815-6943-4d55-8213-255deb60afe2,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-f84dfa32-a690-4640-8fb6-13216323aea2,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-ea170bb8-caeb-4e50-b458-07a56b379a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-66e5f24b-4e33-48f8-9256-655aa0f7d4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-10d739ee-1bd2-4dfc-955f-1ad2adc0e957,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-7dc4294b-1412-4fa1-9132-86554571025f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1481344328-172.17.0.16-1595639668844:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44237,DS-ce411c73-412e-402d-85e9-803616e2dae1,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-7afceba6-b610-4a65-9e62-4fe6b77b53c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-9c8282d3-ff0c-4a8b-8951-e0a891c14f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42318,DS-97d9a081-8793-47c0-b7de-82fdc47dbfe2,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-29c4959b-3b48-4aaa-afc8-60e94859c8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-5b5401c5-71e0-4b94-9927-ee0c8c4a0562,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-d7efb5a2-2146-47c3-9c1d-f6187e3f7853,DISK], DatanodeInfoWithStorage[127.0.0.1:43025,DS-d8723e80-30aa-4ed5-8ac6-a10df5fa960f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1481344328-172.17.0.16-1595639668844:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44237,DS-ce411c73-412e-402d-85e9-803616e2dae1,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-7afceba6-b610-4a65-9e62-4fe6b77b53c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-9c8282d3-ff0c-4a8b-8951-e0a891c14f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42318,DS-97d9a081-8793-47c0-b7de-82fdc47dbfe2,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-29c4959b-3b48-4aaa-afc8-60e94859c8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-5b5401c5-71e0-4b94-9927-ee0c8c4a0562,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-d7efb5a2-2146-47c3-9c1d-f6187e3f7853,DISK], DatanodeInfoWithStorage[127.0.0.1:43025,DS-d8723e80-30aa-4ed5-8ac6-a10df5fa960f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-519575351-172.17.0.16-1595640605667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40152,DS-9028e20b-f817-489b-b6ed-97b72134f357,DISK], DatanodeInfoWithStorage[127.0.0.1:36936,DS-c2eed46c-e9eb-4fa3-9615-991883cfd8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-22226709-6d88-430a-b150-bd7e87ba593a,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-c8d15721-1f42-4984-9f7c-a3ec0dbfccc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-a9e89b07-129b-4535-8fb9-1a9d4e2468ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-0dc95d24-b846-4e4f-8e0d-6e216aeef463,DISK], DatanodeInfoWithStorage[127.0.0.1:36809,DS-fcd218f6-8c0a-4f65-99f9-680df6cd7afd,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-09e8a1ec-6b58-474c-ace5-b598c579aef8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-519575351-172.17.0.16-1595640605667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40152,DS-9028e20b-f817-489b-b6ed-97b72134f357,DISK], DatanodeInfoWithStorage[127.0.0.1:36936,DS-c2eed46c-e9eb-4fa3-9615-991883cfd8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-22226709-6d88-430a-b150-bd7e87ba593a,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-c8d15721-1f42-4984-9f7c-a3ec0dbfccc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-a9e89b07-129b-4535-8fb9-1a9d4e2468ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-0dc95d24-b846-4e4f-8e0d-6e216aeef463,DISK], DatanodeInfoWithStorage[127.0.0.1:36809,DS-fcd218f6-8c0a-4f65-99f9-680df6cd7afd,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-09e8a1ec-6b58-474c-ace5-b598c579aef8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-3049337-172.17.0.16-1595640977763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43111,DS-5d75d7d1-c93e-4ee9-a286-86c11c15af2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-ce767848-af05-4a25-8842-bfb1c2330539,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-c4c3aa2c-7a09-4f28-9159-3f625499f258,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-f7486a1f-1c50-4674-b770-08c278f7fcfb,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-1b747337-e979-4b22-96a4-12de9d092d10,DISK], DatanodeInfoWithStorage[127.0.0.1:41779,DS-c23e1d58-285e-4275-aa21-39775f8e60e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-7c8409b1-040e-4133-b123-b8e662e1a9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-60f4030d-234a-4aa4-896a-a5e2b2d392f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-3049337-172.17.0.16-1595640977763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43111,DS-5d75d7d1-c93e-4ee9-a286-86c11c15af2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-ce767848-af05-4a25-8842-bfb1c2330539,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-c4c3aa2c-7a09-4f28-9159-3f625499f258,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-f7486a1f-1c50-4674-b770-08c278f7fcfb,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-1b747337-e979-4b22-96a4-12de9d092d10,DISK], DatanodeInfoWithStorage[127.0.0.1:41779,DS-c23e1d58-285e-4275-aa21-39775f8e60e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-7c8409b1-040e-4133-b123-b8e662e1a9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-60f4030d-234a-4aa4-896a-a5e2b2d392f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-671280323-172.17.0.16-1595641054944:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34631,DS-20b79740-3b5a-4437-a0fd-ffea689dfbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-89d4051b-4f0f-4875-872b-d168fbc8b645,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-6d1f5ca6-7924-4c58-bcee-325e2272c854,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-bfda322f-b07a-44ec-a8c6-ac071f4091d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-6a96a968-aaf9-41ee-b1f0-cdd9d483f05d,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-8d1f0ecb-9450-4828-9e4f-01b3ffb5994c,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-31b21333-aa0e-4f67-ad92-e2143a6d4f22,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-407ca7ff-8a13-4f87-8584-3dfdbe537a28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-671280323-172.17.0.16-1595641054944:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34631,DS-20b79740-3b5a-4437-a0fd-ffea689dfbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-89d4051b-4f0f-4875-872b-d168fbc8b645,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-6d1f5ca6-7924-4c58-bcee-325e2272c854,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-bfda322f-b07a-44ec-a8c6-ac071f4091d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-6a96a968-aaf9-41ee-b1f0-cdd9d483f05d,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-8d1f0ecb-9450-4828-9e4f-01b3ffb5994c,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-31b21333-aa0e-4f67-ad92-e2143a6d4f22,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-407ca7ff-8a13-4f87-8584-3dfdbe537a28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-348598911-172.17.0.16-1595641140291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37626,DS-cd2eaf1d-398b-452d-9975-ca433a2d73c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-d2c6ff27-d5b8-44f3-81a1-47f5b235a19e,DISK], DatanodeInfoWithStorage[127.0.0.1:34496,DS-8ef4140b-17f6-4778-8653-dfb58d56ed13,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-b7db48da-a5d0-456f-be4a-308fa841b03f,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-9be84adf-2fdd-455b-8c97-1bd6973f297d,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-10e5f3be-d022-4d2e-a1aa-e359a45050a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-3f24360b-7811-49cc-ae8b-da14e2be2fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-c14368de-e954-45a3-912d-26960cf0e553,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-348598911-172.17.0.16-1595641140291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37626,DS-cd2eaf1d-398b-452d-9975-ca433a2d73c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-d2c6ff27-d5b8-44f3-81a1-47f5b235a19e,DISK], DatanodeInfoWithStorage[127.0.0.1:34496,DS-8ef4140b-17f6-4778-8653-dfb58d56ed13,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-b7db48da-a5d0-456f-be4a-308fa841b03f,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-9be84adf-2fdd-455b-8c97-1bd6973f297d,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-10e5f3be-d022-4d2e-a1aa-e359a45050a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-3f24360b-7811-49cc-ae8b-da14e2be2fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-c14368de-e954-45a3-912d-26960cf0e553,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1204814880-172.17.0.16-1595641180827:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36592,DS-5ad91fa8-3d3d-4de6-afbf-34e23b40bc60,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-b446898f-4c85-4fcf-b3ca-1f32bcb20a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-8b7d2994-b74c-4122-93db-3f220d2a3d05,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-ecb7f696-86d7-4f44-9c7c-e8bbdaad9c58,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-6611770e-65da-42aa-8566-3fe50e033f50,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-a912f8cd-1200-4bea-94ff-483c5ca081fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-8928387e-e9eb-4075-8eee-3dc210303a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42375,DS-4bb0a31e-b302-453e-9277-944eec4a0a28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1204814880-172.17.0.16-1595641180827:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36592,DS-5ad91fa8-3d3d-4de6-afbf-34e23b40bc60,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-b446898f-4c85-4fcf-b3ca-1f32bcb20a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-8b7d2994-b74c-4122-93db-3f220d2a3d05,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-ecb7f696-86d7-4f44-9c7c-e8bbdaad9c58,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-6611770e-65da-42aa-8566-3fe50e033f50,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-a912f8cd-1200-4bea-94ff-483c5ca081fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-8928387e-e9eb-4075-8eee-3dc210303a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42375,DS-4bb0a31e-b302-453e-9277-944eec4a0a28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1467859121-172.17.0.16-1595641413954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41903,DS-3af489e4-6761-4c9a-8847-8b1fd2f0b9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-dcf8f97e-a775-4352-85a7-1b162636dcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-cb631f13-2136-41ca-9726-36be8e99996b,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-2774ce9e-c846-4d45-aac7-0b4957263163,DISK], DatanodeInfoWithStorage[127.0.0.1:34282,DS-81ecaa5c-0ad9-48ea-be55-e22be9ffb6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33345,DS-552ca23d-970c-4102-8feb-820aa92b3d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-b0fbe1b2-c679-4aa5-9a59-4be1f3832150,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-256e06f2-cffd-4e77-aa69-a88a47998f8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1467859121-172.17.0.16-1595641413954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41903,DS-3af489e4-6761-4c9a-8847-8b1fd2f0b9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-dcf8f97e-a775-4352-85a7-1b162636dcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-cb631f13-2136-41ca-9726-36be8e99996b,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-2774ce9e-c846-4d45-aac7-0b4957263163,DISK], DatanodeInfoWithStorage[127.0.0.1:34282,DS-81ecaa5c-0ad9-48ea-be55-e22be9ffb6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33345,DS-552ca23d-970c-4102-8feb-820aa92b3d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-b0fbe1b2-c679-4aa5-9a59-4be1f3832150,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-256e06f2-cffd-4e77-aa69-a88a47998f8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1923680817-172.17.0.16-1595641489943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41922,DS-0c8e4708-eff2-494c-a92f-e9aaaded4b45,DISK], DatanodeInfoWithStorage[127.0.0.1:38781,DS-a385c972-804f-4986-be93-eba8ca2ecd62,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-5ef7f996-67df-4c2c-ac0c-a4dc2729872f,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-beeee80f-106e-4045-9d79-cdb2edf03b76,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-22b160a8-e16c-47eb-8e9e-3def72bc2ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-5df3c866-0c33-426a-9a53-47ea2c2b23e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-bf45321e-a826-4a60-8d54-5e2b5a81d76d,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-682dc6e5-8862-4f2c-b1e8-a0e08ac84b4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1923680817-172.17.0.16-1595641489943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41922,DS-0c8e4708-eff2-494c-a92f-e9aaaded4b45,DISK], DatanodeInfoWithStorage[127.0.0.1:38781,DS-a385c972-804f-4986-be93-eba8ca2ecd62,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-5ef7f996-67df-4c2c-ac0c-a4dc2729872f,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-beeee80f-106e-4045-9d79-cdb2edf03b76,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-22b160a8-e16c-47eb-8e9e-3def72bc2ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-5df3c866-0c33-426a-9a53-47ea2c2b23e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-bf45321e-a826-4a60-8d54-5e2b5a81d76d,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-682dc6e5-8862-4f2c-b1e8-a0e08ac84b4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1345316423-172.17.0.16-1595641701658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43867,DS-ef364794-00af-40d4-a98a-524b3dca0e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-b9e31769-1ee0-43a3-8c1c-af703f16135e,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-c357b2ee-0642-45f8-a257-8099f67ad4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-b028ea70-e3bd-47db-936d-8430e6ef0c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-e58d71c9-17f5-4921-a9c2-1bd8dd2a379d,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-975d4571-2130-4581-87d9-a9074147448b,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-35815e07-7719-4317-8b7c-d1b3d268bde2,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-c6bb2934-f1b0-4942-bfb5-9077c1e96c22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1345316423-172.17.0.16-1595641701658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43867,DS-ef364794-00af-40d4-a98a-524b3dca0e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-b9e31769-1ee0-43a3-8c1c-af703f16135e,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-c357b2ee-0642-45f8-a257-8099f67ad4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-b028ea70-e3bd-47db-936d-8430e6ef0c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-e58d71c9-17f5-4921-a9c2-1bd8dd2a379d,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-975d4571-2130-4581-87d9-a9074147448b,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-35815e07-7719-4317-8b7c-d1b3d268bde2,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-c6bb2934-f1b0-4942-bfb5-9077c1e96c22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1664913996-172.17.0.16-1595642014971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40609,DS-77509b59-41c7-4a92-9907-7189defde0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-80fdb626-a60b-4eaa-b3ff-387559ad57a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42705,DS-7e191839-ad52-4dc6-a213-12879e3c441e,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-0954298a-2fc7-4697-8837-9acb220e9e80,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-ae721e66-5e47-4bbb-817b-3a6fe3fd8c10,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-f0c12470-e5b7-4ba2-998f-a54bc8e1e33c,DISK], DatanodeInfoWithStorage[127.0.0.1:39562,DS-bc08a53c-b2bb-47fb-9224-e2c08b511913,DISK], DatanodeInfoWithStorage[127.0.0.1:42189,DS-58c34e29-2ea2-41a7-a3fd-8ceed191b48a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1664913996-172.17.0.16-1595642014971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40609,DS-77509b59-41c7-4a92-9907-7189defde0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-80fdb626-a60b-4eaa-b3ff-387559ad57a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42705,DS-7e191839-ad52-4dc6-a213-12879e3c441e,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-0954298a-2fc7-4697-8837-9acb220e9e80,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-ae721e66-5e47-4bbb-817b-3a6fe3fd8c10,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-f0c12470-e5b7-4ba2-998f-a54bc8e1e33c,DISK], DatanodeInfoWithStorage[127.0.0.1:39562,DS-bc08a53c-b2bb-47fb-9224-e2c08b511913,DISK], DatanodeInfoWithStorage[127.0.0.1:42189,DS-58c34e29-2ea2-41a7-a3fd-8ceed191b48a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2095877431-172.17.0.16-1595642641894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40800,DS-144583b2-bb16-4fe0-9ba5-575fd096df41,DISK], DatanodeInfoWithStorage[127.0.0.1:38160,DS-1b510de4-5edd-4568-b293-e9a043bc3dab,DISK], DatanodeInfoWithStorage[127.0.0.1:43783,DS-d8992d86-c013-432c-aaca-3ff3a2d93277,DISK], DatanodeInfoWithStorage[127.0.0.1:43723,DS-4353a28d-7134-4156-9505-f43eb8376406,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-be99d89d-43ff-4750-97f6-a1d2f67b6b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41942,DS-a1970877-e08d-45b7-b464-6b51a4ede0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-b707c58c-54c8-4bff-89d7-ec6684efaadf,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-bc836dbf-893f-45db-883b-e8b1f80a0b79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2095877431-172.17.0.16-1595642641894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40800,DS-144583b2-bb16-4fe0-9ba5-575fd096df41,DISK], DatanodeInfoWithStorage[127.0.0.1:38160,DS-1b510de4-5edd-4568-b293-e9a043bc3dab,DISK], DatanodeInfoWithStorage[127.0.0.1:43783,DS-d8992d86-c013-432c-aaca-3ff3a2d93277,DISK], DatanodeInfoWithStorage[127.0.0.1:43723,DS-4353a28d-7134-4156-9505-f43eb8376406,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-be99d89d-43ff-4750-97f6-a1d2f67b6b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41942,DS-a1970877-e08d-45b7-b464-6b51a4ede0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-b707c58c-54c8-4bff-89d7-ec6684efaadf,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-bc836dbf-893f-45db-883b-e8b1f80a0b79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-892293561-172.17.0.16-1595642720687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46283,DS-f08f14e7-ccda-488b-8639-0864df66704d,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-b8622e34-7dce-4510-8adf-c4716be47359,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-a4938eb9-7568-45a7-9f0d-9a4b4e6a3321,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-f75c5998-d047-4c6e-b85f-e6567b8df8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-eaaf9d73-31a4-4e57-9b1d-eef6da7d7b17,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-d43beef0-6648-41d7-80d6-53350d518bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-d1269f91-476f-4bd1-a6e4-c170211b6481,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-4ba00d25-77a5-4d66-8889-c01b1af688d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-892293561-172.17.0.16-1595642720687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46283,DS-f08f14e7-ccda-488b-8639-0864df66704d,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-b8622e34-7dce-4510-8adf-c4716be47359,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-a4938eb9-7568-45a7-9f0d-9a4b4e6a3321,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-f75c5998-d047-4c6e-b85f-e6567b8df8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-eaaf9d73-31a4-4e57-9b1d-eef6da7d7b17,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-d43beef0-6648-41d7-80d6-53350d518bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-d1269f91-476f-4bd1-a6e4-c170211b6481,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-4ba00d25-77a5-4d66-8889-c01b1af688d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-814032814-172.17.0.16-1595643060549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41158,DS-e2d776f8-cd51-41c2-b79f-a63474d300ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38330,DS-4f0c2e73-3afb-4f6f-89d5-c6e62bbdc56f,DISK], DatanodeInfoWithStorage[127.0.0.1:42313,DS-59bdc09f-5147-4354-9196-53e537e8caec,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-0e070e7a-52dd-4165-ab8c-a29843ca8c18,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-cdaeeaa9-1136-47fd-a72a-977322c5aa98,DISK], DatanodeInfoWithStorage[127.0.0.1:34051,DS-2994dde5-3a13-41dd-a626-571d81b3acbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-fc037b59-1eeb-4741-8cc1-10f56347c9be,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-ebc40055-3379-4195-a05f-103462c1ec0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-814032814-172.17.0.16-1595643060549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41158,DS-e2d776f8-cd51-41c2-b79f-a63474d300ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38330,DS-4f0c2e73-3afb-4f6f-89d5-c6e62bbdc56f,DISK], DatanodeInfoWithStorage[127.0.0.1:42313,DS-59bdc09f-5147-4354-9196-53e537e8caec,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-0e070e7a-52dd-4165-ab8c-a29843ca8c18,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-cdaeeaa9-1136-47fd-a72a-977322c5aa98,DISK], DatanodeInfoWithStorage[127.0.0.1:34051,DS-2994dde5-3a13-41dd-a626-571d81b3acbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-fc037b59-1eeb-4741-8cc1-10f56347c9be,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-ebc40055-3379-4195-a05f-103462c1ec0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700182576-172.17.0.16-1595644086056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37332,DS-7dfe6966-70c0-415a-8174-78c35e6b6c78,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-b34a68a0-fbf5-4641-b77e-6ac703a3425d,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-7f0135aa-ac33-4171-93f3-2afe4a25bf70,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-836c2a4a-b823-4bca-8acf-1d8e6f945ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-23b93187-89d8-41aa-89be-79941e6f16b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-a45be10b-664d-4405-abc0-02f8c7345112,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-7bbb748e-d36a-490a-8d5c-799725ef6b08,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-6a218db6-b252-413d-8351-657cfbb75d67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700182576-172.17.0.16-1595644086056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37332,DS-7dfe6966-70c0-415a-8174-78c35e6b6c78,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-b34a68a0-fbf5-4641-b77e-6ac703a3425d,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-7f0135aa-ac33-4171-93f3-2afe4a25bf70,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-836c2a4a-b823-4bca-8acf-1d8e6f945ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-23b93187-89d8-41aa-89be-79941e6f16b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-a45be10b-664d-4405-abc0-02f8c7345112,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-7bbb748e-d36a-490a-8d5c-799725ef6b08,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-6a218db6-b252-413d-8351-657cfbb75d67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5839
