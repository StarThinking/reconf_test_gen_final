reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-694237446-172.17.0.17-1595573590526:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34897,DS-ed198848-5d61-4d11-a552-a167a4320d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-5d29b6c2-05b8-439b-b5d4-afa70fcea5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33364,DS-4948a862-3e8a-4087-863d-0f206b45ae18,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-4fdf86d1-005f-4d90-a69a-d3b2ad0858b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-e4dddae3-ba15-470c-94fd-a7e76d78d1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-a88d3daa-0956-4e59-bea2-80c084761b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-183e8b80-ed20-4882-8e8a-ded91c4f1326,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-fd4b61f9-e885-4796-a641-58072db9ef21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-694237446-172.17.0.17-1595573590526:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34897,DS-ed198848-5d61-4d11-a552-a167a4320d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-5d29b6c2-05b8-439b-b5d4-afa70fcea5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33364,DS-4948a862-3e8a-4087-863d-0f206b45ae18,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-4fdf86d1-005f-4d90-a69a-d3b2ad0858b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-e4dddae3-ba15-470c-94fd-a7e76d78d1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-a88d3daa-0956-4e59-bea2-80c084761b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-183e8b80-ed20-4882-8e8a-ded91c4f1326,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-fd4b61f9-e885-4796-a641-58072db9ef21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-510478654-172.17.0.17-1595574448821:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34552,DS-b63db84e-805a-4c07-935a-650f712b2072,DISK], DatanodeInfoWithStorage[127.0.0.1:41617,DS-56075534-4402-40b9-922c-05493a6071f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-7bfca053-343a-4640-8d18-a538e985b986,DISK], DatanodeInfoWithStorage[127.0.0.1:44518,DS-2fc34869-51d9-4bd4-8d12-33c241a55191,DISK], DatanodeInfoWithStorage[127.0.0.1:39513,DS-824400e7-81ed-4a41-8069-1c6ca7548d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-3bea1022-60d5-4d76-8e8e-968ae8d82529,DISK], DatanodeInfoWithStorage[127.0.0.1:42853,DS-e706b9d4-a9ef-456f-9a4f-41a62c275678,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-c705960c-9810-4a6a-a3a4-94776357d19a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-510478654-172.17.0.17-1595574448821:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34552,DS-b63db84e-805a-4c07-935a-650f712b2072,DISK], DatanodeInfoWithStorage[127.0.0.1:41617,DS-56075534-4402-40b9-922c-05493a6071f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-7bfca053-343a-4640-8d18-a538e985b986,DISK], DatanodeInfoWithStorage[127.0.0.1:44518,DS-2fc34869-51d9-4bd4-8d12-33c241a55191,DISK], DatanodeInfoWithStorage[127.0.0.1:39513,DS-824400e7-81ed-4a41-8069-1c6ca7548d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-3bea1022-60d5-4d76-8e8e-968ae8d82529,DISK], DatanodeInfoWithStorage[127.0.0.1:42853,DS-e706b9d4-a9ef-456f-9a4f-41a62c275678,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-c705960c-9810-4a6a-a3a4-94776357d19a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-71669930-172.17.0.17-1595574485269:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45601,DS-8a930f99-c914-4afb-8cdf-7dc2102f129c,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-43ae3bf8-bd14-43bd-a896-6853765dfc39,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-c4f6b8c2-f14a-4d32-a772-52a8b991f2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35926,DS-1db8a291-9678-4385-8019-e96384e7f629,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-7d3627c1-0238-4d6b-906e-2907e8c5fd18,DISK], DatanodeInfoWithStorage[127.0.0.1:36832,DS-bef71359-277a-4aa7-bb5d-6198cfc1949e,DISK], DatanodeInfoWithStorage[127.0.0.1:33643,DS-a95e6ae5-9c45-4951-b557-c8a310a09a75,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-f6ed6534-1d85-4854-838f-9735a8aa1ab6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-71669930-172.17.0.17-1595574485269:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45601,DS-8a930f99-c914-4afb-8cdf-7dc2102f129c,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-43ae3bf8-bd14-43bd-a896-6853765dfc39,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-c4f6b8c2-f14a-4d32-a772-52a8b991f2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35926,DS-1db8a291-9678-4385-8019-e96384e7f629,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-7d3627c1-0238-4d6b-906e-2907e8c5fd18,DISK], DatanodeInfoWithStorage[127.0.0.1:36832,DS-bef71359-277a-4aa7-bb5d-6198cfc1949e,DISK], DatanodeInfoWithStorage[127.0.0.1:33643,DS-a95e6ae5-9c45-4951-b557-c8a310a09a75,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-f6ed6534-1d85-4854-838f-9735a8aa1ab6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-340103368-172.17.0.17-1595574852296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33179,DS-23552c31-8ee2-478b-add0-270e3397a18e,DISK], DatanodeInfoWithStorage[127.0.0.1:40996,DS-72dc15d9-6caf-4c44-9fb1-300f48b472dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-bfda1fb1-b517-41df-83ab-626465374193,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-799f125a-3ab6-4950-97bf-ae16f17b111d,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-65c0bcce-f4ef-4d98-82d3-c9fd470765f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36516,DS-f8e3391e-1b74-4de9-93b2-5fa6f56124ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-ca832a04-b279-4d99-98d3-75c29a17ec4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-375edfa6-7732-459d-8fcb-bf0e24ff6bde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-340103368-172.17.0.17-1595574852296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33179,DS-23552c31-8ee2-478b-add0-270e3397a18e,DISK], DatanodeInfoWithStorage[127.0.0.1:40996,DS-72dc15d9-6caf-4c44-9fb1-300f48b472dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-bfda1fb1-b517-41df-83ab-626465374193,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-799f125a-3ab6-4950-97bf-ae16f17b111d,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-65c0bcce-f4ef-4d98-82d3-c9fd470765f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36516,DS-f8e3391e-1b74-4de9-93b2-5fa6f56124ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-ca832a04-b279-4d99-98d3-75c29a17ec4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-375edfa6-7732-459d-8fcb-bf0e24ff6bde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1839022487-172.17.0.17-1595575141118:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34982,DS-e52232ea-0509-41fc-880a-2ba6f880f5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-183663eb-4667-49b0-96ae-c9c3cd49ff2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-964b9bd0-2441-413b-b4ee-5a312c6f5007,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-0cf082fe-ebd0-46dc-8f29-ab7a775d3f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37247,DS-6be837ee-660f-4005-8ff9-acd381e0a326,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-c364d581-4bb5-4d67-9237-8cb7fe9a0a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-50ef585d-ae78-4efa-9957-5e66c66e81de,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-b246efa0-0ded-47ab-90cf-db7aef6ff05c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1839022487-172.17.0.17-1595575141118:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34982,DS-e52232ea-0509-41fc-880a-2ba6f880f5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-183663eb-4667-49b0-96ae-c9c3cd49ff2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-964b9bd0-2441-413b-b4ee-5a312c6f5007,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-0cf082fe-ebd0-46dc-8f29-ab7a775d3f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37247,DS-6be837ee-660f-4005-8ff9-acd381e0a326,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-c364d581-4bb5-4d67-9237-8cb7fe9a0a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-50ef585d-ae78-4efa-9957-5e66c66e81de,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-b246efa0-0ded-47ab-90cf-db7aef6ff05c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1705329241-172.17.0.17-1595576303076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43802,DS-54a5688d-7838-431b-9f5a-9f416b9ad397,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-4d1934df-90e8-44d7-a8f0-bacaf3cce6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-39c8af30-87dc-4db9-9e3c-ec8ebb40b2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-0fea488e-0722-417e-993d-9be10e33811a,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-a9839b18-c79c-4274-9d6c-a5da7754affb,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-4b6bb219-f237-4373-b5b8-a49fa93d49d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-20696e81-ae7a-472a-ad46-bb986e04e5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46060,DS-45ffa8cc-3948-494c-bd10-12d0a374976a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1705329241-172.17.0.17-1595576303076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43802,DS-54a5688d-7838-431b-9f5a-9f416b9ad397,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-4d1934df-90e8-44d7-a8f0-bacaf3cce6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-39c8af30-87dc-4db9-9e3c-ec8ebb40b2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-0fea488e-0722-417e-993d-9be10e33811a,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-a9839b18-c79c-4274-9d6c-a5da7754affb,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-4b6bb219-f237-4373-b5b8-a49fa93d49d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-20696e81-ae7a-472a-ad46-bb986e04e5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46060,DS-45ffa8cc-3948-494c-bd10-12d0a374976a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2046667819-172.17.0.17-1595576371526:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37087,DS-117d72a5-c849-4592-9c32-5e58b4f41f28,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-afe6e07f-a3b6-45a0-bc4f-638444aef52c,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-f75ce983-a113-436a-8f65-429a5fbed868,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-7d000abd-6d9d-41ac-9292-98517ff203af,DISK], DatanodeInfoWithStorage[127.0.0.1:44332,DS-7e12d893-4d71-4fd1-9fc6-67c6ff39a055,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-442271fa-7fe0-4ba5-87a5-161dfc00ee13,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-04d3f3f3-5c2e-4ad0-957a-21d6ff9ff869,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-87dcd99e-3df8-464a-97b8-43b8b507efd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2046667819-172.17.0.17-1595576371526:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37087,DS-117d72a5-c849-4592-9c32-5e58b4f41f28,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-afe6e07f-a3b6-45a0-bc4f-638444aef52c,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-f75ce983-a113-436a-8f65-429a5fbed868,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-7d000abd-6d9d-41ac-9292-98517ff203af,DISK], DatanodeInfoWithStorage[127.0.0.1:44332,DS-7e12d893-4d71-4fd1-9fc6-67c6ff39a055,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-442271fa-7fe0-4ba5-87a5-161dfc00ee13,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-04d3f3f3-5c2e-4ad0-957a-21d6ff9ff869,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-87dcd99e-3df8-464a-97b8-43b8b507efd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1511179691-172.17.0.17-1595576593200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40304,DS-c0ae9bd3-49b7-45b2-a189-d2b727e1cd04,DISK], DatanodeInfoWithStorage[127.0.0.1:37637,DS-0385077a-8332-459d-8c99-87afffe1278e,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-f08c1966-44c8-4ce5-a03f-dbd6d3afbf8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-8ae26336-0153-4d24-b966-95c3084e45f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-566f5995-07ea-4afc-a6bb-9196893ab08b,DISK], DatanodeInfoWithStorage[127.0.0.1:41120,DS-bf3ee5b0-b723-4c15-82dd-1b91c5cf5247,DISK], DatanodeInfoWithStorage[127.0.0.1:38600,DS-2cba5b86-e270-4298-a747-514e68450c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-2735562f-6059-4a77-8442-1101482a1348,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1511179691-172.17.0.17-1595576593200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40304,DS-c0ae9bd3-49b7-45b2-a189-d2b727e1cd04,DISK], DatanodeInfoWithStorage[127.0.0.1:37637,DS-0385077a-8332-459d-8c99-87afffe1278e,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-f08c1966-44c8-4ce5-a03f-dbd6d3afbf8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-8ae26336-0153-4d24-b966-95c3084e45f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-566f5995-07ea-4afc-a6bb-9196893ab08b,DISK], DatanodeInfoWithStorage[127.0.0.1:41120,DS-bf3ee5b0-b723-4c15-82dd-1b91c5cf5247,DISK], DatanodeInfoWithStorage[127.0.0.1:38600,DS-2cba5b86-e270-4298-a747-514e68450c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-2735562f-6059-4a77-8442-1101482a1348,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1918865847-172.17.0.17-1595576627028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40776,DS-402a64af-1b3c-4b91-9129-7ba6b62b4d51,DISK], DatanodeInfoWithStorage[127.0.0.1:38267,DS-4e61322d-211a-413e-8cf6-525df71a2f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-cf239e76-ed9c-462a-b498-f60daa16fcb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-db365886-ddc1-4234-aba9-8cf6c4bfbf88,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-0f9e05d1-97d4-42b0-94b0-6e18cbce3758,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-7d690f64-8f44-4470-aabf-4f27f4896331,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-5b6f2c6f-cbb1-4ca6-b11e-8d9eb9a3f443,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-137f058e-3e74-428b-82c4-daeb85639c65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1918865847-172.17.0.17-1595576627028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40776,DS-402a64af-1b3c-4b91-9129-7ba6b62b4d51,DISK], DatanodeInfoWithStorage[127.0.0.1:38267,DS-4e61322d-211a-413e-8cf6-525df71a2f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-cf239e76-ed9c-462a-b498-f60daa16fcb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-db365886-ddc1-4234-aba9-8cf6c4bfbf88,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-0f9e05d1-97d4-42b0-94b0-6e18cbce3758,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-7d690f64-8f44-4470-aabf-4f27f4896331,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-5b6f2c6f-cbb1-4ca6-b11e-8d9eb9a3f443,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-137f058e-3e74-428b-82c4-daeb85639c65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-753247303-172.17.0.17-1595576888911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36454,DS-4e50b65a-063f-4736-b67b-832292b0eb94,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-13544056-656d-4481-aae9-16cf490346a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-405c6be8-5ae4-47d5-968e-0ab341c07cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-bff816e7-c578-4634-8172-7939973e284f,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-fd0300de-d736-4c50-a37a-dfc1b42d163c,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-e7162c51-70f7-44e6-bf6d-2321ed747bad,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-2ce4342c-6109-4950-875f-344bf033e7df,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-cc7c16b4-41b2-4c9c-962a-94e15ddfac66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-753247303-172.17.0.17-1595576888911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36454,DS-4e50b65a-063f-4736-b67b-832292b0eb94,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-13544056-656d-4481-aae9-16cf490346a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-405c6be8-5ae4-47d5-968e-0ab341c07cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-bff816e7-c578-4634-8172-7939973e284f,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-fd0300de-d736-4c50-a37a-dfc1b42d163c,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-e7162c51-70f7-44e6-bf6d-2321ed747bad,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-2ce4342c-6109-4950-875f-344bf033e7df,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-cc7c16b4-41b2-4c9c-962a-94e15ddfac66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1852501673-172.17.0.17-1595577141176:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46072,DS-c7600e6c-7a71-4c80-ab3b-ea3fab32613f,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-e46b58cf-5a21-41b5-8eb8-b35bb68d825f,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-cc806442-0941-48dd-ad06-6a97b6d3f89f,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-58d11a99-85a2-406d-97b5-e0724713fa2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-870c9045-be18-4cd7-848d-ac5485f6fa0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-173b9646-1044-496b-9e04-23172735ee65,DISK], DatanodeInfoWithStorage[127.0.0.1:40270,DS-19a216ff-9e63-4e45-b8ef-584723ac8cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-7694e976-882b-4691-96ba-2ec7368689c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1852501673-172.17.0.17-1595577141176:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46072,DS-c7600e6c-7a71-4c80-ab3b-ea3fab32613f,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-e46b58cf-5a21-41b5-8eb8-b35bb68d825f,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-cc806442-0941-48dd-ad06-6a97b6d3f89f,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-58d11a99-85a2-406d-97b5-e0724713fa2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-870c9045-be18-4cd7-848d-ac5485f6fa0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-173b9646-1044-496b-9e04-23172735ee65,DISK], DatanodeInfoWithStorage[127.0.0.1:40270,DS-19a216ff-9e63-4e45-b8ef-584723ac8cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-7694e976-882b-4691-96ba-2ec7368689c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-465298707-172.17.0.17-1595577166803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38009,DS-635069f7-b27b-4a07-97ca-ee0ba18253f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-16fe7c05-a998-48e0-8347-b8fb47bd53c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-9aba263f-8c9b-4763-9292-656eb858ee17,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-139a08c8-0bbf-4b7e-b6c7-0d366794eb47,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-997341b8-d472-4716-b560-b75a28742c84,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-9f072d3e-c0f5-4a88-8eb9-f71af57441bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-dafb0b52-6e3d-4ecd-9374-8b42deedc3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-2c8978bf-62d3-44a8-932c-54a5d02a2daa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-465298707-172.17.0.17-1595577166803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38009,DS-635069f7-b27b-4a07-97ca-ee0ba18253f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-16fe7c05-a998-48e0-8347-b8fb47bd53c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-9aba263f-8c9b-4763-9292-656eb858ee17,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-139a08c8-0bbf-4b7e-b6c7-0d366794eb47,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-997341b8-d472-4716-b560-b75a28742c84,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-9f072d3e-c0f5-4a88-8eb9-f71af57441bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-dafb0b52-6e3d-4ecd-9374-8b42deedc3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-2c8978bf-62d3-44a8-932c-54a5d02a2daa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1365056289-172.17.0.17-1595577295294:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44088,DS-69bfad54-7231-44cf-9c6a-c28f3b87e7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-f23f2fb4-e7dd-4b0d-857d-93c0d5d5e484,DISK], DatanodeInfoWithStorage[127.0.0.1:39358,DS-5f14af5a-3f9a-4a15-9f66-01bf002cd300,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-d17273ee-0291-401a-a8f3-f1e45ed9ea55,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-7691958c-87b2-4937-93c9-d20f47a2ad54,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-ea194452-a827-42ee-9815-5b08d2b1d36d,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-b4389808-7cd5-4f1b-8692-e4f7db867126,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-850ce9bf-b61b-4065-9ae5-5e61bd3ce596,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1365056289-172.17.0.17-1595577295294:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44088,DS-69bfad54-7231-44cf-9c6a-c28f3b87e7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-f23f2fb4-e7dd-4b0d-857d-93c0d5d5e484,DISK], DatanodeInfoWithStorage[127.0.0.1:39358,DS-5f14af5a-3f9a-4a15-9f66-01bf002cd300,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-d17273ee-0291-401a-a8f3-f1e45ed9ea55,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-7691958c-87b2-4937-93c9-d20f47a2ad54,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-ea194452-a827-42ee-9815-5b08d2b1d36d,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-b4389808-7cd5-4f1b-8692-e4f7db867126,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-850ce9bf-b61b-4065-9ae5-5e61bd3ce596,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-696890061-172.17.0.17-1595577331816:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39482,DS-fa572a25-b36c-4cf6-bffd-962288e1b60d,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-eaa77314-5eff-40b9-b122-3a1b47bc6b75,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-623cf959-484e-4c06-8275-cda070929a63,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-296939bb-ddc7-4645-9a5c-e379e03df2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-61803d84-b0b9-4001-8802-2845d4ebef8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-b3a05e80-f5d8-4210-a094-0dd77887d228,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-90be1af1-e422-4297-a068-2d4096d08318,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-f7d8663c-113a-417f-b77a-6f1438f191c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-696890061-172.17.0.17-1595577331816:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39482,DS-fa572a25-b36c-4cf6-bffd-962288e1b60d,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-eaa77314-5eff-40b9-b122-3a1b47bc6b75,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-623cf959-484e-4c06-8275-cda070929a63,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-296939bb-ddc7-4645-9a5c-e379e03df2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-61803d84-b0b9-4001-8802-2845d4ebef8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-b3a05e80-f5d8-4210-a094-0dd77887d228,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-90be1af1-e422-4297-a068-2d4096d08318,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-f7d8663c-113a-417f-b77a-6f1438f191c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-419681396-172.17.0.17-1595577822421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40049,DS-8472eee7-7fb3-448b-b0f7-5bfd83fd89d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-58211d60-0ad4-451f-aa6a-d3be5cd66c93,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-2f6a11a1-fbe2-4524-867d-143ef04fba45,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-71408ec1-dde1-4d0f-88ff-7c1c09119a87,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-9513a33d-382e-4a4c-b350-ae3371c16397,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-14f49a6d-111f-4573-b03b-34f35ab9b035,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-db77fd96-9b26-442f-a384-1bd9a4bbd756,DISK], DatanodeInfoWithStorage[127.0.0.1:35889,DS-1b607651-6808-4c86-8eb6-3d58229b5812,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-419681396-172.17.0.17-1595577822421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40049,DS-8472eee7-7fb3-448b-b0f7-5bfd83fd89d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-58211d60-0ad4-451f-aa6a-d3be5cd66c93,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-2f6a11a1-fbe2-4524-867d-143ef04fba45,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-71408ec1-dde1-4d0f-88ff-7c1c09119a87,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-9513a33d-382e-4a4c-b350-ae3371c16397,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-14f49a6d-111f-4573-b03b-34f35ab9b035,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-db77fd96-9b26-442f-a384-1bd9a4bbd756,DISK], DatanodeInfoWithStorage[127.0.0.1:35889,DS-1b607651-6808-4c86-8eb6-3d58229b5812,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1383705314-172.17.0.17-1595577977958:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41576,DS-886dfde5-c991-46b4-a34e-cbadb353d116,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-c6933727-fffc-4dc2-bf39-0aeebf76d32e,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-cb661ae1-67e8-45ad-a83b-fd2041889dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-8daa2283-88ee-44ea-8271-d850ffa6f474,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-52f83dc3-7cfd-41cf-9ff7-a088c796b53f,DISK], DatanodeInfoWithStorage[127.0.0.1:41842,DS-cd4f157d-f2ca-4a2d-a24d-e9e82eb395a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43765,DS-fa104ac0-b6a5-4627-bf75-4f2ca63a32f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-f1088e41-f8fd-47d9-8bc4-6d6626b2cfe3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1383705314-172.17.0.17-1595577977958:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41576,DS-886dfde5-c991-46b4-a34e-cbadb353d116,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-c6933727-fffc-4dc2-bf39-0aeebf76d32e,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-cb661ae1-67e8-45ad-a83b-fd2041889dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-8daa2283-88ee-44ea-8271-d850ffa6f474,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-52f83dc3-7cfd-41cf-9ff7-a088c796b53f,DISK], DatanodeInfoWithStorage[127.0.0.1:41842,DS-cd4f157d-f2ca-4a2d-a24d-e9e82eb395a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43765,DS-fa104ac0-b6a5-4627-bf75-4f2ca63a32f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-f1088e41-f8fd-47d9-8bc4-6d6626b2cfe3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-993329112-172.17.0.17-1595578122153:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44208,DS-552f1d8e-247d-4691-9310-215b2cbf0e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44820,DS-2c7c73da-7896-4dc8-b580-6d03f7cf7d99,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-a50079ba-7680-43dc-a7f2-7335b42db5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-0f64cad2-819b-4d31-88d9-47d2e91e0889,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-0cbf0e81-0580-4d17-87f5-36f7d4d9f63b,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-5f6a4c37-4b83-4d6f-adb1-d0d937351f92,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-9e0191d5-554c-439c-a6f3-8b74ffb6251d,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-92d9ae18-720b-45e5-b2fe-063eab0c905b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-993329112-172.17.0.17-1595578122153:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44208,DS-552f1d8e-247d-4691-9310-215b2cbf0e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44820,DS-2c7c73da-7896-4dc8-b580-6d03f7cf7d99,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-a50079ba-7680-43dc-a7f2-7335b42db5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-0f64cad2-819b-4d31-88d9-47d2e91e0889,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-0cbf0e81-0580-4d17-87f5-36f7d4d9f63b,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-5f6a4c37-4b83-4d6f-adb1-d0d937351f92,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-9e0191d5-554c-439c-a6f3-8b74ffb6251d,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-92d9ae18-720b-45e5-b2fe-063eab0c905b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 4995
