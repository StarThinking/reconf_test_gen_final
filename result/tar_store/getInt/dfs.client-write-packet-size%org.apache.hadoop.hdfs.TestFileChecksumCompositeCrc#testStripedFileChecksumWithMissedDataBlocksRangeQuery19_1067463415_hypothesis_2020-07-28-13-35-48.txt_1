reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 8
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 8
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-742430516-172.17.0.18-1595944983620:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46878,DS-fd72354c-bb79-482b-b082-c41f613472a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-43630500-52d8-454e-ad28-6dd6dc9f97cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-db1554ed-3b93-4a69-b5e0-a9e14dc5420f,DISK], DatanodeInfoWithStorage[127.0.0.1:39342,DS-f00475ee-f6ab-48fa-8c94-c56affb99043,DISK], DatanodeInfoWithStorage[127.0.0.1:34129,DS-5c4c3dab-7537-4161-bb45-e1e806aaedce,DISK], DatanodeInfoWithStorage[127.0.0.1:40313,DS-be541926-45fd-4169-b18c-91ffae4244a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-7f697db1-3018-4f06-beee-9c21e7f55140,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-a1a5a920-9726-4dec-9d66-9e05c79d35e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-742430516-172.17.0.18-1595944983620:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46878,DS-fd72354c-bb79-482b-b082-c41f613472a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-43630500-52d8-454e-ad28-6dd6dc9f97cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-db1554ed-3b93-4a69-b5e0-a9e14dc5420f,DISK], DatanodeInfoWithStorage[127.0.0.1:39342,DS-f00475ee-f6ab-48fa-8c94-c56affb99043,DISK], DatanodeInfoWithStorage[127.0.0.1:34129,DS-5c4c3dab-7537-4161-bb45-e1e806aaedce,DISK], DatanodeInfoWithStorage[127.0.0.1:40313,DS-be541926-45fd-4169-b18c-91ffae4244a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-7f697db1-3018-4f06-beee-9c21e7f55140,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-a1a5a920-9726-4dec-9d66-9e05c79d35e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 8
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-417768709-172.17.0.18-1595945024077:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36076,DS-5526f12f-0be1-49eb-a8c1-035db9d6ee97,DISK], DatanodeInfoWithStorage[127.0.0.1:35989,DS-3a971963-4b90-4eb8-8645-39415f95e017,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-3c48456f-cf7a-4640-9ca8-2debb75cb8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44501,DS-f481c08f-9c73-46ff-8393-062be92f0062,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-76050dc7-1fd0-4bc1-a235-1776be2c50ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-eeb6f789-795b-46e6-9fb8-914724d4f2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-0c359c12-7548-4b69-a61d-01ff3f87c38d,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-89cd93d5-5613-4796-979a-4cd2769daca0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-417768709-172.17.0.18-1595945024077:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36076,DS-5526f12f-0be1-49eb-a8c1-035db9d6ee97,DISK], DatanodeInfoWithStorage[127.0.0.1:35989,DS-3a971963-4b90-4eb8-8645-39415f95e017,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-3c48456f-cf7a-4640-9ca8-2debb75cb8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44501,DS-f481c08f-9c73-46ff-8393-062be92f0062,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-76050dc7-1fd0-4bc1-a235-1776be2c50ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-eeb6f789-795b-46e6-9fb8-914724d4f2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-0c359c12-7548-4b69-a61d-01ff3f87c38d,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-89cd93d5-5613-4796-979a-4cd2769daca0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 8
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1767131901-172.17.0.18-1595945737690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39278,DS-8eaad68b-51bc-4bc5-baf0-ef654b5d4544,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-8624548a-2e9d-437a-8917-43b531671937,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-2613e3e8-95aa-423b-8b4a-fdc2e1c25967,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-e09f978f-844c-43f0-a175-fba395d0ecd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33425,DS-69ebb7e0-eba1-46be-a301-a9e8533cf8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-4c9d2438-0b90-45d0-a724-e9e1b8933b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-b28b2be3-da9c-44a7-8607-cebf839e68cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33418,DS-3bec0a83-070e-4a7c-a724-0a3885824f17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1767131901-172.17.0.18-1595945737690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39278,DS-8eaad68b-51bc-4bc5-baf0-ef654b5d4544,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-8624548a-2e9d-437a-8917-43b531671937,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-2613e3e8-95aa-423b-8b4a-fdc2e1c25967,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-e09f978f-844c-43f0-a175-fba395d0ecd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33425,DS-69ebb7e0-eba1-46be-a301-a9e8533cf8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-4c9d2438-0b90-45d0-a724-e9e1b8933b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-b28b2be3-da9c-44a7-8607-cebf839e68cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33418,DS-3bec0a83-070e-4a7c-a724-0a3885824f17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 8
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-525652960-172.17.0.18-1595945935193:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43129,DS-38e53cd6-8be2-4b07-a12d-95e6623bda21,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-9eed5aa2-f338-4e96-9d62-fe047b6471ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-e18f6933-8802-4d55-a7ed-7405f97075fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-fdaa4481-b9e4-4dda-8222-ef965a75a856,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-c10206f2-c4d8-45b0-a541-b133d50fb67c,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-a48c3781-7964-4c99-89ef-ac639f8cbe51,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-babf3c71-6c90-49e9-9472-9ca145029367,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-001aac17-d3bc-4a3a-ac22-1f063a7a3c2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-525652960-172.17.0.18-1595945935193:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43129,DS-38e53cd6-8be2-4b07-a12d-95e6623bda21,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-9eed5aa2-f338-4e96-9d62-fe047b6471ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-e18f6933-8802-4d55-a7ed-7405f97075fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-fdaa4481-b9e4-4dda-8222-ef965a75a856,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-c10206f2-c4d8-45b0-a541-b133d50fb67c,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-a48c3781-7964-4c99-89ef-ac639f8cbe51,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-babf3c71-6c90-49e9-9472-9ca145029367,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-001aac17-d3bc-4a3a-ac22-1f063a7a3c2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 8
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1579747418-172.17.0.18-1595946368113:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38750,DS-37c91d75-627f-4af5-ae5a-50d6210f5952,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-f10c1293-f485-4867-989e-948d98e83781,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-3f1fede7-ac87-4440-9514-370f725c2f13,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-38e451c7-cad1-45a0-851e-88b12284cf1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41505,DS-dc6c3251-e6d5-4b58-b6f5-ec0da1e29cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-ec77d76e-cf74-4c0c-8677-f34f7b291bca,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-46140694-7e7a-4167-83de-8a128982855a,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-d75dba79-fc55-4e15-961b-90e05e77ec66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1579747418-172.17.0.18-1595946368113:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38750,DS-37c91d75-627f-4af5-ae5a-50d6210f5952,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-f10c1293-f485-4867-989e-948d98e83781,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-3f1fede7-ac87-4440-9514-370f725c2f13,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-38e451c7-cad1-45a0-851e-88b12284cf1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41505,DS-dc6c3251-e6d5-4b58-b6f5-ec0da1e29cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-ec77d76e-cf74-4c0c-8677-f34f7b291bca,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-46140694-7e7a-4167-83de-8a128982855a,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-d75dba79-fc55-4e15-961b-90e05e77ec66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 8
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-963742395-172.17.0.18-1595946405313:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35629,DS-9651e21a-af26-41e5-8c3b-a0efa372248b,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-a838c728-37f9-45d7-865b-53010da37bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-3ad8506d-81b3-485c-aed9-3e5917eb2102,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-be2d32f7-7468-4464-9c0f-72717fb28345,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-6d2eca98-e302-48e6-a055-a6dd3f641081,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-44d5b0d7-f3f1-45ce-a806-217e82a98213,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-325c0640-79c6-47cf-b984-815f4d3706ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-b21bd137-853f-4245-9b2a-8479798b93e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-963742395-172.17.0.18-1595946405313:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35629,DS-9651e21a-af26-41e5-8c3b-a0efa372248b,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-a838c728-37f9-45d7-865b-53010da37bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-3ad8506d-81b3-485c-aed9-3e5917eb2102,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-be2d32f7-7468-4464-9c0f-72717fb28345,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-6d2eca98-e302-48e6-a055-a6dd3f641081,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-44d5b0d7-f3f1-45ce-a806-217e82a98213,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-325c0640-79c6-47cf-b984-815f4d3706ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-b21bd137-853f-4245-9b2a-8479798b93e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 8
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1167302603-172.17.0.18-1595946727711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45929,DS-836465a3-6465-4867-baaf-edb4702d7878,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-d831cf30-0f39-4bf7-a6d1-0c18e8ae9565,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-e14f3c99-2d10-4786-8788-652a04296b54,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-deb9aa6c-72ff-4262-9333-19b1f386453e,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-92c683b4-7fea-446a-b532-3a93274a0d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-59b92936-a639-40f6-a801-11af4c6cd0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-024a8dad-3dfb-4d94-a7e4-97360ff89d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37577,DS-42669157-34b7-4bd6-9f74-a3df56832178,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1167302603-172.17.0.18-1595946727711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45929,DS-836465a3-6465-4867-baaf-edb4702d7878,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-d831cf30-0f39-4bf7-a6d1-0c18e8ae9565,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-e14f3c99-2d10-4786-8788-652a04296b54,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-deb9aa6c-72ff-4262-9333-19b1f386453e,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-92c683b4-7fea-446a-b532-3a93274a0d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-59b92936-a639-40f6-a801-11af4c6cd0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-024a8dad-3dfb-4d94-a7e4-97360ff89d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37577,DS-42669157-34b7-4bd6-9f74-a3df56832178,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 8
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1740560019-172.17.0.18-1595946937913:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43718,DS-a53dd4ca-6faa-4ef9-8dd5-dd70282c1917,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-fcc6a688-3cd4-4757-9ae3-a4633dd23887,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-6c6a9453-df20-48ab-92b0-48707da82d49,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-a0b93fa3-9d26-43e2-8672-6bdcbeeeeece,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-08fafae5-9b58-4f47-adb1-58808088d0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-714b56fa-6e7c-4ed6-a351-1e2a6517ebc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35293,DS-1054b4e0-7bdb-4f87-9efa-381c23d29396,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-3fbb7aef-1198-40de-b0fe-f8dea15bf831,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1740560019-172.17.0.18-1595946937913:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43718,DS-a53dd4ca-6faa-4ef9-8dd5-dd70282c1917,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-fcc6a688-3cd4-4757-9ae3-a4633dd23887,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-6c6a9453-df20-48ab-92b0-48707da82d49,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-a0b93fa3-9d26-43e2-8672-6bdcbeeeeece,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-08fafae5-9b58-4f47-adb1-58808088d0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-714b56fa-6e7c-4ed6-a351-1e2a6517ebc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35293,DS-1054b4e0-7bdb-4f87-9efa-381c23d29396,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-3fbb7aef-1198-40de-b0fe-f8dea15bf831,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 8
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-953539617-172.17.0.18-1595947018821:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45146,DS-7a8d2023-e209-4447-b7c4-e85d1ffe56ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-5d8e205c-b182-4a13-888a-e01c8a602bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-9998d3ca-ef4b-49cc-bb00-d8086eac0ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-963fc2a4-afa1-48b9-b440-32f0292572be,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-e1f50339-9c96-416c-b268-035534e59d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-b5bbe5f8-6532-49e9-a2e0-052a1d23bab4,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-5355201a-759c-4b63-9fa8-463a63ea602e,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-3bb10a10-320f-4dd9-a972-72db7c1581b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-953539617-172.17.0.18-1595947018821:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45146,DS-7a8d2023-e209-4447-b7c4-e85d1ffe56ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-5d8e205c-b182-4a13-888a-e01c8a602bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-9998d3ca-ef4b-49cc-bb00-d8086eac0ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-963fc2a4-afa1-48b9-b440-32f0292572be,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-e1f50339-9c96-416c-b268-035534e59d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-b5bbe5f8-6532-49e9-a2e0-052a1d23bab4,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-5355201a-759c-4b63-9fa8-463a63ea602e,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-3bb10a10-320f-4dd9-a972-72db7c1581b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 8
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-823176204-172.17.0.18-1595947061800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37786,DS-46b478b6-2709-454a-9fe5-ce4177c03cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-d54920a0-6502-43ba-a5ff-ebe92a64d867,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-bf94c9a6-fc7a-49ff-b7f9-d9e94e17a79d,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-560fb03e-5dee-40ba-bace-342d20c18c97,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-d817e0a4-5e2e-4d4c-91b0-8798d51a4cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46500,DS-d31f268d-272e-4b0f-b9f9-885cb9b648cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-1a8c1c01-d7ef-4af7-8e6b-40ec9857c932,DISK], DatanodeInfoWithStorage[127.0.0.1:44369,DS-8ae4fc87-9d7e-4ee5-87b9-a7c24b28011a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-823176204-172.17.0.18-1595947061800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37786,DS-46b478b6-2709-454a-9fe5-ce4177c03cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-d54920a0-6502-43ba-a5ff-ebe92a64d867,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-bf94c9a6-fc7a-49ff-b7f9-d9e94e17a79d,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-560fb03e-5dee-40ba-bace-342d20c18c97,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-d817e0a4-5e2e-4d4c-91b0-8798d51a4cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46500,DS-d31f268d-272e-4b0f-b9f9-885cb9b648cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-1a8c1c01-d7ef-4af7-8e6b-40ec9857c932,DISK], DatanodeInfoWithStorage[127.0.0.1:44369,DS-8ae4fc87-9d7e-4ee5-87b9-a7c24b28011a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 8
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1458031911-172.17.0.18-1595947428254:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32800,DS-41d7f0fc-9ec4-42ec-b5a9-67ade10259e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41965,DS-1975c362-d842-48a5-a6a5-ba38a6559368,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-6ea97304-b877-4c63-8d8e-5da182292295,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-c3672b02-741c-4cf2-ac43-2011826dcdc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-cbace98b-a53b-4864-a757-142354f04f12,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-fda2465a-b8f2-452a-a562-fd1d936955ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42163,DS-c147239e-83f6-4523-8646-1e5f06f41986,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-0f709f34-4ff8-4fbc-919c-2f588cd74a4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1458031911-172.17.0.18-1595947428254:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32800,DS-41d7f0fc-9ec4-42ec-b5a9-67ade10259e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41965,DS-1975c362-d842-48a5-a6a5-ba38a6559368,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-6ea97304-b877-4c63-8d8e-5da182292295,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-c3672b02-741c-4cf2-ac43-2011826dcdc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-cbace98b-a53b-4864-a757-142354f04f12,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-fda2465a-b8f2-452a-a562-fd1d936955ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42163,DS-c147239e-83f6-4523-8646-1e5f06f41986,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-0f709f34-4ff8-4fbc-919c-2f588cd74a4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 8
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1422885787-172.17.0.18-1595947551533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38584,DS-e633f088-3232-4a14-899c-3a88edbdb609,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-190efa7a-4338-4ce1-9e9f-af090962aba7,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-02a6ccd1-3ee4-4b68-b38f-db0a92b60b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-1e24e783-5623-41dd-8ace-8c6ab9f29b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46854,DS-f1cb3d47-2cf7-412e-89d7-4dbc6d0466a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39309,DS-c9cdb2ee-28ac-48cc-8031-4658165bd021,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-4e09b0cb-2e3d-4250-991a-9f57929a96ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-e883ddb2-ecef-46de-901c-742162c40ec7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1422885787-172.17.0.18-1595947551533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38584,DS-e633f088-3232-4a14-899c-3a88edbdb609,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-190efa7a-4338-4ce1-9e9f-af090962aba7,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-02a6ccd1-3ee4-4b68-b38f-db0a92b60b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-1e24e783-5623-41dd-8ace-8c6ab9f29b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46854,DS-f1cb3d47-2cf7-412e-89d7-4dbc6d0466a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39309,DS-c9cdb2ee-28ac-48cc-8031-4658165bd021,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-4e09b0cb-2e3d-4250-991a-9f57929a96ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-e883ddb2-ecef-46de-901c-742162c40ec7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 8
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1509572248-172.17.0.18-1595947687103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43687,DS-c6fe1d44-b752-4e25-b9b2-0f27b02c9990,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-ea125426-a469-4c3e-baef-9d6ed8d12d19,DISK], DatanodeInfoWithStorage[127.0.0.1:39533,DS-5a3ccfa5-6528-4733-84f5-2a03d454b75e,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-0bb6d272-dbb0-4a17-a5da-976871327948,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-1f9177d1-c409-456a-aa79-f7d24a5cdd43,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-ec7520fe-e945-4f5f-9d2b-4a4d52e31aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-4db59566-3f04-4466-b0df-ed2322528921,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-6da66724-8d1a-4a53-8fbd-aec94244fad6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1509572248-172.17.0.18-1595947687103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43687,DS-c6fe1d44-b752-4e25-b9b2-0f27b02c9990,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-ea125426-a469-4c3e-baef-9d6ed8d12d19,DISK], DatanodeInfoWithStorage[127.0.0.1:39533,DS-5a3ccfa5-6528-4733-84f5-2a03d454b75e,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-0bb6d272-dbb0-4a17-a5da-976871327948,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-1f9177d1-c409-456a-aa79-f7d24a5cdd43,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-ec7520fe-e945-4f5f-9d2b-4a4d52e31aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-4db59566-3f04-4466-b0df-ed2322528921,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-6da66724-8d1a-4a53-8fbd-aec94244fad6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 8
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-149469330-172.17.0.18-1595947869068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40998,DS-7145fbf4-b27f-4e4d-bc42-b5eb4db7f3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-08d01d1e-f659-4e10-a332-346e219743af,DISK], DatanodeInfoWithStorage[127.0.0.1:36970,DS-b53b32d3-7059-4148-a870-b538eea23c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-025ee98d-116c-4201-918f-ec0656b23d73,DISK], DatanodeInfoWithStorage[127.0.0.1:36807,DS-f68e0809-bf5d-4720-a974-8b4b8e4b913c,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-934cccda-ebc0-49d5-9ae7-265a489da3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-33d5aa0e-8ec1-4937-951a-2fd008a7793c,DISK], DatanodeInfoWithStorage[127.0.0.1:37615,DS-ec2db8d4-6f9d-435b-a59b-607362ac6a8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-149469330-172.17.0.18-1595947869068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40998,DS-7145fbf4-b27f-4e4d-bc42-b5eb4db7f3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-08d01d1e-f659-4e10-a332-346e219743af,DISK], DatanodeInfoWithStorage[127.0.0.1:36970,DS-b53b32d3-7059-4148-a870-b538eea23c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-025ee98d-116c-4201-918f-ec0656b23d73,DISK], DatanodeInfoWithStorage[127.0.0.1:36807,DS-f68e0809-bf5d-4720-a974-8b4b8e4b913c,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-934cccda-ebc0-49d5-9ae7-265a489da3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-33d5aa0e-8ec1-4937-951a-2fd008a7793c,DISK], DatanodeInfoWithStorage[127.0.0.1:37615,DS-ec2db8d4-6f9d-435b-a59b-607362ac6a8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 8
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1743034905-172.17.0.18-1595947906539:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44534,DS-ed0b670b-1c1a-4090-a984-040081e07230,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-f2342244-e478-449c-9d98-6de2eee7a97a,DISK], DatanodeInfoWithStorage[127.0.0.1:35750,DS-498f1996-2f13-4846-8772-789157b0c3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-bf7ceca9-3520-41e6-8bce-b4b3c3599594,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-2cad8225-85c7-44c3-b86c-6c1cea422013,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-90d6f5f4-c145-48c8-8bb3-f95542b10d74,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-be261d2c-f318-47d7-b85e-4a9239096428,DISK], DatanodeInfoWithStorage[127.0.0.1:44638,DS-d15c691a-c577-47f1-8568-dce22449bcd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1743034905-172.17.0.18-1595947906539:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44534,DS-ed0b670b-1c1a-4090-a984-040081e07230,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-f2342244-e478-449c-9d98-6de2eee7a97a,DISK], DatanodeInfoWithStorage[127.0.0.1:35750,DS-498f1996-2f13-4846-8772-789157b0c3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-bf7ceca9-3520-41e6-8bce-b4b3c3599594,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-2cad8225-85c7-44c3-b86c-6c1cea422013,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-90d6f5f4-c145-48c8-8bb3-f95542b10d74,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-be261d2c-f318-47d7-b85e-4a9239096428,DISK], DatanodeInfoWithStorage[127.0.0.1:44638,DS-d15c691a-c577-47f1-8568-dce22449bcd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 8
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1105586150-172.17.0.18-1595947941293:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35751,DS-bec09a99-b9c1-4d51-a6b3-fd3e416bf95a,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-ce76bef6-1a07-4ef6-b986-30925fdbae93,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-a282c52a-78ef-4af7-a56a-b0fab6709a97,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-79d89144-451e-417d-9cd4-5a1c4d6d7e69,DISK], DatanodeInfoWithStorage[127.0.0.1:46564,DS-20875ea3-30d0-4bf5-b5b1-5d3d1533a542,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-17ef03d6-7e22-4d19-97d4-bc453794b93c,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-00df0a5b-50e3-40da-961d-1c1070526fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:34692,DS-32b4ee21-572f-4356-95b1-103a9bf1bead,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1105586150-172.17.0.18-1595947941293:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35751,DS-bec09a99-b9c1-4d51-a6b3-fd3e416bf95a,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-ce76bef6-1a07-4ef6-b986-30925fdbae93,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-a282c52a-78ef-4af7-a56a-b0fab6709a97,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-79d89144-451e-417d-9cd4-5a1c4d6d7e69,DISK], DatanodeInfoWithStorage[127.0.0.1:46564,DS-20875ea3-30d0-4bf5-b5b1-5d3d1533a542,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-17ef03d6-7e22-4d19-97d4-bc453794b93c,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-00df0a5b-50e3-40da-961d-1c1070526fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:34692,DS-32b4ee21-572f-4356-95b1-103a9bf1bead,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 8
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1103126495-172.17.0.18-1595950668773:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44721,DS-6f542ac3-a11b-47cf-bd81-76820337d855,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-9d74313d-f987-4b26-99b0-29b9c6c2fcea,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-317ba339-e9e4-4be8-a3c5-08678700b93e,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-fa24e8a7-1ee9-4478-8c12-cb1cda4b9483,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-f67e0bf6-0039-48cb-ac7f-938474395824,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-1472ebb4-e873-4ef6-b95f-d4269553b878,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-ae03fe4d-d465-4a05-a360-1134903614da,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-b84b3fba-db84-419d-bacc-9d1fdda1f6a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1103126495-172.17.0.18-1595950668773:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44721,DS-6f542ac3-a11b-47cf-bd81-76820337d855,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-9d74313d-f987-4b26-99b0-29b9c6c2fcea,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-317ba339-e9e4-4be8-a3c5-08678700b93e,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-fa24e8a7-1ee9-4478-8c12-cb1cda4b9483,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-f67e0bf6-0039-48cb-ac7f-938474395824,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-1472ebb4-e873-4ef6-b95f-d4269553b878,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-ae03fe4d-d465-4a05-a360-1134903614da,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-b84b3fba-db84-419d-bacc-9d1fdda1f6a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 8
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-461459224-172.17.0.18-1595951600936:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46158,DS-728fa78a-4351-4bc2-ab5a-f70de6997b11,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-2661ba83-23ef-443a-9d9f-6fc14a328148,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-496e69cd-b2b2-411c-9a82-4ddac021bdeb,DISK], DatanodeInfoWithStorage[127.0.0.1:45276,DS-c920c38b-5986-4482-8974-601a615c740b,DISK], DatanodeInfoWithStorage[127.0.0.1:43697,DS-bcae7982-97a2-4025-8bd6-bba4a3abe013,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-8eea4194-c169-4d4e-a663-2ad6aabb1395,DISK], DatanodeInfoWithStorage[127.0.0.1:39487,DS-59b0e331-ef2b-4c79-b6f7-b34a08461db6,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-24dd0f69-6266-4d28-b4ea-8ac7e626b7a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-461459224-172.17.0.18-1595951600936:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46158,DS-728fa78a-4351-4bc2-ab5a-f70de6997b11,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-2661ba83-23ef-443a-9d9f-6fc14a328148,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-496e69cd-b2b2-411c-9a82-4ddac021bdeb,DISK], DatanodeInfoWithStorage[127.0.0.1:45276,DS-c920c38b-5986-4482-8974-601a615c740b,DISK], DatanodeInfoWithStorage[127.0.0.1:43697,DS-bcae7982-97a2-4025-8bd6-bba4a3abe013,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-8eea4194-c169-4d4e-a663-2ad6aabb1395,DISK], DatanodeInfoWithStorage[127.0.0.1:39487,DS-59b0e331-ef2b-4c79-b6f7-b34a08461db6,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-24dd0f69-6266-4d28-b4ea-8ac7e626b7a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 8
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1685212174-172.17.0.18-1595951733791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35655,DS-cc9731b0-0215-459d-970a-90a579d161c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-7204fad9-6449-4375-966a-b177d3291ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-fa201d42-1f7e-45e5-b09a-3497085c4a24,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-ab8f8abf-f1d9-49d5-a08c-839f102e823e,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-6cfa19d1-4fb3-42e8-838e-952f10b3be59,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-2ab0dde5-bf0c-4645-8f2e-f7c2e12cd2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45688,DS-f80c6f25-b8e6-46b6-b577-d9ba58fd118b,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-843c7467-5f3b-4388-81cb-22b27b18dfa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1685212174-172.17.0.18-1595951733791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35655,DS-cc9731b0-0215-459d-970a-90a579d161c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-7204fad9-6449-4375-966a-b177d3291ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-fa201d42-1f7e-45e5-b09a-3497085c4a24,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-ab8f8abf-f1d9-49d5-a08c-839f102e823e,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-6cfa19d1-4fb3-42e8-838e-952f10b3be59,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-2ab0dde5-bf0c-4645-8f2e-f7c2e12cd2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45688,DS-f80c6f25-b8e6-46b6-b577-d9ba58fd118b,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-843c7467-5f3b-4388-81cb-22b27b18dfa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 8404
