reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 64
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 64
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1210996864-172.17.0.4-1596008192831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37284,DS-3a42c84c-7cf1-47f6-a4ac-c777f148b309,DISK], DatanodeInfoWithStorage[127.0.0.1:36047,DS-adaad28b-2665-4c8c-93cf-1e61e0abeef0,DISK], DatanodeInfoWithStorage[127.0.0.1:42796,DS-ffc3a0b8-84f8-4939-a917-0eb5dd0a4da5,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-c0bbfa45-d0d8-4530-a26a-24e33d4864db,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-995f16ce-651b-4f8f-bc79-e5535083913b,DISK], DatanodeInfoWithStorage[127.0.0.1:46758,DS-4def84e4-8c3b-4112-813d-1e6e7ba9400a,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-c917ede6-1214-463e-bcdd-5fccfe868ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-08e53feb-cabe-49e1-9266-73fb3b419fd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1210996864-172.17.0.4-1596008192831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37284,DS-3a42c84c-7cf1-47f6-a4ac-c777f148b309,DISK], DatanodeInfoWithStorage[127.0.0.1:36047,DS-adaad28b-2665-4c8c-93cf-1e61e0abeef0,DISK], DatanodeInfoWithStorage[127.0.0.1:42796,DS-ffc3a0b8-84f8-4939-a917-0eb5dd0a4da5,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-c0bbfa45-d0d8-4530-a26a-24e33d4864db,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-995f16ce-651b-4f8f-bc79-e5535083913b,DISK], DatanodeInfoWithStorage[127.0.0.1:46758,DS-4def84e4-8c3b-4112-813d-1e6e7ba9400a,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-c917ede6-1214-463e-bcdd-5fccfe868ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-08e53feb-cabe-49e1-9266-73fb3b419fd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 64
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-293872551-172.17.0.4-1596008331496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40110,DS-91f6b1dc-a8fd-4a67-93b1-204a3b63c301,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-a4e8a444-0c9f-4bff-bdd9-49fb23b194de,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-f7dbd1c2-1bf3-441b-96bd-a097238c8caa,DISK], DatanodeInfoWithStorage[127.0.0.1:37254,DS-9f309d37-d2d3-4a4a-8eac-9ed2d3634f55,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-44a3ecbd-c290-415e-8c9a-18582f17ce1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45010,DS-080c5bce-cc7c-4795-abaa-c3439e428163,DISK], DatanodeInfoWithStorage[127.0.0.1:35413,DS-41c6e951-2741-4fc4-bcca-6263275c0575,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-74552104-2649-44ea-aed6-0c82327259d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-293872551-172.17.0.4-1596008331496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40110,DS-91f6b1dc-a8fd-4a67-93b1-204a3b63c301,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-a4e8a444-0c9f-4bff-bdd9-49fb23b194de,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-f7dbd1c2-1bf3-441b-96bd-a097238c8caa,DISK], DatanodeInfoWithStorage[127.0.0.1:37254,DS-9f309d37-d2d3-4a4a-8eac-9ed2d3634f55,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-44a3ecbd-c290-415e-8c9a-18582f17ce1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45010,DS-080c5bce-cc7c-4795-abaa-c3439e428163,DISK], DatanodeInfoWithStorage[127.0.0.1:35413,DS-41c6e951-2741-4fc4-bcca-6263275c0575,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-74552104-2649-44ea-aed6-0c82327259d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 64
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-65617082-172.17.0.4-1596008442923:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36903,DS-aaf6853f-8d4c-4142-83ae-87a2495b6d08,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-bb90887c-e353-4d2c-8958-c301fc6a64ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-1703738e-9649-4611-ab19-b94de12bd5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-2ef05eb2-f40f-4f49-a52e-1dd01c5d7d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-eea2c732-fca6-426a-8bd2-fa1b8409f629,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-bf443c65-4567-4590-854d-59a61e1b0ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-0782fb86-02cf-44cc-af5f-dfbd94ff5af1,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-9134ba32-4e51-4c90-8373-363035bf334b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-65617082-172.17.0.4-1596008442923:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36903,DS-aaf6853f-8d4c-4142-83ae-87a2495b6d08,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-bb90887c-e353-4d2c-8958-c301fc6a64ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-1703738e-9649-4611-ab19-b94de12bd5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-2ef05eb2-f40f-4f49-a52e-1dd01c5d7d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-eea2c732-fca6-426a-8bd2-fa1b8409f629,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-bf443c65-4567-4590-854d-59a61e1b0ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-0782fb86-02cf-44cc-af5f-dfbd94ff5af1,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-9134ba32-4e51-4c90-8373-363035bf334b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 64
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-321659622-172.17.0.4-1596008577734:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45345,DS-3b15d089-21dc-4de4-89b8-90fc20d2a9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-540b5d09-3147-46c8-9594-13878830b181,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-f87ebee7-500b-4b06-9f5f-89452fce00bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43169,DS-670334d6-6377-4a4f-8cf6-639d6a78ce54,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-354b7fb1-9ed5-4864-8af1-bf9ac0b29100,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-430c7ede-6dec-465e-80b6-40c1ffb3d07f,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-58feb73f-af5b-4167-ae81-590b72a22319,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-7488672c-5a68-4ede-a5f1-c3ac4d350829,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-321659622-172.17.0.4-1596008577734:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45345,DS-3b15d089-21dc-4de4-89b8-90fc20d2a9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-540b5d09-3147-46c8-9594-13878830b181,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-f87ebee7-500b-4b06-9f5f-89452fce00bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43169,DS-670334d6-6377-4a4f-8cf6-639d6a78ce54,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-354b7fb1-9ed5-4864-8af1-bf9ac0b29100,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-430c7ede-6dec-465e-80b6-40c1ffb3d07f,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-58feb73f-af5b-4167-ae81-590b72a22319,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-7488672c-5a68-4ede-a5f1-c3ac4d350829,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 64
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-454777482-172.17.0.4-1596009268362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43795,DS-35bc3873-440a-4afe-bfbb-f7223a28e457,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-27e83f64-0ab5-42b7-80a2-1f32b4294f77,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-f2d22147-8e0f-4bf3-b807-40a455dba1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-9ae0f39d-e4d2-43ee-87d3-5bf30e7de5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-35bf025d-fd03-4ec5-a613-3f0420f1a2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-3f9edda4-1dfd-4eff-b053-27dd3b9c5379,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-26f9f63f-bc7d-4b2c-bcca-5d5e1857a390,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-07bb9269-c4ec-48c4-8559-25642c096305,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-454777482-172.17.0.4-1596009268362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43795,DS-35bc3873-440a-4afe-bfbb-f7223a28e457,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-27e83f64-0ab5-42b7-80a2-1f32b4294f77,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-f2d22147-8e0f-4bf3-b807-40a455dba1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-9ae0f39d-e4d2-43ee-87d3-5bf30e7de5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-35bf025d-fd03-4ec5-a613-3f0420f1a2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-3f9edda4-1dfd-4eff-b053-27dd3b9c5379,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-26f9f63f-bc7d-4b2c-bcca-5d5e1857a390,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-07bb9269-c4ec-48c4-8559-25642c096305,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 64
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-267844874-172.17.0.4-1596009497599:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44092,DS-6aa161ac-53d4-4290-a651-2caba8e36ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-00ee3592-7557-4b10-aeea-0b4b7568e0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-d6d45ed3-87ba-42b3-a560-170eb8c1c35c,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-540e53d4-b8fd-4ff5-ba33-dda3e981dcc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-64185e59-7e73-4aae-bfbd-ade1e61c96ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-654d74f1-2b03-4cfd-8493-5ee6683a03ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-d1b6aaf5-3b00-4f32-b791-0bb3e6336f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-4bc7bab3-df9b-43ce-99cf-04348beb7dda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-267844874-172.17.0.4-1596009497599:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44092,DS-6aa161ac-53d4-4290-a651-2caba8e36ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-00ee3592-7557-4b10-aeea-0b4b7568e0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-d6d45ed3-87ba-42b3-a560-170eb8c1c35c,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-540e53d4-b8fd-4ff5-ba33-dda3e981dcc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-64185e59-7e73-4aae-bfbd-ade1e61c96ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-654d74f1-2b03-4cfd-8493-5ee6683a03ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-d1b6aaf5-3b00-4f32-b791-0bb3e6336f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-4bc7bab3-df9b-43ce-99cf-04348beb7dda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 64
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2048697436-172.17.0.4-1596009818889:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40035,DS-85731f42-35ba-4cec-b26a-d4e3ff5dfc22,DISK], DatanodeInfoWithStorage[127.0.0.1:36791,DS-b07bf48a-b399-41a1-95b4-212e05970fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-6c230146-e30c-4858-be3f-a0710bd585f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41468,DS-b2e0e7ad-4452-4a06-8514-bf4d68ae6fda,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-18744a4d-656c-4b9a-b306-f7cd98ee66cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-32c5435d-14a8-41f0-b816-578f57cec964,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-50126802-282c-40ba-9559-099a23ffa9be,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-86020b2b-855f-4106-9fe8-c24924d2ba60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2048697436-172.17.0.4-1596009818889:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40035,DS-85731f42-35ba-4cec-b26a-d4e3ff5dfc22,DISK], DatanodeInfoWithStorage[127.0.0.1:36791,DS-b07bf48a-b399-41a1-95b4-212e05970fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-6c230146-e30c-4858-be3f-a0710bd585f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41468,DS-b2e0e7ad-4452-4a06-8514-bf4d68ae6fda,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-18744a4d-656c-4b9a-b306-f7cd98ee66cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-32c5435d-14a8-41f0-b816-578f57cec964,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-50126802-282c-40ba-9559-099a23ffa9be,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-86020b2b-855f-4106-9fe8-c24924d2ba60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 64
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-68594759-172.17.0.4-1596010336195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41632,DS-2638e69d-3212-4177-b991-2977a99b443b,DISK], DatanodeInfoWithStorage[127.0.0.1:34126,DS-4c3a7494-8aac-41b3-af5a-0b17cf8e9cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-95b1e755-c75d-45ea-8405-3d486c79baab,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-298a5713-dbdc-4b6a-b809-1f6bef700bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-e1cbe15c-105b-49f3-9ecf-0f526c51c7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-4f3af2c3-4c7a-407e-9cf5-aaf0004237b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-b37f1933-f821-41c0-bd41-e4e06b5f326f,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-b13f949e-cb13-44db-8776-443e45b92758,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-68594759-172.17.0.4-1596010336195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41632,DS-2638e69d-3212-4177-b991-2977a99b443b,DISK], DatanodeInfoWithStorage[127.0.0.1:34126,DS-4c3a7494-8aac-41b3-af5a-0b17cf8e9cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-95b1e755-c75d-45ea-8405-3d486c79baab,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-298a5713-dbdc-4b6a-b809-1f6bef700bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-e1cbe15c-105b-49f3-9ecf-0f526c51c7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-4f3af2c3-4c7a-407e-9cf5-aaf0004237b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-b37f1933-f821-41c0-bd41-e4e06b5f326f,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-b13f949e-cb13-44db-8776-443e45b92758,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 64
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1757255393-172.17.0.4-1596010374573:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46170,DS-265bf492-d54f-4269-ae2d-18f8638f46d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-919d802f-89c9-4a8d-a1e0-4474a79b8670,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-bf71bcdd-bbd8-4b52-a81e-8a7bbe212cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-63f25b62-428c-499b-8309-9a6a3e909ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-3dec5904-b992-4fac-846d-9785ccd290d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-da97303d-ba17-475a-baf6-c842997885f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-38582ecc-be1f-40a4-88a4-fa52dd484b05,DISK], DatanodeInfoWithStorage[127.0.0.1:35433,DS-0114d63b-c10c-4e10-a669-6af9bb3c543d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1757255393-172.17.0.4-1596010374573:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46170,DS-265bf492-d54f-4269-ae2d-18f8638f46d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-919d802f-89c9-4a8d-a1e0-4474a79b8670,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-bf71bcdd-bbd8-4b52-a81e-8a7bbe212cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-63f25b62-428c-499b-8309-9a6a3e909ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-3dec5904-b992-4fac-846d-9785ccd290d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-da97303d-ba17-475a-baf6-c842997885f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-38582ecc-be1f-40a4-88a4-fa52dd484b05,DISK], DatanodeInfoWithStorage[127.0.0.1:35433,DS-0114d63b-c10c-4e10-a669-6af9bb3c543d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 64
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-749581900-172.17.0.4-1596010523563:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35782,DS-5d7157e9-e3b3-4377-a387-8d833d3595c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-aca118ea-1964-47f0-85a3-ed142dec85a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-560fe861-795d-4646-afea-2b50ad004a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38849,DS-8adcf420-7632-442d-a531-c52a7e7020fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-f361bfa7-daf3-4e63-ba39-da04466b2bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-f313c970-0848-4ff0-bf38-fd439c336bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-dc61efe7-261a-46ad-81ee-c4f5adc04eff,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-8007295f-7072-44f8-8ef7-26d0a6c110b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-749581900-172.17.0.4-1596010523563:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35782,DS-5d7157e9-e3b3-4377-a387-8d833d3595c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-aca118ea-1964-47f0-85a3-ed142dec85a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-560fe861-795d-4646-afea-2b50ad004a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38849,DS-8adcf420-7632-442d-a531-c52a7e7020fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-f361bfa7-daf3-4e63-ba39-da04466b2bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-f313c970-0848-4ff0-bf38-fd439c336bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-dc61efe7-261a-46ad-81ee-c4f5adc04eff,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-8007295f-7072-44f8-8ef7-26d0a6c110b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 64
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2046866882-172.17.0.4-1596010640476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42582,DS-8627f13c-56ac-4ec8-9614-2ee4d38a8168,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-633f0e7c-c6dd-4206-8236-7e3bc490557d,DISK], DatanodeInfoWithStorage[127.0.0.1:35289,DS-677840fc-3f13-4268-87b0-cc890b805906,DISK], DatanodeInfoWithStorage[127.0.0.1:34355,DS-01baf499-d55e-487a-9bcd-0f12a0c8d18e,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-9d6dac71-7f3f-4bac-8fc6-dd75d9903edb,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-93fc39e7-5d20-49af-bd92-fd460f119a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-29ab1a6d-c2bb-4102-930b-b1f9a753a273,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-6204c758-7dea-4e79-a019-860f931063b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2046866882-172.17.0.4-1596010640476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42582,DS-8627f13c-56ac-4ec8-9614-2ee4d38a8168,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-633f0e7c-c6dd-4206-8236-7e3bc490557d,DISK], DatanodeInfoWithStorage[127.0.0.1:35289,DS-677840fc-3f13-4268-87b0-cc890b805906,DISK], DatanodeInfoWithStorage[127.0.0.1:34355,DS-01baf499-d55e-487a-9bcd-0f12a0c8d18e,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-9d6dac71-7f3f-4bac-8fc6-dd75d9903edb,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-93fc39e7-5d20-49af-bd92-fd460f119a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-29ab1a6d-c2bb-4102-930b-b1f9a753a273,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-6204c758-7dea-4e79-a019-860f931063b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 64
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-673141570-172.17.0.4-1596011394912:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33253,DS-5e4ec48c-871c-4a0a-892c-b9490dc61247,DISK], DatanodeInfoWithStorage[127.0.0.1:39057,DS-116a6411-025f-49da-81cf-f135e20e41a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-48301e40-3fff-45e9-819f-43d36b2e3020,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-eac9187e-a26f-4db7-ba9e-1610cd4df0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-67bce9c8-acd2-4923-9221-48f34f236425,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-f2a419f1-e7be-4420-a55c-4d9870a23a79,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-a1031d45-ec64-4623-b90e-1bc9a32cbdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-cd661e72-99b6-4211-97ee-4acf0dd86e84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-673141570-172.17.0.4-1596011394912:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33253,DS-5e4ec48c-871c-4a0a-892c-b9490dc61247,DISK], DatanodeInfoWithStorage[127.0.0.1:39057,DS-116a6411-025f-49da-81cf-f135e20e41a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-48301e40-3fff-45e9-819f-43d36b2e3020,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-eac9187e-a26f-4db7-ba9e-1610cd4df0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-67bce9c8-acd2-4923-9221-48f34f236425,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-f2a419f1-e7be-4420-a55c-4d9870a23a79,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-a1031d45-ec64-4623-b90e-1bc9a32cbdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-cd661e72-99b6-4211-97ee-4acf0dd86e84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 64
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1275464248-172.17.0.4-1596011433096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44913,DS-f61b33d0-d70c-4e83-ba47-881b51e4b8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34687,DS-ceea5db7-18f5-4454-bf65-a567cce89fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-e44c8c39-5b50-4bab-8c25-f0845b741fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37959,DS-22b8bc1a-2404-4161-9174-c7c2c848d649,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-fa0be455-93fe-47c1-aef7-e432bcfa911d,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-95c9f178-0a60-44ff-846c-30962c358947,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-131fc313-4ee7-4cbe-8d65-cb7354191bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41190,DS-21fd89dd-b3d7-4ee8-94d1-0c0a1f539d3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1275464248-172.17.0.4-1596011433096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44913,DS-f61b33d0-d70c-4e83-ba47-881b51e4b8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34687,DS-ceea5db7-18f5-4454-bf65-a567cce89fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-e44c8c39-5b50-4bab-8c25-f0845b741fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37959,DS-22b8bc1a-2404-4161-9174-c7c2c848d649,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-fa0be455-93fe-47c1-aef7-e432bcfa911d,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-95c9f178-0a60-44ff-846c-30962c358947,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-131fc313-4ee7-4cbe-8d65-cb7354191bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41190,DS-21fd89dd-b3d7-4ee8-94d1-0c0a1f539d3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 64
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1914755749-172.17.0.4-1596012478664:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41125,DS-aa863766-4d30-479e-ae57-dfe3a2a4c42b,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-dc856e9a-03d4-46ed-a904-2700d5b19d96,DISK], DatanodeInfoWithStorage[127.0.0.1:35797,DS-4d740c07-f8a1-4e5d-a4bb-915e7c3eeed8,DISK], DatanodeInfoWithStorage[127.0.0.1:43253,DS-d7ce801b-7f0f-47a6-bdae-544d74360d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-541d96d2-71cb-4abb-95ea-d961b26292eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-7d027034-0140-4efd-b671-3bf22df8abec,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-d9050d62-d7dd-47c9-bd6e-fba19d3a5f64,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-2823e07b-6a9d-4865-a579-fdd768c6db4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1914755749-172.17.0.4-1596012478664:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41125,DS-aa863766-4d30-479e-ae57-dfe3a2a4c42b,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-dc856e9a-03d4-46ed-a904-2700d5b19d96,DISK], DatanodeInfoWithStorage[127.0.0.1:35797,DS-4d740c07-f8a1-4e5d-a4bb-915e7c3eeed8,DISK], DatanodeInfoWithStorage[127.0.0.1:43253,DS-d7ce801b-7f0f-47a6-bdae-544d74360d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-541d96d2-71cb-4abb-95ea-d961b26292eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-7d027034-0140-4efd-b671-3bf22df8abec,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-d9050d62-d7dd-47c9-bd6e-fba19d3a5f64,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-2823e07b-6a9d-4865-a579-fdd768c6db4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 64
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-618363245-172.17.0.4-1596012546711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36334,DS-946d2bb4-d16a-4802-8772-14b6fb030d72,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-4cbdbf0d-d229-4074-a141-5dd4eb3bade0,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-3a3009a1-6d1c-48ee-afb1-f39f6200441f,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-d2997312-29e7-407a-90de-ef16e1b32d19,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-ea364f40-0363-4caa-9fa1-fc6cf063dda2,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-a3138a4e-c4b8-4748-823e-84e712b620a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-ab8ee5ef-5064-4a15-ad87-523c22e9c02c,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-3251bf0f-9b0c-44e9-b264-79ed1d193b80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-618363245-172.17.0.4-1596012546711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36334,DS-946d2bb4-d16a-4802-8772-14b6fb030d72,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-4cbdbf0d-d229-4074-a141-5dd4eb3bade0,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-3a3009a1-6d1c-48ee-afb1-f39f6200441f,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-d2997312-29e7-407a-90de-ef16e1b32d19,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-ea364f40-0363-4caa-9fa1-fc6cf063dda2,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-a3138a4e-c4b8-4748-823e-84e712b620a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-ab8ee5ef-5064-4a15-ad87-523c22e9c02c,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-3251bf0f-9b0c-44e9-b264-79ed1d193b80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 64
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1026120063-172.17.0.4-1596012747804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38496,DS-29d8c3d2-48c6-4bcc-91cf-4eb78f14ba0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-07851afb-f197-41fa-99da-86084c24ebad,DISK], DatanodeInfoWithStorage[127.0.0.1:45355,DS-5bb2203d-ee58-48b7-a15b-46ecf511b28e,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-209454ad-a73d-402a-b226-2015c023870a,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-bccf1089-1d85-4707-b060-764f90d239e4,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-2b48a956-ae4d-40d6-a1e6-ca08824817a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-399f443c-d781-498c-b7cb-57d275d259a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-8ba53a95-d262-4330-a075-b432fae7a476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1026120063-172.17.0.4-1596012747804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38496,DS-29d8c3d2-48c6-4bcc-91cf-4eb78f14ba0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-07851afb-f197-41fa-99da-86084c24ebad,DISK], DatanodeInfoWithStorage[127.0.0.1:45355,DS-5bb2203d-ee58-48b7-a15b-46ecf511b28e,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-209454ad-a73d-402a-b226-2015c023870a,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-bccf1089-1d85-4707-b060-764f90d239e4,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-2b48a956-ae4d-40d6-a1e6-ca08824817a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-399f443c-d781-498c-b7cb-57d275d259a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-8ba53a95-d262-4330-a075-b432fae7a476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5361
