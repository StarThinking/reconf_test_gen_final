reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1443653282-172.17.0.21-1596001998600:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46139,DS-4ff836c7-247f-490f-b2db-2a629a9acca8,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-865bb57b-8078-4fa1-aaf5-8122302dfc09,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-1e22a3c8-dcdf-421f-a59d-e64b897f1b96,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-79f4a9e6-0ff9-42bc-b92b-38a11ca38cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-60a1d7e6-98e4-42d8-a6fb-fd3bd682a6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-9cf74190-d61b-491b-a912-31884e289d43,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-0276f751-4c7d-4838-912a-7fe1037f44ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42828,DS-a54e5ae3-a32b-4182-b84f-3128e7c38f5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1443653282-172.17.0.21-1596001998600:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46139,DS-4ff836c7-247f-490f-b2db-2a629a9acca8,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-865bb57b-8078-4fa1-aaf5-8122302dfc09,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-1e22a3c8-dcdf-421f-a59d-e64b897f1b96,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-79f4a9e6-0ff9-42bc-b92b-38a11ca38cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-60a1d7e6-98e4-42d8-a6fb-fd3bd682a6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-9cf74190-d61b-491b-a912-31884e289d43,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-0276f751-4c7d-4838-912a-7fe1037f44ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42828,DS-a54e5ae3-a32b-4182-b84f-3128e7c38f5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2147446916-172.17.0.21-1596002585521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34014,DS-8c47dafa-ac8c-4022-945b-e734b4ecb761,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-cb164282-7d52-4db9-a05d-194ebc480925,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-0c119a80-9fd5-4f4a-8fee-782b9b6eb932,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-a1346942-ef2c-4fc4-95a0-33d0c9361190,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-c614a593-b379-4f2b-b214-8b0430009dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-1ad4a63f-9769-4932-b6e8-becf02610b55,DISK], DatanodeInfoWithStorage[127.0.0.1:35295,DS-2c0f4f74-a37c-4823-ab73-b2bd1c476b90,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-cdebf2a6-6687-43dc-9fad-ebdb3a4a0c3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2147446916-172.17.0.21-1596002585521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34014,DS-8c47dafa-ac8c-4022-945b-e734b4ecb761,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-cb164282-7d52-4db9-a05d-194ebc480925,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-0c119a80-9fd5-4f4a-8fee-782b9b6eb932,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-a1346942-ef2c-4fc4-95a0-33d0c9361190,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-c614a593-b379-4f2b-b214-8b0430009dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-1ad4a63f-9769-4932-b6e8-becf02610b55,DISK], DatanodeInfoWithStorage[127.0.0.1:35295,DS-2c0f4f74-a37c-4823-ab73-b2bd1c476b90,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-cdebf2a6-6687-43dc-9fad-ebdb3a4a0c3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2069807067-172.17.0.21-1596002689490:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40901,DS-ee0f501a-b6cd-4153-adf8-5074463933e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-a3fbf2c4-6cc7-45c6-afd0-67dc7c7982a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44631,DS-9a76789f-0036-4068-9b14-0d5e0cb8ffcb,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-60fabb49-b114-4b65-81dd-db7ab1068cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-5a4d653d-8ce0-44fe-8c8f-8f4a396bed8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-8a256647-f371-40db-a8fa-5d0f1baded6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-5c9e061b-fbed-45b7-9744-f06d2adddf76,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-eb6d13b3-3383-4523-9f8a-6bd32686c98d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2069807067-172.17.0.21-1596002689490:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40901,DS-ee0f501a-b6cd-4153-adf8-5074463933e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-a3fbf2c4-6cc7-45c6-afd0-67dc7c7982a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44631,DS-9a76789f-0036-4068-9b14-0d5e0cb8ffcb,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-60fabb49-b114-4b65-81dd-db7ab1068cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-5a4d653d-8ce0-44fe-8c8f-8f4a396bed8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-8a256647-f371-40db-a8fa-5d0f1baded6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-5c9e061b-fbed-45b7-9744-f06d2adddf76,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-eb6d13b3-3383-4523-9f8a-6bd32686c98d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-921195141-172.17.0.21-1596003075707:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34628,DS-e6f19f10-419d-4e61-b218-80d17c97079d,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-5911d35a-9e34-4545-81f2-2a2fb7cfe78d,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-a410b0a0-1e3f-45e2-bf56-ea7a13dc5bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-bca7cf64-9d8d-42fa-82ea-a66526c9fe2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-7d08c0c4-c0b3-4d78-8213-94acd2494537,DISK], DatanodeInfoWithStorage[127.0.0.1:43802,DS-a006f4ab-34f2-4f52-b3e9-bf6b133f57ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-7df7d905-f545-4033-b340-4d79265d6197,DISK], DatanodeInfoWithStorage[127.0.0.1:42163,DS-7f8d02da-b4f8-40a8-98bb-523bc0a7e62b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-921195141-172.17.0.21-1596003075707:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34628,DS-e6f19f10-419d-4e61-b218-80d17c97079d,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-5911d35a-9e34-4545-81f2-2a2fb7cfe78d,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-a410b0a0-1e3f-45e2-bf56-ea7a13dc5bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-bca7cf64-9d8d-42fa-82ea-a66526c9fe2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-7d08c0c4-c0b3-4d78-8213-94acd2494537,DISK], DatanodeInfoWithStorage[127.0.0.1:43802,DS-a006f4ab-34f2-4f52-b3e9-bf6b133f57ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-7df7d905-f545-4033-b340-4d79265d6197,DISK], DatanodeInfoWithStorage[127.0.0.1:42163,DS-7f8d02da-b4f8-40a8-98bb-523bc0a7e62b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-512365950-172.17.0.21-1596003296312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46053,DS-405f85d0-b7f8-4ddb-bf64-733a31ca69e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33496,DS-3e15bc17-647b-4cb7-9aa1-ee73c1e0fa62,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-e194e726-9220-4e33-b142-b214ebce8997,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-0447272b-83b5-406c-b35a-16588257fa20,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-c0612b13-2966-4655-ab35-63285d1d940c,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-133bd44e-7ff9-46ee-ae3c-92e7d093ffeb,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-f7ff142e-f487-4c31-9c39-706fd1e47d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-a4cdf58e-dd07-4659-9d31-87667491468d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-512365950-172.17.0.21-1596003296312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46053,DS-405f85d0-b7f8-4ddb-bf64-733a31ca69e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33496,DS-3e15bc17-647b-4cb7-9aa1-ee73c1e0fa62,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-e194e726-9220-4e33-b142-b214ebce8997,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-0447272b-83b5-406c-b35a-16588257fa20,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-c0612b13-2966-4655-ab35-63285d1d940c,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-133bd44e-7ff9-46ee-ae3c-92e7d093ffeb,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-f7ff142e-f487-4c31-9c39-706fd1e47d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-a4cdf58e-dd07-4659-9d31-87667491468d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1291881962-172.17.0.21-1596003441327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37610,DS-ea634cc7-7d2b-4d12-92b6-ed651863110b,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-d6a23fc6-1760-4934-bc3c-98306c172d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-4b736608-5107-4b09-9299-552024ce0e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-32260682-89c4-4ce6-9ed3-be01014031bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41036,DS-faffc428-f849-468a-a9d4-5eab61a1077a,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-91a0fc1f-82d3-4bf7-b093-c672739fa5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39224,DS-113d4b44-f0a4-49bc-9db1-206490403f34,DISK], DatanodeInfoWithStorage[127.0.0.1:46157,DS-f729ff43-c8f2-4c09-aff5-33f4279cea3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1291881962-172.17.0.21-1596003441327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37610,DS-ea634cc7-7d2b-4d12-92b6-ed651863110b,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-d6a23fc6-1760-4934-bc3c-98306c172d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-4b736608-5107-4b09-9299-552024ce0e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-32260682-89c4-4ce6-9ed3-be01014031bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41036,DS-faffc428-f849-468a-a9d4-5eab61a1077a,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-91a0fc1f-82d3-4bf7-b093-c672739fa5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39224,DS-113d4b44-f0a4-49bc-9db1-206490403f34,DISK], DatanodeInfoWithStorage[127.0.0.1:46157,DS-f729ff43-c8f2-4c09-aff5-33f4279cea3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1464312701-172.17.0.21-1596004409291:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35450,DS-906118c9-b8c6-4d9d-8b72-08d24e2d9223,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-f741cb08-3d6d-49f4-b50c-2931ab49304c,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-7d54309a-1bc3-43d7-a1dc-f7706d4362a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39271,DS-93a70cbe-9331-4b9f-b85e-75ac97bdf1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44916,DS-4297b8b4-30e8-4c12-9887-bc3fc5b91843,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-50ffc28a-262b-42db-a662-906ad53e96ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-a42c5d5d-8a9a-4420-a6b7-8c82a5f24dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-2ac875b2-ff01-4b20-9327-bbc5b20e5374,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1464312701-172.17.0.21-1596004409291:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35450,DS-906118c9-b8c6-4d9d-8b72-08d24e2d9223,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-f741cb08-3d6d-49f4-b50c-2931ab49304c,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-7d54309a-1bc3-43d7-a1dc-f7706d4362a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39271,DS-93a70cbe-9331-4b9f-b85e-75ac97bdf1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44916,DS-4297b8b4-30e8-4c12-9887-bc3fc5b91843,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-50ffc28a-262b-42db-a662-906ad53e96ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-a42c5d5d-8a9a-4420-a6b7-8c82a5f24dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-2ac875b2-ff01-4b20-9327-bbc5b20e5374,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-247514395-172.17.0.21-1596004678733:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45360,DS-f4e5e7b3-1994-4d41-8abb-cfb7efeec666,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-900d55bb-e1ab-47ac-a87d-60ba26572c98,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-671d0939-552f-49fe-8138-50b7d60f0a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-45ddd3e1-1202-46d1-bacc-776925754fac,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-54ccdd73-833f-473d-b503-b7f5bef33fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-415676b0-7163-46fd-84a1-c34237715915,DISK], DatanodeInfoWithStorage[127.0.0.1:43262,DS-b7c55b9c-f748-4b10-b4f6-1dc6c2956e51,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-378e8bee-6b05-46ab-8263-012e53cfd5ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-247514395-172.17.0.21-1596004678733:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45360,DS-f4e5e7b3-1994-4d41-8abb-cfb7efeec666,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-900d55bb-e1ab-47ac-a87d-60ba26572c98,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-671d0939-552f-49fe-8138-50b7d60f0a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-45ddd3e1-1202-46d1-bacc-776925754fac,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-54ccdd73-833f-473d-b503-b7f5bef33fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-415676b0-7163-46fd-84a1-c34237715915,DISK], DatanodeInfoWithStorage[127.0.0.1:43262,DS-b7c55b9c-f748-4b10-b4f6-1dc6c2956e51,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-378e8bee-6b05-46ab-8263-012e53cfd5ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-453754911-172.17.0.21-1596004912080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38523,DS-47bfeb6f-5b4e-497d-b7ba-50f156060006,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-41c8980a-32a2-4dc8-8fa8-da2e5f137335,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-4bce01f6-37e8-438c-b7f4-3ce70544c64c,DISK], DatanodeInfoWithStorage[127.0.0.1:45008,DS-98638d23-e61c-410a-9cc4-103659df4627,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-7d19bf7e-f8e9-4842-9254-3fab51b921c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-d543916e-1c86-441e-a9db-e03e34902d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-dbb404cf-c3d8-45b3-8a4a-596dafa30407,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-a8b66035-9d9c-44b8-9e7e-336f9dc2aef0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-453754911-172.17.0.21-1596004912080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38523,DS-47bfeb6f-5b4e-497d-b7ba-50f156060006,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-41c8980a-32a2-4dc8-8fa8-da2e5f137335,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-4bce01f6-37e8-438c-b7f4-3ce70544c64c,DISK], DatanodeInfoWithStorage[127.0.0.1:45008,DS-98638d23-e61c-410a-9cc4-103659df4627,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-7d19bf7e-f8e9-4842-9254-3fab51b921c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-d543916e-1c86-441e-a9db-e03e34902d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-dbb404cf-c3d8-45b3-8a4a-596dafa30407,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-a8b66035-9d9c-44b8-9e7e-336f9dc2aef0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-105642265-172.17.0.21-1596004947640:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37349,DS-9fbc3010-fedb-44ae-a27c-2e3b4df956eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-ee8f87b6-8ba2-4f48-a459-6374be775bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-c869c284-7582-4bae-8e0a-bbe5941ace5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-40044fed-b713-4c4b-826f-65d7273bc7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-f59aefa5-48c9-431a-905b-7a8a4dd9f156,DISK], DatanodeInfoWithStorage[127.0.0.1:38190,DS-c0e363d6-5edd-4151-b7e1-88b7a811570b,DISK], DatanodeInfoWithStorage[127.0.0.1:33171,DS-b7f14635-30dd-418c-be84-40a356c2d19a,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-1a0cf224-14ec-47d6-b4fc-2aa583635642,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-105642265-172.17.0.21-1596004947640:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37349,DS-9fbc3010-fedb-44ae-a27c-2e3b4df956eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-ee8f87b6-8ba2-4f48-a459-6374be775bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-c869c284-7582-4bae-8e0a-bbe5941ace5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-40044fed-b713-4c4b-826f-65d7273bc7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-f59aefa5-48c9-431a-905b-7a8a4dd9f156,DISK], DatanodeInfoWithStorage[127.0.0.1:38190,DS-c0e363d6-5edd-4151-b7e1-88b7a811570b,DISK], DatanodeInfoWithStorage[127.0.0.1:33171,DS-b7f14635-30dd-418c-be84-40a356c2d19a,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-1a0cf224-14ec-47d6-b4fc-2aa583635642,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-818012858-172.17.0.21-1596005084557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35004,DS-a2a4e61f-5285-433d-8e84-843bcb81b6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-de0274ef-66bd-4cd4-839e-6abd617eeb2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-89b22e36-60f0-4630-970a-9ea1ff7a0a84,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-1a1b4813-5187-4f6d-8cdd-83fbb0a37714,DISK], DatanodeInfoWithStorage[127.0.0.1:39619,DS-d1e08f67-2660-47e0-b8a4-8521d885f3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-7834969f-2a9d-4104-85ad-21d67e7f1c74,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-5879479d-5e06-40b9-9788-9a39170d318f,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-8c20c1cc-38ba-48ca-ae27-3612c9ff6e13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-818012858-172.17.0.21-1596005084557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35004,DS-a2a4e61f-5285-433d-8e84-843bcb81b6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-de0274ef-66bd-4cd4-839e-6abd617eeb2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-89b22e36-60f0-4630-970a-9ea1ff7a0a84,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-1a1b4813-5187-4f6d-8cdd-83fbb0a37714,DISK], DatanodeInfoWithStorage[127.0.0.1:39619,DS-d1e08f67-2660-47e0-b8a4-8521d885f3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-7834969f-2a9d-4104-85ad-21d67e7f1c74,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-5879479d-5e06-40b9-9788-9a39170d318f,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-8c20c1cc-38ba-48ca-ae27-3612c9ff6e13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1834733584-172.17.0.21-1596005525258:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45264,DS-bcb5f51e-113a-4078-86f1-bdf94a0e92b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-492dff5a-f227-4836-9ff3-19cecb6f463c,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-601e6db1-4c73-4407-b2e0-ab794616b72d,DISK], DatanodeInfoWithStorage[127.0.0.1:46582,DS-5a8e4739-4401-4bf7-ba3a-1ec0d231a6de,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-2c0bc390-43d6-416a-b366-c09b76a615fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-4ba4d5b7-4104-434f-9ad5-c75a8d2d212f,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-b75ad8f0-204d-4325-a216-1f8cc84b76be,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-a264e637-91da-4ab2-ba90-a96786bda016,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1834733584-172.17.0.21-1596005525258:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45264,DS-bcb5f51e-113a-4078-86f1-bdf94a0e92b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-492dff5a-f227-4836-9ff3-19cecb6f463c,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-601e6db1-4c73-4407-b2e0-ab794616b72d,DISK], DatanodeInfoWithStorage[127.0.0.1:46582,DS-5a8e4739-4401-4bf7-ba3a-1ec0d231a6de,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-2c0bc390-43d6-416a-b366-c09b76a615fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-4ba4d5b7-4104-434f-9ad5-c75a8d2d212f,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-b75ad8f0-204d-4325-a216-1f8cc84b76be,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-a264e637-91da-4ab2-ba90-a96786bda016,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-337882923-172.17.0.21-1596005600990:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38673,DS-a575eaae-7af1-45e3-b575-a04f63b4e0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-09bcb557-6048-4a24-af1a-2664d229eb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-91004a06-e6e9-4a23-8acf-774823f66932,DISK], DatanodeInfoWithStorage[127.0.0.1:37992,DS-6db5275f-f972-443d-903c-870222adb1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-ae50f2ed-ba38-41fe-a6e8-28738a9a8a16,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-6f1896a9-3f12-4263-a925-b08de0b963d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34925,DS-d6b712f7-9d1f-4ae5-9d47-8e6ab509763f,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-1b7e9671-2ab9-48ae-97dc-30fb34530819,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-337882923-172.17.0.21-1596005600990:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38673,DS-a575eaae-7af1-45e3-b575-a04f63b4e0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-09bcb557-6048-4a24-af1a-2664d229eb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-91004a06-e6e9-4a23-8acf-774823f66932,DISK], DatanodeInfoWithStorage[127.0.0.1:37992,DS-6db5275f-f972-443d-903c-870222adb1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-ae50f2ed-ba38-41fe-a6e8-28738a9a8a16,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-6f1896a9-3f12-4263-a925-b08de0b963d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34925,DS-d6b712f7-9d1f-4ae5-9d47-8e6ab509763f,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-1b7e9671-2ab9-48ae-97dc-30fb34530819,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-221004835-172.17.0.21-1596005768288:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34046,DS-bf4caec8-2bf3-44f8-8410-f00022a1cb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-03869723-0361-4f83-83a8-3488e84fa17e,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-7e2e1680-f9a2-4402-815c-becd2c23cc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-76129ff1-baf5-4018-9434-0dfb6354ef05,DISK], DatanodeInfoWithStorage[127.0.0.1:42968,DS-6655ebb0-c8e3-4fb5-bf42-f37874fbc38e,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-3672d263-ab60-4379-aa80-5089871cb703,DISK], DatanodeInfoWithStorage[127.0.0.1:36049,DS-1a31e14f-e395-444f-8d70-30f9d511a5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-b06ffd9d-e8f5-4d19-b0d7-d078da5e7330,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-221004835-172.17.0.21-1596005768288:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34046,DS-bf4caec8-2bf3-44f8-8410-f00022a1cb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-03869723-0361-4f83-83a8-3488e84fa17e,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-7e2e1680-f9a2-4402-815c-becd2c23cc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-76129ff1-baf5-4018-9434-0dfb6354ef05,DISK], DatanodeInfoWithStorage[127.0.0.1:42968,DS-6655ebb0-c8e3-4fb5-bf42-f37874fbc38e,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-3672d263-ab60-4379-aa80-5089871cb703,DISK], DatanodeInfoWithStorage[127.0.0.1:36049,DS-1a31e14f-e395-444f-8d70-30f9d511a5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-b06ffd9d-e8f5-4d19-b0d7-d078da5e7330,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-596590708-172.17.0.21-1596005834724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37093,DS-70d4ef82-f082-426e-976f-fea3d1161e15,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-d954219a-982d-4fda-a379-f77c55e402db,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-45a31d27-2112-4f30-b816-9b66de10f393,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-d58cd91c-b17e-4c37-af87-52530360fa87,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-afdbd166-4977-4879-a05d-e48ce675d7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-530743eb-d2ab-4075-9e73-5700df220118,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-3967d48d-0140-4c1a-8ee4-bbb6bdb31da8,DISK], DatanodeInfoWithStorage[127.0.0.1:46004,DS-3da61058-0564-4e33-9e2b-4d9c4eae2068,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-596590708-172.17.0.21-1596005834724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37093,DS-70d4ef82-f082-426e-976f-fea3d1161e15,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-d954219a-982d-4fda-a379-f77c55e402db,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-45a31d27-2112-4f30-b816-9b66de10f393,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-d58cd91c-b17e-4c37-af87-52530360fa87,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-afdbd166-4977-4879-a05d-e48ce675d7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-530743eb-d2ab-4075-9e73-5700df220118,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-3967d48d-0140-4c1a-8ee4-bbb6bdb31da8,DISK], DatanodeInfoWithStorage[127.0.0.1:46004,DS-3da61058-0564-4e33-9e2b-4d9c4eae2068,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-719044843-172.17.0.21-1596006274220:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39064,DS-d2b9796b-7d7d-4234-9269-5c0f8d75644a,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-df487bde-012e-44f4-ad1c-77dd17327ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-3b5e45a2-bdb1-4b68-be91-6271069a4a29,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-0858cdae-858c-4f58-b650-e773f210fe68,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-0fa207c9-9662-42d3-be8d-3368769c5909,DISK], DatanodeInfoWithStorage[127.0.0.1:41391,DS-4f87c03a-f805-425f-a698-b0bd5dad9601,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-da7f3dc7-ba84-4daa-864b-219f731ce489,DISK], DatanodeInfoWithStorage[127.0.0.1:33835,DS-4150193b-f45c-48cd-8298-a2b4dd2b787d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-719044843-172.17.0.21-1596006274220:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39064,DS-d2b9796b-7d7d-4234-9269-5c0f8d75644a,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-df487bde-012e-44f4-ad1c-77dd17327ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-3b5e45a2-bdb1-4b68-be91-6271069a4a29,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-0858cdae-858c-4f58-b650-e773f210fe68,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-0fa207c9-9662-42d3-be8d-3368769c5909,DISK], DatanodeInfoWithStorage[127.0.0.1:41391,DS-4f87c03a-f805-425f-a698-b0bd5dad9601,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-da7f3dc7-ba84-4daa-864b-219f731ce489,DISK], DatanodeInfoWithStorage[127.0.0.1:33835,DS-4150193b-f45c-48cd-8298-a2b4dd2b787d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-601824947-172.17.0.21-1596006312501:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38901,DS-ed26a217-8870-43bd-ad48-45d68e1f36f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-f8ad425b-bbf6-45d3-84ac-d3664149584b,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-c185a4ca-26b9-427e-806c-a7812c9e713b,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-948c3bb0-5dc6-4870-b375-e63252d12db6,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-abf4fc74-ab89-4568-abca-86eebce553cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-65684306-5809-470a-8b57-3454490eb7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-1d1ef714-9429-4c4f-93cd-bea890f30302,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-df6c854c-2220-409b-8810-804b1646745f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-601824947-172.17.0.21-1596006312501:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38901,DS-ed26a217-8870-43bd-ad48-45d68e1f36f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-f8ad425b-bbf6-45d3-84ac-d3664149584b,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-c185a4ca-26b9-427e-806c-a7812c9e713b,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-948c3bb0-5dc6-4870-b375-e63252d12db6,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-abf4fc74-ab89-4568-abca-86eebce553cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-65684306-5809-470a-8b57-3454490eb7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-1d1ef714-9429-4c4f-93cd-bea890f30302,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-df6c854c-2220-409b-8810-804b1646745f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-4496080-172.17.0.21-1596006349603:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39314,DS-2415cbb6-9772-4d2e-b91f-8c7520f35dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-9894a212-d4f2-482a-8f0f-3fa396848f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-0a653946-db7d-413f-babb-f1e1d182c01d,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-56c8360d-226f-4e82-bfa0-17329677613c,DISK], DatanodeInfoWithStorage[127.0.0.1:42327,DS-3ce01de7-6e67-4f18-b830-2d74abd77c05,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-73b9fa42-7cf2-426f-9d09-18154f11609e,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-22ad93e3-c0b3-4498-a780-e2b6d3b0157f,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-4ba1b1a1-9328-4fe3-9bee-13bcb7737842,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-4496080-172.17.0.21-1596006349603:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39314,DS-2415cbb6-9772-4d2e-b91f-8c7520f35dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-9894a212-d4f2-482a-8f0f-3fa396848f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-0a653946-db7d-413f-babb-f1e1d182c01d,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-56c8360d-226f-4e82-bfa0-17329677613c,DISK], DatanodeInfoWithStorage[127.0.0.1:42327,DS-3ce01de7-6e67-4f18-b830-2d74abd77c05,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-73b9fa42-7cf2-426f-9d09-18154f11609e,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-22ad93e3-c0b3-4498-a780-e2b6d3b0157f,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-4ba1b1a1-9328-4fe3-9bee-13bcb7737842,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-402588422-172.17.0.21-1596006630985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33794,DS-2a785f8e-1906-4e94-93bd-cf223bfc0f07,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-70ad94e2-c36f-424a-804b-84853b9a5772,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-e3591308-9224-4420-83c3-208a62d87a87,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-2f62d842-aece-4916-b180-c53e53808b73,DISK], DatanodeInfoWithStorage[127.0.0.1:40449,DS-945f7829-3e2f-4cea-a3c7-e93b51b66d45,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-46572a4c-80db-4a9e-8040-b9353bee0e79,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-5edeb862-5e7c-4450-abe9-2fd388625675,DISK], DatanodeInfoWithStorage[127.0.0.1:35878,DS-64cf997b-eac9-4ae6-9ef0-a6388fe573d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-402588422-172.17.0.21-1596006630985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33794,DS-2a785f8e-1906-4e94-93bd-cf223bfc0f07,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-70ad94e2-c36f-424a-804b-84853b9a5772,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-e3591308-9224-4420-83c3-208a62d87a87,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-2f62d842-aece-4916-b180-c53e53808b73,DISK], DatanodeInfoWithStorage[127.0.0.1:40449,DS-945f7829-3e2f-4cea-a3c7-e93b51b66d45,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-46572a4c-80db-4a9e-8040-b9353bee0e79,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-5edeb862-5e7c-4450-abe9-2fd388625675,DISK], DatanodeInfoWithStorage[127.0.0.1:35878,DS-64cf997b-eac9-4ae6-9ef0-a6388fe573d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-539213156-172.17.0.21-1596006867487:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45413,DS-ecf4a49a-bc29-4cc7-bb9a-9e24f2ef18f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-e8db32f1-2a07-4717-8ed9-4b8c251c509a,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-635a5705-cada-46cf-a450-781e7abf9598,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-a25ebcae-4c4f-4a99-91a8-79828da4b651,DISK], DatanodeInfoWithStorage[127.0.0.1:42075,DS-b5774f45-29e3-4e57-a059-9a1ab6752be4,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-bdaee386-f2a8-4190-9569-1edb157e0ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-fbe45446-9049-482b-a211-22c6df788968,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-ccfb949a-2325-4b59-b556-d392f3d9a1d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-539213156-172.17.0.21-1596006867487:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45413,DS-ecf4a49a-bc29-4cc7-bb9a-9e24f2ef18f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-e8db32f1-2a07-4717-8ed9-4b8c251c509a,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-635a5705-cada-46cf-a450-781e7abf9598,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-a25ebcae-4c4f-4a99-91a8-79828da4b651,DISK], DatanodeInfoWithStorage[127.0.0.1:42075,DS-b5774f45-29e3-4e57-a059-9a1ab6752be4,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-bdaee386-f2a8-4190-9569-1edb157e0ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-fbe45446-9049-482b-a211-22c6df788968,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-ccfb949a-2325-4b59-b556-d392f3d9a1d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-592183355-172.17.0.21-1596007195714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34334,DS-5666c240-7599-4d98-8528-65c2ac206cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-1ccd96e2-3501-40d1-ba7b-fae17b1a153e,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-ddd8163a-d481-45da-ade0-8409c95e907f,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-fa8bde63-74f0-4c64-bc8b-9cde3dc55b13,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-7895edd2-34e5-4db3-97c9-86782be10c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-6e0c8d1a-8768-4474-b9f6-41d5f734ca7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-7ffb2326-8114-4d5a-988e-437be70f9358,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-da8d9eeb-dd76-4d7d-8c0f-4ffaa4111bce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-592183355-172.17.0.21-1596007195714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34334,DS-5666c240-7599-4d98-8528-65c2ac206cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-1ccd96e2-3501-40d1-ba7b-fae17b1a153e,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-ddd8163a-d481-45da-ade0-8409c95e907f,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-fa8bde63-74f0-4c64-bc8b-9cde3dc55b13,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-7895edd2-34e5-4db3-97c9-86782be10c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-6e0c8d1a-8768-4474-b9f6-41d5f734ca7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-7ffb2326-8114-4d5a-988e-437be70f9358,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-da8d9eeb-dd76-4d7d-8c0f-4ffaa4111bce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2022381366-172.17.0.21-1596007274652:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45407,DS-513a2984-3e67-40f0-a140-180d238f3845,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-a6a5f6d9-5cb3-4d04-89dd-be55174502b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46233,DS-9f307ffb-620f-4f74-bd13-dd9be545f577,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-ad445857-c8f5-42f1-bd1b-7029552e25ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-7c43b1e5-6852-4a7b-b3ee-e831b73d6d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-bd1423e4-be06-4326-96d5-1247b1add566,DISK], DatanodeInfoWithStorage[127.0.0.1:41162,DS-a40ac04f-1353-4800-b25a-0ffb8f1da0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38041,DS-d005954a-60d0-439b-9b35-8e91a428f8ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2022381366-172.17.0.21-1596007274652:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45407,DS-513a2984-3e67-40f0-a140-180d238f3845,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-a6a5f6d9-5cb3-4d04-89dd-be55174502b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46233,DS-9f307ffb-620f-4f74-bd13-dd9be545f577,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-ad445857-c8f5-42f1-bd1b-7029552e25ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-7c43b1e5-6852-4a7b-b3ee-e831b73d6d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-bd1423e4-be06-4326-96d5-1247b1add566,DISK], DatanodeInfoWithStorage[127.0.0.1:41162,DS-a40ac04f-1353-4800-b25a-0ffb8f1da0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38041,DS-d005954a-60d0-439b-9b35-8e91a428f8ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1812634195-172.17.0.21-1596007316116:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34422,DS-07bb39b8-c3c9-49ae-b051-0bea47be6f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41798,DS-995a4f57-b106-47a8-9337-fe08eead7533,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-67b5bdc1-ee8d-4404-acd8-bd914d065e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-1893a6f3-2a43-4351-a73c-1a837ead7ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-efc8c332-f3f4-4f96-b4f2-a6bfe8d9717d,DISK], DatanodeInfoWithStorage[127.0.0.1:41868,DS-eb9a5d75-e61f-48f0-87b0-3f2f4162e3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-366015cd-7c50-4195-95d7-a098deff5da5,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-4e1a36f1-32b2-498f-a1fa-a89cd84be8a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1812634195-172.17.0.21-1596007316116:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34422,DS-07bb39b8-c3c9-49ae-b051-0bea47be6f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41798,DS-995a4f57-b106-47a8-9337-fe08eead7533,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-67b5bdc1-ee8d-4404-acd8-bd914d065e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-1893a6f3-2a43-4351-a73c-1a837ead7ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-efc8c332-f3f4-4f96-b4f2-a6bfe8d9717d,DISK], DatanodeInfoWithStorage[127.0.0.1:41868,DS-eb9a5d75-e61f-48f0-87b0-3f2f4162e3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-366015cd-7c50-4195-95d7-a098deff5da5,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-4e1a36f1-32b2-498f-a1fa-a89cd84be8a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5396
