reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2052986419-172.17.0.13-1595492629947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37643,DS-8a99a2f6-68df-40b8-acfa-99bdb3ba4e50,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-e8aec3bd-6976-44c0-8cee-3505c7c78a05,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-4162d1b3-3445-476e-93a9-7a48d0d8bc0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-87397337-be8d-48e7-88f4-0325b358c6c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45487,DS-42d1c16b-0b88-4373-87cf-c509a916b0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41485,DS-f1773476-5d7b-49fa-af49-97aa362d990d,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-60485b90-52b8-4c78-b15d-7fda3224f3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-ebeb40d3-c7c7-4ca8-9d2c-5c9a2cccc04c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2052986419-172.17.0.13-1595492629947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37643,DS-8a99a2f6-68df-40b8-acfa-99bdb3ba4e50,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-e8aec3bd-6976-44c0-8cee-3505c7c78a05,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-4162d1b3-3445-476e-93a9-7a48d0d8bc0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-87397337-be8d-48e7-88f4-0325b358c6c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45487,DS-42d1c16b-0b88-4373-87cf-c509a916b0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41485,DS-f1773476-5d7b-49fa-af49-97aa362d990d,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-60485b90-52b8-4c78-b15d-7fda3224f3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-ebeb40d3-c7c7-4ca8-9d2c-5c9a2cccc04c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1202670158-172.17.0.13-1595492813444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46322,DS-7fd753ce-273a-48b9-beb7-f58bd625631f,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-185e5fd1-bf24-4534-89f4-cc952b9f7e68,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-ddb67ab3-e824-4ef9-9841-0c312e81e74b,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-b0832c48-d50e-4eab-a850-1d46cd7ce7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33022,DS-61864faa-ad66-4e14-b701-e296a1ebe9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-b0bc9f17-eeb1-430e-8a57-d334f9ac8ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-f5c95742-7acd-4dc9-a52e-0f4cfe702c38,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-9480abca-c233-4b6d-bae5-d0b8826b06cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1202670158-172.17.0.13-1595492813444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46322,DS-7fd753ce-273a-48b9-beb7-f58bd625631f,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-185e5fd1-bf24-4534-89f4-cc952b9f7e68,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-ddb67ab3-e824-4ef9-9841-0c312e81e74b,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-b0832c48-d50e-4eab-a850-1d46cd7ce7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33022,DS-61864faa-ad66-4e14-b701-e296a1ebe9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-b0bc9f17-eeb1-430e-8a57-d334f9ac8ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-f5c95742-7acd-4dc9-a52e-0f4cfe702c38,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-9480abca-c233-4b6d-bae5-d0b8826b06cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-835639439-172.17.0.13-1595493401947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44347,DS-ef2dd146-a483-4166-bee8-6308d9853c88,DISK], DatanodeInfoWithStorage[127.0.0.1:33605,DS-9831dbf7-51ca-4410-8925-a0dea448bac6,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-394740b5-aae2-4c45-9edb-77d2fe0c36d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-ad7057ad-91e2-41bc-b748-dbd63fb029d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36454,DS-cfc9b055-6228-46a5-90a2-6d035d0fea3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-242c45e3-5bb7-4529-9a8b-d6a4d8ccb960,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-d4d1d2d4-adda-4890-90c4-a6aafbad8bce,DISK], DatanodeInfoWithStorage[127.0.0.1:36835,DS-47764cf7-b22f-449b-b531-e6652557d354,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-835639439-172.17.0.13-1595493401947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44347,DS-ef2dd146-a483-4166-bee8-6308d9853c88,DISK], DatanodeInfoWithStorage[127.0.0.1:33605,DS-9831dbf7-51ca-4410-8925-a0dea448bac6,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-394740b5-aae2-4c45-9edb-77d2fe0c36d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-ad7057ad-91e2-41bc-b748-dbd63fb029d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36454,DS-cfc9b055-6228-46a5-90a2-6d035d0fea3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-242c45e3-5bb7-4529-9a8b-d6a4d8ccb960,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-d4d1d2d4-adda-4890-90c4-a6aafbad8bce,DISK], DatanodeInfoWithStorage[127.0.0.1:36835,DS-47764cf7-b22f-449b-b531-e6652557d354,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2131211104-172.17.0.13-1595493588377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39750,DS-3ae2f3c4-f5a0-48fe-89ee-1d0a2f726f70,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-ffd29ebe-df8c-4319-886c-907d3be6e32a,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-908c6277-8103-4049-bd29-9565d2e53795,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-412427c9-abf9-4069-a991-aae1d27d1a09,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-a24de5f3-9d48-4556-b6d7-ab65cd1f4610,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-4670c9a7-2d58-41da-91b3-bad57672d82c,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-b60a6ba9-90bb-41e4-9f5e-e9d3ce5b2924,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-7eac12dd-272f-4ddb-9dc1-4e29dc07cb5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2131211104-172.17.0.13-1595493588377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39750,DS-3ae2f3c4-f5a0-48fe-89ee-1d0a2f726f70,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-ffd29ebe-df8c-4319-886c-907d3be6e32a,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-908c6277-8103-4049-bd29-9565d2e53795,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-412427c9-abf9-4069-a991-aae1d27d1a09,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-a24de5f3-9d48-4556-b6d7-ab65cd1f4610,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-4670c9a7-2d58-41da-91b3-bad57672d82c,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-b60a6ba9-90bb-41e4-9f5e-e9d3ce5b2924,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-7eac12dd-272f-4ddb-9dc1-4e29dc07cb5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2095372566-172.17.0.13-1595494405990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43131,DS-cb621ca5-2338-44a3-9edb-2885a19a8a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-b4bb2b95-21e4-4df5-be97-e81840751452,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-7a0734f2-0d6a-4431-a09b-e4bf3aba3159,DISK], DatanodeInfoWithStorage[127.0.0.1:39652,DS-6b39e487-27b3-4d42-879a-359a98c6ea5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-e6b5b624-c1bd-4a78-8fc1-0097a0e303be,DISK], DatanodeInfoWithStorage[127.0.0.1:45747,DS-6c22f595-c1e6-4ca1-b6f3-31d50b23260b,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-606b1cf8-10d5-4063-a397-8d1e5432c2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40761,DS-f9b04b2b-1354-4fb5-b52a-74dfc7828b82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2095372566-172.17.0.13-1595494405990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43131,DS-cb621ca5-2338-44a3-9edb-2885a19a8a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-b4bb2b95-21e4-4df5-be97-e81840751452,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-7a0734f2-0d6a-4431-a09b-e4bf3aba3159,DISK], DatanodeInfoWithStorage[127.0.0.1:39652,DS-6b39e487-27b3-4d42-879a-359a98c6ea5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-e6b5b624-c1bd-4a78-8fc1-0097a0e303be,DISK], DatanodeInfoWithStorage[127.0.0.1:45747,DS-6c22f595-c1e6-4ca1-b6f3-31d50b23260b,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-606b1cf8-10d5-4063-a397-8d1e5432c2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40761,DS-f9b04b2b-1354-4fb5-b52a-74dfc7828b82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1833084867-172.17.0.13-1595494437847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46126,DS-310580e8-8043-4ae4-be55-f60036bde0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-4cc6d444-ec9d-4c22-8294-3c0d03e153fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-1139e0bd-9c06-4572-9a98-0174d33820a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41162,DS-cb03fe1b-cde1-4a34-b5fe-d4bf03a29f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-19093682-0687-4dd8-af6b-d9b8378e5e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-c72a2dc0-3d62-4a12-9625-bf180b9dfb52,DISK], DatanodeInfoWithStorage[127.0.0.1:34949,DS-365db578-a822-4da2-a41b-d728f2859827,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-2f7a9c3d-1350-4328-bcc1-0ee7e2112d06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1833084867-172.17.0.13-1595494437847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46126,DS-310580e8-8043-4ae4-be55-f60036bde0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-4cc6d444-ec9d-4c22-8294-3c0d03e153fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-1139e0bd-9c06-4572-9a98-0174d33820a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41162,DS-cb03fe1b-cde1-4a34-b5fe-d4bf03a29f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-19093682-0687-4dd8-af6b-d9b8378e5e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-c72a2dc0-3d62-4a12-9625-bf180b9dfb52,DISK], DatanodeInfoWithStorage[127.0.0.1:34949,DS-365db578-a822-4da2-a41b-d728f2859827,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-2f7a9c3d-1350-4328-bcc1-0ee7e2112d06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-971137649-172.17.0.13-1595494998965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38195,DS-aaa04412-bf22-4e5a-a5a5-44a97be64001,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-141b1cbe-80db-4e08-a440-015bf5f9a35d,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-37eb7bca-362d-4eb0-addc-ca0028ca1090,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-32868015-d506-4cbb-a1a8-bd49f8d37db8,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-f86b05e8-7695-4f93-9196-3720dacc0085,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-fbd89eb6-3eb9-4d7c-a0e5-ce4a4bcfb1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-980d4d3f-f682-4255-b214-858ecb238e07,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-23718985-f140-4293-84a2-ba362f0ec26c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-971137649-172.17.0.13-1595494998965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38195,DS-aaa04412-bf22-4e5a-a5a5-44a97be64001,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-141b1cbe-80db-4e08-a440-015bf5f9a35d,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-37eb7bca-362d-4eb0-addc-ca0028ca1090,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-32868015-d506-4cbb-a1a8-bd49f8d37db8,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-f86b05e8-7695-4f93-9196-3720dacc0085,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-fbd89eb6-3eb9-4d7c-a0e5-ce4a4bcfb1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-980d4d3f-f682-4255-b214-858ecb238e07,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-23718985-f140-4293-84a2-ba362f0ec26c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-671336223-172.17.0.13-1595495033421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38117,DS-d4537fdd-c9c3-44ea-8cb4-02b0b632da82,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-1c5d10ef-f2e4-4729-9ea0-ede102d83537,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-611a2696-d34b-4ffd-8ab8-097ad666f360,DISK], DatanodeInfoWithStorage[127.0.0.1:39613,DS-1a047ff1-c573-42b7-b6f9-a37b7f2ba45b,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-500480ba-e14b-44f4-a09d-eb8d1d1906aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-dfaab6e4-9d60-4676-a783-66a65aae5615,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-66f89ca9-f07d-4bc0-999b-4244d3e5e14a,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-76958451-d9ab-4e12-b739-0a3887b8d8b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-671336223-172.17.0.13-1595495033421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38117,DS-d4537fdd-c9c3-44ea-8cb4-02b0b632da82,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-1c5d10ef-f2e4-4729-9ea0-ede102d83537,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-611a2696-d34b-4ffd-8ab8-097ad666f360,DISK], DatanodeInfoWithStorage[127.0.0.1:39613,DS-1a047ff1-c573-42b7-b6f9-a37b7f2ba45b,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-500480ba-e14b-44f4-a09d-eb8d1d1906aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-dfaab6e4-9d60-4676-a783-66a65aae5615,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-66f89ca9-f07d-4bc0-999b-4244d3e5e14a,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-76958451-d9ab-4e12-b739-0a3887b8d8b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1085630309-172.17.0.13-1595495681686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35539,DS-f8446374-dc2b-48f3-80b3-a33b6c1d01e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-c7e22dae-f4f6-4dc8-843a-341ef0abbac4,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-bf303793-41b7-4907-a979-b0894406785c,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-69acb96e-b0c3-4f55-bcc3-8729a2cd9196,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-02873b88-dbb2-41b5-8d14-d2f573c311ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34788,DS-61d82538-4fe4-4609-a33e-a2ebb4d0f765,DISK], DatanodeInfoWithStorage[127.0.0.1:44777,DS-f91e7bec-19b7-4f0f-bdd9-2f8546a0b57f,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-7edfc876-79bc-4ecd-9aa3-0b3c428e8a80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1085630309-172.17.0.13-1595495681686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35539,DS-f8446374-dc2b-48f3-80b3-a33b6c1d01e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-c7e22dae-f4f6-4dc8-843a-341ef0abbac4,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-bf303793-41b7-4907-a979-b0894406785c,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-69acb96e-b0c3-4f55-bcc3-8729a2cd9196,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-02873b88-dbb2-41b5-8d14-d2f573c311ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34788,DS-61d82538-4fe4-4609-a33e-a2ebb4d0f765,DISK], DatanodeInfoWithStorage[127.0.0.1:44777,DS-f91e7bec-19b7-4f0f-bdd9-2f8546a0b57f,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-7edfc876-79bc-4ecd-9aa3-0b3c428e8a80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2066543661-172.17.0.13-1595495931272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41948,DS-30d584de-0bd2-4466-b014-cd9066304511,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-caabd3cd-495c-4bae-8bd4-17c9d5c7f350,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-8f88ec31-25ec-467a-9aae-d9dd36e721f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-78d33b19-8412-45b4-b91f-a18f3c5fbf61,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-ae8e0b68-bf60-49bf-aeaf-14efd182c532,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-8f2fe285-5cce-4792-85ac-940f7a42edc4,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-0f41f6a8-440b-4a8f-b275-5e2ef6c21194,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-05fba7b9-b7ad-4167-a424-5d18ff2de020,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2066543661-172.17.0.13-1595495931272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41948,DS-30d584de-0bd2-4466-b014-cd9066304511,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-caabd3cd-495c-4bae-8bd4-17c9d5c7f350,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-8f88ec31-25ec-467a-9aae-d9dd36e721f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-78d33b19-8412-45b4-b91f-a18f3c5fbf61,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-ae8e0b68-bf60-49bf-aeaf-14efd182c532,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-8f2fe285-5cce-4792-85ac-940f7a42edc4,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-0f41f6a8-440b-4a8f-b275-5e2ef6c21194,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-05fba7b9-b7ad-4167-a424-5d18ff2de020,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-762036760-172.17.0.13-1595496032454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44496,DS-d98d47c7-1bba-40f4-b913-ec1636192ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:42614,DS-7eb1c9bf-dcd4-4bba-8f3c-6f303c77f95a,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-808be11d-cd53-4523-8b24-c97fbdfc2f84,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-375a1504-3f70-44ac-8ee7-805a768af8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-9de1fe5b-530b-44cd-bfbd-20c7ca9505b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-f6a46abe-5fe8-464d-afa2-b9caf49aa19c,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-cfe7cb53-59da-474f-ae21-06b1e5043a35,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-f079fca8-c2f7-4bc8-9594-4101b6b0ba54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-762036760-172.17.0.13-1595496032454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44496,DS-d98d47c7-1bba-40f4-b913-ec1636192ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:42614,DS-7eb1c9bf-dcd4-4bba-8f3c-6f303c77f95a,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-808be11d-cd53-4523-8b24-c97fbdfc2f84,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-375a1504-3f70-44ac-8ee7-805a768af8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-9de1fe5b-530b-44cd-bfbd-20c7ca9505b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-f6a46abe-5fe8-464d-afa2-b9caf49aa19c,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-cfe7cb53-59da-474f-ae21-06b1e5043a35,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-f079fca8-c2f7-4bc8-9594-4101b6b0ba54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-877864778-172.17.0.13-1595496388332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40623,DS-78fd24ec-9acc-4bf6-b559-4d847686b960,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-77da1308-f3c2-405f-bcc7-461ad073a3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35647,DS-60239018-4c41-497c-bf9b-4ed21b4fdf8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-690298f7-9c5d-41d1-83cd-cadda128b936,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-9d26c742-c917-4e03-a34f-560a334dce70,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-dfb27ca7-5dd0-4c40-bd34-972f32e0f392,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-186470e7-370b-4aa7-a310-64215b90477c,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-59a1b683-659f-4258-91e6-fa6244491436,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-877864778-172.17.0.13-1595496388332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40623,DS-78fd24ec-9acc-4bf6-b559-4d847686b960,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-77da1308-f3c2-405f-bcc7-461ad073a3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35647,DS-60239018-4c41-497c-bf9b-4ed21b4fdf8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-690298f7-9c5d-41d1-83cd-cadda128b936,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-9d26c742-c917-4e03-a34f-560a334dce70,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-dfb27ca7-5dd0-4c40-bd34-972f32e0f392,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-186470e7-370b-4aa7-a310-64215b90477c,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-59a1b683-659f-4258-91e6-fa6244491436,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-538875716-172.17.0.13-1595496466336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33915,DS-b7f57478-9780-43ea-9d4c-aee8b6ecaf35,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-f772d089-cadb-41a8-be82-9b36f2e94c38,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-80cb22f3-4c2e-4bf7-b1d9-06e3ac6f5618,DISK], DatanodeInfoWithStorage[127.0.0.1:34513,DS-908c8af8-8424-4724-b335-4b755dd3e42a,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-d24994c0-2203-4a52-b656-b6c00040762f,DISK], DatanodeInfoWithStorage[127.0.0.1:39487,DS-c38b35af-2eab-4ea4-a8fa-d7aa9b5d70af,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-6e6e3c92-a429-4897-bbc6-d4106a900091,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-ce8978bb-8b0a-42dc-a1fc-d42efb580506,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-538875716-172.17.0.13-1595496466336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33915,DS-b7f57478-9780-43ea-9d4c-aee8b6ecaf35,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-f772d089-cadb-41a8-be82-9b36f2e94c38,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-80cb22f3-4c2e-4bf7-b1d9-06e3ac6f5618,DISK], DatanodeInfoWithStorage[127.0.0.1:34513,DS-908c8af8-8424-4724-b335-4b755dd3e42a,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-d24994c0-2203-4a52-b656-b6c00040762f,DISK], DatanodeInfoWithStorage[127.0.0.1:39487,DS-c38b35af-2eab-4ea4-a8fa-d7aa9b5d70af,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-6e6e3c92-a429-4897-bbc6-d4106a900091,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-ce8978bb-8b0a-42dc-a1fc-d42efb580506,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1281383679-172.17.0.13-1595497333625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39988,DS-b99b1132-d160-4200-9957-f8b9eebb6d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-2b3ac080-20eb-45b0-9813-791898d09ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-8064d65f-0293-4e81-a74f-04dc7fdff738,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-a3704b1e-b5f4-4881-87c7-f5b68fe738da,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-6aba5272-6a82-4deb-ae09-8e90cb1c6c27,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-9b51cafa-38de-47a6-a468-6766f01c15c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40731,DS-53d4457b-7f1f-4676-8e9c-b93615cf6438,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-2a819d1b-cdc3-4593-93de-38917dd4bfd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1281383679-172.17.0.13-1595497333625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39988,DS-b99b1132-d160-4200-9957-f8b9eebb6d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-2b3ac080-20eb-45b0-9813-791898d09ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-8064d65f-0293-4e81-a74f-04dc7fdff738,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-a3704b1e-b5f4-4881-87c7-f5b68fe738da,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-6aba5272-6a82-4deb-ae09-8e90cb1c6c27,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-9b51cafa-38de-47a6-a468-6766f01c15c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40731,DS-53d4457b-7f1f-4676-8e9c-b93615cf6438,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-2a819d1b-cdc3-4593-93de-38917dd4bfd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1110516037-172.17.0.13-1595497380464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40825,DS-66296e45-c1bf-461c-a699-7e93c1a49a60,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-e70c8f67-49c0-46e6-b985-09652599bff4,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-5154eb4e-0efb-47c5-b672-4fe926667d57,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-8ff7c27c-8144-4503-b9b2-207985750aad,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-fd40967e-2cb3-4883-8087-6447af5776c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-c0b4bb0d-0c88-4391-9f96-d2b11cab02f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-0a312c8d-4251-4670-a4e2-0db2cbf630d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-cef39bb6-8b29-4782-ba51-280c90591758,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1110516037-172.17.0.13-1595497380464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40825,DS-66296e45-c1bf-461c-a699-7e93c1a49a60,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-e70c8f67-49c0-46e6-b985-09652599bff4,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-5154eb4e-0efb-47c5-b672-4fe926667d57,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-8ff7c27c-8144-4503-b9b2-207985750aad,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-fd40967e-2cb3-4883-8087-6447af5776c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-c0b4bb0d-0c88-4391-9f96-d2b11cab02f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-0a312c8d-4251-4670-a4e2-0db2cbf630d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-cef39bb6-8b29-4782-ba51-280c90591758,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-658089990-172.17.0.13-1595497571355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42928,DS-9354d667-1292-4443-a17b-de56898de8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-d3695e72-dd34-4c8a-a439-427c42583205,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-a5d4303a-2987-481d-b87f-b13d66528a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-c15dc391-4b40-41fd-bdcb-6e458ae73fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-68efe014-b5bf-42fd-9366-bad50cb8d6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-f2aba3a3-7d7e-49dc-980f-9a28650ed6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-0c342e3b-652c-4f03-ae82-836b1fb43eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-633f5fe1-02c7-40e9-bdc5-54092c439037,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-658089990-172.17.0.13-1595497571355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42928,DS-9354d667-1292-4443-a17b-de56898de8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-d3695e72-dd34-4c8a-a439-427c42583205,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-a5d4303a-2987-481d-b87f-b13d66528a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-c15dc391-4b40-41fd-bdcb-6e458ae73fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-68efe014-b5bf-42fd-9366-bad50cb8d6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-f2aba3a3-7d7e-49dc-980f-9a28650ed6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-0c342e3b-652c-4f03-ae82-836b1fb43eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-633f5fe1-02c7-40e9-bdc5-54092c439037,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-547026897-172.17.0.13-1595497772099:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39615,DS-d0b12eca-6f2c-4f55-84e1-461971e93366,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-0be1b578-9ce3-434e-978c-bde147085ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-c6018baf-6079-48d4-be22-2904787ba035,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-273a5eac-7a71-416b-90c8-4a45bc6b0dad,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-7ce9d1d2-8569-4760-a589-a0c342d2022a,DISK], DatanodeInfoWithStorage[127.0.0.1:35842,DS-303c8973-4f24-4a00-b871-5af770eb11f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-0ad0dc02-c07c-4c3b-aa02-2e3d643841e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40913,DS-b19db869-60ab-4c1c-92f6-2a0849a2edfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-547026897-172.17.0.13-1595497772099:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39615,DS-d0b12eca-6f2c-4f55-84e1-461971e93366,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-0be1b578-9ce3-434e-978c-bde147085ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-c6018baf-6079-48d4-be22-2904787ba035,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-273a5eac-7a71-416b-90c8-4a45bc6b0dad,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-7ce9d1d2-8569-4760-a589-a0c342d2022a,DISK], DatanodeInfoWithStorage[127.0.0.1:35842,DS-303c8973-4f24-4a00-b871-5af770eb11f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-0ad0dc02-c07c-4c3b-aa02-2e3d643841e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40913,DS-b19db869-60ab-4c1c-92f6-2a0849a2edfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1253726140-172.17.0.13-1595497812679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37028,DS-8ccf9772-5546-4814-b388-d50687cf814c,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-ce96f989-a345-4fcb-a48a-f144baf37463,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-8a333a99-6e85-40b7-b1a8-3690aacdcd5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-82768616-1d67-4f63-b192-ebf4f463de61,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-905a9d82-2667-4aeb-83ac-7c9950e426b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-e17553ae-a09c-486c-9911-df4417372d91,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-ff3dc4f3-8f9b-4c04-9bff-008c7e82a293,DISK], DatanodeInfoWithStorage[127.0.0.1:46043,DS-93e53042-2e1d-4223-a57c-f54745892aea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1253726140-172.17.0.13-1595497812679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37028,DS-8ccf9772-5546-4814-b388-d50687cf814c,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-ce96f989-a345-4fcb-a48a-f144baf37463,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-8a333a99-6e85-40b7-b1a8-3690aacdcd5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-82768616-1d67-4f63-b192-ebf4f463de61,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-905a9d82-2667-4aeb-83ac-7c9950e426b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-e17553ae-a09c-486c-9911-df4417372d91,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-ff3dc4f3-8f9b-4c04-9bff-008c7e82a293,DISK], DatanodeInfoWithStorage[127.0.0.1:46043,DS-93e53042-2e1d-4223-a57c-f54745892aea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5606
