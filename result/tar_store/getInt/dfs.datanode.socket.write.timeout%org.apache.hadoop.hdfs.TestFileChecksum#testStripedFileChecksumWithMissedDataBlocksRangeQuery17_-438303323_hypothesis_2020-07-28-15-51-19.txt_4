reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-64469105-172.17.0.5-1595952560708:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39274,DS-e62bed52-e6d6-41bd-895f-cc4037018967,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-2b1a077f-32ef-4806-be88-24c98576975b,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-b1377f58-3a55-42b2-94bc-89525c946f88,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-9b9b702e-eadb-40df-80d9-a870176f7b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-6269e3b8-bf71-47a9-960e-8a99d0be44cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44909,DS-b223d175-21b0-423a-bf29-cebc5acaa37f,DISK], DatanodeInfoWithStorage[127.0.0.1:36740,DS-41d8980f-b5a0-4dc6-83e6-9ab37d4cbfba,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-14646548-b0d7-4dfc-9a33-b5b0ad0c430d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-64469105-172.17.0.5-1595952560708:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39274,DS-e62bed52-e6d6-41bd-895f-cc4037018967,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-2b1a077f-32ef-4806-be88-24c98576975b,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-b1377f58-3a55-42b2-94bc-89525c946f88,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-9b9b702e-eadb-40df-80d9-a870176f7b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-6269e3b8-bf71-47a9-960e-8a99d0be44cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44909,DS-b223d175-21b0-423a-bf29-cebc5acaa37f,DISK], DatanodeInfoWithStorage[127.0.0.1:36740,DS-41d8980f-b5a0-4dc6-83e6-9ab37d4cbfba,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-14646548-b0d7-4dfc-9a33-b5b0ad0c430d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1581309656-172.17.0.5-1595952768311:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38077,DS-957fb47c-63be-418e-b3e7-553d472e72f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40388,DS-d078c722-9438-4a87-b0cb-187679228c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35136,DS-f0c364b4-fd61-42e6-8d9f-13e4fd2f1867,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-6d1f87fe-df20-4d9d-8c7e-be8b21b721b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44405,DS-4e2a2dc7-2f60-4323-a356-826533f2533d,DISK], DatanodeInfoWithStorage[127.0.0.1:33409,DS-9ad07e5e-1162-4918-814d-b70673272b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-262d4a52-ae42-4fd6-9789-82da9e9eda19,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-ca41bf65-0424-4de0-9494-22e4f8a922b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1581309656-172.17.0.5-1595952768311:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38077,DS-957fb47c-63be-418e-b3e7-553d472e72f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40388,DS-d078c722-9438-4a87-b0cb-187679228c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35136,DS-f0c364b4-fd61-42e6-8d9f-13e4fd2f1867,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-6d1f87fe-df20-4d9d-8c7e-be8b21b721b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44405,DS-4e2a2dc7-2f60-4323-a356-826533f2533d,DISK], DatanodeInfoWithStorage[127.0.0.1:33409,DS-9ad07e5e-1162-4918-814d-b70673272b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-262d4a52-ae42-4fd6-9789-82da9e9eda19,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-ca41bf65-0424-4de0-9494-22e4f8a922b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-918129874-172.17.0.5-1595953690555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43658,DS-ea3b3ee5-4f6e-4453-9139-07b857e657b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39149,DS-1593573f-51a7-4551-a115-6858ee328881,DISK], DatanodeInfoWithStorage[127.0.0.1:37305,DS-a8fcfefe-2bce-4aa7-aee9-e90d3d325f41,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-b9676989-23ec-4994-a678-7c1ad2ea563a,DISK], DatanodeInfoWithStorage[127.0.0.1:35857,DS-983ab27f-ec50-4d70-b990-37632a1be8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-7e36ac5e-3538-4dee-b5ee-31a446978481,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-f67f3d72-7ecd-4403-ba4a-0baa416db327,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-0cc2f669-58f1-4c5e-9d07-f543da223ca3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-918129874-172.17.0.5-1595953690555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43658,DS-ea3b3ee5-4f6e-4453-9139-07b857e657b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39149,DS-1593573f-51a7-4551-a115-6858ee328881,DISK], DatanodeInfoWithStorage[127.0.0.1:37305,DS-a8fcfefe-2bce-4aa7-aee9-e90d3d325f41,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-b9676989-23ec-4994-a678-7c1ad2ea563a,DISK], DatanodeInfoWithStorage[127.0.0.1:35857,DS-983ab27f-ec50-4d70-b990-37632a1be8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-7e36ac5e-3538-4dee-b5ee-31a446978481,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-f67f3d72-7ecd-4403-ba4a-0baa416db327,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-0cc2f669-58f1-4c5e-9d07-f543da223ca3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-271229006-172.17.0.5-1595953764950:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41915,DS-d1ce77ed-8914-440a-aee3-a661f42463dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43316,DS-1d0fdcfc-69c4-4829-a085-690dfc409594,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-4c957544-d12c-4028-b0fa-8c7a5c6f6cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-ee3cd90c-ec18-4035-b141-114c222ea76b,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-f2ecb770-12fd-40bb-9cfb-84912cb027ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-1fe31516-9252-4c26-a18a-fc4b66c618de,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-93aa03c4-1981-4738-ad09-e2903213d5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-60e2aa5e-c182-4ed9-b172-09f0c64ddac4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-271229006-172.17.0.5-1595953764950:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41915,DS-d1ce77ed-8914-440a-aee3-a661f42463dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43316,DS-1d0fdcfc-69c4-4829-a085-690dfc409594,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-4c957544-d12c-4028-b0fa-8c7a5c6f6cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-ee3cd90c-ec18-4035-b141-114c222ea76b,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-f2ecb770-12fd-40bb-9cfb-84912cb027ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-1fe31516-9252-4c26-a18a-fc4b66c618de,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-93aa03c4-1981-4738-ad09-e2903213d5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-60e2aa5e-c182-4ed9-b172-09f0c64ddac4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-514929421-172.17.0.5-1595953904838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46264,DS-984d23b4-7a7b-4948-ad7d-9de27edb63f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-ac28c079-becb-4192-9011-2304baebb16c,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-05803334-6d85-4c71-80a1-a44e2d22a5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-1522805b-4f5c-4c6c-b392-7e61b13f6924,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-d3e0200c-25c4-4c73-8d49-f29a403ac086,DISK], DatanodeInfoWithStorage[127.0.0.1:33944,DS-db271df7-adda-47f1-b4d3-bca9cacd3058,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-9084cb1c-a2b5-42d8-b91c-3ced344ee495,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-5b363445-d82d-4cc4-bd11-a6a402496591,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-514929421-172.17.0.5-1595953904838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46264,DS-984d23b4-7a7b-4948-ad7d-9de27edb63f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-ac28c079-becb-4192-9011-2304baebb16c,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-05803334-6d85-4c71-80a1-a44e2d22a5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-1522805b-4f5c-4c6c-b392-7e61b13f6924,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-d3e0200c-25c4-4c73-8d49-f29a403ac086,DISK], DatanodeInfoWithStorage[127.0.0.1:33944,DS-db271df7-adda-47f1-b4d3-bca9cacd3058,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-9084cb1c-a2b5-42d8-b91c-3ced344ee495,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-5b363445-d82d-4cc4-bd11-a6a402496591,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-655893885-172.17.0.5-1595954266338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40241,DS-d6fc79c2-83ec-4af4-bea3-14fd681692a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-aea95ed5-2367-40cf-92e7-c6252673b790,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-1f39e0ed-56ce-4450-944c-dce0f0e9bb54,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-ae98d332-b92a-49d1-8912-9c2729887c88,DISK], DatanodeInfoWithStorage[127.0.0.1:36457,DS-5f5a31f8-a0c0-4b4e-b968-77fd422a7c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-6e5111f6-5157-41a6-9665-a826e3e01573,DISK], DatanodeInfoWithStorage[127.0.0.1:38427,DS-68a3dda1-4f6c-4723-bab4-8a89b03749dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-6bb8e5b1-3fd2-49e1-b825-238daff44775,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-655893885-172.17.0.5-1595954266338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40241,DS-d6fc79c2-83ec-4af4-bea3-14fd681692a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-aea95ed5-2367-40cf-92e7-c6252673b790,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-1f39e0ed-56ce-4450-944c-dce0f0e9bb54,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-ae98d332-b92a-49d1-8912-9c2729887c88,DISK], DatanodeInfoWithStorage[127.0.0.1:36457,DS-5f5a31f8-a0c0-4b4e-b968-77fd422a7c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-6e5111f6-5157-41a6-9665-a826e3e01573,DISK], DatanodeInfoWithStorage[127.0.0.1:38427,DS-68a3dda1-4f6c-4723-bab4-8a89b03749dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-6bb8e5b1-3fd2-49e1-b825-238daff44775,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2055920353-172.17.0.5-1595954439946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41576,DS-ca56e9b3-410a-45e7-bf89-9ca98bf894c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-e101fa58-eff1-4bfa-b14e-7a1967c97978,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-59bfdb99-07ea-43bf-9010-86d50d4386c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-4d690be1-3e37-4841-b696-61862439a8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-a73edf5e-f7b4-45e6-b2d3-951b41b311d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-b1b9a17e-3e22-4c1e-8d6d-4356f7e57c66,DISK], DatanodeInfoWithStorage[127.0.0.1:40897,DS-d6420efb-8626-49a1-bc12-e0c6dc92c8de,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-00fc67f9-d248-4905-b243-00bba84c5c3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2055920353-172.17.0.5-1595954439946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41576,DS-ca56e9b3-410a-45e7-bf89-9ca98bf894c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-e101fa58-eff1-4bfa-b14e-7a1967c97978,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-59bfdb99-07ea-43bf-9010-86d50d4386c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-4d690be1-3e37-4841-b696-61862439a8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-a73edf5e-f7b4-45e6-b2d3-951b41b311d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-b1b9a17e-3e22-4c1e-8d6d-4356f7e57c66,DISK], DatanodeInfoWithStorage[127.0.0.1:40897,DS-d6420efb-8626-49a1-bc12-e0c6dc92c8de,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-00fc67f9-d248-4905-b243-00bba84c5c3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1047476015-172.17.0.5-1595954575540:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36645,DS-44db9cdf-8e0f-4a88-b748-67cf17b3ce3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37585,DS-7a73bfa8-ca8a-42e9-ae69-392e6020f478,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-689e82f6-714b-4bae-abf8-b83f9dbf46cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-eb6b00e0-76c6-4b52-bdcd-f9c2c20aeca9,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-51ca92fd-b831-40d4-a53f-d5bdad36c8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-efa83e61-6261-49fc-9261-235809714d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-e65e7706-3597-4a46-85dd-7fc21f33a6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-97965d8b-5dfb-4e9f-b578-5966e23ef88a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1047476015-172.17.0.5-1595954575540:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36645,DS-44db9cdf-8e0f-4a88-b748-67cf17b3ce3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37585,DS-7a73bfa8-ca8a-42e9-ae69-392e6020f478,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-689e82f6-714b-4bae-abf8-b83f9dbf46cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-eb6b00e0-76c6-4b52-bdcd-f9c2c20aeca9,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-51ca92fd-b831-40d4-a53f-d5bdad36c8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-efa83e61-6261-49fc-9261-235809714d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-e65e7706-3597-4a46-85dd-7fc21f33a6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-97965d8b-5dfb-4e9f-b578-5966e23ef88a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1531221575-172.17.0.5-1595954614837:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39189,DS-8ddebe3e-1378-4d3e-903f-660d87fc02b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-c9c98c03-aac4-4e0e-94b5-e0246e47a264,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-dee553c2-76d0-44ad-a4d9-9c9a38a2d817,DISK], DatanodeInfoWithStorage[127.0.0.1:40000,DS-74ed6fd9-76b3-4304-bab0-cd1534175d60,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-8bd82b37-7955-41ab-8203-dccc41aed91a,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-44555691-88ca-47b4-b0c8-2e4de8ef24b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-2fc64233-2c6f-4ef7-966b-76418673f758,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-7bd88bbf-225e-4d2d-81da-78dd3915ff01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1531221575-172.17.0.5-1595954614837:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39189,DS-8ddebe3e-1378-4d3e-903f-660d87fc02b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-c9c98c03-aac4-4e0e-94b5-e0246e47a264,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-dee553c2-76d0-44ad-a4d9-9c9a38a2d817,DISK], DatanodeInfoWithStorage[127.0.0.1:40000,DS-74ed6fd9-76b3-4304-bab0-cd1534175d60,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-8bd82b37-7955-41ab-8203-dccc41aed91a,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-44555691-88ca-47b4-b0c8-2e4de8ef24b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-2fc64233-2c6f-4ef7-966b-76418673f758,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-7bd88bbf-225e-4d2d-81da-78dd3915ff01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1442894868-172.17.0.5-1595954717030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45997,DS-32304a2f-2c9d-4635-97bf-586ad750be74,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-43cbbadd-aa03-48ac-91f2-a2a7c15418de,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-9e6d896d-2d57-45bd-b563-4bdf8cd3068b,DISK], DatanodeInfoWithStorage[127.0.0.1:45118,DS-98f85c31-fe61-4eca-8e73-9bc6438848ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-bb755bd6-1403-490e-a1a7-288ab1abc96e,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-c37ab9d9-d616-49ee-853e-73a27e891000,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-967bc3df-1871-47f1-867c-006e103c0d12,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-7bd341db-84f7-456f-8f1b-691fa508afe1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1442894868-172.17.0.5-1595954717030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45997,DS-32304a2f-2c9d-4635-97bf-586ad750be74,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-43cbbadd-aa03-48ac-91f2-a2a7c15418de,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-9e6d896d-2d57-45bd-b563-4bdf8cd3068b,DISK], DatanodeInfoWithStorage[127.0.0.1:45118,DS-98f85c31-fe61-4eca-8e73-9bc6438848ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-bb755bd6-1403-490e-a1a7-288ab1abc96e,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-c37ab9d9-d616-49ee-853e-73a27e891000,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-967bc3df-1871-47f1-867c-006e103c0d12,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-7bd341db-84f7-456f-8f1b-691fa508afe1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1496474618-172.17.0.5-1595954831437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40944,DS-0ccc6194-ed61-4eaa-badd-18e1b26e2dab,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-631204a4-6b5c-4172-aa53-390574ba6581,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-e319bc3c-2eb9-4f86-8792-0aebfc83c49e,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-27852a45-9926-4a05-a145-6fc7599316bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-45b1052a-e4da-433f-a867-aa42de2f7441,DISK], DatanodeInfoWithStorage[127.0.0.1:45852,DS-76087936-465f-49c0-ac8a-e1aaa16c1880,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-0e00454d-33f9-4441-8b73-b83971fbf02f,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-66e96e1e-a6c5-41cd-bb55-05720b0bc953,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1496474618-172.17.0.5-1595954831437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40944,DS-0ccc6194-ed61-4eaa-badd-18e1b26e2dab,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-631204a4-6b5c-4172-aa53-390574ba6581,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-e319bc3c-2eb9-4f86-8792-0aebfc83c49e,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-27852a45-9926-4a05-a145-6fc7599316bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-45b1052a-e4da-433f-a867-aa42de2f7441,DISK], DatanodeInfoWithStorage[127.0.0.1:45852,DS-76087936-465f-49c0-ac8a-e1aaa16c1880,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-0e00454d-33f9-4441-8b73-b83971fbf02f,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-66e96e1e-a6c5-41cd-bb55-05720b0bc953,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-997224668-172.17.0.5-1595955426828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46753,DS-f11f5428-e65e-4762-8d32-3b8855b3d2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44180,DS-5b7d1446-6e9a-44fa-93a3-55e99cc0e5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-f0546073-e0b5-48a7-a236-96b5a01b5df9,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-87cafd15-64f4-47f6-b7a3-f3617d2abf80,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-3a644eeb-7358-4393-8b52-f4a11f488853,DISK], DatanodeInfoWithStorage[127.0.0.1:34471,DS-688a7142-00bb-479f-8222-613acaba15d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-5a3b168a-b1ea-4a51-99da-70c9a3ec8fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-ddb698b7-da49-41bb-8bb4-a421894e72af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-997224668-172.17.0.5-1595955426828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46753,DS-f11f5428-e65e-4762-8d32-3b8855b3d2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44180,DS-5b7d1446-6e9a-44fa-93a3-55e99cc0e5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-f0546073-e0b5-48a7-a236-96b5a01b5df9,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-87cafd15-64f4-47f6-b7a3-f3617d2abf80,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-3a644eeb-7358-4393-8b52-f4a11f488853,DISK], DatanodeInfoWithStorage[127.0.0.1:34471,DS-688a7142-00bb-479f-8222-613acaba15d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-5a3b168a-b1ea-4a51-99da-70c9a3ec8fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-ddb698b7-da49-41bb-8bb4-a421894e72af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-525620443-172.17.0.5-1595955718594:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34767,DS-fe27f1a6-4744-4a70-8f67-606e3feba0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36390,DS-511bb77c-0794-4c0b-91d0-c21d4e8174cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-04ebee9e-f2ae-458b-8199-1801de77f83c,DISK], DatanodeInfoWithStorage[127.0.0.1:46335,DS-44ce8970-2286-49a2-84fc-3d05df02633b,DISK], DatanodeInfoWithStorage[127.0.0.1:36083,DS-c779107f-0e73-410d-ac70-a3ed609336bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-ce3d23f4-036a-415a-8925-f8cc5df9ccfe,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-aab5e9e9-219c-4695-9fc3-e849074846c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-52d54782-ea3b-4d45-b771-d26fdf7ef241,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-525620443-172.17.0.5-1595955718594:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34767,DS-fe27f1a6-4744-4a70-8f67-606e3feba0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36390,DS-511bb77c-0794-4c0b-91d0-c21d4e8174cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-04ebee9e-f2ae-458b-8199-1801de77f83c,DISK], DatanodeInfoWithStorage[127.0.0.1:46335,DS-44ce8970-2286-49a2-84fc-3d05df02633b,DISK], DatanodeInfoWithStorage[127.0.0.1:36083,DS-c779107f-0e73-410d-ac70-a3ed609336bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-ce3d23f4-036a-415a-8925-f8cc5df9ccfe,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-aab5e9e9-219c-4695-9fc3-e849074846c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-52d54782-ea3b-4d45-b771-d26fdf7ef241,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-571061070-172.17.0.5-1595955833876:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38327,DS-c1023b4f-46b7-40ee-ac0a-8f7fe1e7d851,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-b7d5afb2-32c2-4a68-ac44-85831b0b04e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-f603ade9-cf29-4730-a2eb-72ff3e3b4e10,DISK], DatanodeInfoWithStorage[127.0.0.1:37552,DS-a65c2ca9-43c3-454a-b89a-3a88d71129c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35477,DS-c4547c7d-0302-42fe-90b5-bccaec171e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-2957a2df-ddbd-4ddf-8f24-80e1f55daa62,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-49d730e3-7181-44c7-ad30-d08b82797112,DISK], DatanodeInfoWithStorage[127.0.0.1:39886,DS-082c4eb3-7319-48be-acda-40494473a829,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-571061070-172.17.0.5-1595955833876:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38327,DS-c1023b4f-46b7-40ee-ac0a-8f7fe1e7d851,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-b7d5afb2-32c2-4a68-ac44-85831b0b04e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-f603ade9-cf29-4730-a2eb-72ff3e3b4e10,DISK], DatanodeInfoWithStorage[127.0.0.1:37552,DS-a65c2ca9-43c3-454a-b89a-3a88d71129c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35477,DS-c4547c7d-0302-42fe-90b5-bccaec171e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-2957a2df-ddbd-4ddf-8f24-80e1f55daa62,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-49d730e3-7181-44c7-ad30-d08b82797112,DISK], DatanodeInfoWithStorage[127.0.0.1:39886,DS-082c4eb3-7319-48be-acda-40494473a829,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 960000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-365528672-172.17.0.5-1595956499644:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43981,DS-e145d31c-abcc-4890-b68d-e2df8f5467be,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-e3c87963-4ae3-4b8b-8bf7-a6174c0a1c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-1e484633-b406-406b-aff3-ebf5bf8d939c,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-467c7c49-62ec-4acc-bc3e-5229bd58927c,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-9ebb29d4-f6d7-4778-84ba-6efb2d616180,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-8fc759b3-d59e-4c00-8f3b-5b160d35de9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-239ab824-ef8e-40b9-8798-58acf61feca3,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-fe0def37-e401-4756-be13-eaf2e889fffa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-365528672-172.17.0.5-1595956499644:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43981,DS-e145d31c-abcc-4890-b68d-e2df8f5467be,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-e3c87963-4ae3-4b8b-8bf7-a6174c0a1c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-1e484633-b406-406b-aff3-ebf5bf8d939c,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-467c7c49-62ec-4acc-bc3e-5229bd58927c,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-9ebb29d4-f6d7-4778-84ba-6efb2d616180,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-8fc759b3-d59e-4c00-8f3b-5b160d35de9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-239ab824-ef8e-40b9-8798-58acf61feca3,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-fe0def37-e401-4756-be13-eaf2e889fffa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5273
