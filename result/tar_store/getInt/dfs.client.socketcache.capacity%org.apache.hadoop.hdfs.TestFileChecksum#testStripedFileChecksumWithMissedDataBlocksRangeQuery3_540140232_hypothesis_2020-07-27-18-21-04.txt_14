reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1290619097-172.17.0.18-1595874185986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46377,DS-43d0d231-dbe0-4f73-a833-db8ef0aea480,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-09dbe264-d411-4374-b66d-b9952a722c37,DISK], DatanodeInfoWithStorage[127.0.0.1:42970,DS-f02b92a7-5c7b-4792-a797-97ae06ab0a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39414,DS-3394d177-8c2b-496b-9ec4-91edd52a39d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-4ea56ccc-1899-45fb-9489-4aeb28563388,DISK], DatanodeInfoWithStorage[127.0.0.1:44774,DS-355b7a36-b0cd-4bb2-ac62-5dd41fad79ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-a5a5e548-50f0-4ac3-bbca-782949f76a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-dcd22167-41a0-4cda-b523-2095b116cbac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1290619097-172.17.0.18-1595874185986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46377,DS-43d0d231-dbe0-4f73-a833-db8ef0aea480,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-09dbe264-d411-4374-b66d-b9952a722c37,DISK], DatanodeInfoWithStorage[127.0.0.1:42970,DS-f02b92a7-5c7b-4792-a797-97ae06ab0a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39414,DS-3394d177-8c2b-496b-9ec4-91edd52a39d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-4ea56ccc-1899-45fb-9489-4aeb28563388,DISK], DatanodeInfoWithStorage[127.0.0.1:44774,DS-355b7a36-b0cd-4bb2-ac62-5dd41fad79ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-a5a5e548-50f0-4ac3-bbca-782949f76a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-dcd22167-41a0-4cda-b523-2095b116cbac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1746457044-172.17.0.18-1595874474777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33017,DS-346d6299-bb0c-42ee-ab69-42628b2db4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-a9ee7bcd-739e-4cc1-a345-fbfc3edd5a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-59d64a79-5dc5-4edb-98e3-d7095cd78ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-955f4df7-48d1-4ff2-a4d6-7e9316bd354b,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-8e374c56-762f-4ded-b86f-c34c3e01f6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-b6933000-2896-4eaf-9468-0be53082a448,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-4989a692-21ea-4ed8-b5bf-61b064125a84,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-7b51fa9c-afd4-44d9-81e3-8099d79024c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1746457044-172.17.0.18-1595874474777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33017,DS-346d6299-bb0c-42ee-ab69-42628b2db4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-a9ee7bcd-739e-4cc1-a345-fbfc3edd5a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-59d64a79-5dc5-4edb-98e3-d7095cd78ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-955f4df7-48d1-4ff2-a4d6-7e9316bd354b,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-8e374c56-762f-4ded-b86f-c34c3e01f6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-b6933000-2896-4eaf-9468-0be53082a448,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-4989a692-21ea-4ed8-b5bf-61b064125a84,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-7b51fa9c-afd4-44d9-81e3-8099d79024c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1553241029-172.17.0.18-1595874623102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44543,DS-5440c4b5-dc31-48c1-808e-cbae7298d15a,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-e4516fb6-8d0b-49b0-b650-deaaecee60a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-9a6bcbd3-ab8a-4aba-8847-ad915f2f296a,DISK], DatanodeInfoWithStorage[127.0.0.1:39727,DS-fe72995a-b9b5-48b2-96fd-64cb8b2c2a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-8dd60651-e5e7-470f-85e3-652fbca9a8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-f261c90e-a25b-4efe-a190-3656cb058751,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-1b4ab0ca-6402-411d-b5a6-330ecd989113,DISK], DatanodeInfoWithStorage[127.0.0.1:33776,DS-1bcdc818-ca6d-4adc-8b99-3b4a2fe11d20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1553241029-172.17.0.18-1595874623102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44543,DS-5440c4b5-dc31-48c1-808e-cbae7298d15a,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-e4516fb6-8d0b-49b0-b650-deaaecee60a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-9a6bcbd3-ab8a-4aba-8847-ad915f2f296a,DISK], DatanodeInfoWithStorage[127.0.0.1:39727,DS-fe72995a-b9b5-48b2-96fd-64cb8b2c2a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-8dd60651-e5e7-470f-85e3-652fbca9a8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-f261c90e-a25b-4efe-a190-3656cb058751,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-1b4ab0ca-6402-411d-b5a6-330ecd989113,DISK], DatanodeInfoWithStorage[127.0.0.1:33776,DS-1bcdc818-ca6d-4adc-8b99-3b4a2fe11d20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-819523423-172.17.0.18-1595874705567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45813,DS-ef9b90f3-7623-41a4-abf5-bd089553f965,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-a3f85a0c-4f4e-4fb0-9bcf-7e86f483170c,DISK], DatanodeInfoWithStorage[127.0.0.1:41225,DS-c393b030-6002-4dd2-989b-75227f47e33f,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-b7468cd0-28a2-4097-8550-1bf5d64674fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36593,DS-6d95c7b8-edac-4919-97e6-da94e8fdde5d,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-68d4028d-a351-4e32-8ef0-7f67bcc3cdd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-ff7ec401-74fc-4bf1-b727-b4db678e8887,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-5357eb7c-23eb-4e4c-b79f-6f1b20c3fed6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-819523423-172.17.0.18-1595874705567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45813,DS-ef9b90f3-7623-41a4-abf5-bd089553f965,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-a3f85a0c-4f4e-4fb0-9bcf-7e86f483170c,DISK], DatanodeInfoWithStorage[127.0.0.1:41225,DS-c393b030-6002-4dd2-989b-75227f47e33f,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-b7468cd0-28a2-4097-8550-1bf5d64674fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36593,DS-6d95c7b8-edac-4919-97e6-da94e8fdde5d,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-68d4028d-a351-4e32-8ef0-7f67bcc3cdd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-ff7ec401-74fc-4bf1-b727-b4db678e8887,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-5357eb7c-23eb-4e4c-b79f-6f1b20c3fed6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1390671075-172.17.0.18-1595874878566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34826,DS-a0f22a77-83c5-44f4-a676-54c9c096518a,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-62f1226f-4aac-4e62-a100-4f8469a246a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-3dc000db-8e58-46c4-a545-0b31ce2fe882,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-74659c0e-a809-4393-aca0-1c6a02e56f82,DISK], DatanodeInfoWithStorage[127.0.0.1:42759,DS-d79f5998-3b90-4bd4-aa58-207d483deaac,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-786b9205-ee86-472b-b590-755b5aaacbc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-f7b04d30-864f-446e-a60d-c1061afa9685,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-8b68b888-7891-4e06-9bc3-0d41c8279369,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1390671075-172.17.0.18-1595874878566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34826,DS-a0f22a77-83c5-44f4-a676-54c9c096518a,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-62f1226f-4aac-4e62-a100-4f8469a246a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-3dc000db-8e58-46c4-a545-0b31ce2fe882,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-74659c0e-a809-4393-aca0-1c6a02e56f82,DISK], DatanodeInfoWithStorage[127.0.0.1:42759,DS-d79f5998-3b90-4bd4-aa58-207d483deaac,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-786b9205-ee86-472b-b590-755b5aaacbc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-f7b04d30-864f-446e-a60d-c1061afa9685,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-8b68b888-7891-4e06-9bc3-0d41c8279369,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-132424963-172.17.0.18-1595874916349:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34886,DS-2370064d-fc61-4904-ae9a-64af4cc3d611,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-87e8f993-c8da-4bd9-a301-5869b7b9e169,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-e92500d4-4eae-4b78-8046-f28bf5864344,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-d4e4fdc2-330c-4925-bd53-99334a982a06,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-70cafc23-f768-4478-b090-455ce4460633,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-92bb0102-2d56-4356-898e-4e0c398b834b,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-3168fa14-1234-412c-acca-751927955b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-6b59679c-c2a6-48f9-a10b-ef75ac6d9d97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-132424963-172.17.0.18-1595874916349:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34886,DS-2370064d-fc61-4904-ae9a-64af4cc3d611,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-87e8f993-c8da-4bd9-a301-5869b7b9e169,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-e92500d4-4eae-4b78-8046-f28bf5864344,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-d4e4fdc2-330c-4925-bd53-99334a982a06,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-70cafc23-f768-4478-b090-455ce4460633,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-92bb0102-2d56-4356-898e-4e0c398b834b,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-3168fa14-1234-412c-acca-751927955b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-6b59679c-c2a6-48f9-a10b-ef75ac6d9d97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-241866341-172.17.0.18-1595874948886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39661,DS-37979d28-80f7-442a-88ab-7997a3e7d59a,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-6228357b-e037-427b-aaae-6b544cbd2086,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-5c9669ce-94a4-4a62-bbe7-7652eeb13cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34839,DS-3956f9c4-46f5-4a96-9484-50952d5db7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41609,DS-800d5615-6b06-4210-94c4-1b822692fd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-c6a98d5f-ef48-460e-8194-3dccd560f169,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-acf0a1d6-1e61-40fe-a64e-2970166a6b05,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-c0c4c75f-70a9-4ef4-a5a7-79d416bb09eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-241866341-172.17.0.18-1595874948886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39661,DS-37979d28-80f7-442a-88ab-7997a3e7d59a,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-6228357b-e037-427b-aaae-6b544cbd2086,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-5c9669ce-94a4-4a62-bbe7-7652eeb13cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34839,DS-3956f9c4-46f5-4a96-9484-50952d5db7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41609,DS-800d5615-6b06-4210-94c4-1b822692fd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-c6a98d5f-ef48-460e-8194-3dccd560f169,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-acf0a1d6-1e61-40fe-a64e-2970166a6b05,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-c0c4c75f-70a9-4ef4-a5a7-79d416bb09eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-123276298-172.17.0.18-1595875025611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45824,DS-3125cf9e-1993-4609-a9a9-9fd1c2dd0ead,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-b14be915-63ec-4af0-8931-a81c4ff9371c,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-4f622b2f-f879-459f-9e14-74279fd08a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-ac44bd23-6c6a-45b1-adef-6e391bf641d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-e4d8e009-4635-4b48-932e-8bacdcbd8650,DISK], DatanodeInfoWithStorage[127.0.0.1:36080,DS-a10636e8-26d2-4f7d-82e2-3577fb9caefe,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-693b53b8-2330-4c2a-baef-0d6e5c324441,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-795c114b-3a05-45f6-822a-9074aeb319d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-123276298-172.17.0.18-1595875025611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45824,DS-3125cf9e-1993-4609-a9a9-9fd1c2dd0ead,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-b14be915-63ec-4af0-8931-a81c4ff9371c,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-4f622b2f-f879-459f-9e14-74279fd08a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-ac44bd23-6c6a-45b1-adef-6e391bf641d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-e4d8e009-4635-4b48-932e-8bacdcbd8650,DISK], DatanodeInfoWithStorage[127.0.0.1:36080,DS-a10636e8-26d2-4f7d-82e2-3577fb9caefe,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-693b53b8-2330-4c2a-baef-0d6e5c324441,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-795c114b-3a05-45f6-822a-9074aeb319d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-295999335-172.17.0.18-1595875061043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41091,DS-14bb91e2-cf74-4ac8-a0e8-a15243b3d877,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-9b6a0d99-6858-42f7-85c4-b1d5a1cce2de,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-1b70bf47-bdfe-468c-a147-3653e7bda4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-b10db303-bbf0-4fc7-8213-a2b1138f1862,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-ec4c6417-3a2c-4ca8-82c5-a27140a17e09,DISK], DatanodeInfoWithStorage[127.0.0.1:40564,DS-7c75b8f3-ed00-4764-b64c-1f18471b6921,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-f5f7d1ff-beba-4fc4-a839-bab5fd288fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-3ebed8b2-5634-44dd-b43e-24fca69ef8c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-295999335-172.17.0.18-1595875061043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41091,DS-14bb91e2-cf74-4ac8-a0e8-a15243b3d877,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-9b6a0d99-6858-42f7-85c4-b1d5a1cce2de,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-1b70bf47-bdfe-468c-a147-3653e7bda4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-b10db303-bbf0-4fc7-8213-a2b1138f1862,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-ec4c6417-3a2c-4ca8-82c5-a27140a17e09,DISK], DatanodeInfoWithStorage[127.0.0.1:40564,DS-7c75b8f3-ed00-4764-b64c-1f18471b6921,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-f5f7d1ff-beba-4fc4-a839-bab5fd288fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-3ebed8b2-5634-44dd-b43e-24fca69ef8c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1222070253-172.17.0.18-1595875743792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38245,DS-2f1a1f97-efb4-4b21-b9cf-44ba0a56811f,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-901a1c73-5cb7-4011-ad1c-a92b1de96f98,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-bb33b713-c2e1-487f-8091-1de9a62bd9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-771dcc39-4599-4074-a842-66b22d71d6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-c72ebc8c-afd1-4a0f-b290-f411eff7ad70,DISK], DatanodeInfoWithStorage[127.0.0.1:44952,DS-a0effb9c-0588-4cf2-93b5-156d1caf766a,DISK], DatanodeInfoWithStorage[127.0.0.1:43317,DS-9b3c1fb5-2d58-4e79-998b-db91da9e62ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-62951ee3-b28a-4ce0-b51b-2dcead95b9d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1222070253-172.17.0.18-1595875743792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38245,DS-2f1a1f97-efb4-4b21-b9cf-44ba0a56811f,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-901a1c73-5cb7-4011-ad1c-a92b1de96f98,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-bb33b713-c2e1-487f-8091-1de9a62bd9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-771dcc39-4599-4074-a842-66b22d71d6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-c72ebc8c-afd1-4a0f-b290-f411eff7ad70,DISK], DatanodeInfoWithStorage[127.0.0.1:44952,DS-a0effb9c-0588-4cf2-93b5-156d1caf766a,DISK], DatanodeInfoWithStorage[127.0.0.1:43317,DS-9b3c1fb5-2d58-4e79-998b-db91da9e62ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-62951ee3-b28a-4ce0-b51b-2dcead95b9d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1396679906-172.17.0.18-1595875845449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39015,DS-e89cfc58-3f31-487a-9403-03dbc3ce08fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-56e651d3-38df-4a51-b2aa-6ce5dd170731,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-8e50f9da-9dcc-48b0-8f8a-8e36806b9e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-06f427e7-a463-4b08-b41a-195b04fda940,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-8c584074-930b-4c93-9ca0-cf2f82727c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-e75f8abd-754d-468c-8b4b-b6672d0db6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-b1055bf6-04cb-4165-8209-c00cf06bac8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-12741f28-54e7-49e3-b8e4-f82edf6491da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1396679906-172.17.0.18-1595875845449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39015,DS-e89cfc58-3f31-487a-9403-03dbc3ce08fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-56e651d3-38df-4a51-b2aa-6ce5dd170731,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-8e50f9da-9dcc-48b0-8f8a-8e36806b9e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-06f427e7-a463-4b08-b41a-195b04fda940,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-8c584074-930b-4c93-9ca0-cf2f82727c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-e75f8abd-754d-468c-8b4b-b6672d0db6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-b1055bf6-04cb-4165-8209-c00cf06bac8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-12741f28-54e7-49e3-b8e4-f82edf6491da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1361876017-172.17.0.18-1595876328196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35296,DS-0572cbfd-ef66-411c-8d0d-c44977aa614e,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-06ccadf5-1e16-41af-b053-793617ccac53,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-fe7fd952-87dc-4f0a-8645-03cda6e95a28,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-f26fe052-9313-462d-a984-8346ca172249,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-7efd61f0-21d6-4555-8454-f32889505abc,DISK], DatanodeInfoWithStorage[127.0.0.1:34768,DS-fcd1fddc-7cd3-4354-b4a7-e2b7c9c98a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-72d25712-8a18-4ed5-8f52-4984dc255195,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-9ad78d88-3524-4fea-89d9-b99f7f895849,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1361876017-172.17.0.18-1595876328196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35296,DS-0572cbfd-ef66-411c-8d0d-c44977aa614e,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-06ccadf5-1e16-41af-b053-793617ccac53,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-fe7fd952-87dc-4f0a-8645-03cda6e95a28,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-f26fe052-9313-462d-a984-8346ca172249,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-7efd61f0-21d6-4555-8454-f32889505abc,DISK], DatanodeInfoWithStorage[127.0.0.1:34768,DS-fcd1fddc-7cd3-4354-b4a7-e2b7c9c98a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-72d25712-8a18-4ed5-8f52-4984dc255195,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-9ad78d88-3524-4fea-89d9-b99f7f895849,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1263935953-172.17.0.18-1595876899891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40362,DS-89a89eab-8440-4ad7-add9-fd2f2f70b011,DISK], DatanodeInfoWithStorage[127.0.0.1:34470,DS-bc51712b-6edf-495d-9985-8946fc8f2ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-909cdce5-3f6b-4693-9628-fd3161787c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34253,DS-d2212cdd-b5e9-40f2-8161-dd96345dcf91,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-7b6fae87-169c-465a-acd2-52c26143e2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46364,DS-fc475713-9ee8-42f1-8ac2-874e1adb9152,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-1debc005-3e41-4f92-8b0a-3d8217139d84,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-406ac140-39ac-4368-b806-5bec687e00ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1263935953-172.17.0.18-1595876899891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40362,DS-89a89eab-8440-4ad7-add9-fd2f2f70b011,DISK], DatanodeInfoWithStorage[127.0.0.1:34470,DS-bc51712b-6edf-495d-9985-8946fc8f2ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-909cdce5-3f6b-4693-9628-fd3161787c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34253,DS-d2212cdd-b5e9-40f2-8161-dd96345dcf91,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-7b6fae87-169c-465a-acd2-52c26143e2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46364,DS-fc475713-9ee8-42f1-8ac2-874e1adb9152,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-1debc005-3e41-4f92-8b0a-3d8217139d84,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-406ac140-39ac-4368-b806-5bec687e00ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-544707762-172.17.0.18-1595877372577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39451,DS-378ddcf4-5bf8-46ca-ab0b-9a9af31c046d,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-ecde4e4b-b922-467c-9141-335e2bf1389e,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-f16c62f0-0e33-44e4-abac-9708de0c334a,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-8e2ab39d-904d-4cbc-8849-51bc53659470,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-fdbd7119-8fad-4931-80b4-99d5cb9d8569,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-56fc7c5b-13eb-4346-b6f0-72aa8bcc1976,DISK], DatanodeInfoWithStorage[127.0.0.1:42679,DS-53e92bc2-5a73-47d2-858a-d02be4ff860d,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-433945a3-2fcc-4fc9-8940-144044426131,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-544707762-172.17.0.18-1595877372577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39451,DS-378ddcf4-5bf8-46ca-ab0b-9a9af31c046d,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-ecde4e4b-b922-467c-9141-335e2bf1389e,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-f16c62f0-0e33-44e4-abac-9708de0c334a,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-8e2ab39d-904d-4cbc-8849-51bc53659470,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-fdbd7119-8fad-4931-80b4-99d5cb9d8569,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-56fc7c5b-13eb-4346-b6f0-72aa8bcc1976,DISK], DatanodeInfoWithStorage[127.0.0.1:42679,DS-53e92bc2-5a73-47d2-858a-d02be4ff860d,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-433945a3-2fcc-4fc9-8940-144044426131,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1449239477-172.17.0.18-1595877575799:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40258,DS-efeaf231-06ee-46a4-8aba-70a722e269cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46299,DS-3ed09eed-ec73-4fba-8907-67af6f373c74,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-fa5a83c6-52dc-4ca6-af14-fc47dde594cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44041,DS-ef69b62e-8755-43b8-bbbe-a0e54793e923,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-942d220f-6403-487c-b403-bf1e40149fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37454,DS-66cfc47a-9ea9-4585-8c57-a1283ebd4c48,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-0d2e062e-d2af-4ab3-b137-cdba0cd99656,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-55e9b5a0-c8c0-417c-a431-a95fb45eea54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1449239477-172.17.0.18-1595877575799:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40258,DS-efeaf231-06ee-46a4-8aba-70a722e269cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46299,DS-3ed09eed-ec73-4fba-8907-67af6f373c74,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-fa5a83c6-52dc-4ca6-af14-fc47dde594cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44041,DS-ef69b62e-8755-43b8-bbbe-a0e54793e923,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-942d220f-6403-487c-b403-bf1e40149fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37454,DS-66cfc47a-9ea9-4585-8c57-a1283ebd4c48,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-0d2e062e-d2af-4ab3-b137-cdba0cd99656,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-55e9b5a0-c8c0-417c-a431-a95fb45eea54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2007161017-172.17.0.18-1595877644337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35241,DS-ad263536-87c9-4cd8-87e6-021d1f0a3aac,DISK], DatanodeInfoWithStorage[127.0.0.1:39433,DS-1c3d721f-8019-4285-8934-f2ba4fe3566d,DISK], DatanodeInfoWithStorage[127.0.0.1:40038,DS-bb246edf-7aab-456c-a221-897442119a58,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-a7bc42b6-5ce6-42c5-986c-ee1a6efdef9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35370,DS-4eb5d4bf-c973-4723-afe4-f13941fd51b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-21116a6d-dab5-4ea6-8f56-2723367e88a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-64c2a1a8-70bc-43f5-a60f-93c0e7e77925,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-70a2a647-4316-410a-ab85-e492ab01807c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2007161017-172.17.0.18-1595877644337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35241,DS-ad263536-87c9-4cd8-87e6-021d1f0a3aac,DISK], DatanodeInfoWithStorage[127.0.0.1:39433,DS-1c3d721f-8019-4285-8934-f2ba4fe3566d,DISK], DatanodeInfoWithStorage[127.0.0.1:40038,DS-bb246edf-7aab-456c-a221-897442119a58,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-a7bc42b6-5ce6-42c5-986c-ee1a6efdef9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35370,DS-4eb5d4bf-c973-4723-afe4-f13941fd51b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-21116a6d-dab5-4ea6-8f56-2723367e88a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-64c2a1a8-70bc-43f5-a60f-93c0e7e77925,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-70a2a647-4316-410a-ab85-e492ab01807c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-368000422-172.17.0.18-1595877680822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41639,DS-9cc16e6a-2079-49b9-81bd-0c7a1bbc515d,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-e6d4dd14-aa67-4bd4-8324-6c00dff79b27,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-f97f3f0c-338d-4d82-82c0-2046b01da00d,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-cc65a54d-b1c2-4513-bee3-8e6a9d61dbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-1270704f-01f7-45bd-960d-8d6cb1b550fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-18c6aba5-b01e-49d1-bc10-63845011a972,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-731f037d-a99e-474c-ac95-c5bcf81123e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-db81d83f-5eaa-47d7-87f5-cbef1789074d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-368000422-172.17.0.18-1595877680822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41639,DS-9cc16e6a-2079-49b9-81bd-0c7a1bbc515d,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-e6d4dd14-aa67-4bd4-8324-6c00dff79b27,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-f97f3f0c-338d-4d82-82c0-2046b01da00d,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-cc65a54d-b1c2-4513-bee3-8e6a9d61dbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-1270704f-01f7-45bd-960d-8d6cb1b550fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-18c6aba5-b01e-49d1-bc10-63845011a972,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-731f037d-a99e-474c-ac95-c5bcf81123e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-db81d83f-5eaa-47d7-87f5-cbef1789074d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1006634935-172.17.0.18-1595877715295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34062,DS-6fac11e4-45f2-48e2-bd8c-079276c0470f,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-2faafc41-daff-4b78-9f6c-9ea152d1ec5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-f125cd0d-9909-4fcf-9c4c-037fbfd82286,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-1ba3c391-e081-42e6-bebe-7c2ac9c297d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-47f9bd11-7dc3-4dfa-a9c3-55314eb17cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-42b7b63a-1018-4fee-8a7e-a40e1d19d3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-d975432f-652f-42ca-96e9-c48456c0eba5,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-0adb6937-e788-4b74-b295-13f520853a7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1006634935-172.17.0.18-1595877715295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34062,DS-6fac11e4-45f2-48e2-bd8c-079276c0470f,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-2faafc41-daff-4b78-9f6c-9ea152d1ec5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-f125cd0d-9909-4fcf-9c4c-037fbfd82286,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-1ba3c391-e081-42e6-bebe-7c2ac9c297d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-47f9bd11-7dc3-4dfa-a9c3-55314eb17cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-42b7b63a-1018-4fee-8a7e-a40e1d19d3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-d975432f-652f-42ca-96e9-c48456c0eba5,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-0adb6937-e788-4b74-b295-13f520853a7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-337923721-172.17.0.18-1595877822127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40006,DS-67acf994-8d4b-41ec-911a-06373d58fb17,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-3f209c00-4703-4f44-bc9f-a09decfd4431,DISK], DatanodeInfoWithStorage[127.0.0.1:33855,DS-438172f3-d044-42d2-8b9b-3ba5436eb315,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-e77b4846-4707-447a-ad36-28d7533caacb,DISK], DatanodeInfoWithStorage[127.0.0.1:35243,DS-f4861b3a-89a8-436b-9675-dda93d7d42cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-72f60d5c-d4fb-4fdd-b697-8835ad8b3f91,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-90d6fc2e-63ff-4902-9359-d7bda1a24905,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-1cb4b8c6-1d31-4638-b52b-3c029665a7c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-337923721-172.17.0.18-1595877822127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40006,DS-67acf994-8d4b-41ec-911a-06373d58fb17,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-3f209c00-4703-4f44-bc9f-a09decfd4431,DISK], DatanodeInfoWithStorage[127.0.0.1:33855,DS-438172f3-d044-42d2-8b9b-3ba5436eb315,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-e77b4846-4707-447a-ad36-28d7533caacb,DISK], DatanodeInfoWithStorage[127.0.0.1:35243,DS-f4861b3a-89a8-436b-9675-dda93d7d42cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-72f60d5c-d4fb-4fdd-b697-8835ad8b3f91,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-90d6fc2e-63ff-4902-9359-d7bda1a24905,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-1cb4b8c6-1d31-4638-b52b-3c029665a7c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1292911979-172.17.0.18-1595878761347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33527,DS-061f70d5-f31e-4df8-b77f-37e758197835,DISK], DatanodeInfoWithStorage[127.0.0.1:44614,DS-dfd4268d-bd0e-48a0-9e43-9f1c16f1d31a,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-29765946-d9cb-4146-832b-a08d7b4e899b,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-1d82a736-80e9-43fb-9801-98cbe3beca5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43112,DS-f69b665c-ad49-470c-a939-4716e71f9000,DISK], DatanodeInfoWithStorage[127.0.0.1:32787,DS-a08187ec-85ec-487c-9ce1-5ac282e59113,DISK], DatanodeInfoWithStorage[127.0.0.1:46391,DS-a5689298-429f-412c-aff0-1ace5bc80873,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-ec6836b4-322f-408b-b637-af8be9814d21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1292911979-172.17.0.18-1595878761347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33527,DS-061f70d5-f31e-4df8-b77f-37e758197835,DISK], DatanodeInfoWithStorage[127.0.0.1:44614,DS-dfd4268d-bd0e-48a0-9e43-9f1c16f1d31a,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-29765946-d9cb-4146-832b-a08d7b4e899b,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-1d82a736-80e9-43fb-9801-98cbe3beca5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43112,DS-f69b665c-ad49-470c-a939-4716e71f9000,DISK], DatanodeInfoWithStorage[127.0.0.1:32787,DS-a08187ec-85ec-487c-9ce1-5ac282e59113,DISK], DatanodeInfoWithStorage[127.0.0.1:46391,DS-a5689298-429f-412c-aff0-1ace5bc80873,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-ec6836b4-322f-408b-b637-af8be9814d21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-250613901-172.17.0.18-1595879184874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41372,DS-49ff89b3-6628-46bc-aca3-e0ba6fbf0a46,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-83483c71-a2ca-4998-9c5f-c3c9c8d5ff28,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-ad31535d-86ef-4640-84ee-1030eece3664,DISK], DatanodeInfoWithStorage[127.0.0.1:46529,DS-fd44f0de-29ec-4bff-a08b-9721f44c4398,DISK], DatanodeInfoWithStorage[127.0.0.1:45651,DS-0a70d425-a425-447e-8795-521669f8897d,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-664f0725-e1eb-42a5-ab78-e2af36918716,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-30b48240-6f0b-44a6-bd20-d45b6712c996,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-700b81bb-ada3-4238-b169-4ba355dcb86b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-250613901-172.17.0.18-1595879184874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41372,DS-49ff89b3-6628-46bc-aca3-e0ba6fbf0a46,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-83483c71-a2ca-4998-9c5f-c3c9c8d5ff28,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-ad31535d-86ef-4640-84ee-1030eece3664,DISK], DatanodeInfoWithStorage[127.0.0.1:46529,DS-fd44f0de-29ec-4bff-a08b-9721f44c4398,DISK], DatanodeInfoWithStorage[127.0.0.1:45651,DS-0a70d425-a425-447e-8795-521669f8897d,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-664f0725-e1eb-42a5-ab78-e2af36918716,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-30b48240-6f0b-44a6-bd20-d45b6712c996,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-700b81bb-ada3-4238-b169-4ba355dcb86b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5369
