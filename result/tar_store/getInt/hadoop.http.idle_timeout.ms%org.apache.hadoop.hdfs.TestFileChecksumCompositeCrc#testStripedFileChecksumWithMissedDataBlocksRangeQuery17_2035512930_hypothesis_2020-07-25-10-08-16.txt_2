reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-957066593-172.17.0.8-1595671911727:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46014,DS-ffbb7478-076f-43a0-a9dc-5a13b2db685c,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-e1a15200-975a-4d41-a427-95569dba7b02,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-41f8034c-a020-45e8-8a6c-174cf3f6f1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-cc42e2cc-f40f-4f4a-84f3-222546b47d51,DISK], DatanodeInfoWithStorage[127.0.0.1:44776,DS-0a52ec30-fa10-4494-b26b-9ef5953c1121,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-c6f27b6a-a466-461a-9c69-2380d6064d22,DISK], DatanodeInfoWithStorage[127.0.0.1:34121,DS-e62ba2d3-c1f9-4da4-8ea6-49d32c9bb0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-8e8d8aee-82da-4684-ab23-9e2dde5d07ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-957066593-172.17.0.8-1595671911727:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46014,DS-ffbb7478-076f-43a0-a9dc-5a13b2db685c,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-e1a15200-975a-4d41-a427-95569dba7b02,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-41f8034c-a020-45e8-8a6c-174cf3f6f1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-cc42e2cc-f40f-4f4a-84f3-222546b47d51,DISK], DatanodeInfoWithStorage[127.0.0.1:44776,DS-0a52ec30-fa10-4494-b26b-9ef5953c1121,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-c6f27b6a-a466-461a-9c69-2380d6064d22,DISK], DatanodeInfoWithStorage[127.0.0.1:34121,DS-e62ba2d3-c1f9-4da4-8ea6-49d32c9bb0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-8e8d8aee-82da-4684-ab23-9e2dde5d07ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-489290727-172.17.0.8-1595672489805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45832,DS-c43240cd-3499-490a-8846-0978db9150a2,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-4a18311f-2dc6-4e5d-82c6-de3f4a45a485,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-1d078d0d-66cf-4c4f-a5df-61cf071ed67f,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-4679b34e-0256-4600-ba28-91c9ed3da2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36745,DS-8982d1c2-1d9c-4c37-abee-39d76cbdd670,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-e7a83f33-1828-4f2e-984e-f34d4146b71f,DISK], DatanodeInfoWithStorage[127.0.0.1:34448,DS-934824db-7cdc-43be-a5cd-a51467450afa,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-84c89113-7e9a-4d9d-a397-4a50e127f932,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-489290727-172.17.0.8-1595672489805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45832,DS-c43240cd-3499-490a-8846-0978db9150a2,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-4a18311f-2dc6-4e5d-82c6-de3f4a45a485,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-1d078d0d-66cf-4c4f-a5df-61cf071ed67f,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-4679b34e-0256-4600-ba28-91c9ed3da2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36745,DS-8982d1c2-1d9c-4c37-abee-39d76cbdd670,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-e7a83f33-1828-4f2e-984e-f34d4146b71f,DISK], DatanodeInfoWithStorage[127.0.0.1:34448,DS-934824db-7cdc-43be-a5cd-a51467450afa,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-84c89113-7e9a-4d9d-a397-4a50e127f932,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-738003065-172.17.0.8-1595672593678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33292,DS-d2f2de07-2e93-4c3d-8ac0-b4b560c391d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39896,DS-f22a2a47-eebb-402b-b392-9ff4735caa46,DISK], DatanodeInfoWithStorage[127.0.0.1:35431,DS-0f93eb98-e96d-4387-ac2c-99996c890c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-17cf7e3b-fc80-4d62-a824-4c6d14468e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45640,DS-f56aeb99-dc06-457a-825c-6a634243a9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38963,DS-77082762-c46c-472c-bc59-f4e6fbd2173a,DISK], DatanodeInfoWithStorage[127.0.0.1:44272,DS-5c722961-f1f4-407c-a484-9f61eb6ffb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46218,DS-0e1dab64-5514-45ce-84aa-7715be16e0cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-738003065-172.17.0.8-1595672593678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33292,DS-d2f2de07-2e93-4c3d-8ac0-b4b560c391d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39896,DS-f22a2a47-eebb-402b-b392-9ff4735caa46,DISK], DatanodeInfoWithStorage[127.0.0.1:35431,DS-0f93eb98-e96d-4387-ac2c-99996c890c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-17cf7e3b-fc80-4d62-a824-4c6d14468e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45640,DS-f56aeb99-dc06-457a-825c-6a634243a9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38963,DS-77082762-c46c-472c-bc59-f4e6fbd2173a,DISK], DatanodeInfoWithStorage[127.0.0.1:44272,DS-5c722961-f1f4-407c-a484-9f61eb6ffb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46218,DS-0e1dab64-5514-45ce-84aa-7715be16e0cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2028211777-172.17.0.8-1595672700558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46618,DS-3a15013b-ff48-4a40-99ff-435a90a68d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-65090e90-446e-4b9e-b0e6-6b14d196d0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34900,DS-38bd1cea-788c-47b6-b535-26d797140482,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-46645988-5e4a-4f07-8f1e-788e68411eab,DISK], DatanodeInfoWithStorage[127.0.0.1:36544,DS-68054da1-1086-4049-ae92-187343fd0bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-96f34cf0-35e9-4b4a-82e6-a7d7a7251c58,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-4baea07f-e063-44bd-97b0-37f2443485e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-8d7b118d-e243-46c0-bbfb-94c3797b17ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2028211777-172.17.0.8-1595672700558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46618,DS-3a15013b-ff48-4a40-99ff-435a90a68d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-65090e90-446e-4b9e-b0e6-6b14d196d0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34900,DS-38bd1cea-788c-47b6-b535-26d797140482,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-46645988-5e4a-4f07-8f1e-788e68411eab,DISK], DatanodeInfoWithStorage[127.0.0.1:36544,DS-68054da1-1086-4049-ae92-187343fd0bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-96f34cf0-35e9-4b4a-82e6-a7d7a7251c58,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-4baea07f-e063-44bd-97b0-37f2443485e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-8d7b118d-e243-46c0-bbfb-94c3797b17ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-721256155-172.17.0.8-1595673178181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42680,DS-e28d29bd-c43f-4d3b-9ab1-c7fec9ebb3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-d790a220-39d9-4860-a132-aaacc6ba5ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-c169824f-d93b-4d92-bea2-71d52a6b9d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-6176aa7b-1fd7-4916-af47-5be5ef94bf2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-3013d70e-89d0-4dbd-8b62-e6d37e901d96,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-0965e544-b133-4b7b-a6f3-87bad6f1cb56,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-082f3bfa-3f87-4b14-9c2e-9e40f9c21d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-2ba1fa10-9427-437c-9146-b899cbe02647,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-721256155-172.17.0.8-1595673178181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42680,DS-e28d29bd-c43f-4d3b-9ab1-c7fec9ebb3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-d790a220-39d9-4860-a132-aaacc6ba5ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-c169824f-d93b-4d92-bea2-71d52a6b9d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-6176aa7b-1fd7-4916-af47-5be5ef94bf2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-3013d70e-89d0-4dbd-8b62-e6d37e901d96,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-0965e544-b133-4b7b-a6f3-87bad6f1cb56,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-082f3bfa-3f87-4b14-9c2e-9e40f9c21d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-2ba1fa10-9427-437c-9146-b899cbe02647,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-637559273-172.17.0.8-1595673412834:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38347,DS-5dd74253-ebce-42fb-97fb-6ff04d20574a,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-827e0ae3-a4d5-4716-b8f8-154d9fa388d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-ef7781ee-649a-4dc7-b993-be37023ffd24,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-541f46eb-99aa-4d6c-84f0-5b3c017c67b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-35757861-0c6a-44f1-b850-2b605d47b55a,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-cfea3af6-ec62-426a-8f89-730501eb2998,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-3ae34ee1-7cd5-4c48-b1c7-8f8c6e2d551d,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-cd663887-4e74-419c-8cf4-71a287c7e80f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-637559273-172.17.0.8-1595673412834:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38347,DS-5dd74253-ebce-42fb-97fb-6ff04d20574a,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-827e0ae3-a4d5-4716-b8f8-154d9fa388d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-ef7781ee-649a-4dc7-b993-be37023ffd24,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-541f46eb-99aa-4d6c-84f0-5b3c017c67b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-35757861-0c6a-44f1-b850-2b605d47b55a,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-cfea3af6-ec62-426a-8f89-730501eb2998,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-3ae34ee1-7cd5-4c48-b1c7-8f8c6e2d551d,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-cd663887-4e74-419c-8cf4-71a287c7e80f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1802043677-172.17.0.8-1595673575367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42185,DS-c85e02fe-cd9a-4bd0-81fe-4fb0807cf6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-61f42afe-34f6-4ef9-aa23-d1bdc826d265,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-952829aa-2a3c-4b5e-81b0-7bf667cb1060,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-500229bd-d724-442e-b945-17beee1777e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-aafd0075-b296-46b8-98ba-2ee7622a7d62,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-f2cc1c54-5a20-47d8-b7cc-e032cfa3041a,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-d61a0949-2f73-4fe9-abc6-f684f2eba880,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-3d98ebde-80c5-48ba-ad03-bf90eb92616e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1802043677-172.17.0.8-1595673575367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42185,DS-c85e02fe-cd9a-4bd0-81fe-4fb0807cf6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-61f42afe-34f6-4ef9-aa23-d1bdc826d265,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-952829aa-2a3c-4b5e-81b0-7bf667cb1060,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-500229bd-d724-442e-b945-17beee1777e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-aafd0075-b296-46b8-98ba-2ee7622a7d62,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-f2cc1c54-5a20-47d8-b7cc-e032cfa3041a,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-d61a0949-2f73-4fe9-abc6-f684f2eba880,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-3d98ebde-80c5-48ba-ad03-bf90eb92616e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1265926168-172.17.0.8-1595674075657:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41198,DS-b3eaa81e-c8d4-48e9-beb4-610e9ac3cf31,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-47e3fafd-f7e3-4a93-8dd3-bd0156a025f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-d5d05906-3408-4628-8ac3-a165a8dac972,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-bd843278-cb2f-4fe8-a3ef-1c7b96c514ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46587,DS-717f95b2-f7ac-42c3-aa55-ca5e22489d80,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-3660b3c7-3ac8-47fe-8f35-87f5a1b5fc84,DISK], DatanodeInfoWithStorage[127.0.0.1:33073,DS-2bb3bd07-b88f-486e-8f0d-f28af9defdd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-2d3187bd-21e6-45a3-80ba-f762185c10e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1265926168-172.17.0.8-1595674075657:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41198,DS-b3eaa81e-c8d4-48e9-beb4-610e9ac3cf31,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-47e3fafd-f7e3-4a93-8dd3-bd0156a025f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-d5d05906-3408-4628-8ac3-a165a8dac972,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-bd843278-cb2f-4fe8-a3ef-1c7b96c514ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46587,DS-717f95b2-f7ac-42c3-aa55-ca5e22489d80,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-3660b3c7-3ac8-47fe-8f35-87f5a1b5fc84,DISK], DatanodeInfoWithStorage[127.0.0.1:33073,DS-2bb3bd07-b88f-486e-8f0d-f28af9defdd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-2d3187bd-21e6-45a3-80ba-f762185c10e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1250953897-172.17.0.8-1595674330215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33763,DS-b8a42f8a-dde8-4cbd-8efe-265d2cf47bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-1af2c80d-4d04-45f4-867f-a4ccfc17ee2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-f683c189-f04e-49a8-94c8-66e89d451878,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-9680bba6-8d16-4b03-bf7f-df0b09296502,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-51e88133-bb12-499b-b1d4-4870455e193a,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-efd08760-9355-4ad6-a832-25e4b70e7072,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-b735be8f-d539-424d-bacb-624bc6f6ce82,DISK], DatanodeInfoWithStorage[127.0.0.1:45254,DS-37887eb8-aa45-49cf-aee8-b8ee6275bd10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1250953897-172.17.0.8-1595674330215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33763,DS-b8a42f8a-dde8-4cbd-8efe-265d2cf47bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-1af2c80d-4d04-45f4-867f-a4ccfc17ee2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-f683c189-f04e-49a8-94c8-66e89d451878,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-9680bba6-8d16-4b03-bf7f-df0b09296502,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-51e88133-bb12-499b-b1d4-4870455e193a,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-efd08760-9355-4ad6-a832-25e4b70e7072,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-b735be8f-d539-424d-bacb-624bc6f6ce82,DISK], DatanodeInfoWithStorage[127.0.0.1:45254,DS-37887eb8-aa45-49cf-aee8-b8ee6275bd10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1870943129-172.17.0.8-1595674576257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46157,DS-466aa2aa-991f-43ac-8d87-caccd4226d10,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-a9fdfa2a-27e3-4ee8-9cab-8c31e8d89236,DISK], DatanodeInfoWithStorage[127.0.0.1:44021,DS-03625f96-7722-47fe-be64-69f4e3e1fbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36249,DS-fe993072-2f91-43f7-9f22-3735bdac3d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-9f330614-19fb-40e4-a10b-34fcdb4a2b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-1a31b8c3-f81e-41c5-9803-a4cb1fec7549,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-b1042156-117b-4842-a75f-f29772e940a6,DISK], DatanodeInfoWithStorage[127.0.0.1:32859,DS-3d43f850-e010-4e1b-a391-5ff84ce852c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1870943129-172.17.0.8-1595674576257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46157,DS-466aa2aa-991f-43ac-8d87-caccd4226d10,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-a9fdfa2a-27e3-4ee8-9cab-8c31e8d89236,DISK], DatanodeInfoWithStorage[127.0.0.1:44021,DS-03625f96-7722-47fe-be64-69f4e3e1fbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36249,DS-fe993072-2f91-43f7-9f22-3735bdac3d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-9f330614-19fb-40e4-a10b-34fcdb4a2b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-1a31b8c3-f81e-41c5-9803-a4cb1fec7549,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-b1042156-117b-4842-a75f-f29772e940a6,DISK], DatanodeInfoWithStorage[127.0.0.1:32859,DS-3d43f850-e010-4e1b-a391-5ff84ce852c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1985049453-172.17.0.8-1595674604014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32870,DS-d963ecb4-fe92-4f9d-8979-a1d05f8c2190,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-8dd31cf0-c9ca-4f36-97d1-799b21a9f4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-772a00a7-474c-4154-b5d0-96ce258caf22,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-41d367e0-0f8a-417d-a071-c29e331fc6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-462f2631-4564-4c90-ad55-31021c6cfb8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34536,DS-38d144ba-4280-41de-8a3e-2d624ffd31f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-94caed16-0da9-4a6b-b4bd-48374089570b,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-83c2e9d1-696c-43ec-a291-f5c629c535e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1985049453-172.17.0.8-1595674604014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32870,DS-d963ecb4-fe92-4f9d-8979-a1d05f8c2190,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-8dd31cf0-c9ca-4f36-97d1-799b21a9f4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-772a00a7-474c-4154-b5d0-96ce258caf22,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-41d367e0-0f8a-417d-a071-c29e331fc6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-462f2631-4564-4c90-ad55-31021c6cfb8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34536,DS-38d144ba-4280-41de-8a3e-2d624ffd31f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-94caed16-0da9-4a6b-b4bd-48374089570b,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-83c2e9d1-696c-43ec-a291-f5c629c535e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2079976572-172.17.0.8-1595674764401:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33933,DS-d88f4eb4-ba7f-435f-ac2e-564ef26a8e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-a6a944d2-fede-4b39-91cd-7b59dcc19a60,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-a8003835-82ab-420f-80b4-0ea80030d483,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-dd84f8b1-f658-4af2-b83b-9d4b76d124cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-107cd0f1-663b-4c5a-bdba-ca3ba2d16740,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-d72e05ca-ecec-4e4e-ad13-0f93f469f8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-11b846cc-0d75-4785-ab60-e728672d18c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44116,DS-42a6e37e-44fd-46f5-8ac6-b059df57be9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2079976572-172.17.0.8-1595674764401:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33933,DS-d88f4eb4-ba7f-435f-ac2e-564ef26a8e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-a6a944d2-fede-4b39-91cd-7b59dcc19a60,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-a8003835-82ab-420f-80b4-0ea80030d483,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-dd84f8b1-f658-4af2-b83b-9d4b76d124cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-107cd0f1-663b-4c5a-bdba-ca3ba2d16740,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-d72e05ca-ecec-4e4e-ad13-0f93f469f8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-11b846cc-0d75-4785-ab60-e728672d18c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44116,DS-42a6e37e-44fd-46f5-8ac6-b059df57be9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1694878872-172.17.0.8-1595674919663:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33459,DS-f4fa34ab-2214-4f92-ae4a-89df270138f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-1110f1b4-7867-42e0-a68a-a26934955866,DISK], DatanodeInfoWithStorage[127.0.0.1:45691,DS-10c4ec3c-e165-4eaf-8c72-1a98d7df66d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-d5254d82-5625-4fb3-b01a-a5a78b80ef49,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-34005b02-6ba5-4820-88aa-0f2c54a36d86,DISK], DatanodeInfoWithStorage[127.0.0.1:43439,DS-b4686a99-6ea3-41a2-a99d-1ef1e95fd7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-85571889-fbf0-4a16-bfd9-1a67e0cf5a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-be965624-b273-4961-bc0c-f06236643d55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1694878872-172.17.0.8-1595674919663:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33459,DS-f4fa34ab-2214-4f92-ae4a-89df270138f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-1110f1b4-7867-42e0-a68a-a26934955866,DISK], DatanodeInfoWithStorage[127.0.0.1:45691,DS-10c4ec3c-e165-4eaf-8c72-1a98d7df66d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-d5254d82-5625-4fb3-b01a-a5a78b80ef49,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-34005b02-6ba5-4820-88aa-0f2c54a36d86,DISK], DatanodeInfoWithStorage[127.0.0.1:43439,DS-b4686a99-6ea3-41a2-a99d-1ef1e95fd7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-85571889-fbf0-4a16-bfd9-1a67e0cf5a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-be965624-b273-4961-bc0c-f06236643d55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-318675839-172.17.0.8-1595675513488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40702,DS-fd5cadcd-efd5-47ef-85f2-598502b71e63,DISK], DatanodeInfoWithStorage[127.0.0.1:42258,DS-05544c7e-2b5b-4806-b3fb-df330bdd27b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-2bd93f75-4605-4c86-8129-a4309bdb59fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-65184f5d-9c86-4b5c-ab7a-a6e171d719f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-54cdfba7-d315-4c32-bd76-cd6ba794d7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-83bc92d7-860e-42cd-8e3d-052b4ab1fd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-20b1c87a-afbc-4169-bf3d-1b2d361834c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-24a258a7-d249-4742-baff-cd60de1b4567,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-318675839-172.17.0.8-1595675513488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40702,DS-fd5cadcd-efd5-47ef-85f2-598502b71e63,DISK], DatanodeInfoWithStorage[127.0.0.1:42258,DS-05544c7e-2b5b-4806-b3fb-df330bdd27b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-2bd93f75-4605-4c86-8129-a4309bdb59fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-65184f5d-9c86-4b5c-ab7a-a6e171d719f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-54cdfba7-d315-4c32-bd76-cd6ba794d7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-83bc92d7-860e-42cd-8e3d-052b4ab1fd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-20b1c87a-afbc-4169-bf3d-1b2d361834c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-24a258a7-d249-4742-baff-cd60de1b4567,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-740248967-172.17.0.8-1595675615689:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37821,DS-fab95b84-d9e0-4283-b6e0-18bcf6a5559f,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-c49a7760-51b2-4334-bce7-e2f7e7c7d679,DISK], DatanodeInfoWithStorage[127.0.0.1:40342,DS-f029324a-1ef9-499c-ba43-feddacf09c66,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-fba2e608-747a-4eeb-b282-65d1b2516e72,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-b9b263a9-7cfa-4f61-b549-7214fb972f32,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-759eee38-eb99-49b7-a663-89b9d99814fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-bb588e23-b0ad-4313-8962-a83371ba9a55,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-d9ce8da1-65b5-4337-9640-82e810807b32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-740248967-172.17.0.8-1595675615689:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37821,DS-fab95b84-d9e0-4283-b6e0-18bcf6a5559f,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-c49a7760-51b2-4334-bce7-e2f7e7c7d679,DISK], DatanodeInfoWithStorage[127.0.0.1:40342,DS-f029324a-1ef9-499c-ba43-feddacf09c66,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-fba2e608-747a-4eeb-b282-65d1b2516e72,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-b9b263a9-7cfa-4f61-b549-7214fb972f32,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-759eee38-eb99-49b7-a663-89b9d99814fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-bb588e23-b0ad-4313-8962-a83371ba9a55,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-d9ce8da1-65b5-4337-9640-82e810807b32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-638005449-172.17.0.8-1595676254919:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42283,DS-13f5ce26-f026-4279-ab75-0bdd19f808be,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-0c876117-b485-42f3-8187-39812f342538,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-774b7185-100c-442c-8acf-97a8e39803fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-ec33981f-763a-46c8-bfb9-b516a58b639f,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-a6273a3a-4e6b-4901-82c9-8ec37b6798d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42949,DS-57281b78-9c46-4cb0-a882-cccc6bcb9359,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-4cf82bc8-53a9-4cab-93d1-454ac39c29cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-02cdf43d-508e-44ef-bd63-e8146ec1db7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-638005449-172.17.0.8-1595676254919:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42283,DS-13f5ce26-f026-4279-ab75-0bdd19f808be,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-0c876117-b485-42f3-8187-39812f342538,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-774b7185-100c-442c-8acf-97a8e39803fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-ec33981f-763a-46c8-bfb9-b516a58b639f,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-a6273a3a-4e6b-4901-82c9-8ec37b6798d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42949,DS-57281b78-9c46-4cb0-a882-cccc6bcb9359,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-4cf82bc8-53a9-4cab-93d1-454ac39c29cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-02cdf43d-508e-44ef-bd63-e8146ec1db7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 4992
