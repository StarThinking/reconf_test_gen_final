reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-511882811-172.17.0.6-1595807087399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46308,DS-0325d870-18e6-4aeb-bdec-98ac4021cc3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-991e3e64-7c27-4ca6-b317-8042fef0b093,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-16a88715-6178-4a41-b3c4-14009f24d8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-eee1fd82-4753-491a-94cf-318e0039c808,DISK], DatanodeInfoWithStorage[127.0.0.1:33751,DS-35bdd91f-f04e-4646-a094-d71df7b2d27b,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-b5544274-ff69-47f4-b996-5a6bbe69dc15,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-19053b57-4192-4114-8986-c72cfb6a9bac,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-4adf2896-4567-4969-920b-1a6a1428ccbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-511882811-172.17.0.6-1595807087399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46308,DS-0325d870-18e6-4aeb-bdec-98ac4021cc3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-991e3e64-7c27-4ca6-b317-8042fef0b093,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-16a88715-6178-4a41-b3c4-14009f24d8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-eee1fd82-4753-491a-94cf-318e0039c808,DISK], DatanodeInfoWithStorage[127.0.0.1:33751,DS-35bdd91f-f04e-4646-a094-d71df7b2d27b,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-b5544274-ff69-47f4-b996-5a6bbe69dc15,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-19053b57-4192-4114-8986-c72cfb6a9bac,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-4adf2896-4567-4969-920b-1a6a1428ccbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1194427781-172.17.0.6-1595808078101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37563,DS-6c9d7f97-0af1-4725-910e-7dfeca7a39f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-025c16c9-daa9-4505-acfd-859d0a99f9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-0f6a5e2a-3054-4bd4-b0d4-b2721c1e4a71,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-11631d80-23ec-482b-962d-55053e1dc897,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-1d9a2d28-15bb-4c7a-be88-364738015aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-371b002b-e463-4347-92d0-e1d46594e9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-068f7a63-b05c-45b5-9afc-20cb071c8879,DISK], DatanodeInfoWithStorage[127.0.0.1:46326,DS-2eca387d-70d3-4227-9119-896211553524,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1194427781-172.17.0.6-1595808078101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37563,DS-6c9d7f97-0af1-4725-910e-7dfeca7a39f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-025c16c9-daa9-4505-acfd-859d0a99f9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-0f6a5e2a-3054-4bd4-b0d4-b2721c1e4a71,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-11631d80-23ec-482b-962d-55053e1dc897,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-1d9a2d28-15bb-4c7a-be88-364738015aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-371b002b-e463-4347-92d0-e1d46594e9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-068f7a63-b05c-45b5-9afc-20cb071c8879,DISK], DatanodeInfoWithStorage[127.0.0.1:46326,DS-2eca387d-70d3-4227-9119-896211553524,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1453449997-172.17.0.6-1595808612063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38961,DS-6cd117cb-4c73-45a9-bd9f-cc7357b1536d,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-dc392e86-0538-41f6-b104-8700bd2723ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36544,DS-72087b0e-0947-428d-b51e-73662b1df7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33372,DS-21c91a14-8620-4586-94ad-b1468685bf6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37394,DS-de567e6c-c679-432f-bbe1-ff0f136a4235,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-a89a0cc4-adc1-4da2-93fd-293c841583d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-0cd21539-3e38-49a1-b5f1-b5e4036469ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-c6150d02-016e-4890-a123-ad172f744f4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1453449997-172.17.0.6-1595808612063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38961,DS-6cd117cb-4c73-45a9-bd9f-cc7357b1536d,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-dc392e86-0538-41f6-b104-8700bd2723ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36544,DS-72087b0e-0947-428d-b51e-73662b1df7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33372,DS-21c91a14-8620-4586-94ad-b1468685bf6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37394,DS-de567e6c-c679-432f-bbe1-ff0f136a4235,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-a89a0cc4-adc1-4da2-93fd-293c841583d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-0cd21539-3e38-49a1-b5f1-b5e4036469ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-c6150d02-016e-4890-a123-ad172f744f4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1644982203-172.17.0.6-1595808725597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39093,DS-6f10d308-d69b-448f-a898-141ca2bb7a86,DISK], DatanodeInfoWithStorage[127.0.0.1:42443,DS-c6f77b8a-7e6a-475d-9f6e-5165afdbce50,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-4e7ae585-782e-400d-a1b2-135ea597c55b,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-46c3b94b-9749-4d6b-a288-665879d1c881,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-d4b380af-2ce8-4854-8b34-0b3b742ba4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-9eabf0e4-4b27-4527-b9bf-391f345aa01b,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-f5c79692-02e7-49ec-a9be-1fe238e0db50,DISK], DatanodeInfoWithStorage[127.0.0.1:39562,DS-ca11bf6c-7643-4836-ae6d-3e02be46c7e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1644982203-172.17.0.6-1595808725597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39093,DS-6f10d308-d69b-448f-a898-141ca2bb7a86,DISK], DatanodeInfoWithStorage[127.0.0.1:42443,DS-c6f77b8a-7e6a-475d-9f6e-5165afdbce50,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-4e7ae585-782e-400d-a1b2-135ea597c55b,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-46c3b94b-9749-4d6b-a288-665879d1c881,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-d4b380af-2ce8-4854-8b34-0b3b742ba4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-9eabf0e4-4b27-4527-b9bf-391f345aa01b,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-f5c79692-02e7-49ec-a9be-1fe238e0db50,DISK], DatanodeInfoWithStorage[127.0.0.1:39562,DS-ca11bf6c-7643-4836-ae6d-3e02be46c7e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1481141919-172.17.0.6-1595809181906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45095,DS-d51c4832-6a25-47b2-aa06-8ec17a91dc40,DISK], DatanodeInfoWithStorage[127.0.0.1:44869,DS-f990f0a9-e423-4211-b692-9c9fbe04dbfd,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-a7722e63-7f6b-4338-aa7b-43cdb9289cab,DISK], DatanodeInfoWithStorage[127.0.0.1:38133,DS-9e43e2d2-a02a-415a-9880-3d33767b07ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40968,DS-4faa4420-6ac0-4a01-8dbb-c529aaf4f154,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-aebcc1e0-4698-47ca-b361-0b65f8fb64fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-89446ab1-da4c-4b50-8ab8-b6dddd86da5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-63bb79c1-d2c0-41b3-869c-9d429574eef8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1481141919-172.17.0.6-1595809181906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45095,DS-d51c4832-6a25-47b2-aa06-8ec17a91dc40,DISK], DatanodeInfoWithStorage[127.0.0.1:44869,DS-f990f0a9-e423-4211-b692-9c9fbe04dbfd,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-a7722e63-7f6b-4338-aa7b-43cdb9289cab,DISK], DatanodeInfoWithStorage[127.0.0.1:38133,DS-9e43e2d2-a02a-415a-9880-3d33767b07ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40968,DS-4faa4420-6ac0-4a01-8dbb-c529aaf4f154,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-aebcc1e0-4698-47ca-b361-0b65f8fb64fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-89446ab1-da4c-4b50-8ab8-b6dddd86da5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-63bb79c1-d2c0-41b3-869c-9d429574eef8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1875716814-172.17.0.6-1595809417902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34040,DS-11cd5fc7-8917-4de9-b06a-a6bb8deda792,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-e2bde772-f9d0-4c31-b7c1-26475574a839,DISK], DatanodeInfoWithStorage[127.0.0.1:40078,DS-004176ec-5313-462d-a12e-f033a1059c61,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-3d056de7-56a5-4df2-94e2-6e802dc1fa29,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-112f8999-ea57-4b2f-8cc2-b624d1a0317e,DISK], DatanodeInfoWithStorage[127.0.0.1:39829,DS-cd02eb67-146e-4513-b8da-400d2105f7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-ae2a9040-2491-480c-b799-ec88c4592d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41288,DS-73362d90-be1e-4676-9165-1fd787cea27e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1875716814-172.17.0.6-1595809417902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34040,DS-11cd5fc7-8917-4de9-b06a-a6bb8deda792,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-e2bde772-f9d0-4c31-b7c1-26475574a839,DISK], DatanodeInfoWithStorage[127.0.0.1:40078,DS-004176ec-5313-462d-a12e-f033a1059c61,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-3d056de7-56a5-4df2-94e2-6e802dc1fa29,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-112f8999-ea57-4b2f-8cc2-b624d1a0317e,DISK], DatanodeInfoWithStorage[127.0.0.1:39829,DS-cd02eb67-146e-4513-b8da-400d2105f7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-ae2a9040-2491-480c-b799-ec88c4592d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41288,DS-73362d90-be1e-4676-9165-1fd787cea27e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-67710805-172.17.0.6-1595809685989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44408,DS-c14c57b8-4540-4391-b808-3d7b5bb96563,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-c0cf91e1-b7f9-4fd4-b4ba-420318d91d45,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-0ac9f83a-d506-47f5-9aa3-e01624ac03b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36890,DS-db457c05-0b95-44c9-8bd1-728114617235,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-f3250eea-2f1d-4ac3-9cdb-c7c8ec7f7b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-b73f5c87-b2b1-47df-b940-df8e065650f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46181,DS-86aa48d6-5252-457c-aae2-f55b31d8cb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46785,DS-4e28501f-8628-4bd7-9c46-159f0b527349,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-67710805-172.17.0.6-1595809685989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44408,DS-c14c57b8-4540-4391-b808-3d7b5bb96563,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-c0cf91e1-b7f9-4fd4-b4ba-420318d91d45,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-0ac9f83a-d506-47f5-9aa3-e01624ac03b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36890,DS-db457c05-0b95-44c9-8bd1-728114617235,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-f3250eea-2f1d-4ac3-9cdb-c7c8ec7f7b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-b73f5c87-b2b1-47df-b940-df8e065650f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46181,DS-86aa48d6-5252-457c-aae2-f55b31d8cb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46785,DS-4e28501f-8628-4bd7-9c46-159f0b527349,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-676143911-172.17.0.6-1595809947209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46355,DS-68cd337e-1db7-4112-9912-cc1b03575244,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-5cd155cf-78ac-46d5-a1f6-77d81434020e,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-2602cd16-adfb-4982-a4cf-8a3d8ad49e37,DISK], DatanodeInfoWithStorage[127.0.0.1:36742,DS-eb8aeb8d-ad37-4f58-87b4-b2be07b670a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-d865854b-282b-4eb7-9ed2-eaa1a3fb8fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-a9deb57b-4f5c-4318-b072-7dbd8ff02d59,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-ae6800b3-6627-470b-bf64-4c1e94435984,DISK], DatanodeInfoWithStorage[127.0.0.1:42759,DS-2c3c7ea1-da61-4957-a2a7-d509c80e526e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-676143911-172.17.0.6-1595809947209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46355,DS-68cd337e-1db7-4112-9912-cc1b03575244,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-5cd155cf-78ac-46d5-a1f6-77d81434020e,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-2602cd16-adfb-4982-a4cf-8a3d8ad49e37,DISK], DatanodeInfoWithStorage[127.0.0.1:36742,DS-eb8aeb8d-ad37-4f58-87b4-b2be07b670a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-d865854b-282b-4eb7-9ed2-eaa1a3fb8fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-a9deb57b-4f5c-4318-b072-7dbd8ff02d59,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-ae6800b3-6627-470b-bf64-4c1e94435984,DISK], DatanodeInfoWithStorage[127.0.0.1:42759,DS-2c3c7ea1-da61-4957-a2a7-d509c80e526e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-715111360-172.17.0.6-1595810019789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35546,DS-6a98e73f-bd70-446e-90f2-ed14684c61bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-fd14fc46-8ed6-47d7-ba93-227393fe599c,DISK], DatanodeInfoWithStorage[127.0.0.1:46794,DS-c6310813-a56c-4e8f-9935-7a0d68e6566f,DISK], DatanodeInfoWithStorage[127.0.0.1:46182,DS-7f8d89cc-166e-43a2-abd6-3abb3d15130c,DISK], DatanodeInfoWithStorage[127.0.0.1:43778,DS-85ddbbe5-a4e1-443e-b522-f6cdd170a5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36888,DS-6ebcb8e8-e58c-4565-bc72-aedc6e932fab,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-de451872-58be-49d7-9262-1bf01bb607fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-c978d1aa-bd2c-4730-ac6b-cc74eed3d1b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-715111360-172.17.0.6-1595810019789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35546,DS-6a98e73f-bd70-446e-90f2-ed14684c61bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-fd14fc46-8ed6-47d7-ba93-227393fe599c,DISK], DatanodeInfoWithStorage[127.0.0.1:46794,DS-c6310813-a56c-4e8f-9935-7a0d68e6566f,DISK], DatanodeInfoWithStorage[127.0.0.1:46182,DS-7f8d89cc-166e-43a2-abd6-3abb3d15130c,DISK], DatanodeInfoWithStorage[127.0.0.1:43778,DS-85ddbbe5-a4e1-443e-b522-f6cdd170a5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36888,DS-6ebcb8e8-e58c-4565-bc72-aedc6e932fab,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-de451872-58be-49d7-9262-1bf01bb607fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-c978d1aa-bd2c-4730-ac6b-cc74eed3d1b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1759141777-172.17.0.6-1595810421250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36989,DS-8dae7805-7f41-4fa8-abce-8df759b85fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-683497f4-ffb1-4c55-a28c-def501cd6301,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-82282737-dbfb-4101-b42c-af5ea1bc3d08,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-3ab670c9-dcd9-4512-ab79-da0675918be3,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-562f8c62-66d3-4020-a163-2512a49582f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44507,DS-9c8f31d6-da65-4329-9524-bf90687156f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-a031b629-799a-43df-a305-ac4d5f13ecc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36529,DS-616486f8-9939-4d54-8543-638380ad3bcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1759141777-172.17.0.6-1595810421250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36989,DS-8dae7805-7f41-4fa8-abce-8df759b85fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-683497f4-ffb1-4c55-a28c-def501cd6301,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-82282737-dbfb-4101-b42c-af5ea1bc3d08,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-3ab670c9-dcd9-4512-ab79-da0675918be3,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-562f8c62-66d3-4020-a163-2512a49582f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44507,DS-9c8f31d6-da65-4329-9524-bf90687156f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-a031b629-799a-43df-a305-ac4d5f13ecc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36529,DS-616486f8-9939-4d54-8543-638380ad3bcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-352314862-172.17.0.6-1595810707644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33235,DS-9a6b02fb-af4a-4ba3-a730-9a3c14e3faeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-b0e9b7d0-c5ab-468e-95ec-f0d2f8caff6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41075,DS-4f54b44a-cec9-409c-9651-e89973766295,DISK], DatanodeInfoWithStorage[127.0.0.1:43503,DS-310a45b6-bfab-4e8a-a9a0-7329518bffa3,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-a3340057-6e6b-4285-a299-e22cdeacc778,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-68162b6b-a420-4936-aaf9-c893b5a192a2,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-0101928a-8376-4142-92b8-aaabdb742d19,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-d536c13e-98a3-45af-8af5-86ac669aa099,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-352314862-172.17.0.6-1595810707644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33235,DS-9a6b02fb-af4a-4ba3-a730-9a3c14e3faeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-b0e9b7d0-c5ab-468e-95ec-f0d2f8caff6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41075,DS-4f54b44a-cec9-409c-9651-e89973766295,DISK], DatanodeInfoWithStorage[127.0.0.1:43503,DS-310a45b6-bfab-4e8a-a9a0-7329518bffa3,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-a3340057-6e6b-4285-a299-e22cdeacc778,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-68162b6b-a420-4936-aaf9-c893b5a192a2,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-0101928a-8376-4142-92b8-aaabdb742d19,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-d536c13e-98a3-45af-8af5-86ac669aa099,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-898041392-172.17.0.6-1595811078959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39159,DS-2ee87bd6-0939-4ea5-ab4a-c4bd08117ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-62c1afc2-2a8c-4edd-ae38-ae32445b8b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36296,DS-b10ca800-5b86-489f-aa6d-39d1a2dab457,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-7e350f8d-7fca-441b-9f4b-96d6f5cac8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33312,DS-b8afdc1e-897e-4dad-8308-ce8e29ba11f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-3db5b4c4-1c28-4f47-a771-f7e3780a13bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-589741af-5ca2-4eb1-b443-dbf49e17ce44,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-8da2d79b-493f-4849-9704-7e3373cec98b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-898041392-172.17.0.6-1595811078959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39159,DS-2ee87bd6-0939-4ea5-ab4a-c4bd08117ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-62c1afc2-2a8c-4edd-ae38-ae32445b8b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36296,DS-b10ca800-5b86-489f-aa6d-39d1a2dab457,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-7e350f8d-7fca-441b-9f4b-96d6f5cac8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33312,DS-b8afdc1e-897e-4dad-8308-ce8e29ba11f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-3db5b4c4-1c28-4f47-a771-f7e3780a13bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-589741af-5ca2-4eb1-b443-dbf49e17ce44,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-8da2d79b-493f-4849-9704-7e3373cec98b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1657298892-172.17.0.6-1595811147000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35482,DS-53964f35-9255-4fed-8efa-30dfa2926bac,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-acf8af76-e6ad-46f0-b38c-878f3898c72b,DISK], DatanodeInfoWithStorage[127.0.0.1:34985,DS-c4839828-21bb-45d4-8619-35c1021baaaf,DISK], DatanodeInfoWithStorage[127.0.0.1:40275,DS-a73953cc-885e-432a-aa67-ccaafe319508,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-c58ad871-38c5-49fd-9dcd-5f64ab3e800e,DISK], DatanodeInfoWithStorage[127.0.0.1:44673,DS-45d51eb0-1134-42a4-a15d-bf7eb8b5abda,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-33ae7805-dce2-47b0-9ccb-f7b434ac20f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-f6d60fbe-aeb5-4834-82a1-20dabc7a22b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1657298892-172.17.0.6-1595811147000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35482,DS-53964f35-9255-4fed-8efa-30dfa2926bac,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-acf8af76-e6ad-46f0-b38c-878f3898c72b,DISK], DatanodeInfoWithStorage[127.0.0.1:34985,DS-c4839828-21bb-45d4-8619-35c1021baaaf,DISK], DatanodeInfoWithStorage[127.0.0.1:40275,DS-a73953cc-885e-432a-aa67-ccaafe319508,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-c58ad871-38c5-49fd-9dcd-5f64ab3e800e,DISK], DatanodeInfoWithStorage[127.0.0.1:44673,DS-45d51eb0-1134-42a4-a15d-bf7eb8b5abda,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-33ae7805-dce2-47b0-9ccb-f7b434ac20f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-f6d60fbe-aeb5-4834-82a1-20dabc7a22b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2105804310-172.17.0.6-1595811723089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46448,DS-55d8361a-7a11-4251-981b-84b5530e1f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-93cb9262-015a-4052-8f3b-07fe57abbe50,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-bde3036b-31aa-445a-a012-2c5a4485d455,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-fbd2ce28-5986-46a8-8db9-7fb3bf6c19df,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-5c685b8b-fb06-45ee-85b9-d62588646142,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-b4c16d13-c199-44a7-9368-d58ac4cd7176,DISK], DatanodeInfoWithStorage[127.0.0.1:37553,DS-8030edbe-d4d1-4b9c-8a06-81113c9b23a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-54c727c4-5cce-4eff-8f5e-36fb514e885a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2105804310-172.17.0.6-1595811723089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46448,DS-55d8361a-7a11-4251-981b-84b5530e1f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-93cb9262-015a-4052-8f3b-07fe57abbe50,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-bde3036b-31aa-445a-a012-2c5a4485d455,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-fbd2ce28-5986-46a8-8db9-7fb3bf6c19df,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-5c685b8b-fb06-45ee-85b9-d62588646142,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-b4c16d13-c199-44a7-9368-d58ac4cd7176,DISK], DatanodeInfoWithStorage[127.0.0.1:37553,DS-8030edbe-d4d1-4b9c-8a06-81113c9b23a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-54c727c4-5cce-4eff-8f5e-36fb514e885a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2120686904-172.17.0.6-1595811911353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34992,DS-34478806-eabd-471d-9b40-44c2402db556,DISK], DatanodeInfoWithStorage[127.0.0.1:37283,DS-6b1ea312-6d27-459b-af46-878c3ee149d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-f4a81688-d66e-4947-b5e8-553df987109e,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-edd7065c-e61b-4352-a55e-fb6755982d74,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-5fb9374c-0407-4766-b9a8-c5ec3b60f8de,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-c421fa43-348c-4a3e-910f-5137f8aac047,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-3aa6d616-1e0e-46fa-8cdd-c3278562c24c,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-0372decb-d482-4377-b8c2-1c85a8d800e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2120686904-172.17.0.6-1595811911353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34992,DS-34478806-eabd-471d-9b40-44c2402db556,DISK], DatanodeInfoWithStorage[127.0.0.1:37283,DS-6b1ea312-6d27-459b-af46-878c3ee149d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-f4a81688-d66e-4947-b5e8-553df987109e,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-edd7065c-e61b-4352-a55e-fb6755982d74,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-5fb9374c-0407-4766-b9a8-c5ec3b60f8de,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-c421fa43-348c-4a3e-910f-5137f8aac047,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-3aa6d616-1e0e-46fa-8cdd-c3278562c24c,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-0372decb-d482-4377-b8c2-1c85a8d800e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1415063103-172.17.0.6-1595812280162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41355,DS-7a8f8e6f-a816-4285-a699-b508722bdacf,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-b6c4cb4c-b89b-4e39-9e99-e94c663b705d,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-7b9dad8b-3c5a-46cf-a68e-0b36574ef469,DISK], DatanodeInfoWithStorage[127.0.0.1:35871,DS-cc720eba-5e33-45f8-afb4-a073d18f3c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-6bd1a888-d586-4e7f-8dcd-f51c053e9bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-24e91465-99ea-4f47-baf1-48b1cba9e895,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-f5c5c63f-1501-44e8-a314-fd785391964c,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-4c2262ad-8c36-4688-843f-9b5f947e500c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1415063103-172.17.0.6-1595812280162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41355,DS-7a8f8e6f-a816-4285-a699-b508722bdacf,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-b6c4cb4c-b89b-4e39-9e99-e94c663b705d,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-7b9dad8b-3c5a-46cf-a68e-0b36574ef469,DISK], DatanodeInfoWithStorage[127.0.0.1:35871,DS-cc720eba-5e33-45f8-afb4-a073d18f3c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-6bd1a888-d586-4e7f-8dcd-f51c053e9bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-24e91465-99ea-4f47-baf1-48b1cba9e895,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-f5c5c63f-1501-44e8-a314-fd785391964c,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-4c2262ad-8c36-4688-843f-9b5f947e500c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1485275980-172.17.0.6-1595812428215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44631,DS-12e70668-eea4-48db-af37-0c42dacf823f,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-0f76c45b-4d4e-47bb-b72b-e8e04344e873,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-f31dca97-96be-44e5-b584-120377511c90,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-091808a4-32b6-4035-9b64-3e8f364b21cc,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-26a69e2d-1fd5-4da2-90b9-d25cc1daa639,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-30c9063c-5a75-4e9e-a21a-42661426aa68,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-65a04dd1-c15a-4b85-9552-33d5ed1fbc17,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-e871c877-fe71-4b4e-a6e2-8c62d3fed3d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1485275980-172.17.0.6-1595812428215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44631,DS-12e70668-eea4-48db-af37-0c42dacf823f,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-0f76c45b-4d4e-47bb-b72b-e8e04344e873,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-f31dca97-96be-44e5-b584-120377511c90,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-091808a4-32b6-4035-9b64-3e8f364b21cc,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-26a69e2d-1fd5-4da2-90b9-d25cc1daa639,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-30c9063c-5a75-4e9e-a21a-42661426aa68,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-65a04dd1-c15a-4b85-9552-33d5ed1fbc17,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-e871c877-fe71-4b4e-a6e2-8c62d3fed3d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 30
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-551475341-172.17.0.6-1595812460561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37108,DS-dab22434-54c1-44a6-8d0a-0e4b7b689d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-8a0080a6-ff34-456f-b1cb-326483febb80,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-07925b0f-d70a-4e6a-9130-c33792364213,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-d8c4c011-eae3-48b6-a6a3-f117258f6d88,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-d6c9b369-27fd-4cb2-8e3a-96aebf26f53f,DISK], DatanodeInfoWithStorage[127.0.0.1:41744,DS-a0c63e34-cbb6-49b7-975e-82f7b66fec29,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-964254b1-4a86-4ec3-ac97-b6fee7b534d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-92c00a8f-cc64-43c2-a345-7180cec3c75a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-551475341-172.17.0.6-1595812460561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37108,DS-dab22434-54c1-44a6-8d0a-0e4b7b689d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-8a0080a6-ff34-456f-b1cb-326483febb80,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-07925b0f-d70a-4e6a-9130-c33792364213,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-d8c4c011-eae3-48b6-a6a3-f117258f6d88,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-d6c9b369-27fd-4cb2-8e3a-96aebf26f53f,DISK], DatanodeInfoWithStorage[127.0.0.1:41744,DS-a0c63e34-cbb6-49b7-975e-82f7b66fec29,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-964254b1-4a86-4ec3-ac97-b6fee7b534d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-92c00a8f-cc64-43c2-a345-7180cec3c75a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5452
