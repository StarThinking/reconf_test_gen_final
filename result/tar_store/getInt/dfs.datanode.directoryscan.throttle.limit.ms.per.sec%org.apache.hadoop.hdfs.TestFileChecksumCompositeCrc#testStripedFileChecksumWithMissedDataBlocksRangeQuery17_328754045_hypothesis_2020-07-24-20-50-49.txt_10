reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1883835290-172.17.0.19-1595624030453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43804,DS-4d523827-be33-4386-9a4e-e414c1b97691,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-c153bfa7-7696-4232-9d6c-c6a0a174773a,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-2dde2556-cd52-4b13-86c3-1e7e515b0789,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-f8b9b2bb-3fbc-4085-8782-87fd0ab25920,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-881a0003-2f0b-452c-a80a-5793d3c34fca,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-c4c622e8-9ec3-42ab-ab6c-854a304e9d96,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-2fe5eeaf-173a-434f-b25a-868ed43a25b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38345,DS-b52c2103-31f7-4b16-bbdb-6c08af02cdb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1883835290-172.17.0.19-1595624030453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43804,DS-4d523827-be33-4386-9a4e-e414c1b97691,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-c153bfa7-7696-4232-9d6c-c6a0a174773a,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-2dde2556-cd52-4b13-86c3-1e7e515b0789,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-f8b9b2bb-3fbc-4085-8782-87fd0ab25920,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-881a0003-2f0b-452c-a80a-5793d3c34fca,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-c4c622e8-9ec3-42ab-ab6c-854a304e9d96,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-2fe5eeaf-173a-434f-b25a-868ed43a25b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38345,DS-b52c2103-31f7-4b16-bbdb-6c08af02cdb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1460074694-172.17.0.19-1595624340723:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38796,DS-2cbc05c5-b072-49eb-bb9c-acf864ca6c35,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-f93a58ad-6903-449a-88af-3fd3fe9ee3af,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-40ed5119-5522-4b6d-928f-fdf4fae7e15b,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-cffc7e34-18e9-4c3c-bed0-4ac75d0d13e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-f624ef14-5645-4d63-8a1d-8f6b28e746b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-58f2b20a-01cd-4380-aae5-c2cc09805911,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-1dffc9e6-a9ce-4a22-87a2-adb2c9972a36,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-e7b25005-ef32-437c-855e-7cc465c4c28a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1460074694-172.17.0.19-1595624340723:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38796,DS-2cbc05c5-b072-49eb-bb9c-acf864ca6c35,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-f93a58ad-6903-449a-88af-3fd3fe9ee3af,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-40ed5119-5522-4b6d-928f-fdf4fae7e15b,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-cffc7e34-18e9-4c3c-bed0-4ac75d0d13e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-f624ef14-5645-4d63-8a1d-8f6b28e746b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-58f2b20a-01cd-4380-aae5-c2cc09805911,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-1dffc9e6-a9ce-4a22-87a2-adb2c9972a36,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-e7b25005-ef32-437c-855e-7cc465c4c28a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1186486482-172.17.0.19-1595624397978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37559,DS-d6c63d05-e4c5-433e-8222-847ae896cd91,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-04e25c78-37a7-44dc-8f33-bc3f18b4ff36,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-c3350d18-ac33-4a36-a662-e7c3cc6d8eff,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-8037032e-3506-460f-8115-e5cf301b10cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-392d2aa8-11c7-4216-b211-5b2e58bb6bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-008d3400-75f4-4020-93bb-e54fe6422d64,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-6ac73f87-a4b8-4f44-b9dc-2943ee92bc69,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-b0b0982e-4cdf-49cc-9e7f-438c92b87099,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1186486482-172.17.0.19-1595624397978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37559,DS-d6c63d05-e4c5-433e-8222-847ae896cd91,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-04e25c78-37a7-44dc-8f33-bc3f18b4ff36,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-c3350d18-ac33-4a36-a662-e7c3cc6d8eff,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-8037032e-3506-460f-8115-e5cf301b10cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-392d2aa8-11c7-4216-b211-5b2e58bb6bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-008d3400-75f4-4020-93bb-e54fe6422d64,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-6ac73f87-a4b8-4f44-b9dc-2943ee92bc69,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-b0b0982e-4cdf-49cc-9e7f-438c92b87099,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-31572456-172.17.0.19-1595624845363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42665,DS-40008dc5-cd85-4722-a4d1-82e744e0c2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-8957b043-2a74-4591-a71f-a97506366e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-0d999294-3a02-4b5c-a4ea-82dfb0b36b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-a6373f45-e1c0-4c80-b311-c8b20c5c3bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-f2090102-b463-481a-b5d8-bb8d80a70b27,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-b71a2e6d-95e6-4efc-8317-99ae711cfed7,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-87bbf5dd-7e8f-49b4-9da2-9723d8c88aff,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-af949021-481c-4974-a2bc-f207aa407bdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-31572456-172.17.0.19-1595624845363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42665,DS-40008dc5-cd85-4722-a4d1-82e744e0c2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-8957b043-2a74-4591-a71f-a97506366e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-0d999294-3a02-4b5c-a4ea-82dfb0b36b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-a6373f45-e1c0-4c80-b311-c8b20c5c3bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-f2090102-b463-481a-b5d8-bb8d80a70b27,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-b71a2e6d-95e6-4efc-8317-99ae711cfed7,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-87bbf5dd-7e8f-49b4-9da2-9723d8c88aff,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-af949021-481c-4974-a2bc-f207aa407bdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1064241373-172.17.0.19-1595624948217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39249,DS-0be3e4f7-7284-4d53-9efa-0fff7804e337,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-dba3ba52-d68a-4344-8bc3-0a6d436a5d03,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-d453def7-b439-47d1-8655-0f81fd52473d,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-8a72a410-6dd4-49f4-b033-73acaf704449,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-42ee55ef-b5ab-4ab6-95e1-12a43bc4a45f,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-45d04e39-0a2a-4c9e-ba08-60a9ed959c53,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-717cd749-10e0-43b3-ba8d-3f27518e02c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-72221aab-1565-4030-aa10-fe79f4e1a273,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1064241373-172.17.0.19-1595624948217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39249,DS-0be3e4f7-7284-4d53-9efa-0fff7804e337,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-dba3ba52-d68a-4344-8bc3-0a6d436a5d03,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-d453def7-b439-47d1-8655-0f81fd52473d,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-8a72a410-6dd4-49f4-b033-73acaf704449,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-42ee55ef-b5ab-4ab6-95e1-12a43bc4a45f,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-45d04e39-0a2a-4c9e-ba08-60a9ed959c53,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-717cd749-10e0-43b3-ba8d-3f27518e02c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-72221aab-1565-4030-aa10-fe79f4e1a273,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2014110594-172.17.0.19-1595624983944:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36944,DS-b894db97-0fd2-4a7c-985e-2dd00e51db03,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-804e4ad9-7949-431d-9dbf-ea756fea9dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-5abfedeb-237d-452e-9096-fbce2fed9a84,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-9d59c7b6-0fab-4404-90ac-79adc241ccd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-ac140c08-c119-41c1-8694-a4fbb86f11bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37881,DS-18902809-e815-4bf5-bb99-38d88e595aea,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-dd15df5b-9441-4c61-87f7-f34e0dc5e58c,DISK], DatanodeInfoWithStorage[127.0.0.1:41798,DS-e30c055b-309b-41e1-bb10-3ff05e0d273d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2014110594-172.17.0.19-1595624983944:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36944,DS-b894db97-0fd2-4a7c-985e-2dd00e51db03,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-804e4ad9-7949-431d-9dbf-ea756fea9dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-5abfedeb-237d-452e-9096-fbce2fed9a84,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-9d59c7b6-0fab-4404-90ac-79adc241ccd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-ac140c08-c119-41c1-8694-a4fbb86f11bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37881,DS-18902809-e815-4bf5-bb99-38d88e595aea,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-dd15df5b-9441-4c61-87f7-f34e0dc5e58c,DISK], DatanodeInfoWithStorage[127.0.0.1:41798,DS-e30c055b-309b-41e1-bb10-3ff05e0d273d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-984261155-172.17.0.19-1595625452864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33778,DS-389af1b3-f89e-49e6-9e0f-f86ae23387df,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-97f2b94b-b09d-48db-ad90-716895c59afd,DISK], DatanodeInfoWithStorage[127.0.0.1:34078,DS-618c923c-e2df-4f06-8de2-d44ca5b1cb52,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-f9d77889-afe4-4155-978e-96a5dec31768,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-b127d743-1735-4170-b227-eb7b361f3e26,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-1f473e39-54c5-47d1-99e2-f10af65ea483,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-538fadc7-ba7d-4cd2-a318-bc202e145dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-4a4e0a81-cc36-4265-8227-977130dc28a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-984261155-172.17.0.19-1595625452864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33778,DS-389af1b3-f89e-49e6-9e0f-f86ae23387df,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-97f2b94b-b09d-48db-ad90-716895c59afd,DISK], DatanodeInfoWithStorage[127.0.0.1:34078,DS-618c923c-e2df-4f06-8de2-d44ca5b1cb52,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-f9d77889-afe4-4155-978e-96a5dec31768,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-b127d743-1735-4170-b227-eb7b361f3e26,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-1f473e39-54c5-47d1-99e2-f10af65ea483,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-538fadc7-ba7d-4cd2-a318-bc202e145dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-4a4e0a81-cc36-4265-8227-977130dc28a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-559070125-172.17.0.19-1595625487138:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39266,DS-87f32f72-2dc0-4a33-8870-617a75dfd2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-de13bb49-7ebe-45ed-a092-edc02e2e6a29,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-070ddf33-5672-4714-bbca-a17eeb2421a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-17a16bd4-1b14-4664-8189-f96288a0a269,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-4ab677b8-52e3-446a-a7d9-987444277ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-e0166b12-5c3e-4964-836b-2f0fb4177065,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-9e409382-a693-4a2a-9f6b-1ee77e0c4c38,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-bc6bf4b7-fe4f-456b-b119-203914bc476e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-559070125-172.17.0.19-1595625487138:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39266,DS-87f32f72-2dc0-4a33-8870-617a75dfd2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-de13bb49-7ebe-45ed-a092-edc02e2e6a29,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-070ddf33-5672-4714-bbca-a17eeb2421a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-17a16bd4-1b14-4664-8189-f96288a0a269,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-4ab677b8-52e3-446a-a7d9-987444277ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-e0166b12-5c3e-4964-836b-2f0fb4177065,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-9e409382-a693-4a2a-9f6b-1ee77e0c4c38,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-bc6bf4b7-fe4f-456b-b119-203914bc476e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-613273654-172.17.0.19-1595625590756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44859,DS-0be115b8-c16b-4a78-8fab-238b0387de08,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-8013369b-d3ba-4d2c-a650-a6ebc3cd4d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-e45ba2cb-760e-40bb-ac8d-2b7db3f4d871,DISK], DatanodeInfoWithStorage[127.0.0.1:38828,DS-a2256230-ae45-47ec-8efb-04351bc49895,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-121194c9-ae74-4649-a66f-0b8d6aee5461,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-92ef173f-fe9c-430b-9934-1f6e805496fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39867,DS-794b4bd6-9fc8-4c55-a052-18b9368c4940,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-abf9bc59-73c7-4d48-9dd3-2c03fb4fc354,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-613273654-172.17.0.19-1595625590756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44859,DS-0be115b8-c16b-4a78-8fab-238b0387de08,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-8013369b-d3ba-4d2c-a650-a6ebc3cd4d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-e45ba2cb-760e-40bb-ac8d-2b7db3f4d871,DISK], DatanodeInfoWithStorage[127.0.0.1:38828,DS-a2256230-ae45-47ec-8efb-04351bc49895,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-121194c9-ae74-4649-a66f-0b8d6aee5461,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-92ef173f-fe9c-430b-9934-1f6e805496fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39867,DS-794b4bd6-9fc8-4c55-a052-18b9368c4940,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-abf9bc59-73c7-4d48-9dd3-2c03fb4fc354,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-237674987-172.17.0.19-1595626202520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39991,DS-d8b55cbc-dd57-46e1-8107-b966b283e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-d1a2e4b7-a227-48c0-99e6-31b28ee0889f,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-bf4cddec-9e38-4967-bea9-dee8742538ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35282,DS-a8242220-937c-4cc3-b7aa-fb42dc903fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:46623,DS-93915b9f-3911-4e87-9dc9-c268cbccb3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-2a43afc5-57ce-49be-a483-23fc10f02e42,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-2fa60414-f68a-44da-b0d2-64be430534f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-4213d9d8-8ada-434b-a47f-d0664834f57f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-237674987-172.17.0.19-1595626202520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39991,DS-d8b55cbc-dd57-46e1-8107-b966b283e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-d1a2e4b7-a227-48c0-99e6-31b28ee0889f,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-bf4cddec-9e38-4967-bea9-dee8742538ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35282,DS-a8242220-937c-4cc3-b7aa-fb42dc903fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:46623,DS-93915b9f-3911-4e87-9dc9-c268cbccb3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-2a43afc5-57ce-49be-a483-23fc10f02e42,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-2fa60414-f68a-44da-b0d2-64be430534f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-4213d9d8-8ada-434b-a47f-d0664834f57f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-537508660-172.17.0.19-1595626308738:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36162,DS-d314b37a-55ec-4855-9699-e0d367ead1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-1c4b0f7f-02fc-4c89-bd94-f0fe7e448d88,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-7b8a036a-c551-4d2c-a451-461290b9c4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-b4c32218-046e-4076-96da-e2b7ce971809,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-d77601cb-3197-4c8c-a224-76959593d52b,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-b3b65980-4a19-4e2f-9a12-45bc09bd4de5,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-1e18eba8-8c20-437c-9dbd-5f0931963943,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-50c9368d-d8e0-46ae-abd7-b91848471915,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-537508660-172.17.0.19-1595626308738:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36162,DS-d314b37a-55ec-4855-9699-e0d367ead1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-1c4b0f7f-02fc-4c89-bd94-f0fe7e448d88,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-7b8a036a-c551-4d2c-a451-461290b9c4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-b4c32218-046e-4076-96da-e2b7ce971809,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-d77601cb-3197-4c8c-a224-76959593d52b,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-b3b65980-4a19-4e2f-9a12-45bc09bd4de5,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-1e18eba8-8c20-437c-9dbd-5f0931963943,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-50c9368d-d8e0-46ae-abd7-b91848471915,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-29511818-172.17.0.19-1595626533002:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41011,DS-608eaa54-2676-4de0-9b39-68b37b93a87c,DISK], DatanodeInfoWithStorage[127.0.0.1:41505,DS-160d57aa-2c9a-4b08-8d8f-6bfbfe0e4f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-ee864372-7d32-4738-8e66-9647c79f9fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-55bdfad0-c8b5-4781-9033-4cc1f2223654,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-ddff29f9-de87-4052-a0c1-b3d9b3aaf7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-4c2da24d-277d-4010-bd20-f0cc4b5dd76d,DISK], DatanodeInfoWithStorage[127.0.0.1:36693,DS-276b63d0-8f86-48ce-ae83-a5380a6c28cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-16135889-1c1c-4218-8383-60d174e27eeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-29511818-172.17.0.19-1595626533002:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41011,DS-608eaa54-2676-4de0-9b39-68b37b93a87c,DISK], DatanodeInfoWithStorage[127.0.0.1:41505,DS-160d57aa-2c9a-4b08-8d8f-6bfbfe0e4f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-ee864372-7d32-4738-8e66-9647c79f9fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-55bdfad0-c8b5-4781-9033-4cc1f2223654,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-ddff29f9-de87-4052-a0c1-b3d9b3aaf7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-4c2da24d-277d-4010-bd20-f0cc4b5dd76d,DISK], DatanodeInfoWithStorage[127.0.0.1:36693,DS-276b63d0-8f86-48ce-ae83-a5380a6c28cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-16135889-1c1c-4218-8383-60d174e27eeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-535190428-172.17.0.19-1595626796551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36506,DS-b0014546-10c8-4d80-a3b9-ae64206d84fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-cf026afd-0c24-49c8-becc-68a0a916e0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-510bc455-6f65-491e-855f-a29a739d5ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-56d80c59-8c63-4f7e-9902-7095ffa97354,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-911e8d76-adeb-4f9b-b4b0-b4bf280e2b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-121b1d1a-e7d2-4acf-8824-05c972223253,DISK], DatanodeInfoWithStorage[127.0.0.1:42679,DS-b61e885b-01f1-4432-ad73-1d41ffbe9205,DISK], DatanodeInfoWithStorage[127.0.0.1:41000,DS-0277bd27-9416-4aff-9eaa-57b756947e97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-535190428-172.17.0.19-1595626796551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36506,DS-b0014546-10c8-4d80-a3b9-ae64206d84fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-cf026afd-0c24-49c8-becc-68a0a916e0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-510bc455-6f65-491e-855f-a29a739d5ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-56d80c59-8c63-4f7e-9902-7095ffa97354,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-911e8d76-adeb-4f9b-b4b0-b4bf280e2b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-121b1d1a-e7d2-4acf-8824-05c972223253,DISK], DatanodeInfoWithStorage[127.0.0.1:42679,DS-b61e885b-01f1-4432-ad73-1d41ffbe9205,DISK], DatanodeInfoWithStorage[127.0.0.1:41000,DS-0277bd27-9416-4aff-9eaa-57b756947e97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1043416954-172.17.0.19-1595627196019:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36012,DS-23aa5cd8-7605-4408-be19-e3018a793095,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-4629e552-5e08-41b4-90cf-72690c780322,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-cc6f64bf-3c69-441b-8a8b-137a1f2b42b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-a946cbd2-655e-4906-84d9-35a5f7347a90,DISK], DatanodeInfoWithStorage[127.0.0.1:34453,DS-a24bbc8f-94aa-4110-9908-0efefcdf0fde,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-9e9f45a0-cb10-412e-84e1-29390f7de576,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-210a22b0-1c82-444a-8a98-acbfef311d33,DISK], DatanodeInfoWithStorage[127.0.0.1:46264,DS-cd6139db-93db-4314-b1ff-d46aeb3c18b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1043416954-172.17.0.19-1595627196019:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36012,DS-23aa5cd8-7605-4408-be19-e3018a793095,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-4629e552-5e08-41b4-90cf-72690c780322,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-cc6f64bf-3c69-441b-8a8b-137a1f2b42b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-a946cbd2-655e-4906-84d9-35a5f7347a90,DISK], DatanodeInfoWithStorage[127.0.0.1:34453,DS-a24bbc8f-94aa-4110-9908-0efefcdf0fde,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-9e9f45a0-cb10-412e-84e1-29390f7de576,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-210a22b0-1c82-444a-8a98-acbfef311d33,DISK], DatanodeInfoWithStorage[127.0.0.1:46264,DS-cd6139db-93db-4314-b1ff-d46aeb3c18b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1502888658-172.17.0.19-1595627262171:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40496,DS-5350967c-3e97-4f1c-9061-2b44df2592c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-7e5731a0-da7f-4e14-a6c4-4548e9784d03,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-ebdd3f7e-dc12-4ba6-80f3-5e16ce21647d,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-efc04807-3e36-42dd-8cc6-74a6c75111c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-050abb2c-e7b8-47fa-888e-816861276401,DISK], DatanodeInfoWithStorage[127.0.0.1:45362,DS-02f4cb03-d751-40fa-b4c5-8a6cd5cbc322,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-3d5ea51d-69cd-44e0-a0b7-3d5f0d615d84,DISK], DatanodeInfoWithStorage[127.0.0.1:39504,DS-d367ccf6-6b0f-4d83-a82f-564b2d250cb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1502888658-172.17.0.19-1595627262171:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40496,DS-5350967c-3e97-4f1c-9061-2b44df2592c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-7e5731a0-da7f-4e14-a6c4-4548e9784d03,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-ebdd3f7e-dc12-4ba6-80f3-5e16ce21647d,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-efc04807-3e36-42dd-8cc6-74a6c75111c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-050abb2c-e7b8-47fa-888e-816861276401,DISK], DatanodeInfoWithStorage[127.0.0.1:45362,DS-02f4cb03-d751-40fa-b4c5-8a6cd5cbc322,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-3d5ea51d-69cd-44e0-a0b7-3d5f0d615d84,DISK], DatanodeInfoWithStorage[127.0.0.1:39504,DS-d367ccf6-6b0f-4d83-a82f-564b2d250cb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-85169784-172.17.0.19-1595627367197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37178,DS-f2c3a38c-2049-47aa-aba5-305638a5b4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-3cdd9f38-1287-412f-af49-30a098ebed1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-31625b98-8666-40f4-ae1d-cff6edd6a634,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-fe98282e-466f-4d86-b255-662283fa542b,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-d563bd8c-610d-4055-b7d0-350e93b0b316,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-c4c2992d-a098-48f4-8bbf-4169a1eb8d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-87f1751f-5802-4c3d-91db-e9a893c41178,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-9f126dad-19ca-48c7-9a4a-23c5f178a71c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-85169784-172.17.0.19-1595627367197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37178,DS-f2c3a38c-2049-47aa-aba5-305638a5b4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-3cdd9f38-1287-412f-af49-30a098ebed1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-31625b98-8666-40f4-ae1d-cff6edd6a634,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-fe98282e-466f-4d86-b255-662283fa542b,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-d563bd8c-610d-4055-b7d0-350e93b0b316,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-c4c2992d-a098-48f4-8bbf-4169a1eb8d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-87f1751f-5802-4c3d-91db-e9a893c41178,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-9f126dad-19ca-48c7-9a4a-23c5f178a71c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-743733318-172.17.0.19-1595627444339:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35123,DS-f324e7db-2a6f-497e-9a44-1f6768c7e356,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-a8de13b7-e992-4d6d-aa19-5461c60c49d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-435aeb07-d5fb-4117-8b07-98ad35acf873,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-a76ea420-60b7-4356-be42-ea34acc8930b,DISK], DatanodeInfoWithStorage[127.0.0.1:41166,DS-b927e3df-78d8-4e21-b9ce-88fff6a32ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-29733a74-6851-48ac-a30a-891f5e0b23a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-f8a1da65-a304-4767-a836-5faed2f0b94f,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-95dd2781-578f-4ffa-9c4c-9e3a13d1baad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-743733318-172.17.0.19-1595627444339:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35123,DS-f324e7db-2a6f-497e-9a44-1f6768c7e356,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-a8de13b7-e992-4d6d-aa19-5461c60c49d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-435aeb07-d5fb-4117-8b07-98ad35acf873,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-a76ea420-60b7-4356-be42-ea34acc8930b,DISK], DatanodeInfoWithStorage[127.0.0.1:41166,DS-b927e3df-78d8-4e21-b9ce-88fff6a32ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-29733a74-6851-48ac-a30a-891f5e0b23a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-f8a1da65-a304-4767-a836-5faed2f0b94f,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-95dd2781-578f-4ffa-9c4c-9e3a13d1baad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1117009725-172.17.0.19-1595627712091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33485,DS-7881fa6f-51ee-4bd4-bcc7-c019cc5d8270,DISK], DatanodeInfoWithStorage[127.0.0.1:44780,DS-684412dc-f5aa-44e0-954d-4af262e6f488,DISK], DatanodeInfoWithStorage[127.0.0.1:42007,DS-0775b2a8-bbe9-4003-9f01-c4b47975d45a,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-7d1fd68d-cab2-4c93-85d2-ad4a528644ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-d52a7c0c-ca03-4591-9263-a3c9650d5cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-10ec83e0-c4aa-4207-aab6-b996a35b9b26,DISK], DatanodeInfoWithStorage[127.0.0.1:45714,DS-b24fafb7-7d69-445c-b00a-d556d1cb3bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-afb5c18e-bdef-4c28-9f38-312bbec7ff30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1117009725-172.17.0.19-1595627712091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33485,DS-7881fa6f-51ee-4bd4-bcc7-c019cc5d8270,DISK], DatanodeInfoWithStorage[127.0.0.1:44780,DS-684412dc-f5aa-44e0-954d-4af262e6f488,DISK], DatanodeInfoWithStorage[127.0.0.1:42007,DS-0775b2a8-bbe9-4003-9f01-c4b47975d45a,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-7d1fd68d-cab2-4c93-85d2-ad4a528644ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-d52a7c0c-ca03-4591-9263-a3c9650d5cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-10ec83e0-c4aa-4207-aab6-b996a35b9b26,DISK], DatanodeInfoWithStorage[127.0.0.1:45714,DS-b24fafb7-7d69-445c-b00a-d556d1cb3bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-afb5c18e-bdef-4c28-9f38-312bbec7ff30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1279162035-172.17.0.19-1595627748535:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33301,DS-d5ab2d60-532c-4a86-b053-4d1839e26619,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-19d0436b-cb26-4579-97c5-e49c2b14eb66,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-a018b7c2-d90e-4db4-9158-9aac3cce7058,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-db250044-70c5-487c-a1a3-76dfdf821d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-3b19a702-e465-4035-aee1-2fb73bcdb1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-22cb0be5-d508-4dfe-8762-19a1e3061be3,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-bacb1148-a15a-4fc2-ad5e-701bc9481f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38420,DS-f0faf2fa-a244-4776-adf8-01e2798036db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1279162035-172.17.0.19-1595627748535:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33301,DS-d5ab2d60-532c-4a86-b053-4d1839e26619,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-19d0436b-cb26-4579-97c5-e49c2b14eb66,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-a018b7c2-d90e-4db4-9158-9aac3cce7058,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-db250044-70c5-487c-a1a3-76dfdf821d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-3b19a702-e465-4035-aee1-2fb73bcdb1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-22cb0be5-d508-4dfe-8762-19a1e3061be3,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-bacb1148-a15a-4fc2-ad5e-701bc9481f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38420,DS-f0faf2fa-a244-4776-adf8-01e2798036db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1215790276-172.17.0.19-1595627855252:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37435,DS-ddf40935-d9f2-4c50-b195-6934d67e2075,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-e74946cd-ba6a-4520-8217-fd55d65396d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45354,DS-c165dc7e-41b7-4c78-a862-d74717b85dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-a577d25d-decf-4561-bac5-027ca3dc542d,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-7c20c8c7-2249-41a1-9bad-5a0875c6d96c,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-20cdfdbc-2dea-4dcb-96fd-afcc9eccfa04,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-f7faf43c-d67f-40ff-9720-3eebe3aa0f38,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-ef4a29fc-62fb-4ee5-b43a-6e3f4abf9b4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1215790276-172.17.0.19-1595627855252:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37435,DS-ddf40935-d9f2-4c50-b195-6934d67e2075,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-e74946cd-ba6a-4520-8217-fd55d65396d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45354,DS-c165dc7e-41b7-4c78-a862-d74717b85dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-a577d25d-decf-4561-bac5-027ca3dc542d,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-7c20c8c7-2249-41a1-9bad-5a0875c6d96c,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-20cdfdbc-2dea-4dcb-96fd-afcc9eccfa04,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-f7faf43c-d67f-40ff-9720-3eebe3aa0f38,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-ef4a29fc-62fb-4ee5-b43a-6e3f4abf9b4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1978378774-172.17.0.19-1595628081044:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33955,DS-985ab001-b5c9-45d0-aa65-d04ecf9a5700,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-de6931eb-603c-4eff-ad4c-d75240c6840d,DISK], DatanodeInfoWithStorage[127.0.0.1:42742,DS-1b560737-ea27-4ffc-b10d-49173fddaca0,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-f14905da-6dfe-492e-bba7-c1c8d08ae8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45266,DS-3b89e6d4-6a76-4aa1-a26b-1a1814a5ca08,DISK], DatanodeInfoWithStorage[127.0.0.1:39215,DS-e11b99ed-c40f-481f-b19c-ebb299e86952,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-0d7a431b-9128-4bf6-9d25-f9b54d4b772c,DISK], DatanodeInfoWithStorage[127.0.0.1:33192,DS-324f67b9-3629-4be1-a7f0-cfca6343cecf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1978378774-172.17.0.19-1595628081044:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33955,DS-985ab001-b5c9-45d0-aa65-d04ecf9a5700,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-de6931eb-603c-4eff-ad4c-d75240c6840d,DISK], DatanodeInfoWithStorage[127.0.0.1:42742,DS-1b560737-ea27-4ffc-b10d-49173fddaca0,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-f14905da-6dfe-492e-bba7-c1c8d08ae8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45266,DS-3b89e6d4-6a76-4aa1-a26b-1a1814a5ca08,DISK], DatanodeInfoWithStorage[127.0.0.1:39215,DS-e11b99ed-c40f-481f-b19c-ebb299e86952,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-0d7a431b-9128-4bf6-9d25-f9b54d4b772c,DISK], DatanodeInfoWithStorage[127.0.0.1:33192,DS-324f67b9-3629-4be1-a7f0-cfca6343cecf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-978793027-172.17.0.19-1595628159705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34952,DS-ea5e680a-4719-4cd7-9a29-fa2d474bfc38,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-5700cfee-033f-4f8b-b65f-62194e81a608,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-115b06ac-8d81-492a-a9f6-07694ba197fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-472da13e-6486-4117-9c26-b5bde79238d7,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-8576eebf-df19-4a0c-8db8-f9868ea64073,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-b7e5f42f-e2b1-474b-a6ab-dcd1d53553c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-188657ad-4721-4828-8125-3488df1cb4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-7c2a3f1d-c532-4a8b-a79e-edcd1b7f9139,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-978793027-172.17.0.19-1595628159705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34952,DS-ea5e680a-4719-4cd7-9a29-fa2d474bfc38,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-5700cfee-033f-4f8b-b65f-62194e81a608,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-115b06ac-8d81-492a-a9f6-07694ba197fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-472da13e-6486-4117-9c26-b5bde79238d7,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-8576eebf-df19-4a0c-8db8-f9868ea64073,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-b7e5f42f-e2b1-474b-a6ab-dcd1d53553c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-188657ad-4721-4828-8125-3488df1cb4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-7c2a3f1d-c532-4a8b-a79e-edcd1b7f9139,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2141038212-172.17.0.19-1595628526810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44105,DS-d15ef223-8f56-4c74-9b7d-fb085c22ec5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-d73f002c-e9dd-4ac5-9c97-c4c6fa7ed8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-331dd723-26a9-41cc-9815-d030aba6b6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-b0a93882-bb62-459e-898e-407aa8932614,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-4f3626d5-fb25-4508-a7d2-354f8c2bccb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-e3faf659-a6a0-4003-a003-7b8a2f055d78,DISK], DatanodeInfoWithStorage[127.0.0.1:40833,DS-541aecac-e557-4a07-b103-667cd71d061c,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-8db126dc-67ba-408a-a858-46e86efc15d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2141038212-172.17.0.19-1595628526810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44105,DS-d15ef223-8f56-4c74-9b7d-fb085c22ec5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-d73f002c-e9dd-4ac5-9c97-c4c6fa7ed8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-331dd723-26a9-41cc-9815-d030aba6b6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-b0a93882-bb62-459e-898e-407aa8932614,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-4f3626d5-fb25-4508-a7d2-354f8c2bccb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-e3faf659-a6a0-4003-a003-7b8a2f055d78,DISK], DatanodeInfoWithStorage[127.0.0.1:40833,DS-541aecac-e557-4a07-b103-667cd71d061c,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-8db126dc-67ba-408a-a858-46e86efc15d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5105
