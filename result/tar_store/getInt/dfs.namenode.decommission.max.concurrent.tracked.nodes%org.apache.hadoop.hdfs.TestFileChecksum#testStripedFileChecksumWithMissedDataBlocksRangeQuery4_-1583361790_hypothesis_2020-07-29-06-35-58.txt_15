reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1789173086-172.17.0.2-1596004605774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44511,DS-7935b6f9-7d02-4753-a012-ef1d9f767f42,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-61a09e46-d1cd-4c86-80b8-997775a8bcc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-d535398c-6c28-43bf-82f5-358a07ab4ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-1bc9d895-7cbc-4e23-9dc8-ef043c0979d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-4fdacfb1-5918-4bd6-bf2e-ea9d3b3dc8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-4faf69f6-6663-4191-947c-6bc816df92f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-8a9531a2-32ee-416a-914c-5aa00c3843f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-f1e27c25-7dc2-42dc-9caf-496fdb8b9914,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1789173086-172.17.0.2-1596004605774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44511,DS-7935b6f9-7d02-4753-a012-ef1d9f767f42,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-61a09e46-d1cd-4c86-80b8-997775a8bcc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-d535398c-6c28-43bf-82f5-358a07ab4ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-1bc9d895-7cbc-4e23-9dc8-ef043c0979d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-4fdacfb1-5918-4bd6-bf2e-ea9d3b3dc8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-4faf69f6-6663-4191-947c-6bc816df92f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-8a9531a2-32ee-416a-914c-5aa00c3843f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-f1e27c25-7dc2-42dc-9caf-496fdb8b9914,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1042362061-172.17.0.2-1596004722089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43655,DS-339e5534-00b8-42d0-a788-1a4b13ff5ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:46428,DS-f6169973-dbff-41c9-81b7-9d39ce0438f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-b9aa1dd1-6cb0-4e18-a83b-1517a326c4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-cca9d1bd-33a5-42d6-beec-29792f4382bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33949,DS-c1e6b1d8-c8e6-4099-a76d-0e28d9395f99,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-25f3b4bf-c253-492b-b8e4-9acd13a569b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-29ec9868-b70d-486b-97e6-257a3bb5efce,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-6dbe3afb-c1e1-4ea9-a6a5-18ca83612260,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1042362061-172.17.0.2-1596004722089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43655,DS-339e5534-00b8-42d0-a788-1a4b13ff5ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:46428,DS-f6169973-dbff-41c9-81b7-9d39ce0438f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-b9aa1dd1-6cb0-4e18-a83b-1517a326c4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-cca9d1bd-33a5-42d6-beec-29792f4382bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33949,DS-c1e6b1d8-c8e6-4099-a76d-0e28d9395f99,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-25f3b4bf-c253-492b-b8e4-9acd13a569b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-29ec9868-b70d-486b-97e6-257a3bb5efce,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-6dbe3afb-c1e1-4ea9-a6a5-18ca83612260,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1583885455-172.17.0.2-1596004806877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42483,DS-cabaf6c7-d8f8-42aa-93d3-e60063d4bce7,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-6c0b88d7-31bf-44e2-bdf5-1b8ab330f692,DISK], DatanodeInfoWithStorage[127.0.0.1:35392,DS-b6845bf7-2a27-4f21-ae6e-f9dbba2d9855,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-da399373-32c5-4f77-9181-4a96249b42e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-e5477d68-35ae-4239-9210-9f139fdc88f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-ab424d80-4730-4004-afc1-b1ed690e309e,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-7f022d2b-5b61-4b26-bec8-3f9efd1a83b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-2a7cb11e-5e86-4117-ab16-d820ee9e6d20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1583885455-172.17.0.2-1596004806877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42483,DS-cabaf6c7-d8f8-42aa-93d3-e60063d4bce7,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-6c0b88d7-31bf-44e2-bdf5-1b8ab330f692,DISK], DatanodeInfoWithStorage[127.0.0.1:35392,DS-b6845bf7-2a27-4f21-ae6e-f9dbba2d9855,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-da399373-32c5-4f77-9181-4a96249b42e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-e5477d68-35ae-4239-9210-9f139fdc88f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-ab424d80-4730-4004-afc1-b1ed690e309e,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-7f022d2b-5b61-4b26-bec8-3f9efd1a83b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-2a7cb11e-5e86-4117-ab16-d820ee9e6d20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-349792163-172.17.0.2-1596004877615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34436,DS-583ca62a-b11e-453e-b3c5-b04291e44013,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-c71f78cb-44b9-4e07-ab71-7bf76abca18e,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-6f8d48d2-e794-4e88-8797-82da453073cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-a82ea70a-ad2d-431d-bd22-3f24b0bcfa04,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-def5b484-ff00-409c-862f-666844c0414c,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-18d9db3e-e6af-4cc9-9b23-35ffaecf49ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40979,DS-779da4a9-fb0f-4e23-98b5-90c72d4c630b,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-8db113e3-f8d2-4c86-bf8d-68d4abed5785,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-349792163-172.17.0.2-1596004877615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34436,DS-583ca62a-b11e-453e-b3c5-b04291e44013,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-c71f78cb-44b9-4e07-ab71-7bf76abca18e,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-6f8d48d2-e794-4e88-8797-82da453073cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-a82ea70a-ad2d-431d-bd22-3f24b0bcfa04,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-def5b484-ff00-409c-862f-666844c0414c,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-18d9db3e-e6af-4cc9-9b23-35ffaecf49ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40979,DS-779da4a9-fb0f-4e23-98b5-90c72d4c630b,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-8db113e3-f8d2-4c86-bf8d-68d4abed5785,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1888561313-172.17.0.2-1596004911983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46344,DS-66c729a3-831b-4e24-8532-3f31e24c88c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-06357a02-0cbc-4730-a166-bd766867a54e,DISK], DatanodeInfoWithStorage[127.0.0.1:43938,DS-b4ec32cd-e8eb-48b1-8de1-ac68c37341f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-8c068282-f30b-4e2c-90c7-572a7aa9253b,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-953a995e-eb0c-446b-b50f-97fc771a1c93,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-2a70c9e9-4661-4177-b226-08ea20271435,DISK], DatanodeInfoWithStorage[127.0.0.1:46623,DS-6282d44b-8dea-45f4-8cf0-22e33fe54602,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-b86215ba-6421-479c-a55e-a7ac77ce3186,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1888561313-172.17.0.2-1596004911983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46344,DS-66c729a3-831b-4e24-8532-3f31e24c88c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-06357a02-0cbc-4730-a166-bd766867a54e,DISK], DatanodeInfoWithStorage[127.0.0.1:43938,DS-b4ec32cd-e8eb-48b1-8de1-ac68c37341f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-8c068282-f30b-4e2c-90c7-572a7aa9253b,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-953a995e-eb0c-446b-b50f-97fc771a1c93,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-2a70c9e9-4661-4177-b226-08ea20271435,DISK], DatanodeInfoWithStorage[127.0.0.1:46623,DS-6282d44b-8dea-45f4-8cf0-22e33fe54602,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-b86215ba-6421-479c-a55e-a7ac77ce3186,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1610635067-172.17.0.2-1596005468483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35309,DS-b251e63b-a7e3-4292-968e-2207bb75a4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-7eeef265-3db7-4322-96a6-a2af030cb6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-a10b2916-3525-437b-8993-962c4f44f26e,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-5b192306-9c65-4b94-8a79-98fa4ff3b6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40668,DS-0170d90a-951c-441f-841e-fccf3bf34139,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-2156f4e8-78b5-4a98-b242-6406574dc464,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-7bc6e57b-ce62-438a-9f8d-52061ccc222c,DISK], DatanodeInfoWithStorage[127.0.0.1:33875,DS-3ed63d3c-cf29-4c07-9e98-22052088c61c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1610635067-172.17.0.2-1596005468483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35309,DS-b251e63b-a7e3-4292-968e-2207bb75a4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-7eeef265-3db7-4322-96a6-a2af030cb6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-a10b2916-3525-437b-8993-962c4f44f26e,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-5b192306-9c65-4b94-8a79-98fa4ff3b6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40668,DS-0170d90a-951c-441f-841e-fccf3bf34139,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-2156f4e8-78b5-4a98-b242-6406574dc464,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-7bc6e57b-ce62-438a-9f8d-52061ccc222c,DISK], DatanodeInfoWithStorage[127.0.0.1:33875,DS-3ed63d3c-cf29-4c07-9e98-22052088c61c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1488127563-172.17.0.2-1596005948913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35151,DS-2db87886-bb3f-4507-b722-6acb90c730bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-c4653954-40fe-4ba8-8510-52607843a095,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-885757fe-5baf-4f5c-8ef9-331760ce41bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-e5fd617b-4ec9-411c-8111-43dbddc8a830,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-1eb707a8-6698-4b2e-bc87-8e0373437656,DISK], DatanodeInfoWithStorage[127.0.0.1:45330,DS-679c30d6-6ccb-4b36-9fa8-53108999076d,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-cb3cb366-e38d-4c5d-969b-b6e009f56a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-6af14b70-4ea1-456e-a893-56f9bab0297e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1488127563-172.17.0.2-1596005948913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35151,DS-2db87886-bb3f-4507-b722-6acb90c730bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-c4653954-40fe-4ba8-8510-52607843a095,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-885757fe-5baf-4f5c-8ef9-331760ce41bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-e5fd617b-4ec9-411c-8111-43dbddc8a830,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-1eb707a8-6698-4b2e-bc87-8e0373437656,DISK], DatanodeInfoWithStorage[127.0.0.1:45330,DS-679c30d6-6ccb-4b36-9fa8-53108999076d,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-cb3cb366-e38d-4c5d-969b-b6e009f56a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-6af14b70-4ea1-456e-a893-56f9bab0297e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-261394427-172.17.0.2-1596006058355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39668,DS-16afe6ad-44c0-4777-86ee-1c02eb64267f,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-880ee0ed-ddd8-431a-8d97-b699df8643db,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-ad2caf50-81b8-40fc-a8e1-0a2957cff6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40413,DS-f843ba57-9107-4290-8315-aeec20d8e6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-96cdf04e-260c-42c3-ad86-a278cb71212b,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-41d90dee-ead6-43bb-ad26-dad7225b0811,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-05afd016-14e2-48ce-930b-e1470196481d,DISK], DatanodeInfoWithStorage[127.0.0.1:38584,DS-aa8aa76a-a62e-4e29-a51d-1ffb09b90a69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-261394427-172.17.0.2-1596006058355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39668,DS-16afe6ad-44c0-4777-86ee-1c02eb64267f,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-880ee0ed-ddd8-431a-8d97-b699df8643db,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-ad2caf50-81b8-40fc-a8e1-0a2957cff6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40413,DS-f843ba57-9107-4290-8315-aeec20d8e6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-96cdf04e-260c-42c3-ad86-a278cb71212b,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-41d90dee-ead6-43bb-ad26-dad7225b0811,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-05afd016-14e2-48ce-930b-e1470196481d,DISK], DatanodeInfoWithStorage[127.0.0.1:38584,DS-aa8aa76a-a62e-4e29-a51d-1ffb09b90a69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1308641973-172.17.0.2-1596006502177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39399,DS-6ad663a5-9aab-4eea-975b-fee94a02850a,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-2eeafbbc-93ca-47f0-aec1-82a766b716b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-ba4e58a3-8fc5-4890-a81f-3a6244b81f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-30ba3203-e282-469d-af6e-86484bbba2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-b262eb0e-54d0-49d7-873f-592830ad59a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-18cc73b6-babf-4db0-9f43-fcc895b2bf01,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-7687b402-2b3f-45c6-8b97-0429db26dc40,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-8e5890f3-c258-4228-b2aa-a261f6d0fecb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1308641973-172.17.0.2-1596006502177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39399,DS-6ad663a5-9aab-4eea-975b-fee94a02850a,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-2eeafbbc-93ca-47f0-aec1-82a766b716b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-ba4e58a3-8fc5-4890-a81f-3a6244b81f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-30ba3203-e282-469d-af6e-86484bbba2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-b262eb0e-54d0-49d7-873f-592830ad59a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-18cc73b6-babf-4db0-9f43-fcc895b2bf01,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-7687b402-2b3f-45c6-8b97-0429db26dc40,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-8e5890f3-c258-4228-b2aa-a261f6d0fecb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1567212907-172.17.0.2-1596006744704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40242,DS-7c384786-a563-46b2-861e-3a24b3b9c941,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-4c6b65a5-b09f-4f12-8c3b-c6a1aedca9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42509,DS-039c112f-127d-4f6e-b292-f1d8b9004bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-46f5b42c-27b8-4ed1-9e18-528093061aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-e86f6eec-405a-4410-bf10-8eb37124ef5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-5fcbad98-be03-493e-b271-8e4dc9db0db4,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-ab3ee3ce-3cb0-4d51-9f54-3b9355cbaff0,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-2ec1e8e2-4c64-4aef-b51a-71f374d522cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1567212907-172.17.0.2-1596006744704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40242,DS-7c384786-a563-46b2-861e-3a24b3b9c941,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-4c6b65a5-b09f-4f12-8c3b-c6a1aedca9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42509,DS-039c112f-127d-4f6e-b292-f1d8b9004bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-46f5b42c-27b8-4ed1-9e18-528093061aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-e86f6eec-405a-4410-bf10-8eb37124ef5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-5fcbad98-be03-493e-b271-8e4dc9db0db4,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-ab3ee3ce-3cb0-4d51-9f54-3b9355cbaff0,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-2ec1e8e2-4c64-4aef-b51a-71f374d522cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-225516158-172.17.0.2-1596006890653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43454,DS-f6e8d9d8-f112-47b5-a60f-9d7d028a62d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37444,DS-40e6a023-4fd5-4994-863f-7878ce1ca0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-52b99862-4c67-44e6-a780-9c79f047deab,DISK], DatanodeInfoWithStorage[127.0.0.1:45330,DS-975ca26c-c880-4cec-9ced-eb30ad0a79db,DISK], DatanodeInfoWithStorage[127.0.0.1:34786,DS-4bc7ff72-bd12-4c4f-ab85-86941938d4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43906,DS-f4a33e1b-4238-4e39-a463-cc14d17e86c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37366,DS-5d84cd53-5f21-4bf0-925e-5f70032bff95,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-3a836c1e-0c1e-42dd-bfcd-972a6dbb9859,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-225516158-172.17.0.2-1596006890653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43454,DS-f6e8d9d8-f112-47b5-a60f-9d7d028a62d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37444,DS-40e6a023-4fd5-4994-863f-7878ce1ca0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-52b99862-4c67-44e6-a780-9c79f047deab,DISK], DatanodeInfoWithStorage[127.0.0.1:45330,DS-975ca26c-c880-4cec-9ced-eb30ad0a79db,DISK], DatanodeInfoWithStorage[127.0.0.1:34786,DS-4bc7ff72-bd12-4c4f-ab85-86941938d4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43906,DS-f4a33e1b-4238-4e39-a463-cc14d17e86c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37366,DS-5d84cd53-5f21-4bf0-925e-5f70032bff95,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-3a836c1e-0c1e-42dd-bfcd-972a6dbb9859,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1533817873-172.17.0.2-1596007716366:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36107,DS-307abd22-1333-450b-9788-adc67fc40858,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-775e03a4-dd57-4275-b474-aaa0cb780d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-02ba0259-5613-4123-8f00-2751d2a5c410,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-66886d6e-2c2e-4439-9f5e-6fc902e9c04c,DISK], DatanodeInfoWithStorage[127.0.0.1:32793,DS-e6ec4ef5-01eb-4735-b0de-a632c6407610,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-c5aaebac-b9ce-4e11-80c4-51e6290c87c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-032cfb1e-f987-4933-a430-c3fe1d3b010d,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-6eab8f62-42ec-4b48-a45e-28d65b9f78e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1533817873-172.17.0.2-1596007716366:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36107,DS-307abd22-1333-450b-9788-adc67fc40858,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-775e03a4-dd57-4275-b474-aaa0cb780d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-02ba0259-5613-4123-8f00-2751d2a5c410,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-66886d6e-2c2e-4439-9f5e-6fc902e9c04c,DISK], DatanodeInfoWithStorage[127.0.0.1:32793,DS-e6ec4ef5-01eb-4735-b0de-a632c6407610,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-c5aaebac-b9ce-4e11-80c4-51e6290c87c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-032cfb1e-f987-4933-a430-c3fe1d3b010d,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-6eab8f62-42ec-4b48-a45e-28d65b9f78e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1964728339-172.17.0.2-1596008816196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33766,DS-c3b9da19-8515-4468-8e96-73d106f1cc00,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-d4e81970-2144-4745-9131-3f07aab1e7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-28efbe21-0143-4a27-ae06-fe0cd83f4776,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-fce192ec-c9ce-4d17-bb48-53a8a1011879,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-b8d5e45b-6767-4cf6-b201-54a03bfc3dad,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-786878d8-8efc-407d-9e51-3ceba8b6272b,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-10e06aef-8232-4643-aef9-072ff33ac8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34129,DS-69e9d99c-3612-47d1-a560-03128280db1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1964728339-172.17.0.2-1596008816196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33766,DS-c3b9da19-8515-4468-8e96-73d106f1cc00,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-d4e81970-2144-4745-9131-3f07aab1e7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-28efbe21-0143-4a27-ae06-fe0cd83f4776,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-fce192ec-c9ce-4d17-bb48-53a8a1011879,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-b8d5e45b-6767-4cf6-b201-54a03bfc3dad,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-786878d8-8efc-407d-9e51-3ceba8b6272b,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-10e06aef-8232-4643-aef9-072ff33ac8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34129,DS-69e9d99c-3612-47d1-a560-03128280db1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-939031484-172.17.0.2-1596009039298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43228,DS-448a899a-d82e-4f6c-a9a0-6e8ea0995bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-589528cf-976d-4134-a737-2721d64be07e,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-652871cb-c5fb-4085-95b9-bc9948287e11,DISK], DatanodeInfoWithStorage[127.0.0.1:44352,DS-81ff65bb-de03-4e04-807c-c92693ed3d06,DISK], DatanodeInfoWithStorage[127.0.0.1:44777,DS-b4210e51-8ebb-4a84-80d7-542dd96f2957,DISK], DatanodeInfoWithStorage[127.0.0.1:44916,DS-f952fb1d-aa87-4e31-b6ab-5f56aa29b87f,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-6aad2c41-aee8-4f35-b02a-aff9391355fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32929,DS-4dfcc465-fc2f-4145-98da-4ae0d60ab407,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-939031484-172.17.0.2-1596009039298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43228,DS-448a899a-d82e-4f6c-a9a0-6e8ea0995bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-589528cf-976d-4134-a737-2721d64be07e,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-652871cb-c5fb-4085-95b9-bc9948287e11,DISK], DatanodeInfoWithStorage[127.0.0.1:44352,DS-81ff65bb-de03-4e04-807c-c92693ed3d06,DISK], DatanodeInfoWithStorage[127.0.0.1:44777,DS-b4210e51-8ebb-4a84-80d7-542dd96f2957,DISK], DatanodeInfoWithStorage[127.0.0.1:44916,DS-f952fb1d-aa87-4e31-b6ab-5f56aa29b87f,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-6aad2c41-aee8-4f35-b02a-aff9391355fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32929,DS-4dfcc465-fc2f-4145-98da-4ae0d60ab407,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-918681209-172.17.0.2-1596009111070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46605,DS-8be9ae87-a604-468b-92d4-966d8d827170,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-69b20e39-840f-4cec-93d0-bcb146f9ef25,DISK], DatanodeInfoWithStorage[127.0.0.1:44674,DS-3b2621e8-cdd5-4a66-8244-a36aa04da93c,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-96e79116-f19e-4dfe-962c-367f29771724,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-a53010d7-da7f-4eee-b5c2-170e3d54ea4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-968c88e6-43cc-4083-ba61-a255495d5bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-90898d45-7b29-481f-9337-0bda9e753d11,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-27727b01-b7f6-4ed5-845f-d5baac74ec7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-918681209-172.17.0.2-1596009111070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46605,DS-8be9ae87-a604-468b-92d4-966d8d827170,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-69b20e39-840f-4cec-93d0-bcb146f9ef25,DISK], DatanodeInfoWithStorage[127.0.0.1:44674,DS-3b2621e8-cdd5-4a66-8244-a36aa04da93c,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-96e79116-f19e-4dfe-962c-367f29771724,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-a53010d7-da7f-4eee-b5c2-170e3d54ea4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-968c88e6-43cc-4083-ba61-a255495d5bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-90898d45-7b29-481f-9337-0bda9e753d11,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-27727b01-b7f6-4ed5-845f-d5baac74ec7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1861121037-172.17.0.2-1596009605898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35765,DS-68717ee9-ca0a-41df-b4ac-377bb3d9fc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-5b3b975d-3707-479e-9ea0-e2f65e91f923,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-a61479cf-7e81-45af-88d1-7ced17928af3,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-84f5c308-0432-4d79-ae84-3e15c6a733c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-e40d8730-eede-4d29-91ed-6140990a3c24,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-98c628de-117c-4707-8dfb-b14ea438ef02,DISK], DatanodeInfoWithStorage[127.0.0.1:40186,DS-7a4dc5ca-65ef-4050-a674-233438771538,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-9de6d25a-0da1-4aa8-ac65-96a925acbf2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1861121037-172.17.0.2-1596009605898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35765,DS-68717ee9-ca0a-41df-b4ac-377bb3d9fc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-5b3b975d-3707-479e-9ea0-e2f65e91f923,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-a61479cf-7e81-45af-88d1-7ced17928af3,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-84f5c308-0432-4d79-ae84-3e15c6a733c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-e40d8730-eede-4d29-91ed-6140990a3c24,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-98c628de-117c-4707-8dfb-b14ea438ef02,DISK], DatanodeInfoWithStorage[127.0.0.1:40186,DS-7a4dc5ca-65ef-4050-a674-233438771538,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-9de6d25a-0da1-4aa8-ac65-96a925acbf2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092615895-172.17.0.2-1596009920868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40774,DS-0de04f01-24c5-45ea-8477-43d869441a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-25704b62-6b27-43b8-a703-a6d78b03d7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34554,DS-761fbfec-807b-452f-8cab-01c495809c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-8a627eac-c7af-4048-8b56-bce56d6e796f,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-b85cd34e-eb3e-4e5c-97b2-1419dfde22d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-ff33ee98-644f-4e05-b5d8-75af3f5b543d,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-437437cd-ea02-4f90-a7a4-7d66ae643d72,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-f5062bcc-d1c3-41ef-97e4-d09964c60f87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092615895-172.17.0.2-1596009920868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40774,DS-0de04f01-24c5-45ea-8477-43d869441a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-25704b62-6b27-43b8-a703-a6d78b03d7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34554,DS-761fbfec-807b-452f-8cab-01c495809c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-8a627eac-c7af-4048-8b56-bce56d6e796f,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-b85cd34e-eb3e-4e5c-97b2-1419dfde22d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-ff33ee98-644f-4e05-b5d8-75af3f5b543d,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-437437cd-ea02-4f90-a7a4-7d66ae643d72,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-f5062bcc-d1c3-41ef-97e4-d09964c60f87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5414
