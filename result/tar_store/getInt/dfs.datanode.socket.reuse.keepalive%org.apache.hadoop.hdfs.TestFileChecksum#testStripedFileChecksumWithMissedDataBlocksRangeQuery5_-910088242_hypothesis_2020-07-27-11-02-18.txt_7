reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1461802727-172.17.0.11-1595848019084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39061,DS-0c111be1-4827-4ad2-ac28-c2897c90fc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-f6d5d348-d2bf-4d74-a9bf-5d9dffe7e9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-73287bbe-129b-4cac-8591-155607251f58,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-a54a3610-c808-4462-998b-0da2f93d5828,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-b0b371f2-cf96-45ab-87de-d59a0aa9f402,DISK], DatanodeInfoWithStorage[127.0.0.1:36561,DS-183ef610-8851-46e6-9090-70409c95bd61,DISK], DatanodeInfoWithStorage[127.0.0.1:45969,DS-ad660253-109f-47a9-9f7d-6965464bb074,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-d86c734b-4ac2-45c4-b164-796b6bde4100,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1461802727-172.17.0.11-1595848019084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39061,DS-0c111be1-4827-4ad2-ac28-c2897c90fc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-f6d5d348-d2bf-4d74-a9bf-5d9dffe7e9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-73287bbe-129b-4cac-8591-155607251f58,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-a54a3610-c808-4462-998b-0da2f93d5828,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-b0b371f2-cf96-45ab-87de-d59a0aa9f402,DISK], DatanodeInfoWithStorage[127.0.0.1:36561,DS-183ef610-8851-46e6-9090-70409c95bd61,DISK], DatanodeInfoWithStorage[127.0.0.1:45969,DS-ad660253-109f-47a9-9f7d-6965464bb074,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-d86c734b-4ac2-45c4-b164-796b6bde4100,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-938051302-172.17.0.11-1595848094486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40717,DS-4d0bb8ba-c036-4d2d-a794-b08b8f01c65e,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-6f715b9c-e705-4a24-acc9-f62d59220d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-6777065a-5906-49a7-bdb1-70fd3e64e8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-178def6e-3c24-40ff-aa7e-4877d6fe4558,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-d9bf8df4-4081-43ef-8bc4-134c8ffaa383,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-9f063e78-1577-4e8c-8d4b-e36b7be0f863,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-76b62bfc-2c70-4d86-9b64-0abe5d680807,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-c63e4464-71e4-4853-83bd-0dd06f1d2dd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-938051302-172.17.0.11-1595848094486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40717,DS-4d0bb8ba-c036-4d2d-a794-b08b8f01c65e,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-6f715b9c-e705-4a24-acc9-f62d59220d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-6777065a-5906-49a7-bdb1-70fd3e64e8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-178def6e-3c24-40ff-aa7e-4877d6fe4558,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-d9bf8df4-4081-43ef-8bc4-134c8ffaa383,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-9f063e78-1577-4e8c-8d4b-e36b7be0f863,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-76b62bfc-2c70-4d86-9b64-0abe5d680807,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-c63e4464-71e4-4853-83bd-0dd06f1d2dd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1301247673-172.17.0.11-1595848299710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35836,DS-15f01f7d-5c1b-4803-9b30-5f7d87e90edd,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-3d1167c0-6809-4e7c-aa51-8ca592749410,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-9088920b-a822-41ad-ba67-fc0cf20e99d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-ce1f80a2-7a32-413d-abb4-907a248a5bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-1efae7a6-d529-4328-afbf-0373652dcd35,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-bca032a7-13b0-43de-aa39-881c427cd522,DISK], DatanodeInfoWithStorage[127.0.0.1:45069,DS-6c7e2514-8437-4ae7-8aed-fa107f108a61,DISK], DatanodeInfoWithStorage[127.0.0.1:34768,DS-3810f441-1a56-4bb3-9c6a-8590e22a332f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1301247673-172.17.0.11-1595848299710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35836,DS-15f01f7d-5c1b-4803-9b30-5f7d87e90edd,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-3d1167c0-6809-4e7c-aa51-8ca592749410,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-9088920b-a822-41ad-ba67-fc0cf20e99d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-ce1f80a2-7a32-413d-abb4-907a248a5bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-1efae7a6-d529-4328-afbf-0373652dcd35,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-bca032a7-13b0-43de-aa39-881c427cd522,DISK], DatanodeInfoWithStorage[127.0.0.1:45069,DS-6c7e2514-8437-4ae7-8aed-fa107f108a61,DISK], DatanodeInfoWithStorage[127.0.0.1:34768,DS-3810f441-1a56-4bb3-9c6a-8590e22a332f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-271200797-172.17.0.11-1595848380866:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42471,DS-c1d5b5e9-26c8-41f5-96a2-105a067060c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-1f982e8c-7ad7-4b50-86d9-3e868e60f49a,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-b60e7b07-e776-46ee-8fa2-097aff7d611d,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-1e36cb20-b46d-4dd2-ad1f-3bf59418f9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-2dda07de-9fcf-4843-9297-bfcb8a70fbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-daaade75-4900-4ca0-a62b-c11298e76588,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-417d3e5e-ab0d-4c3f-8787-a1f4a86ddd42,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-b309fcc4-1d23-4a0b-82ef-d0eecb168b54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-271200797-172.17.0.11-1595848380866:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42471,DS-c1d5b5e9-26c8-41f5-96a2-105a067060c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-1f982e8c-7ad7-4b50-86d9-3e868e60f49a,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-b60e7b07-e776-46ee-8fa2-097aff7d611d,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-1e36cb20-b46d-4dd2-ad1f-3bf59418f9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-2dda07de-9fcf-4843-9297-bfcb8a70fbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-daaade75-4900-4ca0-a62b-c11298e76588,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-417d3e5e-ab0d-4c3f-8787-a1f4a86ddd42,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-b309fcc4-1d23-4a0b-82ef-d0eecb168b54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1771881516-172.17.0.11-1595848977533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43629,DS-ea8af5b6-c99c-46fe-951a-f585a75f3908,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-93d906df-33ee-440e-a0f4-557424fcfa23,DISK], DatanodeInfoWithStorage[127.0.0.1:38860,DS-ff29bed2-1f46-4c8b-9c6a-eb11e68c3813,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-88570ccd-df0b-4bb4-858b-d94e602936cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-3df12530-761f-4d5c-bf96-1139ddb7024a,DISK], DatanodeInfoWithStorage[127.0.0.1:46100,DS-50a68a86-9bdb-4eb9-a964-7df3bba03452,DISK], DatanodeInfoWithStorage[127.0.0.1:43469,DS-bf5e8924-67f6-42f0-b9be-dd52141c6ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-3e31a39d-4617-4f80-9f0b-3d3d1bf99222,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1771881516-172.17.0.11-1595848977533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43629,DS-ea8af5b6-c99c-46fe-951a-f585a75f3908,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-93d906df-33ee-440e-a0f4-557424fcfa23,DISK], DatanodeInfoWithStorage[127.0.0.1:38860,DS-ff29bed2-1f46-4c8b-9c6a-eb11e68c3813,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-88570ccd-df0b-4bb4-858b-d94e602936cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-3df12530-761f-4d5c-bf96-1139ddb7024a,DISK], DatanodeInfoWithStorage[127.0.0.1:46100,DS-50a68a86-9bdb-4eb9-a964-7df3bba03452,DISK], DatanodeInfoWithStorage[127.0.0.1:43469,DS-bf5e8924-67f6-42f0-b9be-dd52141c6ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-3e31a39d-4617-4f80-9f0b-3d3d1bf99222,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1400327047-172.17.0.11-1595849997100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46073,DS-d43ca248-1259-4d61-a136-222d0629820c,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-7e2cb0f4-8a61-4a8b-afc1-7015dad23bab,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-5a108df7-2c45-47ad-a839-25a3a33ff95a,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-f4d0e200-017a-4229-b25a-97597264fec3,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-04d4753e-05b6-4f3e-8842-0a86dc1f6c70,DISK], DatanodeInfoWithStorage[127.0.0.1:34867,DS-0217f5a7-6ef1-4372-8262-17fde9de37db,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-72e2041c-a493-4a86-a41e-ac021be6251d,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-905a5cec-cc00-493e-8024-e18fe47c0c08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1400327047-172.17.0.11-1595849997100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46073,DS-d43ca248-1259-4d61-a136-222d0629820c,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-7e2cb0f4-8a61-4a8b-afc1-7015dad23bab,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-5a108df7-2c45-47ad-a839-25a3a33ff95a,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-f4d0e200-017a-4229-b25a-97597264fec3,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-04d4753e-05b6-4f3e-8842-0a86dc1f6c70,DISK], DatanodeInfoWithStorage[127.0.0.1:34867,DS-0217f5a7-6ef1-4372-8262-17fde9de37db,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-72e2041c-a493-4a86-a41e-ac021be6251d,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-905a5cec-cc00-493e-8024-e18fe47c0c08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1169157696-172.17.0.11-1595850154001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45583,DS-06894f24-4e37-4f5a-9caf-886be4fca0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-1a933e7f-9f6c-4750-9d55-ba6cbb633158,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-456dc86c-d0f3-43cc-99da-2302acc4023e,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-016c6db4-82a1-49cf-abec-e72bd5468bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-4f2b7e7f-8c4d-4a10-85da-a12aaf5d39dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-052fa6c5-38d1-424f-9689-18148f63ec2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-107976bf-9603-4a1a-bdac-c7b5f7052d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46120,DS-10fe253e-f75f-468b-bcb2-e4431646144e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1169157696-172.17.0.11-1595850154001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45583,DS-06894f24-4e37-4f5a-9caf-886be4fca0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-1a933e7f-9f6c-4750-9d55-ba6cbb633158,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-456dc86c-d0f3-43cc-99da-2302acc4023e,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-016c6db4-82a1-49cf-abec-e72bd5468bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-4f2b7e7f-8c4d-4a10-85da-a12aaf5d39dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-052fa6c5-38d1-424f-9689-18148f63ec2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-107976bf-9603-4a1a-bdac-c7b5f7052d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46120,DS-10fe253e-f75f-468b-bcb2-e4431646144e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1462276367-172.17.0.11-1595850375867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42020,DS-ae98b8eb-1e33-4780-ac4b-eb2ca3ca34e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38878,DS-18e1cce9-42dd-4660-ac2d-dbddcace46df,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-eb4a24ac-07bf-44c0-a87e-d425eb4661f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-e95d0d88-206c-4ca0-8f69-493c6effe944,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-8ca6741a-f74d-4709-a5e4-728abf31c0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:32838,DS-2e7d1a26-9ba6-479e-9f2d-9985736a398b,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-24db674b-575c-4f62-b0f6-ded0f275159f,DISK], DatanodeInfoWithStorage[127.0.0.1:38499,DS-9fbbe011-9e42-4609-9e91-4d48075b6451,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1462276367-172.17.0.11-1595850375867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42020,DS-ae98b8eb-1e33-4780-ac4b-eb2ca3ca34e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38878,DS-18e1cce9-42dd-4660-ac2d-dbddcace46df,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-eb4a24ac-07bf-44c0-a87e-d425eb4661f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-e95d0d88-206c-4ca0-8f69-493c6effe944,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-8ca6741a-f74d-4709-a5e4-728abf31c0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:32838,DS-2e7d1a26-9ba6-479e-9f2d-9985736a398b,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-24db674b-575c-4f62-b0f6-ded0f275159f,DISK], DatanodeInfoWithStorage[127.0.0.1:38499,DS-9fbbe011-9e42-4609-9e91-4d48075b6451,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-374177588-172.17.0.11-1595850963145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34715,DS-263d81b5-555f-4381-a783-bc31811bed2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43520,DS-45fb19a0-03b8-4e7d-8ea0-18fa3d32b5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-85138ff7-1d46-4d13-89a7-30d5d1c41d67,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-a44eb479-192d-458f-99b4-8aaf8e513a87,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-28403fdb-617d-4d98-be5f-b1e74723db5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-4ac26d08-aac0-4286-8d5b-695331730f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-9fbd3f89-121c-40b9-aeaa-7f5bce00be6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-6dfecdd3-acf8-4fc2-821f-1b0083e3f3df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-374177588-172.17.0.11-1595850963145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34715,DS-263d81b5-555f-4381-a783-bc31811bed2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43520,DS-45fb19a0-03b8-4e7d-8ea0-18fa3d32b5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-85138ff7-1d46-4d13-89a7-30d5d1c41d67,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-a44eb479-192d-458f-99b4-8aaf8e513a87,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-28403fdb-617d-4d98-be5f-b1e74723db5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-4ac26d08-aac0-4286-8d5b-695331730f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-9fbd3f89-121c-40b9-aeaa-7f5bce00be6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-6dfecdd3-acf8-4fc2-821f-1b0083e3f3df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-778601544-172.17.0.11-1595851039062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34111,DS-cb8b663d-a842-4c1a-93be-5bd51e31505c,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-423a8892-8c6c-4736-b519-63b254a6ce3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-0612c1a7-165e-43b7-82b1-fd7ba57acea4,DISK], DatanodeInfoWithStorage[127.0.0.1:39246,DS-7d843428-d200-410f-9456-e5457281459a,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-15761972-0bef-40fd-b896-12b5a69ddae0,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-d7f41037-1dba-483d-b221-a28ceffacb24,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-98049716-9b01-446f-ac3b-fc174a5a5900,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-b60e726b-2ef8-4da8-8ac9-89d102ac6852,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-778601544-172.17.0.11-1595851039062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34111,DS-cb8b663d-a842-4c1a-93be-5bd51e31505c,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-423a8892-8c6c-4736-b519-63b254a6ce3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-0612c1a7-165e-43b7-82b1-fd7ba57acea4,DISK], DatanodeInfoWithStorage[127.0.0.1:39246,DS-7d843428-d200-410f-9456-e5457281459a,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-15761972-0bef-40fd-b896-12b5a69ddae0,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-d7f41037-1dba-483d-b221-a28ceffacb24,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-98049716-9b01-446f-ac3b-fc174a5a5900,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-b60e726b-2ef8-4da8-8ac9-89d102ac6852,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1535414674-172.17.0.11-1595851184838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35077,DS-2d6d3bca-63aa-4490-8694-6606a645d3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-f922e04f-ae7a-45ec-a56a-28003bde8fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-4432ff96-6efd-42de-a998-e519711dc595,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-100fa832-d157-4dab-821d-0d146c56c531,DISK], DatanodeInfoWithStorage[127.0.0.1:42159,DS-a2793d25-5741-4b7c-b87a-d13ba775243d,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-b2fbbc21-2a2b-450f-b75a-52101ddceead,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-f0fc485f-29f2-44f8-9be7-86c71f01bd1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-ae4eaf5f-0ed6-470b-a772-a2f335e24416,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1535414674-172.17.0.11-1595851184838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35077,DS-2d6d3bca-63aa-4490-8694-6606a645d3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-f922e04f-ae7a-45ec-a56a-28003bde8fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-4432ff96-6efd-42de-a998-e519711dc595,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-100fa832-d157-4dab-821d-0d146c56c531,DISK], DatanodeInfoWithStorage[127.0.0.1:42159,DS-a2793d25-5741-4b7c-b87a-d13ba775243d,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-b2fbbc21-2a2b-450f-b75a-52101ddceead,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-f0fc485f-29f2-44f8-9be7-86c71f01bd1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-ae4eaf5f-0ed6-470b-a772-a2f335e24416,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1607902472-172.17.0.11-1595851614949:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37377,DS-f19edfe2-4fad-464c-9d7d-d03371e920f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37021,DS-132881e0-25bb-42f6-afe6-601f69eb6fea,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-a889dd20-cd7e-46f5-85d2-b7d502875da0,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-bea44400-b179-455e-96d8-816be7998ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-1c666617-40d4-4844-9ea5-42969ddfd5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-28c924cd-608e-4329-988b-bb8e7bf0e12e,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-21450e7f-7cef-4ac3-a7d8-dfc4ff36b75f,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-5a0b86a6-99c2-43b1-8794-8a91377024f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1607902472-172.17.0.11-1595851614949:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37377,DS-f19edfe2-4fad-464c-9d7d-d03371e920f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37021,DS-132881e0-25bb-42f6-afe6-601f69eb6fea,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-a889dd20-cd7e-46f5-85d2-b7d502875da0,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-bea44400-b179-455e-96d8-816be7998ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-1c666617-40d4-4844-9ea5-42969ddfd5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-28c924cd-608e-4329-988b-bb8e7bf0e12e,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-21450e7f-7cef-4ac3-a7d8-dfc4ff36b75f,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-5a0b86a6-99c2-43b1-8794-8a91377024f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-379997650-172.17.0.11-1595851803954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39244,DS-b25b5fa0-963c-4af7-9d04-37e93324690e,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-5701ba0f-534f-4a85-918e-a38f93bd56ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45470,DS-7baee0ef-8389-4b90-8ae1-4eb2fd868e97,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-14da8cd8-5817-4aaa-a96d-758e812f4497,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-ea414a6f-ebd7-4654-8eaa-074af3ee065b,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-b4527d54-90a1-4f30-a6bb-4a8093104b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43481,DS-3d57cdbe-45eb-42f8-9854-db6829c39b41,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-120e1162-7809-4fd6-bb6a-3d55198d5301,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-379997650-172.17.0.11-1595851803954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39244,DS-b25b5fa0-963c-4af7-9d04-37e93324690e,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-5701ba0f-534f-4a85-918e-a38f93bd56ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45470,DS-7baee0ef-8389-4b90-8ae1-4eb2fd868e97,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-14da8cd8-5817-4aaa-a96d-758e812f4497,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-ea414a6f-ebd7-4654-8eaa-074af3ee065b,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-b4527d54-90a1-4f30-a6bb-4a8093104b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43481,DS-3d57cdbe-45eb-42f8-9854-db6829c39b41,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-120e1162-7809-4fd6-bb6a-3d55198d5301,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1715241949-172.17.0.11-1595852858199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37919,DS-e3d9c42c-26f7-4632-842d-b19dcb8b8431,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-ebf9d0e4-8a98-4454-9319-fa0d3db3030e,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-979e3a6b-4184-45fa-8c86-9f689038481d,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-3c0fb96f-4768-4653-bbe2-6715191958ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-f0b60462-55f1-47d3-8206-de0c7f1e9a57,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-0b53edf8-9e6e-4c7b-8670-522b2d692b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38009,DS-799af5d5-bb65-45c7-b292-fdde93da8a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-37fa4827-7072-4990-a65f-4cee7382975e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1715241949-172.17.0.11-1595852858199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37919,DS-e3d9c42c-26f7-4632-842d-b19dcb8b8431,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-ebf9d0e4-8a98-4454-9319-fa0d3db3030e,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-979e3a6b-4184-45fa-8c86-9f689038481d,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-3c0fb96f-4768-4653-bbe2-6715191958ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-f0b60462-55f1-47d3-8206-de0c7f1e9a57,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-0b53edf8-9e6e-4c7b-8670-522b2d692b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38009,DS-799af5d5-bb65-45c7-b292-fdde93da8a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-37fa4827-7072-4990-a65f-4cee7382975e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1341041163-172.17.0.11-1595853178428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41750,DS-141c7fe4-dec3-4a30-9b6b-62780f05eab7,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-30366422-8dd9-48e1-b9b3-1024354f2968,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-e6f8de72-701d-42bd-9eb3-dc9f1aa59d58,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-115efa2c-8428-4963-ad36-673c7f72cc56,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-d8f872cf-bb4d-40a1-9623-8ead98b046d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-fc285d72-ac6e-4f0c-be5f-34d4689cd707,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-9f759282-4991-4226-808f-eb025b7d700a,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-f5b4c9ec-cb46-419b-8635-66909c8f7a52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1341041163-172.17.0.11-1595853178428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41750,DS-141c7fe4-dec3-4a30-9b6b-62780f05eab7,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-30366422-8dd9-48e1-b9b3-1024354f2968,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-e6f8de72-701d-42bd-9eb3-dc9f1aa59d58,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-115efa2c-8428-4963-ad36-673c7f72cc56,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-d8f872cf-bb4d-40a1-9623-8ead98b046d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-fc285d72-ac6e-4f0c-be5f-34d4689cd707,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-9f759282-4991-4226-808f-eb025b7d700a,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-f5b4c9ec-cb46-419b-8635-66909c8f7a52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5655
