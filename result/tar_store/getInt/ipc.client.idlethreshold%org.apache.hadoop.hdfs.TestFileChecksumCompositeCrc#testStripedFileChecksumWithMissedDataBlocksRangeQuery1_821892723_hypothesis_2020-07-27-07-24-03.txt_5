reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-106878784-172.17.0.2-1595834687439:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38385,DS-b1d05cff-bd0c-4fdc-9e64-82d7a5151d82,DISK], DatanodeInfoWithStorage[127.0.0.1:46030,DS-1bb43b0c-6969-41d7-a8a3-a66aa5e29641,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-3b411d91-5763-4f8d-a412-5829d1fd37d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-34ea58f3-995c-4c45-bdae-6f2b9a28716c,DISK], DatanodeInfoWithStorage[127.0.0.1:34324,DS-53a87d0b-4c72-4a1c-bfaa-9bdb3858fa88,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-28fb78a9-0713-4acf-a2f9-56d7b3ed0b11,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-7197422c-7b70-4df8-b9b7-bec3358d629e,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-32e2fb96-84dc-4866-a985-4cf60b7c4b53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-106878784-172.17.0.2-1595834687439:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38385,DS-b1d05cff-bd0c-4fdc-9e64-82d7a5151d82,DISK], DatanodeInfoWithStorage[127.0.0.1:46030,DS-1bb43b0c-6969-41d7-a8a3-a66aa5e29641,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-3b411d91-5763-4f8d-a412-5829d1fd37d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-34ea58f3-995c-4c45-bdae-6f2b9a28716c,DISK], DatanodeInfoWithStorage[127.0.0.1:34324,DS-53a87d0b-4c72-4a1c-bfaa-9bdb3858fa88,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-28fb78a9-0713-4acf-a2f9-56d7b3ed0b11,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-7197422c-7b70-4df8-b9b7-bec3358d629e,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-32e2fb96-84dc-4866-a985-4cf60b7c4b53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1111444607-172.17.0.2-1595835117092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36506,DS-cddd86e6-2f4d-4853-8080-73e7e2a5ebf8,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-69284c7a-a518-4974-9554-ccfad939714d,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-4db9cbb5-745b-496b-8375-aa7cf95d9fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:43508,DS-b592fa7d-eb6f-4694-b1be-9482502c6547,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-10f3e0e0-bf43-4e9a-a8e1-48b9b9cad068,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-c240fd06-3c10-414c-8e68-f281777666f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36301,DS-bf351f14-0f19-4a1e-aba1-e9100a671d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37228,DS-9c6dac54-6004-448d-9374-c5dc7c9630b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1111444607-172.17.0.2-1595835117092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36506,DS-cddd86e6-2f4d-4853-8080-73e7e2a5ebf8,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-69284c7a-a518-4974-9554-ccfad939714d,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-4db9cbb5-745b-496b-8375-aa7cf95d9fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:43508,DS-b592fa7d-eb6f-4694-b1be-9482502c6547,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-10f3e0e0-bf43-4e9a-a8e1-48b9b9cad068,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-c240fd06-3c10-414c-8e68-f281777666f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36301,DS-bf351f14-0f19-4a1e-aba1-e9100a671d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37228,DS-9c6dac54-6004-448d-9374-c5dc7c9630b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1605976030-172.17.0.2-1595835314124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42587,DS-cab853db-bd3f-407c-9edf-0179caab69ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35162,DS-d3ceb3d6-a8fb-4991-990b-6feb42ba4e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-6079e33c-092c-4a5f-b8f1-613c353699a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-1c0c29d5-e478-44b9-806a-1908a8d65850,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-29bd86f9-3c21-4917-95fb-0662d2b185e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39035,DS-f6e3bce4-44f8-4145-9739-b479b8beea89,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-708fde29-60d5-4b5c-9348-f6c490552b90,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-cf7f9834-3d44-4121-aa42-036a6d8c912b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1605976030-172.17.0.2-1595835314124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42587,DS-cab853db-bd3f-407c-9edf-0179caab69ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35162,DS-d3ceb3d6-a8fb-4991-990b-6feb42ba4e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-6079e33c-092c-4a5f-b8f1-613c353699a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-1c0c29d5-e478-44b9-806a-1908a8d65850,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-29bd86f9-3c21-4917-95fb-0662d2b185e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39035,DS-f6e3bce4-44f8-4145-9739-b479b8beea89,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-708fde29-60d5-4b5c-9348-f6c490552b90,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-cf7f9834-3d44-4121-aa42-036a6d8c912b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1182455953-172.17.0.2-1595835344650:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46503,DS-583a3efa-19b5-404e-87ee-08903f720ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-8c290e80-30f1-4c09-80f8-427b4a5e5695,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-eba5dccb-79ee-4c44-ba3b-0e732daf976e,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-efbf49ab-64c4-4f74-bbe9-fb1decfe7ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-e0dc6358-353c-42e0-b693-4f6efe931fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:44780,DS-0dd68528-cb9d-422d-8203-d05de078b767,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-8c583110-3ba4-43a9-9d4b-6ae17e002fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-ff505952-72f6-491c-be09-2face318f97b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1182455953-172.17.0.2-1595835344650:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46503,DS-583a3efa-19b5-404e-87ee-08903f720ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-8c290e80-30f1-4c09-80f8-427b4a5e5695,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-eba5dccb-79ee-4c44-ba3b-0e732daf976e,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-efbf49ab-64c4-4f74-bbe9-fb1decfe7ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-e0dc6358-353c-42e0-b693-4f6efe931fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:44780,DS-0dd68528-cb9d-422d-8203-d05de078b767,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-8c583110-3ba4-43a9-9d4b-6ae17e002fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-ff505952-72f6-491c-be09-2face318f97b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-936971322-172.17.0.2-1595835653699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45094,DS-b6c4a20f-c7bd-4e5f-875c-bfc1dec69314,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-436f7b25-5730-472a-8d77-93903a5afac2,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-09806fdb-ef1e-4668-b10f-2b5ac0ed4184,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-9762b63d-561d-4356-b18b-6a20c215c542,DISK], DatanodeInfoWithStorage[127.0.0.1:46539,DS-494c5cc3-36a2-49b9-a404-bd13598120a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-d871ac95-6612-4b71-9da7-48ba90820bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-93e30a74-f314-4ab8-9cbb-57b55fa7ccd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-7c7e5f68-a542-411b-99c6-2657d9a584dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-936971322-172.17.0.2-1595835653699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45094,DS-b6c4a20f-c7bd-4e5f-875c-bfc1dec69314,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-436f7b25-5730-472a-8d77-93903a5afac2,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-09806fdb-ef1e-4668-b10f-2b5ac0ed4184,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-9762b63d-561d-4356-b18b-6a20c215c542,DISK], DatanodeInfoWithStorage[127.0.0.1:46539,DS-494c5cc3-36a2-49b9-a404-bd13598120a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-d871ac95-6612-4b71-9da7-48ba90820bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-93e30a74-f314-4ab8-9cbb-57b55fa7ccd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-7c7e5f68-a542-411b-99c6-2657d9a584dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-484308156-172.17.0.2-1595835978364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39517,DS-cb6f0db4-8046-47f2-b1c6-6e6fb80e2558,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-5ba049b9-d947-4be1-9a82-5c37f8fe1eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-f5d14e2d-67cd-406c-842b-6545d5639bee,DISK], DatanodeInfoWithStorage[127.0.0.1:33565,DS-732b3248-4cdb-42ea-909e-9c6812561f56,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-0cd2e79d-8fcd-47d1-801b-b5d7b56fcc13,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-ffe1f613-e172-4069-9ad3-cc5626803c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46199,DS-dde330d5-99f9-40aa-bbdd-612ceb29b853,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-9e31cf7e-2c93-4807-9b61-34e50574d0b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-484308156-172.17.0.2-1595835978364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39517,DS-cb6f0db4-8046-47f2-b1c6-6e6fb80e2558,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-5ba049b9-d947-4be1-9a82-5c37f8fe1eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-f5d14e2d-67cd-406c-842b-6545d5639bee,DISK], DatanodeInfoWithStorage[127.0.0.1:33565,DS-732b3248-4cdb-42ea-909e-9c6812561f56,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-0cd2e79d-8fcd-47d1-801b-b5d7b56fcc13,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-ffe1f613-e172-4069-9ad3-cc5626803c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46199,DS-dde330d5-99f9-40aa-bbdd-612ceb29b853,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-9e31cf7e-2c93-4807-9b61-34e50574d0b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548138898-172.17.0.2-1595836384307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33535,DS-47e4b80b-1625-4af8-8d7e-106472757564,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-1d27d808-9621-4eeb-9a6a-91da8c4d90e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-1c63f29f-e163-44c6-aff7-088a29e2ae0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38183,DS-74d8562b-83ef-4297-991f-d3f9d64e350d,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-7da53e61-35c7-4a53-9103-6a54766ec1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36540,DS-f5794dd8-3148-4af0-85a8-3a465cb2de3f,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-102cc3c3-4912-4e97-ac91-610ef9773352,DISK], DatanodeInfoWithStorage[127.0.0.1:37940,DS-e953d30b-6031-4966-ac6b-690bb7400c96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548138898-172.17.0.2-1595836384307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33535,DS-47e4b80b-1625-4af8-8d7e-106472757564,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-1d27d808-9621-4eeb-9a6a-91da8c4d90e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-1c63f29f-e163-44c6-aff7-088a29e2ae0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38183,DS-74d8562b-83ef-4297-991f-d3f9d64e350d,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-7da53e61-35c7-4a53-9103-6a54766ec1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36540,DS-f5794dd8-3148-4af0-85a8-3a465cb2de3f,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-102cc3c3-4912-4e97-ac91-610ef9773352,DISK], DatanodeInfoWithStorage[127.0.0.1:37940,DS-e953d30b-6031-4966-ac6b-690bb7400c96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1105544886-172.17.0.2-1595836416343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36677,DS-84d46fc4-6d46-43a1-ac46-12e6e9497a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43917,DS-d7e69412-4760-4ee8-ac2e-96cc05851343,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-ad03d6a1-ab09-4bab-942d-73131b84c7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36977,DS-b67f125e-5350-4541-8f50-c627404ce824,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-9e9c8794-e06a-446b-a917-476ff2b2afcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-a3032321-21b0-44b6-a7bd-62764552f943,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-40ed72e9-51ca-429d-aa55-2ec264b42fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-e06d822d-3513-4bd6-aa20-0020d8986c6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1105544886-172.17.0.2-1595836416343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36677,DS-84d46fc4-6d46-43a1-ac46-12e6e9497a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43917,DS-d7e69412-4760-4ee8-ac2e-96cc05851343,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-ad03d6a1-ab09-4bab-942d-73131b84c7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36977,DS-b67f125e-5350-4541-8f50-c627404ce824,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-9e9c8794-e06a-446b-a917-476ff2b2afcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-a3032321-21b0-44b6-a7bd-62764552f943,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-40ed72e9-51ca-429d-aa55-2ec264b42fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-e06d822d-3513-4bd6-aa20-0020d8986c6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-440338997-172.17.0.2-1595836477243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33651,DS-46175f1a-7b6b-44b3-b71a-0ce40447a613,DISK], DatanodeInfoWithStorage[127.0.0.1:46870,DS-f8bc0cf8-fd81-472c-916b-4a671a60bf2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-557f3065-693b-4cbc-be78-19720f983aae,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-9cdec857-73a5-48aa-9f2d-1241eb64e156,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-d88edebb-0eae-4eca-9f2b-7b87890ac7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-9934a4ac-365f-494c-a087-8b0f7767c968,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-16314059-3c2b-4ee6-946b-185f0a01bf2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-b5bfdf00-b00d-4f96-9d53-38554d52674e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-440338997-172.17.0.2-1595836477243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33651,DS-46175f1a-7b6b-44b3-b71a-0ce40447a613,DISK], DatanodeInfoWithStorage[127.0.0.1:46870,DS-f8bc0cf8-fd81-472c-916b-4a671a60bf2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-557f3065-693b-4cbc-be78-19720f983aae,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-9cdec857-73a5-48aa-9f2d-1241eb64e156,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-d88edebb-0eae-4eca-9f2b-7b87890ac7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-9934a4ac-365f-494c-a087-8b0f7767c968,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-16314059-3c2b-4ee6-946b-185f0a01bf2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-b5bfdf00-b00d-4f96-9d53-38554d52674e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1295842404-172.17.0.2-1595836619036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45564,DS-69a8c176-0f1b-48f1-967a-4792745ec26a,DISK], DatanodeInfoWithStorage[127.0.0.1:40308,DS-301ca663-b4eb-416b-a148-3eb25b55d1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-66c04395-dd56-4d2f-bb23-259afb23d2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-41b0f05e-2eda-448b-9711-20748f84bf89,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-5c81d19b-7db8-416e-ae91-e72a8804436c,DISK], DatanodeInfoWithStorage[127.0.0.1:35368,DS-39fe3afd-49d1-4a0b-906a-eb62cb780db4,DISK], DatanodeInfoWithStorage[127.0.0.1:37259,DS-82a43d28-cc7b-4d76-bf9d-e8a812a5cbdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-bd202550-d0a2-4b97-93db-fd633fc313e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1295842404-172.17.0.2-1595836619036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45564,DS-69a8c176-0f1b-48f1-967a-4792745ec26a,DISK], DatanodeInfoWithStorage[127.0.0.1:40308,DS-301ca663-b4eb-416b-a148-3eb25b55d1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-66c04395-dd56-4d2f-bb23-259afb23d2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-41b0f05e-2eda-448b-9711-20748f84bf89,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-5c81d19b-7db8-416e-ae91-e72a8804436c,DISK], DatanodeInfoWithStorage[127.0.0.1:35368,DS-39fe3afd-49d1-4a0b-906a-eb62cb780db4,DISK], DatanodeInfoWithStorage[127.0.0.1:37259,DS-82a43d28-cc7b-4d76-bf9d-e8a812a5cbdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-bd202550-d0a2-4b97-93db-fd633fc313e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-148015457-172.17.0.2-1595837113436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36199,DS-411e6795-0932-47f6-8b29-421f606ff468,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-bd14e8e5-5865-4c20-b53c-04b34837ec70,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-7ad100af-b888-46fd-a1ab-569340beaf21,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-2248c60b-6d46-45b5-bb04-c6680534e2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-4165b584-7968-407d-b429-464187bd077e,DISK], DatanodeInfoWithStorage[127.0.0.1:37954,DS-88583888-5edc-4136-9ef9-d710cbafadc9,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-e5d36545-4efe-448a-a748-1cddc9f0f28e,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-0fb53833-82b2-4d81-895b-9f9a2f061d43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-148015457-172.17.0.2-1595837113436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36199,DS-411e6795-0932-47f6-8b29-421f606ff468,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-bd14e8e5-5865-4c20-b53c-04b34837ec70,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-7ad100af-b888-46fd-a1ab-569340beaf21,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-2248c60b-6d46-45b5-bb04-c6680534e2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-4165b584-7968-407d-b429-464187bd077e,DISK], DatanodeInfoWithStorage[127.0.0.1:37954,DS-88583888-5edc-4136-9ef9-d710cbafadc9,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-e5d36545-4efe-448a-a748-1cddc9f0f28e,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-0fb53833-82b2-4d81-895b-9f9a2f061d43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-541877678-172.17.0.2-1595837748067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39289,DS-6f81e24d-01cb-4c5e-af2f-b50a29ce20d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-e25d65f9-cbd9-4746-a3cb-dc92075cd86d,DISK], DatanodeInfoWithStorage[127.0.0.1:33875,DS-704fa312-ea5a-498d-8e49-5019c50d7602,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-988a2e9a-2a74-49f8-815d-b2e2ec4498d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-cdd15a07-1fc9-49af-a867-2fc41adc917c,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-93437539-6e38-4e70-b883-a362b3bbb290,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-6585d712-9d49-433c-977a-06a3873047ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-02d46d79-9b26-4838-80df-9a12afcfa516,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-541877678-172.17.0.2-1595837748067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39289,DS-6f81e24d-01cb-4c5e-af2f-b50a29ce20d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-e25d65f9-cbd9-4746-a3cb-dc92075cd86d,DISK], DatanodeInfoWithStorage[127.0.0.1:33875,DS-704fa312-ea5a-498d-8e49-5019c50d7602,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-988a2e9a-2a74-49f8-815d-b2e2ec4498d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-cdd15a07-1fc9-49af-a867-2fc41adc917c,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-93437539-6e38-4e70-b883-a362b3bbb290,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-6585d712-9d49-433c-977a-06a3873047ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-02d46d79-9b26-4838-80df-9a12afcfa516,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1415500899-172.17.0.2-1595837805361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43667,DS-8384f1a7-42a4-4e88-9987-69b1b7286b09,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-fb5e4108-abb7-47a4-bc7a-399b1d1c9586,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-dcaf6412-a94e-4e95-9875-02e1ad639a31,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-7073ef7e-9212-4ad6-a48a-3f57a17ee447,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-ac890551-4732-45ee-b2eb-b981fa94d6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42853,DS-1d7dc36e-201d-4f06-b4b6-efa52ec25b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-ef0bdb0e-2f62-4cf4-b068-b5796db1c873,DISK], DatanodeInfoWithStorage[127.0.0.1:36381,DS-8f25d241-5199-4aa4-b174-d87df78fc56e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1415500899-172.17.0.2-1595837805361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43667,DS-8384f1a7-42a4-4e88-9987-69b1b7286b09,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-fb5e4108-abb7-47a4-bc7a-399b1d1c9586,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-dcaf6412-a94e-4e95-9875-02e1ad639a31,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-7073ef7e-9212-4ad6-a48a-3f57a17ee447,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-ac890551-4732-45ee-b2eb-b981fa94d6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42853,DS-1d7dc36e-201d-4f06-b4b6-efa52ec25b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-ef0bdb0e-2f62-4cf4-b068-b5796db1c873,DISK], DatanodeInfoWithStorage[127.0.0.1:36381,DS-8f25d241-5199-4aa4-b174-d87df78fc56e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-845486424-172.17.0.2-1595838096780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43042,DS-8e284905-33b6-4de8-9e06-35b2a5cf9255,DISK], DatanodeInfoWithStorage[127.0.0.1:45227,DS-5aab8066-0773-4c2a-a4e2-53748f796da1,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-8ae17a13-3f40-4d16-beb1-5afe5a54d210,DISK], DatanodeInfoWithStorage[127.0.0.1:46534,DS-da2a372a-1867-4a30-bbdf-2ccf58145456,DISK], DatanodeInfoWithStorage[127.0.0.1:34273,DS-fb16e1e6-2baf-489e-9aee-d0100166df8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-8a29a06c-8138-4af3-b578-ca0773e2b44d,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-f4b601eb-61ce-4741-9f0d-5aaa1fc7a487,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-71f7b864-6e21-4e0e-a07c-abe672e0b560,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-845486424-172.17.0.2-1595838096780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43042,DS-8e284905-33b6-4de8-9e06-35b2a5cf9255,DISK], DatanodeInfoWithStorage[127.0.0.1:45227,DS-5aab8066-0773-4c2a-a4e2-53748f796da1,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-8ae17a13-3f40-4d16-beb1-5afe5a54d210,DISK], DatanodeInfoWithStorage[127.0.0.1:46534,DS-da2a372a-1867-4a30-bbdf-2ccf58145456,DISK], DatanodeInfoWithStorage[127.0.0.1:34273,DS-fb16e1e6-2baf-489e-9aee-d0100166df8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-8a29a06c-8138-4af3-b578-ca0773e2b44d,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-f4b601eb-61ce-4741-9f0d-5aaa1fc7a487,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-71f7b864-6e21-4e0e-a07c-abe672e0b560,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-658526119-172.17.0.2-1595838173967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34512,DS-67bdfd1b-38a5-45eb-b9e0-32b0312910e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-8ff436dc-0584-4004-8e97-46440297b74b,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-c8d6218b-e62f-4e7b-9557-9f42e6ee51ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-606bece6-a16c-4fd6-9a65-a9cbd3b5259f,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-2c216eba-a8d7-411b-8a82-8ee09a316394,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-d03b1896-965a-4393-b732-e8c31b4d60cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-ab260a52-73be-4b69-87ad-90d45c75d7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-8819284b-f1c9-4961-af91-cc7073003080,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-658526119-172.17.0.2-1595838173967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34512,DS-67bdfd1b-38a5-45eb-b9e0-32b0312910e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-8ff436dc-0584-4004-8e97-46440297b74b,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-c8d6218b-e62f-4e7b-9557-9f42e6ee51ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-606bece6-a16c-4fd6-9a65-a9cbd3b5259f,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-2c216eba-a8d7-411b-8a82-8ee09a316394,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-d03b1896-965a-4393-b732-e8c31b4d60cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-ab260a52-73be-4b69-87ad-90d45c75d7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-8819284b-f1c9-4961-af91-cc7073003080,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1659581014-172.17.0.2-1595838705159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39054,DS-3ef5bc64-1429-41ff-9d0e-db6d3684565a,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-ef241a1f-e509-4f1d-a470-58acf92489bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-9f71c7a6-78f2-410b-8979-66271a72fccf,DISK], DatanodeInfoWithStorage[127.0.0.1:35893,DS-87f074d0-05c1-4f66-8006-490b83910ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-c3d49e00-097e-401e-99c8-90ef2e5d9ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-5e89b9f1-1c81-4f17-a869-d97df0889e99,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-2e1a1001-c3c3-428a-a22f-8459103aaf1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-e97754bb-725c-43d8-9a41-53c9b350f938,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1659581014-172.17.0.2-1595838705159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39054,DS-3ef5bc64-1429-41ff-9d0e-db6d3684565a,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-ef241a1f-e509-4f1d-a470-58acf92489bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-9f71c7a6-78f2-410b-8979-66271a72fccf,DISK], DatanodeInfoWithStorage[127.0.0.1:35893,DS-87f074d0-05c1-4f66-8006-490b83910ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-c3d49e00-097e-401e-99c8-90ef2e5d9ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-5e89b9f1-1c81-4f17-a869-d97df0889e99,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-2e1a1001-c3c3-428a-a22f-8459103aaf1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-e97754bb-725c-43d8-9a41-53c9b350f938,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1693319136-172.17.0.2-1595838738318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46121,DS-1256bd12-7803-4c2b-a1d4-c7d6fe7831ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-82d741b1-cf92-4402-ac4f-ae09bbc27435,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-0e7d2911-8667-49c3-be25-5073128fe984,DISK], DatanodeInfoWithStorage[127.0.0.1:37585,DS-cea5a15d-eb1f-4041-bcb6-1ce64a247359,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-cf814c4b-c94e-4958-b097-e3966ccd4051,DISK], DatanodeInfoWithStorage[127.0.0.1:40647,DS-472e0a6c-182b-4cea-b728-e188aa07e446,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-ec9dc351-b72d-427a-a9ea-9a7abddf4037,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-5c61f17e-2753-45d0-87c6-18d954520a90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1693319136-172.17.0.2-1595838738318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46121,DS-1256bd12-7803-4c2b-a1d4-c7d6fe7831ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-82d741b1-cf92-4402-ac4f-ae09bbc27435,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-0e7d2911-8667-49c3-be25-5073128fe984,DISK], DatanodeInfoWithStorage[127.0.0.1:37585,DS-cea5a15d-eb1f-4041-bcb6-1ce64a247359,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-cf814c4b-c94e-4958-b097-e3966ccd4051,DISK], DatanodeInfoWithStorage[127.0.0.1:40647,DS-472e0a6c-182b-4cea-b728-e188aa07e446,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-ec9dc351-b72d-427a-a9ea-9a7abddf4037,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-5c61f17e-2753-45d0-87c6-18d954520a90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-721482434-172.17.0.2-1595839128311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41029,DS-085613c7-8524-48a4-9b3d-9646fa956626,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-7e80e888-2ca9-49b0-82a9-6a7a57511f00,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-60c74564-f759-4817-8b01-95b35491fce3,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-1cb46acc-b9bf-4168-aad1-04d632c7fa4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43081,DS-62114d5b-3de2-430a-b189-50505fff7e14,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-2958614d-18da-4fdd-9e1f-29aff23a67a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-3ce80417-2fdd-4773-b3b5-6a76bdfceab1,DISK], DatanodeInfoWithStorage[127.0.0.1:35630,DS-b891ef37-16d5-4019-b018-a41746928d49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-721482434-172.17.0.2-1595839128311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41029,DS-085613c7-8524-48a4-9b3d-9646fa956626,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-7e80e888-2ca9-49b0-82a9-6a7a57511f00,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-60c74564-f759-4817-8b01-95b35491fce3,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-1cb46acc-b9bf-4168-aad1-04d632c7fa4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43081,DS-62114d5b-3de2-430a-b189-50505fff7e14,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-2958614d-18da-4fdd-9e1f-29aff23a67a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-3ce80417-2fdd-4773-b3b5-6a76bdfceab1,DISK], DatanodeInfoWithStorage[127.0.0.1:35630,DS-b891ef37-16d5-4019-b018-a41746928d49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-765963640-172.17.0.2-1595839376058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41719,DS-d4b977eb-929c-4f8b-8431-e842aebdec31,DISK], DatanodeInfoWithStorage[127.0.0.1:42994,DS-338fb4d0-0f46-4110-9077-b845959fe5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-b6a0227b-7b37-46c4-9ee2-639cf092cb06,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-99b5ce01-614f-4f73-8f44-a469b72c5cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42327,DS-7f5f0959-4f51-40bb-ae8a-70f4f7d126c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-20807e70-36f6-44be-b6b5-25499487d742,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-b310ac9a-f4a4-4710-9f86-0ed8401e922e,DISK], DatanodeInfoWithStorage[127.0.0.1:39710,DS-162f64e5-ff91-4fcc-b52b-f2f38b0a9e82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-765963640-172.17.0.2-1595839376058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41719,DS-d4b977eb-929c-4f8b-8431-e842aebdec31,DISK], DatanodeInfoWithStorage[127.0.0.1:42994,DS-338fb4d0-0f46-4110-9077-b845959fe5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-b6a0227b-7b37-46c4-9ee2-639cf092cb06,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-99b5ce01-614f-4f73-8f44-a469b72c5cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42327,DS-7f5f0959-4f51-40bb-ae8a-70f4f7d126c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-20807e70-36f6-44be-b6b5-25499487d742,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-b310ac9a-f4a4-4710-9f86-0ed8401e922e,DISK], DatanodeInfoWithStorage[127.0.0.1:39710,DS-162f64e5-ff91-4fcc-b52b-f2f38b0a9e82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1757545567-172.17.0.2-1595839505852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39544,DS-5c0efc3f-e43b-4a66-98c7-9b7c46b68449,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-14ec0554-2aa3-4275-999a-aa2ecd7c928a,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-5276c07b-191e-4554-9d9b-34f6a7cebb54,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-ed49222b-993f-4562-8782-a12c48a8be15,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-fc1ff521-bd01-44a2-9308-96a180ba2905,DISK], DatanodeInfoWithStorage[127.0.0.1:38901,DS-da2e8c38-4fdc-460b-9e76-8e80d2e81f94,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-213095f4-5b3a-4433-a454-98b4ea9625c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37377,DS-d1d52134-aba6-4015-b8af-d333c2302435,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1757545567-172.17.0.2-1595839505852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39544,DS-5c0efc3f-e43b-4a66-98c7-9b7c46b68449,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-14ec0554-2aa3-4275-999a-aa2ecd7c928a,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-5276c07b-191e-4554-9d9b-34f6a7cebb54,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-ed49222b-993f-4562-8782-a12c48a8be15,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-fc1ff521-bd01-44a2-9308-96a180ba2905,DISK], DatanodeInfoWithStorage[127.0.0.1:38901,DS-da2e8c38-4fdc-460b-9e76-8e80d2e81f94,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-213095f4-5b3a-4433-a454-98b4ea9625c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37377,DS-d1d52134-aba6-4015-b8af-d333c2302435,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1537912329-172.17.0.2-1595839546751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36223,DS-555a159d-15d2-426a-8154-0873be47dccc,DISK], DatanodeInfoWithStorage[127.0.0.1:45640,DS-055d03e3-88d6-4839-ad09-939e97e5592b,DISK], DatanodeInfoWithStorage[127.0.0.1:44946,DS-7c64e564-5f34-4bf3-842c-2b4932fe034c,DISK], DatanodeInfoWithStorage[127.0.0.1:33359,DS-ac509218-c193-4fd3-b8da-084480226c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35383,DS-c81754ba-f124-4b0f-8e75-89664074d6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-ef083157-4f2f-46cb-b35d-f5bd4a7cf080,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-896be52b-58b5-47fa-b593-3a2cba6a8b05,DISK], DatanodeInfoWithStorage[127.0.0.1:44227,DS-1a6018a0-c103-481f-a3e8-44250f465dc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1537912329-172.17.0.2-1595839546751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36223,DS-555a159d-15d2-426a-8154-0873be47dccc,DISK], DatanodeInfoWithStorage[127.0.0.1:45640,DS-055d03e3-88d6-4839-ad09-939e97e5592b,DISK], DatanodeInfoWithStorage[127.0.0.1:44946,DS-7c64e564-5f34-4bf3-842c-2b4932fe034c,DISK], DatanodeInfoWithStorage[127.0.0.1:33359,DS-ac509218-c193-4fd3-b8da-084480226c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35383,DS-c81754ba-f124-4b0f-8e75-89664074d6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-ef083157-4f2f-46cb-b35d-f5bd4a7cf080,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-896be52b-58b5-47fa-b593-3a2cba6a8b05,DISK], DatanodeInfoWithStorage[127.0.0.1:44227,DS-1a6018a0-c103-481f-a3e8-44250f465dc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5139
