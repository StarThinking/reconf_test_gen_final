reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-914011031-172.17.0.9-1595936399392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42768,DS-d95563f3-3f3f-41f5-81c5-1b106ff3d40b,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-77299a78-1798-4cef-9634-533df750b184,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-4b8dd301-ec84-4575-ae6a-59a5d2e2e4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40087,DS-fa1ac22d-d903-4c0b-893c-c5b1d4fb235d,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-e075a3d9-cf06-4ea7-a0a5-c98f9fbeb46a,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-2fe5deb2-fb39-4a3c-8381-d34dc3c5a98e,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-3fe033fb-2878-41be-8124-c2d16d93c05a,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-439a8689-72cf-444f-bbd8-2b3ee8fb78c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-914011031-172.17.0.9-1595936399392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42768,DS-d95563f3-3f3f-41f5-81c5-1b106ff3d40b,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-77299a78-1798-4cef-9634-533df750b184,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-4b8dd301-ec84-4575-ae6a-59a5d2e2e4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40087,DS-fa1ac22d-d903-4c0b-893c-c5b1d4fb235d,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-e075a3d9-cf06-4ea7-a0a5-c98f9fbeb46a,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-2fe5deb2-fb39-4a3c-8381-d34dc3c5a98e,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-3fe033fb-2878-41be-8124-c2d16d93c05a,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-439a8689-72cf-444f-bbd8-2b3ee8fb78c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1872168523-172.17.0.9-1595936552783:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41176,DS-7b0dee9a-db52-4e05-9621-04422e0fe61f,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-4dce3018-a239-4f51-a6a7-5382e6eac708,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-036fd5ef-dcb4-45bb-a7ee-371f3e224877,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-226a42a4-5d8f-4963-aa47-172104954490,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-57052ab5-e0f6-4aac-b9f2-c5375ed73c09,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-c2448537-677c-411a-90d0-667efcbed344,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-94418d0c-1e04-4d2d-8393-3c4bf6e6122d,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-eed4d640-923f-404a-8cdd-e47966cc348f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1872168523-172.17.0.9-1595936552783:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41176,DS-7b0dee9a-db52-4e05-9621-04422e0fe61f,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-4dce3018-a239-4f51-a6a7-5382e6eac708,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-036fd5ef-dcb4-45bb-a7ee-371f3e224877,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-226a42a4-5d8f-4963-aa47-172104954490,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-57052ab5-e0f6-4aac-b9f2-c5375ed73c09,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-c2448537-677c-411a-90d0-667efcbed344,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-94418d0c-1e04-4d2d-8393-3c4bf6e6122d,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-eed4d640-923f-404a-8cdd-e47966cc348f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-949932341-172.17.0.9-1595936803602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41720,DS-ba27e222-3633-4323-a422-3c1fb963024d,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-0b1e1d10-5f40-4754-b83f-612a2aa4c5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36187,DS-80cb5d64-2363-49d2-8d24-986e5e83d6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34521,DS-2c9f22f7-24f8-42c1-a894-2485e3299be3,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-49f5a59e-2684-4904-9c81-3b78864200da,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-2195f2a0-c5a3-42ad-9298-cd696502cd73,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-ea37c237-95df-44fc-8223-fe64f635eeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-dd7d5854-47f2-41f2-9dd3-00ae1425379b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-949932341-172.17.0.9-1595936803602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41720,DS-ba27e222-3633-4323-a422-3c1fb963024d,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-0b1e1d10-5f40-4754-b83f-612a2aa4c5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36187,DS-80cb5d64-2363-49d2-8d24-986e5e83d6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34521,DS-2c9f22f7-24f8-42c1-a894-2485e3299be3,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-49f5a59e-2684-4904-9c81-3b78864200da,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-2195f2a0-c5a3-42ad-9298-cd696502cd73,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-ea37c237-95df-44fc-8223-fe64f635eeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-dd7d5854-47f2-41f2-9dd3-00ae1425379b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1242460541-172.17.0.9-1595937127823:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35672,DS-0be147e2-9423-4390-bc2e-523829d807a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-ea8f5bf8-0dce-486f-975f-feb796ac1553,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-016e1694-5ab4-470b-b9da-0e3acbdbc5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-d83714a6-90d6-4f8c-8faf-1c92b69410b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-86fccbdd-c0aa-42eb-96e9-d6eee66dbf5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-ba5bb73d-d6e1-46fa-a4c9-6f23efcb9bef,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-1d2b8f14-a690-4780-903b-0b76f9c61c87,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-a4783b4e-873f-4e31-b189-d758c04dac7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1242460541-172.17.0.9-1595937127823:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35672,DS-0be147e2-9423-4390-bc2e-523829d807a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-ea8f5bf8-0dce-486f-975f-feb796ac1553,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-016e1694-5ab4-470b-b9da-0e3acbdbc5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-d83714a6-90d6-4f8c-8faf-1c92b69410b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-86fccbdd-c0aa-42eb-96e9-d6eee66dbf5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-ba5bb73d-d6e1-46fa-a4c9-6f23efcb9bef,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-1d2b8f14-a690-4780-903b-0b76f9c61c87,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-a4783b4e-873f-4e31-b189-d758c04dac7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-285343827-172.17.0.9-1595937332549:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40357,DS-a2878182-4de5-4f05-b496-961eddaceb1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-4527755f-9669-48b0-9c8b-a9a44757e8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-8f77c43c-0aa5-484d-81c6-4d0b3c39990c,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-decf95d2-1f49-43a2-91da-5cabe4b7a3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35036,DS-ef0aa6fd-e873-4bcd-9c7c-11c0bf19d104,DISK], DatanodeInfoWithStorage[127.0.0.1:44997,DS-30e439fd-10e1-4629-8aa1-5c6e6adc92a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-66bd6e81-2b45-4f2a-907a-66d006bd6495,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-5a487980-081c-464c-86eb-faf5333cfc7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-285343827-172.17.0.9-1595937332549:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40357,DS-a2878182-4de5-4f05-b496-961eddaceb1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-4527755f-9669-48b0-9c8b-a9a44757e8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-8f77c43c-0aa5-484d-81c6-4d0b3c39990c,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-decf95d2-1f49-43a2-91da-5cabe4b7a3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35036,DS-ef0aa6fd-e873-4bcd-9c7c-11c0bf19d104,DISK], DatanodeInfoWithStorage[127.0.0.1:44997,DS-30e439fd-10e1-4629-8aa1-5c6e6adc92a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-66bd6e81-2b45-4f2a-907a-66d006bd6495,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-5a487980-081c-464c-86eb-faf5333cfc7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-169276308-172.17.0.9-1595937409691:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42347,DS-671c2870-b96f-484c-bfe1-f4abfb77b7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-37911df3-7d18-40ca-b553-618793d6e72c,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-704520df-ff81-4748-b30c-03f59939383d,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-080db591-7a2a-4536-8e49-0609dc12d58e,DISK], DatanodeInfoWithStorage[127.0.0.1:39169,DS-454c67b8-469a-4f9b-8cc8-27e7dcbb4fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-56327f81-db53-49f6-b45d-7d0402328b16,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-4be03a14-444c-4567-b67f-a3b74e020e18,DISK], DatanodeInfoWithStorage[127.0.0.1:38947,DS-cc538743-3314-4285-9436-df3f4f414069,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-169276308-172.17.0.9-1595937409691:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42347,DS-671c2870-b96f-484c-bfe1-f4abfb77b7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-37911df3-7d18-40ca-b553-618793d6e72c,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-704520df-ff81-4748-b30c-03f59939383d,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-080db591-7a2a-4536-8e49-0609dc12d58e,DISK], DatanodeInfoWithStorage[127.0.0.1:39169,DS-454c67b8-469a-4f9b-8cc8-27e7dcbb4fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-56327f81-db53-49f6-b45d-7d0402328b16,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-4be03a14-444c-4567-b67f-a3b74e020e18,DISK], DatanodeInfoWithStorage[127.0.0.1:38947,DS-cc538743-3314-4285-9436-df3f4f414069,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1480232273-172.17.0.9-1595937734355:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41095,DS-e4f51240-fa78-4ca0-93a2-73b58bb2a11a,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-85b484e2-0f56-4e1a-b748-b83b77691aba,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-97ee8b32-20ed-4b20-ac89-585da55dc66c,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-ceab3e8d-c6a3-47fc-b160-f7b158be49ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-0fc99121-74bc-4af2-be27-a61351b6e3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-a4befd0a-4fb8-46f4-904a-f37544270c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-37746014-f980-4788-b888-72d5f964aee0,DISK], DatanodeInfoWithStorage[127.0.0.1:40461,DS-c92a3a93-d9c1-478c-85b7-9605fb54be4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1480232273-172.17.0.9-1595937734355:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41095,DS-e4f51240-fa78-4ca0-93a2-73b58bb2a11a,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-85b484e2-0f56-4e1a-b748-b83b77691aba,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-97ee8b32-20ed-4b20-ac89-585da55dc66c,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-ceab3e8d-c6a3-47fc-b160-f7b158be49ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-0fc99121-74bc-4af2-be27-a61351b6e3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-a4befd0a-4fb8-46f4-904a-f37544270c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-37746014-f980-4788-b888-72d5f964aee0,DISK], DatanodeInfoWithStorage[127.0.0.1:40461,DS-c92a3a93-d9c1-478c-85b7-9605fb54be4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-638563999-172.17.0.9-1595937897777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38160,DS-1c74cb20-9bba-43ed-b896-62f6c063e68e,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-246df40f-59c2-4556-ab1e-8ceef126ea7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-637d77bd-148c-45d0-8839-da0efcacf240,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-ebc48c1e-23da-44b5-a52b-faa33875f6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36631,DS-77ad0dca-fa2f-4bbb-beb2-86a17e94a04c,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-4d9db4e6-edf9-45a1-bd8b-f0d9649c49f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-c1945ec5-57b9-4afd-9476-ccb2aeb24508,DISK], DatanodeInfoWithStorage[127.0.0.1:40346,DS-b027eed3-3c9b-4241-850d-af96445be6bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-638563999-172.17.0.9-1595937897777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38160,DS-1c74cb20-9bba-43ed-b896-62f6c063e68e,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-246df40f-59c2-4556-ab1e-8ceef126ea7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-637d77bd-148c-45d0-8839-da0efcacf240,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-ebc48c1e-23da-44b5-a52b-faa33875f6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36631,DS-77ad0dca-fa2f-4bbb-beb2-86a17e94a04c,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-4d9db4e6-edf9-45a1-bd8b-f0d9649c49f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-c1945ec5-57b9-4afd-9476-ccb2aeb24508,DISK], DatanodeInfoWithStorage[127.0.0.1:40346,DS-b027eed3-3c9b-4241-850d-af96445be6bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-820129922-172.17.0.9-1595938166598:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37591,DS-0d3a01b4-df5c-48a7-aea5-bf809fad54bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-9b0c98a7-d51b-4ed9-b891-1a3e5f1f2c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-74d92614-1ce6-4987-b21c-8c5c5f9e2111,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-c65b44e1-c4cf-4b6b-93d1-a6b4e807bd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-fb86be07-14ea-4c7b-bd03-4b805f1a42ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-ab78f895-d39a-49c1-9626-60794cd1fbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-d9fcf4d6-9ef6-478e-a424-391dfecf09d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-2a61182a-9405-46da-917b-9a86f808d985,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-820129922-172.17.0.9-1595938166598:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37591,DS-0d3a01b4-df5c-48a7-aea5-bf809fad54bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-9b0c98a7-d51b-4ed9-b891-1a3e5f1f2c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-74d92614-1ce6-4987-b21c-8c5c5f9e2111,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-c65b44e1-c4cf-4b6b-93d1-a6b4e807bd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-fb86be07-14ea-4c7b-bd03-4b805f1a42ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-ab78f895-d39a-49c1-9626-60794cd1fbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-d9fcf4d6-9ef6-478e-a424-391dfecf09d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-2a61182a-9405-46da-917b-9a86f808d985,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-660812448-172.17.0.9-1595938524342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35068,DS-6bc3fdb1-48ef-45c8-8931-248e4cd80e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-50db7e78-ba89-4f21-93d1-c21f53a9fc48,DISK], DatanodeInfoWithStorage[127.0.0.1:39172,DS-3b16f371-7ce8-422d-801d-563df33d3028,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-ec257047-a4bc-4226-9a22-bfcfdca68423,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-1987cfde-cf2b-49da-807e-4a11e7a1e788,DISK], DatanodeInfoWithStorage[127.0.0.1:37607,DS-cd86cd12-3a66-4266-a79c-d2c3f46942be,DISK], DatanodeInfoWithStorage[127.0.0.1:34244,DS-101770a8-d8af-4cc4-9567-a967d76078c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-265e665d-adf7-433c-84a8-e09222da764c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-660812448-172.17.0.9-1595938524342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35068,DS-6bc3fdb1-48ef-45c8-8931-248e4cd80e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-50db7e78-ba89-4f21-93d1-c21f53a9fc48,DISK], DatanodeInfoWithStorage[127.0.0.1:39172,DS-3b16f371-7ce8-422d-801d-563df33d3028,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-ec257047-a4bc-4226-9a22-bfcfdca68423,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-1987cfde-cf2b-49da-807e-4a11e7a1e788,DISK], DatanodeInfoWithStorage[127.0.0.1:37607,DS-cd86cd12-3a66-4266-a79c-d2c3f46942be,DISK], DatanodeInfoWithStorage[127.0.0.1:34244,DS-101770a8-d8af-4cc4-9567-a967d76078c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-265e665d-adf7-433c-84a8-e09222da764c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1974179796-172.17.0.9-1595938987010:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37904,DS-7976c51e-28b4-46c8-a6a1-fba39fa7aa95,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-a7e06ec2-1b54-4af9-99bb-ec5ee9cd0823,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-124dcedd-9820-4a7b-b635-717ed2e3c699,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-1d45ba1c-09e6-4f90-85a2-bd028ba3ff1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-9ca1767f-4e77-4841-bf70-490a18467d95,DISK], DatanodeInfoWithStorage[127.0.0.1:33950,DS-c1ff8b29-5927-45ca-8408-9d1fc5aa9524,DISK], DatanodeInfoWithStorage[127.0.0.1:42139,DS-d06ed955-0c4e-4938-b32e-bda9ed6321e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-2965aded-7fbd-4493-8386-7dc5f9ab7b95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1974179796-172.17.0.9-1595938987010:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37904,DS-7976c51e-28b4-46c8-a6a1-fba39fa7aa95,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-a7e06ec2-1b54-4af9-99bb-ec5ee9cd0823,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-124dcedd-9820-4a7b-b635-717ed2e3c699,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-1d45ba1c-09e6-4f90-85a2-bd028ba3ff1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-9ca1767f-4e77-4841-bf70-490a18467d95,DISK], DatanodeInfoWithStorage[127.0.0.1:33950,DS-c1ff8b29-5927-45ca-8408-9d1fc5aa9524,DISK], DatanodeInfoWithStorage[127.0.0.1:42139,DS-d06ed955-0c4e-4938-b32e-bda9ed6321e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-2965aded-7fbd-4493-8386-7dc5f9ab7b95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-100774682-172.17.0.9-1595939117993:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43039,DS-7d7ef74e-cef2-4155-940e-c218347d2a79,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-06be9bf9-b6e7-4b79-8fcb-6810919e1ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-b6721f1a-2974-4e35-99b3-cad03ba2591f,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-862ea0a1-69df-4083-a3a1-1cd39d5eb219,DISK], DatanodeInfoWithStorage[127.0.0.1:41139,DS-5dcd3c0a-9949-4ed7-b69e-f7cfd1a469e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-737b6a19-6e13-4a5b-abe2-f0813ef30aab,DISK], DatanodeInfoWithStorage[127.0.0.1:34355,DS-f49b26b7-695b-4971-adfb-8e443398b1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-2ba3d3b9-49d5-41a8-a914-655cf36b2310,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-100774682-172.17.0.9-1595939117993:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43039,DS-7d7ef74e-cef2-4155-940e-c218347d2a79,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-06be9bf9-b6e7-4b79-8fcb-6810919e1ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-b6721f1a-2974-4e35-99b3-cad03ba2591f,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-862ea0a1-69df-4083-a3a1-1cd39d5eb219,DISK], DatanodeInfoWithStorage[127.0.0.1:41139,DS-5dcd3c0a-9949-4ed7-b69e-f7cfd1a469e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-737b6a19-6e13-4a5b-abe2-f0813ef30aab,DISK], DatanodeInfoWithStorage[127.0.0.1:34355,DS-f49b26b7-695b-4971-adfb-8e443398b1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-2ba3d3b9-49d5-41a8-a914-655cf36b2310,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1874925537-172.17.0.9-1595939258231:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33292,DS-9b6efddb-e43e-42f5-99c3-5f795611ae41,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-d84ab8df-2330-4444-bbbc-0e1080e1d4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-c0ad15d6-5bdd-43f8-bcfb-f7f9125dccba,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-b61aa93e-e60e-4ca4-9bef-e0067d94653b,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-00aed562-0610-46ad-99e2-7c005525164b,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-29bedbb5-0584-48ff-bc86-22e97cb1ae65,DISK], DatanodeInfoWithStorage[127.0.0.1:33594,DS-c75f691c-8fcb-4981-a87b-b348d2ca3cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-28c59e89-259e-4567-ac2a-16989256689f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1874925537-172.17.0.9-1595939258231:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33292,DS-9b6efddb-e43e-42f5-99c3-5f795611ae41,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-d84ab8df-2330-4444-bbbc-0e1080e1d4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-c0ad15d6-5bdd-43f8-bcfb-f7f9125dccba,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-b61aa93e-e60e-4ca4-9bef-e0067d94653b,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-00aed562-0610-46ad-99e2-7c005525164b,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-29bedbb5-0584-48ff-bc86-22e97cb1ae65,DISK], DatanodeInfoWithStorage[127.0.0.1:33594,DS-c75f691c-8fcb-4981-a87b-b348d2ca3cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-28c59e89-259e-4567-ac2a-16989256689f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1914904897-172.17.0.9-1595939538488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44405,DS-1e8d69b2-7199-4048-a0b0-fbd9bfe14ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-7a6d9f71-6061-4c21-8352-c9ddbb8c335b,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-2aa7d6ec-880f-4bb7-9648-7d950bf103fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-f118c62f-56a8-4886-9d04-3d7aba3301d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-20dbb62c-38c1-4db8-8806-4228b62fc064,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-6c4e406d-63ed-42bd-a998-e583c0804997,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-42064b5c-62da-4f49-bf8e-bf9bc80dc0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-8a88345a-ac08-4f3a-ab8d-e3e8d4aaae39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1914904897-172.17.0.9-1595939538488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44405,DS-1e8d69b2-7199-4048-a0b0-fbd9bfe14ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-7a6d9f71-6061-4c21-8352-c9ddbb8c335b,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-2aa7d6ec-880f-4bb7-9648-7d950bf103fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-f118c62f-56a8-4886-9d04-3d7aba3301d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-20dbb62c-38c1-4db8-8806-4228b62fc064,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-6c4e406d-63ed-42bd-a998-e583c0804997,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-42064b5c-62da-4f49-bf8e-bf9bc80dc0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-8a88345a-ac08-4f3a-ab8d-e3e8d4aaae39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-325883543-172.17.0.9-1595939713140:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40454,DS-d2a92404-f9b9-4638-8665-fe281f3095c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-5836f05a-f966-4a34-b747-8b70f0864f50,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-22fd4223-f7b4-40ca-a51d-55acd181a191,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-fc515855-2cfd-4e9b-a084-f79271aab57b,DISK], DatanodeInfoWithStorage[127.0.0.1:37401,DS-cfabaa62-24ec-4871-8765-a1fac7467d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-56e30bcc-47e1-43e0-843e-db0d37857f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-aaa9f3fa-620f-4d1e-8eee-e1e760e7967a,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-e3acff34-9938-42f5-af70-e91e200a46a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-325883543-172.17.0.9-1595939713140:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40454,DS-d2a92404-f9b9-4638-8665-fe281f3095c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-5836f05a-f966-4a34-b747-8b70f0864f50,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-22fd4223-f7b4-40ca-a51d-55acd181a191,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-fc515855-2cfd-4e9b-a084-f79271aab57b,DISK], DatanodeInfoWithStorage[127.0.0.1:37401,DS-cfabaa62-24ec-4871-8765-a1fac7467d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-56e30bcc-47e1-43e0-843e-db0d37857f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-aaa9f3fa-620f-4d1e-8eee-e1e760e7967a,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-e3acff34-9938-42f5-af70-e91e200a46a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1997165696-172.17.0.9-1595939919318:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37307,DS-0fac8eb4-eb42-4f5f-a016-9e3aae78dc1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-3de113a1-1774-4ef6-b673-dc7c0a81e394,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-4b930418-a757-41f2-940c-05da5058c498,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-b0248a00-2a81-43c8-bc9d-917b401f99bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-95729ce9-a9b3-4919-900a-02488cbe8716,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-c4c860bd-4015-4776-981b-4cb834fd595b,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-e5b507dc-156d-401f-be5e-c84f7e69ee02,DISK], DatanodeInfoWithStorage[127.0.0.1:44768,DS-7cc9dfb3-e956-475a-a799-927e00c55265,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1997165696-172.17.0.9-1595939919318:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37307,DS-0fac8eb4-eb42-4f5f-a016-9e3aae78dc1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-3de113a1-1774-4ef6-b673-dc7c0a81e394,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-4b930418-a757-41f2-940c-05da5058c498,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-b0248a00-2a81-43c8-bc9d-917b401f99bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-95729ce9-a9b3-4919-900a-02488cbe8716,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-c4c860bd-4015-4776-981b-4cb834fd595b,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-e5b507dc-156d-401f-be5e-c84f7e69ee02,DISK], DatanodeInfoWithStorage[127.0.0.1:44768,DS-7cc9dfb3-e956-475a-a799-927e00c55265,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2058803354-172.17.0.9-1595940174443:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40654,DS-0a7ae22c-cc70-4724-bc65-e1670eeb21cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-bb46170a-fb2e-41f1-8230-e1a6808fba77,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-97209ade-785a-40c0-b0a9-2eb82fea208f,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-95b5f7af-e96b-471e-b20c-0f20bb4cb5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-573afc1f-c730-4a24-971d-84bf7ef9f640,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-d0076b43-ff7c-4d7a-a862-4e7f1fda14e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-31afe021-23b8-4db6-9857-aa4c90ab9582,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-4d8545a1-a88c-4028-9b14-9869d1f6845e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2058803354-172.17.0.9-1595940174443:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40654,DS-0a7ae22c-cc70-4724-bc65-e1670eeb21cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-bb46170a-fb2e-41f1-8230-e1a6808fba77,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-97209ade-785a-40c0-b0a9-2eb82fea208f,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-95b5f7af-e96b-471e-b20c-0f20bb4cb5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-573afc1f-c730-4a24-971d-84bf7ef9f640,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-d0076b43-ff7c-4d7a-a862-4e7f1fda14e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-31afe021-23b8-4db6-9857-aa4c90ab9582,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-4d8545a1-a88c-4028-9b14-9869d1f6845e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1739556832-172.17.0.9-1595940776916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44405,DS-c0a17cf5-741b-4a68-b498-e7910baecdbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-935b5b94-d0eb-4aaa-88ea-41e922b7d52b,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-61979019-1626-4151-85d0-16d3a9b4786b,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-4b601b33-347c-4983-88d8-1f0430856b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-40081d40-1840-4586-ab93-8e23acdbbdba,DISK], DatanodeInfoWithStorage[127.0.0.1:39913,DS-9f534215-4ea2-4212-a44a-dcd00846b115,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-347c75e9-2ecf-4e2e-949f-ff94c7956acd,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-ccd0ab18-3aed-47c1-b35e-1e96eb5b98fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1739556832-172.17.0.9-1595940776916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44405,DS-c0a17cf5-741b-4a68-b498-e7910baecdbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-935b5b94-d0eb-4aaa-88ea-41e922b7d52b,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-61979019-1626-4151-85d0-16d3a9b4786b,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-4b601b33-347c-4983-88d8-1f0430856b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-40081d40-1840-4586-ab93-8e23acdbbdba,DISK], DatanodeInfoWithStorage[127.0.0.1:39913,DS-9f534215-4ea2-4212-a44a-dcd00846b115,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-347c75e9-2ecf-4e2e-949f-ff94c7956acd,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-ccd0ab18-3aed-47c1-b35e-1e96eb5b98fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-286978658-172.17.0.9-1595940959897:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41898,DS-39246153-5427-4405-be5e-e648ac87cf03,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-dcae11d7-a2ca-4be4-9809-0824131de177,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-fa8f02a5-17ac-4c0a-aaba-0fe64286408c,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-22c65939-ccab-4158-89a9-f718fef3ccc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35087,DS-d374490e-a1b5-4ab0-b2f3-86e60527b9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36970,DS-dc992dc9-b01f-4d1d-8e6d-613990df27fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-5693df95-592c-4093-a92b-086d8f21dd83,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-e304c90c-d4c4-4452-b44b-38dd2b9a07c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-286978658-172.17.0.9-1595940959897:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41898,DS-39246153-5427-4405-be5e-e648ac87cf03,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-dcae11d7-a2ca-4be4-9809-0824131de177,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-fa8f02a5-17ac-4c0a-aaba-0fe64286408c,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-22c65939-ccab-4158-89a9-f718fef3ccc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35087,DS-d374490e-a1b5-4ab0-b2f3-86e60527b9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36970,DS-dc992dc9-b01f-4d1d-8e6d-613990df27fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-5693df95-592c-4093-a92b-086d8f21dd83,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-e304c90c-d4c4-4452-b44b-38dd2b9a07c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-535507199-172.17.0.9-1595941027363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33410,DS-b297bd32-2894-4806-a335-37ad1034f9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-57b7f45e-0d72-4a06-a39a-df1d9e5cb0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-f72ff029-9dcf-4652-85fe-b2a062a436de,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-5d041599-fe1c-45a6-866d-9c065698253f,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-9807c56b-1ccd-4011-ac0e-81e8042ca888,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-bccd78c0-3f8d-41dd-8375-5ab45271d6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-1ac6a0e4-c437-467e-a0bf-a1536dc3929f,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-706bd9d3-7a03-4c25-93d0-243ff68da044,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-535507199-172.17.0.9-1595941027363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33410,DS-b297bd32-2894-4806-a335-37ad1034f9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-57b7f45e-0d72-4a06-a39a-df1d9e5cb0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-f72ff029-9dcf-4652-85fe-b2a062a436de,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-5d041599-fe1c-45a6-866d-9c065698253f,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-9807c56b-1ccd-4011-ac0e-81e8042ca888,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-bccd78c0-3f8d-41dd-8375-5ab45271d6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-1ac6a0e4-c437-467e-a0bf-a1536dc3929f,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-706bd9d3-7a03-4c25-93d0-243ff68da044,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1899337915-172.17.0.9-1595941060067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44158,DS-1eab8332-2ce9-4846-a2d3-8e432a9b87ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-45c89de3-8bfe-4ba1-8a72-c3621fca6831,DISK], DatanodeInfoWithStorage[127.0.0.1:43881,DS-888711d1-10e1-4feb-8b7b-16fdc9ee1c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-0cd77d46-6268-4d78-a620-51a2bc204ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:39169,DS-4133c98b-aa97-46bb-8b77-fc5737762b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-45c2f103-d4f2-4491-9362-03c8e30791e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-1d3be4ff-a84e-48d4-81e2-76b6d877e751,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-ae19bece-b3ae-4b16-9087-169b845d3fa4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1899337915-172.17.0.9-1595941060067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44158,DS-1eab8332-2ce9-4846-a2d3-8e432a9b87ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-45c89de3-8bfe-4ba1-8a72-c3621fca6831,DISK], DatanodeInfoWithStorage[127.0.0.1:43881,DS-888711d1-10e1-4feb-8b7b-16fdc9ee1c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-0cd77d46-6268-4d78-a620-51a2bc204ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:39169,DS-4133c98b-aa97-46bb-8b77-fc5737762b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-45c2f103-d4f2-4491-9362-03c8e30791e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-1d3be4ff-a84e-48d4-81e2-76b6d877e751,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-ae19bece-b3ae-4b16-9087-169b845d3fa4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1116563756-172.17.0.9-1595941158268:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44407,DS-49b88211-b714-451a-9e6a-eb707102331b,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-82f7f42d-02a3-40a0-b715-97af5021bea0,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-5028fc01-596b-48a4-a73c-29134e07a19f,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-8c9a7163-04ef-4b6a-86eb-ae8ebb794fba,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-6984041c-4565-455e-a39e-45e4564372c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40604,DS-3ac3b93f-f40b-463c-b868-e571ad72613f,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-fd6ce3ae-0aee-40f5-8ebf-a30d1a98c3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-54cad5bf-06d7-4eca-88cf-722b1441d790,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1116563756-172.17.0.9-1595941158268:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44407,DS-49b88211-b714-451a-9e6a-eb707102331b,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-82f7f42d-02a3-40a0-b715-97af5021bea0,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-5028fc01-596b-48a4-a73c-29134e07a19f,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-8c9a7163-04ef-4b6a-86eb-ae8ebb794fba,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-6984041c-4565-455e-a39e-45e4564372c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40604,DS-3ac3b93f-f40b-463c-b868-e571ad72613f,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-fd6ce3ae-0aee-40f5-8ebf-a30d1a98c3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-54cad5bf-06d7-4eca-88cf-722b1441d790,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.max.attempts
component: hdfs:NameNode
v1: 15
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-728877354-172.17.0.9-1595941192590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44826,DS-45945e39-fb2a-4d25-9e7d-d4ea70483353,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-5d77141f-5007-4133-ba16-2bc7db17a380,DISK], DatanodeInfoWithStorage[127.0.0.1:45064,DS-030a135d-a86c-4bf7-85a2-72a4765cafd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-98061bc4-d05c-489a-91c8-d9feb3d2485d,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-e12e796a-893a-4d38-99b2-ce96fe3c8c84,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-6e60bb34-0239-44f9-8fd5-bf1bdec97903,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-0774e0d1-785e-4a02-bf3c-6a2f88a21856,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-bbd5457d-d406-417c-ae28-1ea75c27f17a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-728877354-172.17.0.9-1595941192590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44826,DS-45945e39-fb2a-4d25-9e7d-d4ea70483353,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-5d77141f-5007-4133-ba16-2bc7db17a380,DISK], DatanodeInfoWithStorage[127.0.0.1:45064,DS-030a135d-a86c-4bf7-85a2-72a4765cafd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-98061bc4-d05c-489a-91c8-d9feb3d2485d,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-e12e796a-893a-4d38-99b2-ce96fe3c8c84,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-6e60bb34-0239-44f9-8fd5-bf1bdec97903,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-0774e0d1-785e-4a02-bf3c-6a2f88a21856,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-bbd5457d-d406-417c-ae28-1ea75c27f17a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5214
