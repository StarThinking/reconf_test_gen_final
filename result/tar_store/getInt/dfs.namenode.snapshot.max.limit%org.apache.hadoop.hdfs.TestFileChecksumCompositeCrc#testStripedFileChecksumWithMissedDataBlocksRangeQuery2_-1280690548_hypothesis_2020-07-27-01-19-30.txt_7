reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 1
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 1
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2095317854-172.17.0.18-1595812992426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39017,DS-3135b0b0-5924-40aa-8553-56f1187543da,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-27857331-76ab-47f9-92c9-9566f9cf3607,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-a78d6a57-3754-4aa7-93bd-1440bc87d89e,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-70b4d041-c19f-4f89-b14e-bfdecd8f30d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-1b5db9cd-8adc-43f5-809e-54af2fb0807a,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-b5968060-f649-4cad-b835-2824f641048d,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-e369eb25-758b-4e64-95b6-a57da2d72181,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-60630795-3904-4c22-b316-088da4379589,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2095317854-172.17.0.18-1595812992426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39017,DS-3135b0b0-5924-40aa-8553-56f1187543da,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-27857331-76ab-47f9-92c9-9566f9cf3607,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-a78d6a57-3754-4aa7-93bd-1440bc87d89e,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-70b4d041-c19f-4f89-b14e-bfdecd8f30d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-1b5db9cd-8adc-43f5-809e-54af2fb0807a,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-b5968060-f649-4cad-b835-2824f641048d,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-e369eb25-758b-4e64-95b6-a57da2d72181,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-60630795-3904-4c22-b316-088da4379589,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 1
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-89231553-172.17.0.18-1595813033237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34291,DS-784002ac-fce4-41b8-833c-cd76158b18b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-b3b93bd3-0e53-4d93-b14d-6e5fe26ec0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-63c779d6-a665-4df6-aae4-1b5648da9c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36628,DS-64c818bb-315d-42fb-9aff-c8cf8b485403,DISK], DatanodeInfoWithStorage[127.0.0.1:39807,DS-98763707-a869-4f73-a97d-92d553253259,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-3348d1d0-4e05-46a9-b62d-e1585226bd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-f07267b2-2732-4599-9b13-a8c2bb73b634,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-3e53656d-9cad-46eb-8106-5659042806fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-89231553-172.17.0.18-1595813033237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34291,DS-784002ac-fce4-41b8-833c-cd76158b18b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-b3b93bd3-0e53-4d93-b14d-6e5fe26ec0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-63c779d6-a665-4df6-aae4-1b5648da9c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36628,DS-64c818bb-315d-42fb-9aff-c8cf8b485403,DISK], DatanodeInfoWithStorage[127.0.0.1:39807,DS-98763707-a869-4f73-a97d-92d553253259,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-3348d1d0-4e05-46a9-b62d-e1585226bd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-f07267b2-2732-4599-9b13-a8c2bb73b634,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-3e53656d-9cad-46eb-8106-5659042806fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 1
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1792629144-172.17.0.18-1595813581639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41998,DS-8735c4a5-9abe-4597-bf19-f26a49ae3adb,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-77af9571-fb0c-4a14-816e-bc23b67c838e,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-d75d643d-fab3-4893-a771-cbd8824a7102,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-da848d0f-ed25-43b1-9b12-ede8023dab0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-a70ec852-5ac7-4e2a-8308-7a510941ef8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-41fc2cc7-22c0-4413-acdd-b4d69f8b946c,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-9a8c9acf-560b-4915-8960-4f064ded9522,DISK], DatanodeInfoWithStorage[127.0.0.1:34456,DS-37924c7b-e7c7-45fd-b5ff-197399f9ef21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1792629144-172.17.0.18-1595813581639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41998,DS-8735c4a5-9abe-4597-bf19-f26a49ae3adb,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-77af9571-fb0c-4a14-816e-bc23b67c838e,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-d75d643d-fab3-4893-a771-cbd8824a7102,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-da848d0f-ed25-43b1-9b12-ede8023dab0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-a70ec852-5ac7-4e2a-8308-7a510941ef8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-41fc2cc7-22c0-4413-acdd-b4d69f8b946c,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-9a8c9acf-560b-4915-8960-4f064ded9522,DISK], DatanodeInfoWithStorage[127.0.0.1:34456,DS-37924c7b-e7c7-45fd-b5ff-197399f9ef21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 1
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1535082399-172.17.0.18-1595813768073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40437,DS-7747b6a6-5b3d-4432-bdea-289d5a195f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-f9e79f5c-aec7-4be7-8024-a44e333f637f,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-f7d881c0-0b37-4189-9100-fac27d18a026,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-dc660b92-4fcc-49c7-92e9-2cd63b4b79e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-f06fa7d0-fe67-4880-98b9-9db2cdee4986,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-98cb0940-eea1-405e-9be9-00f4af6472b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-04f0215c-a938-4e93-b8c5-27357ec770ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-3ca1cdb5-1505-4ef2-9f15-25d9bf25aa7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1535082399-172.17.0.18-1595813768073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40437,DS-7747b6a6-5b3d-4432-bdea-289d5a195f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-f9e79f5c-aec7-4be7-8024-a44e333f637f,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-f7d881c0-0b37-4189-9100-fac27d18a026,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-dc660b92-4fcc-49c7-92e9-2cd63b4b79e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-f06fa7d0-fe67-4880-98b9-9db2cdee4986,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-98cb0940-eea1-405e-9be9-00f4af6472b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-04f0215c-a938-4e93-b8c5-27357ec770ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-3ca1cdb5-1505-4ef2-9f15-25d9bf25aa7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 1
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-154439910-172.17.0.18-1595813852429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33244,DS-ca7e32d9-1938-4ca3-aa9e-3eff7039d6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45719,DS-c85daf1d-b99c-40e9-834d-d4822f97a21f,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-46e51140-69a0-4dae-ab4f-0d9d1f398249,DISK], DatanodeInfoWithStorage[127.0.0.1:37170,DS-8767b154-115c-4a9b-9086-294282669b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43081,DS-54e550b8-a6c8-435f-997a-51c90370e588,DISK], DatanodeInfoWithStorage[127.0.0.1:37185,DS-3bade725-5b25-41ea-a3b0-a57e6b3b27be,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-63a57a3a-5b3c-4970-8072-dbda06a5a10e,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-ebf5d03d-868e-475e-ad31-2e71c62d3c49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-154439910-172.17.0.18-1595813852429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33244,DS-ca7e32d9-1938-4ca3-aa9e-3eff7039d6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45719,DS-c85daf1d-b99c-40e9-834d-d4822f97a21f,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-46e51140-69a0-4dae-ab4f-0d9d1f398249,DISK], DatanodeInfoWithStorage[127.0.0.1:37170,DS-8767b154-115c-4a9b-9086-294282669b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43081,DS-54e550b8-a6c8-435f-997a-51c90370e588,DISK], DatanodeInfoWithStorage[127.0.0.1:37185,DS-3bade725-5b25-41ea-a3b0-a57e6b3b27be,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-63a57a3a-5b3c-4970-8072-dbda06a5a10e,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-ebf5d03d-868e-475e-ad31-2e71c62d3c49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 1
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-792523413-172.17.0.18-1595814877239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41557,DS-97c21bb4-1a74-46d1-96d7-30813285107d,DISK], DatanodeInfoWithStorage[127.0.0.1:41468,DS-544e0cb4-9dd5-4e33-8cb4-49c29e3d5e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-f4132771-2087-4657-aa11-84b36e65c6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-f4443c4f-a6cc-4c66-9fc2-7589e8a06010,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-798814e1-b06f-4cb7-8b77-c67481d79c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-df6d4fd4-a6b8-43db-8ac3-60db0caadb8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-04276b6b-e655-483c-87c8-9e834c840691,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-c58421e7-1ca9-4ae7-9a73-febaa31044d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-792523413-172.17.0.18-1595814877239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41557,DS-97c21bb4-1a74-46d1-96d7-30813285107d,DISK], DatanodeInfoWithStorage[127.0.0.1:41468,DS-544e0cb4-9dd5-4e33-8cb4-49c29e3d5e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-f4132771-2087-4657-aa11-84b36e65c6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-f4443c4f-a6cc-4c66-9fc2-7589e8a06010,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-798814e1-b06f-4cb7-8b77-c67481d79c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-df6d4fd4-a6b8-43db-8ac3-60db0caadb8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-04276b6b-e655-483c-87c8-9e834c840691,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-c58421e7-1ca9-4ae7-9a73-febaa31044d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 1
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-104657632-172.17.0.18-1595815435814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38909,DS-d13bc0cb-5717-4b06-85a4-02505eb35f04,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-18a1645c-70c1-4083-b2b3-53bf2f46026c,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-55878dfc-6589-4d73-9161-3732a0364aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-54dcee18-4e5e-4550-9e88-1414088a8d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-cba5da48-cb0e-4c2b-8e90-58a4dd8d3b06,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-5bf229d9-99f6-4216-85d2-0c95ea31dfd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44938,DS-4aeb3880-bccb-4b07-8bd0-e6869623dee4,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-d27667a5-7405-4ff3-a31a-a9110b92bebb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-104657632-172.17.0.18-1595815435814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38909,DS-d13bc0cb-5717-4b06-85a4-02505eb35f04,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-18a1645c-70c1-4083-b2b3-53bf2f46026c,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-55878dfc-6589-4d73-9161-3732a0364aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-54dcee18-4e5e-4550-9e88-1414088a8d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-cba5da48-cb0e-4c2b-8e90-58a4dd8d3b06,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-5bf229d9-99f6-4216-85d2-0c95ea31dfd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44938,DS-4aeb3880-bccb-4b07-8bd0-e6869623dee4,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-d27667a5-7405-4ff3-a31a-a9110b92bebb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 1
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-495506821-172.17.0.18-1595815974265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38026,DS-0d2cf399-ec2f-494a-96e8-00a946e01008,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-e659df2e-b0d0-43ac-9cb0-2e242dc973aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-c2750799-4e3b-4f73-a5f6-5af841cc3992,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-401e0871-b8f5-49ab-aaef-131d042320a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42886,DS-a3deef60-99a9-4ab4-8735-6240f3949406,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-91399cc9-3be8-403f-9e45-793598634e31,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-1a761eae-afbf-4883-a33e-d6fd3db9c509,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-451d4682-9452-49a7-b352-250cd04a78ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-495506821-172.17.0.18-1595815974265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38026,DS-0d2cf399-ec2f-494a-96e8-00a946e01008,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-e659df2e-b0d0-43ac-9cb0-2e242dc973aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-c2750799-4e3b-4f73-a5f6-5af841cc3992,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-401e0871-b8f5-49ab-aaef-131d042320a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42886,DS-a3deef60-99a9-4ab4-8735-6240f3949406,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-91399cc9-3be8-403f-9e45-793598634e31,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-1a761eae-afbf-4883-a33e-d6fd3db9c509,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-451d4682-9452-49a7-b352-250cd04a78ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 1
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2042068955-172.17.0.18-1595816105775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38685,DS-6603627e-cf6f-4d72-a65f-94f5005d62ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-eeed4bf6-fe35-4ef9-a633-d0e1ebd08686,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-a07b53bd-9474-4970-9874-b12caf93e0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-10074e41-2931-48e3-808a-b5a08ca144b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-38a65156-c0ab-4e49-adab-f93b02885e79,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-d2328b80-1917-465c-80ad-34dddac55e22,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-424058c8-581e-42df-9076-43305cfe2452,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-93b6c7ad-79df-4390-997b-6e41257f90a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2042068955-172.17.0.18-1595816105775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38685,DS-6603627e-cf6f-4d72-a65f-94f5005d62ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-eeed4bf6-fe35-4ef9-a633-d0e1ebd08686,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-a07b53bd-9474-4970-9874-b12caf93e0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-10074e41-2931-48e3-808a-b5a08ca144b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-38a65156-c0ab-4e49-adab-f93b02885e79,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-d2328b80-1917-465c-80ad-34dddac55e22,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-424058c8-581e-42df-9076-43305cfe2452,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-93b6c7ad-79df-4390-997b-6e41257f90a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 1
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1124871518-172.17.0.18-1595816258979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44974,DS-a109f8d5-82a2-4d56-81ff-5ff379f99a12,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-e2b5fe65-5b85-472a-9721-5654f4526bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-d9c03ec3-2096-4399-ae2e-25b1ea68358b,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-c8503ac3-a315-44a2-b6e6-98cb35070615,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-f1c7afbf-6854-4c65-a2bc-2860335595a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-b80fa11a-02e3-49ad-bef2-fe2debe508bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-f10173d1-c6d2-4281-a82c-a72d4b14b436,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-6f77723e-ece9-431b-82d9-08f98137f78d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1124871518-172.17.0.18-1595816258979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44974,DS-a109f8d5-82a2-4d56-81ff-5ff379f99a12,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-e2b5fe65-5b85-472a-9721-5654f4526bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-d9c03ec3-2096-4399-ae2e-25b1ea68358b,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-c8503ac3-a315-44a2-b6e6-98cb35070615,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-f1c7afbf-6854-4c65-a2bc-2860335595a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-b80fa11a-02e3-49ad-bef2-fe2debe508bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-f10173d1-c6d2-4281-a82c-a72d4b14b436,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-6f77723e-ece9-431b-82d9-08f98137f78d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 1
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1495865046-172.17.0.18-1595816331906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38285,DS-71de54a3-31be-43e5-ba39-df7db875deb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37184,DS-2d82331c-a81b-412c-8a98-2bb26be514ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45634,DS-2c4e39a0-3f48-42f4-a0c6-6db2cf939207,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-22e9dd2d-14bf-406e-b15f-51201b90a2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-55ea13ae-c2c2-4e18-a835-cd24ebb98e43,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-8e8a82d6-8ad6-474e-9ae3-992e91ea2a40,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-61b2ec4c-0f10-4974-ac7b-5564634b2dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-f8f82d2e-0a9b-4a0e-bc0a-309767160210,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1495865046-172.17.0.18-1595816331906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38285,DS-71de54a3-31be-43e5-ba39-df7db875deb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37184,DS-2d82331c-a81b-412c-8a98-2bb26be514ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45634,DS-2c4e39a0-3f48-42f4-a0c6-6db2cf939207,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-22e9dd2d-14bf-406e-b15f-51201b90a2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-55ea13ae-c2c2-4e18-a835-cd24ebb98e43,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-8e8a82d6-8ad6-474e-9ae3-992e91ea2a40,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-61b2ec4c-0f10-4974-ac7b-5564634b2dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-f8f82d2e-0a9b-4a0e-bc0a-309767160210,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 1
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-533674289-172.17.0.18-1595816514804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33299,DS-ad83e13b-8b6f-4104-a2e2-368dd17e1f30,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-967c3a41-45a5-41d8-9132-17ec2f75ad5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-95291c24-9d4a-42fe-b8cb-241c05b81efb,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-b8853cfb-ef88-45e8-8b25-e6cd213cf001,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-caf72712-fd91-471f-b07d-f1956dbf96fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-bcc80421-b63f-4771-b268-aa7fd417b234,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-4b92ad41-3c78-40ec-bbff-51dbe3bc2760,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-d9a521fd-ecbc-4388-a2ee-f183d157d4b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-533674289-172.17.0.18-1595816514804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33299,DS-ad83e13b-8b6f-4104-a2e2-368dd17e1f30,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-967c3a41-45a5-41d8-9132-17ec2f75ad5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-95291c24-9d4a-42fe-b8cb-241c05b81efb,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-b8853cfb-ef88-45e8-8b25-e6cd213cf001,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-caf72712-fd91-471f-b07d-f1956dbf96fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-bcc80421-b63f-4771-b268-aa7fd417b234,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-4b92ad41-3c78-40ec-bbff-51dbe3bc2760,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-d9a521fd-ecbc-4388-a2ee-f183d157d4b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 1
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-979257547-172.17.0.18-1595816598039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44266,DS-b56fb63c-5e87-414e-9195-50253d0007c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-ac3399de-c4a9-4146-b6b9-390d58056533,DISK], DatanodeInfoWithStorage[127.0.0.1:40834,DS-e671b4fb-d600-4cf3-82a2-5574a8f5c688,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-1a3c75c8-b39d-41f8-ade4-952a2ae5f890,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-83bdafc9-893c-431d-91b1-581956a78a60,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-6fba8614-faf0-41e3-9b7d-803ef56e670d,DISK], DatanodeInfoWithStorage[127.0.0.1:37403,DS-8512e66e-daf5-46ef-877b-7a8bde004761,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-8b90b78e-a864-49c9-a0a5-ee776620f36a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-979257547-172.17.0.18-1595816598039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44266,DS-b56fb63c-5e87-414e-9195-50253d0007c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-ac3399de-c4a9-4146-b6b9-390d58056533,DISK], DatanodeInfoWithStorage[127.0.0.1:40834,DS-e671b4fb-d600-4cf3-82a2-5574a8f5c688,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-1a3c75c8-b39d-41f8-ade4-952a2ae5f890,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-83bdafc9-893c-431d-91b1-581956a78a60,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-6fba8614-faf0-41e3-9b7d-803ef56e670d,DISK], DatanodeInfoWithStorage[127.0.0.1:37403,DS-8512e66e-daf5-46ef-877b-7a8bde004761,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-8b90b78e-a864-49c9-a0a5-ee776620f36a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 1
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-55974438-172.17.0.18-1595816819662:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40481,DS-4bb4d857-1200-4f71-a33f-1b7fbd7ec024,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-9a616635-bd6b-4b8a-bacf-ba4ebd5c43fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-b9c81211-3965-4147-8f5f-a56ebe8b2734,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-964e2044-ab36-48bb-afe3-5498c4e76f96,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-7801d226-fdaf-408f-9b89-ca0aeb001539,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-42f38dac-f686-4236-a3ee-21752edbc096,DISK], DatanodeInfoWithStorage[127.0.0.1:38565,DS-0144c19c-b5ff-416c-8462-838c6370b743,DISK], DatanodeInfoWithStorage[127.0.0.1:38644,DS-344b567a-bdc1-4c50-a20e-3fe5125ef97a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-55974438-172.17.0.18-1595816819662:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40481,DS-4bb4d857-1200-4f71-a33f-1b7fbd7ec024,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-9a616635-bd6b-4b8a-bacf-ba4ebd5c43fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-b9c81211-3965-4147-8f5f-a56ebe8b2734,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-964e2044-ab36-48bb-afe3-5498c4e76f96,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-7801d226-fdaf-408f-9b89-ca0aeb001539,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-42f38dac-f686-4236-a3ee-21752edbc096,DISK], DatanodeInfoWithStorage[127.0.0.1:38565,DS-0144c19c-b5ff-416c-8462-838c6370b743,DISK], DatanodeInfoWithStorage[127.0.0.1:38644,DS-344b567a-bdc1-4c50-a20e-3fe5125ef97a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 1
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-42789294-172.17.0.18-1595817073726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36150,DS-ec3029ae-0240-4b8c-bdb0-4eb920706648,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-9f074199-8110-4c41-8d19-021495596fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-90cae666-826f-4813-bdc8-c2af41e10903,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-87dab81f-d9da-4dd5-b279-41df606e9aee,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-bd90e51d-4afc-4170-a89c-c53b1e25d866,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-f27313c4-961d-42b6-9859-82583fcf6359,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-0c9a5ec5-51a4-4558-a992-99aca5a902b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-1492d5a6-e998-4655-9d52-2ac21dd44464,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-42789294-172.17.0.18-1595817073726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36150,DS-ec3029ae-0240-4b8c-bdb0-4eb920706648,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-9f074199-8110-4c41-8d19-021495596fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-90cae666-826f-4813-bdc8-c2af41e10903,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-87dab81f-d9da-4dd5-b279-41df606e9aee,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-bd90e51d-4afc-4170-a89c-c53b1e25d866,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-f27313c4-961d-42b6-9859-82583fcf6359,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-0c9a5ec5-51a4-4558-a992-99aca5a902b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-1492d5a6-e998-4655-9d52-2ac21dd44464,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 1
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-537484152-172.17.0.18-1595817229692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40332,DS-d7f7d9fa-8dfa-4291-98d0-3f265a5587ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-56e5b59d-ddad-4558-bd51-a718b7a543a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-ad8ebd14-034d-4b02-8924-b3f4defbf34f,DISK], DatanodeInfoWithStorage[127.0.0.1:43041,DS-1469bf85-d5fd-4f48-8877-4f00cfd7897c,DISK], DatanodeInfoWithStorage[127.0.0.1:46015,DS-29bcc4f8-1c3b-4805-b338-24fa4803e192,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-4ca8026d-3c44-473b-8fbb-f28f1dac990c,DISK], DatanodeInfoWithStorage[127.0.0.1:33817,DS-1ed58b9b-9a4a-494e-919d-fe13a0d44fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-3dde4ee9-78dc-4d96-921d-0052be46f521,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-537484152-172.17.0.18-1595817229692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40332,DS-d7f7d9fa-8dfa-4291-98d0-3f265a5587ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-56e5b59d-ddad-4558-bd51-a718b7a543a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-ad8ebd14-034d-4b02-8924-b3f4defbf34f,DISK], DatanodeInfoWithStorage[127.0.0.1:43041,DS-1469bf85-d5fd-4f48-8877-4f00cfd7897c,DISK], DatanodeInfoWithStorage[127.0.0.1:46015,DS-29bcc4f8-1c3b-4805-b338-24fa4803e192,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-4ca8026d-3c44-473b-8fbb-f28f1dac990c,DISK], DatanodeInfoWithStorage[127.0.0.1:33817,DS-1ed58b9b-9a4a-494e-919d-fe13a0d44fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-3dde4ee9-78dc-4d96-921d-0052be46f521,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 1
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1198301738-172.17.0.18-1595817306752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35862,DS-87465b62-330f-47f6-8637-7c7a0f939492,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-e9a14ce2-9d75-4126-9950-88294b6b048b,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-dc458d57-a595-4fad-a2a0-d8e1065e14e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44550,DS-07a5284a-2c1d-4ff2-abc2-53b98b2e4630,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-d1cf4e0a-3de4-43b7-bf3a-93895aabae64,DISK], DatanodeInfoWithStorage[127.0.0.1:33773,DS-e35bbffa-79a1-4a9d-a417-f320f7e999ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38475,DS-16a2c56e-6929-4a2e-b685-b2715f2b404f,DISK], DatanodeInfoWithStorage[127.0.0.1:36728,DS-6bde13eb-1c1a-4831-91f0-219b45671328,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1198301738-172.17.0.18-1595817306752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35862,DS-87465b62-330f-47f6-8637-7c7a0f939492,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-e9a14ce2-9d75-4126-9950-88294b6b048b,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-dc458d57-a595-4fad-a2a0-d8e1065e14e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44550,DS-07a5284a-2c1d-4ff2-abc2-53b98b2e4630,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-d1cf4e0a-3de4-43b7-bf3a-93895aabae64,DISK], DatanodeInfoWithStorage[127.0.0.1:33773,DS-e35bbffa-79a1-4a9d-a417-f320f7e999ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38475,DS-16a2c56e-6929-4a2e-b685-b2715f2b404f,DISK], DatanodeInfoWithStorage[127.0.0.1:36728,DS-6bde13eb-1c1a-4831-91f0-219b45671328,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 1
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1194785078-172.17.0.18-1595817347829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41461,DS-78e37edb-85b6-43ce-8e03-41cc9e3f826d,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-3a63e4bd-d62d-4676-b859-bbedd54f54c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-92c6f996-d0e6-440d-8eee-95dff2213133,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-6d638aa8-3d31-4cd7-ba4b-eb62394015dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-7ac2c7d7-10f6-4e17-8c67-c89190198b65,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-929ad4e4-3e4e-4c74-b8e4-1bd48e43eee0,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-dcc445f7-db3f-4fe0-bb88-63962b98935a,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-ca445d3a-0ea2-4f01-85ef-eecd070c83b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1194785078-172.17.0.18-1595817347829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41461,DS-78e37edb-85b6-43ce-8e03-41cc9e3f826d,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-3a63e4bd-d62d-4676-b859-bbedd54f54c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-92c6f996-d0e6-440d-8eee-95dff2213133,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-6d638aa8-3d31-4cd7-ba4b-eb62394015dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-7ac2c7d7-10f6-4e17-8c67-c89190198b65,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-929ad4e4-3e4e-4c74-b8e4-1bd48e43eee0,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-dcc445f7-db3f-4fe0-bb88-63962b98935a,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-ca445d3a-0ea2-4f01-85ef-eecd070c83b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 1
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1021982786-172.17.0.18-1595817784312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38527,DS-32b141d9-116d-449a-954f-8af72cd6280a,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-b643005a-8b23-4f28-9436-36039c7b9b61,DISK], DatanodeInfoWithStorage[127.0.0.1:33121,DS-545775e7-044d-4d86-9833-6ee79175376f,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-0b14f32f-1963-41fe-81e5-072ca126ce8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-1ce14027-eed2-4b81-96c3-1ceec449a096,DISK], DatanodeInfoWithStorage[127.0.0.1:35441,DS-6727003a-bef6-4555-9ae8-198ebfc0183b,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-54240536-f1a7-4bad-b622-05b869de5c19,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-157cdf8b-b061-413e-bb6e-cb54cd53ec5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1021982786-172.17.0.18-1595817784312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38527,DS-32b141d9-116d-449a-954f-8af72cd6280a,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-b643005a-8b23-4f28-9436-36039c7b9b61,DISK], DatanodeInfoWithStorage[127.0.0.1:33121,DS-545775e7-044d-4d86-9833-6ee79175376f,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-0b14f32f-1963-41fe-81e5-072ca126ce8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-1ce14027-eed2-4b81-96c3-1ceec449a096,DISK], DatanodeInfoWithStorage[127.0.0.1:35441,DS-6727003a-bef6-4555-9ae8-198ebfc0183b,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-54240536-f1a7-4bad-b622-05b869de5c19,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-157cdf8b-b061-413e-bb6e-cb54cd53ec5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 1
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1177699606-172.17.0.18-1595817964383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39922,DS-97986281-db20-4bc3-a87c-0fa6c475cac1,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-a81a18ea-7024-4bf1-8de2-f1a13ee82fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39523,DS-c2c74ed7-f0a7-4cb9-95d1-69673c3ee57b,DISK], DatanodeInfoWithStorage[127.0.0.1:42113,DS-9dfe2b49-b959-4094-a3bc-356e9866c410,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-70289256-40ae-43f6-ac33-fd6a1946230a,DISK], DatanodeInfoWithStorage[127.0.0.1:33411,DS-562a79d2-3ad8-4659-b6dd-790539def626,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-e1038f39-f795-4e8e-92e8-057c768d0c04,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-ebe66669-4049-47b5-9893-0de55712f67a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1177699606-172.17.0.18-1595817964383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39922,DS-97986281-db20-4bc3-a87c-0fa6c475cac1,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-a81a18ea-7024-4bf1-8de2-f1a13ee82fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39523,DS-c2c74ed7-f0a7-4cb9-95d1-69673c3ee57b,DISK], DatanodeInfoWithStorage[127.0.0.1:42113,DS-9dfe2b49-b959-4094-a3bc-356e9866c410,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-70289256-40ae-43f6-ac33-fd6a1946230a,DISK], DatanodeInfoWithStorage[127.0.0.1:33411,DS-562a79d2-3ad8-4659-b6dd-790539def626,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-e1038f39-f795-4e8e-92e8-057c768d0c04,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-ebe66669-4049-47b5-9893-0de55712f67a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 1
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1708899539-172.17.0.18-1595818027402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36664,DS-2fb310af-4908-4250-8897-2c36cbb4c5ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-44003cfa-155a-40d8-acaf-cc9e6d0c61e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40022,DS-aa68f42c-08bf-4d56-833c-f83fc435d0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-30ae5366-b89f-4590-8eb6-953407197b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-2775654e-8eec-4e63-a7f6-7b75747c09cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-15ba98a3-abb9-4c12-a474-39908c272405,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-ac7a643b-088c-4377-bf34-5c57fc571b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-37b5ec1b-a8d2-40a6-b369-5388ce593118,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1708899539-172.17.0.18-1595818027402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36664,DS-2fb310af-4908-4250-8897-2c36cbb4c5ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-44003cfa-155a-40d8-acaf-cc9e6d0c61e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40022,DS-aa68f42c-08bf-4d56-833c-f83fc435d0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-30ae5366-b89f-4590-8eb6-953407197b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-2775654e-8eec-4e63-a7f6-7b75747c09cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-15ba98a3-abb9-4c12-a474-39908c272405,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-ac7a643b-088c-4377-bf34-5c57fc571b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-37b5ec1b-a8d2-40a6-b369-5388ce593118,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5320
