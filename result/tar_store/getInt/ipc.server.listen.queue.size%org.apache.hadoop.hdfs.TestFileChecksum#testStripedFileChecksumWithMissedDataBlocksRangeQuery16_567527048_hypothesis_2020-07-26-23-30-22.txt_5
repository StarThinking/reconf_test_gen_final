reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 16384
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 16384
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-670535841-172.17.0.9-1595806305338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43005,DS-155b2fdd-ce6b-446e-bd67-85357e1f7c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-4905dd3d-6dc1-4a08-8560-92bb010623e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-a54601f3-1e29-4683-9689-3a4604ac0a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-bfe94fde-9864-4531-a851-3645e283f51c,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-e57bf005-f3d0-4c3c-b2bf-614578a75d04,DISK], DatanodeInfoWithStorage[127.0.0.1:43041,DS-2d939749-e734-40d9-b2bd-12259bc610d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-aa3b9f9d-3e95-4e04-8509-28b4c06f1e10,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-fa9828d4-cf2e-42a5-a442-218ab710428b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-670535841-172.17.0.9-1595806305338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43005,DS-155b2fdd-ce6b-446e-bd67-85357e1f7c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-4905dd3d-6dc1-4a08-8560-92bb010623e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-a54601f3-1e29-4683-9689-3a4604ac0a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-bfe94fde-9864-4531-a851-3645e283f51c,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-e57bf005-f3d0-4c3c-b2bf-614578a75d04,DISK], DatanodeInfoWithStorage[127.0.0.1:43041,DS-2d939749-e734-40d9-b2bd-12259bc610d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-aa3b9f9d-3e95-4e04-8509-28b4c06f1e10,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-fa9828d4-cf2e-42a5-a442-218ab710428b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 16384
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-635626180-172.17.0.9-1595806958227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38111,DS-4beb7fc8-f3bf-4e7f-a093-87b03337014d,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-67a9474d-50b9-4166-b3ab-dfdae6d1b452,DISK], DatanodeInfoWithStorage[127.0.0.1:36457,DS-ed29c6a4-9c49-4d6c-9857-1ee882a77f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-279033cc-b171-4095-b9d7-4679e604bb25,DISK], DatanodeInfoWithStorage[127.0.0.1:46228,DS-64254f72-cf64-4c66-8520-fdc4f0530ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-c879a7a5-ea72-44e8-bdd5-a0586f0f25fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-44b32300-b643-4909-9dc6-fce083bcdb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-a188549b-68c2-449a-adbb-ddd8a416fd7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-635626180-172.17.0.9-1595806958227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38111,DS-4beb7fc8-f3bf-4e7f-a093-87b03337014d,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-67a9474d-50b9-4166-b3ab-dfdae6d1b452,DISK], DatanodeInfoWithStorage[127.0.0.1:36457,DS-ed29c6a4-9c49-4d6c-9857-1ee882a77f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-279033cc-b171-4095-b9d7-4679e604bb25,DISK], DatanodeInfoWithStorage[127.0.0.1:46228,DS-64254f72-cf64-4c66-8520-fdc4f0530ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-c879a7a5-ea72-44e8-bdd5-a0586f0f25fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-44b32300-b643-4909-9dc6-fce083bcdb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-a188549b-68c2-449a-adbb-ddd8a416fd7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 16384
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1644047801-172.17.0.9-1595808372470:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33015,DS-c4ae88ed-ec2a-4050-b369-a79f32e96ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:40038,DS-a6ed93cf-0d84-45e3-b97d-2da00f052f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-ca9002e3-1e8f-4644-9ba5-b4d30f877fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-3dc219a0-2637-4d3a-b51b-3b7ddd3d071e,DISK], DatanodeInfoWithStorage[127.0.0.1:35293,DS-e6882c09-6694-4632-b806-7769d82d1b99,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-729586ea-b81f-4347-9927-a18f1e6f1434,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-886ec18a-5dbb-4960-add9-5d0650b4fdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-54daa190-5258-499e-b8e3-5e371ded1bde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1644047801-172.17.0.9-1595808372470:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33015,DS-c4ae88ed-ec2a-4050-b369-a79f32e96ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:40038,DS-a6ed93cf-0d84-45e3-b97d-2da00f052f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-ca9002e3-1e8f-4644-9ba5-b4d30f877fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-3dc219a0-2637-4d3a-b51b-3b7ddd3d071e,DISK], DatanodeInfoWithStorage[127.0.0.1:35293,DS-e6882c09-6694-4632-b806-7769d82d1b99,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-729586ea-b81f-4347-9927-a18f1e6f1434,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-886ec18a-5dbb-4960-add9-5d0650b4fdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-54daa190-5258-499e-b8e3-5e371ded1bde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 16384
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-862390418-172.17.0.9-1595808592717:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38857,DS-6b8fee81-aae2-4db0-b1f9-56ed30ccfec4,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-d3bcbfb2-c721-40e5-946d-6af8ef1e3e72,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-9586258a-b4d4-4fe7-96fd-de3593c4b667,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-13ececa4-9896-43f5-9ac2-19f11902a90b,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-f2d8d60c-22b3-472e-84dc-5d4bb6e5c70d,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-c3d5abc4-a5ad-4511-a15d-332e934650fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46052,DS-903ba15e-7a5d-4c8c-9aab-d1f5cbb8f31e,DISK], DatanodeInfoWithStorage[127.0.0.1:33414,DS-0f5ee63e-68a8-4287-9442-de8b5911b09a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-862390418-172.17.0.9-1595808592717:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38857,DS-6b8fee81-aae2-4db0-b1f9-56ed30ccfec4,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-d3bcbfb2-c721-40e5-946d-6af8ef1e3e72,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-9586258a-b4d4-4fe7-96fd-de3593c4b667,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-13ececa4-9896-43f5-9ac2-19f11902a90b,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-f2d8d60c-22b3-472e-84dc-5d4bb6e5c70d,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-c3d5abc4-a5ad-4511-a15d-332e934650fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46052,DS-903ba15e-7a5d-4c8c-9aab-d1f5cbb8f31e,DISK], DatanodeInfoWithStorage[127.0.0.1:33414,DS-0f5ee63e-68a8-4287-9442-de8b5911b09a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 16384
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1587959325-172.17.0.9-1595809057561:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33698,DS-2fcadda1-e419-409e-a395-4318a3e418a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-d01bb322-1b88-4352-908b-39d56ec8adef,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-ed841266-03c5-4205-8c2b-8f9ede083803,DISK], DatanodeInfoWithStorage[127.0.0.1:45997,DS-b9b95306-69cb-4c14-ba81-09991f13ed5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-d681f9ac-3ed3-4e04-b79e-e537fa241b63,DISK], DatanodeInfoWithStorage[127.0.0.1:39902,DS-8c81f8a9-8527-49f6-8340-d2c7a8577f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-ce7f284a-326f-478b-aab7-ce3da79712ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-fa9e37ef-01b1-48ea-a07e-375fedd1f9b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1587959325-172.17.0.9-1595809057561:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33698,DS-2fcadda1-e419-409e-a395-4318a3e418a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-d01bb322-1b88-4352-908b-39d56ec8adef,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-ed841266-03c5-4205-8c2b-8f9ede083803,DISK], DatanodeInfoWithStorage[127.0.0.1:45997,DS-b9b95306-69cb-4c14-ba81-09991f13ed5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-d681f9ac-3ed3-4e04-b79e-e537fa241b63,DISK], DatanodeInfoWithStorage[127.0.0.1:39902,DS-8c81f8a9-8527-49f6-8340-d2c7a8577f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-ce7f284a-326f-478b-aab7-ce3da79712ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-fa9e37ef-01b1-48ea-a07e-375fedd1f9b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 16384
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-160018301-172.17.0.9-1595809273443:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44012,DS-d13269d7-aa9f-44ce-ba66-cfe94014b7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-bca5125f-4af5-4fe2-8100-5932237d409e,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-04970ff3-1d38-47d0-adba-89d9f8a431f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40311,DS-ec1c6fec-f074-42f9-a6ac-29c7d1da2bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-f63002df-ec94-4ce1-adee-4cc1b3b4e5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-9781e1cf-95a3-4d7d-b530-6af53e9ba8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36648,DS-576ff029-dc03-49dc-8049-4fc21121c4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-92c26144-daf7-4899-bf74-dc19a5f13cb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-160018301-172.17.0.9-1595809273443:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44012,DS-d13269d7-aa9f-44ce-ba66-cfe94014b7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-bca5125f-4af5-4fe2-8100-5932237d409e,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-04970ff3-1d38-47d0-adba-89d9f8a431f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40311,DS-ec1c6fec-f074-42f9-a6ac-29c7d1da2bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-f63002df-ec94-4ce1-adee-4cc1b3b4e5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-9781e1cf-95a3-4d7d-b530-6af53e9ba8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36648,DS-576ff029-dc03-49dc-8049-4fc21121c4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-92c26144-daf7-4899-bf74-dc19a5f13cb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 16384
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1018546700-172.17.0.9-1595809893533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40977,DS-789446ba-cabc-444e-9214-eaea369d6b85,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-5fea5bf9-2b3a-42d3-bae7-b86d8517840f,DISK], DatanodeInfoWithStorage[127.0.0.1:44776,DS-962bebee-ca1a-4e0d-910c-68395d53a1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-451c12a2-eb30-45ac-9fee-415cf596593c,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-d31f315f-df96-4af7-ad13-6ba48b165c12,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-bcc54941-7661-4214-81dc-32bc08c38376,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-f382ed6e-3a57-4727-87cf-dcd718297d50,DISK], DatanodeInfoWithStorage[127.0.0.1:34928,DS-4968a611-78e1-48d1-9380-62bec03706ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1018546700-172.17.0.9-1595809893533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40977,DS-789446ba-cabc-444e-9214-eaea369d6b85,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-5fea5bf9-2b3a-42d3-bae7-b86d8517840f,DISK], DatanodeInfoWithStorage[127.0.0.1:44776,DS-962bebee-ca1a-4e0d-910c-68395d53a1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-451c12a2-eb30-45ac-9fee-415cf596593c,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-d31f315f-df96-4af7-ad13-6ba48b165c12,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-bcc54941-7661-4214-81dc-32bc08c38376,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-f382ed6e-3a57-4727-87cf-dcd718297d50,DISK], DatanodeInfoWithStorage[127.0.0.1:34928,DS-4968a611-78e1-48d1-9380-62bec03706ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 16384
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1999858590-172.17.0.9-1595809932121:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35713,DS-52c1f7f4-8722-4db4-8553-f0f83a56ded3,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-ae65812b-54c2-4919-81b8-c812a6a9caba,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-b2b6f418-de3f-4081-9d7d-ddb3aee0646a,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-2ae58364-fefd-4bf2-ae88-2e968357f2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-487fa04a-0a3b-42c4-8490-b90ad7265050,DISK], DatanodeInfoWithStorage[127.0.0.1:37283,DS-ab684a87-d342-486f-92e8-ab59cb03a870,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-aa51337c-6d6d-412a-83ec-07ed4ea7e507,DISK], DatanodeInfoWithStorage[127.0.0.1:44320,DS-1a2bc883-0f52-4c50-aef6-0507bc82a97b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1999858590-172.17.0.9-1595809932121:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35713,DS-52c1f7f4-8722-4db4-8553-f0f83a56ded3,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-ae65812b-54c2-4919-81b8-c812a6a9caba,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-b2b6f418-de3f-4081-9d7d-ddb3aee0646a,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-2ae58364-fefd-4bf2-ae88-2e968357f2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-487fa04a-0a3b-42c4-8490-b90ad7265050,DISK], DatanodeInfoWithStorage[127.0.0.1:37283,DS-ab684a87-d342-486f-92e8-ab59cb03a870,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-aa51337c-6d6d-412a-83ec-07ed4ea7e507,DISK], DatanodeInfoWithStorage[127.0.0.1:44320,DS-1a2bc883-0f52-4c50-aef6-0507bc82a97b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 16384
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1780307037-172.17.0.9-1595810082855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36856,DS-2be7e2cf-e9b3-4f59-85fd-9403857a085d,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-6daa63f4-3eee-4329-b2d6-833f35e4a4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33358,DS-faab5663-0ba0-4f04-95bc-05d6069741ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-572e2a7d-6b33-4816-a934-6d326a36587a,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-7f2bc934-b493-4ff7-9abf-735310a4afb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-0c4bf88a-b91a-4bfc-8cc4-f74314b62ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-de45c688-9f2e-4012-89c6-ca741b391186,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-81a35ef2-7b45-415e-bbf9-a72f48961b08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1780307037-172.17.0.9-1595810082855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36856,DS-2be7e2cf-e9b3-4f59-85fd-9403857a085d,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-6daa63f4-3eee-4329-b2d6-833f35e4a4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33358,DS-faab5663-0ba0-4f04-95bc-05d6069741ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-572e2a7d-6b33-4816-a934-6d326a36587a,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-7f2bc934-b493-4ff7-9abf-735310a4afb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-0c4bf88a-b91a-4bfc-8cc4-f74314b62ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-de45c688-9f2e-4012-89c6-ca741b391186,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-81a35ef2-7b45-415e-bbf9-a72f48961b08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 16384
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1689932883-172.17.0.9-1595810581629:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35899,DS-64758848-b417-4a44-b3f5-e764994cc324,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-6113bf56-ceee-44a4-83f9-aa4c2755cbdd,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-af3fd695-bafd-48d6-8547-bd055e020533,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-86a61048-7c0c-4f99-830f-28b3ee5eb2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-a7fbcaae-4ee3-4d63-9f43-997b6fb8f4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-3d80764a-04d3-4cdd-ad00-0f9cc541147f,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-ed4b42a7-f65f-4a83-96c8-fd169125adec,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-ab6ad2f3-ec5e-4917-b1e4-a33e3bae11e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1689932883-172.17.0.9-1595810581629:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35899,DS-64758848-b417-4a44-b3f5-e764994cc324,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-6113bf56-ceee-44a4-83f9-aa4c2755cbdd,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-af3fd695-bafd-48d6-8547-bd055e020533,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-86a61048-7c0c-4f99-830f-28b3ee5eb2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-a7fbcaae-4ee3-4d63-9f43-997b6fb8f4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-3d80764a-04d3-4cdd-ad00-0f9cc541147f,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-ed4b42a7-f65f-4a83-96c8-fd169125adec,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-ab6ad2f3-ec5e-4917-b1e4-a33e3bae11e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 16384
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2021194815-172.17.0.9-1595811203966:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37691,DS-c195a1a8-830f-40e9-b613-025e14023362,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-7a44a44f-8eea-4d9f-ae82-fd6e9edc7a20,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-639107e8-2def-477f-a71a-0ede38e03b73,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-6202c5c2-44dc-4139-b82f-01ed5ff0ae5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-21a14f1d-294a-41b5-8db8-4be57f078a27,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-1bbc098a-6e75-424d-bea6-f6d7636704ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46234,DS-bb870e4b-0443-402d-8b1f-1d8cb705f398,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-c55b5b30-4ef0-409b-addd-8e443a3c01ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2021194815-172.17.0.9-1595811203966:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37691,DS-c195a1a8-830f-40e9-b613-025e14023362,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-7a44a44f-8eea-4d9f-ae82-fd6e9edc7a20,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-639107e8-2def-477f-a71a-0ede38e03b73,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-6202c5c2-44dc-4139-b82f-01ed5ff0ae5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-21a14f1d-294a-41b5-8db8-4be57f078a27,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-1bbc098a-6e75-424d-bea6-f6d7636704ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46234,DS-bb870e4b-0443-402d-8b1f-1d8cb705f398,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-c55b5b30-4ef0-409b-addd-8e443a3c01ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 16384
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1300142530-172.17.0.9-1595811582376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33838,DS-451990b9-0330-4364-809b-cbb330bf9f17,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-aceb682b-4fe3-4492-a8ea-c39464385f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-67e01f87-80d7-44e0-ace0-74a70aae5574,DISK], DatanodeInfoWithStorage[127.0.0.1:40102,DS-57ecb008-960a-4e7b-b407-34f1adaf0d54,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-8160ab0f-52ca-402b-851d-12203d0f1eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-8d55a4a5-5fd2-4e26-b6ab-c3e1d1c70f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39667,DS-a845e1a0-8de1-4590-b094-675eafab1608,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-a61abeeb-eb8a-4834-b4e7-3f2a7faea9e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1300142530-172.17.0.9-1595811582376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33838,DS-451990b9-0330-4364-809b-cbb330bf9f17,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-aceb682b-4fe3-4492-a8ea-c39464385f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-67e01f87-80d7-44e0-ace0-74a70aae5574,DISK], DatanodeInfoWithStorage[127.0.0.1:40102,DS-57ecb008-960a-4e7b-b407-34f1adaf0d54,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-8160ab0f-52ca-402b-851d-12203d0f1eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-8d55a4a5-5fd2-4e26-b6ab-c3e1d1c70f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39667,DS-a845e1a0-8de1-4590-b094-675eafab1608,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-a61abeeb-eb8a-4834-b4e7-3f2a7faea9e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: might be true error
Total execution time in seconds : 5380
