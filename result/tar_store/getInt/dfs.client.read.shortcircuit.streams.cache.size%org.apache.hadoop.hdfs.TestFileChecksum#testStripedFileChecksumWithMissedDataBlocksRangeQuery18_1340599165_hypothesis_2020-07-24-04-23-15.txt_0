reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-336982144-172.17.0.18-1595564609238:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43657,DS-e409c8b6-aac6-463b-917f-4bd28287559b,DISK], DatanodeInfoWithStorage[127.0.0.1:46053,DS-dbdfad6c-63cc-46db-aba0-f18f896df774,DISK], DatanodeInfoWithStorage[127.0.0.1:42416,DS-80b30739-2f87-47ef-a7fd-35a2b3d232e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-b1e30955-7779-4253-a095-9bfc2b617829,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-d683515c-6d22-47ac-9cfd-4be7a1667648,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-8d9ffd78-2827-4702-9d3a-d58f4d227064,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-1c913e53-e5bb-47a4-8779-d55df255d4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-5167f389-ea15-474b-ae1d-45c9b9fec476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-336982144-172.17.0.18-1595564609238:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43657,DS-e409c8b6-aac6-463b-917f-4bd28287559b,DISK], DatanodeInfoWithStorage[127.0.0.1:46053,DS-dbdfad6c-63cc-46db-aba0-f18f896df774,DISK], DatanodeInfoWithStorage[127.0.0.1:42416,DS-80b30739-2f87-47ef-a7fd-35a2b3d232e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-b1e30955-7779-4253-a095-9bfc2b617829,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-d683515c-6d22-47ac-9cfd-4be7a1667648,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-8d9ffd78-2827-4702-9d3a-d58f4d227064,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-1c913e53-e5bb-47a4-8779-d55df255d4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-5167f389-ea15-474b-ae1d-45c9b9fec476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-865304986-172.17.0.18-1595564671290:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35525,DS-5cd04727-280a-4220-9de4-f7347d1e31f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-01d32ae6-940f-4872-8799-3ef96e9346cf,DISK], DatanodeInfoWithStorage[127.0.0.1:32938,DS-518b7830-0641-4a40-bc4b-baab0435a412,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-1be38264-9daf-4946-b9fe-7f83b9fe5f37,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-2ddbea28-93c0-41e3-8bfc-7a6b19c92198,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-23441ca5-3d60-4300-9fff-ce378cea0252,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-4e3e8179-983d-4922-baf3-7d3f9719d414,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-a9725d8f-e4fb-43d8-90b3-e9987a728a17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-865304986-172.17.0.18-1595564671290:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35525,DS-5cd04727-280a-4220-9de4-f7347d1e31f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-01d32ae6-940f-4872-8799-3ef96e9346cf,DISK], DatanodeInfoWithStorage[127.0.0.1:32938,DS-518b7830-0641-4a40-bc4b-baab0435a412,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-1be38264-9daf-4946-b9fe-7f83b9fe5f37,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-2ddbea28-93c0-41e3-8bfc-7a6b19c92198,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-23441ca5-3d60-4300-9fff-ce378cea0252,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-4e3e8179-983d-4922-baf3-7d3f9719d414,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-a9725d8f-e4fb-43d8-90b3-e9987a728a17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1513419738-172.17.0.18-1595565176715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38828,DS-481fc256-6d5d-4759-b734-26bfae9da732,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-847d162a-6c5c-43ce-a480-fe283d7331dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-738eb799-ce78-4860-a17f-2501399d72b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-30baf717-ba42-4913-9d3b-c4c30200572a,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-9aa88912-b1dd-436a-aac6-b4c16b9c086b,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-73225823-feff-436f-a7ba-7be953820232,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-42b84a7a-0064-4866-a733-1c69b553f83c,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-a00825d4-63bb-45b5-a6ba-de37b4259d10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1513419738-172.17.0.18-1595565176715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38828,DS-481fc256-6d5d-4759-b734-26bfae9da732,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-847d162a-6c5c-43ce-a480-fe283d7331dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-738eb799-ce78-4860-a17f-2501399d72b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-30baf717-ba42-4913-9d3b-c4c30200572a,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-9aa88912-b1dd-436a-aac6-b4c16b9c086b,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-73225823-feff-436f-a7ba-7be953820232,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-42b84a7a-0064-4866-a733-1c69b553f83c,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-a00825d4-63bb-45b5-a6ba-de37b4259d10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1108160041-172.17.0.18-1595565211817:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43365,DS-217cb1f4-c0ab-454a-8271-0e87b23c2104,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-eed018bb-58a0-4fda-9c75-7c9bbe0015cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-e580532d-c107-4c41-8677-37d792edfaf5,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-221b5454-c7c0-456e-84cf-694de8c0280a,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-8a4b7439-36fa-4476-ac94-c2722c2be63d,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-7305877f-ed26-49e1-a7db-f988b14698ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45494,DS-4ba8920e-18ff-4ea3-93d1-91ad28a747c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33243,DS-7d1de5f6-6238-4f04-a886-eeef27fb896c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1108160041-172.17.0.18-1595565211817:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43365,DS-217cb1f4-c0ab-454a-8271-0e87b23c2104,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-eed018bb-58a0-4fda-9c75-7c9bbe0015cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-e580532d-c107-4c41-8677-37d792edfaf5,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-221b5454-c7c0-456e-84cf-694de8c0280a,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-8a4b7439-36fa-4476-ac94-c2722c2be63d,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-7305877f-ed26-49e1-a7db-f988b14698ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45494,DS-4ba8920e-18ff-4ea3-93d1-91ad28a747c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33243,DS-7d1de5f6-6238-4f04-a886-eeef27fb896c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-776011295-172.17.0.18-1595565745709:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36493,DS-aa4abf8e-8686-4088-b25d-587246fc6839,DISK], DatanodeInfoWithStorage[127.0.0.1:35797,DS-f70564c1-b29d-4fa8-989a-f72f836f513e,DISK], DatanodeInfoWithStorage[127.0.0.1:38054,DS-b0d4f050-1896-4c6e-a90a-d7eff2f5fce8,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-f8c31ca3-8ecb-4417-949f-d35ee21367e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-191ec08b-a81c-4d30-ba21-8e1c2fd74c84,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-47e4ee6d-1be1-4e90-bfd4-a654554f53c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-07cf3a80-c131-4e81-bb46-9c190ad49b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-82774d61-5b71-4da7-95ed-aa8bd73a80ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-776011295-172.17.0.18-1595565745709:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36493,DS-aa4abf8e-8686-4088-b25d-587246fc6839,DISK], DatanodeInfoWithStorage[127.0.0.1:35797,DS-f70564c1-b29d-4fa8-989a-f72f836f513e,DISK], DatanodeInfoWithStorage[127.0.0.1:38054,DS-b0d4f050-1896-4c6e-a90a-d7eff2f5fce8,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-f8c31ca3-8ecb-4417-949f-d35ee21367e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-191ec08b-a81c-4d30-ba21-8e1c2fd74c84,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-47e4ee6d-1be1-4e90-bfd4-a654554f53c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-07cf3a80-c131-4e81-bb46-9c190ad49b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-82774d61-5b71-4da7-95ed-aa8bd73a80ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-852452282-172.17.0.18-1595565786047:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44129,DS-fe22dbb8-dc72-429b-91c5-4817189274f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-92f715b7-731c-4972-9afd-8a5015dfef4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-61921551-55c8-4e9f-8fc6-7703016a8d91,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-6a04de27-1d50-44ac-98ed-5c7630c0687b,DISK], DatanodeInfoWithStorage[127.0.0.1:39789,DS-bf19bb26-5dbf-48a9-a8ae-be83e0b47cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-184445a2-7ed6-4b08-af42-fd061d5f4468,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-3e6d129e-8496-45f9-b37f-0db9dab0cacb,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-963131bc-6d1d-4e4e-84e0-3f08e19201cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-852452282-172.17.0.18-1595565786047:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44129,DS-fe22dbb8-dc72-429b-91c5-4817189274f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-92f715b7-731c-4972-9afd-8a5015dfef4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-61921551-55c8-4e9f-8fc6-7703016a8d91,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-6a04de27-1d50-44ac-98ed-5c7630c0687b,DISK], DatanodeInfoWithStorage[127.0.0.1:39789,DS-bf19bb26-5dbf-48a9-a8ae-be83e0b47cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-184445a2-7ed6-4b08-af42-fd061d5f4468,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-3e6d129e-8496-45f9-b37f-0db9dab0cacb,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-963131bc-6d1d-4e4e-84e0-3f08e19201cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1032415642-172.17.0.18-1595565868387:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44740,DS-ec42aba3-ac87-4094-8348-86c8f9648a58,DISK], DatanodeInfoWithStorage[127.0.0.1:46093,DS-128430fe-fbcc-4f64-9486-b7f0a3fa2a62,DISK], DatanodeInfoWithStorage[127.0.0.1:36161,DS-fb51653d-ed30-4979-b276-b447f299ec94,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-f679d90e-dd7c-4e92-961d-96fac126d254,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-913c1f01-8fb7-47b8-a529-8345bfc55339,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-198a2a5e-46e2-4120-a5ff-7757a2cd8723,DISK], DatanodeInfoWithStorage[127.0.0.1:43454,DS-931221af-ae7c-4b8a-a29a-682655d68c24,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-78ea8c35-712c-4269-b553-0df3881878cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1032415642-172.17.0.18-1595565868387:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44740,DS-ec42aba3-ac87-4094-8348-86c8f9648a58,DISK], DatanodeInfoWithStorage[127.0.0.1:46093,DS-128430fe-fbcc-4f64-9486-b7f0a3fa2a62,DISK], DatanodeInfoWithStorage[127.0.0.1:36161,DS-fb51653d-ed30-4979-b276-b447f299ec94,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-f679d90e-dd7c-4e92-961d-96fac126d254,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-913c1f01-8fb7-47b8-a529-8345bfc55339,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-198a2a5e-46e2-4120-a5ff-7757a2cd8723,DISK], DatanodeInfoWithStorage[127.0.0.1:43454,DS-931221af-ae7c-4b8a-a29a-682655d68c24,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-78ea8c35-712c-4269-b553-0df3881878cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1764194283-172.17.0.18-1595565975922:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40653,DS-537c5f1c-1fe5-4a1b-bc3a-f755e77db6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-5650688b-960e-4068-b850-c19769184a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-6ac320da-ff12-4e5b-8da7-d9ec592afaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:39219,DS-c5a7c622-c28c-41b5-9e07-f0e34392c4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-66d725ae-f9d4-454e-b0db-44e48da328c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-2341ab81-fdd0-4756-9ee4-cdffba348173,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-8457aa83-5eb8-4bb4-861a-0e4f9210b083,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-dda858f0-b09b-4299-b8e1-e3144596e8e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1764194283-172.17.0.18-1595565975922:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40653,DS-537c5f1c-1fe5-4a1b-bc3a-f755e77db6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-5650688b-960e-4068-b850-c19769184a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-6ac320da-ff12-4e5b-8da7-d9ec592afaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:39219,DS-c5a7c622-c28c-41b5-9e07-f0e34392c4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-66d725ae-f9d4-454e-b0db-44e48da328c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-2341ab81-fdd0-4756-9ee4-cdffba348173,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-8457aa83-5eb8-4bb4-861a-0e4f9210b083,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-dda858f0-b09b-4299-b8e1-e3144596e8e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1861917728-172.17.0.18-1595566241820:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37786,DS-3ed72d4a-492c-42f7-ade1-773d3ae45851,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-c3e56b24-23a2-4736-b5fe-89840cd5dd54,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-c7e8af6a-babc-40c6-9952-9c295796f8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-0538c9eb-80e8-4f8b-8d7f-cef169a1d7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-9a162922-b4ef-4a6c-b4b5-4d48e92f7a05,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-b234d2ee-507c-4408-acda-37d605ce3eee,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-82482d70-84b8-4f0c-ba8e-2b59f61809bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-f0d1a619-36aa-42b0-9d42-a39fab507806,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1861917728-172.17.0.18-1595566241820:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37786,DS-3ed72d4a-492c-42f7-ade1-773d3ae45851,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-c3e56b24-23a2-4736-b5fe-89840cd5dd54,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-c7e8af6a-babc-40c6-9952-9c295796f8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-0538c9eb-80e8-4f8b-8d7f-cef169a1d7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-9a162922-b4ef-4a6c-b4b5-4d48e92f7a05,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-b234d2ee-507c-4408-acda-37d605ce3eee,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-82482d70-84b8-4f0c-ba8e-2b59f61809bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-f0d1a619-36aa-42b0-9d42-a39fab507806,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-990807691-172.17.0.18-1595566836225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38556,DS-3271e3ac-a069-4660-bd2c-d5e3e2c8cd72,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-bc4260aa-7bdf-4849-a48a-5719b7ea55d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-b8bd5c1a-071c-45eb-b6fa-36607c43fafd,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-0d621cbc-ece7-480f-a21a-a840f8340808,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-bd7e9f8e-7df2-446d-a1a6-19632e6494ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41545,DS-7ba46f53-a53b-4e34-b7c3-f532d8e5564f,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-f34f77cd-7ed4-4010-8c27-e58df401a586,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-ea036fc7-fef2-40f2-a4a2-945c324a69c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-990807691-172.17.0.18-1595566836225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38556,DS-3271e3ac-a069-4660-bd2c-d5e3e2c8cd72,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-bc4260aa-7bdf-4849-a48a-5719b7ea55d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-b8bd5c1a-071c-45eb-b6fa-36607c43fafd,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-0d621cbc-ece7-480f-a21a-a840f8340808,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-bd7e9f8e-7df2-446d-a1a6-19632e6494ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41545,DS-7ba46f53-a53b-4e34-b7c3-f532d8e5564f,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-f34f77cd-7ed4-4010-8c27-e58df401a586,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-ea036fc7-fef2-40f2-a4a2-945c324a69c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-475862016-172.17.0.18-1595566875389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35490,DS-1f294073-e470-4ec5-850d-107e4c785866,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-db10cb56-8353-4cf6-92c4-fdecddb88cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-dc5cbeb8-ce8e-412d-b6fc-155673f19796,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-1b807543-a2a7-401d-890f-df56fd35934a,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-d2e4c382-c729-456c-928a-95434a660b30,DISK], DatanodeInfoWithStorage[127.0.0.1:42215,DS-8c36fbd1-c0a8-432f-895d-41321a99cdd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-f62cbd84-4c88-4b9a-b2fc-ca7a9b926f58,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-0534c671-efde-46d1-b15f-38223c307b44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-475862016-172.17.0.18-1595566875389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35490,DS-1f294073-e470-4ec5-850d-107e4c785866,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-db10cb56-8353-4cf6-92c4-fdecddb88cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-dc5cbeb8-ce8e-412d-b6fc-155673f19796,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-1b807543-a2a7-401d-890f-df56fd35934a,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-d2e4c382-c729-456c-928a-95434a660b30,DISK], DatanodeInfoWithStorage[127.0.0.1:42215,DS-8c36fbd1-c0a8-432f-895d-41321a99cdd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-f62cbd84-4c88-4b9a-b2fc-ca7a9b926f58,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-0534c671-efde-46d1-b15f-38223c307b44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-727358551-172.17.0.18-1595567328357:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33185,DS-aa9a4baf-fefa-4154-a315-d83dfc73b96f,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-28ab93f1-edc0-49d4-ac6e-7c2c7a44d3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-1605ca15-e67e-41f1-9979-af40b28ae6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-fc8dd377-4131-4d31-9126-51f7703453c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-324c5a4e-70ad-467f-a7cd-27bbb3d30d44,DISK], DatanodeInfoWithStorage[127.0.0.1:43134,DS-25e62d4a-9ec9-4e78-8985-ae6de76057dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45605,DS-eded3540-52dc-4400-be49-975e598da54c,DISK], DatanodeInfoWithStorage[127.0.0.1:34925,DS-d77033b2-4ac9-4020-a0bf-819532d6dcab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-727358551-172.17.0.18-1595567328357:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33185,DS-aa9a4baf-fefa-4154-a315-d83dfc73b96f,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-28ab93f1-edc0-49d4-ac6e-7c2c7a44d3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-1605ca15-e67e-41f1-9979-af40b28ae6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-fc8dd377-4131-4d31-9126-51f7703453c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-324c5a4e-70ad-467f-a7cd-27bbb3d30d44,DISK], DatanodeInfoWithStorage[127.0.0.1:43134,DS-25e62d4a-9ec9-4e78-8985-ae6de76057dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45605,DS-eded3540-52dc-4400-be49-975e598da54c,DISK], DatanodeInfoWithStorage[127.0.0.1:34925,DS-d77033b2-4ac9-4020-a0bf-819532d6dcab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1057067287-172.17.0.18-1595568116939:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38236,DS-518aec29-8fcc-4160-afa3-c3f6f845b79d,DISK], DatanodeInfoWithStorage[127.0.0.1:35751,DS-aa0cf130-778f-4fa3-a5f7-511b2124e711,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-cb024d17-15d9-4cad-95f9-a2f932df1264,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-a6893832-7c6d-4ac0-81f9-7850b552c44d,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-1c7c1edd-1bc3-4924-a5da-215875e0b222,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-e5877f80-75b4-4b37-862e-55892fe4fa02,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-45d934c8-656a-4421-80d2-01a44b4281df,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-7c089b36-319e-4827-95ec-18671b17aa11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1057067287-172.17.0.18-1595568116939:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38236,DS-518aec29-8fcc-4160-afa3-c3f6f845b79d,DISK], DatanodeInfoWithStorage[127.0.0.1:35751,DS-aa0cf130-778f-4fa3-a5f7-511b2124e711,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-cb024d17-15d9-4cad-95f9-a2f932df1264,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-a6893832-7c6d-4ac0-81f9-7850b552c44d,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-1c7c1edd-1bc3-4924-a5da-215875e0b222,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-e5877f80-75b4-4b37-862e-55892fe4fa02,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-45d934c8-656a-4421-80d2-01a44b4281df,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-7c089b36-319e-4827-95ec-18671b17aa11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-697650107-172.17.0.18-1595568190749:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33128,DS-964e360c-122a-4517-87cd-602fc6267ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:46396,DS-e217b7c7-67cf-406e-8749-ae987bf8c71f,DISK], DatanodeInfoWithStorage[127.0.0.1:37595,DS-17fea8c3-6f31-4300-a628-c23873e01d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-be3a7453-51e4-4ddf-bf9c-54a19ccc5bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-a5f6ed3f-ef43-4c4c-96e6-b9b67a03006c,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-81fcee81-111e-4e20-b95f-eac41e08349d,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-bcc50ac0-1db3-4752-88c4-738abfbcf357,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-681e46ad-8911-4c8c-a76f-31dda14a1c5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-697650107-172.17.0.18-1595568190749:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33128,DS-964e360c-122a-4517-87cd-602fc6267ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:46396,DS-e217b7c7-67cf-406e-8749-ae987bf8c71f,DISK], DatanodeInfoWithStorage[127.0.0.1:37595,DS-17fea8c3-6f31-4300-a628-c23873e01d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-be3a7453-51e4-4ddf-bf9c-54a19ccc5bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-a5f6ed3f-ef43-4c4c-96e6-b9b67a03006c,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-81fcee81-111e-4e20-b95f-eac41e08349d,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-bcc50ac0-1db3-4752-88c4-738abfbcf357,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-681e46ad-8911-4c8c-a76f-31dda14a1c5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1965514634-172.17.0.18-1595568231545:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43267,DS-7836a7ec-3800-4564-91c3-cbd9df965e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-c262eecf-a483-4726-ba91-913093303c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34863,DS-ecb74ccb-a44b-48e7-95d1-4bdf70a29570,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-d07e2368-c492-4378-a780-66e002f2dda2,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-5728bbdc-f6e3-43a4-b068-d9a649c68b13,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-4459c777-a039-491c-8df3-d5bd5c279029,DISK], DatanodeInfoWithStorage[127.0.0.1:37766,DS-e96c2ced-4519-466d-a508-285a2e6b8abe,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-13b9318b-b896-4309-9223-fc30f3aa922c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1965514634-172.17.0.18-1595568231545:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43267,DS-7836a7ec-3800-4564-91c3-cbd9df965e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-c262eecf-a483-4726-ba91-913093303c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34863,DS-ecb74ccb-a44b-48e7-95d1-4bdf70a29570,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-d07e2368-c492-4378-a780-66e002f2dda2,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-5728bbdc-f6e3-43a4-b068-d9a649c68b13,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-4459c777-a039-491c-8df3-d5bd5c279029,DISK], DatanodeInfoWithStorage[127.0.0.1:37766,DS-e96c2ced-4519-466d-a508-285a2e6b8abe,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-13b9318b-b896-4309-9223-fc30f3aa922c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-940375121-172.17.0.18-1595568543056:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37160,DS-43437acf-e431-4c92-a520-7e05f207e42b,DISK], DatanodeInfoWithStorage[127.0.0.1:43355,DS-82ec657c-f3cf-474c-ad20-5ccc503eb81b,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-bf836f62-9040-498b-8811-8cec6c5642b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38130,DS-82efd97c-8993-41d9-8cd8-a2f75da0a9db,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-65eb5590-32ef-4b92-9a59-5ef2356370ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-a564de84-6dbe-43b7-a42f-150c5f1d576d,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-f302f3ef-93b9-4142-8911-2b443bc7fc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-59515981-dd4b-4f66-98c1-b14d66b70fe7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-940375121-172.17.0.18-1595568543056:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37160,DS-43437acf-e431-4c92-a520-7e05f207e42b,DISK], DatanodeInfoWithStorage[127.0.0.1:43355,DS-82ec657c-f3cf-474c-ad20-5ccc503eb81b,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-bf836f62-9040-498b-8811-8cec6c5642b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38130,DS-82efd97c-8993-41d9-8cd8-a2f75da0a9db,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-65eb5590-32ef-4b92-9a59-5ef2356370ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-a564de84-6dbe-43b7-a42f-150c5f1d576d,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-f302f3ef-93b9-4142-8911-2b443bc7fc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-59515981-dd4b-4f66-98c1-b14d66b70fe7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-930929647-172.17.0.18-1595568656462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34185,DS-34f60f68-ec7a-4d08-b92d-ae236e700742,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-79925fac-a851-4bad-a23c-74ebd6d3dc26,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-ae19d558-0d80-499d-bb56-5864126e2fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-6ac8f6fa-c0a5-4344-bff3-7272f88e76da,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-a7d6c32a-fe89-460d-b0fa-81cab8b3efe4,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-1aab7bff-d8b0-4c3e-9978-b0f372e1af65,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-d8f9227c-21ec-4ff6-bd57-97f67cff7c39,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-6f6c40e3-7f65-424c-812c-e395caf06cdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-930929647-172.17.0.18-1595568656462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34185,DS-34f60f68-ec7a-4d08-b92d-ae236e700742,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-79925fac-a851-4bad-a23c-74ebd6d3dc26,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-ae19d558-0d80-499d-bb56-5864126e2fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-6ac8f6fa-c0a5-4344-bff3-7272f88e76da,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-a7d6c32a-fe89-460d-b0fa-81cab8b3efe4,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-1aab7bff-d8b0-4c3e-9978-b0f372e1af65,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-d8f9227c-21ec-4ff6-bd57-97f67cff7c39,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-6f6c40e3-7f65-424c-812c-e395caf06cdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-617084334-172.17.0.18-1595568837720:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36258,DS-71c5114e-db2d-4392-8c18-d0e280b304b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-d3540532-9958-4353-ac19-877e78a285d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-f85dc655-7ae7-4aca-bc1f-4805aae15dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-70a1c54c-9968-4360-a56f-ddf50b423a20,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-c96aabc7-c2eb-43d7-81cf-4dda03fa6c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-6ae5bbd3-7b80-4eb7-a4e8-670adf9d6fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:46264,DS-2ee142a3-29a4-4960-9923-8a4af034bf47,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-237a7c98-c565-46e6-9228-372a968d40d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-617084334-172.17.0.18-1595568837720:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36258,DS-71c5114e-db2d-4392-8c18-d0e280b304b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-d3540532-9958-4353-ac19-877e78a285d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-f85dc655-7ae7-4aca-bc1f-4805aae15dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-70a1c54c-9968-4360-a56f-ddf50b423a20,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-c96aabc7-c2eb-43d7-81cf-4dda03fa6c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-6ae5bbd3-7b80-4eb7-a4e8-670adf9d6fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:46264,DS-2ee142a3-29a4-4960-9923-8a4af034bf47,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-237a7c98-c565-46e6-9228-372a968d40d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-289787409-172.17.0.18-1595568949693:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37065,DS-0094567f-b176-462a-b466-c547280c5644,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-d240349b-a5a8-4b86-a816-d77ce255724e,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-62ff417f-8fc2-4721-ba0b-bca0acd9335e,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-8511dd03-54b0-495d-a2bd-519a4ea756ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-5e4d5099-60a6-43eb-bb54-c585991cc130,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-d6a56464-e73d-459d-ba04-2ed19360c1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-c8c8f56c-adc3-4adf-b812-321b6e2c4280,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-d4b6dc30-e070-4af7-8703-0991fcedb037,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-289787409-172.17.0.18-1595568949693:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37065,DS-0094567f-b176-462a-b466-c547280c5644,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-d240349b-a5a8-4b86-a816-d77ce255724e,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-62ff417f-8fc2-4721-ba0b-bca0acd9335e,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-8511dd03-54b0-495d-a2bd-519a4ea756ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-5e4d5099-60a6-43eb-bb54-c585991cc130,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-d6a56464-e73d-459d-ba04-2ed19360c1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-c8c8f56c-adc3-4adf-b812-321b6e2c4280,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-d4b6dc30-e070-4af7-8703-0991fcedb037,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-710128487-172.17.0.18-1595569485380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39239,DS-bd8d76e4-9c15-45c2-8af1-53f2c47f5cae,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-6a65c28c-f5b7-4278-a463-8be6c1af6bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-e7531187-3ad6-42da-bfe2-3bb7329c19ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35295,DS-5f2934a7-fa66-4d37-ab45-327a81123606,DISK], DatanodeInfoWithStorage[127.0.0.1:39227,DS-37105a0b-62ea-4b2b-bcb8-4b19a6cc651e,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-75b9e90e-e7a4-4d7f-a261-26290562aa85,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-32d82176-38e3-4e92-bbd4-5e6315878337,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-c5c57374-1319-46d9-9cce-65a8944e273b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-710128487-172.17.0.18-1595569485380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39239,DS-bd8d76e4-9c15-45c2-8af1-53f2c47f5cae,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-6a65c28c-f5b7-4278-a463-8be6c1af6bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-e7531187-3ad6-42da-bfe2-3bb7329c19ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35295,DS-5f2934a7-fa66-4d37-ab45-327a81123606,DISK], DatanodeInfoWithStorage[127.0.0.1:39227,DS-37105a0b-62ea-4b2b-bcb8-4b19a6cc651e,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-75b9e90e-e7a4-4d7f-a261-26290562aa85,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-32d82176-38e3-4e92-bbd4-5e6315878337,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-c5c57374-1319-46d9-9cce-65a8944e273b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-43938720-172.17.0.18-1595569947989:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44982,DS-6b8ebad7-a4f5-4c7f-aedd-17ff73f4e692,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-6a399fdf-a07b-4aee-a2f0-e914e1d8ed99,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-e99d4112-ce8b-4f15-829e-4739966447b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-6a6bd616-6273-4f96-816f-d82befe20284,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-a0e4d2c3-e177-4a04-980b-9282f5fbc281,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-d51d875c-c077-489f-96f3-00095cd49d72,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-1de9968c-0e69-4040-b090-ec164f84b90d,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-1292f3fd-2a33-48c2-ae9b-078d0b21f01b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-43938720-172.17.0.18-1595569947989:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44982,DS-6b8ebad7-a4f5-4c7f-aedd-17ff73f4e692,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-6a399fdf-a07b-4aee-a2f0-e914e1d8ed99,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-e99d4112-ce8b-4f15-829e-4739966447b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-6a6bd616-6273-4f96-816f-d82befe20284,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-a0e4d2c3-e177-4a04-980b-9282f5fbc281,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-d51d875c-c077-489f-96f3-00095cd49d72,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-1de9968c-0e69-4040-b090-ec164f84b90d,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-1292f3fd-2a33-48c2-ae9b-078d0b21f01b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5526
