reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1610066214-172.17.0.20-1595593016768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40849,DS-fe647787-6671-457e-85d2-284eadf7c633,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-a60c085c-38eb-45bd-9f31-33bebe63c9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-8ad45e20-91b0-4617-a3bc-81e7a81068d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-5c0d1c42-b38e-4a8d-b266-2d8bb3cf43a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33359,DS-d145f743-43de-4d14-9c4c-bb5c0cac17b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-3cdbb051-8e45-4e88-ae81-972cc773605a,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-3bb5ada3-3287-4993-bbcf-d323d6ff0872,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-f4a21c87-ecd2-4da3-9170-6135bc2f2a87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1610066214-172.17.0.20-1595593016768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40849,DS-fe647787-6671-457e-85d2-284eadf7c633,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-a60c085c-38eb-45bd-9f31-33bebe63c9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-8ad45e20-91b0-4617-a3bc-81e7a81068d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-5c0d1c42-b38e-4a8d-b266-2d8bb3cf43a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33359,DS-d145f743-43de-4d14-9c4c-bb5c0cac17b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-3cdbb051-8e45-4e88-ae81-972cc773605a,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-3bb5ada3-3287-4993-bbcf-d323d6ff0872,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-f4a21c87-ecd2-4da3-9170-6135bc2f2a87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950271134-172.17.0.20-1595593300929:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43641,DS-29dfaeb7-5ed5-4648-a69f-51ceae13e8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-ec73535c-bda1-4e32-85f0-3887ed885203,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-f32dacf9-0d65-41b0-adf9-900d7b1d23ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-0f2d9f4e-13ec-4f2c-a245-36631ab39f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-2fee210f-5d91-4346-abed-96fa711dc32f,DISK], DatanodeInfoWithStorage[127.0.0.1:39900,DS-085f9ced-3ffe-4a93-9f74-48dcadcf1f52,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-45b12701-b789-4488-b258-8bac1c4f85f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-45d86e03-e904-4b66-8398-73e7509fce5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950271134-172.17.0.20-1595593300929:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43641,DS-29dfaeb7-5ed5-4648-a69f-51ceae13e8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-ec73535c-bda1-4e32-85f0-3887ed885203,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-f32dacf9-0d65-41b0-adf9-900d7b1d23ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-0f2d9f4e-13ec-4f2c-a245-36631ab39f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-2fee210f-5d91-4346-abed-96fa711dc32f,DISK], DatanodeInfoWithStorage[127.0.0.1:39900,DS-085f9ced-3ffe-4a93-9f74-48dcadcf1f52,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-45b12701-b789-4488-b258-8bac1c4f85f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-45d86e03-e904-4b66-8398-73e7509fce5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870887421-172.17.0.20-1595593769028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35784,DS-33c933a3-872c-469c-a588-7dab11ecf62d,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-d3f440ee-c95b-43fd-ba52-74ad3c8d0c63,DISK], DatanodeInfoWithStorage[127.0.0.1:37967,DS-375e42a2-b0fc-49c8-91a6-12030e0722ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-1f8d0039-fbb5-4422-a756-0f285e0de204,DISK], DatanodeInfoWithStorage[127.0.0.1:39809,DS-23958104-89ee-43fe-8508-83c1a4101cca,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-a0bf3e6f-a1f5-43b9-9698-0cb3c751f144,DISK], DatanodeInfoWithStorage[127.0.0.1:43593,DS-723be8b6-ef2c-40a8-b293-452d8a032e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41297,DS-8e5373a8-02b2-48ba-9b88-92f9d5c9cc9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870887421-172.17.0.20-1595593769028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35784,DS-33c933a3-872c-469c-a588-7dab11ecf62d,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-d3f440ee-c95b-43fd-ba52-74ad3c8d0c63,DISK], DatanodeInfoWithStorage[127.0.0.1:37967,DS-375e42a2-b0fc-49c8-91a6-12030e0722ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-1f8d0039-fbb5-4422-a756-0f285e0de204,DISK], DatanodeInfoWithStorage[127.0.0.1:39809,DS-23958104-89ee-43fe-8508-83c1a4101cca,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-a0bf3e6f-a1f5-43b9-9698-0cb3c751f144,DISK], DatanodeInfoWithStorage[127.0.0.1:43593,DS-723be8b6-ef2c-40a8-b293-452d8a032e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41297,DS-8e5373a8-02b2-48ba-9b88-92f9d5c9cc9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-350210011-172.17.0.20-1595593972283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35032,DS-cc914d26-6c01-46ad-b48a-b7622936f09f,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-974cd857-31fb-4f3f-8585-ff687db74fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45754,DS-4026b091-b7a6-4f7d-9aea-c9ba2b8bbc82,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-f7488036-151e-4606-86b6-c1f7699d0dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-1702fb16-8806-4a1f-882c-fb38d2227510,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-55d88965-b0e9-42f4-adde-a7fbd731e32a,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-e6b32bf5-4053-4064-8658-0203740dd98e,DISK], DatanodeInfoWithStorage[127.0.0.1:37011,DS-23c98ac3-2e09-4b36-8321-5b27b4917ab8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-350210011-172.17.0.20-1595593972283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35032,DS-cc914d26-6c01-46ad-b48a-b7622936f09f,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-974cd857-31fb-4f3f-8585-ff687db74fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45754,DS-4026b091-b7a6-4f7d-9aea-c9ba2b8bbc82,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-f7488036-151e-4606-86b6-c1f7699d0dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-1702fb16-8806-4a1f-882c-fb38d2227510,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-55d88965-b0e9-42f4-adde-a7fbd731e32a,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-e6b32bf5-4053-4064-8658-0203740dd98e,DISK], DatanodeInfoWithStorage[127.0.0.1:37011,DS-23c98ac3-2e09-4b36-8321-5b27b4917ab8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1051563738-172.17.0.20-1595594010979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42323,DS-1ed5c914-0b53-4736-a565-79721b5e3c91,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-9133d4e6-c5f5-4a0e-9160-ee9e42076972,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-de4a94db-94ef-4cd5-833b-4fd8ddca2f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-92f5a467-3cd5-46ab-aa62-5ff878164f97,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-9490c7d1-5e6b-491f-951f-bf66bc5ad2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-13590df6-22f4-40b0-8818-585ae2a65dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-5887d56e-baaa-4ead-a5ff-8359d06d542b,DISK], DatanodeInfoWithStorage[127.0.0.1:40436,DS-edbfe569-79a8-420f-8d82-340e5aee62ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1051563738-172.17.0.20-1595594010979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42323,DS-1ed5c914-0b53-4736-a565-79721b5e3c91,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-9133d4e6-c5f5-4a0e-9160-ee9e42076972,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-de4a94db-94ef-4cd5-833b-4fd8ddca2f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-92f5a467-3cd5-46ab-aa62-5ff878164f97,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-9490c7d1-5e6b-491f-951f-bf66bc5ad2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-13590df6-22f4-40b0-8818-585ae2a65dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-5887d56e-baaa-4ead-a5ff-8359d06d542b,DISK], DatanodeInfoWithStorage[127.0.0.1:40436,DS-edbfe569-79a8-420f-8d82-340e5aee62ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1489889470-172.17.0.20-1595594565508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37702,DS-7563acd6-aa9e-4a1a-87e4-ed868540b912,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-b285d26c-913c-4133-ad8e-9d5f2b164e47,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-7f83b17c-dfe5-4fca-bbeb-0883d4d28436,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-867e58dd-abb6-47a4-bdb2-abc5692e63ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-badd3f06-286f-48b0-b100-0482354f343c,DISK], DatanodeInfoWithStorage[127.0.0.1:42777,DS-0a8d05be-7f0d-4bd7-9dbb-7d5235446610,DISK], DatanodeInfoWithStorage[127.0.0.1:43317,DS-a05f633c-3fef-410b-8b3f-48253833ed57,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-68ea0373-bd96-4d64-9c57-ccd1cb2316f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1489889470-172.17.0.20-1595594565508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37702,DS-7563acd6-aa9e-4a1a-87e4-ed868540b912,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-b285d26c-913c-4133-ad8e-9d5f2b164e47,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-7f83b17c-dfe5-4fca-bbeb-0883d4d28436,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-867e58dd-abb6-47a4-bdb2-abc5692e63ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-badd3f06-286f-48b0-b100-0482354f343c,DISK], DatanodeInfoWithStorage[127.0.0.1:42777,DS-0a8d05be-7f0d-4bd7-9dbb-7d5235446610,DISK], DatanodeInfoWithStorage[127.0.0.1:43317,DS-a05f633c-3fef-410b-8b3f-48253833ed57,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-68ea0373-bd96-4d64-9c57-ccd1cb2316f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-232104991-172.17.0.20-1595594675021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40322,DS-b422400d-4203-46e3-8f48-b7316ca822a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-5056937b-817a-4b02-9b26-fac6f474a9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40397,DS-c5e4f3a1-69ea-470b-b52f-ed9ed3e55abf,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-e1124903-3f76-4f3e-bb7f-310980bb5e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35553,DS-501e50a4-1030-4d6a-8638-3e2ed7b206ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40865,DS-59083818-8141-4e4f-8332-2045d6bd7b78,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-77b3008e-3d1e-4290-89ba-ea7139ef7b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-bba2c2d1-c414-4dcf-a12c-312b6a2374a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-232104991-172.17.0.20-1595594675021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40322,DS-b422400d-4203-46e3-8f48-b7316ca822a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-5056937b-817a-4b02-9b26-fac6f474a9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40397,DS-c5e4f3a1-69ea-470b-b52f-ed9ed3e55abf,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-e1124903-3f76-4f3e-bb7f-310980bb5e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35553,DS-501e50a4-1030-4d6a-8638-3e2ed7b206ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40865,DS-59083818-8141-4e4f-8332-2045d6bd7b78,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-77b3008e-3d1e-4290-89ba-ea7139ef7b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-bba2c2d1-c414-4dcf-a12c-312b6a2374a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1614349927-172.17.0.20-1595594749301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43348,DS-fe0542c0-25a4-4f51-b0d7-7dc75f77e2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-2e38b500-b6be-4b22-a6b6-f3acbc020422,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-89a17659-ef23-454c-b015-499aaa6bc484,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-78f2bc26-f520-47d8-b21a-6718e8c9aecb,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-84ddf273-a0ef-4352-9337-dc7f2287952e,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-6fe0775a-ee09-4bdb-92a8-ad69cc90de00,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-84c29ca6-3456-4d0d-a8ac-5ffe2a196f75,DISK], DatanodeInfoWithStorage[127.0.0.1:40856,DS-f3839323-6501-447d-9cd9-4a24ec4ebde2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1614349927-172.17.0.20-1595594749301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43348,DS-fe0542c0-25a4-4f51-b0d7-7dc75f77e2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-2e38b500-b6be-4b22-a6b6-f3acbc020422,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-89a17659-ef23-454c-b015-499aaa6bc484,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-78f2bc26-f520-47d8-b21a-6718e8c9aecb,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-84ddf273-a0ef-4352-9337-dc7f2287952e,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-6fe0775a-ee09-4bdb-92a8-ad69cc90de00,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-84c29ca6-3456-4d0d-a8ac-5ffe2a196f75,DISK], DatanodeInfoWithStorage[127.0.0.1:40856,DS-f3839323-6501-447d-9cd9-4a24ec4ebde2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1445240820-172.17.0.20-1595594999032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45190,DS-55fe75be-7785-406b-8a2d-766ea29b7f73,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-141f04f4-afe5-4ef5-93fc-58cde222c117,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-93473a58-d5c3-443c-a841-4952ca20a586,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-efd53ca2-c184-4d54-8969-bfa6318ba0db,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-0d7082a6-f1b5-4585-bde3-3fe77c46bedb,DISK], DatanodeInfoWithStorage[127.0.0.1:39507,DS-fab924fb-cad9-4809-b750-99dba8f81086,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-4d9297f7-7f7b-4ed4-9111-53d334f2e14b,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-7900d8d9-9c03-4847-aa26-d8f9323961da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1445240820-172.17.0.20-1595594999032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45190,DS-55fe75be-7785-406b-8a2d-766ea29b7f73,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-141f04f4-afe5-4ef5-93fc-58cde222c117,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-93473a58-d5c3-443c-a841-4952ca20a586,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-efd53ca2-c184-4d54-8969-bfa6318ba0db,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-0d7082a6-f1b5-4585-bde3-3fe77c46bedb,DISK], DatanodeInfoWithStorage[127.0.0.1:39507,DS-fab924fb-cad9-4809-b750-99dba8f81086,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-4d9297f7-7f7b-4ed4-9111-53d334f2e14b,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-7900d8d9-9c03-4847-aa26-d8f9323961da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-835626609-172.17.0.20-1595595256887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34769,DS-6931506f-b198-4760-806e-90ca8d09ec16,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-d8ea5a30-8d67-45d8-8de6-b1630e0b21e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-f6c1580a-05c2-47bf-a769-28b0086d5872,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-4dd78439-e9d0-451d-9930-686ee5c5779a,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-deefbfa4-bcf4-423f-97ba-b32e11fdcd87,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-3a4c0c99-c28a-4a12-ac9f-082c1e655ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-5a48a382-43ec-4fd4-ac4f-310f26317be5,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-c24f5fd9-590c-4bd0-937d-b6ef3c88da5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-835626609-172.17.0.20-1595595256887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34769,DS-6931506f-b198-4760-806e-90ca8d09ec16,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-d8ea5a30-8d67-45d8-8de6-b1630e0b21e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-f6c1580a-05c2-47bf-a769-28b0086d5872,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-4dd78439-e9d0-451d-9930-686ee5c5779a,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-deefbfa4-bcf4-423f-97ba-b32e11fdcd87,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-3a4c0c99-c28a-4a12-ac9f-082c1e655ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-5a48a382-43ec-4fd4-ac4f-310f26317be5,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-c24f5fd9-590c-4bd0-937d-b6ef3c88da5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-759540701-172.17.0.20-1595595555999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36381,DS-143d2f71-dd84-4d6f-9b64-1b89c16f9867,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-0caa7ade-6078-49d6-81a7-559f653eb1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-dda169fc-5d41-4b8d-b0a5-ff365c2e1a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-dda55eda-5e63-44dc-a640-c716f220076a,DISK], DatanodeInfoWithStorage[127.0.0.1:38907,DS-0f4fddd5-9a43-4707-90ec-315e0a61bb83,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-56d93a55-1401-4aca-a626-4a31c56005cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40320,DS-a22f8104-9261-4e46-8ed6-2118f536014b,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-b478defa-6118-45d0-b7d1-3953fb76a0c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-759540701-172.17.0.20-1595595555999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36381,DS-143d2f71-dd84-4d6f-9b64-1b89c16f9867,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-0caa7ade-6078-49d6-81a7-559f653eb1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-dda169fc-5d41-4b8d-b0a5-ff365c2e1a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-dda55eda-5e63-44dc-a640-c716f220076a,DISK], DatanodeInfoWithStorage[127.0.0.1:38907,DS-0f4fddd5-9a43-4707-90ec-315e0a61bb83,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-56d93a55-1401-4aca-a626-4a31c56005cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40320,DS-a22f8104-9261-4e46-8ed6-2118f536014b,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-b478defa-6118-45d0-b7d1-3953fb76a0c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-275722921-172.17.0.20-1595595731307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42454,DS-9cbd5dde-8a65-4625-9cfb-4a8cf231b55b,DISK], DatanodeInfoWithStorage[127.0.0.1:36913,DS-efbb411d-0425-47c9-ab48-9ab6a9cff762,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-abfd40ed-4e3b-45e3-b64a-a0dc3856ed5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-df29a751-c170-4096-a876-e536b983ccb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-fb18bc7c-23f8-453b-9972-f2700ce4102f,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-fb7a76c7-d7c8-4a1c-b8db-d96abd4cd6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42665,DS-745639f6-6c55-4b1d-9d8a-16612aab1a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44802,DS-def1bf43-9ae4-44e2-b4e6-e245770b465b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-275722921-172.17.0.20-1595595731307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42454,DS-9cbd5dde-8a65-4625-9cfb-4a8cf231b55b,DISK], DatanodeInfoWithStorage[127.0.0.1:36913,DS-efbb411d-0425-47c9-ab48-9ab6a9cff762,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-abfd40ed-4e3b-45e3-b64a-a0dc3856ed5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-df29a751-c170-4096-a876-e536b983ccb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-fb18bc7c-23f8-453b-9972-f2700ce4102f,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-fb7a76c7-d7c8-4a1c-b8db-d96abd4cd6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42665,DS-745639f6-6c55-4b1d-9d8a-16612aab1a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44802,DS-def1bf43-9ae4-44e2-b4e6-e245770b465b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1828687507-172.17.0.20-1595595800636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41351,DS-1b13c81a-4275-4f1e-94f3-22ddcd180180,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-bf6add97-76c6-4803-82f5-8d0eb674a478,DISK], DatanodeInfoWithStorage[127.0.0.1:46510,DS-aadd4957-838a-4477-b7e4-14d8b1afec5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-3c925022-61af-4bff-bfb8-b091026f0e62,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-ce9cd8b0-62ba-4f83-a86e-3150d28cdf5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-abc69ef9-1061-41c8-9207-c74f0ad9fe33,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-921b1bda-58a6-4de2-8177-eab4ca6b78b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-4859f490-82d7-4534-9cb2-75f58be07c8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1828687507-172.17.0.20-1595595800636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41351,DS-1b13c81a-4275-4f1e-94f3-22ddcd180180,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-bf6add97-76c6-4803-82f5-8d0eb674a478,DISK], DatanodeInfoWithStorage[127.0.0.1:46510,DS-aadd4957-838a-4477-b7e4-14d8b1afec5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-3c925022-61af-4bff-bfb8-b091026f0e62,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-ce9cd8b0-62ba-4f83-a86e-3150d28cdf5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-abc69ef9-1061-41c8-9207-c74f0ad9fe33,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-921b1bda-58a6-4de2-8177-eab4ca6b78b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-4859f490-82d7-4534-9cb2-75f58be07c8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1807706713-172.17.0.20-1595595949030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40315,DS-24d4b339-e840-466f-bd24-40d8f2e86147,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-28f58bed-ad7f-44d1-add8-84db40cfa13a,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-ed042491-ce8c-4301-9925-f081aa15d97d,DISK], DatanodeInfoWithStorage[127.0.0.1:46515,DS-cc49b714-b837-4736-8a61-d1fa89fe2a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-d0e40495-1724-4891-bc77-ff6c1525d903,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-c6f24096-c14c-483a-8b03-14e83556ac2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-66046260-8bdf-4ed1-88e0-9c7262c7f465,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-f8ff8362-4109-428b-9ea3-cb6aaa779787,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1807706713-172.17.0.20-1595595949030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40315,DS-24d4b339-e840-466f-bd24-40d8f2e86147,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-28f58bed-ad7f-44d1-add8-84db40cfa13a,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-ed042491-ce8c-4301-9925-f081aa15d97d,DISK], DatanodeInfoWithStorage[127.0.0.1:46515,DS-cc49b714-b837-4736-8a61-d1fa89fe2a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-d0e40495-1724-4891-bc77-ff6c1525d903,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-c6f24096-c14c-483a-8b03-14e83556ac2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-66046260-8bdf-4ed1-88e0-9c7262c7f465,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-f8ff8362-4109-428b-9ea3-cb6aaa779787,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1598658798-172.17.0.20-1595596607956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40267,DS-721ad5a2-06fe-46fc-a2ff-bc99cf5bff31,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-195f7c6f-1c4b-4c2a-9c72-1b92e849b639,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-ead34632-5d95-40d3-b4eb-3dda9d1fe445,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-e39c5000-c723-41e8-8fce-d65c25e813df,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-3eedf425-eae0-4dee-84cb-949af86e81dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-6d8a5978-9df9-42fa-90c3-40db589b04ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35242,DS-07cd30b4-0c97-4cc8-8918-6269763a0af6,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-a0049d34-e163-4c4b-a9f6-fad0c6122f14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1598658798-172.17.0.20-1595596607956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40267,DS-721ad5a2-06fe-46fc-a2ff-bc99cf5bff31,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-195f7c6f-1c4b-4c2a-9c72-1b92e849b639,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-ead34632-5d95-40d3-b4eb-3dda9d1fe445,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-e39c5000-c723-41e8-8fce-d65c25e813df,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-3eedf425-eae0-4dee-84cb-949af86e81dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-6d8a5978-9df9-42fa-90c3-40db589b04ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35242,DS-07cd30b4-0c97-4cc8-8918-6269763a0af6,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-a0049d34-e163-4c4b-a9f6-fad0c6122f14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1853908887-172.17.0.20-1595596907458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38860,DS-8a767a2a-af66-4d24-9710-d36a7ef7e7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-f566a7f1-2c82-455b-9420-c2db7361720c,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-2c7651c0-7929-4130-a4eb-ed2eb20d7244,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-e2832990-f8d5-44aa-a282-1549c5885723,DISK], DatanodeInfoWithStorage[127.0.0.1:39371,DS-98143d05-7ce5-4deb-88ac-952f62864840,DISK], DatanodeInfoWithStorage[127.0.0.1:35462,DS-7a22f95f-ca85-4cb4-b64a-562145cca0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-0e20cae6-1701-4706-a740-0ade267133d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-8f9acc82-c0d8-431f-8841-f67d5522a4ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1853908887-172.17.0.20-1595596907458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38860,DS-8a767a2a-af66-4d24-9710-d36a7ef7e7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-f566a7f1-2c82-455b-9420-c2db7361720c,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-2c7651c0-7929-4130-a4eb-ed2eb20d7244,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-e2832990-f8d5-44aa-a282-1549c5885723,DISK], DatanodeInfoWithStorage[127.0.0.1:39371,DS-98143d05-7ce5-4deb-88ac-952f62864840,DISK], DatanodeInfoWithStorage[127.0.0.1:35462,DS-7a22f95f-ca85-4cb4-b64a-562145cca0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-0e20cae6-1701-4706-a740-0ade267133d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-8f9acc82-c0d8-431f-8841-f67d5522a4ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-571290971-172.17.0.20-1595597441892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43129,DS-055feae1-c0ca-4b59-93a0-9f1b8cfe11ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-54128ab8-6e37-4749-b468-3e0a0edf688e,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-c93ba4d8-0090-4a85-9edf-8d3718bcb562,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-b93067a5-7169-4777-a3aa-9ca089f1e340,DISK], DatanodeInfoWithStorage[127.0.0.1:46500,DS-cc81ff7d-c6a7-4979-845a-89ab49cf6653,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-027b82f3-4c49-41de-9d9f-7f2b01eaa13f,DISK], DatanodeInfoWithStorage[127.0.0.1:46412,DS-f20516fd-b5dd-42ba-8b68-9bc759d5f66e,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-3020afe1-6f68-4cd5-8a0c-a4795d296dfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-571290971-172.17.0.20-1595597441892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43129,DS-055feae1-c0ca-4b59-93a0-9f1b8cfe11ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-54128ab8-6e37-4749-b468-3e0a0edf688e,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-c93ba4d8-0090-4a85-9edf-8d3718bcb562,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-b93067a5-7169-4777-a3aa-9ca089f1e340,DISK], DatanodeInfoWithStorage[127.0.0.1:46500,DS-cc81ff7d-c6a7-4979-845a-89ab49cf6653,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-027b82f3-4c49-41de-9d9f-7f2b01eaa13f,DISK], DatanodeInfoWithStorage[127.0.0.1:46412,DS-f20516fd-b5dd-42ba-8b68-9bc759d5f66e,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-3020afe1-6f68-4cd5-8a0c-a4795d296dfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1115301860-172.17.0.20-1595597948437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45997,DS-3938c41a-8d22-4c29-9a25-5e194aa22758,DISK], DatanodeInfoWithStorage[127.0.0.1:41440,DS-2ffa484c-507b-4c28-bca6-f4b9b9cb95e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-216cfad2-8b5e-4693-bfba-98a237f50987,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-e9f5926e-305c-4091-976e-6917cb4b6e95,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-e251536b-a84a-410e-ab25-76ffad4b0d00,DISK], DatanodeInfoWithStorage[127.0.0.1:33962,DS-653f9873-968f-44b1-a60f-ef842a48c9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-b0dd5a62-d428-42b8-8d24-0a4ace5de680,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-3ddf95e2-ff32-4602-8121-7fa5760b4e13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1115301860-172.17.0.20-1595597948437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45997,DS-3938c41a-8d22-4c29-9a25-5e194aa22758,DISK], DatanodeInfoWithStorage[127.0.0.1:41440,DS-2ffa484c-507b-4c28-bca6-f4b9b9cb95e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-216cfad2-8b5e-4693-bfba-98a237f50987,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-e9f5926e-305c-4091-976e-6917cb4b6e95,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-e251536b-a84a-410e-ab25-76ffad4b0d00,DISK], DatanodeInfoWithStorage[127.0.0.1:33962,DS-653f9873-968f-44b1-a60f-ef842a48c9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-b0dd5a62-d428-42b8-8d24-0a4ace5de680,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-3ddf95e2-ff32-4602-8121-7fa5760b4e13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-75845920-172.17.0.20-1595598131200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45258,DS-a189ef9f-edb4-44a3-ae93-43e9d4f0c115,DISK], DatanodeInfoWithStorage[127.0.0.1:43231,DS-d1fc5e9c-8297-4d8e-9b96-d3498984836c,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-f8a7b2d7-b59b-4945-8d61-e3459b4746a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-3b47429b-2e12-45ae-8a4c-6025d679e7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-73ed358c-b8a8-4db0-aafd-18c4c2e254c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-d40312a4-45d9-42fa-ae2a-52a3b735da7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-53969a0d-5452-4051-af57-e879160c44c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-55823ebe-90e4-4e45-afe3-169fc6d39db4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-75845920-172.17.0.20-1595598131200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45258,DS-a189ef9f-edb4-44a3-ae93-43e9d4f0c115,DISK], DatanodeInfoWithStorage[127.0.0.1:43231,DS-d1fc5e9c-8297-4d8e-9b96-d3498984836c,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-f8a7b2d7-b59b-4945-8d61-e3459b4746a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-3b47429b-2e12-45ae-8a4c-6025d679e7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-73ed358c-b8a8-4db0-aafd-18c4c2e254c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-d40312a4-45d9-42fa-ae2a-52a3b735da7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-53969a0d-5452-4051-af57-e879160c44c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-55823ebe-90e4-4e45-afe3-169fc6d39db4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-120667198-172.17.0.20-1595598207956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35897,DS-c95175f8-61c5-44e4-8a21-4b4fd0c1084a,DISK], DatanodeInfoWithStorage[127.0.0.1:46416,DS-1b8494f1-0b5e-4e8b-951e-869af7cfa842,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-cc0fd4f0-fe89-44e0-85a5-083b0004343c,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-50c1d621-d805-4132-a8ba-0ab7c71f497e,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-41ea6d94-30fb-4c8d-a886-90f7f516dae7,DISK], DatanodeInfoWithStorage[127.0.0.1:43692,DS-0bf2860d-405f-4d77-a11e-e3be61f7f89b,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-946b383c-9a5d-4866-b16c-669fed1f65f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-e3264333-593d-4580-9231-0602dc2c4002,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-120667198-172.17.0.20-1595598207956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35897,DS-c95175f8-61c5-44e4-8a21-4b4fd0c1084a,DISK], DatanodeInfoWithStorage[127.0.0.1:46416,DS-1b8494f1-0b5e-4e8b-951e-869af7cfa842,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-cc0fd4f0-fe89-44e0-85a5-083b0004343c,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-50c1d621-d805-4132-a8ba-0ab7c71f497e,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-41ea6d94-30fb-4c8d-a886-90f7f516dae7,DISK], DatanodeInfoWithStorage[127.0.0.1:43692,DS-0bf2860d-405f-4d77-a11e-e3be61f7f89b,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-946b383c-9a5d-4866-b16c-669fed1f65f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-e3264333-593d-4580-9231-0602dc2c4002,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1053903178-172.17.0.20-1595598274518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36193,DS-bfdb148d-72f2-48a4-9271-db8414906569,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-6867b213-dbaf-4c12-b915-6aa7748dc822,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-6e176798-b125-462c-a068-d1c1a575c842,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-e63f9b1f-f340-4ac2-a4fb-3236da7d7a37,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-66eda17e-d88a-4682-b285-b2c3627259cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-1adf84d8-7db2-4adc-a30b-2ca9a0f53950,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-498ddd03-3cf2-4cb7-b7c5-ca4654d3faee,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-1ad345fe-839c-4c3e-b45b-48e489efe204,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1053903178-172.17.0.20-1595598274518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36193,DS-bfdb148d-72f2-48a4-9271-db8414906569,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-6867b213-dbaf-4c12-b915-6aa7748dc822,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-6e176798-b125-462c-a068-d1c1a575c842,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-e63f9b1f-f340-4ac2-a4fb-3236da7d7a37,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-66eda17e-d88a-4682-b285-b2c3627259cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-1adf84d8-7db2-4adc-a30b-2ca9a0f53950,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-498ddd03-3cf2-4cb7-b7c5-ca4654d3faee,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-1ad345fe-839c-4c3e-b45b-48e489efe204,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-274080522-172.17.0.20-1595598361887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42518,DS-315bdf43-67c4-45ea-a7a2-7ced8358c729,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-435eaa79-a32c-4cde-b5a2-98e274035fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-106fef61-a120-459c-a92a-8a304b4bf7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-31ef80dd-e94d-4116-b83d-ce49707a1a02,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-314ae1cf-5a92-47be-bfe1-725f84a84772,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-14136f30-6078-4291-83e0-4de84887ec28,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-5dccbd06-967b-4545-b7cf-56db5e8667f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-37550c37-a0a9-48c7-9bff-b8118b57eac2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-274080522-172.17.0.20-1595598361887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42518,DS-315bdf43-67c4-45ea-a7a2-7ced8358c729,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-435eaa79-a32c-4cde-b5a2-98e274035fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-106fef61-a120-459c-a92a-8a304b4bf7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-31ef80dd-e94d-4116-b83d-ce49707a1a02,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-314ae1cf-5a92-47be-bfe1-725f84a84772,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-14136f30-6078-4291-83e0-4de84887ec28,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-5dccbd06-967b-4545-b7cf-56db5e8667f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-37550c37-a0a9-48c7-9bff-b8118b57eac2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5522
