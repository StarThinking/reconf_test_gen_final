reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-609077848-172.17.0.2-1595557234349:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38196,DS-906111af-c042-436f-aeb0-4b18fe749867,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-0bf5566f-26fa-4740-b8da-06314119c650,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-2d4d2daa-6644-4f39-9f23-0c55a9679a66,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-55daf299-be25-4bfe-be80-6bc19ce7251a,DISK], DatanodeInfoWithStorage[127.0.0.1:39793,DS-649a4b37-45bf-407e-8b3d-1c7abeeb67dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-080b454d-521d-4cee-863c-3486b689cc7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-7f0cdcfb-c4bd-4381-a282-997810b2cee4,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-11e883d5-6043-4b99-84eb-ce124677af6b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-609077848-172.17.0.2-1595557234349:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38196,DS-906111af-c042-436f-aeb0-4b18fe749867,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-0bf5566f-26fa-4740-b8da-06314119c650,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-2d4d2daa-6644-4f39-9f23-0c55a9679a66,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-55daf299-be25-4bfe-be80-6bc19ce7251a,DISK], DatanodeInfoWithStorage[127.0.0.1:39793,DS-649a4b37-45bf-407e-8b3d-1c7abeeb67dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-080b454d-521d-4cee-863c-3486b689cc7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-7f0cdcfb-c4bd-4381-a282-997810b2cee4,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-11e883d5-6043-4b99-84eb-ce124677af6b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-509145228-172.17.0.2-1595557335118:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43406,DS-e10b8be2-0219-4b16-9132-ab794e94eb2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-656eb44d-33a2-449e-9736-9840814dd2c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-65599a70-c97a-4979-ba6d-6a8aa1ca9771,DISK], DatanodeInfoWithStorage[127.0.0.1:33070,DS-2fbd1578-b8bc-403a-bb9d-5bbf7abfc5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35463,DS-dfc49685-42f3-435b-8ddc-8ab5d98234f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-0ea6a508-7f49-490c-be4e-0729f0f72585,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-75eafc8b-7e44-4354-8bcd-fd968d93c638,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-6f9ed23b-7b87-4040-9a99-176e2c6fbb7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-509145228-172.17.0.2-1595557335118:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43406,DS-e10b8be2-0219-4b16-9132-ab794e94eb2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-656eb44d-33a2-449e-9736-9840814dd2c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-65599a70-c97a-4979-ba6d-6a8aa1ca9771,DISK], DatanodeInfoWithStorage[127.0.0.1:33070,DS-2fbd1578-b8bc-403a-bb9d-5bbf7abfc5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35463,DS-dfc49685-42f3-435b-8ddc-8ab5d98234f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-0ea6a508-7f49-490c-be4e-0729f0f72585,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-75eafc8b-7e44-4354-8bcd-fd968d93c638,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-6f9ed23b-7b87-4040-9a99-176e2c6fbb7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1971069741-172.17.0.2-1595557454058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43581,DS-a911804e-d3b0-4dd3-b8fe-90b87d616f23,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-2d460989-96b0-4039-92ee-ed195c99cee8,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-30e51be1-dc07-495c-a528-a9244f5df4df,DISK], DatanodeInfoWithStorage[127.0.0.1:35503,DS-1de87282-9eda-4028-af92-ac04c80e986f,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-bdeafc84-8d26-4ba7-ad3a-a20bf33eb71c,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-70d64f84-ba30-420c-ad92-147d332b52e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-821ec759-bdb9-460a-a071-9aaafcfaed94,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-7ea5e220-2975-468d-9a75-44aa57e4211e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1971069741-172.17.0.2-1595557454058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43581,DS-a911804e-d3b0-4dd3-b8fe-90b87d616f23,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-2d460989-96b0-4039-92ee-ed195c99cee8,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-30e51be1-dc07-495c-a528-a9244f5df4df,DISK], DatanodeInfoWithStorage[127.0.0.1:35503,DS-1de87282-9eda-4028-af92-ac04c80e986f,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-bdeafc84-8d26-4ba7-ad3a-a20bf33eb71c,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-70d64f84-ba30-420c-ad92-147d332b52e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-821ec759-bdb9-460a-a071-9aaafcfaed94,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-7ea5e220-2975-468d-9a75-44aa57e4211e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-143657700-172.17.0.2-1595557488324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36761,DS-88860bbe-8f25-4cfa-aad3-dbc329ed468a,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-fcaa5a67-b7f3-4bfd-a469-d5b37b6ab140,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-5a1bcf8d-b1da-4337-b2b2-672a82a94203,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-62943fc9-4cbf-422b-9a67-287301431382,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-c18f3552-7f2a-4942-ae58-15bc33e4f84f,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-2c08e9f8-e6b0-452b-b61d-d5e9998a0767,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-33bbc2b3-a018-42af-b9c3-a4e2682f9478,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-d9e10e9c-9c5b-4684-99ec-b3ca4cd9eaa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-143657700-172.17.0.2-1595557488324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36761,DS-88860bbe-8f25-4cfa-aad3-dbc329ed468a,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-fcaa5a67-b7f3-4bfd-a469-d5b37b6ab140,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-5a1bcf8d-b1da-4337-b2b2-672a82a94203,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-62943fc9-4cbf-422b-9a67-287301431382,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-c18f3552-7f2a-4942-ae58-15bc33e4f84f,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-2c08e9f8-e6b0-452b-b61d-d5e9998a0767,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-33bbc2b3-a018-42af-b9c3-a4e2682f9478,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-d9e10e9c-9c5b-4684-99ec-b3ca4cd9eaa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1670213799-172.17.0.2-1595557800483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38342,DS-55199632-939c-4791-9037-0744a915d2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-9a6d5de6-e9fc-4629-9416-fbace0746f58,DISK], DatanodeInfoWithStorage[127.0.0.1:46047,DS-f7927576-4426-4fdd-8ae6-d409d22bcdc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-a7520ad4-b4c5-4b24-bbe4-7bd5ebbc59eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43512,DS-ab79f58b-8111-42fb-99a8-7bc67fd8d578,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-71c2906a-4d8b-4915-a0a9-1ecbccd924dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-fb10d6d5-bcd1-4600-91b6-420fbdc4b942,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-4f316f22-7b67-4c2a-b5d8-1c5ed8214f2a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1670213799-172.17.0.2-1595557800483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38342,DS-55199632-939c-4791-9037-0744a915d2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-9a6d5de6-e9fc-4629-9416-fbace0746f58,DISK], DatanodeInfoWithStorage[127.0.0.1:46047,DS-f7927576-4426-4fdd-8ae6-d409d22bcdc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-a7520ad4-b4c5-4b24-bbe4-7bd5ebbc59eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43512,DS-ab79f58b-8111-42fb-99a8-7bc67fd8d578,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-71c2906a-4d8b-4915-a0a9-1ecbccd924dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-fb10d6d5-bcd1-4600-91b6-420fbdc4b942,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-4f316f22-7b67-4c2a-b5d8-1c5ed8214f2a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-298450258-172.17.0.2-1595558216002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42481,DS-2b907b4e-71ce-49c7-b7b6-17036eb6118c,DISK], DatanodeInfoWithStorage[127.0.0.1:45930,DS-df476b9b-4ac8-4b62-9c4e-7dfec3c3eb22,DISK], DatanodeInfoWithStorage[127.0.0.1:38431,DS-914044ff-bc08-4ff3-974c-116445170462,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-198f0f5e-f521-4979-8bce-92f8d03ae094,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-374c925e-d3f3-46d3-83fe-7e9bcf3d1be2,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-821a9654-5508-42a4-b013-d22b0befe4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-94f13b7c-d477-46f1-9bbe-6b0f287dcdee,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-3dedcc7d-2422-4034-87c7-5924de0754f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-298450258-172.17.0.2-1595558216002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42481,DS-2b907b4e-71ce-49c7-b7b6-17036eb6118c,DISK], DatanodeInfoWithStorage[127.0.0.1:45930,DS-df476b9b-4ac8-4b62-9c4e-7dfec3c3eb22,DISK], DatanodeInfoWithStorage[127.0.0.1:38431,DS-914044ff-bc08-4ff3-974c-116445170462,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-198f0f5e-f521-4979-8bce-92f8d03ae094,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-374c925e-d3f3-46d3-83fe-7e9bcf3d1be2,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-821a9654-5508-42a4-b013-d22b0befe4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-94f13b7c-d477-46f1-9bbe-6b0f287dcdee,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-3dedcc7d-2422-4034-87c7-5924de0754f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-355408296-172.17.0.2-1595558623496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40238,DS-55890846-4e71-42af-b128-f1263f68ff0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-66be94ea-e23f-43fa-a0a5-3a7c5d8f2a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-5c8c217e-2b15-48d2-9249-a5186c2c7be5,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-310c6921-84a1-460b-bf1d-243b103a9c32,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-5c56e7e7-1c31-477c-b193-b6ff309c94f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40254,DS-521a2799-2052-4d04-936e-453ca98a74bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-81e1dcd8-81a0-4be8-bd16-702da8397c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42549,DS-15bb710a-5138-4959-bc01-295725ed49e8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-355408296-172.17.0.2-1595558623496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40238,DS-55890846-4e71-42af-b128-f1263f68ff0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-66be94ea-e23f-43fa-a0a5-3a7c5d8f2a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-5c8c217e-2b15-48d2-9249-a5186c2c7be5,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-310c6921-84a1-460b-bf1d-243b103a9c32,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-5c56e7e7-1c31-477c-b193-b6ff309c94f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40254,DS-521a2799-2052-4d04-936e-453ca98a74bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-81e1dcd8-81a0-4be8-bd16-702da8397c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42549,DS-15bb710a-5138-4959-bc01-295725ed49e8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1761718516-172.17.0.2-1595558858575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35680,DS-3c47bbcc-50f5-4752-ba7f-5cf3e9e9b37a,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-d03081c3-6a92-43d4-8a28-7086e324afb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-56faf247-4241-47bd-9153-e1443ed81a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-96e485af-264f-4968-9103-9f0dcddb5b14,DISK], DatanodeInfoWithStorage[127.0.0.1:34569,DS-1ba5f180-5592-45d4-9689-41f7b5f431a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-06b7626e-0277-4c40-9e32-1e072c56c9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-e55793de-6aad-4ca0-a722-f7479cb6f3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45812,DS-13e4e252-fa67-4bd5-8654-4305f064533a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1761718516-172.17.0.2-1595558858575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35680,DS-3c47bbcc-50f5-4752-ba7f-5cf3e9e9b37a,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-d03081c3-6a92-43d4-8a28-7086e324afb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-56faf247-4241-47bd-9153-e1443ed81a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-96e485af-264f-4968-9103-9f0dcddb5b14,DISK], DatanodeInfoWithStorage[127.0.0.1:34569,DS-1ba5f180-5592-45d4-9689-41f7b5f431a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-06b7626e-0277-4c40-9e32-1e072c56c9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-e55793de-6aad-4ca0-a722-f7479cb6f3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45812,DS-13e4e252-fa67-4bd5-8654-4305f064533a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-818619441-172.17.0.2-1595559008459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36619,DS-840cc732-ca82-4edf-9a98-6aba011bced3,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-049d6397-2776-45b9-a6b5-cd7a19fb1781,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-1bcb77d7-589e-4c1d-97f3-4a7c3a2cfed6,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-37251c55-9ce0-4f1b-9bcb-6718e0bebf43,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-de1037aa-def9-46b0-846e-4ecc9f468e47,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-be3b25ae-c4fe-43ad-a13f-ef1dfd757b75,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-7eea513a-7cf7-4136-a7c6-c67e9588d298,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-5e8b2477-3c55-4909-92f6-5fd07feb152b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-818619441-172.17.0.2-1595559008459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36619,DS-840cc732-ca82-4edf-9a98-6aba011bced3,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-049d6397-2776-45b9-a6b5-cd7a19fb1781,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-1bcb77d7-589e-4c1d-97f3-4a7c3a2cfed6,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-37251c55-9ce0-4f1b-9bcb-6718e0bebf43,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-de1037aa-def9-46b0-846e-4ecc9f468e47,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-be3b25ae-c4fe-43ad-a13f-ef1dfd757b75,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-7eea513a-7cf7-4136-a7c6-c67e9588d298,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-5e8b2477-3c55-4909-92f6-5fd07feb152b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-520387060-172.17.0.2-1595559090383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35081,DS-7f7dbc03-187e-46a5-9cae-a235d15de6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-d5d772fd-fc81-40e9-80aa-5a1d169c7b28,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-bb95d669-3b95-4c39-962c-c4cd6e2e71f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-4ec94d44-2bd0-4882-b5d0-51e1f4fdbe1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35424,DS-904e4e6b-3354-426e-b3a3-6391b17343a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42949,DS-67bff785-b6b4-442d-8c19-55d9336b5246,DISK], DatanodeInfoWithStorage[127.0.0.1:41890,DS-1007bfd6-480b-4f11-8040-b91672858e84,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-5f018278-5c0a-41f0-8742-89396d690917,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-520387060-172.17.0.2-1595559090383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35081,DS-7f7dbc03-187e-46a5-9cae-a235d15de6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-d5d772fd-fc81-40e9-80aa-5a1d169c7b28,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-bb95d669-3b95-4c39-962c-c4cd6e2e71f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-4ec94d44-2bd0-4882-b5d0-51e1f4fdbe1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35424,DS-904e4e6b-3354-426e-b3a3-6391b17343a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42949,DS-67bff785-b6b4-442d-8c19-55d9336b5246,DISK], DatanodeInfoWithStorage[127.0.0.1:41890,DS-1007bfd6-480b-4f11-8040-b91672858e84,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-5f018278-5c0a-41f0-8742-89396d690917,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2022748472-172.17.0.2-1595559227905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40294,DS-145d6638-21d3-40ef-a25f-d36813c054e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-e5be97e6-67f3-4bb1-88dd-5520ba948c51,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-eeb08664-8f6c-483d-8f44-28f60c38f618,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-da85f7ee-47c9-4c8c-a0fd-14f5246704f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-ea7d744e-9ae5-4b10-bf13-3286da505180,DISK], DatanodeInfoWithStorage[127.0.0.1:33407,DS-d1da6641-5cb8-47fc-a1b6-4fbd5a7e40c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-815b03c1-d732-4f0d-9eab-929e1a38b479,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-a1366704-7cdd-414c-bdac-2c1a61b8bd03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2022748472-172.17.0.2-1595559227905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40294,DS-145d6638-21d3-40ef-a25f-d36813c054e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-e5be97e6-67f3-4bb1-88dd-5520ba948c51,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-eeb08664-8f6c-483d-8f44-28f60c38f618,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-da85f7ee-47c9-4c8c-a0fd-14f5246704f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-ea7d744e-9ae5-4b10-bf13-3286da505180,DISK], DatanodeInfoWithStorage[127.0.0.1:33407,DS-d1da6641-5cb8-47fc-a1b6-4fbd5a7e40c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-815b03c1-d732-4f0d-9eab-929e1a38b479,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-a1366704-7cdd-414c-bdac-2c1a61b8bd03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1159833864-172.17.0.2-1595559305741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38979,DS-693afb02-b9b6-411f-adb7-05790eee6b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-b5cd4bd0-48f4-4210-95ef-2bdb10f812ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-24d6dbc3-567e-43de-a669-473c8a777732,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-ee91f069-e5dc-47de-8354-7d686155f526,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-806f2cf9-5113-4ed0-b718-2ab1a9b0e4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-2cf28a09-3282-4b0c-9167-b38d21cb4fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-fada4868-0410-4543-addd-e64b323dea54,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-7c5e58e6-22a0-4cd3-b716-7a2a5945ac41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1159833864-172.17.0.2-1595559305741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38979,DS-693afb02-b9b6-411f-adb7-05790eee6b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-b5cd4bd0-48f4-4210-95ef-2bdb10f812ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-24d6dbc3-567e-43de-a669-473c8a777732,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-ee91f069-e5dc-47de-8354-7d686155f526,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-806f2cf9-5113-4ed0-b718-2ab1a9b0e4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-2cf28a09-3282-4b0c-9167-b38d21cb4fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-fada4868-0410-4543-addd-e64b323dea54,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-7c5e58e6-22a0-4cd3-b716-7a2a5945ac41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1262326297-172.17.0.2-1595559375349:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46294,DS-ed795677-9828-401d-b7e7-9d120e1dd1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-3685e62c-188f-4b76-b223-77c9b3bee966,DISK], DatanodeInfoWithStorage[127.0.0.1:43690,DS-cb3cd381-a846-40de-9481-27b5a767e25a,DISK], DatanodeInfoWithStorage[127.0.0.1:46052,DS-b4fe0091-e35d-40cd-bfc7-08a8e79fd507,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-71090fab-6b59-4bb3-b960-ea5512c6fdc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-93f7c5d3-63cf-49d5-bffb-95ef2e0311be,DISK], DatanodeInfoWithStorage[127.0.0.1:39819,DS-91f7d177-8636-41f4-b153-8c5a1ad735e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-222d4660-51dc-467d-8316-5715b139a996,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1262326297-172.17.0.2-1595559375349:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46294,DS-ed795677-9828-401d-b7e7-9d120e1dd1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-3685e62c-188f-4b76-b223-77c9b3bee966,DISK], DatanodeInfoWithStorage[127.0.0.1:43690,DS-cb3cd381-a846-40de-9481-27b5a767e25a,DISK], DatanodeInfoWithStorage[127.0.0.1:46052,DS-b4fe0091-e35d-40cd-bfc7-08a8e79fd507,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-71090fab-6b59-4bb3-b960-ea5512c6fdc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-93f7c5d3-63cf-49d5-bffb-95ef2e0311be,DISK], DatanodeInfoWithStorage[127.0.0.1:39819,DS-91f7d177-8636-41f4-b153-8c5a1ad735e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-222d4660-51dc-467d-8316-5715b139a996,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1600479318-172.17.0.2-1595559640271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38150,DS-4661da29-dd98-46cb-9d61-d41db36b19b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-fd72f2ff-d92f-4076-a078-65ce74f1b287,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-84101bc5-4336-46b2-9282-80e6b0b7b629,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-db2fecc8-2244-42af-be38-73764f2832d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-b73ee81e-ae98-496a-812a-8383d875eeeb,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-93d95b28-fc76-45e2-a27b-85e9ecf4e758,DISK], DatanodeInfoWithStorage[127.0.0.1:36915,DS-54d64cab-a32b-42b4-a78e-22c7726aaeeb,DISK], DatanodeInfoWithStorage[127.0.0.1:46391,DS-4378b42b-abff-4c92-9405-948760a6ce7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1600479318-172.17.0.2-1595559640271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38150,DS-4661da29-dd98-46cb-9d61-d41db36b19b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-fd72f2ff-d92f-4076-a078-65ce74f1b287,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-84101bc5-4336-46b2-9282-80e6b0b7b629,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-db2fecc8-2244-42af-be38-73764f2832d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-b73ee81e-ae98-496a-812a-8383d875eeeb,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-93d95b28-fc76-45e2-a27b-85e9ecf4e758,DISK], DatanodeInfoWithStorage[127.0.0.1:36915,DS-54d64cab-a32b-42b4-a78e-22c7726aaeeb,DISK], DatanodeInfoWithStorage[127.0.0.1:46391,DS-4378b42b-abff-4c92-9405-948760a6ce7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-718225448-172.17.0.2-1595559675322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43172,DS-239e4464-35a1-4cb1-b168-4fa2b2aa86ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-ff7f88f3-d734-47c3-ad14-03a67ab358f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-45afe76f-1673-4178-a1f5-4dfafd9f378c,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-63c0bbf9-1ec1-4dc8-bca6-0f9cc36a3b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-35863560-a34f-4de8-b628-f70db62f401d,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-347f4a40-9ee6-4512-8819-d53ac1b29f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-164af1c9-0e78-4d1b-8dcd-ed00d71a6b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-1c378aff-59da-431d-81a1-32830c50f066,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-718225448-172.17.0.2-1595559675322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43172,DS-239e4464-35a1-4cb1-b168-4fa2b2aa86ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-ff7f88f3-d734-47c3-ad14-03a67ab358f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-45afe76f-1673-4178-a1f5-4dfafd9f378c,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-63c0bbf9-1ec1-4dc8-bca6-0f9cc36a3b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-35863560-a34f-4de8-b628-f70db62f401d,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-347f4a40-9ee6-4512-8819-d53ac1b29f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-164af1c9-0e78-4d1b-8dcd-ed00d71a6b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-1c378aff-59da-431d-81a1-32830c50f066,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1811654781-172.17.0.2-1595559795532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34653,DS-8967cba3-687e-4766-8aee-411a543e7777,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-ac042583-2957-47d9-b6b5-22ffce2d01ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-d3a6fd8f-2c43-40af-a86f-adb4deb8ced7,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-596e1da8-97b1-47eb-beb0-d410d246c86e,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-8579852b-01c3-44ff-af6f-9bec29018f30,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-257b18b5-d84f-4566-be41-58afe9e82939,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-1877d714-794b-4f0d-abdd-6ddbafd55672,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-1dd3b4dd-d5e3-410c-95bb-cb28d447b45f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1811654781-172.17.0.2-1595559795532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34653,DS-8967cba3-687e-4766-8aee-411a543e7777,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-ac042583-2957-47d9-b6b5-22ffce2d01ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-d3a6fd8f-2c43-40af-a86f-adb4deb8ced7,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-596e1da8-97b1-47eb-beb0-d410d246c86e,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-8579852b-01c3-44ff-af6f-9bec29018f30,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-257b18b5-d84f-4566-be41-58afe9e82939,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-1877d714-794b-4f0d-abdd-6ddbafd55672,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-1dd3b4dd-d5e3-410c-95bb-cb28d447b45f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1959414940-172.17.0.2-1595560053522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39772,DS-07dd750c-c012-49f5-b10e-878043d90452,DISK], DatanodeInfoWithStorage[127.0.0.1:43283,DS-c6d20c1d-2541-42ac-b181-71ec4ffb4d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-25fd7494-241b-4ac7-94b1-2ad63b66f632,DISK], DatanodeInfoWithStorage[127.0.0.1:40352,DS-7e32dc90-a1a8-4edb-ae84-0f06fd2b2a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-badb7cc5-bc97-49e4-a359-1716e45ac20d,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-b495d64a-76e4-4290-acac-d91854ed10c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-522ae4bf-52dc-4c0d-9c41-2f3a26eee6af,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-3f82658b-0a55-4cd8-b510-6c39edacc81e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1959414940-172.17.0.2-1595560053522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39772,DS-07dd750c-c012-49f5-b10e-878043d90452,DISK], DatanodeInfoWithStorage[127.0.0.1:43283,DS-c6d20c1d-2541-42ac-b181-71ec4ffb4d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-25fd7494-241b-4ac7-94b1-2ad63b66f632,DISK], DatanodeInfoWithStorage[127.0.0.1:40352,DS-7e32dc90-a1a8-4edb-ae84-0f06fd2b2a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-badb7cc5-bc97-49e4-a359-1716e45ac20d,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-b495d64a-76e4-4290-acac-d91854ed10c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-522ae4bf-52dc-4c0d-9c41-2f3a26eee6af,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-3f82658b-0a55-4cd8-b510-6c39edacc81e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1880612298-172.17.0.2-1595560360125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42240,DS-3dbcdc2a-f071-4a92-9a7e-df48f8bee570,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-33cb5056-f0ad-486f-920e-ba73837fd7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-9d02253e-c320-474a-b231-6d05c0453a43,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-a8072b94-3e6b-4817-9ded-519cfe164c33,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-bd1f4b78-28d6-4af4-9ecf-4fe5629c51ac,DISK], DatanodeInfoWithStorage[127.0.0.1:32904,DS-f482795e-a3e4-431c-8cbc-73267c80ad29,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-89c9d4f9-d990-4c67-bf18-c01f7df9205e,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-b02eb10b-e750-4173-9804-cc08e02f328e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1880612298-172.17.0.2-1595560360125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42240,DS-3dbcdc2a-f071-4a92-9a7e-df48f8bee570,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-33cb5056-f0ad-486f-920e-ba73837fd7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-9d02253e-c320-474a-b231-6d05c0453a43,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-a8072b94-3e6b-4817-9ded-519cfe164c33,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-bd1f4b78-28d6-4af4-9ecf-4fe5629c51ac,DISK], DatanodeInfoWithStorage[127.0.0.1:32904,DS-f482795e-a3e4-431c-8cbc-73267c80ad29,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-89c9d4f9-d990-4c67-bf18-c01f7df9205e,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-b02eb10b-e750-4173-9804-cc08e02f328e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-518658533-172.17.0.2-1595560575990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44216,DS-5bb1e80f-c5bd-4eaa-92f1-64c75eace5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-8da2cad9-b21e-499f-a82a-990d51c00523,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-03cd7624-415b-4feb-9d3a-f2ef2729b122,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-78423b1b-267a-42e6-84e1-0cb91f30937b,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-5e1dd158-3818-4a01-a2fb-abbef3fb8c81,DISK], DatanodeInfoWithStorage[127.0.0.1:41965,DS-c533f2a9-6ef8-4d91-8ff6-4263ae807144,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-fce4bca4-5499-4128-9b50-67bbc700a3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-d8a98657-8993-4e88-b06c-a2d4ef93b1d9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-518658533-172.17.0.2-1595560575990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44216,DS-5bb1e80f-c5bd-4eaa-92f1-64c75eace5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-8da2cad9-b21e-499f-a82a-990d51c00523,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-03cd7624-415b-4feb-9d3a-f2ef2729b122,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-78423b1b-267a-42e6-84e1-0cb91f30937b,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-5e1dd158-3818-4a01-a2fb-abbef3fb8c81,DISK], DatanodeInfoWithStorage[127.0.0.1:41965,DS-c533f2a9-6ef8-4d91-8ff6-4263ae807144,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-fce4bca4-5499-4128-9b50-67bbc700a3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-d8a98657-8993-4e88-b06c-a2d4ef93b1d9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-730532015-172.17.0.2-1595560861956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39606,DS-da5a8733-4b54-428a-9296-1e43106af271,DISK], DatanodeInfoWithStorage[127.0.0.1:35724,DS-fc6d508c-11f7-4f0e-81bb-6524ebe5cde6,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-d325ce60-a0aa-4121-9450-59c2eff68df8,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-d07305a5-9bd7-4edd-8ce4-3545093f6cce,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-40b7090a-c16b-4016-b486-2c150134114b,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-0f197321-8f8d-4a0e-971a-3658fa5a567a,DISK], DatanodeInfoWithStorage[127.0.0.1:46737,DS-8501a411-21fa-41da-8abb-0fb3229efd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-c681f58e-5160-4544-b596-4311f67be3bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-730532015-172.17.0.2-1595560861956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39606,DS-da5a8733-4b54-428a-9296-1e43106af271,DISK], DatanodeInfoWithStorage[127.0.0.1:35724,DS-fc6d508c-11f7-4f0e-81bb-6524ebe5cde6,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-d325ce60-a0aa-4121-9450-59c2eff68df8,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-d07305a5-9bd7-4edd-8ce4-3545093f6cce,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-40b7090a-c16b-4016-b486-2c150134114b,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-0f197321-8f8d-4a0e-971a-3658fa5a567a,DISK], DatanodeInfoWithStorage[127.0.0.1:46737,DS-8501a411-21fa-41da-8abb-0fb3229efd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-c681f58e-5160-4544-b596-4311f67be3bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-226953925-172.17.0.2-1595560943851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43358,DS-8239736e-a312-4934-a550-bebe6bdd0e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45650,DS-bf0281b0-a163-4bd3-ae88-cfc06bbedfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:38241,DS-deb1af68-4ceb-4cc5-ad94-2bc5c63449c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-4d5f2f77-a6e4-4fcd-b142-77e75c5d5fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-79088215-caee-4f21-b82f-8606245c989e,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-4ec82163-c163-48b1-b10e-c42c13bd7314,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-2b51b2a7-0aad-4037-a2d4-2324e88e9cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-9d9a3f89-dda4-41eb-b812-ca9834d8367b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-226953925-172.17.0.2-1595560943851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43358,DS-8239736e-a312-4934-a550-bebe6bdd0e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45650,DS-bf0281b0-a163-4bd3-ae88-cfc06bbedfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:38241,DS-deb1af68-4ceb-4cc5-ad94-2bc5c63449c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-4d5f2f77-a6e4-4fcd-b142-77e75c5d5fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-79088215-caee-4f21-b82f-8606245c989e,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-4ec82163-c163-48b1-b10e-c42c13bd7314,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-2b51b2a7-0aad-4037-a2d4-2324e88e9cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-9d9a3f89-dda4-41eb-b812-ca9834d8367b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-446235278-172.17.0.2-1595561813489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37441,DS-da2d0b9f-b942-4788-b13e-6265218e0a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39785,DS-2e560a33-a768-49ed-93f1-e554f1a7ffc5,DISK], DatanodeInfoWithStorage[127.0.0.1:46534,DS-85385629-69ab-4bde-96b5-d90520b0f80b,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-b8170f36-709d-45ce-8c9a-b7233240af62,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-4e424927-265d-4812-9e29-5b54d6f4e273,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-036dbb05-a40f-4260-a9c8-2bfb7cbbafb6,DISK], DatanodeInfoWithStorage[127.0.0.1:45483,DS-8be5a27a-3b8d-4b40-9357-7e80892e100d,DISK], DatanodeInfoWithStorage[127.0.0.1:35222,DS-9aea4207-f17e-4340-8cc4-e3e012cda36d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-446235278-172.17.0.2-1595561813489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37441,DS-da2d0b9f-b942-4788-b13e-6265218e0a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39785,DS-2e560a33-a768-49ed-93f1-e554f1a7ffc5,DISK], DatanodeInfoWithStorage[127.0.0.1:46534,DS-85385629-69ab-4bde-96b5-d90520b0f80b,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-b8170f36-709d-45ce-8c9a-b7233240af62,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-4e424927-265d-4812-9e29-5b54d6f4e273,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-036dbb05-a40f-4260-a9c8-2bfb7cbbafb6,DISK], DatanodeInfoWithStorage[127.0.0.1:45483,DS-8be5a27a-3b8d-4b40-9357-7e80892e100d,DISK], DatanodeInfoWithStorage[127.0.0.1:35222,DS-9aea4207-f17e-4340-8cc4-e3e012cda36d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-987532695-172.17.0.2-1595562040120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39437,DS-6a40691e-f78d-4d90-95d3-d998f2abe109,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-c35939b6-5317-4f9d-bff3-2eaef156ccfc,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-718cbb46-b2ee-4df4-9e38-acd6672fad63,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-b3ed7b72-d231-41f0-9752-30c17e795d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-1323c10f-149f-424a-8c3a-a78033c97967,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-e0d077c2-5785-4df7-9e3f-57845689a5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-ac2163ce-9dec-4752-8fc7-9375aceaff9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-701f60da-5f72-42d0-8692-a6fadc626fb9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-987532695-172.17.0.2-1595562040120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39437,DS-6a40691e-f78d-4d90-95d3-d998f2abe109,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-c35939b6-5317-4f9d-bff3-2eaef156ccfc,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-718cbb46-b2ee-4df4-9e38-acd6672fad63,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-b3ed7b72-d231-41f0-9752-30c17e795d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-1323c10f-149f-424a-8c3a-a78033c97967,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-e0d077c2-5785-4df7-9e3f-57845689a5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-ac2163ce-9dec-4752-8fc7-9375aceaff9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-701f60da-5f72-42d0-8692-a6fadc626fb9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-200695630-172.17.0.2-1595562075920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45407,DS-15792623-d301-42bd-ab7b-a2ec416d87fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-ba117351-1ec7-400e-b858-755d5e7ea3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-d0503d3b-7504-4e54-bcf0-30ff3c827a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-3c0a76c1-d37f-47ec-819e-4cc997ba2e48,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-964c3553-b711-4b79-9d53-8dacd15536c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-ff6448a3-bfcc-4406-9c8b-ca351e0821c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-69791b3d-0dfa-4e2b-9288-9bc7cc3c08fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-6d82026f-9919-4fb1-96af-b96d818b9150,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-200695630-172.17.0.2-1595562075920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45407,DS-15792623-d301-42bd-ab7b-a2ec416d87fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-ba117351-1ec7-400e-b858-755d5e7ea3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-d0503d3b-7504-4e54-bcf0-30ff3c827a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-3c0a76c1-d37f-47ec-819e-4cc997ba2e48,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-964c3553-b711-4b79-9d53-8dacd15536c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-ff6448a3-bfcc-4406-9c8b-ca351e0821c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-69791b3d-0dfa-4e2b-9288-9bc7cc3c08fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-6d82026f-9919-4fb1-96af-b96d818b9150,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-238782152-172.17.0.2-1595562149966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41536,DS-79d9949b-c37c-49e4-a655-4fefeaa9a0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-df03ad46-b4e5-4590-95df-5bf8b3407009,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-90a797f9-73fa-4b91-8f6f-ac8321e91a43,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-66e3859c-f08c-4fad-b12b-7b19b13356a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36269,DS-d6d4d155-3eed-42f9-8d01-69ddeaf47f68,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-aef62b0f-9a21-4ecd-a03d-32957a9a05ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-f40eed25-efc6-4cfa-bfb3-456eb753f6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-edd84d46-886a-402b-a0af-35792b018dd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-238782152-172.17.0.2-1595562149966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41536,DS-79d9949b-c37c-49e4-a655-4fefeaa9a0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-df03ad46-b4e5-4590-95df-5bf8b3407009,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-90a797f9-73fa-4b91-8f6f-ac8321e91a43,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-66e3859c-f08c-4fad-b12b-7b19b13356a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36269,DS-d6d4d155-3eed-42f9-8d01-69ddeaf47f68,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-aef62b0f-9a21-4ecd-a03d-32957a9a05ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-f40eed25-efc6-4cfa-bfb3-456eb753f6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-edd84d46-886a-402b-a0af-35792b018dd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-832128017-172.17.0.2-1595562224994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41006,DS-cdf55b3b-ba41-4e8e-b30f-7f2603a59e18,DISK], DatanodeInfoWithStorage[127.0.0.1:39221,DS-850fcb10-30c9-4824-8677-6d47c698c35d,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-ece481b9-007f-46a4-bd44-922b6a9f9249,DISK], DatanodeInfoWithStorage[127.0.0.1:43513,DS-33cd455b-276d-4ac7-90bb-d821cfb1d041,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-dfa0a9df-c906-4ccb-a20d-39495e66e702,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-b5a95ffd-06c5-4e4c-b085-9e035783c48d,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-1a0f30a6-ef05-4842-9210-647e10eeca50,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-8c65932d-3a62-4bcc-a691-c890aacbc6aa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-832128017-172.17.0.2-1595562224994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41006,DS-cdf55b3b-ba41-4e8e-b30f-7f2603a59e18,DISK], DatanodeInfoWithStorage[127.0.0.1:39221,DS-850fcb10-30c9-4824-8677-6d47c698c35d,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-ece481b9-007f-46a4-bd44-922b6a9f9249,DISK], DatanodeInfoWithStorage[127.0.0.1:43513,DS-33cd455b-276d-4ac7-90bb-d821cfb1d041,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-dfa0a9df-c906-4ccb-a20d-39495e66e702,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-b5a95ffd-06c5-4e4c-b085-9e035783c48d,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-1a0f30a6-ef05-4842-9210-647e10eeca50,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-8c65932d-3a62-4bcc-a691-c890aacbc6aa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-254454504-172.17.0.2-1595562320427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44856,DS-5a783a4f-fcf1-46d2-84cf-2175b5b90ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:40962,DS-4b8977e8-3824-4516-80ae-8d86f1097cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-17415a6b-a267-478e-b76a-49a09e6ecefe,DISK], DatanodeInfoWithStorage[127.0.0.1:40678,DS-8f35c398-1093-43c2-9a10-d915719e4348,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-a0b49761-b811-46d7-b76f-870a6c3a1484,DISK], DatanodeInfoWithStorage[127.0.0.1:45640,DS-bfee46a2-90e2-427c-b4ca-212b21741e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-944404cf-f336-4e5d-8b4b-0d5d2d29dd73,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-78905800-a041-4814-82c6-dcdb889e356f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-254454504-172.17.0.2-1595562320427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44856,DS-5a783a4f-fcf1-46d2-84cf-2175b5b90ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:40962,DS-4b8977e8-3824-4516-80ae-8d86f1097cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-17415a6b-a267-478e-b76a-49a09e6ecefe,DISK], DatanodeInfoWithStorage[127.0.0.1:40678,DS-8f35c398-1093-43c2-9a10-d915719e4348,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-a0b49761-b811-46d7-b76f-870a6c3a1484,DISK], DatanodeInfoWithStorage[127.0.0.1:45640,DS-bfee46a2-90e2-427c-b4ca-212b21741e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-944404cf-f336-4e5d-8b4b-0d5d2d29dd73,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-78905800-a041-4814-82c6-dcdb889e356f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1306302159-172.17.0.2-1595562353711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42261,DS-df66b018-0736-4aab-bc39-c72c068178b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33917,DS-9f61309f-48f4-42ec-b468-2621b6651406,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-d92784f3-ab54-469a-b76d-6fb86c4f7c69,DISK], DatanodeInfoWithStorage[127.0.0.1:45319,DS-a2d0f8ad-b73d-4d9f-b5d8-498fa6fbcb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-42925563-acd2-42d9-8ef2-c90e0e2f8056,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-e8762a79-9355-4303-8550-ec7834540dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-2d9c42f5-7d54-4642-85e6-851328b39269,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-8516cc85-813e-47c5-9ac2-90da8221bd50,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1306302159-172.17.0.2-1595562353711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42261,DS-df66b018-0736-4aab-bc39-c72c068178b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33917,DS-9f61309f-48f4-42ec-b468-2621b6651406,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-d92784f3-ab54-469a-b76d-6fb86c4f7c69,DISK], DatanodeInfoWithStorage[127.0.0.1:45319,DS-a2d0f8ad-b73d-4d9f-b5d8-498fa6fbcb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-42925563-acd2-42d9-8ef2-c90e0e2f8056,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-e8762a79-9355-4303-8550-ec7834540dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-2d9c42f5-7d54-4642-85e6-851328b39269,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-8516cc85-813e-47c5-9ac2-90da8221bd50,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-977447992-172.17.0.2-1595562769426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37873,DS-dce075fd-a458-4efa-bf2f-7f493ba41be9,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-f5f5ed76-2f1d-46a2-8b0d-2dd50d1ea103,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-b5eb9165-7f87-4ba0-9036-a3c70cd04712,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-6cbc3b81-5f7e-4e59-8fb7-b5a62c54c6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-e45a6b87-b287-4131-9603-da9edc4c56d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-7fb2f6bd-a4f9-4e3f-be18-1b9bf6b617f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-b5d95b7b-650b-4b0d-9b9c-6c6c7757ce9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-014fdaf0-d0fa-4a7a-a95a-49e9b45fec04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-977447992-172.17.0.2-1595562769426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37873,DS-dce075fd-a458-4efa-bf2f-7f493ba41be9,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-f5f5ed76-2f1d-46a2-8b0d-2dd50d1ea103,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-b5eb9165-7f87-4ba0-9036-a3c70cd04712,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-6cbc3b81-5f7e-4e59-8fb7-b5a62c54c6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-e45a6b87-b287-4131-9603-da9edc4c56d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-7fb2f6bd-a4f9-4e3f-be18-1b9bf6b617f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-b5d95b7b-650b-4b0d-9b9c-6c6c7757ce9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-014fdaf0-d0fa-4a7a-a95a-49e9b45fec04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 18 out of 50
result: false positive !!!
Total execution time in seconds : 5652
