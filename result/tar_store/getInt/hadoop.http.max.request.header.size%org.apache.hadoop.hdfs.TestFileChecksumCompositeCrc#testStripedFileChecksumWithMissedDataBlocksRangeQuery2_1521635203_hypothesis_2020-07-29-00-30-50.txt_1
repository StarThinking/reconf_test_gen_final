reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1120495801-172.17.0.21-1595983012184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41135,DS-5d0ab1d0-e19d-4b80-b683-ab77634bd0db,DISK], DatanodeInfoWithStorage[127.0.0.1:42565,DS-2681bc8d-a81b-477b-8f35-e94b1c2fd69b,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-e432662b-3c88-4c8a-968e-b1b6c4d52ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-3855f909-10e3-4771-8547-e0e569bb02af,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-69e34e36-05b1-4fa0-bc64-1f3575b22e29,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-3239ae57-68a5-44f2-a29d-68de32590f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-fbd4a3c9-6df7-48de-af78-6be17ef98da1,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-e81036e6-0c88-42fe-b20e-4135dbd2c80c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1120495801-172.17.0.21-1595983012184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41135,DS-5d0ab1d0-e19d-4b80-b683-ab77634bd0db,DISK], DatanodeInfoWithStorage[127.0.0.1:42565,DS-2681bc8d-a81b-477b-8f35-e94b1c2fd69b,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-e432662b-3c88-4c8a-968e-b1b6c4d52ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-3855f909-10e3-4771-8547-e0e569bb02af,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-69e34e36-05b1-4fa0-bc64-1f3575b22e29,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-3239ae57-68a5-44f2-a29d-68de32590f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-fbd4a3c9-6df7-48de-af78-6be17ef98da1,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-e81036e6-0c88-42fe-b20e-4135dbd2c80c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1951333776-172.17.0.21-1595983415228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46870,DS-e5c4b609-419a-4dd9-988d-3ef1563a2c54,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-22333ec7-2fa5-4bcb-9ff7-b91252c17cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-99543370-1ff4-4491-9855-3c061a0f9df0,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-97b24cbe-c9f4-4d1d-b929-41f215ddb434,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-e41c204b-be26-472a-a7f0-dd4bd94de2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39691,DS-6d34688d-5678-421e-a26c-5706542a7819,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-63a66e56-c7ff-452d-bd6f-fddf57323611,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-878a808b-f644-45c0-932c-fc5c6147cda0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1951333776-172.17.0.21-1595983415228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46870,DS-e5c4b609-419a-4dd9-988d-3ef1563a2c54,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-22333ec7-2fa5-4bcb-9ff7-b91252c17cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-99543370-1ff4-4491-9855-3c061a0f9df0,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-97b24cbe-c9f4-4d1d-b929-41f215ddb434,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-e41c204b-be26-472a-a7f0-dd4bd94de2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39691,DS-6d34688d-5678-421e-a26c-5706542a7819,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-63a66e56-c7ff-452d-bd6f-fddf57323611,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-878a808b-f644-45c0-932c-fc5c6147cda0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-456803796-172.17.0.21-1595983678494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35263,DS-efa1b6b3-5d54-4b49-930a-f4051addda03,DISK], DatanodeInfoWithStorage[127.0.0.1:44782,DS-fcca5270-45b0-47d1-a081-e9bcde3e3869,DISK], DatanodeInfoWithStorage[127.0.0.1:37729,DS-19fbe21e-5c24-4385-bdcf-d160dd2601b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-33d875c8-8d76-4fa4-813b-70d0d944c36d,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-7b18a142-adf0-48e0-bb84-2d1328bc92b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-3d406c58-9b0a-4512-9532-3c2141a880ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-47ecaea2-7f4a-4c0a-9543-b1c4bb5bdc13,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-a28328f8-25ca-4529-8fc9-7140ff5f1041,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-456803796-172.17.0.21-1595983678494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35263,DS-efa1b6b3-5d54-4b49-930a-f4051addda03,DISK], DatanodeInfoWithStorage[127.0.0.1:44782,DS-fcca5270-45b0-47d1-a081-e9bcde3e3869,DISK], DatanodeInfoWithStorage[127.0.0.1:37729,DS-19fbe21e-5c24-4385-bdcf-d160dd2601b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-33d875c8-8d76-4fa4-813b-70d0d944c36d,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-7b18a142-adf0-48e0-bb84-2d1328bc92b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-3d406c58-9b0a-4512-9532-3c2141a880ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-47ecaea2-7f4a-4c0a-9543-b1c4bb5bdc13,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-a28328f8-25ca-4529-8fc9-7140ff5f1041,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2012887157-172.17.0.21-1595983715078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35243,DS-2a6a1f83-fdba-4860-aaba-caf128b414c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-d5b4a371-fd87-4023-a401-2b68011f6ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-669e01c8-ef5d-421f-80fd-4b7ab4625390,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-a3cae091-b94f-4357-9455-553daae0ca0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-b3abb126-e8a2-46b1-bb60-835f53edc0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38983,DS-e9535ad3-15b6-4644-b95e-019f41980be9,DISK], DatanodeInfoWithStorage[127.0.0.1:40132,DS-a7582837-b602-4f67-a3aa-5d16c2e49ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-7da9e026-787e-4247-9df5-8d433999503c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2012887157-172.17.0.21-1595983715078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35243,DS-2a6a1f83-fdba-4860-aaba-caf128b414c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-d5b4a371-fd87-4023-a401-2b68011f6ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-669e01c8-ef5d-421f-80fd-4b7ab4625390,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-a3cae091-b94f-4357-9455-553daae0ca0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-b3abb126-e8a2-46b1-bb60-835f53edc0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38983,DS-e9535ad3-15b6-4644-b95e-019f41980be9,DISK], DatanodeInfoWithStorage[127.0.0.1:40132,DS-a7582837-b602-4f67-a3aa-5d16c2e49ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-7da9e026-787e-4247-9df5-8d433999503c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1988417800-172.17.0.21-1595983928491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43397,DS-3907b537-7811-4774-80f1-529d269c4702,DISK], DatanodeInfoWithStorage[127.0.0.1:38233,DS-063aa2fe-9e5e-41a2-b8c3-6e3870c0b0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-65efa76f-d509-4ee8-9e8d-fd89dc802199,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-a1ad3dbb-b081-48dc-80ee-c7a430f4cf81,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-c00ae898-0113-4a95-8200-bfabc6bd7bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-00e2b682-8248-42d3-b8a1-2a65b7ccadf1,DISK], DatanodeInfoWithStorage[127.0.0.1:46342,DS-f702402d-7334-41c7-880e-d314a2a2cf8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-fef7153b-d20f-4d9c-aed7-2476e4e014ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1988417800-172.17.0.21-1595983928491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43397,DS-3907b537-7811-4774-80f1-529d269c4702,DISK], DatanodeInfoWithStorage[127.0.0.1:38233,DS-063aa2fe-9e5e-41a2-b8c3-6e3870c0b0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-65efa76f-d509-4ee8-9e8d-fd89dc802199,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-a1ad3dbb-b081-48dc-80ee-c7a430f4cf81,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-c00ae898-0113-4a95-8200-bfabc6bd7bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-00e2b682-8248-42d3-b8a1-2a65b7ccadf1,DISK], DatanodeInfoWithStorage[127.0.0.1:46342,DS-f702402d-7334-41c7-880e-d314a2a2cf8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-fef7153b-d20f-4d9c-aed7-2476e4e014ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1358505062-172.17.0.21-1595984766894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46395,DS-2613b410-0309-4e45-8b9d-561c439b0d64,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-278542dd-e470-4f7e-889b-398172e5269a,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-5e887559-7178-4ba8-a639-4272314a5d10,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-1f2ece98-37ab-4f47-a1cd-2a49198c14fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-5436f61a-a204-4be5-80bf-a12e531dcc16,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-9c2afab1-f5b8-4dfc-8884-cd725e973357,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-0bd8d39f-d2db-4e39-8fc8-66e072e007c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-cd3f183d-dec4-44d2-ba04-3acc571d2656,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1358505062-172.17.0.21-1595984766894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46395,DS-2613b410-0309-4e45-8b9d-561c439b0d64,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-278542dd-e470-4f7e-889b-398172e5269a,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-5e887559-7178-4ba8-a639-4272314a5d10,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-1f2ece98-37ab-4f47-a1cd-2a49198c14fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-5436f61a-a204-4be5-80bf-a12e531dcc16,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-9c2afab1-f5b8-4dfc-8884-cd725e973357,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-0bd8d39f-d2db-4e39-8fc8-66e072e007c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-cd3f183d-dec4-44d2-ba04-3acc571d2656,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2070578447-172.17.0.21-1595985821162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34909,DS-d770a81e-fddb-47d3-aa75-2c50fadc853f,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-a061db9a-71d7-48cd-a434-0266d92c4263,DISK], DatanodeInfoWithStorage[127.0.0.1:33339,DS-7b37f3c4-8b40-457c-87f5-1cb1046f88c5,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-1db8a44f-28b3-40bd-91d6-a375306a4c18,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-51cb4645-b184-4f0a-ab85-bc3635e312ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33553,DS-2976d781-6c12-4f78-9fa6-4cac217e4a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-96f36d79-ebfd-425b-824f-ad1cbf0edb89,DISK], DatanodeInfoWithStorage[127.0.0.1:40017,DS-490c3b6e-68d1-4eb6-b238-dd40592212c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2070578447-172.17.0.21-1595985821162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34909,DS-d770a81e-fddb-47d3-aa75-2c50fadc853f,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-a061db9a-71d7-48cd-a434-0266d92c4263,DISK], DatanodeInfoWithStorage[127.0.0.1:33339,DS-7b37f3c4-8b40-457c-87f5-1cb1046f88c5,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-1db8a44f-28b3-40bd-91d6-a375306a4c18,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-51cb4645-b184-4f0a-ab85-bc3635e312ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33553,DS-2976d781-6c12-4f78-9fa6-4cac217e4a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-96f36d79-ebfd-425b-824f-ad1cbf0edb89,DISK], DatanodeInfoWithStorage[127.0.0.1:40017,DS-490c3b6e-68d1-4eb6-b238-dd40592212c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-622655709-172.17.0.21-1595986538380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44735,DS-ead1a5f6-3342-4630-bb81-4eea9d2b870f,DISK], DatanodeInfoWithStorage[127.0.0.1:33086,DS-c272346b-73c9-4a5c-956b-9eb32c6670ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46697,DS-b5742c58-cd97-465c-a380-8d4ccead8317,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-7524c978-efa1-406c-9cc2-33ce1f06e565,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-f2a8ec01-99d9-4952-9f9a-acca07dde559,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-5a1a179c-36db-4761-8887-55f66cb1a2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-0c2ee959-5af1-499d-8a27-1f68b99f6e96,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-244ece0e-3536-4f7e-a407-2f0df8d493dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-622655709-172.17.0.21-1595986538380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44735,DS-ead1a5f6-3342-4630-bb81-4eea9d2b870f,DISK], DatanodeInfoWithStorage[127.0.0.1:33086,DS-c272346b-73c9-4a5c-956b-9eb32c6670ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46697,DS-b5742c58-cd97-465c-a380-8d4ccead8317,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-7524c978-efa1-406c-9cc2-33ce1f06e565,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-f2a8ec01-99d9-4952-9f9a-acca07dde559,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-5a1a179c-36db-4761-8887-55f66cb1a2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-0c2ee959-5af1-499d-8a27-1f68b99f6e96,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-244ece0e-3536-4f7e-a407-2f0df8d493dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-215727154-172.17.0.21-1595986609493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43947,DS-b9acbe7f-da9b-422c-8476-1d1e30ba6034,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-2e3eaa5b-48e5-4584-a0ae-885d84b3d4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-e5eb1c33-511d-4768-90ae-af6ec9eb2991,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-54abda55-c203-4dbf-8235-2017e56da97b,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-f9deb347-01c2-48a9-8a6a-1e2247bdeb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-6bac6ef7-58d1-4940-a529-1640bfe1b29d,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-d5059e8e-ec80-4e2b-84cd-2852f61de2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-9284af98-a0f6-4e5a-a8bf-a74328b71168,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-215727154-172.17.0.21-1595986609493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43947,DS-b9acbe7f-da9b-422c-8476-1d1e30ba6034,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-2e3eaa5b-48e5-4584-a0ae-885d84b3d4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-e5eb1c33-511d-4768-90ae-af6ec9eb2991,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-54abda55-c203-4dbf-8235-2017e56da97b,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-f9deb347-01c2-48a9-8a6a-1e2247bdeb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-6bac6ef7-58d1-4940-a529-1640bfe1b29d,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-d5059e8e-ec80-4e2b-84cd-2852f61de2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-9284af98-a0f6-4e5a-a8bf-a74328b71168,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-37528327-172.17.0.21-1595986795703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42542,DS-1b511be6-da4a-44dc-9bd8-505fcabd57e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-7b12aa6f-de97-4faa-8715-e41a3891c276,DISK], DatanodeInfoWithStorage[127.0.0.1:40711,DS-3bfe3659-db62-476b-b691-9a71c279bba6,DISK], DatanodeInfoWithStorage[127.0.0.1:42656,DS-ce69204f-0509-4a57-849c-94b53e3de373,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-971b933d-e99b-4135-adeb-3c9b6eb09b68,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-d9291e77-1e69-4f20-be65-e0006f902de6,DISK], DatanodeInfoWithStorage[127.0.0.1:41843,DS-98d3a194-e1a6-4fce-9911-af25a5e1aaf4,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-4a89f98f-1a07-4978-80ca-6c4317151398,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-37528327-172.17.0.21-1595986795703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42542,DS-1b511be6-da4a-44dc-9bd8-505fcabd57e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-7b12aa6f-de97-4faa-8715-e41a3891c276,DISK], DatanodeInfoWithStorage[127.0.0.1:40711,DS-3bfe3659-db62-476b-b691-9a71c279bba6,DISK], DatanodeInfoWithStorage[127.0.0.1:42656,DS-ce69204f-0509-4a57-849c-94b53e3de373,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-971b933d-e99b-4135-adeb-3c9b6eb09b68,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-d9291e77-1e69-4f20-be65-e0006f902de6,DISK], DatanodeInfoWithStorage[127.0.0.1:41843,DS-98d3a194-e1a6-4fce-9911-af25a5e1aaf4,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-4a89f98f-1a07-4978-80ca-6c4317151398,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2136825762-172.17.0.21-1595987010863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43832,DS-78435e0e-9112-4590-bb4a-a10871e5fe0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-0be8d122-1649-4c1b-b7c6-048e4fb49c39,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-ebfbbab8-e13f-46b0-9ff2-e207c39cd24a,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-e26696d7-8724-48ad-950d-bf2fae0ae6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-232f85e9-e3b0-4440-81bc-d9e8a10b1211,DISK], DatanodeInfoWithStorage[127.0.0.1:40865,DS-5a04a1b5-61d7-41a6-b000-da86ed05b5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-736fafdb-328c-4c4e-b496-d22c3062d8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-d68e404c-e2ac-455c-bca0-11c6b4de8389,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2136825762-172.17.0.21-1595987010863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43832,DS-78435e0e-9112-4590-bb4a-a10871e5fe0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-0be8d122-1649-4c1b-b7c6-048e4fb49c39,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-ebfbbab8-e13f-46b0-9ff2-e207c39cd24a,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-e26696d7-8724-48ad-950d-bf2fae0ae6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-232f85e9-e3b0-4440-81bc-d9e8a10b1211,DISK], DatanodeInfoWithStorage[127.0.0.1:40865,DS-5a04a1b5-61d7-41a6-b000-da86ed05b5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-736fafdb-328c-4c4e-b496-d22c3062d8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-d68e404c-e2ac-455c-bca0-11c6b4de8389,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1850835276-172.17.0.21-1595987548348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41094,DS-fdd4aa1f-156b-4106-bcfb-84ed8fd58ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-5c881145-6584-4dd7-a425-790b770f3aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-8b70cb52-4057-4cb5-b102-be0ffa20f2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-79034013-7399-4e47-b5cb-2e96267f2c97,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-d0c0cd09-a8da-4aaf-bdfd-41b0b5cdfd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40907,DS-3bd3b31d-8b0a-4d66-8293-17816ef2d449,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-1004679b-2f56-4562-8dde-53fc82b38768,DISK], DatanodeInfoWithStorage[127.0.0.1:42670,DS-f50e5d81-15eb-4199-a66a-3821adbc9361,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1850835276-172.17.0.21-1595987548348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41094,DS-fdd4aa1f-156b-4106-bcfb-84ed8fd58ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-5c881145-6584-4dd7-a425-790b770f3aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-8b70cb52-4057-4cb5-b102-be0ffa20f2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-79034013-7399-4e47-b5cb-2e96267f2c97,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-d0c0cd09-a8da-4aaf-bdfd-41b0b5cdfd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40907,DS-3bd3b31d-8b0a-4d66-8293-17816ef2d449,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-1004679b-2f56-4562-8dde-53fc82b38768,DISK], DatanodeInfoWithStorage[127.0.0.1:42670,DS-f50e5d81-15eb-4199-a66a-3821adbc9361,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1448871315-172.17.0.21-1595987682844:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45440,DS-a2676c78-51cf-4cc2-a229-d363ed5a3976,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-c40c36c7-4182-43fa-90f5-63d28507d9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-058660b4-07c8-4f46-9d68-1961f76d1525,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-bbe40fe6-0a7a-444e-bfe8-88616b15800f,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-857e0280-d437-4379-bf99-b7a6657c6b25,DISK], DatanodeInfoWithStorage[127.0.0.1:32819,DS-0874f484-84f2-4652-af2b-ebaf4c3a4b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33163,DS-a1cd3755-896e-4127-a98f-5490b0716c02,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-2ba492d4-a4b1-439f-b81b-348fa901f444,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1448871315-172.17.0.21-1595987682844:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45440,DS-a2676c78-51cf-4cc2-a229-d363ed5a3976,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-c40c36c7-4182-43fa-90f5-63d28507d9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-058660b4-07c8-4f46-9d68-1961f76d1525,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-bbe40fe6-0a7a-444e-bfe8-88616b15800f,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-857e0280-d437-4379-bf99-b7a6657c6b25,DISK], DatanodeInfoWithStorage[127.0.0.1:32819,DS-0874f484-84f2-4652-af2b-ebaf4c3a4b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33163,DS-a1cd3755-896e-4127-a98f-5490b0716c02,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-2ba492d4-a4b1-439f-b81b-348fa901f444,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5456
