reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-519147836-172.17.0.8-1596001495006:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45421,DS-ebc5d7f0-e31f-4a41-bf31-488c8c439f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-4c97bd7d-b31f-4581-8209-fcadbe802bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-1c7c25da-c9e6-496f-a44c-c86a3348e748,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-e4edae6d-dcfe-402e-b029-436b9e686e90,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-3e42ab01-904f-40b5-87ae-c4e154e42318,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-58cc3a13-f237-42d0-862d-ca4bf50315d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-400cd2a9-d2d7-47ad-8bf3-a9034370769d,DISK], DatanodeInfoWithStorage[127.0.0.1:40451,DS-5e82ae15-aacb-4816-a17a-6b118a9fe16f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-519147836-172.17.0.8-1596001495006:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45421,DS-ebc5d7f0-e31f-4a41-bf31-488c8c439f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-4c97bd7d-b31f-4581-8209-fcadbe802bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-1c7c25da-c9e6-496f-a44c-c86a3348e748,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-e4edae6d-dcfe-402e-b029-436b9e686e90,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-3e42ab01-904f-40b5-87ae-c4e154e42318,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-58cc3a13-f237-42d0-862d-ca4bf50315d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-400cd2a9-d2d7-47ad-8bf3-a9034370769d,DISK], DatanodeInfoWithStorage[127.0.0.1:40451,DS-5e82ae15-aacb-4816-a17a-6b118a9fe16f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1763665109-172.17.0.8-1596001948131:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46144,DS-86937fd1-fc3a-490c-b82a-6b477dbd6fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-12535573-ef5b-4a8d-9472-8c0303708aae,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-e370a22b-479e-4f71-bc0e-e006cb3fb5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-a243779a-8be7-412b-aa1c-af453841a87c,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-ca39008d-196c-441c-9e51-4889383ba365,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-a81d6fcd-4489-44d9-97c5-2dfc67a12a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38523,DS-bb88e663-267f-4e56-921d-d7c797a2fd29,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-6b3dcb55-4752-4032-92de-34ef9e54b97a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1763665109-172.17.0.8-1596001948131:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46144,DS-86937fd1-fc3a-490c-b82a-6b477dbd6fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-12535573-ef5b-4a8d-9472-8c0303708aae,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-e370a22b-479e-4f71-bc0e-e006cb3fb5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-a243779a-8be7-412b-aa1c-af453841a87c,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-ca39008d-196c-441c-9e51-4889383ba365,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-a81d6fcd-4489-44d9-97c5-2dfc67a12a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38523,DS-bb88e663-267f-4e56-921d-d7c797a2fd29,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-6b3dcb55-4752-4032-92de-34ef9e54b97a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-278355858-172.17.0.8-1596002071998:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38856,DS-a1498989-b4ca-41a9-a160-8badadc13322,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-c4423a61-f30c-4971-ba64-731960c293f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-c3b02afb-d2c4-4d4c-8aa9-1bd2c7929430,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-cbc4af55-866c-430e-ab6f-683580eb937d,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-7079071f-e5f8-4bfc-91a5-e20d025eff51,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-18aa5dc3-d7c4-4494-9ef7-f821a0085a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41254,DS-f6f1ad11-4c52-458d-b081-229c8123706b,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-49cbba9d-4da1-4f81-a024-ae22e4774ebf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-278355858-172.17.0.8-1596002071998:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38856,DS-a1498989-b4ca-41a9-a160-8badadc13322,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-c4423a61-f30c-4971-ba64-731960c293f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-c3b02afb-d2c4-4d4c-8aa9-1bd2c7929430,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-cbc4af55-866c-430e-ab6f-683580eb937d,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-7079071f-e5f8-4bfc-91a5-e20d025eff51,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-18aa5dc3-d7c4-4494-9ef7-f821a0085a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41254,DS-f6f1ad11-4c52-458d-b081-229c8123706b,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-49cbba9d-4da1-4f81-a024-ae22e4774ebf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-976759381-172.17.0.8-1596002106162:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37092,DS-1b850b38-8aa4-499f-a975-2d5daf93678d,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-35084b00-66b8-42d5-a1d1-b57d926b8422,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-f458b97a-1323-42db-8b97-7f9e02ac163b,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-1637f793-bb6e-4a71-b018-29c5c9590bee,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-4cd82779-2ac9-46df-970c-5bb3d98f8c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-d235dbc3-f5ac-4d9d-a50d-dc37a0f38d32,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-8772c19b-80bf-4be9-8e76-2193c2fb9597,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-dfc32d4c-2dd9-4c06-8e71-6396e5e4f5c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-976759381-172.17.0.8-1596002106162:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37092,DS-1b850b38-8aa4-499f-a975-2d5daf93678d,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-35084b00-66b8-42d5-a1d1-b57d926b8422,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-f458b97a-1323-42db-8b97-7f9e02ac163b,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-1637f793-bb6e-4a71-b018-29c5c9590bee,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-4cd82779-2ac9-46df-970c-5bb3d98f8c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-d235dbc3-f5ac-4d9d-a50d-dc37a0f38d32,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-8772c19b-80bf-4be9-8e76-2193c2fb9597,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-dfc32d4c-2dd9-4c06-8e71-6396e5e4f5c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-824902533-172.17.0.8-1596002664454:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45031,DS-c4bb1e23-d70d-4613-a6d7-a600d14249b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-67154462-701a-4b09-8e57-9da81fc46551,DISK], DatanodeInfoWithStorage[127.0.0.1:36919,DS-8f91915e-41fa-4f39-a9c2-b7d4d2a33790,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-4dbaca2c-f0be-4193-bba7-ae2ae0157309,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-3cf4e619-f5e8-4d84-9906-5124576437e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-d33ee3be-8b62-40ac-bbd2-a6682c0fa20c,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-b8630b7a-4442-4401-b052-a34d1cec99bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-d226fc2f-6803-48c0-a6e1-7ec71e48d1bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-824902533-172.17.0.8-1596002664454:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45031,DS-c4bb1e23-d70d-4613-a6d7-a600d14249b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-67154462-701a-4b09-8e57-9da81fc46551,DISK], DatanodeInfoWithStorage[127.0.0.1:36919,DS-8f91915e-41fa-4f39-a9c2-b7d4d2a33790,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-4dbaca2c-f0be-4193-bba7-ae2ae0157309,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-3cf4e619-f5e8-4d84-9906-5124576437e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-d33ee3be-8b62-40ac-bbd2-a6682c0fa20c,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-b8630b7a-4442-4401-b052-a34d1cec99bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-d226fc2f-6803-48c0-a6e1-7ec71e48d1bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1597073930-172.17.0.8-1596002803848:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36393,DS-db982b4b-b799-47ac-842e-73066e3b5f98,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-2434436c-b2b2-4d5f-ab28-ea00e3b8c734,DISK], DatanodeInfoWithStorage[127.0.0.1:44747,DS-c94f400e-5ec2-4054-a5a3-236082735c93,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-6edf27d0-440f-49e4-aa86-eb84dfa3e7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-481b152d-3258-4e70-8099-801a771cbd78,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-c5e4ac40-e5b5-4b9a-81ee-a71e0f807128,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-7c047f3b-5f4a-48c8-ab89-dc7a4471bd49,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-ef19d464-8f31-4b6f-a706-757245861c63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1597073930-172.17.0.8-1596002803848:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36393,DS-db982b4b-b799-47ac-842e-73066e3b5f98,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-2434436c-b2b2-4d5f-ab28-ea00e3b8c734,DISK], DatanodeInfoWithStorage[127.0.0.1:44747,DS-c94f400e-5ec2-4054-a5a3-236082735c93,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-6edf27d0-440f-49e4-aa86-eb84dfa3e7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-481b152d-3258-4e70-8099-801a771cbd78,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-c5e4ac40-e5b5-4b9a-81ee-a71e0f807128,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-7c047f3b-5f4a-48c8-ab89-dc7a4471bd49,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-ef19d464-8f31-4b6f-a706-757245861c63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-991459721-172.17.0.8-1596003859591:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40629,DS-553c12a7-4251-40c2-8910-95100b2cde16,DISK], DatanodeInfoWithStorage[127.0.0.1:35761,DS-f12d2371-9032-42b7-bfdc-239992403c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-caf9b487-3843-4bba-8758-e966c9231a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-31bf5222-d898-420c-86cb-df942293cfea,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-6b5984fa-6fdc-4486-8567-793f01178076,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-39109355-20b6-49f6-9513-c569daf93720,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-63f27cfe-b6e1-4397-8b1b-822b14edb5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-9417a69c-760d-420b-9dd0-9a489bafc87d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-991459721-172.17.0.8-1596003859591:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40629,DS-553c12a7-4251-40c2-8910-95100b2cde16,DISK], DatanodeInfoWithStorage[127.0.0.1:35761,DS-f12d2371-9032-42b7-bfdc-239992403c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-caf9b487-3843-4bba-8758-e966c9231a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-31bf5222-d898-420c-86cb-df942293cfea,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-6b5984fa-6fdc-4486-8567-793f01178076,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-39109355-20b6-49f6-9513-c569daf93720,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-63f27cfe-b6e1-4397-8b1b-822b14edb5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-9417a69c-760d-420b-9dd0-9a489bafc87d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-950828084-172.17.0.8-1596004478868:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43842,DS-c9220db4-93ee-4908-89e3-2983dfc19f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35686,DS-16459c70-2951-430a-a7dd-d618e5061164,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-d4e2036e-de05-47fc-9bcb-bba557de7eba,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-7f0d94c1-048b-4a74-9dc0-13279c96a61b,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-02490d67-3934-4d84-abf7-97b1dc9c60c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-1bd1fe8f-d19e-476e-847c-6521e4792ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:40853,DS-8a5af645-2646-4901-9ca1-ae18f21dedcd,DISK], DatanodeInfoWithStorage[127.0.0.1:37673,DS-d1fa0b97-1057-4516-b022-f2bf4570016c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-950828084-172.17.0.8-1596004478868:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43842,DS-c9220db4-93ee-4908-89e3-2983dfc19f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35686,DS-16459c70-2951-430a-a7dd-d618e5061164,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-d4e2036e-de05-47fc-9bcb-bba557de7eba,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-7f0d94c1-048b-4a74-9dc0-13279c96a61b,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-02490d67-3934-4d84-abf7-97b1dc9c60c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-1bd1fe8f-d19e-476e-847c-6521e4792ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:40853,DS-8a5af645-2646-4901-9ca1-ae18f21dedcd,DISK], DatanodeInfoWithStorage[127.0.0.1:37673,DS-d1fa0b97-1057-4516-b022-f2bf4570016c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1606114211-172.17.0.8-1596005738981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39330,DS-b1f7c810-a750-42f0-8698-2e8a6f3004e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44780,DS-040a33a0-07a5-45e1-a3a5-3b24e26030c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-8c626924-8bc3-4040-9568-8478eaffd18c,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-f3c9c511-45b6-4193-9f11-f738ab89f382,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-9a5e0c90-b68a-48f0-9ad1-3ffbfbc20d60,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-02888cfd-ffeb-4e32-96cf-fd3b15f27cea,DISK], DatanodeInfoWithStorage[127.0.0.1:34596,DS-411b69cc-289b-4774-a66f-0ed790bc7cac,DISK], DatanodeInfoWithStorage[127.0.0.1:43390,DS-63db8a49-a2c9-441b-ac18-279e91cc45c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1606114211-172.17.0.8-1596005738981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39330,DS-b1f7c810-a750-42f0-8698-2e8a6f3004e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44780,DS-040a33a0-07a5-45e1-a3a5-3b24e26030c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-8c626924-8bc3-4040-9568-8478eaffd18c,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-f3c9c511-45b6-4193-9f11-f738ab89f382,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-9a5e0c90-b68a-48f0-9ad1-3ffbfbc20d60,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-02888cfd-ffeb-4e32-96cf-fd3b15f27cea,DISK], DatanodeInfoWithStorage[127.0.0.1:34596,DS-411b69cc-289b-4774-a66f-0ed790bc7cac,DISK], DatanodeInfoWithStorage[127.0.0.1:43390,DS-63db8a49-a2c9-441b-ac18-279e91cc45c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5346
