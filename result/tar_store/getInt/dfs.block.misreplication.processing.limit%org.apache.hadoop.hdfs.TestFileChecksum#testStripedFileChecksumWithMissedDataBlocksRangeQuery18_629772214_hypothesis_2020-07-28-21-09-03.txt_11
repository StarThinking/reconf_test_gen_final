reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2063586446-172.17.0.6-1595970825283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42632,DS-ec17d7fa-6caa-41a5-92a8-ed1a4e360c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-055d73d0-ab55-40ae-b788-fb9f6a965987,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-3b855664-f167-4a35-be02-85b7d8e90f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-ccffbd95-9548-4f78-a593-8d232ac8d551,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-552e3409-4a85-4bfa-b3f3-c0448a08ae99,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-582a9665-aa68-41d2-bd59-6f2960c6aca6,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-eb78bb02-665e-4849-a781-aa6463ffac02,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-4515184e-cb79-46b0-950b-84eea4ae33aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2063586446-172.17.0.6-1595970825283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42632,DS-ec17d7fa-6caa-41a5-92a8-ed1a4e360c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-055d73d0-ab55-40ae-b788-fb9f6a965987,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-3b855664-f167-4a35-be02-85b7d8e90f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-ccffbd95-9548-4f78-a593-8d232ac8d551,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-552e3409-4a85-4bfa-b3f3-c0448a08ae99,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-582a9665-aa68-41d2-bd59-6f2960c6aca6,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-eb78bb02-665e-4849-a781-aa6463ffac02,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-4515184e-cb79-46b0-950b-84eea4ae33aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1138092462-172.17.0.6-1595971016760:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37461,DS-4129c853-2658-4454-8364-17758e6323a2,DISK], DatanodeInfoWithStorage[127.0.0.1:32786,DS-059b0b49-9934-4b5b-9a8d-e0793d9bc0af,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-d7a03a74-2704-47de-949e-565f48c304c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-0e36064f-ce64-45a4-aaad-2d4035469fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-0b5293f6-d3f0-4e0f-8054-c51ce77e40e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-2fad2ff4-92d6-4ecc-8377-28d1d8da0d47,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-4d62f0c8-c84d-40ee-84a2-686291196405,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-dbc6b0ea-ae24-4bc6-b982-5aff6b145d99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1138092462-172.17.0.6-1595971016760:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37461,DS-4129c853-2658-4454-8364-17758e6323a2,DISK], DatanodeInfoWithStorage[127.0.0.1:32786,DS-059b0b49-9934-4b5b-9a8d-e0793d9bc0af,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-d7a03a74-2704-47de-949e-565f48c304c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-0e36064f-ce64-45a4-aaad-2d4035469fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-0b5293f6-d3f0-4e0f-8054-c51ce77e40e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-2fad2ff4-92d6-4ecc-8377-28d1d8da0d47,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-4d62f0c8-c84d-40ee-84a2-686291196405,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-dbc6b0ea-ae24-4bc6-b982-5aff6b145d99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1633896094-172.17.0.6-1595972257467:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43566,DS-57e8a555-26fd-44db-aee8-30d444ae9986,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-a40469d4-4ed0-4a34-bbf2-a42a443b4f38,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-fd4c4154-91eb-425f-bb02-16e7c964f4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-b20644e2-f392-4392-8fc7-bdacb8ad8ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-56fca800-4608-4395-8af7-3b1d08f69093,DISK], DatanodeInfoWithStorage[127.0.0.1:38764,DS-be953bcc-0442-45ee-8428-b603f6335c49,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-93e83c88-991c-4ce2-b1c5-4bb615ac3e88,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-160f57d8-a43d-4a71-b74a-9d7083542848,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1633896094-172.17.0.6-1595972257467:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43566,DS-57e8a555-26fd-44db-aee8-30d444ae9986,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-a40469d4-4ed0-4a34-bbf2-a42a443b4f38,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-fd4c4154-91eb-425f-bb02-16e7c964f4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-b20644e2-f392-4392-8fc7-bdacb8ad8ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-56fca800-4608-4395-8af7-3b1d08f69093,DISK], DatanodeInfoWithStorage[127.0.0.1:38764,DS-be953bcc-0442-45ee-8428-b603f6335c49,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-93e83c88-991c-4ce2-b1c5-4bb615ac3e88,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-160f57d8-a43d-4a71-b74a-9d7083542848,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1890720783-172.17.0.6-1595972317383:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43235,DS-7ac6ba30-3120-4a24-8b1b-dc72dab276bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-f0774a7b-11a1-46a5-bebd-1095aebdff08,DISK], DatanodeInfoWithStorage[127.0.0.1:46326,DS-a88bee7a-dd60-4608-a17a-a4f8a3f67288,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-3fda1fb8-6461-4304-a0d1-03e3b22f8d59,DISK], DatanodeInfoWithStorage[127.0.0.1:45521,DS-2797dc1b-1356-4436-9f04-62fdc0f7cc20,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-f9af0c30-bb0d-48b3-8418-994b6216ff1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-b7f68383-23d0-4d07-80ed-2bfd232e0f36,DISK], DatanodeInfoWithStorage[127.0.0.1:34904,DS-226bdc91-65da-4d71-b4b7-41783f4cc498,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1890720783-172.17.0.6-1595972317383:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43235,DS-7ac6ba30-3120-4a24-8b1b-dc72dab276bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-f0774a7b-11a1-46a5-bebd-1095aebdff08,DISK], DatanodeInfoWithStorage[127.0.0.1:46326,DS-a88bee7a-dd60-4608-a17a-a4f8a3f67288,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-3fda1fb8-6461-4304-a0d1-03e3b22f8d59,DISK], DatanodeInfoWithStorage[127.0.0.1:45521,DS-2797dc1b-1356-4436-9f04-62fdc0f7cc20,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-f9af0c30-bb0d-48b3-8418-994b6216ff1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-b7f68383-23d0-4d07-80ed-2bfd232e0f36,DISK], DatanodeInfoWithStorage[127.0.0.1:34904,DS-226bdc91-65da-4d71-b4b7-41783f4cc498,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1311924375-172.17.0.6-1595972651240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43627,DS-41d44a3a-42a2-452f-8e05-9f74af7dbe21,DISK], DatanodeInfoWithStorage[127.0.0.1:40722,DS-d1d88f4d-b4dc-44c1-980b-d3f2ed13dc32,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-a5cc32fe-018e-4ea0-933a-c306173a9769,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-475b52f9-f0b2-4033-a0f6-096c664e5352,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-435977db-1bc1-4d32-aca0-ef78e24dfc3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-390bce1c-3de7-4398-9d3a-91a72a2fc619,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-690fc07f-713b-44fc-9403-716d47a5cab7,DISK], DatanodeInfoWithStorage[127.0.0.1:42990,DS-b1be6958-3e04-4be2-8d41-3d780cce966a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1311924375-172.17.0.6-1595972651240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43627,DS-41d44a3a-42a2-452f-8e05-9f74af7dbe21,DISK], DatanodeInfoWithStorage[127.0.0.1:40722,DS-d1d88f4d-b4dc-44c1-980b-d3f2ed13dc32,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-a5cc32fe-018e-4ea0-933a-c306173a9769,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-475b52f9-f0b2-4033-a0f6-096c664e5352,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-435977db-1bc1-4d32-aca0-ef78e24dfc3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-390bce1c-3de7-4398-9d3a-91a72a2fc619,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-690fc07f-713b-44fc-9403-716d47a5cab7,DISK], DatanodeInfoWithStorage[127.0.0.1:42990,DS-b1be6958-3e04-4be2-8d41-3d780cce966a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1024588133-172.17.0.6-1595972688753:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42568,DS-48d2c0e7-6120-49f3-997b-02b7acab11ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37440,DS-d00b4661-27b4-4e4a-a6d3-524cd6cff540,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-9c7ff68d-3186-4fbb-b497-19ff0351b09f,DISK], DatanodeInfoWithStorage[127.0.0.1:33546,DS-4e3e8d1d-2591-4384-8fad-7b4622bdb820,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-c2d1a1cc-dc52-4479-acaf-9081d6eceda0,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-6942dd2f-75fb-44fd-a328-c9ec57f8ef34,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-39424c4d-d420-4bbc-bbb6-208c1c9ddf80,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-ae584bd1-bf64-4f22-afcd-566e480b2666,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1024588133-172.17.0.6-1595972688753:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42568,DS-48d2c0e7-6120-49f3-997b-02b7acab11ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37440,DS-d00b4661-27b4-4e4a-a6d3-524cd6cff540,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-9c7ff68d-3186-4fbb-b497-19ff0351b09f,DISK], DatanodeInfoWithStorage[127.0.0.1:33546,DS-4e3e8d1d-2591-4384-8fad-7b4622bdb820,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-c2d1a1cc-dc52-4479-acaf-9081d6eceda0,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-6942dd2f-75fb-44fd-a328-c9ec57f8ef34,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-39424c4d-d420-4bbc-bbb6-208c1c9ddf80,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-ae584bd1-bf64-4f22-afcd-566e480b2666,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1196382077-172.17.0.6-1595972851809:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35266,DS-f340c243-0dbf-43e7-85e8-0b78ba8c8e58,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-1d8a3384-0668-44a9-bea5-4b86e27c6cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43906,DS-fc029134-03c7-431f-b873-060e741e475b,DISK], DatanodeInfoWithStorage[127.0.0.1:37933,DS-b9991b52-a968-450d-8db4-fa0a97a8fed5,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-17f232f2-d4cb-4f8b-b8da-e21421a8f160,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-06481c5b-97c2-4445-9cc7-f7b28695b37d,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-9f403575-c4d9-49ce-9144-937c1e780a00,DISK], DatanodeInfoWithStorage[127.0.0.1:38666,DS-0f90055f-6db4-4e22-8e3e-d52a29a1c383,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1196382077-172.17.0.6-1595972851809:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35266,DS-f340c243-0dbf-43e7-85e8-0b78ba8c8e58,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-1d8a3384-0668-44a9-bea5-4b86e27c6cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43906,DS-fc029134-03c7-431f-b873-060e741e475b,DISK], DatanodeInfoWithStorage[127.0.0.1:37933,DS-b9991b52-a968-450d-8db4-fa0a97a8fed5,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-17f232f2-d4cb-4f8b-b8da-e21421a8f160,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-06481c5b-97c2-4445-9cc7-f7b28695b37d,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-9f403575-c4d9-49ce-9144-937c1e780a00,DISK], DatanodeInfoWithStorage[127.0.0.1:38666,DS-0f90055f-6db4-4e22-8e3e-d52a29a1c383,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2127550637-172.17.0.6-1595972998191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36831,DS-ba8b4c51-ea62-4d64-9ab6-192e451635db,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-0e4f8405-a660-4853-b69f-6e6f5ddfdeb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37394,DS-9ffeeeb6-a132-479b-b21e-ec59390a7e69,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-174e2a22-b6db-4971-be58-1bbb07d07d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-92459071-9b71-4af1-9913-af025a779817,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-930fe1ef-ddf2-4c64-a9ea-8a3e142b6382,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-98add49c-f3a6-4e7d-81c5-51a67ce0273e,DISK], DatanodeInfoWithStorage[127.0.0.1:33831,DS-74e08dad-6b84-42d4-a4ac-9d74bb7ec840,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2127550637-172.17.0.6-1595972998191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36831,DS-ba8b4c51-ea62-4d64-9ab6-192e451635db,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-0e4f8405-a660-4853-b69f-6e6f5ddfdeb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37394,DS-9ffeeeb6-a132-479b-b21e-ec59390a7e69,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-174e2a22-b6db-4971-be58-1bbb07d07d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-92459071-9b71-4af1-9913-af025a779817,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-930fe1ef-ddf2-4c64-a9ea-8a3e142b6382,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-98add49c-f3a6-4e7d-81c5-51a67ce0273e,DISK], DatanodeInfoWithStorage[127.0.0.1:33831,DS-74e08dad-6b84-42d4-a4ac-9d74bb7ec840,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-113275297-172.17.0.6-1595973282080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40351,DS-5e9c593f-5ce4-4390-abd5-6dd40fe84fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-6d6be884-7da5-4d2e-a96e-f34129da4311,DISK], DatanodeInfoWithStorage[127.0.0.1:40113,DS-a5be4e48-1690-4b7d-a0f8-4786ac15cd18,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-00f716e9-3760-4387-aa83-6b6e786f1d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-1ea49162-b318-444f-83dc-bd7454d74d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-ae49f9a1-4ee3-4873-a922-5da599e571e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-4e8c5012-7665-449a-8fef-3e5e92fcfad3,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-4b55e221-1ff1-43e4-a35e-9ed568b2a98f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-113275297-172.17.0.6-1595973282080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40351,DS-5e9c593f-5ce4-4390-abd5-6dd40fe84fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-6d6be884-7da5-4d2e-a96e-f34129da4311,DISK], DatanodeInfoWithStorage[127.0.0.1:40113,DS-a5be4e48-1690-4b7d-a0f8-4786ac15cd18,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-00f716e9-3760-4387-aa83-6b6e786f1d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-1ea49162-b318-444f-83dc-bd7454d74d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-ae49f9a1-4ee3-4873-a922-5da599e571e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-4e8c5012-7665-449a-8fef-3e5e92fcfad3,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-4b55e221-1ff1-43e4-a35e-9ed568b2a98f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1553661112-172.17.0.6-1595974230706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38525,DS-89fe0b7c-b135-421f-8e56-cd2eb7359af3,DISK], DatanodeInfoWithStorage[127.0.0.1:33332,DS-7f10eb1c-aa2e-4625-90a6-1a5cf4879617,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-4908f73c-5cce-484e-939c-dd4299ea94df,DISK], DatanodeInfoWithStorage[127.0.0.1:35092,DS-31479d7e-823e-4747-ae8c-334d3142ec8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-bdc329b7-e84e-46e4-a60c-9b1402fc07fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-19049f68-d358-418d-85d9-ee5734ef4135,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-c1d39e2f-2802-402a-9bfe-d6a306fc4f76,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-3e61034b-db1b-4341-a5d3-b0e375691e2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1553661112-172.17.0.6-1595974230706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38525,DS-89fe0b7c-b135-421f-8e56-cd2eb7359af3,DISK], DatanodeInfoWithStorage[127.0.0.1:33332,DS-7f10eb1c-aa2e-4625-90a6-1a5cf4879617,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-4908f73c-5cce-484e-939c-dd4299ea94df,DISK], DatanodeInfoWithStorage[127.0.0.1:35092,DS-31479d7e-823e-4747-ae8c-334d3142ec8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-bdc329b7-e84e-46e4-a60c-9b1402fc07fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-19049f68-d358-418d-85d9-ee5734ef4135,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-c1d39e2f-2802-402a-9bfe-d6a306fc4f76,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-3e61034b-db1b-4341-a5d3-b0e375691e2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-969871094-172.17.0.6-1595974305689:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42783,DS-cdf27ece-55b6-4203-927a-ebd2ff044cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45837,DS-b44bd2b3-564e-4d8f-afff-a409cfe982f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-cf6728a4-51b5-48f6-bd79-5baa169f846b,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-3700f4af-e187-4c9e-939f-1ea6911f7e66,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-b343cbe8-931f-44de-9da9-872ed77b2d93,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-3634f50f-ac7c-415e-b561-6c1ff6f9971c,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-7cd88317-37e4-45a7-911b-d524b80eb187,DISK], DatanodeInfoWithStorage[127.0.0.1:32939,DS-74b5d18b-8915-4dfc-852a-a27c21cd5adf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-969871094-172.17.0.6-1595974305689:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42783,DS-cdf27ece-55b6-4203-927a-ebd2ff044cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45837,DS-b44bd2b3-564e-4d8f-afff-a409cfe982f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-cf6728a4-51b5-48f6-bd79-5baa169f846b,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-3700f4af-e187-4c9e-939f-1ea6911f7e66,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-b343cbe8-931f-44de-9da9-872ed77b2d93,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-3634f50f-ac7c-415e-b561-6c1ff6f9971c,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-7cd88317-37e4-45a7-911b-d524b80eb187,DISK], DatanodeInfoWithStorage[127.0.0.1:32939,DS-74b5d18b-8915-4dfc-852a-a27c21cd5adf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1282673955-172.17.0.6-1595974727614:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37899,DS-10453200-85f5-43e8-a9e0-21b9f32f1756,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-0ae9da36-ee15-4520-b7be-f4071fdd3615,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-e07a06c7-fdc7-493b-ba98-0337eff9394f,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-606cea4a-fa2d-4418-bc2d-759336195a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-6b389c9e-e786-40ab-8835-c36112b4e8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-486e241f-efce-4b97-a6be-59df3298b456,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-edf73e6e-5107-45aa-a144-646d0bd86974,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-a7206919-37de-4b27-b99f-e98ca2ae2d7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1282673955-172.17.0.6-1595974727614:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37899,DS-10453200-85f5-43e8-a9e0-21b9f32f1756,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-0ae9da36-ee15-4520-b7be-f4071fdd3615,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-e07a06c7-fdc7-493b-ba98-0337eff9394f,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-606cea4a-fa2d-4418-bc2d-759336195a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-6b389c9e-e786-40ab-8835-c36112b4e8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-486e241f-efce-4b97-a6be-59df3298b456,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-edf73e6e-5107-45aa-a144-646d0bd86974,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-a7206919-37de-4b27-b99f-e98ca2ae2d7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-787951741-172.17.0.6-1595974763706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42226,DS-1e8395f9-f3db-4825-b92f-0583bfe8d286,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-05520a7a-7ac2-4137-87c5-95180023255f,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-52db5bab-68cb-4dd9-8f40-6dab72b74525,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-5e57565a-a585-4789-9dd3-105ee3edda1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-02b8e4b5-1794-4c6f-b345-bce1c9ea781d,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-c30e163e-cd9e-4ffd-85cf-28d8e66b65fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35697,DS-b20f5e2e-a0ad-410f-80fd-789df995fb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-03b8710b-00ea-4726-8751-023bb9ac829e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-787951741-172.17.0.6-1595974763706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42226,DS-1e8395f9-f3db-4825-b92f-0583bfe8d286,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-05520a7a-7ac2-4137-87c5-95180023255f,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-52db5bab-68cb-4dd9-8f40-6dab72b74525,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-5e57565a-a585-4789-9dd3-105ee3edda1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-02b8e4b5-1794-4c6f-b345-bce1c9ea781d,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-c30e163e-cd9e-4ffd-85cf-28d8e66b65fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35697,DS-b20f5e2e-a0ad-410f-80fd-789df995fb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-03b8710b-00ea-4726-8751-023bb9ac829e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1390829622-172.17.0.6-1595974800209:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33760,DS-bbad19b3-2f08-46d6-9c69-fd0e613f22c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-948ae3ad-f8a5-4cd5-bc86-1cce84212d46,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-3b060dca-f5f2-4f0d-9a62-f38db5cd768f,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-802e9cb4-8529-482e-bfc4-140dc4fad3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-a601473a-074c-4a15-ac75-1c7226506faf,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-1d979560-8eda-4e83-b511-ab136740bf4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38378,DS-7009a2f3-422f-41bb-88f7-c2d496cd2331,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-95fa1764-3494-4b7a-96a8-78280c3099ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1390829622-172.17.0.6-1595974800209:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33760,DS-bbad19b3-2f08-46d6-9c69-fd0e613f22c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-948ae3ad-f8a5-4cd5-bc86-1cce84212d46,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-3b060dca-f5f2-4f0d-9a62-f38db5cd768f,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-802e9cb4-8529-482e-bfc4-140dc4fad3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-a601473a-074c-4a15-ac75-1c7226506faf,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-1d979560-8eda-4e83-b511-ab136740bf4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38378,DS-7009a2f3-422f-41bb-88f7-c2d496cd2331,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-95fa1764-3494-4b7a-96a8-78280c3099ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.misreplication.processing.limit
component: hdfs:NameNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-860471336-172.17.0.6-1595975562319:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41476,DS-c6cfc4c2-e1ee-4d48-a41d-d899de209719,DISK], DatanodeInfoWithStorage[127.0.0.1:36674,DS-61cb2fc4-6d7d-4325-8bd7-eb28b01c5cff,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-97296686-fcf9-47a7-8410-827304b7f0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-afc85aca-3704-4148-8f27-c411c3186624,DISK], DatanodeInfoWithStorage[127.0.0.1:41015,DS-71923257-ebb0-43dd-aecc-e16ea1cc5265,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-8d6a6884-2d37-4b4c-b917-3d5d1917a085,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-46fa9bec-cb6d-40aa-8ceb-01fdc456be67,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-da72e20d-faa0-4ade-9e32-65a3878dc9db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-860471336-172.17.0.6-1595975562319:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41476,DS-c6cfc4c2-e1ee-4d48-a41d-d899de209719,DISK], DatanodeInfoWithStorage[127.0.0.1:36674,DS-61cb2fc4-6d7d-4325-8bd7-eb28b01c5cff,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-97296686-fcf9-47a7-8410-827304b7f0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-afc85aca-3704-4148-8f27-c411c3186624,DISK], DatanodeInfoWithStorage[127.0.0.1:41015,DS-71923257-ebb0-43dd-aecc-e16ea1cc5265,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-8d6a6884-2d37-4b4c-b917-3d5d1917a085,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-46fa9bec-cb6d-40aa-8ceb-01fdc456be67,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-da72e20d-faa0-4ade-9e32-65a3878dc9db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5171
