reconf_parameter: dfs.namenode.snapshot.skiplist.interval
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.interval
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-499622414-172.17.0.2-1595937985322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41536,DS-20d3d71a-452a-4c03-862e-c5aa98d02608,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-9a2d229d-85cc-4958-9421-fdcd969f961f,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-1e87764e-0c08-47f7-bf47-0b8bdf3a8916,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-7f17361b-ae87-4a34-8048-98e5a5a30fde,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-ef3170d3-7b7c-47ea-b741-23577fe9195c,DISK], DatanodeInfoWithStorage[127.0.0.1:38552,DS-bee25eba-4836-4a1a-89bb-c90992e76802,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-3a550365-a3af-483c-8e85-0a46e9838f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33236,DS-ab37d65d-f522-409e-9d57-61eae9b81ce5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-499622414-172.17.0.2-1595937985322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41536,DS-20d3d71a-452a-4c03-862e-c5aa98d02608,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-9a2d229d-85cc-4958-9421-fdcd969f961f,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-1e87764e-0c08-47f7-bf47-0b8bdf3a8916,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-7f17361b-ae87-4a34-8048-98e5a5a30fde,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-ef3170d3-7b7c-47ea-b741-23577fe9195c,DISK], DatanodeInfoWithStorage[127.0.0.1:38552,DS-bee25eba-4836-4a1a-89bb-c90992e76802,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-3a550365-a3af-483c-8e85-0a46e9838f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33236,DS-ab37d65d-f522-409e-9d57-61eae9b81ce5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.interval
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1592296156-172.17.0.2-1595938191938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34195,DS-69d4f28d-fa76-4f0c-b785-e1d19608abd2,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-a0979a40-907b-4db9-9ff9-404bccfc8dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:44132,DS-64f054c5-86b5-4864-9d7d-eca9325a2ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-5fd31f93-a3d8-48de-a9fe-15c8ff3ef11e,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-144c1b92-c0cf-4036-a4f9-2d3d6c8240bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43316,DS-a9f1fe53-40a0-444f-b3de-70c847117f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-bfdd83ec-20fc-48c2-84a6-5f964468a9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-88920004-a99e-4991-9fbb-8b9419f7fdef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1592296156-172.17.0.2-1595938191938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34195,DS-69d4f28d-fa76-4f0c-b785-e1d19608abd2,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-a0979a40-907b-4db9-9ff9-404bccfc8dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:44132,DS-64f054c5-86b5-4864-9d7d-eca9325a2ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-5fd31f93-a3d8-48de-a9fe-15c8ff3ef11e,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-144c1b92-c0cf-4036-a4f9-2d3d6c8240bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43316,DS-a9f1fe53-40a0-444f-b3de-70c847117f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-bfdd83ec-20fc-48c2-84a6-5f964468a9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-88920004-a99e-4991-9fbb-8b9419f7fdef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.interval
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-871989044-172.17.0.2-1595938652022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36164,DS-95c44d67-cfdf-48e3-b7a3-a5c03c868d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-59170e33-f1a7-4d43-987f-7f3b0762f345,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-4a171620-220a-4417-8f60-442566a6ce36,DISK], DatanodeInfoWithStorage[127.0.0.1:38234,DS-c3e3cbe4-f39f-4a52-9c28-1a48f28d9af3,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-7046e6b2-e01d-4208-ba25-c00c3a709843,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-82a8d972-20fb-4d2b-bc37-679154cba2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36631,DS-b030c79b-b21f-4530-abbc-3389d65da609,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-1caa8e98-a9e6-4bf1-b266-394e260aef1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-871989044-172.17.0.2-1595938652022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36164,DS-95c44d67-cfdf-48e3-b7a3-a5c03c868d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-59170e33-f1a7-4d43-987f-7f3b0762f345,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-4a171620-220a-4417-8f60-442566a6ce36,DISK], DatanodeInfoWithStorage[127.0.0.1:38234,DS-c3e3cbe4-f39f-4a52-9c28-1a48f28d9af3,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-7046e6b2-e01d-4208-ba25-c00c3a709843,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-82a8d972-20fb-4d2b-bc37-679154cba2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36631,DS-b030c79b-b21f-4530-abbc-3389d65da609,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-1caa8e98-a9e6-4bf1-b266-394e260aef1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.interval
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1320441069-172.17.0.2-1595938729426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43210,DS-a8e1b453-515b-40cd-8e0f-5338191a5248,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-813259e6-7a2b-4293-abb5-6b7bf3043179,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-6e66247a-316d-4c75-9d88-bc03bb025547,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-4c5ac1c5-56b3-4c98-b4d3-93a32c12d12f,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-dd06abeb-4b27-490b-b552-d75aeba17294,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-475e74b1-c5f7-4e76-92ef-ee8bdb6fcfa5,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-d59c3743-8e50-47a7-a5a8-5fed563d8269,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-d64af085-4e17-4f49-ba9c-79284983506c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1320441069-172.17.0.2-1595938729426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43210,DS-a8e1b453-515b-40cd-8e0f-5338191a5248,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-813259e6-7a2b-4293-abb5-6b7bf3043179,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-6e66247a-316d-4c75-9d88-bc03bb025547,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-4c5ac1c5-56b3-4c98-b4d3-93a32c12d12f,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-dd06abeb-4b27-490b-b552-d75aeba17294,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-475e74b1-c5f7-4e76-92ef-ee8bdb6fcfa5,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-d59c3743-8e50-47a7-a5a8-5fed563d8269,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-d64af085-4e17-4f49-ba9c-79284983506c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.interval
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-343040228-172.17.0.2-1595939453241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37046,DS-e2c87869-d582-4332-9cb2-6a4d0e874dad,DISK], DatanodeInfoWithStorage[127.0.0.1:41554,DS-ddf4ec7f-b49c-4dd9-bd45-07b18d5ad4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-e893d1ec-28e7-4ed8-9420-a90152c32d44,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-178bafc5-0487-4e36-9942-245de7a2c202,DISK], DatanodeInfoWithStorage[127.0.0.1:35842,DS-14edf6c7-f082-401b-8121-25844ca743f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-87de4263-4682-485a-81ae-9b1b1411382a,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-fc7c7d25-0db7-4cc6-88f0-ad9a1ba53af7,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-b1df1e64-5318-4aa3-b78b-6e27829d3959,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-343040228-172.17.0.2-1595939453241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37046,DS-e2c87869-d582-4332-9cb2-6a4d0e874dad,DISK], DatanodeInfoWithStorage[127.0.0.1:41554,DS-ddf4ec7f-b49c-4dd9-bd45-07b18d5ad4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-e893d1ec-28e7-4ed8-9420-a90152c32d44,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-178bafc5-0487-4e36-9942-245de7a2c202,DISK], DatanodeInfoWithStorage[127.0.0.1:35842,DS-14edf6c7-f082-401b-8121-25844ca743f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-87de4263-4682-485a-81ae-9b1b1411382a,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-fc7c7d25-0db7-4cc6-88f0-ad9a1ba53af7,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-b1df1e64-5318-4aa3-b78b-6e27829d3959,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.interval
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-577428115-172.17.0.2-1595939493756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35595,DS-fd0394b9-07cc-40cc-97e9-691a984d7a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-eff56fd6-abaa-4412-81ba-587358f307d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-352d388a-5366-490e-88a0-e296bf3c246a,DISK], DatanodeInfoWithStorage[127.0.0.1:42561,DS-01d6e5c5-98ab-4340-9238-ad66c8be1268,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-e3e6bdf7-edc9-41d0-ac49-37e987041b74,DISK], DatanodeInfoWithStorage[127.0.0.1:40860,DS-479107e4-7876-4366-80f0-bab2b467133f,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-63d740aa-877a-4c74-b0f0-d10a99c39dad,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-f60f5e4a-3bda-4912-82ea-f7a7a77fa54f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-577428115-172.17.0.2-1595939493756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35595,DS-fd0394b9-07cc-40cc-97e9-691a984d7a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-eff56fd6-abaa-4412-81ba-587358f307d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-352d388a-5366-490e-88a0-e296bf3c246a,DISK], DatanodeInfoWithStorage[127.0.0.1:42561,DS-01d6e5c5-98ab-4340-9238-ad66c8be1268,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-e3e6bdf7-edc9-41d0-ac49-37e987041b74,DISK], DatanodeInfoWithStorage[127.0.0.1:40860,DS-479107e4-7876-4366-80f0-bab2b467133f,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-63d740aa-877a-4c74-b0f0-d10a99c39dad,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-f60f5e4a-3bda-4912-82ea-f7a7a77fa54f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.interval
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-564731378-172.17.0.2-1595939593925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37035,DS-eddc944e-e7e7-4db6-91f2-246c202ef8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33456,DS-87e01824-a22c-409b-aabd-6fe17308fbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-f8614535-7fa2-4f29-bf04-e7d92e50ae0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-f817b24e-fb6b-4ac5-aa2a-3211a5fbb8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-319f11c3-e2d5-4a68-9c86-fa5e5bd7a0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-94d780a9-a7ab-42c0-8bf7-f2b27343126a,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-93251fa5-30a2-4af3-ade7-301b6579f478,DISK], DatanodeInfoWithStorage[127.0.0.1:35892,DS-483de3bd-7e41-4420-9576-65835a3aaa8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-564731378-172.17.0.2-1595939593925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37035,DS-eddc944e-e7e7-4db6-91f2-246c202ef8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33456,DS-87e01824-a22c-409b-aabd-6fe17308fbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-f8614535-7fa2-4f29-bf04-e7d92e50ae0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-f817b24e-fb6b-4ac5-aa2a-3211a5fbb8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-319f11c3-e2d5-4a68-9c86-fa5e5bd7a0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-94d780a9-a7ab-42c0-8bf7-f2b27343126a,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-93251fa5-30a2-4af3-ade7-301b6579f478,DISK], DatanodeInfoWithStorage[127.0.0.1:35892,DS-483de3bd-7e41-4420-9576-65835a3aaa8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.interval
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1026770980-172.17.0.2-1595940122547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38007,DS-8ad65cbe-ece8-4731-af45-b0376e83b479,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-30c76f9e-8947-42f6-a109-d8e9702f2631,DISK], DatanodeInfoWithStorage[127.0.0.1:45613,DS-3bc15720-1c8b-4a0c-bb68-2c5bd71f6b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-e2b7b8a0-b6ec-4378-82e4-752537cc763a,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-8cd88b01-2551-4941-8449-f01ee9ff7f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36366,DS-43deef5f-7581-4823-9eb5-3219e5bfa6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-36fcee28-c86f-40c9-b6a3-11d7ab3a77a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-e6d90422-58a0-4d5d-acb9-dbfe66e26af1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1026770980-172.17.0.2-1595940122547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38007,DS-8ad65cbe-ece8-4731-af45-b0376e83b479,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-30c76f9e-8947-42f6-a109-d8e9702f2631,DISK], DatanodeInfoWithStorage[127.0.0.1:45613,DS-3bc15720-1c8b-4a0c-bb68-2c5bd71f6b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-e2b7b8a0-b6ec-4378-82e4-752537cc763a,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-8cd88b01-2551-4941-8449-f01ee9ff7f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36366,DS-43deef5f-7581-4823-9eb5-3219e5bfa6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-36fcee28-c86f-40c9-b6a3-11d7ab3a77a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-e6d90422-58a0-4d5d-acb9-dbfe66e26af1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.interval
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-182671038-172.17.0.2-1595940753299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42561,DS-5a914dbc-cf42-443d-a75a-937e50aaa111,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-b22bca21-b7b0-4ad6-9cab-df743bc1e67a,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-120abe4b-7e21-4c5e-9b87-e0d116c9fce4,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-e587309f-9146-46b2-90ce-bb85c3b99c05,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-d33d59c7-4e92-4212-8448-64975c6f5a72,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-6c193948-c8ab-423a-b000-e9085a1d0552,DISK], DatanodeInfoWithStorage[127.0.0.1:39178,DS-0ab9fc92-5a89-4b93-9b73-9418dc626cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-8d5c76f4-caab-44e4-9069-cffcdddc2b5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-182671038-172.17.0.2-1595940753299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42561,DS-5a914dbc-cf42-443d-a75a-937e50aaa111,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-b22bca21-b7b0-4ad6-9cab-df743bc1e67a,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-120abe4b-7e21-4c5e-9b87-e0d116c9fce4,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-e587309f-9146-46b2-90ce-bb85c3b99c05,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-d33d59c7-4e92-4212-8448-64975c6f5a72,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-6c193948-c8ab-423a-b000-e9085a1d0552,DISK], DatanodeInfoWithStorage[127.0.0.1:39178,DS-0ab9fc92-5a89-4b93-9b73-9418dc626cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-8d5c76f4-caab-44e4-9069-cffcdddc2b5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.interval
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-422762809-172.17.0.2-1595941386897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44401,DS-1202ab88-83ac-4bc2-b98d-02bac6057dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-5c24dc45-1c56-4f9b-b4bb-d8e51f516738,DISK], DatanodeInfoWithStorage[127.0.0.1:35333,DS-5c03c0dc-dfeb-434b-8be8-c3b426c5237e,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-5e478e63-2ee6-480f-880a-e9785f3d2e50,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-d62fe57e-a859-409d-a735-b58224c5ce19,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-7dcb58b9-e9b8-4593-93b3-2ffbbbf023bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-1dda9ac3-8fb7-4187-b58e-e44ee4a72158,DISK], DatanodeInfoWithStorage[127.0.0.1:37775,DS-803a875f-1afc-4f8a-92ba-565db60c8473,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-422762809-172.17.0.2-1595941386897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44401,DS-1202ab88-83ac-4bc2-b98d-02bac6057dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-5c24dc45-1c56-4f9b-b4bb-d8e51f516738,DISK], DatanodeInfoWithStorage[127.0.0.1:35333,DS-5c03c0dc-dfeb-434b-8be8-c3b426c5237e,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-5e478e63-2ee6-480f-880a-e9785f3d2e50,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-d62fe57e-a859-409d-a735-b58224c5ce19,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-7dcb58b9-e9b8-4593-93b3-2ffbbbf023bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-1dda9ac3-8fb7-4187-b58e-e44ee4a72158,DISK], DatanodeInfoWithStorage[127.0.0.1:37775,DS-803a875f-1afc-4f8a-92ba-565db60c8473,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.interval
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1084013646-172.17.0.2-1595942166499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33811,DS-8c741519-eb88-436b-bdbc-b4e9677dadf4,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-15ec62b3-8dbf-4df2-a0d0-a5f6cc493570,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-d6d339e3-0da6-4b3a-b78a-369aa8f49cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-e7761c2d-cb68-424c-8a3d-5ff4469eb11f,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-2b60c278-af13-44a5-a412-9c33bf69ce47,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-98ae5008-2172-4c8d-9e0c-56bac9ca090f,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-e575ae0c-67cc-469d-b550-ae71122cf505,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-7b781c11-d210-4268-99f6-03e642d2770a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1084013646-172.17.0.2-1595942166499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33811,DS-8c741519-eb88-436b-bdbc-b4e9677dadf4,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-15ec62b3-8dbf-4df2-a0d0-a5f6cc493570,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-d6d339e3-0da6-4b3a-b78a-369aa8f49cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-e7761c2d-cb68-424c-8a3d-5ff4469eb11f,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-2b60c278-af13-44a5-a412-9c33bf69ce47,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-98ae5008-2172-4c8d-9e0c-56bac9ca090f,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-e575ae0c-67cc-469d-b550-ae71122cf505,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-7b781c11-d210-4268-99f6-03e642d2770a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.interval
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-826124596-172.17.0.2-1595942585658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38238,DS-c172e072-36ce-4b82-9b57-d5e5909f3865,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-3f57718a-49c1-49d5-a1f8-cf955aa7d26b,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-b9448bb2-df9a-470d-a60b-1f01fdfeaf7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-27ca9da3-b1e4-4cba-a0f2-ff878365b882,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-79e37ca1-8d84-418d-b378-a41216649e99,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-35807564-33d1-404f-88c5-f455bc3a6a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37199,DS-72794c4b-98ef-48b8-b3f9-e248c62cedb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34810,DS-6d45489e-7ce2-493a-b79e-3f8c9c346dde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-826124596-172.17.0.2-1595942585658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38238,DS-c172e072-36ce-4b82-9b57-d5e5909f3865,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-3f57718a-49c1-49d5-a1f8-cf955aa7d26b,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-b9448bb2-df9a-470d-a60b-1f01fdfeaf7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-27ca9da3-b1e4-4cba-a0f2-ff878365b882,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-79e37ca1-8d84-418d-b378-a41216649e99,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-35807564-33d1-404f-88c5-f455bc3a6a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37199,DS-72794c4b-98ef-48b8-b3f9-e248c62cedb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34810,DS-6d45489e-7ce2-493a-b79e-3f8c9c346dde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.interval
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-639835733-172.17.0.2-1595943068904:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43729,DS-7714377a-ef0a-44ab-8bab-eb1b3af62e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-71a649fd-f8cb-4304-85a2-ab180c210f87,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-c0ec680a-2208-4f78-b81c-0588a17551de,DISK], DatanodeInfoWithStorage[127.0.0.1:46377,DS-5777c99f-90f9-4aaf-9967-575582016df4,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-f6fb521a-aa2b-4b89-8339-d0316a1c67dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-374c85cd-eee7-4a31-9d2f-1e1310382bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-ade00b22-74e0-4dd7-b02e-f5c69dc2cf7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-a2f18193-7baa-4fd8-922f-47eae2629f94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-639835733-172.17.0.2-1595943068904:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43729,DS-7714377a-ef0a-44ab-8bab-eb1b3af62e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-71a649fd-f8cb-4304-85a2-ab180c210f87,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-c0ec680a-2208-4f78-b81c-0588a17551de,DISK], DatanodeInfoWithStorage[127.0.0.1:46377,DS-5777c99f-90f9-4aaf-9967-575582016df4,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-f6fb521a-aa2b-4b89-8339-d0316a1c67dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-374c85cd-eee7-4a31-9d2f-1e1310382bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-ade00b22-74e0-4dd7-b02e-f5c69dc2cf7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-a2f18193-7baa-4fd8-922f-47eae2629f94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.interval
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1764395960-172.17.0.2-1595943995632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46194,DS-500d7f0a-f142-47b2-8ace-66a35d183b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-c9d2121c-1ca2-4151-9c2b-88c71f946d30,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-a32d0e77-1c8a-4710-bf83-9b2337047e59,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-e9fac319-0b13-4a56-9eda-d40c333279c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-455f5800-0eb1-4588-9cfb-bc6061c86870,DISK], DatanodeInfoWithStorage[127.0.0.1:33648,DS-bdb4f28d-1794-448b-957d-6e375b38c046,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-6175cf75-fa52-44ed-b1c6-2cc365ed5a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-6ba0a76d-87b2-47ab-950d-ec3ac4baf995,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1764395960-172.17.0.2-1595943995632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46194,DS-500d7f0a-f142-47b2-8ace-66a35d183b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-c9d2121c-1ca2-4151-9c2b-88c71f946d30,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-a32d0e77-1c8a-4710-bf83-9b2337047e59,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-e9fac319-0b13-4a56-9eda-d40c333279c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-455f5800-0eb1-4588-9cfb-bc6061c86870,DISK], DatanodeInfoWithStorage[127.0.0.1:33648,DS-bdb4f28d-1794-448b-957d-6e375b38c046,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-6175cf75-fa52-44ed-b1c6-2cc365ed5a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-6ba0a76d-87b2-47ab-950d-ec3ac4baf995,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 6802
