reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1982225329-172.17.0.12-1595483618714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35777,DS-0888af09-b565-44b7-8177-b6c32fb83b90,DISK], DatanodeInfoWithStorage[127.0.0.1:34798,DS-a80563ea-ca60-4cb0-b153-c12dfc6c84d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38438,DS-7bf60fda-e1f8-40bb-add1-afeb25113e56,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-8c26cafa-1045-4e05-9f05-034d8135c7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-4c97d357-a315-4b9d-a1ab-9294a3b2efa7,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-3acdcf69-5b39-4b40-94f7-0f296a927478,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-483272fd-ab4f-4a2c-b414-5dac7bf55135,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-f9bc8ec7-9347-4d63-b331-a2b48da60a18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1982225329-172.17.0.12-1595483618714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35777,DS-0888af09-b565-44b7-8177-b6c32fb83b90,DISK], DatanodeInfoWithStorage[127.0.0.1:34798,DS-a80563ea-ca60-4cb0-b153-c12dfc6c84d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38438,DS-7bf60fda-e1f8-40bb-add1-afeb25113e56,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-8c26cafa-1045-4e05-9f05-034d8135c7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-4c97d357-a315-4b9d-a1ab-9294a3b2efa7,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-3acdcf69-5b39-4b40-94f7-0f296a927478,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-483272fd-ab4f-4a2c-b414-5dac7bf55135,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-f9bc8ec7-9347-4d63-b331-a2b48da60a18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1540892150-172.17.0.12-1595483835032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34920,DS-e8df6389-8c17-48c7-a8f3-39388373ee79,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-d0862fd8-d3db-475c-8b5a-dd5a449a9c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-8772a381-3628-4eab-a209-eb5811b52b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-0e4f82ee-777d-47b4-9066-a69f37b7e573,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-609da50a-04b6-494e-b1f4-80e9d4adb4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45419,DS-53fac3b9-d149-4219-be03-b2519d04098e,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-c12dbb9e-d699-405b-b9a8-cc0d10c2d71f,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-6a064a51-4a7c-4b8d-830e-f1cdc575e794,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1540892150-172.17.0.12-1595483835032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34920,DS-e8df6389-8c17-48c7-a8f3-39388373ee79,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-d0862fd8-d3db-475c-8b5a-dd5a449a9c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-8772a381-3628-4eab-a209-eb5811b52b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-0e4f82ee-777d-47b4-9066-a69f37b7e573,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-609da50a-04b6-494e-b1f4-80e9d4adb4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45419,DS-53fac3b9-d149-4219-be03-b2519d04098e,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-c12dbb9e-d699-405b-b9a8-cc0d10c2d71f,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-6a064a51-4a7c-4b8d-830e-f1cdc575e794,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1573871683-172.17.0.12-1595484206399:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46677,DS-cd1eb9bf-72c6-457c-ae90-129601ca7fef,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-2315f729-37ce-489d-8ef5-2b0929e5f586,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-82a9f6ac-4887-4b11-b34f-1afb7652e0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-55aa89f3-dc3f-43ce-978a-eafa1f955171,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-d214d81e-b584-4dfc-ac0c-b07240012be5,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-2d678277-474b-47ef-b226-bd3e5b67a2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-df19e829-5f34-4ccd-b184-17d1e159a331,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-3cf510a5-2bb5-494b-b8fc-066435e82d62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1573871683-172.17.0.12-1595484206399:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46677,DS-cd1eb9bf-72c6-457c-ae90-129601ca7fef,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-2315f729-37ce-489d-8ef5-2b0929e5f586,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-82a9f6ac-4887-4b11-b34f-1afb7652e0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-55aa89f3-dc3f-43ce-978a-eafa1f955171,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-d214d81e-b584-4dfc-ac0c-b07240012be5,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-2d678277-474b-47ef-b226-bd3e5b67a2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-df19e829-5f34-4ccd-b184-17d1e159a331,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-3cf510a5-2bb5-494b-b8fc-066435e82d62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1999777241-172.17.0.12-1595484806351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40400,DS-3363a2b1-285d-4994-9b2a-84864874c46d,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-f0e4ea7b-da65-48e2-9940-4ed86ea20fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-5af32f74-c35c-4776-a53f-e66070782ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:39877,DS-b9c7793f-4f81-4c58-99d3-8ad690e39c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-70686f25-3004-4a6f-b65a-e228f3afca74,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-2c2a10c0-6d23-41c2-bcf6-3c65ae24aa0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-c410843a-84e5-464f-9d99-a23c7856852b,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-28328016-8df1-4071-9559-2ec56a261ab5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1999777241-172.17.0.12-1595484806351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40400,DS-3363a2b1-285d-4994-9b2a-84864874c46d,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-f0e4ea7b-da65-48e2-9940-4ed86ea20fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-5af32f74-c35c-4776-a53f-e66070782ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:39877,DS-b9c7793f-4f81-4c58-99d3-8ad690e39c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-70686f25-3004-4a6f-b65a-e228f3afca74,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-2c2a10c0-6d23-41c2-bcf6-3c65ae24aa0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-c410843a-84e5-464f-9d99-a23c7856852b,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-28328016-8df1-4071-9559-2ec56a261ab5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-645237671-172.17.0.12-1595485489106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33714,DS-4749bf18-eafd-4042-9198-5d55b7478326,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-593e0293-985c-4a72-ab75-a45be5f7202c,DISK], DatanodeInfoWithStorage[127.0.0.1:40154,DS-0682bfb1-0d41-499f-b77f-152272d1293f,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-faa18870-3377-4919-b2da-0cea10d2df6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-a7aa47da-3428-41c5-a62c-7c7880030527,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-57e69eb2-83b5-4f55-a691-d5d35b653d92,DISK], DatanodeInfoWithStorage[127.0.0.1:45654,DS-4256a050-75d7-4afb-a7d4-2fa7aa1519b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-91de8939-b4ba-46d7-9859-0cb0658da8f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-645237671-172.17.0.12-1595485489106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33714,DS-4749bf18-eafd-4042-9198-5d55b7478326,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-593e0293-985c-4a72-ab75-a45be5f7202c,DISK], DatanodeInfoWithStorage[127.0.0.1:40154,DS-0682bfb1-0d41-499f-b77f-152272d1293f,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-faa18870-3377-4919-b2da-0cea10d2df6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-a7aa47da-3428-41c5-a62c-7c7880030527,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-57e69eb2-83b5-4f55-a691-d5d35b653d92,DISK], DatanodeInfoWithStorage[127.0.0.1:45654,DS-4256a050-75d7-4afb-a7d4-2fa7aa1519b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-91de8939-b4ba-46d7-9859-0cb0658da8f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-888609425-172.17.0.12-1595486836158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35933,DS-0765ebed-029b-4c8a-9063-2d60a6168aad,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-2a44d770-f248-4d75-adf5-470fddef25ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-ad171f3f-06fa-4b67-8aa8-621a9e78059f,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-35c932ef-af68-4e24-8244-496aff2ff924,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-7892fc53-b0d2-4d83-a927-9f2b191adcaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-a5fbff9a-56db-4b6f-93db-3c2e8db2b791,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-52a0bc6d-194d-4d2e-b6bf-e96aa292d489,DISK], DatanodeInfoWithStorage[127.0.0.1:38532,DS-0ce65ff7-ddba-41cc-8b76-0a606b416870,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-888609425-172.17.0.12-1595486836158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35933,DS-0765ebed-029b-4c8a-9063-2d60a6168aad,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-2a44d770-f248-4d75-adf5-470fddef25ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-ad171f3f-06fa-4b67-8aa8-621a9e78059f,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-35c932ef-af68-4e24-8244-496aff2ff924,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-7892fc53-b0d2-4d83-a927-9f2b191adcaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-a5fbff9a-56db-4b6f-93db-3c2e8db2b791,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-52a0bc6d-194d-4d2e-b6bf-e96aa292d489,DISK], DatanodeInfoWithStorage[127.0.0.1:38532,DS-0ce65ff7-ddba-41cc-8b76-0a606b416870,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1701753383-172.17.0.12-1595487535547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40775,DS-9e02f21f-64fb-4ee0-ac0d-ed8b7919934b,DISK], DatanodeInfoWithStorage[127.0.0.1:39330,DS-983b8e8e-0f27-45aa-aecb-1a3b63c15cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-53803e32-7319-4593-ab97-97556ef29c71,DISK], DatanodeInfoWithStorage[127.0.0.1:37749,DS-b724fb82-32f5-4cf5-9789-b98d03592347,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-ffd13a91-ba02-44c7-8598-cc231b15754f,DISK], DatanodeInfoWithStorage[127.0.0.1:33697,DS-b903c020-ea91-4073-8cca-d2d3f52603f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-2cde3df8-7fed-43b4-bb18-07d25b77e810,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-925e0711-a62f-4deb-a467-c327aef66089,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1701753383-172.17.0.12-1595487535547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40775,DS-9e02f21f-64fb-4ee0-ac0d-ed8b7919934b,DISK], DatanodeInfoWithStorage[127.0.0.1:39330,DS-983b8e8e-0f27-45aa-aecb-1a3b63c15cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-53803e32-7319-4593-ab97-97556ef29c71,DISK], DatanodeInfoWithStorage[127.0.0.1:37749,DS-b724fb82-32f5-4cf5-9789-b98d03592347,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-ffd13a91-ba02-44c7-8598-cc231b15754f,DISK], DatanodeInfoWithStorage[127.0.0.1:33697,DS-b903c020-ea91-4073-8cca-d2d3f52603f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-2cde3df8-7fed-43b4-bb18-07d25b77e810,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-925e0711-a62f-4deb-a467-c327aef66089,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1812391419-172.17.0.12-1595487758861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37332,DS-a5d2a3ef-d321-4aca-9285-71d11a26dc7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-06c3c2e3-9776-4e23-869c-b011dd96269a,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-b72b80fd-b541-4ceb-b3c6-59a4d7cc3748,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-58f88ea8-bf91-4611-912d-526dda63de1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-ea7b530c-e661-4062-9a37-4a71a07e0390,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-59da16c3-3dfa-41c7-908f-e3b92fcceaef,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-7c6c41a6-e73f-47aa-b8ca-a76865ee0ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-2ece170b-45d6-42b4-ad07-35dcddfa587d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1812391419-172.17.0.12-1595487758861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37332,DS-a5d2a3ef-d321-4aca-9285-71d11a26dc7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-06c3c2e3-9776-4e23-869c-b011dd96269a,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-b72b80fd-b541-4ceb-b3c6-59a4d7cc3748,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-58f88ea8-bf91-4611-912d-526dda63de1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-ea7b530c-e661-4062-9a37-4a71a07e0390,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-59da16c3-3dfa-41c7-908f-e3b92fcceaef,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-7c6c41a6-e73f-47aa-b8ca-a76865ee0ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-2ece170b-45d6-42b4-ad07-35dcddfa587d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1497830408-172.17.0.12-1595488341066:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42666,DS-7fdb0a9c-d7a4-4f68-a599-c81420c17f08,DISK], DatanodeInfoWithStorage[127.0.0.1:37411,DS-fb16a71e-8066-4e6d-879a-d269260d6294,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-0678cf33-c190-488b-8c40-9e16ed4748cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-0ad6259e-661a-4eae-b401-9e0ddc5f9719,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-1ff0f70f-f53b-4e87-a948-08c063b53142,DISK], DatanodeInfoWithStorage[127.0.0.1:38781,DS-0b5ee611-c070-458c-932b-fd6a8d4649c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35294,DS-831b49e3-748e-439c-997f-a10751f61355,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-319df912-ba5e-4c8d-993d-388d5d974854,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1497830408-172.17.0.12-1595488341066:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42666,DS-7fdb0a9c-d7a4-4f68-a599-c81420c17f08,DISK], DatanodeInfoWithStorage[127.0.0.1:37411,DS-fb16a71e-8066-4e6d-879a-d269260d6294,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-0678cf33-c190-488b-8c40-9e16ed4748cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-0ad6259e-661a-4eae-b401-9e0ddc5f9719,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-1ff0f70f-f53b-4e87-a948-08c063b53142,DISK], DatanodeInfoWithStorage[127.0.0.1:38781,DS-0b5ee611-c070-458c-932b-fd6a8d4649c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35294,DS-831b49e3-748e-439c-997f-a10751f61355,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-319df912-ba5e-4c8d-993d-388d5d974854,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1845924102-172.17.0.12-1595488372833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42207,DS-c8a5aee5-b712-4ff4-998a-a8f0e8fd39e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-ef06ead4-c557-48bb-85ca-ad75142a2eee,DISK], DatanodeInfoWithStorage[127.0.0.1:38617,DS-784daebf-3a60-45b0-bb61-ffbafc4cf785,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-c8660fc7-2f53-4549-8510-7b7403acc64b,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-7333d295-f31b-4bc6-8019-d50777843c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-a4ae2f39-af48-4159-819c-c86156fe0802,DISK], DatanodeInfoWithStorage[127.0.0.1:37536,DS-d38e7da2-86b2-4284-ba3f-8de2339eabb5,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-afac0188-c8b5-4dc0-8dc1-e427b0fe96d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1845924102-172.17.0.12-1595488372833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42207,DS-c8a5aee5-b712-4ff4-998a-a8f0e8fd39e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-ef06ead4-c557-48bb-85ca-ad75142a2eee,DISK], DatanodeInfoWithStorage[127.0.0.1:38617,DS-784daebf-3a60-45b0-bb61-ffbafc4cf785,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-c8660fc7-2f53-4549-8510-7b7403acc64b,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-7333d295-f31b-4bc6-8019-d50777843c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-a4ae2f39-af48-4159-819c-c86156fe0802,DISK], DatanodeInfoWithStorage[127.0.0.1:37536,DS-d38e7da2-86b2-4284-ba3f-8de2339eabb5,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-afac0188-c8b5-4dc0-8dc1-e427b0fe96d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: false positive !!!
Total execution time in seconds : 5238
