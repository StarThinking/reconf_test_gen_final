reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1228704110-172.17.0.5-1595896149453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34065,DS-5a01c5d8-d61a-4338-a045-167e01e76738,DISK], DatanodeInfoWithStorage[127.0.0.1:46274,DS-60f8e411-9b06-4877-897f-00be1a891a82,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-4e7eb667-7ba9-494c-9902-e70818ef5c82,DISK], DatanodeInfoWithStorage[127.0.0.1:34569,DS-fd831abc-04ac-47d4-a782-8a8f527caf8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-06575420-bbc4-4748-8455-84977995d0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-60392f77-50dc-411c-8407-a72ac42cd132,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-d1c8df40-a717-462e-979c-ebde9fa5f3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-15356114-c11a-4ec5-9fde-3c79490b075e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1228704110-172.17.0.5-1595896149453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34065,DS-5a01c5d8-d61a-4338-a045-167e01e76738,DISK], DatanodeInfoWithStorage[127.0.0.1:46274,DS-60f8e411-9b06-4877-897f-00be1a891a82,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-4e7eb667-7ba9-494c-9902-e70818ef5c82,DISK], DatanodeInfoWithStorage[127.0.0.1:34569,DS-fd831abc-04ac-47d4-a782-8a8f527caf8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-06575420-bbc4-4748-8455-84977995d0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-60392f77-50dc-411c-8407-a72ac42cd132,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-d1c8df40-a717-462e-979c-ebde9fa5f3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-15356114-c11a-4ec5-9fde-3c79490b075e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-904406152-172.17.0.5-1595896193874:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45235,DS-b5c639ec-984d-4e8b-833d-2b36db872761,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-f42166c9-d15f-4767-958a-a0f71e22b535,DISK], DatanodeInfoWithStorage[127.0.0.1:44404,DS-d4bb539c-5df1-4c46-ac8f-f0fdf80da96b,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-c1d65619-bf3f-4879-92c7-c43e367ff186,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-5679b13b-3170-46b4-b780-db4671159416,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-66c8ebba-f374-49bb-af7e-7d5b694673e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33950,DS-c53ce639-6c8e-4faf-878e-9f59c31fd576,DISK], DatanodeInfoWithStorage[127.0.0.1:44913,DS-9b07765c-7b75-4e4b-a3b5-1c3b7773bff8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-904406152-172.17.0.5-1595896193874:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45235,DS-b5c639ec-984d-4e8b-833d-2b36db872761,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-f42166c9-d15f-4767-958a-a0f71e22b535,DISK], DatanodeInfoWithStorage[127.0.0.1:44404,DS-d4bb539c-5df1-4c46-ac8f-f0fdf80da96b,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-c1d65619-bf3f-4879-92c7-c43e367ff186,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-5679b13b-3170-46b4-b780-db4671159416,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-66c8ebba-f374-49bb-af7e-7d5b694673e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33950,DS-c53ce639-6c8e-4faf-878e-9f59c31fd576,DISK], DatanodeInfoWithStorage[127.0.0.1:44913,DS-9b07765c-7b75-4e4b-a3b5-1c3b7773bff8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1108876400-172.17.0.5-1595896231579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33316,DS-2117ab4c-3c1f-432a-bd7f-04061ba23efd,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-ac5eeb6c-b66b-42c6-be9f-9a477fe4a9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-56f51b5e-56a0-4c81-84a5-175961915b83,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-a536a7f6-be6c-4398-9685-1e165ae60d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39609,DS-6fadb760-578e-46bc-838f-45465ffd8691,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-ae832dff-9fff-4d18-a425-1d6925b35233,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-5db7be21-d5e5-4618-bb15-67f975d15bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-3fdfb7fc-49c5-43cc-a0f4-eee10a163531,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1108876400-172.17.0.5-1595896231579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33316,DS-2117ab4c-3c1f-432a-bd7f-04061ba23efd,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-ac5eeb6c-b66b-42c6-be9f-9a477fe4a9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-56f51b5e-56a0-4c81-84a5-175961915b83,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-a536a7f6-be6c-4398-9685-1e165ae60d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39609,DS-6fadb760-578e-46bc-838f-45465ffd8691,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-ae832dff-9fff-4d18-a425-1d6925b35233,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-5db7be21-d5e5-4618-bb15-67f975d15bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-3fdfb7fc-49c5-43cc-a0f4-eee10a163531,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1659597434-172.17.0.5-1595896493507:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43520,DS-66effb8f-9e7a-4eb4-8979-a366931dcdef,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-5f7c2b2b-a2bb-4fb3-a409-b5afe4ab72bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33922,DS-8ba8bbe2-bf5c-4888-b612-b701a62028e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-31ba1f98-ef44-4f76-839c-f93097f01ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:36419,DS-ff65b39c-3d04-4ff7-abdb-81b24408201b,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-5db53a78-a071-4482-b6f2-048ca9078f57,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-5a398c70-26b4-4026-a07e-5cad8a679005,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-60f0d5fa-9c58-4a89-8f58-a73b64c6b154,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1659597434-172.17.0.5-1595896493507:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43520,DS-66effb8f-9e7a-4eb4-8979-a366931dcdef,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-5f7c2b2b-a2bb-4fb3-a409-b5afe4ab72bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33922,DS-8ba8bbe2-bf5c-4888-b612-b701a62028e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-31ba1f98-ef44-4f76-839c-f93097f01ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:36419,DS-ff65b39c-3d04-4ff7-abdb-81b24408201b,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-5db53a78-a071-4482-b6f2-048ca9078f57,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-5a398c70-26b4-4026-a07e-5cad8a679005,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-60f0d5fa-9c58-4a89-8f58-a73b64c6b154,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-616016062-172.17.0.5-1595897154065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34863,DS-81c46384-88be-4fdd-86ab-5f1db1546b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42410,DS-b84b3b2f-7db4-4066-8e27-fd86be25883c,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-db55bb5b-aa35-44ea-a963-297a778140f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-d7504df3-0359-4269-8695-9beeb62a61f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37796,DS-45523c7d-d61a-4c1a-981f-c5b3d7c10a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-e978feec-9596-4f09-aaae-c53819c02ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-a24e7eb0-03d7-4aa1-848d-685bccd516a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-f16dd3e1-c955-42a3-8f2b-6136989fa812,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-616016062-172.17.0.5-1595897154065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34863,DS-81c46384-88be-4fdd-86ab-5f1db1546b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42410,DS-b84b3b2f-7db4-4066-8e27-fd86be25883c,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-db55bb5b-aa35-44ea-a963-297a778140f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-d7504df3-0359-4269-8695-9beeb62a61f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37796,DS-45523c7d-d61a-4c1a-981f-c5b3d7c10a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-e978feec-9596-4f09-aaae-c53819c02ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-a24e7eb0-03d7-4aa1-848d-685bccd516a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-f16dd3e1-c955-42a3-8f2b-6136989fa812,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1741297296-172.17.0.5-1595897530204:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41264,DS-b4fdecc8-19da-4839-b759-08d5c4575e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-f94c5222-8ba7-46f8-b858-9e01fb4d514d,DISK], DatanodeInfoWithStorage[127.0.0.1:33322,DS-f370a2f9-dab9-4f7c-bd80-37e501f5ac5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-6ef02cc9-0b60-4f46-a547-dec5190bb77c,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-9308967d-6af6-4cbb-8d34-2a73ec4bdafa,DISK], DatanodeInfoWithStorage[127.0.0.1:34656,DS-81fc29c9-acda-4263-a5a0-4cb6c690c3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-814a9141-4f05-4a18-afb8-df2c6df7711a,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-36b2fb13-dcb3-484d-9468-f6e5d73f0303,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1741297296-172.17.0.5-1595897530204:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41264,DS-b4fdecc8-19da-4839-b759-08d5c4575e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-f94c5222-8ba7-46f8-b858-9e01fb4d514d,DISK], DatanodeInfoWithStorage[127.0.0.1:33322,DS-f370a2f9-dab9-4f7c-bd80-37e501f5ac5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-6ef02cc9-0b60-4f46-a547-dec5190bb77c,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-9308967d-6af6-4cbb-8d34-2a73ec4bdafa,DISK], DatanodeInfoWithStorage[127.0.0.1:34656,DS-81fc29c9-acda-4263-a5a0-4cb6c690c3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-814a9141-4f05-4a18-afb8-df2c6df7711a,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-36b2fb13-dcb3-484d-9468-f6e5d73f0303,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1833192909-172.17.0.5-1595897632361:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41360,DS-43e7d695-3b4b-4ba4-84ce-ca2093d628ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-d1b1b07e-588f-42ee-8c46-56b8ee8cf941,DISK], DatanodeInfoWithStorage[127.0.0.1:36908,DS-dae2f7a1-5075-4851-bcf9-9669fe615cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-f8b81682-69f3-4725-b513-c3a94655f819,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-e9102ea9-e3a4-4cd1-b534-afcbfc7bce94,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-1d27e33f-a771-4c5d-bc49-f684edfb5254,DISK], DatanodeInfoWithStorage[127.0.0.1:45463,DS-7ebe0067-d311-44b3-aeae-3fdc92aab514,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-d3000d7c-5515-47c7-857b-563c47f5e382,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1833192909-172.17.0.5-1595897632361:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41360,DS-43e7d695-3b4b-4ba4-84ce-ca2093d628ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-d1b1b07e-588f-42ee-8c46-56b8ee8cf941,DISK], DatanodeInfoWithStorage[127.0.0.1:36908,DS-dae2f7a1-5075-4851-bcf9-9669fe615cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-f8b81682-69f3-4725-b513-c3a94655f819,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-e9102ea9-e3a4-4cd1-b534-afcbfc7bce94,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-1d27e33f-a771-4c5d-bc49-f684edfb5254,DISK], DatanodeInfoWithStorage[127.0.0.1:45463,DS-7ebe0067-d311-44b3-aeae-3fdc92aab514,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-d3000d7c-5515-47c7-857b-563c47f5e382,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1470213079-172.17.0.5-1595897702350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33560,DS-c8e26881-ebd1-472e-aef3-423ebca20e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36420,DS-8d3ff6f7-11a5-4cef-8c88-5e062b0ea3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-c06825af-38b1-4521-9aa9-82362a87ffac,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-21c93f78-034c-4005-8935-a7c0acee51b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-97d8b93f-4b23-41ab-ab11-adc2a56fa3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37874,DS-0c878e65-cca7-4d8a-8061-52337ed0588d,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-38db8534-9dc1-4a32-9570-c8e4e70494e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40039,DS-f2475529-0585-4be6-bcf8-b9f761bc4ea5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1470213079-172.17.0.5-1595897702350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33560,DS-c8e26881-ebd1-472e-aef3-423ebca20e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36420,DS-8d3ff6f7-11a5-4cef-8c88-5e062b0ea3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-c06825af-38b1-4521-9aa9-82362a87ffac,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-21c93f78-034c-4005-8935-a7c0acee51b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-97d8b93f-4b23-41ab-ab11-adc2a56fa3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37874,DS-0c878e65-cca7-4d8a-8061-52337ed0588d,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-38db8534-9dc1-4a32-9570-c8e4e70494e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40039,DS-f2475529-0585-4be6-bcf8-b9f761bc4ea5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-625213176-172.17.0.5-1595898014962:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33456,DS-ed1b2845-1a3a-4854-8f52-31ef7ad57404,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-93675a0b-f480-48eb-8b50-a6ab9c09bf8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-ad6301d7-7daf-4ac8-8616-1c4560368d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-3232aaa6-db22-47c2-b0e8-dd120c88936b,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-a5227b3b-8b8a-4991-87ac-ac19b6c6cd58,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-c1c55b2c-8eed-403f-80dc-084306bb95d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-4e40fb48-5216-48de-b8a7-a66eccabee80,DISK], DatanodeInfoWithStorage[127.0.0.1:34357,DS-38ddc7be-aa6a-4797-8688-7cd30b7fa608,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-625213176-172.17.0.5-1595898014962:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33456,DS-ed1b2845-1a3a-4854-8f52-31ef7ad57404,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-93675a0b-f480-48eb-8b50-a6ab9c09bf8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-ad6301d7-7daf-4ac8-8616-1c4560368d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-3232aaa6-db22-47c2-b0e8-dd120c88936b,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-a5227b3b-8b8a-4991-87ac-ac19b6c6cd58,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-c1c55b2c-8eed-403f-80dc-084306bb95d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-4e40fb48-5216-48de-b8a7-a66eccabee80,DISK], DatanodeInfoWithStorage[127.0.0.1:34357,DS-38ddc7be-aa6a-4797-8688-7cd30b7fa608,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-769991441-172.17.0.5-1595899529261:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35124,DS-62614dae-4461-41a3-b25e-e70079c65247,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-c667a94a-46e2-4506-b728-d994714cd7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-8fb157b5-c19f-46f4-85d7-43adeb6f7c55,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-6cb69910-5296-430e-99b5-e7c0cc10465c,DISK], DatanodeInfoWithStorage[127.0.0.1:38194,DS-3a3b26ee-50fe-4a22-994f-7583f71828af,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-cf13cc78-48cc-49be-aa58-e91c98cacb7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-f61e5170-c465-48ab-8107-433851c09751,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-abf81bed-bc8c-4eaa-aae0-f326f0a2ae37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-769991441-172.17.0.5-1595899529261:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35124,DS-62614dae-4461-41a3-b25e-e70079c65247,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-c667a94a-46e2-4506-b728-d994714cd7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-8fb157b5-c19f-46f4-85d7-43adeb6f7c55,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-6cb69910-5296-430e-99b5-e7c0cc10465c,DISK], DatanodeInfoWithStorage[127.0.0.1:38194,DS-3a3b26ee-50fe-4a22-994f-7583f71828af,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-cf13cc78-48cc-49be-aa58-e91c98cacb7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-f61e5170-c465-48ab-8107-433851c09751,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-abf81bed-bc8c-4eaa-aae0-f326f0a2ae37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2036530644-172.17.0.5-1595899809822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45915,DS-1c582733-0762-4493-ac5f-291d6b08b61f,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-4f1414d4-9d21-473e-8205-02eb1133e270,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-f4b7bd47-5196-476e-a500-e36f14575988,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-d4ecae35-c0e8-40c3-97e7-ba76272455fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-c0e1a52f-6464-4da1-90a8-c8681504763b,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-300421ef-5b00-4416-88ee-fe9927e08169,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-e3203d04-28af-4d3a-ae71-19cdbf393d07,DISK], DatanodeInfoWithStorage[127.0.0.1:33682,DS-1d19ba35-f89c-4257-8331-e8da2e90f622,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2036530644-172.17.0.5-1595899809822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45915,DS-1c582733-0762-4493-ac5f-291d6b08b61f,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-4f1414d4-9d21-473e-8205-02eb1133e270,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-f4b7bd47-5196-476e-a500-e36f14575988,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-d4ecae35-c0e8-40c3-97e7-ba76272455fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-c0e1a52f-6464-4da1-90a8-c8681504763b,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-300421ef-5b00-4416-88ee-fe9927e08169,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-e3203d04-28af-4d3a-ae71-19cdbf393d07,DISK], DatanodeInfoWithStorage[127.0.0.1:33682,DS-1d19ba35-f89c-4257-8331-e8da2e90f622,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-16638960-172.17.0.5-1595899974717:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43431,DS-681795ed-5187-4990-b014-9ac93e371f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-628a98fb-7ad3-4e96-acfd-3ef4bf998881,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-f99d40be-9155-4540-979b-7d27a8c9cfd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39764,DS-c29eaadf-bc93-4b6f-bc28-30fe9f308055,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-d2b82302-4931-4009-b774-bffc0ea7605d,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-38fef17e-920c-4378-a864-a7e83627e403,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-ec273c04-8195-448c-94e9-9f715eb7f179,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-9f48ce79-83fc-4bf8-8b7d-7e9f3eca694b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-16638960-172.17.0.5-1595899974717:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43431,DS-681795ed-5187-4990-b014-9ac93e371f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-628a98fb-7ad3-4e96-acfd-3ef4bf998881,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-f99d40be-9155-4540-979b-7d27a8c9cfd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39764,DS-c29eaadf-bc93-4b6f-bc28-30fe9f308055,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-d2b82302-4931-4009-b774-bffc0ea7605d,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-38fef17e-920c-4378-a864-a7e83627e403,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-ec273c04-8195-448c-94e9-9f715eb7f179,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-9f48ce79-83fc-4bf8-8b7d-7e9f3eca694b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-690915629-172.17.0.5-1595900290679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45397,DS-d6b3ccb8-37cc-43c9-9165-dc8da95ea68a,DISK], DatanodeInfoWithStorage[127.0.0.1:44938,DS-7685aa91-7565-4631-b9bf-6b614d4f13af,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-dac9becc-cbb6-4db3-bf56-deb47763ca98,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-dd620609-c4cc-42c0-9a32-bafade5e01fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-ee568ccc-d29c-4bc6-88e6-838a56f1e613,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-f38adde2-7b48-4f1d-b965-0861d7b04b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-7d3faefe-33d1-43df-992a-4b43027ce27a,DISK], DatanodeInfoWithStorage[127.0.0.1:41996,DS-0d6ee1be-a17f-46cf-98a2-9a77e3ad865e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-690915629-172.17.0.5-1595900290679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45397,DS-d6b3ccb8-37cc-43c9-9165-dc8da95ea68a,DISK], DatanodeInfoWithStorage[127.0.0.1:44938,DS-7685aa91-7565-4631-b9bf-6b614d4f13af,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-dac9becc-cbb6-4db3-bf56-deb47763ca98,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-dd620609-c4cc-42c0-9a32-bafade5e01fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-ee568ccc-d29c-4bc6-88e6-838a56f1e613,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-f38adde2-7b48-4f1d-b965-0861d7b04b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-7d3faefe-33d1-43df-992a-4b43027ce27a,DISK], DatanodeInfoWithStorage[127.0.0.1:41996,DS-0d6ee1be-a17f-46cf-98a2-9a77e3ad865e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-71117230-172.17.0.5-1595900770329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36167,DS-6b6c17f5-a09b-4dfc-862e-79d87c3c517f,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-4052b57e-aa4f-4485-a6c4-8edc45339ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-ef0055b0-5ec8-4302-9d20-ec0487bc7b34,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-a410d58c-7437-4b80-9660-ff59e8ee5d43,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-bec5b498-de20-4489-9d1a-5fb58cedef08,DISK], DatanodeInfoWithStorage[127.0.0.1:41847,DS-55f2b285-38fa-4794-b92c-fc76cc221985,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-4c4a337b-7e70-40d5-86bd-4eba843d48b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-34895c03-70a6-404a-b804-c74e808da814,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-71117230-172.17.0.5-1595900770329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36167,DS-6b6c17f5-a09b-4dfc-862e-79d87c3c517f,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-4052b57e-aa4f-4485-a6c4-8edc45339ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-ef0055b0-5ec8-4302-9d20-ec0487bc7b34,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-a410d58c-7437-4b80-9660-ff59e8ee5d43,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-bec5b498-de20-4489-9d1a-5fb58cedef08,DISK], DatanodeInfoWithStorage[127.0.0.1:41847,DS-55f2b285-38fa-4794-b92c-fc76cc221985,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-4c4a337b-7e70-40d5-86bd-4eba843d48b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-34895c03-70a6-404a-b804-c74e808da814,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2118526151-172.17.0.5-1595900883936:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44955,DS-43007713-67e4-42fc-b4e0-c52056cfacd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-98ac1867-106f-4a5c-826e-8ce5fbbc68af,DISK], DatanodeInfoWithStorage[127.0.0.1:39182,DS-2193228a-d75a-4dd0-bc01-7684b70a977d,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-12031eda-392b-4a48-841f-ec90310073ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-0d0f84c1-c9e9-4a20-be16-132c9428e30f,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-7f00155c-fc3a-4b39-8e0c-659e870c7814,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-924d0a10-266e-4505-b8e5-b4b85da08b06,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-cb63a84d-283f-4520-958d-e6902bf19760,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2118526151-172.17.0.5-1595900883936:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44955,DS-43007713-67e4-42fc-b4e0-c52056cfacd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-98ac1867-106f-4a5c-826e-8ce5fbbc68af,DISK], DatanodeInfoWithStorage[127.0.0.1:39182,DS-2193228a-d75a-4dd0-bc01-7684b70a977d,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-12031eda-392b-4a48-841f-ec90310073ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-0d0f84c1-c9e9-4a20-be16-132c9428e30f,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-7f00155c-fc3a-4b39-8e0c-659e870c7814,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-924d0a10-266e-4505-b8e5-b4b85da08b06,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-cb63a84d-283f-4520-958d-e6902bf19760,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-669281690-172.17.0.5-1595900960956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41040,DS-b61a99f8-a2f6-42db-a9bd-43f69e9ada45,DISK], DatanodeInfoWithStorage[127.0.0.1:32938,DS-39acd4a3-9189-433d-95bc-803813eaead0,DISK], DatanodeInfoWithStorage[127.0.0.1:42886,DS-81b363e1-f6f8-4d30-b1d0-fa2341f82a50,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-3872fae0-c4e1-4728-9e9f-8c2150246736,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-c0bc8aa4-f175-43ba-bf5b-af571c1dedce,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-0bb5812f-f41d-4a82-b7e8-b013e224dba1,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-19aa17d5-0b6b-4cd4-9fbf-1cea2f13115f,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-51eb731d-ca2b-43e5-b1a4-7a4e1e9a8fdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-669281690-172.17.0.5-1595900960956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41040,DS-b61a99f8-a2f6-42db-a9bd-43f69e9ada45,DISK], DatanodeInfoWithStorage[127.0.0.1:32938,DS-39acd4a3-9189-433d-95bc-803813eaead0,DISK], DatanodeInfoWithStorage[127.0.0.1:42886,DS-81b363e1-f6f8-4d30-b1d0-fa2341f82a50,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-3872fae0-c4e1-4728-9e9f-8c2150246736,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-c0bc8aa4-f175-43ba-bf5b-af571c1dedce,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-0bb5812f-f41d-4a82-b7e8-b013e224dba1,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-19aa17d5-0b6b-4cd4-9fbf-1cea2f13115f,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-51eb731d-ca2b-43e5-b1a4-7a4e1e9a8fdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1165405377-172.17.0.5-1595900993036:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45995,DS-b882156a-73ff-4e5b-a2d4-c35d3a652135,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-f3866077-8bf9-451b-b70f-c01ed89d3547,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-b8474d42-edf1-4601-9f0a-ad96c62d1648,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-f1b3baeb-ee5d-4743-9906-363306c60868,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-e430430d-5e64-4038-b5fc-8e9460e9fa7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35301,DS-f28dde1f-84ab-42ed-8a65-37cada8c0c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-21f8e115-9677-40c4-b5af-cf84aece62e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44501,DS-ed29af46-d919-45f0-8b05-feeef8e9160e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1165405377-172.17.0.5-1595900993036:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45995,DS-b882156a-73ff-4e5b-a2d4-c35d3a652135,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-f3866077-8bf9-451b-b70f-c01ed89d3547,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-b8474d42-edf1-4601-9f0a-ad96c62d1648,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-f1b3baeb-ee5d-4743-9906-363306c60868,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-e430430d-5e64-4038-b5fc-8e9460e9fa7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35301,DS-f28dde1f-84ab-42ed-8a65-37cada8c0c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-21f8e115-9677-40c4-b5af-cf84aece62e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44501,DS-ed29af46-d919-45f0-8b05-feeef8e9160e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5275
