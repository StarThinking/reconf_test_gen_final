reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-40423249-172.17.0.4-1595810060301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33008,DS-b0531ef1-8c59-45be-b538-cda455da6e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-a3efbbce-6123-4c41-8184-c70620d2096d,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-e4725194-ac40-48fa-a444-a4d0bd8bf008,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-b20d48aa-3c0c-4263-80ca-35e3c7f6bced,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-3c56053c-6c5f-482a-9fd4-eb020028ad24,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-95979478-e686-4696-8c6c-d0a3c49a27a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-3653a1e5-8a15-41a2-9054-7060befa2428,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-10a29e6e-bf59-4014-b5a9-57fc6c56b5bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-40423249-172.17.0.4-1595810060301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33008,DS-b0531ef1-8c59-45be-b538-cda455da6e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-a3efbbce-6123-4c41-8184-c70620d2096d,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-e4725194-ac40-48fa-a444-a4d0bd8bf008,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-b20d48aa-3c0c-4263-80ca-35e3c7f6bced,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-3c56053c-6c5f-482a-9fd4-eb020028ad24,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-95979478-e686-4696-8c6c-d0a3c49a27a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-3653a1e5-8a15-41a2-9054-7060befa2428,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-10a29e6e-bf59-4014-b5a9-57fc6c56b5bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-770555537-172.17.0.4-1595810097751:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46826,DS-c41af242-e2fc-4ce9-b6ed-dd32adbbf013,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-04de6be2-dd32-46e7-a1ae-40aeb8bd2ade,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-0bf96b19-22af-4e1f-b5cd-2c5bb37dfbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-f9b28659-ec7e-4e12-91f4-3ed7d9658c54,DISK], DatanodeInfoWithStorage[127.0.0.1:40376,DS-8c0e082e-47cd-4a97-be0a-7b91e7ebdefb,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-c98a6a13-3ec2-47ee-9b3b-6f2e68a41585,DISK], DatanodeInfoWithStorage[127.0.0.1:33264,DS-33f9e9d7-36bc-4ee7-a6f3-cd7a5d906226,DISK], DatanodeInfoWithStorage[127.0.0.1:41710,DS-648b9193-ef80-42c3-b169-6fb579917dfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-770555537-172.17.0.4-1595810097751:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46826,DS-c41af242-e2fc-4ce9-b6ed-dd32adbbf013,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-04de6be2-dd32-46e7-a1ae-40aeb8bd2ade,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-0bf96b19-22af-4e1f-b5cd-2c5bb37dfbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-f9b28659-ec7e-4e12-91f4-3ed7d9658c54,DISK], DatanodeInfoWithStorage[127.0.0.1:40376,DS-8c0e082e-47cd-4a97-be0a-7b91e7ebdefb,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-c98a6a13-3ec2-47ee-9b3b-6f2e68a41585,DISK], DatanodeInfoWithStorage[127.0.0.1:33264,DS-33f9e9d7-36bc-4ee7-a6f3-cd7a5d906226,DISK], DatanodeInfoWithStorage[127.0.0.1:41710,DS-648b9193-ef80-42c3-b169-6fb579917dfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1924973758-172.17.0.4-1595810174517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44533,DS-babd9627-6b23-454e-8db0-92cf6ed3b886,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-7097e445-f7d7-42c0-99b3-8f2a8167fb26,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-3ad41dec-049f-484d-a6dd-81aced7add2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38173,DS-d0f8cd30-88b4-4d57-a8d0-014f57982edf,DISK], DatanodeInfoWithStorage[127.0.0.1:41101,DS-159251c6-91ca-44d2-b625-4a53263313e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40422,DS-ff8eabb9-517b-4e32-8cc6-2bee65e3ee54,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-89d873fa-1fac-4cc0-80d7-fcf35efe9743,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-783cf47f-4291-4d84-9281-7cc672424beb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1924973758-172.17.0.4-1595810174517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44533,DS-babd9627-6b23-454e-8db0-92cf6ed3b886,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-7097e445-f7d7-42c0-99b3-8f2a8167fb26,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-3ad41dec-049f-484d-a6dd-81aced7add2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38173,DS-d0f8cd30-88b4-4d57-a8d0-014f57982edf,DISK], DatanodeInfoWithStorage[127.0.0.1:41101,DS-159251c6-91ca-44d2-b625-4a53263313e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40422,DS-ff8eabb9-517b-4e32-8cc6-2bee65e3ee54,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-89d873fa-1fac-4cc0-80d7-fcf35efe9743,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-783cf47f-4291-4d84-9281-7cc672424beb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-377177079-172.17.0.4-1595810355171:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44843,DS-258ce6ef-f37b-475e-8eeb-eb028bbae450,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-9952467d-c44c-4014-999b-f85a93861549,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-f7accbb1-589f-4fd1-9241-92b501150660,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-b254e8b4-7d71-4a2f-96ae-dcc53f056587,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-02fc88d4-9dd3-4880-9f06-3a20137ed829,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-027c94a0-f9bf-4531-b0f8-f0c00abfb593,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-66e6c4f6-e82d-4bc6-ae41-553741c2fd00,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-972704fb-2db8-4ed7-bd60-5ef33df78dbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-377177079-172.17.0.4-1595810355171:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44843,DS-258ce6ef-f37b-475e-8eeb-eb028bbae450,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-9952467d-c44c-4014-999b-f85a93861549,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-f7accbb1-589f-4fd1-9241-92b501150660,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-b254e8b4-7d71-4a2f-96ae-dcc53f056587,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-02fc88d4-9dd3-4880-9f06-3a20137ed829,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-027c94a0-f9bf-4531-b0f8-f0c00abfb593,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-66e6c4f6-e82d-4bc6-ae41-553741c2fd00,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-972704fb-2db8-4ed7-bd60-5ef33df78dbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-237577504-172.17.0.4-1595810814663:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39256,DS-747c6035-81df-498b-93d5-9d0e76dbe2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-506a7c43-4c37-4266-aa69-b4941e690d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-33378f04-c3e8-4990-942f-07de0fcc66c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-6c679a00-9082-474d-82fd-40c1508de225,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-8d2d62de-4705-4e7a-9ccb-59dfff120910,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-87a7d97f-383a-4997-b829-ae5472871268,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-659e5a35-4dd9-498c-bd5a-ce8e75e27f98,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-3a993df6-1b2f-4b23-a216-c1c517ef7ac1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-237577504-172.17.0.4-1595810814663:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39256,DS-747c6035-81df-498b-93d5-9d0e76dbe2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-506a7c43-4c37-4266-aa69-b4941e690d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-33378f04-c3e8-4990-942f-07de0fcc66c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-6c679a00-9082-474d-82fd-40c1508de225,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-8d2d62de-4705-4e7a-9ccb-59dfff120910,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-87a7d97f-383a-4997-b829-ae5472871268,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-659e5a35-4dd9-498c-bd5a-ce8e75e27f98,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-3a993df6-1b2f-4b23-a216-c1c517ef7ac1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1131095240-172.17.0.4-1595812006955:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43535,DS-7dee0fda-4eaf-4a3a-aa88-e1aec836f5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-ba2fe6c3-b1b0-4ec8-ae7e-ce0d09924df6,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-7246d186-c4b5-4368-aff8-ab23cd888698,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-87697a10-fa6c-4a77-ab01-91b0a11fbd49,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-0ba57c58-a2cf-4a19-9bba-4dba6f7d7f66,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-9a01b4ff-b132-4c59-a9a7-1198c7a8a22d,DISK], DatanodeInfoWithStorage[127.0.0.1:45118,DS-93f8dc7e-46c3-402a-baae-ce2f4dac1fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-5112cb4e-aa60-4831-a6a7-8abe98fd4829,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1131095240-172.17.0.4-1595812006955:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43535,DS-7dee0fda-4eaf-4a3a-aa88-e1aec836f5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-ba2fe6c3-b1b0-4ec8-ae7e-ce0d09924df6,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-7246d186-c4b5-4368-aff8-ab23cd888698,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-87697a10-fa6c-4a77-ab01-91b0a11fbd49,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-0ba57c58-a2cf-4a19-9bba-4dba6f7d7f66,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-9a01b4ff-b132-4c59-a9a7-1198c7a8a22d,DISK], DatanodeInfoWithStorage[127.0.0.1:45118,DS-93f8dc7e-46c3-402a-baae-ce2f4dac1fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-5112cb4e-aa60-4831-a6a7-8abe98fd4829,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1930830551-172.17.0.4-1595812426870:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43790,DS-8ecb44d1-1d6e-4d3c-8ff0-5086c8f91a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-a6d7a6ba-6128-46ac-8f93-7110cfed9735,DISK], DatanodeInfoWithStorage[127.0.0.1:44794,DS-e608a14f-8dcb-4003-8bd3-5ec3be36298d,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-bf252957-e5f0-4cf6-b312-ba4ded314959,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-3c36c1e8-ec77-4c9f-a725-6a80b809989a,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-e4db91ee-8257-4561-be3e-e1fc5a03ba98,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-d1c358f2-31d5-49a4-8c11-a54ed18f8232,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-b6809e4f-8f91-40ae-b9d8-9ef009cdd630,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1930830551-172.17.0.4-1595812426870:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43790,DS-8ecb44d1-1d6e-4d3c-8ff0-5086c8f91a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-a6d7a6ba-6128-46ac-8f93-7110cfed9735,DISK], DatanodeInfoWithStorage[127.0.0.1:44794,DS-e608a14f-8dcb-4003-8bd3-5ec3be36298d,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-bf252957-e5f0-4cf6-b312-ba4ded314959,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-3c36c1e8-ec77-4c9f-a725-6a80b809989a,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-e4db91ee-8257-4561-be3e-e1fc5a03ba98,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-d1c358f2-31d5-49a4-8c11-a54ed18f8232,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-b6809e4f-8f91-40ae-b9d8-9ef009cdd630,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1277651058-172.17.0.4-1595812933678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33314,DS-349597fe-da46-4d3a-a3f2-4069792b4a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42251,DS-9094b1ce-a1a7-4eb7-b4f9-8940ab0be4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-e4a89503-20d7-4ec2-94b9-695fdc92359e,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-40665464-709b-4d1a-8125-b3ae47e3d581,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-dca07143-92e7-4308-8fa9-d6a9ee1551be,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-d3bab571-a0ea-4d18-be73-55ad319e7f25,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-e5a81107-c1c9-4f6f-941c-27fc63bd2e79,DISK], DatanodeInfoWithStorage[127.0.0.1:45683,DS-c8344ed2-dd5c-4406-bf4b-09e8f13126d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1277651058-172.17.0.4-1595812933678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33314,DS-349597fe-da46-4d3a-a3f2-4069792b4a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42251,DS-9094b1ce-a1a7-4eb7-b4f9-8940ab0be4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-e4a89503-20d7-4ec2-94b9-695fdc92359e,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-40665464-709b-4d1a-8125-b3ae47e3d581,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-dca07143-92e7-4308-8fa9-d6a9ee1551be,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-d3bab571-a0ea-4d18-be73-55ad319e7f25,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-e5a81107-c1c9-4f6f-941c-27fc63bd2e79,DISK], DatanodeInfoWithStorage[127.0.0.1:45683,DS-c8344ed2-dd5c-4406-bf4b-09e8f13126d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1694416669-172.17.0.4-1595813074471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43310,DS-6d6e49e4-e0d6-4ed4-8c2f-d6f5dd4525a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42480,DS-e4ac7ac7-c983-4ba6-9441-4815fea3c5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-71bc6d6c-0617-443a-8ab9-f1ed8fa99c18,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-0b8e9d2f-0f51-437c-a46b-37e7127b66ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-e28fd074-9d84-40ac-93cb-d4951ae97337,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-dcdff1cd-f8c5-4cc5-9bf9-4c2f801c6199,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-8cc6cba9-30e6-47b6-b6d1-9616b20b7bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-d04b7819-49c1-4d38-a603-37c506fbd873,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1694416669-172.17.0.4-1595813074471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43310,DS-6d6e49e4-e0d6-4ed4-8c2f-d6f5dd4525a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42480,DS-e4ac7ac7-c983-4ba6-9441-4815fea3c5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-71bc6d6c-0617-443a-8ab9-f1ed8fa99c18,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-0b8e9d2f-0f51-437c-a46b-37e7127b66ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-e28fd074-9d84-40ac-93cb-d4951ae97337,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-dcdff1cd-f8c5-4cc5-9bf9-4c2f801c6199,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-8cc6cba9-30e6-47b6-b6d1-9616b20b7bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-d04b7819-49c1-4d38-a603-37c506fbd873,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-835393243-172.17.0.4-1595813530005:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35249,DS-fa84fd27-7d51-48ba-a3c8-8f93a1ace352,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-4d0fdbdd-086b-4c5a-ac7b-40e8a7d53c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-760033fd-4847-4444-b0a6-ca59c4144bce,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-1a7e71e7-e622-4c6d-bd7c-b4d1c657bedb,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-2e54304a-1707-494c-9845-96a6a7cc6d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-2d63bbe2-3795-4ded-982b-d3ae8c44b761,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-ae19c2e9-d354-4a15-ae38-a44b8220d32b,DISK], DatanodeInfoWithStorage[127.0.0.1:46834,DS-52d4fc73-eb5b-4986-ab5f-771ff3af990b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-835393243-172.17.0.4-1595813530005:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35249,DS-fa84fd27-7d51-48ba-a3c8-8f93a1ace352,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-4d0fdbdd-086b-4c5a-ac7b-40e8a7d53c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-760033fd-4847-4444-b0a6-ca59c4144bce,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-1a7e71e7-e622-4c6d-bd7c-b4d1c657bedb,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-2e54304a-1707-494c-9845-96a6a7cc6d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-2d63bbe2-3795-4ded-982b-d3ae8c44b761,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-ae19c2e9-d354-4a15-ae38-a44b8220d32b,DISK], DatanodeInfoWithStorage[127.0.0.1:46834,DS-52d4fc73-eb5b-4986-ab5f-771ff3af990b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1719070884-172.17.0.4-1595813572288:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36119,DS-e7c74e9b-b8b3-4520-94c7-fe28db843b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-2e16073d-1b00-4169-a4da-1fb674cef0be,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-b0c7355f-8d32-488a-aede-5d3e07652cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42164,DS-b92a513d-bc61-4b57-bf3d-f276a2f58c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-0ea187e1-20d4-4635-bb18-580f78d00def,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-3f0beb2b-93e4-43c6-9d9b-2067b2aff678,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-ea168510-eb78-4e46-a3dc-a229117f7af9,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-f1422eff-203a-44a4-9813-a680e6698b4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1719070884-172.17.0.4-1595813572288:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36119,DS-e7c74e9b-b8b3-4520-94c7-fe28db843b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-2e16073d-1b00-4169-a4da-1fb674cef0be,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-b0c7355f-8d32-488a-aede-5d3e07652cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42164,DS-b92a513d-bc61-4b57-bf3d-f276a2f58c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-0ea187e1-20d4-4635-bb18-580f78d00def,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-3f0beb2b-93e4-43c6-9d9b-2067b2aff678,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-ea168510-eb78-4e46-a3dc-a229117f7af9,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-f1422eff-203a-44a4-9813-a680e6698b4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-59025308-172.17.0.4-1595813606444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34004,DS-c14b58c2-ce37-4c87-ab64-35d3bd71dcf1,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-cccedfb4-ef65-474f-bef5-23d744f96200,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-0f974169-bf8f-41eb-96c0-e3f638559b21,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-e8b4f141-2db7-4eca-ae1f-d026dea76995,DISK], DatanodeInfoWithStorage[127.0.0.1:40283,DS-e7450ab2-fef5-4d4d-b1c7-f961614be5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-87f24471-daa6-4643-ad5f-fab3ea3cfdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-306f7b7b-8a7d-4918-b395-0b334239f3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-cdb7ee68-0434-4fd9-b7a2-65dbd914b522,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-59025308-172.17.0.4-1595813606444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34004,DS-c14b58c2-ce37-4c87-ab64-35d3bd71dcf1,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-cccedfb4-ef65-474f-bef5-23d744f96200,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-0f974169-bf8f-41eb-96c0-e3f638559b21,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-e8b4f141-2db7-4eca-ae1f-d026dea76995,DISK], DatanodeInfoWithStorage[127.0.0.1:40283,DS-e7450ab2-fef5-4d4d-b1c7-f961614be5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-87f24471-daa6-4643-ad5f-fab3ea3cfdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-306f7b7b-8a7d-4918-b395-0b334239f3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-cdb7ee68-0434-4fd9-b7a2-65dbd914b522,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-936225932-172.17.0.4-1595813718189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33271,DS-eecd0bc8-75a9-4138-abbd-36fea713a7f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37595,DS-2697786d-86e0-4841-a514-6501cc877565,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-6c75e5a7-265c-4fc8-bad6-92b469eb0adc,DISK], DatanodeInfoWithStorage[127.0.0.1:41925,DS-02eafc68-e4d3-4bd5-81c6-d89b373e985d,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-d3124eba-8c81-4867-9b8e-3f42b12d7bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-2153ca70-d99f-46ab-959b-966ba4ab7638,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-81b3a779-5577-4692-843a-b03dcd3f3f65,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-648a307a-ec90-49eb-8c2f-f0f9ddc30922,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-936225932-172.17.0.4-1595813718189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33271,DS-eecd0bc8-75a9-4138-abbd-36fea713a7f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37595,DS-2697786d-86e0-4841-a514-6501cc877565,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-6c75e5a7-265c-4fc8-bad6-92b469eb0adc,DISK], DatanodeInfoWithStorage[127.0.0.1:41925,DS-02eafc68-e4d3-4bd5-81c6-d89b373e985d,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-d3124eba-8c81-4867-9b8e-3f42b12d7bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-2153ca70-d99f-46ab-959b-966ba4ab7638,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-81b3a779-5577-4692-843a-b03dcd3f3f65,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-648a307a-ec90-49eb-8c2f-f0f9ddc30922,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2020976231-172.17.0.4-1595814276064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35983,DS-e03e5b2b-f36b-4ac5-8df5-82d44dfa6e69,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-5a2953fc-bc3b-4e05-a6de-e6a12dcc101d,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-c91a6e67-8df8-4e49-90b9-93c055bb6a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36694,DS-9e4f45bb-5552-4a60-8f92-1f9089430904,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-e051606a-e65e-4411-9f91-e90273f63b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-566faf2a-0738-4126-9157-94e3ac8d0054,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-f78b92a9-a2e8-4858-b169-87070e749e92,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-4e4a12dc-d999-4f83-be71-4096381de90c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2020976231-172.17.0.4-1595814276064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35983,DS-e03e5b2b-f36b-4ac5-8df5-82d44dfa6e69,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-5a2953fc-bc3b-4e05-a6de-e6a12dcc101d,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-c91a6e67-8df8-4e49-90b9-93c055bb6a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36694,DS-9e4f45bb-5552-4a60-8f92-1f9089430904,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-e051606a-e65e-4411-9f91-e90273f63b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-566faf2a-0738-4126-9157-94e3ac8d0054,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-f78b92a9-a2e8-4858-b169-87070e749e92,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-4e4a12dc-d999-4f83-be71-4096381de90c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-339136183-172.17.0.4-1595814426416:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33180,DS-bc19719a-1dd1-45f0-b3ef-bb9a96308642,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-7d2063bc-c447-4a89-8cf7-7de35363aa77,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-4068649e-b124-42c4-983b-f2f300460630,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-9b2347b4-cd66-4b38-87d4-9412a30523b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-8448945c-329e-4997-b360-57bf1a3eaf31,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-818fe51d-1267-4969-8f32-3b053a2c82fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-934f753d-91a0-4c8f-a85f-a27ead33dba2,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-6778d3aa-c076-45da-8074-83851e90a4d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-339136183-172.17.0.4-1595814426416:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33180,DS-bc19719a-1dd1-45f0-b3ef-bb9a96308642,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-7d2063bc-c447-4a89-8cf7-7de35363aa77,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-4068649e-b124-42c4-983b-f2f300460630,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-9b2347b4-cd66-4b38-87d4-9412a30523b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-8448945c-329e-4997-b360-57bf1a3eaf31,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-818fe51d-1267-4969-8f32-3b053a2c82fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-934f753d-91a0-4c8f-a85f-a27ead33dba2,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-6778d3aa-c076-45da-8074-83851e90a4d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-229882008-172.17.0.4-1595814490436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43461,DS-26c93b0b-15a7-4346-a67a-f37166a24b14,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-f56a7187-a443-4c54-ac8f-015f0066ffa1,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-302f5ced-ca57-4cbd-a34c-dc366cc8e8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-f2e944c2-2c83-4107-b8e7-ff64ee21c4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38775,DS-a5af3dde-d067-4e6a-97ac-0a43989f3a97,DISK], DatanodeInfoWithStorage[127.0.0.1:34010,DS-5ffbc18c-8fb1-4344-b0d9-c28030617d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40358,DS-bded57e3-d54a-4790-ab3e-a73a1e7ac2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35300,DS-949c2372-4b97-421c-835e-07d5aa151fa4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-229882008-172.17.0.4-1595814490436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43461,DS-26c93b0b-15a7-4346-a67a-f37166a24b14,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-f56a7187-a443-4c54-ac8f-015f0066ffa1,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-302f5ced-ca57-4cbd-a34c-dc366cc8e8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-f2e944c2-2c83-4107-b8e7-ff64ee21c4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38775,DS-a5af3dde-d067-4e6a-97ac-0a43989f3a97,DISK], DatanodeInfoWithStorage[127.0.0.1:34010,DS-5ffbc18c-8fb1-4344-b0d9-c28030617d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40358,DS-bded57e3-d54a-4790-ab3e-a73a1e7ac2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35300,DS-949c2372-4b97-421c-835e-07d5aa151fa4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2111052931-172.17.0.4-1595814682109:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39909,DS-19af6294-9b30-439a-81bd-674fd5854711,DISK], DatanodeInfoWithStorage[127.0.0.1:34402,DS-09956ac4-892a-432b-ab17-3bb25b93a659,DISK], DatanodeInfoWithStorage[127.0.0.1:43232,DS-8a5f46de-9597-4559-b1b0-2d6397586322,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-b4d1be2b-503e-4a18-9fe1-41c3979db223,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-8851ee13-966c-44fe-8aa9-60f95872e4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-6fde15a4-5807-4f04-9136-596e93e67a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-6bc7c44a-0ec6-4e8d-9274-df2787341d05,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-3f1558d2-3cb7-41c5-a7eb-26963dec0f67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2111052931-172.17.0.4-1595814682109:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39909,DS-19af6294-9b30-439a-81bd-674fd5854711,DISK], DatanodeInfoWithStorage[127.0.0.1:34402,DS-09956ac4-892a-432b-ab17-3bb25b93a659,DISK], DatanodeInfoWithStorage[127.0.0.1:43232,DS-8a5f46de-9597-4559-b1b0-2d6397586322,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-b4d1be2b-503e-4a18-9fe1-41c3979db223,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-8851ee13-966c-44fe-8aa9-60f95872e4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-6fde15a4-5807-4f04-9136-596e93e67a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-6bc7c44a-0ec6-4e8d-9274-df2787341d05,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-3f1558d2-3cb7-41c5-a7eb-26963dec0f67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1327012986-172.17.0.4-1595814899782:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37287,DS-9b88f642-d03f-4aa7-a3fd-cdca26dfdca0,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-654cfcfe-e51b-4500-b3ce-f634d9e9f422,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-8dcb449d-d5b3-4e01-839d-b5bdef7701a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-c8025e4c-cc96-4aa5-9fa8-973ad0e51a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-c9134166-331c-4bb0-baa3-26d207862042,DISK], DatanodeInfoWithStorage[127.0.0.1:34529,DS-db22211a-a42f-44ee-8869-b93ddf13373d,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-178d4bc8-0018-4012-b5c5-6b8aa819dc62,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-6635138e-eae5-4e05-a037-e59555b6e6ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1327012986-172.17.0.4-1595814899782:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37287,DS-9b88f642-d03f-4aa7-a3fd-cdca26dfdca0,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-654cfcfe-e51b-4500-b3ce-f634d9e9f422,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-8dcb449d-d5b3-4e01-839d-b5bdef7701a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-c8025e4c-cc96-4aa5-9fa8-973ad0e51a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-c9134166-331c-4bb0-baa3-26d207862042,DISK], DatanodeInfoWithStorage[127.0.0.1:34529,DS-db22211a-a42f-44ee-8869-b93ddf13373d,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-178d4bc8-0018-4012-b5c5-6b8aa819dc62,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-6635138e-eae5-4e05-a037-e59555b6e6ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-867282351-172.17.0.4-1595814932514:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37409,DS-d62f3386-09bf-461d-87a1-84f21d07387b,DISK], DatanodeInfoWithStorage[127.0.0.1:43004,DS-cc0386da-27fe-4691-846a-d166529edae2,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-064c279f-7618-453a-9440-faab3cee3019,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-11a7e838-6fa6-49cf-bb44-9dd7b96816eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-f98f11a6-fa7b-4a3a-a53c-79bcc40d1ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:35557,DS-04beb905-33a9-4c76-8fe1-4a56b2f2ce51,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-ccfbfe3a-7838-4d0d-9a32-b8291e5e516d,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-fdad93cc-a6fc-406e-8b38-f02df35fc7e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-867282351-172.17.0.4-1595814932514:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37409,DS-d62f3386-09bf-461d-87a1-84f21d07387b,DISK], DatanodeInfoWithStorage[127.0.0.1:43004,DS-cc0386da-27fe-4691-846a-d166529edae2,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-064c279f-7618-453a-9440-faab3cee3019,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-11a7e838-6fa6-49cf-bb44-9dd7b96816eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-f98f11a6-fa7b-4a3a-a53c-79bcc40d1ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:35557,DS-04beb905-33a9-4c76-8fe1-4a56b2f2ce51,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-ccfbfe3a-7838-4d0d-9a32-b8291e5e516d,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-fdad93cc-a6fc-406e-8b38-f02df35fc7e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1295910113-172.17.0.4-1595815006832:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40239,DS-847c94e0-e921-4d73-b66e-2c610a8733c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38962,DS-55d1f92b-d048-4bc2-9efb-d4da6393400f,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-1e72aafd-8588-415b-9309-e1511c4b30ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-a813e5a9-3223-4a81-941f-639718abfd8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-d8057488-70c8-4254-8583-86da992e46ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-8f8e20bd-fe5a-4fef-8d28-6988eb141eca,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-f0794d94-bf2f-4612-a090-da3b947a69fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-67bd2333-b0ee-4e4a-a432-8385e8c727e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1295910113-172.17.0.4-1595815006832:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40239,DS-847c94e0-e921-4d73-b66e-2c610a8733c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38962,DS-55d1f92b-d048-4bc2-9efb-d4da6393400f,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-1e72aafd-8588-415b-9309-e1511c4b30ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-a813e5a9-3223-4a81-941f-639718abfd8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-d8057488-70c8-4254-8583-86da992e46ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-8f8e20bd-fe5a-4fef-8d28-6988eb141eca,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-f0794d94-bf2f-4612-a090-da3b947a69fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-67bd2333-b0ee-4e4a-a432-8385e8c727e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5308
