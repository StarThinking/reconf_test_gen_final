reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-79442228-172.17.0.18-1595949703768:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34564,DS-e136aa0f-ace4-4d20-8b7e-a807a232aa43,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-c9ccb781-3bb7-439a-9a4f-5fa8c7e07251,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-1aa2872a-2a4e-4416-926e-84aa80a003d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-96d2e8e7-e057-4431-94c4-08e4b8c00450,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-607da6df-1752-48ca-a1f9-46bb897ad8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42541,DS-53f65201-09e2-4734-9433-e7f792ce1acd,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-40438e2a-3268-4e96-8a98-890f578cbf20,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-5fead7ea-ebe9-4f8a-a891-22270e18a16d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-79442228-172.17.0.18-1595949703768:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34564,DS-e136aa0f-ace4-4d20-8b7e-a807a232aa43,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-c9ccb781-3bb7-439a-9a4f-5fa8c7e07251,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-1aa2872a-2a4e-4416-926e-84aa80a003d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-96d2e8e7-e057-4431-94c4-08e4b8c00450,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-607da6df-1752-48ca-a1f9-46bb897ad8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42541,DS-53f65201-09e2-4734-9433-e7f792ce1acd,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-40438e2a-3268-4e96-8a98-890f578cbf20,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-5fead7ea-ebe9-4f8a-a891-22270e18a16d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2126065476-172.17.0.18-1595949770770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35382,DS-0113282c-a27a-4fef-ac2f-b8fe67352bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:36026,DS-0dd79628-4eca-4d3c-92ed-cc03ad323fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:46081,DS-5b0ace11-ba20-445f-a69e-c73887d988d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-5076b7b3-160f-4af6-968d-1988e17c28fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-6543cbf2-879c-44e3-b97b-7a41f32a6a06,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-7e3fc40e-68d6-43f9-b62c-151c96e22f17,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-e8e9a036-6d28-46dd-b11a-4650b48134f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-68ec8b48-e90d-4365-a3c3-c277d886fff9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2126065476-172.17.0.18-1595949770770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35382,DS-0113282c-a27a-4fef-ac2f-b8fe67352bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:36026,DS-0dd79628-4eca-4d3c-92ed-cc03ad323fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:46081,DS-5b0ace11-ba20-445f-a69e-c73887d988d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-5076b7b3-160f-4af6-968d-1988e17c28fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-6543cbf2-879c-44e3-b97b-7a41f32a6a06,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-7e3fc40e-68d6-43f9-b62c-151c96e22f17,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-e8e9a036-6d28-46dd-b11a-4650b48134f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-68ec8b48-e90d-4365-a3c3-c277d886fff9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-457659288-172.17.0.18-1595950794376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37675,DS-a3e30dde-930d-49b7-9e70-363a3a763a44,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-5e071f77-2098-4cea-a804-4c7c311fa7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-281790d4-2eba-4570-a925-496517d40304,DISK], DatanodeInfoWithStorage[127.0.0.1:40670,DS-fed0ae20-dd56-4f3b-9303-4e469ccc3600,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-f49bd8da-f790-4b1b-b561-632f45466935,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-44ad5175-80e2-4d52-89b4-71feca98b091,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-aeb2729c-fdff-4a03-bbf5-efcf20cf51e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-d2c18c86-ed0f-459b-9fa3-2bee41104f2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-457659288-172.17.0.18-1595950794376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37675,DS-a3e30dde-930d-49b7-9e70-363a3a763a44,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-5e071f77-2098-4cea-a804-4c7c311fa7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-281790d4-2eba-4570-a925-496517d40304,DISK], DatanodeInfoWithStorage[127.0.0.1:40670,DS-fed0ae20-dd56-4f3b-9303-4e469ccc3600,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-f49bd8da-f790-4b1b-b561-632f45466935,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-44ad5175-80e2-4d52-89b4-71feca98b091,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-aeb2729c-fdff-4a03-bbf5-efcf20cf51e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-d2c18c86-ed0f-459b-9fa3-2bee41104f2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1274166821-172.17.0.18-1595950830739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40223,DS-cfcaa21c-5786-4967-bd39-1d023c571028,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-4c47f622-74a3-41b5-afc0-a8a68581feed,DISK], DatanodeInfoWithStorage[127.0.0.1:36112,DS-a0631e15-66b7-4cc5-a8f0-c8c4ce53f463,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-72b638c8-b0cc-46ad-be84-88d9d0c682ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32928,DS-51b7b633-aedc-4a5d-bfbe-62f8ab24f196,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-e041e526-9c72-4f50-a81b-f8c778cc85da,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-b740a987-857a-4225-a73b-ff8da2819ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-b6a2eca1-f49d-43e5-8fd8-5554d7cbf8cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1274166821-172.17.0.18-1595950830739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40223,DS-cfcaa21c-5786-4967-bd39-1d023c571028,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-4c47f622-74a3-41b5-afc0-a8a68581feed,DISK], DatanodeInfoWithStorage[127.0.0.1:36112,DS-a0631e15-66b7-4cc5-a8f0-c8c4ce53f463,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-72b638c8-b0cc-46ad-be84-88d9d0c682ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32928,DS-51b7b633-aedc-4a5d-bfbe-62f8ab24f196,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-e041e526-9c72-4f50-a81b-f8c778cc85da,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-b740a987-857a-4225-a73b-ff8da2819ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-b6a2eca1-f49d-43e5-8fd8-5554d7cbf8cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1230482520-172.17.0.18-1595951561363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39783,DS-3ec44f75-8add-41b6-87e1-de2a7b29f3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-397ba77c-a0e0-4ecd-880f-632606aea1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-bdc094c3-9739-4657-9823-b2a158ddbc70,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-bf50abe1-07ae-4382-b878-896bf4c986db,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-fc9c8900-658d-4262-a917-828bd5b16120,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-597670d9-22c3-4d19-a247-36ba2c6dbcff,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-ee6b3908-aa01-4494-916a-bb739c50d76b,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-7ab1723a-0266-49f5-b804-9181298a0ee7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1230482520-172.17.0.18-1595951561363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39783,DS-3ec44f75-8add-41b6-87e1-de2a7b29f3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-397ba77c-a0e0-4ecd-880f-632606aea1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-bdc094c3-9739-4657-9823-b2a158ddbc70,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-bf50abe1-07ae-4382-b878-896bf4c986db,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-fc9c8900-658d-4262-a917-828bd5b16120,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-597670d9-22c3-4d19-a247-36ba2c6dbcff,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-ee6b3908-aa01-4494-916a-bb739c50d76b,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-7ab1723a-0266-49f5-b804-9181298a0ee7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-845734126-172.17.0.18-1595951750133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32965,DS-ec911957-dcc3-4d08-8bcf-8a34fd2b3336,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-d8805b79-e15a-4837-8bc6-bfbed33b0099,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-8b3cdb7c-61a9-43a5-a6be-f0da868da166,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-fa9143ce-8adb-4fc0-ae47-ca7084339fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-c0456c90-cf96-4678-b588-a3bd92dc8ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-5fac109a-cd21-4029-a526-ecccaea7e600,DISK], DatanodeInfoWithStorage[127.0.0.1:42296,DS-46450062-1644-4970-acf9-333690fa036b,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-d815f18c-73e4-440d-ae24-f8b290db0d67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-845734126-172.17.0.18-1595951750133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32965,DS-ec911957-dcc3-4d08-8bcf-8a34fd2b3336,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-d8805b79-e15a-4837-8bc6-bfbed33b0099,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-8b3cdb7c-61a9-43a5-a6be-f0da868da166,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-fa9143ce-8adb-4fc0-ae47-ca7084339fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-c0456c90-cf96-4678-b588-a3bd92dc8ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-5fac109a-cd21-4029-a526-ecccaea7e600,DISK], DatanodeInfoWithStorage[127.0.0.1:42296,DS-46450062-1644-4970-acf9-333690fa036b,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-d815f18c-73e4-440d-ae24-f8b290db0d67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-152430673-172.17.0.18-1595951824603:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46039,DS-b1cc0b8a-b205-4363-9878-2acbf68af41d,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-a93f41a2-22ab-4fd8-99a8-9568f501f33e,DISK], DatanodeInfoWithStorage[127.0.0.1:39026,DS-ce306434-7094-46d6-83b1-5574721dc5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-9ba3f992-e60f-4d17-af81-d95bcc147bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-37e0f5be-44f6-4f97-af15-b3b03a2c0c97,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-18961330-5d4c-45f3-9626-41cc46883971,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-2f28ae18-f2ee-42e6-a92a-0dfa3a4d6c57,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-2b3b85ad-c7b8-42f2-aeb6-e372b55bf845,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-152430673-172.17.0.18-1595951824603:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46039,DS-b1cc0b8a-b205-4363-9878-2acbf68af41d,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-a93f41a2-22ab-4fd8-99a8-9568f501f33e,DISK], DatanodeInfoWithStorage[127.0.0.1:39026,DS-ce306434-7094-46d6-83b1-5574721dc5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-9ba3f992-e60f-4d17-af81-d95bcc147bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-37e0f5be-44f6-4f97-af15-b3b03a2c0c97,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-18961330-5d4c-45f3-9626-41cc46883971,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-2f28ae18-f2ee-42e6-a92a-0dfa3a4d6c57,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-2b3b85ad-c7b8-42f2-aeb6-e372b55bf845,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1523789128-172.17.0.18-1595951946996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43542,DS-482c2f99-da4b-4d5e-bcc3-3eea9ea918f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-18c3cdc1-f5c1-4c69-8e12-faaf6d027e91,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-43d34a75-00c3-434c-a783-a04f83af4367,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-d216604a-c429-48dc-a3cb-f29ce7a2af7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-517119e7-16bd-449f-8c7f-f194a7dbc311,DISK], DatanodeInfoWithStorage[127.0.0.1:35338,DS-3eb7258c-caca-4a8c-8785-9f6cb2fc8242,DISK], DatanodeInfoWithStorage[127.0.0.1:39929,DS-af1e2431-b506-4d69-8bad-fcacb46486c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-b7776691-092c-494b-847f-3bac11444eeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1523789128-172.17.0.18-1595951946996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43542,DS-482c2f99-da4b-4d5e-bcc3-3eea9ea918f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-18c3cdc1-f5c1-4c69-8e12-faaf6d027e91,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-43d34a75-00c3-434c-a783-a04f83af4367,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-d216604a-c429-48dc-a3cb-f29ce7a2af7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-517119e7-16bd-449f-8c7f-f194a7dbc311,DISK], DatanodeInfoWithStorage[127.0.0.1:35338,DS-3eb7258c-caca-4a8c-8785-9f6cb2fc8242,DISK], DatanodeInfoWithStorage[127.0.0.1:39929,DS-af1e2431-b506-4d69-8bad-fcacb46486c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-b7776691-092c-494b-847f-3bac11444eeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-514167536-172.17.0.18-1595952179392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41598,DS-a3c6dd53-8153-405c-bf80-35c44135c803,DISK], DatanodeInfoWithStorage[127.0.0.1:36265,DS-f0c90b48-856b-461c-bb0c-12179d896613,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-90503c9d-cfbc-4355-a95e-28baddc481ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37208,DS-262cb577-89fd-4a07-a392-cfb1b91466e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-4639cf73-1509-43fb-ab70-83791c82a901,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-1b7dad1b-7960-4271-85cf-aacb7882ae3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-4ae7d065-52f5-4314-b86c-fd223b63d113,DISK], DatanodeInfoWithStorage[127.0.0.1:45202,DS-1f86fb1c-5bbe-4abf-9b53-c025a7b3d95d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-514167536-172.17.0.18-1595952179392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41598,DS-a3c6dd53-8153-405c-bf80-35c44135c803,DISK], DatanodeInfoWithStorage[127.0.0.1:36265,DS-f0c90b48-856b-461c-bb0c-12179d896613,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-90503c9d-cfbc-4355-a95e-28baddc481ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37208,DS-262cb577-89fd-4a07-a392-cfb1b91466e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-4639cf73-1509-43fb-ab70-83791c82a901,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-1b7dad1b-7960-4271-85cf-aacb7882ae3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-4ae7d065-52f5-4314-b86c-fd223b63d113,DISK], DatanodeInfoWithStorage[127.0.0.1:45202,DS-1f86fb1c-5bbe-4abf-9b53-c025a7b3d95d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1675061115-172.17.0.18-1595952808055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40748,DS-2a19dfef-e30f-4500-9cc7-6dd53ac2c08c,DISK], DatanodeInfoWithStorage[127.0.0.1:33910,DS-23486219-0d45-4dc9-a530-9dc48a98f313,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-ee78f615-bd2c-4311-890d-828490fd17b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43288,DS-25a5c4b9-ca84-4b74-9f21-29a70bc5f796,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-398a84c3-6572-4a8d-80de-4519e985f68e,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-45001f20-2e4b-483e-b64b-5b3784bb25d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-f09a5caf-5184-4ea9-a468-be4473298175,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-8eca392e-f100-4a6f-a5fd-396e6062c5b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1675061115-172.17.0.18-1595952808055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40748,DS-2a19dfef-e30f-4500-9cc7-6dd53ac2c08c,DISK], DatanodeInfoWithStorage[127.0.0.1:33910,DS-23486219-0d45-4dc9-a530-9dc48a98f313,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-ee78f615-bd2c-4311-890d-828490fd17b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43288,DS-25a5c4b9-ca84-4b74-9f21-29a70bc5f796,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-398a84c3-6572-4a8d-80de-4519e985f68e,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-45001f20-2e4b-483e-b64b-5b3784bb25d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-f09a5caf-5184-4ea9-a468-be4473298175,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-8eca392e-f100-4a6f-a5fd-396e6062c5b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-671584398-172.17.0.18-1595952850516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37249,DS-d3bbdaba-d256-40bf-97e2-e646dbbc2e93,DISK], DatanodeInfoWithStorage[127.0.0.1:37872,DS-9f96018d-8f51-41fb-becb-e152e3178a35,DISK], DatanodeInfoWithStorage[127.0.0.1:34680,DS-4d40a1cb-2244-45af-833a-ead5bbe8489e,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-42e3c823-51cd-4748-90da-b3ce4de541c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41958,DS-0cd464a8-785c-4e96-b0f7-6e59e53b503f,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-d39c9f4e-fd77-4c1a-890c-1fdc53483839,DISK], DatanodeInfoWithStorage[127.0.0.1:46181,DS-fa17e4dd-c92f-41a5-b6b7-5583a9dc7609,DISK], DatanodeInfoWithStorage[127.0.0.1:41376,DS-4c6464a7-f98f-4cca-9584-b2e92918616b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-671584398-172.17.0.18-1595952850516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37249,DS-d3bbdaba-d256-40bf-97e2-e646dbbc2e93,DISK], DatanodeInfoWithStorage[127.0.0.1:37872,DS-9f96018d-8f51-41fb-becb-e152e3178a35,DISK], DatanodeInfoWithStorage[127.0.0.1:34680,DS-4d40a1cb-2244-45af-833a-ead5bbe8489e,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-42e3c823-51cd-4748-90da-b3ce4de541c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41958,DS-0cd464a8-785c-4e96-b0f7-6e59e53b503f,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-d39c9f4e-fd77-4c1a-890c-1fdc53483839,DISK], DatanodeInfoWithStorage[127.0.0.1:46181,DS-fa17e4dd-c92f-41a5-b6b7-5583a9dc7609,DISK], DatanodeInfoWithStorage[127.0.0.1:41376,DS-4c6464a7-f98f-4cca-9584-b2e92918616b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1192472383-172.17.0.18-1595953099474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40502,DS-95f18c29-b709-4f49-8065-961d8fe64473,DISK], DatanodeInfoWithStorage[127.0.0.1:41468,DS-10034f3a-a5ce-47ba-bbb9-506fb23c9452,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-0f9240e8-4c4d-40db-a245-350a78ecf766,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-729260a9-f336-4a85-929f-8dec0d42e8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33411,DS-033b1632-87c2-4948-920a-a12d55e3243d,DISK], DatanodeInfoWithStorage[127.0.0.1:46513,DS-5d43aac2-fdd9-4d67-9273-77d7914a84b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-d9b92ba8-b1b4-4ad6-a4e3-055c07609716,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-31408c64-1b8e-448a-9b44-d784b7ab0c6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1192472383-172.17.0.18-1595953099474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40502,DS-95f18c29-b709-4f49-8065-961d8fe64473,DISK], DatanodeInfoWithStorage[127.0.0.1:41468,DS-10034f3a-a5ce-47ba-bbb9-506fb23c9452,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-0f9240e8-4c4d-40db-a245-350a78ecf766,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-729260a9-f336-4a85-929f-8dec0d42e8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33411,DS-033b1632-87c2-4948-920a-a12d55e3243d,DISK], DatanodeInfoWithStorage[127.0.0.1:46513,DS-5d43aac2-fdd9-4d67-9273-77d7914a84b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-d9b92ba8-b1b4-4ad6-a4e3-055c07609716,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-31408c64-1b8e-448a-9b44-d784b7ab0c6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-965004468-172.17.0.18-1595953135935:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43334,DS-60bccf28-73c9-40d5-bed3-d8b81d916db4,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-b645a304-2918-42a5-b033-45d9f2659c17,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-2fb7a5b3-d9a9-4306-babd-b34066a9e61a,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-3269266b-a4bb-4ff8-b4d2-25d9002f0e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-40fb8722-e42a-46f7-bc2d-672fe48f82a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-fe193902-4ce3-4abe-8c68-88a3b9588164,DISK], DatanodeInfoWithStorage[127.0.0.1:45370,DS-dadff52b-d25b-400c-9a1f-50ec188300dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-03518dc5-4ee0-44d3-aa91-1ee982df59ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-965004468-172.17.0.18-1595953135935:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43334,DS-60bccf28-73c9-40d5-bed3-d8b81d916db4,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-b645a304-2918-42a5-b033-45d9f2659c17,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-2fb7a5b3-d9a9-4306-babd-b34066a9e61a,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-3269266b-a4bb-4ff8-b4d2-25d9002f0e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-40fb8722-e42a-46f7-bc2d-672fe48f82a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-fe193902-4ce3-4abe-8c68-88a3b9588164,DISK], DatanodeInfoWithStorage[127.0.0.1:45370,DS-dadff52b-d25b-400c-9a1f-50ec188300dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-03518dc5-4ee0-44d3-aa91-1ee982df59ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1099832613-172.17.0.18-1595953667443:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44836,DS-64ef4b62-6cea-4285-9577-61e4a0b0a2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-92309454-5ada-4528-9015-cc54a8df2fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-63b2fa32-97e5-47f9-a0d6-3ebf020a24a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-3c9faef9-eb9f-437e-b7b2-220ee893e4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-11c995a9-1461-4d0f-bc72-aafd4a0e8ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:43858,DS-f013cd66-30a7-4dea-a73a-873d2b57944d,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-945a938c-02fc-40f4-af27-897eaf89d32c,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-b5a80045-aaf3-4f3d-9d72-ae138395c792,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1099832613-172.17.0.18-1595953667443:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44836,DS-64ef4b62-6cea-4285-9577-61e4a0b0a2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-92309454-5ada-4528-9015-cc54a8df2fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-63b2fa32-97e5-47f9-a0d6-3ebf020a24a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-3c9faef9-eb9f-437e-b7b2-220ee893e4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-11c995a9-1461-4d0f-bc72-aafd4a0e8ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:43858,DS-f013cd66-30a7-4dea-a73a-873d2b57944d,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-945a938c-02fc-40f4-af27-897eaf89d32c,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-b5a80045-aaf3-4f3d-9d72-ae138395c792,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-818998567-172.17.0.18-1595954899533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45060,DS-a7ebdece-5aea-4dcf-8d7b-99786d0b8425,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-4b9c89e9-0531-41f5-9438-fd878089957a,DISK], DatanodeInfoWithStorage[127.0.0.1:42000,DS-2ed2b3d5-5fc8-4ec0-9f27-959b20a6abca,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-9b920b7b-1a6b-4336-a59c-75787adb467b,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-d0bdfe4f-fd1f-4c1e-aaf6-385bd4d8c3d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-ede0765f-dc5c-4f78-a2ad-d751939c7176,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-ab4542c0-d4f8-4b8c-9111-bd3fd25f3a72,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-f93b9188-1a24-4559-87e3-82646caadc05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-818998567-172.17.0.18-1595954899533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45060,DS-a7ebdece-5aea-4dcf-8d7b-99786d0b8425,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-4b9c89e9-0531-41f5-9438-fd878089957a,DISK], DatanodeInfoWithStorage[127.0.0.1:42000,DS-2ed2b3d5-5fc8-4ec0-9f27-959b20a6abca,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-9b920b7b-1a6b-4336-a59c-75787adb467b,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-d0bdfe4f-fd1f-4c1e-aaf6-385bd4d8c3d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-ede0765f-dc5c-4f78-a2ad-d751939c7176,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-ab4542c0-d4f8-4b8c-9111-bd3fd25f3a72,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-f93b9188-1a24-4559-87e3-82646caadc05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5338
