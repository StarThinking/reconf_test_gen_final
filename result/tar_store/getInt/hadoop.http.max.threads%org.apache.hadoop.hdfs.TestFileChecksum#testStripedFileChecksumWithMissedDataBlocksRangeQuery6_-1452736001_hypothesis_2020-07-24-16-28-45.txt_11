reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-795405719-172.17.0.9-1595608287522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40657,DS-d99b0256-21ff-435a-a0e0-041d7c9ae5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-ea5aadb3-9373-4d37-81db-06346369e7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37744,DS-ec0663da-8e08-4577-b642-db88713282e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41291,DS-612e9db6-c0e9-490d-988c-9dc21e8392fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-ea9ca3e4-d4e8-4859-86ec-1d1d25d40f29,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-cd577e56-f661-4bd9-b40f-d5a71446bbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-ab2ace3c-b306-4699-8f69-0882aa2cd528,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-e64564a5-368a-47ba-8a38-09ac6c11a27b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-795405719-172.17.0.9-1595608287522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40657,DS-d99b0256-21ff-435a-a0e0-041d7c9ae5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-ea5aadb3-9373-4d37-81db-06346369e7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37744,DS-ec0663da-8e08-4577-b642-db88713282e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41291,DS-612e9db6-c0e9-490d-988c-9dc21e8392fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-ea9ca3e4-d4e8-4859-86ec-1d1d25d40f29,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-cd577e56-f661-4bd9-b40f-d5a71446bbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-ab2ace3c-b306-4699-8f69-0882aa2cd528,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-e64564a5-368a-47ba-8a38-09ac6c11a27b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-895617179-172.17.0.9-1595608462016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46639,DS-fe400a09-1688-4482-9fbd-2f3f9890e206,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-61fdd252-8b3b-4ba2-a2e0-5a18d3367e76,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-787faf51-6d8b-4975-ae7b-1acf865a13f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-dbbd63e0-596d-48c4-b98b-46690a1df5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-cde5d425-96d2-4ffd-9322-74182d402801,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-e65c0340-5dc5-414d-b8de-196d556b4400,DISK], DatanodeInfoWithStorage[127.0.0.1:46484,DS-3d68673e-49d0-4649-9928-5b8701479d59,DISK], DatanodeInfoWithStorage[127.0.0.1:44104,DS-f94d2617-5837-458c-99b6-e827c1dd4baa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-895617179-172.17.0.9-1595608462016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46639,DS-fe400a09-1688-4482-9fbd-2f3f9890e206,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-61fdd252-8b3b-4ba2-a2e0-5a18d3367e76,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-787faf51-6d8b-4975-ae7b-1acf865a13f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-dbbd63e0-596d-48c4-b98b-46690a1df5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-cde5d425-96d2-4ffd-9322-74182d402801,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-e65c0340-5dc5-414d-b8de-196d556b4400,DISK], DatanodeInfoWithStorage[127.0.0.1:46484,DS-3d68673e-49d0-4649-9928-5b8701479d59,DISK], DatanodeInfoWithStorage[127.0.0.1:44104,DS-f94d2617-5837-458c-99b6-e827c1dd4baa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1252918944-172.17.0.9-1595608493231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44881,DS-2477266b-1e77-4c61-a137-135c0cb6d233,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-e67b214b-57bb-476e-b45a-44bb27063d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-56868f7d-dd17-4c0b-8c3d-a485380cde2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-115257fc-ff2d-4767-b498-32e55d932d60,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-7789ff76-4f3d-48fc-96ff-c11fbc2d2b27,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-03bb4817-b7fb-48c8-ac9d-127c1ca6240e,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-18ec5287-d0fb-4ba6-8d99-493739f6f629,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-325417b6-5fc2-47f0-9b86-b7471b554e4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1252918944-172.17.0.9-1595608493231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44881,DS-2477266b-1e77-4c61-a137-135c0cb6d233,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-e67b214b-57bb-476e-b45a-44bb27063d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-56868f7d-dd17-4c0b-8c3d-a485380cde2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-115257fc-ff2d-4767-b498-32e55d932d60,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-7789ff76-4f3d-48fc-96ff-c11fbc2d2b27,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-03bb4817-b7fb-48c8-ac9d-127c1ca6240e,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-18ec5287-d0fb-4ba6-8d99-493739f6f629,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-325417b6-5fc2-47f0-9b86-b7471b554e4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-855340368-172.17.0.9-1595608862181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46816,DS-f2d7678a-ade6-4f64-90e9-109993a3426f,DISK], DatanodeInfoWithStorage[127.0.0.1:42759,DS-1a72dc83-99f2-4b61-89a5-b22b6e557909,DISK], DatanodeInfoWithStorage[127.0.0.1:33527,DS-8cb94786-4cf6-463d-83e3-19071ab979df,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-81f2d2bd-fcab-4bc9-b72b-2e97b591b66f,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-b9e9e29d-24ea-4dc2-9ac2-ac8e90fd654d,DISK], DatanodeInfoWithStorage[127.0.0.1:33663,DS-b2b811a8-2f51-49c8-8c95-1b9aa544a135,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-f8cba133-3049-4982-98dd-8e5e9219b62c,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-9469a892-75a2-4f21-a2e1-c3c2a12c30ae,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-855340368-172.17.0.9-1595608862181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46816,DS-f2d7678a-ade6-4f64-90e9-109993a3426f,DISK], DatanodeInfoWithStorage[127.0.0.1:42759,DS-1a72dc83-99f2-4b61-89a5-b22b6e557909,DISK], DatanodeInfoWithStorage[127.0.0.1:33527,DS-8cb94786-4cf6-463d-83e3-19071ab979df,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-81f2d2bd-fcab-4bc9-b72b-2e97b591b66f,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-b9e9e29d-24ea-4dc2-9ac2-ac8e90fd654d,DISK], DatanodeInfoWithStorage[127.0.0.1:33663,DS-b2b811a8-2f51-49c8-8c95-1b9aa544a135,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-f8cba133-3049-4982-98dd-8e5e9219b62c,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-9469a892-75a2-4f21-a2e1-c3c2a12c30ae,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-434371519-172.17.0.9-1595609083296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43141,DS-850918bb-4b70-42f2-836f-e32bab1f1328,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-2e3ce53f-416f-4732-80ce-338b448ce087,DISK], DatanodeInfoWithStorage[127.0.0.1:41715,DS-c338bf2a-0cc0-418c-880f-006b1aad6822,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-01f7101a-409f-4e40-b029-60e35a4482e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35555,DS-963463e4-cdd2-44fe-809c-598d4031edf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-526b80d5-947f-41e2-85e9-7e150d1891c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-0ee62d73-510a-4df5-a187-56899b705909,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-943cd8ff-0ed6-4345-be68-ba12570ace91,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-434371519-172.17.0.9-1595609083296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43141,DS-850918bb-4b70-42f2-836f-e32bab1f1328,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-2e3ce53f-416f-4732-80ce-338b448ce087,DISK], DatanodeInfoWithStorage[127.0.0.1:41715,DS-c338bf2a-0cc0-418c-880f-006b1aad6822,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-01f7101a-409f-4e40-b029-60e35a4482e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35555,DS-963463e4-cdd2-44fe-809c-598d4031edf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-526b80d5-947f-41e2-85e9-7e150d1891c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-0ee62d73-510a-4df5-a187-56899b705909,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-943cd8ff-0ed6-4345-be68-ba12570ace91,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1480631874-172.17.0.9-1595609424925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45124,DS-fde6442b-6355-4ed4-a6ea-76e4591c0525,DISK], DatanodeInfoWithStorage[127.0.0.1:32986,DS-5039f1f0-a058-4ff9-8ca6-10f2e9b88f05,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-d4bba328-0dff-4fa6-85f9-cf67065f1ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-9f7e90a6-e1b0-4f94-bb95-e313202fac35,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-73345d5d-5e0d-4d65-a927-e3bd2ba76b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34928,DS-02a1b26e-1d81-4084-a2c6-3790ccc31fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-b3cf5aee-6f62-4b39-9e90-13274b029cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42329,DS-b0ca0a21-3b62-465f-aa0d-2d81144a2077,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1480631874-172.17.0.9-1595609424925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45124,DS-fde6442b-6355-4ed4-a6ea-76e4591c0525,DISK], DatanodeInfoWithStorage[127.0.0.1:32986,DS-5039f1f0-a058-4ff9-8ca6-10f2e9b88f05,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-d4bba328-0dff-4fa6-85f9-cf67065f1ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-9f7e90a6-e1b0-4f94-bb95-e313202fac35,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-73345d5d-5e0d-4d65-a927-e3bd2ba76b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34928,DS-02a1b26e-1d81-4084-a2c6-3790ccc31fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-b3cf5aee-6f62-4b39-9e90-13274b029cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42329,DS-b0ca0a21-3b62-465f-aa0d-2d81144a2077,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-838912160-172.17.0.9-1595609607946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36440,DS-8b3b142c-f0b0-4f23-b251-66f2ee0e9f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-4f3c706f-4a08-48a3-b21e-093188cf91d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-931326c2-82d4-443b-a41b-4a591d0c3758,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-82d2ea0f-b817-4fb9-a759-20d1b70fd1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-4440a9b9-9757-417b-901f-a02650b88b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-2e2bc160-32f3-47cd-9363-5ed105e40875,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-7f3e68dc-3708-45d9-bbf2-d86979f106c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-c69f9c1b-2627-4bb8-8479-a93c0f9b6f8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-838912160-172.17.0.9-1595609607946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36440,DS-8b3b142c-f0b0-4f23-b251-66f2ee0e9f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-4f3c706f-4a08-48a3-b21e-093188cf91d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-931326c2-82d4-443b-a41b-4a591d0c3758,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-82d2ea0f-b817-4fb9-a759-20d1b70fd1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-4440a9b9-9757-417b-901f-a02650b88b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-2e2bc160-32f3-47cd-9363-5ed105e40875,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-7f3e68dc-3708-45d9-bbf2-d86979f106c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-c69f9c1b-2627-4bb8-8479-a93c0f9b6f8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1493231116-172.17.0.9-1595610023871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45393,DS-16159cc6-dc77-44d2-ab65-d66ed2a1a542,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-e960e638-ca9e-459a-988a-d7eac30bb62d,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-139f4f46-a0e8-485a-8b9f-d87b75a1504e,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-4b3c3a7f-7888-4d79-bf38-a63ccef4baba,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-eba38672-0451-4879-951a-2bddfaaa3f39,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-5afff07a-145e-4e43-ae9a-49766e372b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44903,DS-46efd37e-0644-4cb2-93ab-b39051435760,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-5b982474-5aba-4293-a479-2ca01a0b97a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1493231116-172.17.0.9-1595610023871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45393,DS-16159cc6-dc77-44d2-ab65-d66ed2a1a542,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-e960e638-ca9e-459a-988a-d7eac30bb62d,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-139f4f46-a0e8-485a-8b9f-d87b75a1504e,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-4b3c3a7f-7888-4d79-bf38-a63ccef4baba,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-eba38672-0451-4879-951a-2bddfaaa3f39,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-5afff07a-145e-4e43-ae9a-49766e372b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44903,DS-46efd37e-0644-4cb2-93ab-b39051435760,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-5b982474-5aba-4293-a479-2ca01a0b97a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1046572678-172.17.0.9-1595611113685:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44708,DS-f8824a6d-dee9-4e7b-9e2f-71d5113fbfae,DISK], DatanodeInfoWithStorage[127.0.0.1:39979,DS-8392e74d-a3b5-4250-946e-1741b487dfdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44756,DS-40b1e96e-9539-4414-9dfe-ff4879a78112,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-b4109836-8d70-48cf-9887-b22c97a897e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-69106766-3453-45dd-93ec-aba5d67c586f,DISK], DatanodeInfoWithStorage[127.0.0.1:34447,DS-b410eeb6-b96c-4eec-a23a-3ee24a7931c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-71eac8ac-c21e-4a04-850f-d0dad8e12b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-451181fe-00f3-49b3-9d2f-9d926f576686,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1046572678-172.17.0.9-1595611113685:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44708,DS-f8824a6d-dee9-4e7b-9e2f-71d5113fbfae,DISK], DatanodeInfoWithStorage[127.0.0.1:39979,DS-8392e74d-a3b5-4250-946e-1741b487dfdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44756,DS-40b1e96e-9539-4414-9dfe-ff4879a78112,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-b4109836-8d70-48cf-9887-b22c97a897e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-69106766-3453-45dd-93ec-aba5d67c586f,DISK], DatanodeInfoWithStorage[127.0.0.1:34447,DS-b410eeb6-b96c-4eec-a23a-3ee24a7931c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-71eac8ac-c21e-4a04-850f-d0dad8e12b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-451181fe-00f3-49b3-9d2f-9d926f576686,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-469168008-172.17.0.9-1595611211545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33432,DS-af0bd002-7bb8-4832-9bcd-b89d3ce28ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-b7ebd38d-8162-41b0-94b3-7c3b0e0664a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46610,DS-6557a62e-c847-4951-8896-3db62b376168,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-2f90af83-8d5c-4ac7-a953-85dc247ac671,DISK], DatanodeInfoWithStorage[127.0.0.1:36454,DS-30ce5b6a-3c4e-4391-b638-da2466426137,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-97e870a0-07fa-4ed4-93b1-94264fd7137f,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-17ea1f13-aeb5-4ca8-9cf3-46ffcd51d8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-92f523d2-1f59-453f-bd3e-f520ccbd198d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-469168008-172.17.0.9-1595611211545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33432,DS-af0bd002-7bb8-4832-9bcd-b89d3ce28ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-b7ebd38d-8162-41b0-94b3-7c3b0e0664a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46610,DS-6557a62e-c847-4951-8896-3db62b376168,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-2f90af83-8d5c-4ac7-a953-85dc247ac671,DISK], DatanodeInfoWithStorage[127.0.0.1:36454,DS-30ce5b6a-3c4e-4391-b638-da2466426137,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-97e870a0-07fa-4ed4-93b1-94264fd7137f,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-17ea1f13-aeb5-4ca8-9cf3-46ffcd51d8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-92f523d2-1f59-453f-bd3e-f520ccbd198d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-994347204-172.17.0.9-1595611352836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37365,DS-181999e6-c581-4269-abce-e50e961238bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-864acde4-b808-4f62-b1f9-376b54016f18,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-10149dce-c57b-450a-abe3-a840a2aa137c,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-e9aa059d-0d14-4a4a-bca0-53db9fe15f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-f26d7cfe-d6c0-4653-9108-76d31ddb26be,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-e1e3a0a8-f82b-4baf-aafa-3ffa479a0f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41727,DS-2a09cce3-88c6-4d61-891f-4ec580cde74c,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-99e44670-211f-474b-a1fa-e8eb1682535e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-994347204-172.17.0.9-1595611352836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37365,DS-181999e6-c581-4269-abce-e50e961238bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-864acde4-b808-4f62-b1f9-376b54016f18,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-10149dce-c57b-450a-abe3-a840a2aa137c,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-e9aa059d-0d14-4a4a-bca0-53db9fe15f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-f26d7cfe-d6c0-4653-9108-76d31ddb26be,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-e1e3a0a8-f82b-4baf-aafa-3ffa479a0f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41727,DS-2a09cce3-88c6-4d61-891f-4ec580cde74c,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-99e44670-211f-474b-a1fa-e8eb1682535e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-186433710-172.17.0.9-1595611569891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41132,DS-db51eef7-63db-4792-9ba4-b347cedc76a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-7895fc13-250e-4769-a35f-cff453f15c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36553,DS-2e7e576d-6a59-47f1-a12a-e929ca14493c,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-07362e46-ffe0-40ae-87a9-fa09940d20b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43806,DS-1b8f8503-8dfb-46f0-b6ef-a1a800be6647,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-8a519ca2-0503-4e05-a724-b289028bec80,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-b3ae1601-5d57-4aac-af4e-53150dbaddac,DISK], DatanodeInfoWithStorage[127.0.0.1:40917,DS-d9e0cf08-7a6b-4422-917a-11d8dec40193,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-186433710-172.17.0.9-1595611569891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41132,DS-db51eef7-63db-4792-9ba4-b347cedc76a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-7895fc13-250e-4769-a35f-cff453f15c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36553,DS-2e7e576d-6a59-47f1-a12a-e929ca14493c,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-07362e46-ffe0-40ae-87a9-fa09940d20b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43806,DS-1b8f8503-8dfb-46f0-b6ef-a1a800be6647,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-8a519ca2-0503-4e05-a724-b289028bec80,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-b3ae1601-5d57-4aac-af4e-53150dbaddac,DISK], DatanodeInfoWithStorage[127.0.0.1:40917,DS-d9e0cf08-7a6b-4422-917a-11d8dec40193,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-976468492-172.17.0.9-1595611600974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44944,DS-31fdfa88-ef07-447a-b194-4fe98c141c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-9394e769-bddd-4f05-a24e-b5116d69b9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-5c2e655a-efe1-467d-9708-a1119789dcb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-c12d431f-6b4c-461c-a203-fd6952dd55ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43081,DS-3bd66eb9-25c5-46f2-b0eb-883faa48dc31,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-8970a333-8584-4daf-b29c-7848926f73b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-a31998ab-0ea9-4e3e-af9c-0454b93eba6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-0f22830b-3926-498c-a852-6ca0c69adf9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-976468492-172.17.0.9-1595611600974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44944,DS-31fdfa88-ef07-447a-b194-4fe98c141c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-9394e769-bddd-4f05-a24e-b5116d69b9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-5c2e655a-efe1-467d-9708-a1119789dcb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-c12d431f-6b4c-461c-a203-fd6952dd55ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43081,DS-3bd66eb9-25c5-46f2-b0eb-883faa48dc31,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-8970a333-8584-4daf-b29c-7848926f73b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-a31998ab-0ea9-4e3e-af9c-0454b93eba6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-0f22830b-3926-498c-a852-6ca0c69adf9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1015316861-172.17.0.9-1595611639271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34806,DS-a36e9d27-8816-4462-9316-dcb6b09e9f13,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-734d9414-4610-467d-9e69-7454708e1776,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-514bbc9a-c667-4f8c-b952-3bac168a430a,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-368e7e41-b092-480d-82d4-a49e54d3f689,DISK], DatanodeInfoWithStorage[127.0.0.1:37064,DS-e6ef340e-b5cd-4311-8e6a-a15c4b815281,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-d818507a-72c6-488c-80af-9991e4a77ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-b21eda1f-ac03-4891-81a4-961afb3335b8,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-36ca987f-1778-4f8d-89aa-21dc294ecda1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1015316861-172.17.0.9-1595611639271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34806,DS-a36e9d27-8816-4462-9316-dcb6b09e9f13,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-734d9414-4610-467d-9e69-7454708e1776,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-514bbc9a-c667-4f8c-b952-3bac168a430a,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-368e7e41-b092-480d-82d4-a49e54d3f689,DISK], DatanodeInfoWithStorage[127.0.0.1:37064,DS-e6ef340e-b5cd-4311-8e6a-a15c4b815281,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-d818507a-72c6-488c-80af-9991e4a77ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-b21eda1f-ac03-4891-81a4-961afb3335b8,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-36ca987f-1778-4f8d-89aa-21dc294ecda1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-366658934-172.17.0.9-1595611708314:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42148,DS-c12c03fe-7508-499b-8ead-64dbb8c2ae6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43906,DS-46d67097-2b77-475d-b64d-1f4e8a3657e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-64468dcf-8e80-47f5-8606-2728c0a650ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-00786171-12ab-4992-904c-941138f23c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-7163cbb5-a44a-4510-84f3-61b84f9c7d08,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-ca49da48-be2b-479f-a961-dcf05eae6b16,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-92022d2a-7ed0-47e6-ae18-b79bb57fb060,DISK], DatanodeInfoWithStorage[127.0.0.1:45405,DS-4d909cea-8430-4062-ba1a-0b3d63512d64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-366658934-172.17.0.9-1595611708314:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42148,DS-c12c03fe-7508-499b-8ead-64dbb8c2ae6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43906,DS-46d67097-2b77-475d-b64d-1f4e8a3657e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-64468dcf-8e80-47f5-8606-2728c0a650ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-00786171-12ab-4992-904c-941138f23c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-7163cbb5-a44a-4510-84f3-61b84f9c7d08,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-ca49da48-be2b-479f-a961-dcf05eae6b16,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-92022d2a-7ed0-47e6-ae18-b79bb57fb060,DISK], DatanodeInfoWithStorage[127.0.0.1:45405,DS-4d909cea-8430-4062-ba1a-0b3d63512d64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1077966270-172.17.0.9-1595611786185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44124,DS-788930e3-1446-46ab-83b5-96f78abe8add,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-05a1b34f-ad49-46c6-a593-346fb8217985,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-a84b44f2-d9e8-4f70-9713-63870e358565,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-c769f1ba-ab3b-4871-97c6-fcbd6bcde4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-4d4e0b05-5399-4a88-bcba-046bc8f3d507,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-204ba54a-73d1-4bb9-96f3-47c3c352f88e,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-26bac86c-908b-4762-9d0d-c5a86dae0479,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-a57162bb-46dc-4674-b1cd-b6992ff72a5e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1077966270-172.17.0.9-1595611786185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44124,DS-788930e3-1446-46ab-83b5-96f78abe8add,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-05a1b34f-ad49-46c6-a593-346fb8217985,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-a84b44f2-d9e8-4f70-9713-63870e358565,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-c769f1ba-ab3b-4871-97c6-fcbd6bcde4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-4d4e0b05-5399-4a88-bcba-046bc8f3d507,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-204ba54a-73d1-4bb9-96f3-47c3c352f88e,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-26bac86c-908b-4762-9d0d-c5a86dae0479,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-a57162bb-46dc-4674-b1cd-b6992ff72a5e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1774156805-172.17.0.9-1595611917818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37576,DS-3b4bacfe-ef9f-402d-9b99-10d1dce1bc69,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-71f2f9cf-da16-4919-ae2b-8b86e0d7eada,DISK], DatanodeInfoWithStorage[127.0.0.1:37784,DS-135350dd-b4b0-42ab-8e25-958b4b72a31e,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-3d7eabd3-8fd0-41f3-8f5b-5c025be27fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-7924fd4f-73f2-4550-bd61-6a39b285dfec,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-4c5d2a5b-1488-4a6f-b50b-ce14123e6656,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-8c4bab80-fedd-486d-b407-6a29b36d0118,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-bf00f2ca-ed54-4bee-beda-f25f0cb3aa67,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1774156805-172.17.0.9-1595611917818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37576,DS-3b4bacfe-ef9f-402d-9b99-10d1dce1bc69,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-71f2f9cf-da16-4919-ae2b-8b86e0d7eada,DISK], DatanodeInfoWithStorage[127.0.0.1:37784,DS-135350dd-b4b0-42ab-8e25-958b4b72a31e,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-3d7eabd3-8fd0-41f3-8f5b-5c025be27fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-7924fd4f-73f2-4550-bd61-6a39b285dfec,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-4c5d2a5b-1488-4a6f-b50b-ce14123e6656,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-8c4bab80-fedd-486d-b407-6a29b36d0118,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-bf00f2ca-ed54-4bee-beda-f25f0cb3aa67,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1976537346-172.17.0.9-1595612018242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32984,DS-4d0cdfb0-5187-4d99-b51f-aede69189a64,DISK], DatanodeInfoWithStorage[127.0.0.1:42704,DS-b75637e3-7a7c-4dff-adbe-bb64fcbeb563,DISK], DatanodeInfoWithStorage[127.0.0.1:40283,DS-46f189cd-494b-4a41-b546-97cf236a2026,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-c7dc8205-65fd-4476-9a2a-14a19dce664b,DISK], DatanodeInfoWithStorage[127.0.0.1:44195,DS-264b7833-f181-4940-8e1e-a0e6555ed1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-272ae9ed-f413-4bc4-b5fc-9448a121dc60,DISK], DatanodeInfoWithStorage[127.0.0.1:46811,DS-4934eaa8-1266-4512-9515-713294b30a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-fe2fceb8-717b-4f2d-99e1-3b69c8261570,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1976537346-172.17.0.9-1595612018242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32984,DS-4d0cdfb0-5187-4d99-b51f-aede69189a64,DISK], DatanodeInfoWithStorage[127.0.0.1:42704,DS-b75637e3-7a7c-4dff-adbe-bb64fcbeb563,DISK], DatanodeInfoWithStorage[127.0.0.1:40283,DS-46f189cd-494b-4a41-b546-97cf236a2026,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-c7dc8205-65fd-4476-9a2a-14a19dce664b,DISK], DatanodeInfoWithStorage[127.0.0.1:44195,DS-264b7833-f181-4940-8e1e-a0e6555ed1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-272ae9ed-f413-4bc4-b5fc-9448a121dc60,DISK], DatanodeInfoWithStorage[127.0.0.1:46811,DS-4934eaa8-1266-4512-9515-713294b30a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-fe2fceb8-717b-4f2d-99e1-3b69c8261570,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1858174570-172.17.0.9-1595612338737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38531,DS-ee32c498-82dd-40b7-9d3b-ce616d958d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-59812ca7-e64b-43da-bb60-3a5442f72816,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-8a566a4d-36a0-494e-a3b4-6b528704a5de,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-2189aa51-8cb6-4d3a-bc51-391fd22d21bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36089,DS-5a66bde8-8f78-4aca-b9ff-31ec63fb7fac,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-0d40cec5-d3f1-40be-951e-700816f40dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-f8e7f2e7-b87c-41de-bfeb-6c7bb986351b,DISK], DatanodeInfoWithStorage[127.0.0.1:37536,DS-be675c60-0faa-4da8-a37c-1f69d42cf6da,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1858174570-172.17.0.9-1595612338737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38531,DS-ee32c498-82dd-40b7-9d3b-ce616d958d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-59812ca7-e64b-43da-bb60-3a5442f72816,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-8a566a4d-36a0-494e-a3b4-6b528704a5de,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-2189aa51-8cb6-4d3a-bc51-391fd22d21bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36089,DS-5a66bde8-8f78-4aca-b9ff-31ec63fb7fac,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-0d40cec5-d3f1-40be-951e-700816f40dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-f8e7f2e7-b87c-41de-bfeb-6c7bb986351b,DISK], DatanodeInfoWithStorage[127.0.0.1:37536,DS-be675c60-0faa-4da8-a37c-1f69d42cf6da,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1570747888-172.17.0.9-1595612420622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37609,DS-36e8613a-21ee-43d0-a99d-70df9c23d693,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-13452f34-a18a-44ad-a73b-b8446c9aee5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42290,DS-ea44c573-ad74-4829-9762-004d8508cbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38066,DS-2e34d949-286e-46d5-a61c-480a37fb0253,DISK], DatanodeInfoWithStorage[127.0.0.1:44968,DS-852a8877-99d8-4d32-832f-37ec3118d3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-5d780f43-9882-4658-95ac-53f46a662b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37651,DS-d60cf291-85fd-4467-9589-76c1d076551c,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-28ed0088-3562-4203-8766-b925db1e5ede,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1570747888-172.17.0.9-1595612420622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37609,DS-36e8613a-21ee-43d0-a99d-70df9c23d693,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-13452f34-a18a-44ad-a73b-b8446c9aee5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42290,DS-ea44c573-ad74-4829-9762-004d8508cbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38066,DS-2e34d949-286e-46d5-a61c-480a37fb0253,DISK], DatanodeInfoWithStorage[127.0.0.1:44968,DS-852a8877-99d8-4d32-832f-37ec3118d3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-5d780f43-9882-4658-95ac-53f46a662b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37651,DS-d60cf291-85fd-4467-9589-76c1d076551c,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-28ed0088-3562-4203-8766-b925db1e5ede,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2029760808-172.17.0.9-1595612489967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38434,DS-a540e153-7412-4655-b1de-6d7e64fdb17c,DISK], DatanodeInfoWithStorage[127.0.0.1:35424,DS-9d1a77aa-c9db-41bc-b2eb-f4049f5be7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41818,DS-2829ca7d-a438-4ed0-af6f-02ff2fb2875a,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-180160bf-3ed9-44cf-97ae-8dad34bcb41e,DISK], DatanodeInfoWithStorage[127.0.0.1:37268,DS-0024354a-fb9d-4752-aa9d-d103aa29a61e,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-9a757ac5-b53e-4718-b997-251a18f1ba93,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-d1fad0c4-4db9-49b8-a4f6-adb57db1016c,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-3d23aeb2-3bd4-494b-850c-e67b0a7c3f9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2029760808-172.17.0.9-1595612489967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38434,DS-a540e153-7412-4655-b1de-6d7e64fdb17c,DISK], DatanodeInfoWithStorage[127.0.0.1:35424,DS-9d1a77aa-c9db-41bc-b2eb-f4049f5be7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41818,DS-2829ca7d-a438-4ed0-af6f-02ff2fb2875a,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-180160bf-3ed9-44cf-97ae-8dad34bcb41e,DISK], DatanodeInfoWithStorage[127.0.0.1:37268,DS-0024354a-fb9d-4752-aa9d-d103aa29a61e,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-9a757ac5-b53e-4718-b997-251a18f1ba93,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-d1fad0c4-4db9-49b8-a4f6-adb57db1016c,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-3d23aeb2-3bd4-494b-850c-e67b0a7c3f9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-686110658-172.17.0.9-1595612898166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45952,DS-1e67582d-234a-4a9c-8c57-8fe9d0da4ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-da876ba1-4981-45d2-9f53-a012916b07ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40452,DS-d8105f01-c6c6-4b14-a4aa-671c282e4173,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-718887ca-16d9-4aaa-8c9c-8fcf7a56bcc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33239,DS-8b7811a2-c66c-4034-a594-ba1ba6565c80,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-696aec05-2e74-433f-9a78-377f3edcc220,DISK], DatanodeInfoWithStorage[127.0.0.1:46214,DS-a7b66c35-d25b-4ebe-a535-4d7b427ec823,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-950cf6a8-a017-403f-9b35-a576a72e769d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-686110658-172.17.0.9-1595612898166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45952,DS-1e67582d-234a-4a9c-8c57-8fe9d0da4ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-da876ba1-4981-45d2-9f53-a012916b07ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40452,DS-d8105f01-c6c6-4b14-a4aa-671c282e4173,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-718887ca-16d9-4aaa-8c9c-8fcf7a56bcc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33239,DS-8b7811a2-c66c-4034-a594-ba1ba6565c80,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-696aec05-2e74-433f-9a78-377f3edcc220,DISK], DatanodeInfoWithStorage[127.0.0.1:46214,DS-a7b66c35-d25b-4ebe-a535-4d7b427ec823,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-950cf6a8-a017-403f-9b35-a576a72e769d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5126
