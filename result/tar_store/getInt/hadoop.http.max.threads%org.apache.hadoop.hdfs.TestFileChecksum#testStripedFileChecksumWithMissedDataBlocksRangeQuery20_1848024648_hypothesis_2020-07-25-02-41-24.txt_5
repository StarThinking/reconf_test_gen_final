reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1194386453-172.17.0.18-1595645123858:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37682,DS-c48adb0b-7b10-4a5d-b832-92e3faede8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-557c1168-c53c-444a-8f9c-1be94d2c1555,DISK], DatanodeInfoWithStorage[127.0.0.1:34081,DS-6805deff-320b-4002-bf30-5ebc64ed53d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-cd1da497-874b-482d-8c11-8e1d8fa0383c,DISK], DatanodeInfoWithStorage[127.0.0.1:40595,DS-a393c49c-d40c-4961-a2bc-fdc6f5953041,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-777dcf81-6e09-474f-a94b-09bec8039071,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-1c9b765d-2e31-4549-a867-ce2f1c8e2495,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-cdf67a5d-c90b-460d-a24c-56baf2dc003c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1194386453-172.17.0.18-1595645123858:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37682,DS-c48adb0b-7b10-4a5d-b832-92e3faede8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-557c1168-c53c-444a-8f9c-1be94d2c1555,DISK], DatanodeInfoWithStorage[127.0.0.1:34081,DS-6805deff-320b-4002-bf30-5ebc64ed53d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-cd1da497-874b-482d-8c11-8e1d8fa0383c,DISK], DatanodeInfoWithStorage[127.0.0.1:40595,DS-a393c49c-d40c-4961-a2bc-fdc6f5953041,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-777dcf81-6e09-474f-a94b-09bec8039071,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-1c9b765d-2e31-4549-a867-ce2f1c8e2495,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-cdf67a5d-c90b-460d-a24c-56baf2dc003c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-165706429-172.17.0.18-1595645152391:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39652,DS-580a2f99-c00b-4762-8678-84e09649e633,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-2e569e2f-bc81-4eab-a60a-ccdd7cd96432,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-6db5e209-2853-4b2d-9db4-2308101762a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-7deaa597-c339-48fc-80ae-102906f67139,DISK], DatanodeInfoWithStorage[127.0.0.1:44988,DS-9a3d0ddb-1345-4ef2-8b00-769cb3260c62,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-445ab95b-5884-4d95-8efb-83d924e09a00,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-4d16b4fd-1af6-405a-81f5-745a638e6e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-4f872d7a-363e-414f-95f1-7822735fa5f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-165706429-172.17.0.18-1595645152391:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39652,DS-580a2f99-c00b-4762-8678-84e09649e633,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-2e569e2f-bc81-4eab-a60a-ccdd7cd96432,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-6db5e209-2853-4b2d-9db4-2308101762a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-7deaa597-c339-48fc-80ae-102906f67139,DISK], DatanodeInfoWithStorage[127.0.0.1:44988,DS-9a3d0ddb-1345-4ef2-8b00-769cb3260c62,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-445ab95b-5884-4d95-8efb-83d924e09a00,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-4d16b4fd-1af6-405a-81f5-745a638e6e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-4f872d7a-363e-414f-95f1-7822735fa5f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-651482549-172.17.0.18-1595645447656:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45476,DS-e310acba-26b8-47c0-a32d-916674bef787,DISK], DatanodeInfoWithStorage[127.0.0.1:42877,DS-f6be8b2f-7f82-490b-a35e-cfdc01664948,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-74f77660-2e41-49cd-ae82-5dddb29e4a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-21c67015-76fe-4e80-89e7-eea6ea83249b,DISK], DatanodeInfoWithStorage[127.0.0.1:43690,DS-34c2b848-0f62-472f-8c5f-1f31ef65704c,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-8da64a0b-01d3-4ad8-a67f-83aa45aa00e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-2e7fbfae-a29c-49fe-924e-0943db96b601,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-97d0748f-a6ca-4275-8a19-d375215ba2cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-651482549-172.17.0.18-1595645447656:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45476,DS-e310acba-26b8-47c0-a32d-916674bef787,DISK], DatanodeInfoWithStorage[127.0.0.1:42877,DS-f6be8b2f-7f82-490b-a35e-cfdc01664948,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-74f77660-2e41-49cd-ae82-5dddb29e4a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-21c67015-76fe-4e80-89e7-eea6ea83249b,DISK], DatanodeInfoWithStorage[127.0.0.1:43690,DS-34c2b848-0f62-472f-8c5f-1f31ef65704c,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-8da64a0b-01d3-4ad8-a67f-83aa45aa00e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-2e7fbfae-a29c-49fe-924e-0943db96b601,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-97d0748f-a6ca-4275-8a19-d375215ba2cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-377748142-172.17.0.18-1595646085610:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38911,DS-490c0d68-feaf-4b07-a004-f3a582f2bb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43656,DS-ff2393eb-a10c-4af9-b2ec-d9b07d4911c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-dee53c24-f610-47a1-afe8-2de2721ef605,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-87b54161-a8b4-45d0-a4ec-87fb5a5556da,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-9546291f-8ebb-41d1-ad78-b975095bbd2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-6b80f1d7-7a9d-4c59-8c61-71056f6494d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40250,DS-47d672f8-ca3b-41f4-a2d6-6fc11f289fea,DISK], DatanodeInfoWithStorage[127.0.0.1:45037,DS-2881d48c-9b5f-4cb0-bad3-a7c17062151e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-377748142-172.17.0.18-1595646085610:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38911,DS-490c0d68-feaf-4b07-a004-f3a582f2bb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43656,DS-ff2393eb-a10c-4af9-b2ec-d9b07d4911c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-dee53c24-f610-47a1-afe8-2de2721ef605,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-87b54161-a8b4-45d0-a4ec-87fb5a5556da,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-9546291f-8ebb-41d1-ad78-b975095bbd2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-6b80f1d7-7a9d-4c59-8c61-71056f6494d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40250,DS-47d672f8-ca3b-41f4-a2d6-6fc11f289fea,DISK], DatanodeInfoWithStorage[127.0.0.1:45037,DS-2881d48c-9b5f-4cb0-bad3-a7c17062151e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-895765834-172.17.0.18-1595646176799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34322,DS-e68e7768-6226-4802-aa2e-03c3eb472dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-6d2469f6-0de0-47ef-90a3-28ce09fc7ded,DISK], DatanodeInfoWithStorage[127.0.0.1:38818,DS-22f77792-fb6d-4c8b-b514-eaf79a7f32be,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-692231e9-5198-4c5f-9dec-ede67e9c0961,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-201642b8-d122-4c55-b4e5-b34f988b2854,DISK], DatanodeInfoWithStorage[127.0.0.1:43173,DS-93d038a0-891c-43f2-bd2d-e1a2b45c308f,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-455448ba-ba10-4928-ba51-545d4345dd47,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-a63d4ed5-56a9-46af-8317-49ee37f94238,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-895765834-172.17.0.18-1595646176799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34322,DS-e68e7768-6226-4802-aa2e-03c3eb472dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-6d2469f6-0de0-47ef-90a3-28ce09fc7ded,DISK], DatanodeInfoWithStorage[127.0.0.1:38818,DS-22f77792-fb6d-4c8b-b514-eaf79a7f32be,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-692231e9-5198-4c5f-9dec-ede67e9c0961,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-201642b8-d122-4c55-b4e5-b34f988b2854,DISK], DatanodeInfoWithStorage[127.0.0.1:43173,DS-93d038a0-891c-43f2-bd2d-e1a2b45c308f,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-455448ba-ba10-4928-ba51-545d4345dd47,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-a63d4ed5-56a9-46af-8317-49ee37f94238,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1505580068-172.17.0.18-1595646337226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34253,DS-640011f2-7e6f-4ad5-ba40-0c6d96cecf1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-e6a596e6-eb6b-4e31-bb73-ecf046cf763b,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-c6577a26-f76b-4bcf-b3ad-5ff702831054,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-c8699185-dce7-4b0a-8180-1f48478b7705,DISK], DatanodeInfoWithStorage[127.0.0.1:33533,DS-851cfb92-a952-4b5f-8f16-b21571b553ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-74ebf869-89be-4404-9390-90823455753f,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-961c067f-5e7f-4a87-82de-07bc6ca0c3db,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-fb9c7749-fdcc-40a6-9437-ed38e3e58fd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1505580068-172.17.0.18-1595646337226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34253,DS-640011f2-7e6f-4ad5-ba40-0c6d96cecf1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-e6a596e6-eb6b-4e31-bb73-ecf046cf763b,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-c6577a26-f76b-4bcf-b3ad-5ff702831054,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-c8699185-dce7-4b0a-8180-1f48478b7705,DISK], DatanodeInfoWithStorage[127.0.0.1:33533,DS-851cfb92-a952-4b5f-8f16-b21571b553ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-74ebf869-89be-4404-9390-90823455753f,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-961c067f-5e7f-4a87-82de-07bc6ca0c3db,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-fb9c7749-fdcc-40a6-9437-ed38e3e58fd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-944357764-172.17.0.18-1595646564242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43470,DS-1d5a992d-d663-4abd-87e2-db49ca71953a,DISK], DatanodeInfoWithStorage[127.0.0.1:38236,DS-ed6f13be-c552-4748-add6-596e14532369,DISK], DatanodeInfoWithStorage[127.0.0.1:45650,DS-6e5b7387-6c57-4928-a077-04b0ab90232b,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-95324648-bd59-47e9-bb74-a86d23e81dff,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-56fa8bc0-d35b-4b0c-9176-5699ba8e4158,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-5dfb6056-3daa-4e31-8e45-27cf75acae66,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-c21313ee-27f0-40e1-a79c-2d944ebe34b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-a1ce0b21-e4e7-436e-b723-fc63a71d8cdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-944357764-172.17.0.18-1595646564242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43470,DS-1d5a992d-d663-4abd-87e2-db49ca71953a,DISK], DatanodeInfoWithStorage[127.0.0.1:38236,DS-ed6f13be-c552-4748-add6-596e14532369,DISK], DatanodeInfoWithStorage[127.0.0.1:45650,DS-6e5b7387-6c57-4928-a077-04b0ab90232b,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-95324648-bd59-47e9-bb74-a86d23e81dff,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-56fa8bc0-d35b-4b0c-9176-5699ba8e4158,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-5dfb6056-3daa-4e31-8e45-27cf75acae66,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-c21313ee-27f0-40e1-a79c-2d944ebe34b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-a1ce0b21-e4e7-436e-b723-fc63a71d8cdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-249313590-172.17.0.18-1595646996316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46663,DS-eb0b9b96-38e2-4cfc-b79f-c32f460cc64c,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-9bd2e763-bef7-4f5b-a750-8722dc98aac4,DISK], DatanodeInfoWithStorage[127.0.0.1:44370,DS-e4591403-8fc9-4e9e-b686-420a7d07b2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45587,DS-0ec447ac-1d61-493c-8137-798b1c83857d,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-7007e735-9189-431a-8e03-2e4b2df57bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-bcf2c338-f42a-49ce-b96b-90e4bd4c50d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-4d8cdbb3-0093-43ed-ac06-c0626c46b235,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-aa730989-125d-48be-b90b-9114e89dcbb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-249313590-172.17.0.18-1595646996316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46663,DS-eb0b9b96-38e2-4cfc-b79f-c32f460cc64c,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-9bd2e763-bef7-4f5b-a750-8722dc98aac4,DISK], DatanodeInfoWithStorage[127.0.0.1:44370,DS-e4591403-8fc9-4e9e-b686-420a7d07b2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45587,DS-0ec447ac-1d61-493c-8137-798b1c83857d,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-7007e735-9189-431a-8e03-2e4b2df57bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-bcf2c338-f42a-49ce-b96b-90e4bd4c50d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-4d8cdbb3-0093-43ed-ac06-c0626c46b235,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-aa730989-125d-48be-b90b-9114e89dcbb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2024360615-172.17.0.18-1595647166112:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39532,DS-c4626722-41b8-4a9b-a03d-51d6f7a80cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-5c0c9ab3-0051-46f5-8526-dfb28e1f0590,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-ed847810-6b43-49a7-b0d8-0329670f357f,DISK], DatanodeInfoWithStorage[127.0.0.1:33182,DS-dcff38ef-9252-424e-9ecb-3901c62ace58,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-d5f8e5c2-dc9a-40f6-9263-03fbbc1194f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-e1bd5257-58bb-4541-911c-8d48bafe2324,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-fd9cf85f-c09d-4bd6-97f4-74535b41f7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41071,DS-6d8392e6-d8fe-47e1-9dec-439995f1eeb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2024360615-172.17.0.18-1595647166112:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39532,DS-c4626722-41b8-4a9b-a03d-51d6f7a80cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-5c0c9ab3-0051-46f5-8526-dfb28e1f0590,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-ed847810-6b43-49a7-b0d8-0329670f357f,DISK], DatanodeInfoWithStorage[127.0.0.1:33182,DS-dcff38ef-9252-424e-9ecb-3901c62ace58,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-d5f8e5c2-dc9a-40f6-9263-03fbbc1194f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-e1bd5257-58bb-4541-911c-8d48bafe2324,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-fd9cf85f-c09d-4bd6-97f4-74535b41f7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41071,DS-6d8392e6-d8fe-47e1-9dec-439995f1eeb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1562949285-172.17.0.18-1595647309791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42963,DS-412e7ce5-3551-44f6-8d4a-eb89bb1963b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-14e9b6f0-a57d-40c1-855b-c0e263e9369e,DISK], DatanodeInfoWithStorage[127.0.0.1:42022,DS-1f2f812b-69b3-4027-b17d-59b710fcf5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-1f800ee1-2456-43ac-aad9-c4f3bc1851ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-670039e8-e221-4291-bf97-7b1174010a26,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-5b731696-0290-4d12-9799-ec678e6f3990,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-337f9113-4a3b-4de0-afab-3d940b8a0fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-80e22b29-11d5-4558-934e-63bb6502b62b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1562949285-172.17.0.18-1595647309791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42963,DS-412e7ce5-3551-44f6-8d4a-eb89bb1963b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-14e9b6f0-a57d-40c1-855b-c0e263e9369e,DISK], DatanodeInfoWithStorage[127.0.0.1:42022,DS-1f2f812b-69b3-4027-b17d-59b710fcf5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-1f800ee1-2456-43ac-aad9-c4f3bc1851ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-670039e8-e221-4291-bf97-7b1174010a26,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-5b731696-0290-4d12-9799-ec678e6f3990,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-337f9113-4a3b-4de0-afab-3d940b8a0fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-80e22b29-11d5-4558-934e-63bb6502b62b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1519022080-172.17.0.18-1595647349538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42881,DS-61245dcb-9216-4976-aabe-e8075153f0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-4988d19a-7b36-4a21-8f35-db8035e02151,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-78c8cba9-8934-42b7-bb53-84d264932db9,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-6f8c7c2e-2405-4079-a3f5-f0e288a8e4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43125,DS-ec2354fa-bbe5-4ffc-9f37-f4557f215bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-625cc43d-b0e0-442e-ac91-5b9e4d8cba71,DISK], DatanodeInfoWithStorage[127.0.0.1:35998,DS-8e697804-327a-47aa-8d88-02dfef3304a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-6231e72d-5150-4baf-9cca-4182ead493bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1519022080-172.17.0.18-1595647349538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42881,DS-61245dcb-9216-4976-aabe-e8075153f0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-4988d19a-7b36-4a21-8f35-db8035e02151,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-78c8cba9-8934-42b7-bb53-84d264932db9,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-6f8c7c2e-2405-4079-a3f5-f0e288a8e4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43125,DS-ec2354fa-bbe5-4ffc-9f37-f4557f215bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-625cc43d-b0e0-442e-ac91-5b9e4d8cba71,DISK], DatanodeInfoWithStorage[127.0.0.1:35998,DS-8e697804-327a-47aa-8d88-02dfef3304a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-6231e72d-5150-4baf-9cca-4182ead493bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-214711673-172.17.0.18-1595647539685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34200,DS-bad4790a-dafd-4226-9a81-a5951f9f2c32,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-1abf8bc8-3f87-47d1-b943-2c957f5cf291,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-b518c9d3-8876-459c-892a-7db5aa4fe2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-846798ab-2e86-4955-aabd-29e179a7b666,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-7938fbaa-fb5e-4a53-94b6-c0e1a0771f38,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-51b70fa1-898e-4fd3-ac66-91c1018a26ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-e549883d-53be-4213-8d8e-dde30fcaf0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-fc066884-0223-40f7-b0b4-f5e5173ddc65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-214711673-172.17.0.18-1595647539685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34200,DS-bad4790a-dafd-4226-9a81-a5951f9f2c32,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-1abf8bc8-3f87-47d1-b943-2c957f5cf291,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-b518c9d3-8876-459c-892a-7db5aa4fe2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-846798ab-2e86-4955-aabd-29e179a7b666,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-7938fbaa-fb5e-4a53-94b6-c0e1a0771f38,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-51b70fa1-898e-4fd3-ac66-91c1018a26ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-e549883d-53be-4213-8d8e-dde30fcaf0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-fc066884-0223-40f7-b0b4-f5e5173ddc65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1142372290-172.17.0.18-1595647690996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43833,DS-f7e072fa-8f2c-4b92-99a3-fdbb4e755a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:32839,DS-f9fbd44f-ef25-4b55-87f1-f2bddf24ea73,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-9fe26742-1e37-4837-bf1d-5514d3f4726f,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-3665af57-1ac6-4bb2-8c9a-362206efbe8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-288d3d90-0311-49ad-aaf6-d0df4a3cdc04,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-43578f9d-0e37-4b15-b87a-c5465b78ca3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-f47c47ad-00a0-4c81-a9ad-292449b1d7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-5876f350-b999-4ef1-ab15-ae0b37370186,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1142372290-172.17.0.18-1595647690996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43833,DS-f7e072fa-8f2c-4b92-99a3-fdbb4e755a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:32839,DS-f9fbd44f-ef25-4b55-87f1-f2bddf24ea73,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-9fe26742-1e37-4837-bf1d-5514d3f4726f,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-3665af57-1ac6-4bb2-8c9a-362206efbe8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-288d3d90-0311-49ad-aaf6-d0df4a3cdc04,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-43578f9d-0e37-4b15-b87a-c5465b78ca3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-f47c47ad-00a0-4c81-a9ad-292449b1d7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-5876f350-b999-4ef1-ab15-ae0b37370186,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-659962914-172.17.0.18-1595647733071:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39975,DS-dc989eb6-65c5-40f5-85d2-66ecb5432798,DISK], DatanodeInfoWithStorage[127.0.0.1:41843,DS-13108519-bdbf-4cb5-b2e7-1f850baadeb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41392,DS-874f690d-36f2-4d24-bb88-140d07aa0d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-03c92d4e-7de3-4124-998e-cade165eda7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46424,DS-315740c5-89d5-4d02-a6fa-6c1c4568f6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-cf5c513c-a420-44c3-ae0b-64bed7c3b9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40522,DS-34d24363-2e7c-424b-b043-78a567e985a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43834,DS-28300c9d-097b-449c-be69-568562a7c0b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-659962914-172.17.0.18-1595647733071:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39975,DS-dc989eb6-65c5-40f5-85d2-66ecb5432798,DISK], DatanodeInfoWithStorage[127.0.0.1:41843,DS-13108519-bdbf-4cb5-b2e7-1f850baadeb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41392,DS-874f690d-36f2-4d24-bb88-140d07aa0d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-03c92d4e-7de3-4124-998e-cade165eda7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46424,DS-315740c5-89d5-4d02-a6fa-6c1c4568f6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-cf5c513c-a420-44c3-ae0b-64bed7c3b9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40522,DS-34d24363-2e7c-424b-b043-78a567e985a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43834,DS-28300c9d-097b-449c-be69-568562a7c0b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1897936541-172.17.0.18-1595647768636:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45773,DS-0fb60aff-391b-4a46-b32a-4dca686299fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37021,DS-4634279c-26ae-4175-919f-f255c1239f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-872062c8-ad7a-4f92-9b8d-c1e4af132090,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-af74344b-eeae-425e-8c79-b889a38be503,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-4bb76999-e7de-4de8-840e-7122ca75613e,DISK], DatanodeInfoWithStorage[127.0.0.1:35541,DS-ab55cebb-3518-4474-9497-ee205879f7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-6f20535d-b5a6-4ee0-b3e0-ddcaacd94598,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-54d07a40-a740-4285-839f-57fd2b02b2f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1897936541-172.17.0.18-1595647768636:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45773,DS-0fb60aff-391b-4a46-b32a-4dca686299fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37021,DS-4634279c-26ae-4175-919f-f255c1239f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-872062c8-ad7a-4f92-9b8d-c1e4af132090,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-af74344b-eeae-425e-8c79-b889a38be503,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-4bb76999-e7de-4de8-840e-7122ca75613e,DISK], DatanodeInfoWithStorage[127.0.0.1:35541,DS-ab55cebb-3518-4474-9497-ee205879f7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-6f20535d-b5a6-4ee0-b3e0-ddcaacd94598,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-54d07a40-a740-4285-839f-57fd2b02b2f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2110619366-172.17.0.18-1595648125396:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34211,DS-c556d9c5-cc6f-4d20-9fda-e3a1a06c5a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37323,DS-1a5b320d-c6ce-49f8-ae3b-d2ec35b71390,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-766ea72b-1993-426a-9e58-8d723068a900,DISK], DatanodeInfoWithStorage[127.0.0.1:41790,DS-0a02b2a2-8f54-4c13-9956-0926ac671b64,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-32cab187-feef-4c4c-8a1d-ad005fcd8d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-1f11f6d3-e23b-4373-ab24-06a139483abb,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-aae1d5bb-235b-4631-a02d-714324be41c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37612,DS-0496d92c-600a-4a33-9d73-1d6df607bebe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2110619366-172.17.0.18-1595648125396:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34211,DS-c556d9c5-cc6f-4d20-9fda-e3a1a06c5a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37323,DS-1a5b320d-c6ce-49f8-ae3b-d2ec35b71390,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-766ea72b-1993-426a-9e58-8d723068a900,DISK], DatanodeInfoWithStorage[127.0.0.1:41790,DS-0a02b2a2-8f54-4c13-9956-0926ac671b64,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-32cab187-feef-4c4c-8a1d-ad005fcd8d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-1f11f6d3-e23b-4373-ab24-06a139483abb,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-aae1d5bb-235b-4631-a02d-714324be41c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37612,DS-0496d92c-600a-4a33-9d73-1d6df607bebe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1137934356-172.17.0.18-1595648700578:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35770,DS-e6ff091f-b542-41ab-98e5-e24ca3af33d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-6d8168ca-0aad-4b10-a453-dc39c4b5b9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-6e9a6ad6-ad7a-4481-9e72-c9383f116663,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-d96b0089-3dab-41bc-b5d4-5adfa4dd4906,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-c33249fe-b59f-4d28-98a2-4babfd1ea40f,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-c22c6f9d-ba29-4e7a-8225-0160152b30ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-e233a96d-268b-4b3d-9e63-131679f05f51,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-a2ebb579-2874-4270-a29d-55498e4777d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1137934356-172.17.0.18-1595648700578:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35770,DS-e6ff091f-b542-41ab-98e5-e24ca3af33d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-6d8168ca-0aad-4b10-a453-dc39c4b5b9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-6e9a6ad6-ad7a-4481-9e72-c9383f116663,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-d96b0089-3dab-41bc-b5d4-5adfa4dd4906,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-c33249fe-b59f-4d28-98a2-4babfd1ea40f,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-c22c6f9d-ba29-4e7a-8225-0160152b30ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-e233a96d-268b-4b3d-9e63-131679f05f51,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-a2ebb579-2874-4270-a29d-55498e4777d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-959249917-172.17.0.18-1595648839418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42584,DS-7c4040c6-0b1f-48d0-bef9-d3e4e0e62afe,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-192e5b97-ecec-4109-b76b-311c4fd38fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-1406aa36-1ff6-4cd6-bf81-e3ec3e856102,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-ba4f200f-4861-4b61-9498-d80adcfe0890,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-a5c33d60-3584-4c03-bd17-842d8835458e,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-4cc4999d-4925-48bc-b1dd-5528145d2098,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-f3902e60-568d-4007-a81a-ae66e018831c,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-6dae5d81-7443-4c9f-8472-4e47ef981e13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-959249917-172.17.0.18-1595648839418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42584,DS-7c4040c6-0b1f-48d0-bef9-d3e4e0e62afe,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-192e5b97-ecec-4109-b76b-311c4fd38fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-1406aa36-1ff6-4cd6-bf81-e3ec3e856102,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-ba4f200f-4861-4b61-9498-d80adcfe0890,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-a5c33d60-3584-4c03-bd17-842d8835458e,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-4cc4999d-4925-48bc-b1dd-5528145d2098,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-f3902e60-568d-4007-a81a-ae66e018831c,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-6dae5d81-7443-4c9f-8472-4e47ef981e13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1717749725-172.17.0.18-1595648876140:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45351,DS-cdfa02ca-5fe6-463b-9826-7af9ae54abfa,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-68552dcf-8eb7-4437-a019-9faa04f5ad20,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-f6755ff7-964b-4fe6-83ca-c49cbe5d3173,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-fcc20ed3-e25e-4b9a-815b-8184632b7410,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-3193aee4-6414-48be-9507-68e613bfec81,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-66691782-0a99-456d-9e28-a21ecd3e388b,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-d9217586-3c0b-4891-a829-93e210685fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-fedf589a-5b65-4bea-ae76-f03793290099,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1717749725-172.17.0.18-1595648876140:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45351,DS-cdfa02ca-5fe6-463b-9826-7af9ae54abfa,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-68552dcf-8eb7-4437-a019-9faa04f5ad20,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-f6755ff7-964b-4fe6-83ca-c49cbe5d3173,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-fcc20ed3-e25e-4b9a-815b-8184632b7410,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-3193aee4-6414-48be-9507-68e613bfec81,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-66691782-0a99-456d-9e28-a21ecd3e388b,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-d9217586-3c0b-4891-a829-93e210685fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-fedf589a-5b65-4bea-ae76-f03793290099,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1031789115-172.17.0.18-1595648943999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37633,DS-02d5d4f7-60c3-42fe-9c70-193110cfd018,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-c2f89648-11c9-4c7d-87bd-be5ad7c85943,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-3e80b739-3bac-45b3-9b87-be7029d6cebd,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-0dcf58a3-3a30-4ef9-b60c-d2405193703e,DISK], DatanodeInfoWithStorage[127.0.0.1:34890,DS-d0d383fb-63e1-49a7-ae8d-af241dd91fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-4d89c055-aab8-4621-918e-b041376e5f88,DISK], DatanodeInfoWithStorage[127.0.0.1:41547,DS-0c55a68a-b7d8-4b1f-b3d0-f5db441d6f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46428,DS-88aa903d-becd-45ab-a73e-fdf347eee232,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1031789115-172.17.0.18-1595648943999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37633,DS-02d5d4f7-60c3-42fe-9c70-193110cfd018,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-c2f89648-11c9-4c7d-87bd-be5ad7c85943,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-3e80b739-3bac-45b3-9b87-be7029d6cebd,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-0dcf58a3-3a30-4ef9-b60c-d2405193703e,DISK], DatanodeInfoWithStorage[127.0.0.1:34890,DS-d0d383fb-63e1-49a7-ae8d-af241dd91fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-4d89c055-aab8-4621-918e-b041376e5f88,DISK], DatanodeInfoWithStorage[127.0.0.1:41547,DS-0c55a68a-b7d8-4b1f-b3d0-f5db441d6f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46428,DS-88aa903d-becd-45ab-a73e-fdf347eee232,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1595270265-172.17.0.18-1595649404110:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32775,DS-f8b1ace2-8233-4f5f-9350-3cf6daaa5e77,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-8eadf66b-5451-4e20-bd67-ff4b57b61a43,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-81267188-5b1c-4cef-b5be-6fa66e2a7091,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-3fc097a5-8897-47e2-bec1-037c7bc7f5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-e3311f24-649e-487e-96ec-a245fd8c080c,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-0249881b-343d-4bcd-bd4d-78e831501422,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-84e881c1-6cf4-4500-83bc-5fd09cb5c0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-747c17b5-e42e-4f27-bdb9-95cbf3a10b1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1595270265-172.17.0.18-1595649404110:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32775,DS-f8b1ace2-8233-4f5f-9350-3cf6daaa5e77,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-8eadf66b-5451-4e20-bd67-ff4b57b61a43,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-81267188-5b1c-4cef-b5be-6fa66e2a7091,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-3fc097a5-8897-47e2-bec1-037c7bc7f5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-e3311f24-649e-487e-96ec-a245fd8c080c,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-0249881b-343d-4bcd-bd4d-78e831501422,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-84e881c1-6cf4-4500-83bc-5fd09cb5c0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-747c17b5-e42e-4f27-bdb9-95cbf3a10b1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1239133500-172.17.0.18-1595649527879:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33926,DS-e3e91822-4837-4d98-ae06-04b00e067e74,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-9d5f8f25-c4c8-4112-9563-0be615006f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34833,DS-82f2b216-ea91-48d0-9294-8b6fcfa76331,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-3ab4153b-d5c5-4f7b-b001-ac2cfee19fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-8ee38be4-4810-47d3-8a07-fe73975d313e,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-d1246ce6-1248-4614-bffb-d13eef84d654,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-42b93620-7d7a-4a08-ae29-4f09648f1b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43613,DS-f1f99744-edde-4d0b-9d47-1860a7aa9c78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1239133500-172.17.0.18-1595649527879:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33926,DS-e3e91822-4837-4d98-ae06-04b00e067e74,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-9d5f8f25-c4c8-4112-9563-0be615006f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34833,DS-82f2b216-ea91-48d0-9294-8b6fcfa76331,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-3ab4153b-d5c5-4f7b-b001-ac2cfee19fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-8ee38be4-4810-47d3-8a07-fe73975d313e,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-d1246ce6-1248-4614-bffb-d13eef84d654,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-42b93620-7d7a-4a08-ae29-4f09648f1b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43613,DS-f1f99744-edde-4d0b-9d47-1860a7aa9c78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5178
