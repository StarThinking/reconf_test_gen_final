reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-447425474-172.17.0.12-1595620750908:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35367,DS-04cde47c-0b80-4b8b-8903-f9fd199abe63,DISK], DatanodeInfoWithStorage[127.0.0.1:33555,DS-557c0605-0ea0-4ead-b2f2-5ba60e3800d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-ecb17868-d3d2-4662-818b-1e88045df907,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-43d42358-3049-4813-add1-11d855f85983,DISK], DatanodeInfoWithStorage[127.0.0.1:44041,DS-a0767f55-c389-460e-94cc-f038a29b64df,DISK], DatanodeInfoWithStorage[127.0.0.1:43810,DS-2a969db3-ce0a-4e55-b707-a4814169d5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-fb55c910-b566-4657-9e65-d59f92affd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-999d1909-16ff-455e-9d72-94e40de2c1b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-447425474-172.17.0.12-1595620750908:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35367,DS-04cde47c-0b80-4b8b-8903-f9fd199abe63,DISK], DatanodeInfoWithStorage[127.0.0.1:33555,DS-557c0605-0ea0-4ead-b2f2-5ba60e3800d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-ecb17868-d3d2-4662-818b-1e88045df907,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-43d42358-3049-4813-add1-11d855f85983,DISK], DatanodeInfoWithStorage[127.0.0.1:44041,DS-a0767f55-c389-460e-94cc-f038a29b64df,DISK], DatanodeInfoWithStorage[127.0.0.1:43810,DS-2a969db3-ce0a-4e55-b707-a4814169d5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-fb55c910-b566-4657-9e65-d59f92affd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-999d1909-16ff-455e-9d72-94e40de2c1b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1811382471-172.17.0.12-1595620885266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40367,DS-1121b2de-ab88-4205-ad43-bea959b8d6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-39861acc-aacf-454f-b62a-9c0551b32755,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-0c280e68-847f-4edb-af29-8279e1d21de2,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-870bad46-bb5b-471e-8c36-083cbd47b724,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-c6f57ecc-3890-4a25-92cb-03da5b6bd6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44236,DS-7801639c-ce57-4f3a-9d7a-0efffd18bfe1,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-62c4d734-3708-4689-89c1-d6925c5cb7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-950dd8b3-bcfa-4b6e-a13f-d862685f06c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1811382471-172.17.0.12-1595620885266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40367,DS-1121b2de-ab88-4205-ad43-bea959b8d6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-39861acc-aacf-454f-b62a-9c0551b32755,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-0c280e68-847f-4edb-af29-8279e1d21de2,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-870bad46-bb5b-471e-8c36-083cbd47b724,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-c6f57ecc-3890-4a25-92cb-03da5b6bd6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44236,DS-7801639c-ce57-4f3a-9d7a-0efffd18bfe1,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-62c4d734-3708-4689-89c1-d6925c5cb7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-950dd8b3-bcfa-4b6e-a13f-d862685f06c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-859275382-172.17.0.12-1595621515690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35477,DS-56cd49c1-dc58-47cb-8531-0970e844bc6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-e4a8be96-5252-4856-84b1-ee128158e157,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-9b1bf097-7381-493f-a0dd-ec3626685dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-b70951f9-bb27-4fe5-93b1-8d67dda22a88,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-17b05ed7-153a-43bf-884f-dd0bbad679c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-a4bb33a6-1e14-498a-97f6-4b99c511265c,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-7997e1f2-283a-4d8d-989a-a85befbe9cde,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-d5d68c89-98a5-4880-8d51-e31eece71dca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-859275382-172.17.0.12-1595621515690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35477,DS-56cd49c1-dc58-47cb-8531-0970e844bc6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-e4a8be96-5252-4856-84b1-ee128158e157,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-9b1bf097-7381-493f-a0dd-ec3626685dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-b70951f9-bb27-4fe5-93b1-8d67dda22a88,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-17b05ed7-153a-43bf-884f-dd0bbad679c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-a4bb33a6-1e14-498a-97f6-4b99c511265c,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-7997e1f2-283a-4d8d-989a-a85befbe9cde,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-d5d68c89-98a5-4880-8d51-e31eece71dca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-677617691-172.17.0.12-1595622049366:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46349,DS-7d5b97c9-f8a2-4c47-9f87-f04464dc582c,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-3bf6f227-2805-4725-bbf3-0e271e2c3c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-4421e02f-17fe-448d-970f-7d59e234deeb,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-4a99365a-6be6-45c1-893f-abfffde59d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-166c869b-9d9d-4b42-a346-5cc0c5d70713,DISK], DatanodeInfoWithStorage[127.0.0.1:37239,DS-afb9a6df-2955-49d2-93dd-556561c6e09c,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-40d7da1d-b708-46b0-8685-614980763997,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-4baadacf-5aaf-4d75-b29e-7e8148897d06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-677617691-172.17.0.12-1595622049366:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46349,DS-7d5b97c9-f8a2-4c47-9f87-f04464dc582c,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-3bf6f227-2805-4725-bbf3-0e271e2c3c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-4421e02f-17fe-448d-970f-7d59e234deeb,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-4a99365a-6be6-45c1-893f-abfffde59d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-166c869b-9d9d-4b42-a346-5cc0c5d70713,DISK], DatanodeInfoWithStorage[127.0.0.1:37239,DS-afb9a6df-2955-49d2-93dd-556561c6e09c,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-40d7da1d-b708-46b0-8685-614980763997,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-4baadacf-5aaf-4d75-b29e-7e8148897d06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-929376510-172.17.0.12-1595622088849:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37017,DS-b9ab21ce-e6a8-44f6-9579-94d1dc7a6acf,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-695cb7c8-807f-4e96-b95b-d7b3a9eef992,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-6babda97-4cb9-42d1-a37f-25241e27a1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-08c0c33b-1e3c-4193-805e-fcc867b918a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-5270ba7d-a6b3-4194-9f31-92d6a7630132,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-b5a16f88-e732-4cd7-8242-7601c1f40e48,DISK], DatanodeInfoWithStorage[127.0.0.1:36544,DS-ecc7980c-4d3c-436a-a23d-d61af772bec1,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-35d6308f-c888-4fb7-bbaa-f67e3abf2044,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-929376510-172.17.0.12-1595622088849:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37017,DS-b9ab21ce-e6a8-44f6-9579-94d1dc7a6acf,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-695cb7c8-807f-4e96-b95b-d7b3a9eef992,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-6babda97-4cb9-42d1-a37f-25241e27a1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-08c0c33b-1e3c-4193-805e-fcc867b918a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-5270ba7d-a6b3-4194-9f31-92d6a7630132,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-b5a16f88-e732-4cd7-8242-7601c1f40e48,DISK], DatanodeInfoWithStorage[127.0.0.1:36544,DS-ecc7980c-4d3c-436a-a23d-d61af772bec1,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-35d6308f-c888-4fb7-bbaa-f67e3abf2044,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1997407593-172.17.0.12-1595623109726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38732,DS-987aa669-b37a-48f7-aef1-f356a2742229,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-d796517c-baf4-45a5-889c-0bdd8dd68290,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-b1d02c50-fb68-4012-9ee0-6456ba3168d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-86884c3a-fbc6-4181-974b-3c961fa3c201,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-01b885d8-525b-449b-9719-7964d5692db7,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-04efaf65-440b-475e-af9e-a651c296fdff,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-8ae708a7-7cba-4da7-aa33-0c6c95a22205,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-b5d1d980-6cce-4074-9671-9785a9bd07ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1997407593-172.17.0.12-1595623109726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38732,DS-987aa669-b37a-48f7-aef1-f356a2742229,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-d796517c-baf4-45a5-889c-0bdd8dd68290,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-b1d02c50-fb68-4012-9ee0-6456ba3168d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-86884c3a-fbc6-4181-974b-3c961fa3c201,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-01b885d8-525b-449b-9719-7964d5692db7,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-04efaf65-440b-475e-af9e-a651c296fdff,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-8ae708a7-7cba-4da7-aa33-0c6c95a22205,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-b5d1d980-6cce-4074-9671-9785a9bd07ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1279114737-172.17.0.12-1595623200178:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41877,DS-7069d218-2c8d-48d1-965d-a19c0409529b,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-cc3507f5-aca5-43ea-bea5-46bdcc031e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-b27661b5-e877-431a-9104-4c6c4a4fa1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-309372ab-f338-4376-9143-7980878a97f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45042,DS-d9f64905-869c-4e7f-8b03-17dd32c54b79,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-ce81aef6-d17c-46d3-ae39-e38a947503cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-395f4aff-535a-4e72-a370-29dae7a471db,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-bc677fd6-b2d4-4389-a30c-97af10fe4068,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1279114737-172.17.0.12-1595623200178:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41877,DS-7069d218-2c8d-48d1-965d-a19c0409529b,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-cc3507f5-aca5-43ea-bea5-46bdcc031e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-b27661b5-e877-431a-9104-4c6c4a4fa1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-309372ab-f338-4376-9143-7980878a97f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45042,DS-d9f64905-869c-4e7f-8b03-17dd32c54b79,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-ce81aef6-d17c-46d3-ae39-e38a947503cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-395f4aff-535a-4e72-a370-29dae7a471db,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-bc677fd6-b2d4-4389-a30c-97af10fe4068,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2085293693-172.17.0.12-1595623346836:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34276,DS-a5cee27f-0e20-49a8-a3ef-239523315f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40423,DS-dc511129-5cf4-4683-bbec-d2c0b7bc2dea,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-783f00de-cd3a-4e01-be4e-072e7c1cce3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-91e3fd76-afd0-4289-b89a-ecb3b6c1ffd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-146077f6-7abe-4ec8-9d7e-ed4a8fa35b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-40e88396-88c0-492f-a058-56c8a877a747,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-321f71b4-51ad-4d9c-8ca9-6d1b72c7957e,DISK], DatanodeInfoWithStorage[127.0.0.1:37145,DS-08d7314b-3621-4fde-a97d-33daa7ee67b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2085293693-172.17.0.12-1595623346836:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34276,DS-a5cee27f-0e20-49a8-a3ef-239523315f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40423,DS-dc511129-5cf4-4683-bbec-d2c0b7bc2dea,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-783f00de-cd3a-4e01-be4e-072e7c1cce3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-91e3fd76-afd0-4289-b89a-ecb3b6c1ffd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-146077f6-7abe-4ec8-9d7e-ed4a8fa35b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-40e88396-88c0-492f-a058-56c8a877a747,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-321f71b4-51ad-4d9c-8ca9-6d1b72c7957e,DISK], DatanodeInfoWithStorage[127.0.0.1:37145,DS-08d7314b-3621-4fde-a97d-33daa7ee67b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1985852589-172.17.0.12-1595624295205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34261,DS-f741f696-fcf5-4189-b80f-cd01019b2205,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-11930981-b22b-4144-9cf6-3da6cdab4909,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-f2256cae-4c10-45ef-ad8c-14f42cfde4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-534d0ae5-3b5e-47c8-9517-8ac4cf686bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-0abdc6af-2a8b-4f0c-9d85-c184abef05f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-93c4b7e7-92ef-4765-a9a8-ce54be1ab7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-5327c452-f0e5-430e-a889-c0896188eb57,DISK], DatanodeInfoWithStorage[127.0.0.1:35220,DS-bd248f20-ab68-4fde-9778-047132d4bbf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1985852589-172.17.0.12-1595624295205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34261,DS-f741f696-fcf5-4189-b80f-cd01019b2205,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-11930981-b22b-4144-9cf6-3da6cdab4909,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-f2256cae-4c10-45ef-ad8c-14f42cfde4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-534d0ae5-3b5e-47c8-9517-8ac4cf686bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-0abdc6af-2a8b-4f0c-9d85-c184abef05f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-93c4b7e7-92ef-4765-a9a8-ce54be1ab7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-5327c452-f0e5-430e-a889-c0896188eb57,DISK], DatanodeInfoWithStorage[127.0.0.1:35220,DS-bd248f20-ab68-4fde-9778-047132d4bbf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1944954057-172.17.0.12-1595624726975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33868,DS-9f4adb83-7a2f-4527-a8de-5fda38d58333,DISK], DatanodeInfoWithStorage[127.0.0.1:34687,DS-94bbea51-430a-4be8-a477-d1716a9c158f,DISK], DatanodeInfoWithStorage[127.0.0.1:45719,DS-653e2516-55d0-49bb-ad24-4b53974a344a,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-b46ad7e6-d005-46de-823c-bae2d12a69ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-e2170829-8f36-4e64-9d9f-37d0c14182aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-16293136-32e0-4645-8517-c4a891d05d34,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-293a53b8-84df-46cd-be15-a5d59261c816,DISK], DatanodeInfoWithStorage[127.0.0.1:39044,DS-ff81159d-3d13-4a79-a7a4-3b302ea1d042,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1944954057-172.17.0.12-1595624726975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33868,DS-9f4adb83-7a2f-4527-a8de-5fda38d58333,DISK], DatanodeInfoWithStorage[127.0.0.1:34687,DS-94bbea51-430a-4be8-a477-d1716a9c158f,DISK], DatanodeInfoWithStorage[127.0.0.1:45719,DS-653e2516-55d0-49bb-ad24-4b53974a344a,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-b46ad7e6-d005-46de-823c-bae2d12a69ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-e2170829-8f36-4e64-9d9f-37d0c14182aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-16293136-32e0-4645-8517-c4a891d05d34,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-293a53b8-84df-46cd-be15-a5d59261c816,DISK], DatanodeInfoWithStorage[127.0.0.1:39044,DS-ff81159d-3d13-4a79-a7a4-3b302ea1d042,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1337686951-172.17.0.12-1595624767626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33771,DS-7e46b27d-4696-4ee4-8a64-8676931a0153,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-7624612c-b636-4915-8054-fb31a9a74e76,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-5c59c4eb-7867-4518-982d-ad457b819600,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-6ef4ecb1-5863-4cff-8841-0888ebb664df,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-37d9d678-91a8-4f75-b610-9f4a7808bb63,DISK], DatanodeInfoWithStorage[127.0.0.1:46545,DS-92f413a5-5e10-466c-a809-624566b3dde5,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-90fedc6f-5af1-47cf-a8ae-775ac8894606,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-c0a74fbf-593c-4174-b7e2-ce05e7003919,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1337686951-172.17.0.12-1595624767626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33771,DS-7e46b27d-4696-4ee4-8a64-8676931a0153,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-7624612c-b636-4915-8054-fb31a9a74e76,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-5c59c4eb-7867-4518-982d-ad457b819600,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-6ef4ecb1-5863-4cff-8841-0888ebb664df,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-37d9d678-91a8-4f75-b610-9f4a7808bb63,DISK], DatanodeInfoWithStorage[127.0.0.1:46545,DS-92f413a5-5e10-466c-a809-624566b3dde5,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-90fedc6f-5af1-47cf-a8ae-775ac8894606,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-c0a74fbf-593c-4174-b7e2-ce05e7003919,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-167068615-172.17.0.12-1595625168434:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40884,DS-1a9cccdf-2b9c-47b7-a25c-d63d6c579b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-745ab562-9cbc-432a-ac48-7ae21dadfe39,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-c47d607b-3641-4592-bbf9-114c1090b579,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-8b60ced4-29e5-4430-82fa-e6c6f871ad53,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-85356b65-3d4f-425b-80fd-a8b8a11bbb5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-7def81d1-2fd7-4a9f-a308-97114c066cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-4e1cb1ba-17f7-4423-a5a8-cd9112d9f261,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-325dfd9b-8fa4-4441-ab16-47a40f28429b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-167068615-172.17.0.12-1595625168434:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40884,DS-1a9cccdf-2b9c-47b7-a25c-d63d6c579b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-745ab562-9cbc-432a-ac48-7ae21dadfe39,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-c47d607b-3641-4592-bbf9-114c1090b579,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-8b60ced4-29e5-4430-82fa-e6c6f871ad53,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-85356b65-3d4f-425b-80fd-a8b8a11bbb5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-7def81d1-2fd7-4a9f-a308-97114c066cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-4e1cb1ba-17f7-4423-a5a8-cd9112d9f261,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-325dfd9b-8fa4-4441-ab16-47a40f28429b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-725240338-172.17.0.12-1595625732720:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36535,DS-67836271-89af-4332-9d69-b8f4917a080f,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-a9b0ca0e-b428-40a9-a847-8bece8bb7b01,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-61d3a883-a305-419e-a992-11dd775cf3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-60c6741d-e86f-4174-b953-9bd46eb55e56,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-dc497bba-5127-4fcf-a6b5-3eb4931b74bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-065b0f56-0e10-4e83-b949-c4363dc8b394,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-3c222073-8afe-46d0-bbdf-ba636e638ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:43060,DS-db1d196b-190b-44cc-a841-da6cfc1bf1e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-725240338-172.17.0.12-1595625732720:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36535,DS-67836271-89af-4332-9d69-b8f4917a080f,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-a9b0ca0e-b428-40a9-a847-8bece8bb7b01,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-61d3a883-a305-419e-a992-11dd775cf3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-60c6741d-e86f-4174-b953-9bd46eb55e56,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-dc497bba-5127-4fcf-a6b5-3eb4931b74bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-065b0f56-0e10-4e83-b949-c4363dc8b394,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-3c222073-8afe-46d0-bbdf-ba636e638ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:43060,DS-db1d196b-190b-44cc-a841-da6cfc1bf1e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1533203285-172.17.0.12-1595625775603:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36355,DS-cadfb165-e5fb-4159-a369-d48ade51d021,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-2917a26b-3cc0-4489-bde8-972fd60fa5be,DISK], DatanodeInfoWithStorage[127.0.0.1:35171,DS-2637c03d-5cb3-4d27-aee6-26f7c80782f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-939d8d85-43dd-4b8c-bd02-a11e002a823b,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-5889a112-5341-462f-b06b-ec0921726a54,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-0a58dc30-acda-4775-9fa0-e57957faf64a,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-985ef277-66bc-445e-9f39-567fc81b5421,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-5b7faed7-3ec2-42ad-b51e-e091c82bae1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1533203285-172.17.0.12-1595625775603:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36355,DS-cadfb165-e5fb-4159-a369-d48ade51d021,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-2917a26b-3cc0-4489-bde8-972fd60fa5be,DISK], DatanodeInfoWithStorage[127.0.0.1:35171,DS-2637c03d-5cb3-4d27-aee6-26f7c80782f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-939d8d85-43dd-4b8c-bd02-a11e002a823b,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-5889a112-5341-462f-b06b-ec0921726a54,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-0a58dc30-acda-4775-9fa0-e57957faf64a,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-985ef277-66bc-445e-9f39-567fc81b5421,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-5b7faed7-3ec2-42ad-b51e-e091c82bae1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1494166065-172.17.0.12-1595626056712:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44832,DS-e954c720-9541-4ac2-ac51-5f78b0e14e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-7ab91c33-4f90-4e48-a56e-62b69d97720c,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-b2804812-25ce-4725-b648-3c311537f15a,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-69d9491f-5a6e-427a-a579-e1dc898781a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-e583e731-c727-4f88-a8ca-eaafa164b3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-91d25a9b-344e-4658-bfb2-397d4eaf3c67,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-919a8a47-f323-4cd9-afbb-8cb1892a43b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-f51abbe8-3df0-41aa-8b62-cadcb15d0348,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1494166065-172.17.0.12-1595626056712:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44832,DS-e954c720-9541-4ac2-ac51-5f78b0e14e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-7ab91c33-4f90-4e48-a56e-62b69d97720c,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-b2804812-25ce-4725-b648-3c311537f15a,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-69d9491f-5a6e-427a-a579-e1dc898781a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-e583e731-c727-4f88-a8ca-eaafa164b3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-91d25a9b-344e-4658-bfb2-397d4eaf3c67,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-919a8a47-f323-4cd9-afbb-8cb1892a43b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-f51abbe8-3df0-41aa-8b62-cadcb15d0348,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1658135561-172.17.0.12-1595626276011:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40868,DS-ef13086f-7e79-45e0-b1bb-2c1242c3a5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-6f500a33-a3fa-40eb-97c2-be6b4f834721,DISK], DatanodeInfoWithStorage[127.0.0.1:39790,DS-2cc9d2c6-8db8-4270-80b7-effc394c741f,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-999bd580-f432-4807-9f4f-a796500d8ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:43824,DS-1830b7d1-eebc-4514-b8a9-7f82d337c104,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-2dd2491c-569c-4144-b834-e59cc1bd6f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-a145cdfd-8d25-494e-b6ff-580cb0566b41,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-34d443e7-82db-45df-93e0-374497a9cbf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1658135561-172.17.0.12-1595626276011:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40868,DS-ef13086f-7e79-45e0-b1bb-2c1242c3a5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-6f500a33-a3fa-40eb-97c2-be6b4f834721,DISK], DatanodeInfoWithStorage[127.0.0.1:39790,DS-2cc9d2c6-8db8-4270-80b7-effc394c741f,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-999bd580-f432-4807-9f4f-a796500d8ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:43824,DS-1830b7d1-eebc-4514-b8a9-7f82d337c104,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-2dd2491c-569c-4144-b834-e59cc1bd6f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-a145cdfd-8d25-494e-b6ff-580cb0566b41,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-34d443e7-82db-45df-93e0-374497a9cbf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-84940443-172.17.0.12-1595626360063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36288,DS-8a4a247f-bcf6-434b-8c27-9eb996bfc203,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-2e42d485-b804-4635-9ac0-87dc42577b72,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-486d2650-488a-4bc0-bdeb-491065c55b69,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-2b23fd7d-0c43-468b-bf46-5bf933879828,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-d02b747a-066c-42fa-a5e5-b072e564e1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-84ed5ea5-ab3b-4032-8547-7dbc8b5b436d,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-a1c97d1a-9b6d-4639-af13-88682ccc4d65,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-55b676af-c56c-4845-b4d5-6c0fafd8d26e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-84940443-172.17.0.12-1595626360063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36288,DS-8a4a247f-bcf6-434b-8c27-9eb996bfc203,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-2e42d485-b804-4635-9ac0-87dc42577b72,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-486d2650-488a-4bc0-bdeb-491065c55b69,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-2b23fd7d-0c43-468b-bf46-5bf933879828,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-d02b747a-066c-42fa-a5e5-b072e564e1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-84ed5ea5-ab3b-4032-8547-7dbc8b5b436d,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-a1c97d1a-9b6d-4639-af13-88682ccc4d65,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-55b676af-c56c-4845-b4d5-6c0fafd8d26e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1323420272-172.17.0.12-1595626864983:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45857,DS-666754c6-980e-4bcf-9e1b-0eec6bd90bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-b296eeb8-b973-4b68-8ae0-0de774837f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-be51afd1-d71c-4312-9000-3a2e03e15c31,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-ad14b139-3654-4551-88a8-32d4f827f96d,DISK], DatanodeInfoWithStorage[127.0.0.1:41486,DS-0f493928-acd8-4da9-96cb-952cd1505929,DISK], DatanodeInfoWithStorage[127.0.0.1:42136,DS-78b831ef-4d62-46b2-bfe4-f495293aca72,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-67a832f1-0710-4b05-84c5-7f5524dbb467,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-13841f13-b6d0-4865-a4bb-498e566000e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1323420272-172.17.0.12-1595626864983:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45857,DS-666754c6-980e-4bcf-9e1b-0eec6bd90bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-b296eeb8-b973-4b68-8ae0-0de774837f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-be51afd1-d71c-4312-9000-3a2e03e15c31,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-ad14b139-3654-4551-88a8-32d4f827f96d,DISK], DatanodeInfoWithStorage[127.0.0.1:41486,DS-0f493928-acd8-4da9-96cb-952cd1505929,DISK], DatanodeInfoWithStorage[127.0.0.1:42136,DS-78b831ef-4d62-46b2-bfe4-f495293aca72,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-67a832f1-0710-4b05-84c5-7f5524dbb467,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-13841f13-b6d0-4865-a4bb-498e566000e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 6572
