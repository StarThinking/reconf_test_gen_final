reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1202212556-172.17.0.14-1595928123247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37736,DS-59c05ed0-4e93-4ad0-9ae9-dec5c90b9559,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-08e958e5-5386-4fac-9582-eb9ed8fa3e48,DISK], DatanodeInfoWithStorage[127.0.0.1:36446,DS-30834d63-57ad-4886-ad8c-4706dbeed419,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-1074ec41-4824-466e-8299-68c82ea998b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-62a9b9ea-a300-403a-a184-78820f5b578b,DISK], DatanodeInfoWithStorage[127.0.0.1:45585,DS-527a796d-a152-4795-8a59-b9a6b5bab88b,DISK], DatanodeInfoWithStorage[127.0.0.1:45030,DS-738ccdc6-4a93-4c1b-8df9-bf476659453f,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-f8b81aea-420b-4e3a-b6b3-7253f717f293,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1202212556-172.17.0.14-1595928123247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37736,DS-59c05ed0-4e93-4ad0-9ae9-dec5c90b9559,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-08e958e5-5386-4fac-9582-eb9ed8fa3e48,DISK], DatanodeInfoWithStorage[127.0.0.1:36446,DS-30834d63-57ad-4886-ad8c-4706dbeed419,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-1074ec41-4824-466e-8299-68c82ea998b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-62a9b9ea-a300-403a-a184-78820f5b578b,DISK], DatanodeInfoWithStorage[127.0.0.1:45585,DS-527a796d-a152-4795-8a59-b9a6b5bab88b,DISK], DatanodeInfoWithStorage[127.0.0.1:45030,DS-738ccdc6-4a93-4c1b-8df9-bf476659453f,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-f8b81aea-420b-4e3a-b6b3-7253f717f293,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1864570363-172.17.0.14-1595928598536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46212,DS-65cc8bfb-81a5-4249-8458-cf3566875c06,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-89085584-d170-45e2-8ff8-31d805380a45,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-845b185f-9912-49ed-8292-bfff4e4b828e,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-5c93a7ae-e459-44fa-9acb-831665bea1ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-039ab4db-3602-4f16-b5c9-994631f5941f,DISK], DatanodeInfoWithStorage[127.0.0.1:39376,DS-c37ec05a-c8d6-4291-868e-5b1750cc19a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-00fbb2dd-e09b-4491-b3fa-1bda2c15014d,DISK], DatanodeInfoWithStorage[127.0.0.1:45217,DS-5afa96e7-ab29-4dee-b76a-5583415edfa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1864570363-172.17.0.14-1595928598536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46212,DS-65cc8bfb-81a5-4249-8458-cf3566875c06,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-89085584-d170-45e2-8ff8-31d805380a45,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-845b185f-9912-49ed-8292-bfff4e4b828e,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-5c93a7ae-e459-44fa-9acb-831665bea1ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-039ab4db-3602-4f16-b5c9-994631f5941f,DISK], DatanodeInfoWithStorage[127.0.0.1:39376,DS-c37ec05a-c8d6-4291-868e-5b1750cc19a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-00fbb2dd-e09b-4491-b3fa-1bda2c15014d,DISK], DatanodeInfoWithStorage[127.0.0.1:45217,DS-5afa96e7-ab29-4dee-b76a-5583415edfa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-594416828-172.17.0.14-1595928666865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45006,DS-059e2827-bb72-44dd-90c5-b6a8a0a62bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:46860,DS-2cf8ec4a-bcfd-466e-b019-e9c258586018,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-5ae4a403-c953-4dfd-ad1b-726db6c615f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-f10ddf74-ede3-4976-8817-44c8d168f981,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-ea4db226-6908-4020-a8d8-710b0e49af75,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-30117050-d445-483e-b73b-5b2b7c5f16e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-5eb5aa29-275d-4dc0-a6ac-2758415105b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-8f356761-c887-4c1f-8b53-efc3fb0c8ba1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-594416828-172.17.0.14-1595928666865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45006,DS-059e2827-bb72-44dd-90c5-b6a8a0a62bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:46860,DS-2cf8ec4a-bcfd-466e-b019-e9c258586018,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-5ae4a403-c953-4dfd-ad1b-726db6c615f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-f10ddf74-ede3-4976-8817-44c8d168f981,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-ea4db226-6908-4020-a8d8-710b0e49af75,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-30117050-d445-483e-b73b-5b2b7c5f16e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-5eb5aa29-275d-4dc0-a6ac-2758415105b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-8f356761-c887-4c1f-8b53-efc3fb0c8ba1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-560320312-172.17.0.14-1595928766413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40378,DS-fa1cd414-6f0a-4d00-99f6-f836606d2e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-dd52daf1-fbf4-43ac-b188-70d431e3b50e,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-f12ee2b9-9271-413a-a8d6-e679db9fb029,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-c015a6a2-1357-47d7-aee5-2b7fd423220b,DISK], DatanodeInfoWithStorage[127.0.0.1:45688,DS-18ac89f3-f685-4151-a21d-c70a0fc4d840,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-c9954202-284e-4015-9a29-7aeab177e79a,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-42ea3124-8972-4c40-b98c-5a2d1d1e9271,DISK], DatanodeInfoWithStorage[127.0.0.1:33777,DS-47a6e9be-398a-41c0-ae00-28c9eb70fc3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-560320312-172.17.0.14-1595928766413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40378,DS-fa1cd414-6f0a-4d00-99f6-f836606d2e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-dd52daf1-fbf4-43ac-b188-70d431e3b50e,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-f12ee2b9-9271-413a-a8d6-e679db9fb029,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-c015a6a2-1357-47d7-aee5-2b7fd423220b,DISK], DatanodeInfoWithStorage[127.0.0.1:45688,DS-18ac89f3-f685-4151-a21d-c70a0fc4d840,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-c9954202-284e-4015-9a29-7aeab177e79a,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-42ea3124-8972-4c40-b98c-5a2d1d1e9271,DISK], DatanodeInfoWithStorage[127.0.0.1:33777,DS-47a6e9be-398a-41c0-ae00-28c9eb70fc3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-987104262-172.17.0.14-1595928957729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43203,DS-d9ddcb37-0870-494c-b417-c56fff95d7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41006,DS-b04d866a-38de-45be-a5de-4e23578410b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-563ac319-ab23-4b4f-a609-c2c79c1f5c25,DISK], DatanodeInfoWithStorage[127.0.0.1:41187,DS-da8b6fe1-ac20-4960-ba46-974eb8cc5c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-21a8da4a-5dd5-49ca-9b27-5f5d5f741d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-bf9835ae-2160-4a99-8ba4-ad187276fed9,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-fbb95b88-231b-4cab-8290-ca2127acf0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-f87e3590-a28e-49ed-a9d4-53471a87fe08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-987104262-172.17.0.14-1595928957729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43203,DS-d9ddcb37-0870-494c-b417-c56fff95d7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41006,DS-b04d866a-38de-45be-a5de-4e23578410b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-563ac319-ab23-4b4f-a609-c2c79c1f5c25,DISK], DatanodeInfoWithStorage[127.0.0.1:41187,DS-da8b6fe1-ac20-4960-ba46-974eb8cc5c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-21a8da4a-5dd5-49ca-9b27-5f5d5f741d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-bf9835ae-2160-4a99-8ba4-ad187276fed9,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-fbb95b88-231b-4cab-8290-ca2127acf0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-f87e3590-a28e-49ed-a9d4-53471a87fe08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-876637326-172.17.0.14-1595929448524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46505,DS-3abd2368-95c5-4ceb-864f-e9cada9fff0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40308,DS-6f0a38e1-5a05-46a0-92bd-0b2748d030d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-a0424210-35c3-4f4a-b353-5053f0ae59b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-944d9ab1-4d83-48cd-9c3e-f200129fc557,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-a27b958e-7051-499d-a87a-f2d3b9e291df,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-e03eb112-cd6c-4a06-8b97-a4bd59481072,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-2e3727e3-c615-4bce-a5ff-7f9f7170c92f,DISK], DatanodeInfoWithStorage[127.0.0.1:42907,DS-885ce3fe-2dff-47ae-847b-7eca42b707a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-876637326-172.17.0.14-1595929448524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46505,DS-3abd2368-95c5-4ceb-864f-e9cada9fff0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40308,DS-6f0a38e1-5a05-46a0-92bd-0b2748d030d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-a0424210-35c3-4f4a-b353-5053f0ae59b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-944d9ab1-4d83-48cd-9c3e-f200129fc557,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-a27b958e-7051-499d-a87a-f2d3b9e291df,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-e03eb112-cd6c-4a06-8b97-a4bd59481072,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-2e3727e3-c615-4bce-a5ff-7f9f7170c92f,DISK], DatanodeInfoWithStorage[127.0.0.1:42907,DS-885ce3fe-2dff-47ae-847b-7eca42b707a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-819754363-172.17.0.14-1595929487954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44979,DS-103937eb-01af-42fc-8c82-4e2ada327365,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-98bcb94a-55a0-4560-8ee0-3f457742643d,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-d58b32f8-aac0-4786-8268-c1cc2aa9ca3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45046,DS-5da1d31f-d25e-4bfd-8ebd-091e4d04b1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35431,DS-c8038280-2199-4e1a-977d-34848c6c975f,DISK], DatanodeInfoWithStorage[127.0.0.1:39242,DS-7787edea-69c3-4fb3-a1ad-f2bea62dd86b,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-9fa0ba26-def6-44df-a8ab-deed65bdfe51,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-1ab62390-3138-4a23-accd-2215b134acd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-819754363-172.17.0.14-1595929487954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44979,DS-103937eb-01af-42fc-8c82-4e2ada327365,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-98bcb94a-55a0-4560-8ee0-3f457742643d,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-d58b32f8-aac0-4786-8268-c1cc2aa9ca3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45046,DS-5da1d31f-d25e-4bfd-8ebd-091e4d04b1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35431,DS-c8038280-2199-4e1a-977d-34848c6c975f,DISK], DatanodeInfoWithStorage[127.0.0.1:39242,DS-7787edea-69c3-4fb3-a1ad-f2bea62dd86b,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-9fa0ba26-def6-44df-a8ab-deed65bdfe51,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-1ab62390-3138-4a23-accd-2215b134acd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1398466720-172.17.0.14-1595929528312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37254,DS-e0b279bb-d7c0-4bf9-9e45-805f1ba6a53d,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-672a3614-6e7d-4f67-9ec6-172a8b4269c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-56a53d87-199f-4a9d-a5dc-1100e317842f,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-4423225e-61c3-4a4b-8879-ddd5e2c14f82,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-b6fe4f66-59db-4109-8ba2-cb930b709694,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-34b5a49a-695a-4aa2-bf54-a6e7704f3df0,DISK], DatanodeInfoWithStorage[127.0.0.1:42601,DS-53795bcc-5a5f-4320-b371-f9dd8d7370ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41713,DS-fcf1fed1-2d4a-40cb-9ae3-849817736158,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1398466720-172.17.0.14-1595929528312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37254,DS-e0b279bb-d7c0-4bf9-9e45-805f1ba6a53d,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-672a3614-6e7d-4f67-9ec6-172a8b4269c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-56a53d87-199f-4a9d-a5dc-1100e317842f,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-4423225e-61c3-4a4b-8879-ddd5e2c14f82,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-b6fe4f66-59db-4109-8ba2-cb930b709694,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-34b5a49a-695a-4aa2-bf54-a6e7704f3df0,DISK], DatanodeInfoWithStorage[127.0.0.1:42601,DS-53795bcc-5a5f-4320-b371-f9dd8d7370ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41713,DS-fcf1fed1-2d4a-40cb-9ae3-849817736158,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1954593859-172.17.0.14-1595929689348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40277,DS-6f8ae751-5fbd-43fe-b6ed-6c19c0df5239,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-fb162082-3274-4bb3-aaac-ee19d399574e,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-d21d4651-f608-416f-b14c-50930919e2ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-49095e07-9493-486a-8b6d-80f7fd3c7701,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-7151f111-31b0-4249-ac78-bb89ae1e94c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-b88be927-3602-4dca-94da-2c475565d375,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-dd21b8e5-0766-4eb0-8610-657f63d1a196,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-924c75a4-749a-4b9d-93c3-358fad842f35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1954593859-172.17.0.14-1595929689348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40277,DS-6f8ae751-5fbd-43fe-b6ed-6c19c0df5239,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-fb162082-3274-4bb3-aaac-ee19d399574e,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-d21d4651-f608-416f-b14c-50930919e2ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-49095e07-9493-486a-8b6d-80f7fd3c7701,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-7151f111-31b0-4249-ac78-bb89ae1e94c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-b88be927-3602-4dca-94da-2c475565d375,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-dd21b8e5-0766-4eb0-8610-657f63d1a196,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-924c75a4-749a-4b9d-93c3-358fad842f35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-370118776-172.17.0.14-1595929875418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37305,DS-20c9ae7c-a327-4381-953f-c81eef83f116,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-95b07c94-18f5-4382-a2b3-ff9f78b26953,DISK], DatanodeInfoWithStorage[127.0.0.1:37401,DS-ad8e1f9f-0ac4-479e-a64b-dbd6653b4992,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-65c82ba6-56da-4cbb-bd14-6ab21840135e,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-28e22bf4-3088-40c8-b879-c41d05f13b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41864,DS-653a9ae5-17af-49c3-855f-0ee012d3c3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46634,DS-10cf341e-f053-48c6-86ae-d0710cf2f34e,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-8ee40256-1347-42ab-b209-1dda2a13f181,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-370118776-172.17.0.14-1595929875418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37305,DS-20c9ae7c-a327-4381-953f-c81eef83f116,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-95b07c94-18f5-4382-a2b3-ff9f78b26953,DISK], DatanodeInfoWithStorage[127.0.0.1:37401,DS-ad8e1f9f-0ac4-479e-a64b-dbd6653b4992,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-65c82ba6-56da-4cbb-bd14-6ab21840135e,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-28e22bf4-3088-40c8-b879-c41d05f13b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41864,DS-653a9ae5-17af-49c3-855f-0ee012d3c3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46634,DS-10cf341e-f053-48c6-86ae-d0710cf2f34e,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-8ee40256-1347-42ab-b209-1dda2a13f181,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1000410048-172.17.0.14-1595930126956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33396,DS-5e857a20-94fc-4134-ae64-9146ad249ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-6933efd1-85bb-480f-8e16-a0e17b37ace3,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-c19a9cc3-1ade-4248-a42f-87fecf501ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-79a19e24-3821-4b07-b273-638d1a55c710,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-e2c433aa-2878-42f3-a934-77702437951d,DISK], DatanodeInfoWithStorage[127.0.0.1:39658,DS-6ff3f95f-675b-4224-a8cc-8b567d23bc68,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-33109176-d730-4a61-b324-42bb81c9ec8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-efbe0c71-9a32-4790-b008-188d17b75277,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1000410048-172.17.0.14-1595930126956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33396,DS-5e857a20-94fc-4134-ae64-9146ad249ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-6933efd1-85bb-480f-8e16-a0e17b37ace3,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-c19a9cc3-1ade-4248-a42f-87fecf501ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-79a19e24-3821-4b07-b273-638d1a55c710,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-e2c433aa-2878-42f3-a934-77702437951d,DISK], DatanodeInfoWithStorage[127.0.0.1:39658,DS-6ff3f95f-675b-4224-a8cc-8b567d23bc68,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-33109176-d730-4a61-b324-42bb81c9ec8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-efbe0c71-9a32-4790-b008-188d17b75277,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1145534181-172.17.0.14-1595930486362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35714,DS-4af97c3f-1e04-4328-bc59-101b0d54c92c,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-87a71f71-13cc-48cb-9829-5a02f6077a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-05c9990a-1708-4796-9dc9-7617d453904b,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-b51d3c17-12ae-4a98-9ddc-818b21f9a4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-10f847c7-ba22-4026-b049-e35e89bb333a,DISK], DatanodeInfoWithStorage[127.0.0.1:43253,DS-37e65788-22ba-4d5b-a6ef-41c43f9ed195,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-a2737c81-5f81-4a82-a401-ae2afbfb0616,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-28234111-085d-432b-b487-0711f944b7c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1145534181-172.17.0.14-1595930486362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35714,DS-4af97c3f-1e04-4328-bc59-101b0d54c92c,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-87a71f71-13cc-48cb-9829-5a02f6077a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-05c9990a-1708-4796-9dc9-7617d453904b,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-b51d3c17-12ae-4a98-9ddc-818b21f9a4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-10f847c7-ba22-4026-b049-e35e89bb333a,DISK], DatanodeInfoWithStorage[127.0.0.1:43253,DS-37e65788-22ba-4d5b-a6ef-41c43f9ed195,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-a2737c81-5f81-4a82-a401-ae2afbfb0616,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-28234111-085d-432b-b487-0711f944b7c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-92648673-172.17.0.14-1595930670547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34819,DS-79cf009a-4471-4cfe-9395-a346d3827bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-5512cad6-0aa9-40a3-9713-99caaba3060f,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-a1f3ca56-7918-44f6-9fff-44a30c1fadf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-d616f011-b233-43a4-b081-3bd33b99515f,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-56faad8b-a855-461e-935c-53aaaa1498d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36168,DS-c7f81784-b63a-4078-81a1-fafb2b015966,DISK], DatanodeInfoWithStorage[127.0.0.1:45591,DS-90904105-9c2f-40f2-906e-b0b13fde8aec,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-e9941b2d-d957-444a-b645-aca47bb614b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-92648673-172.17.0.14-1595930670547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34819,DS-79cf009a-4471-4cfe-9395-a346d3827bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-5512cad6-0aa9-40a3-9713-99caaba3060f,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-a1f3ca56-7918-44f6-9fff-44a30c1fadf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-d616f011-b233-43a4-b081-3bd33b99515f,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-56faad8b-a855-461e-935c-53aaaa1498d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36168,DS-c7f81784-b63a-4078-81a1-fafb2b015966,DISK], DatanodeInfoWithStorage[127.0.0.1:45591,DS-90904105-9c2f-40f2-906e-b0b13fde8aec,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-e9941b2d-d957-444a-b645-aca47bb614b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-15656104-172.17.0.14-1595931081345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33532,DS-b46dec26-ea0f-4a28-af28-a2dfbfb52637,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-6d6e18ce-a9df-4236-86ea-8027e72d7217,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-33edabeb-d94d-4a85-9b8b-68b57c4c0388,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-935a205f-c25f-46b6-bafa-5a9d3e165d86,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-60d620e4-38a8-486c-a6c3-82684fa48f06,DISK], DatanodeInfoWithStorage[127.0.0.1:37829,DS-84002d46-9271-4bc1-9962-7ec747a8c75c,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-f664d191-ec09-4225-904a-3c8fa123dcd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-c4f8b743-2154-471b-af16-eecbfc7f6409,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-15656104-172.17.0.14-1595931081345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33532,DS-b46dec26-ea0f-4a28-af28-a2dfbfb52637,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-6d6e18ce-a9df-4236-86ea-8027e72d7217,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-33edabeb-d94d-4a85-9b8b-68b57c4c0388,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-935a205f-c25f-46b6-bafa-5a9d3e165d86,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-60d620e4-38a8-486c-a6c3-82684fa48f06,DISK], DatanodeInfoWithStorage[127.0.0.1:37829,DS-84002d46-9271-4bc1-9962-7ec747a8c75c,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-f664d191-ec09-4225-904a-3c8fa123dcd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-c4f8b743-2154-471b-af16-eecbfc7f6409,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-571542898-172.17.0.14-1595931319825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40171,DS-787dc8c1-ccd4-4d4e-88ed-f5b7a92a684c,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-a752bca7-aa9f-4dd2-9975-241976d33516,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-d803742c-c880-4886-b59e-321d454e35c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-47f72d0d-d0c2-498b-87c5-2e2bd8d5f3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46165,DS-ff178e1f-aa5a-4a3b-8e08-e6d0efcc5810,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-269aa2dc-dd98-4bdb-9ac3-abc88a2cddd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-248f076d-6f02-4564-843b-6c9109a04c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46149,DS-1e34d92c-1198-40e5-bf37-deb16708bee7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-571542898-172.17.0.14-1595931319825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40171,DS-787dc8c1-ccd4-4d4e-88ed-f5b7a92a684c,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-a752bca7-aa9f-4dd2-9975-241976d33516,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-d803742c-c880-4886-b59e-321d454e35c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-47f72d0d-d0c2-498b-87c5-2e2bd8d5f3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46165,DS-ff178e1f-aa5a-4a3b-8e08-e6d0efcc5810,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-269aa2dc-dd98-4bdb-9ac3-abc88a2cddd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-248f076d-6f02-4564-843b-6c9109a04c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46149,DS-1e34d92c-1198-40e5-bf37-deb16708bee7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1088093464-172.17.0.14-1595931997229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36633,DS-a26a6754-3682-4972-a20b-5a52e7be22fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-1e5909e4-cda8-4689-aed5-7f32ffe72726,DISK], DatanodeInfoWithStorage[127.0.0.1:35338,DS-4defbd55-6721-47c4-912b-fc0dc4e5a782,DISK], DatanodeInfoWithStorage[127.0.0.1:40147,DS-14a9f77f-690a-45b0-b72b-be437f786f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-98a154bb-cb38-441b-8a38-dd9e88686bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-b658b84f-a8df-4a23-a3ce-b339d2cce32d,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-86137d4b-95b9-4c27-be63-db46a952ae06,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-80c4c0a7-ad4f-4e83-87eb-63471ed0938a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1088093464-172.17.0.14-1595931997229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36633,DS-a26a6754-3682-4972-a20b-5a52e7be22fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-1e5909e4-cda8-4689-aed5-7f32ffe72726,DISK], DatanodeInfoWithStorage[127.0.0.1:35338,DS-4defbd55-6721-47c4-912b-fc0dc4e5a782,DISK], DatanodeInfoWithStorage[127.0.0.1:40147,DS-14a9f77f-690a-45b0-b72b-be437f786f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-98a154bb-cb38-441b-8a38-dd9e88686bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-b658b84f-a8df-4a23-a3ce-b339d2cce32d,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-86137d4b-95b9-4c27-be63-db46a952ae06,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-80c4c0a7-ad4f-4e83-87eb-63471ed0938a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1000124916-172.17.0.14-1595932102735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37257,DS-20238caf-739b-4eaa-96a2-a503aecf73ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-c6022567-f9e6-4a1f-aafc-e673715c7fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38647,DS-d679dab8-a532-4978-a52f-14fa98f10edc,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-19b6b9c4-3f23-4637-9a31-eeaae0f5cd17,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-c0fc92ac-e3f2-41ce-a1dc-560e4fceae18,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-ce7e3450-c394-48cd-b2d8-97339ef9cfcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42905,DS-06d66a4e-f905-4273-a2c1-5e5cb56f9571,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-4ce56c89-d619-4c38-9cd3-5d4403cef48c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1000124916-172.17.0.14-1595932102735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37257,DS-20238caf-739b-4eaa-96a2-a503aecf73ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-c6022567-f9e6-4a1f-aafc-e673715c7fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38647,DS-d679dab8-a532-4978-a52f-14fa98f10edc,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-19b6b9c4-3f23-4637-9a31-eeaae0f5cd17,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-c0fc92ac-e3f2-41ce-a1dc-560e4fceae18,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-ce7e3450-c394-48cd-b2d8-97339ef9cfcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42905,DS-06d66a4e-f905-4273-a2c1-5e5cb56f9571,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-4ce56c89-d619-4c38-9cd3-5d4403cef48c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-729677119-172.17.0.14-1595932209483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42028,DS-53f0d06f-1ba6-4ba4-9193-3c2ef280373a,DISK], DatanodeInfoWithStorage[127.0.0.1:33894,DS-1de51334-7e59-4119-850d-cc4389de4416,DISK], DatanodeInfoWithStorage[127.0.0.1:37958,DS-d6c253e3-e430-419d-b6e3-6c7a127e1bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:39474,DS-7ae7de40-a2d5-471b-b065-df7e11b8c4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-c78f46b9-1c6a-46a4-92bc-3f0cd38a2e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42168,DS-fdb336e7-352a-4334-a961-36ed8e39a0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39470,DS-ad834414-98a4-475b-bc05-ed30c1529529,DISK], DatanodeInfoWithStorage[127.0.0.1:45924,DS-e832b6c1-bdee-4f1c-ad3d-005e934cac57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-729677119-172.17.0.14-1595932209483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42028,DS-53f0d06f-1ba6-4ba4-9193-3c2ef280373a,DISK], DatanodeInfoWithStorage[127.0.0.1:33894,DS-1de51334-7e59-4119-850d-cc4389de4416,DISK], DatanodeInfoWithStorage[127.0.0.1:37958,DS-d6c253e3-e430-419d-b6e3-6c7a127e1bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:39474,DS-7ae7de40-a2d5-471b-b065-df7e11b8c4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-c78f46b9-1c6a-46a4-92bc-3f0cd38a2e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42168,DS-fdb336e7-352a-4334-a961-36ed8e39a0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39470,DS-ad834414-98a4-475b-bc05-ed30c1529529,DISK], DatanodeInfoWithStorage[127.0.0.1:45924,DS-e832b6c1-bdee-4f1c-ad3d-005e934cac57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950314327-172.17.0.14-1595932693750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43000,DS-36d61556-96df-43c1-ad27-a73341205069,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-0cced2ee-9c03-4814-bae7-9292e1170396,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-f84daf26-294d-46ce-a065-046ecb306bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-24b0fd44-197f-46da-9971-be7637a5e028,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-28b027f4-cf0f-427e-b1b2-97a52733e306,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-31216a38-59d0-4916-838a-ea5b799820b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-bedccd9c-daad-42c1-98c3-f00672740fef,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-800d9c49-58fb-4c63-920a-3ff0778c2d5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950314327-172.17.0.14-1595932693750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43000,DS-36d61556-96df-43c1-ad27-a73341205069,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-0cced2ee-9c03-4814-bae7-9292e1170396,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-f84daf26-294d-46ce-a065-046ecb306bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-24b0fd44-197f-46da-9971-be7637a5e028,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-28b027f4-cf0f-427e-b1b2-97a52733e306,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-31216a38-59d0-4916-838a-ea5b799820b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-bedccd9c-daad-42c1-98c3-f00672740fef,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-800d9c49-58fb-4c63-920a-3ff0778c2d5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1690884725-172.17.0.14-1595933127664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40672,DS-cb730188-6028-42f2-a227-e6e4df905da8,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-919dcac1-176f-43a0-b187-b46fb4e155ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-12b85a66-2529-483b-8be0-4e2672dbb088,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-a205f9f6-f49a-483a-a102-dfc4ec4cb9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-488fbf68-73c9-4cc1-ac84-5b26d975c53f,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-63098ed9-e338-42d0-a0a6-225c448ea86f,DISK], DatanodeInfoWithStorage[127.0.0.1:33414,DS-8c3d18b3-103d-47ca-9019-db343148551e,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-dc9857c5-0039-4d19-8ec2-86cd2a4ba689,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1690884725-172.17.0.14-1595933127664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40672,DS-cb730188-6028-42f2-a227-e6e4df905da8,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-919dcac1-176f-43a0-b187-b46fb4e155ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-12b85a66-2529-483b-8be0-4e2672dbb088,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-a205f9f6-f49a-483a-a102-dfc4ec4cb9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-488fbf68-73c9-4cc1-ac84-5b26d975c53f,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-63098ed9-e338-42d0-a0a6-225c448ea86f,DISK], DatanodeInfoWithStorage[127.0.0.1:33414,DS-8c3d18b3-103d-47ca-9019-db343148551e,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-dc9857c5-0039-4d19-8ec2-86cd2a4ba689,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5492
