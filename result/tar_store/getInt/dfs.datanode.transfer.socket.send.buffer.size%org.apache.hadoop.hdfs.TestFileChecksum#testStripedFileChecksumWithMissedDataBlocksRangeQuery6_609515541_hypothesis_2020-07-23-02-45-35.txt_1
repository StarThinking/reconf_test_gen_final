reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-597161537-172.17.0.16-1595472347247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44950,DS-efb720b8-fbf5-4dc1-b800-5f04670f0ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:39155,DS-2bb8e971-072b-47f9-8a8b-2a541b057395,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-5f43368d-3dfd-49aa-bf5f-9af0ea110535,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-67c7c09e-dec6-404b-a171-8b8817ba6252,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-18eaddc3-803f-49e2-9d66-ce9301ebac5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-e300dd0f-73b4-489a-a756-697596baa76c,DISK], DatanodeInfoWithStorage[127.0.0.1:34273,DS-1f214144-8b75-44ce-8063-881f86a7ff0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-d0c5bdf8-595a-4385-a12d-7bb9786f7d85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-597161537-172.17.0.16-1595472347247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44950,DS-efb720b8-fbf5-4dc1-b800-5f04670f0ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:39155,DS-2bb8e971-072b-47f9-8a8b-2a541b057395,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-5f43368d-3dfd-49aa-bf5f-9af0ea110535,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-67c7c09e-dec6-404b-a171-8b8817ba6252,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-18eaddc3-803f-49e2-9d66-ce9301ebac5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-e300dd0f-73b4-489a-a756-697596baa76c,DISK], DatanodeInfoWithStorage[127.0.0.1:34273,DS-1f214144-8b75-44ce-8063-881f86a7ff0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-d0c5bdf8-595a-4385-a12d-7bb9786f7d85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1629380663-172.17.0.16-1595472538091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37813,DS-b4a887fd-098f-4f7c-a313-bef932c3927b,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-c4b0f0f8-d7aa-4646-864f-6e1a89e6396e,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-2d916a8e-71c2-416c-8484-4706f740bc67,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-8e3c83d5-9805-418d-b464-81d6f1f5624a,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-b4fd72c4-fbc7-4765-887a-8c6b7daf7ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-06d1805e-64b4-4873-8983-e61c109b106d,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-d2af1911-4cf7-4857-a980-89a4889784a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-e567cd67-5c5c-44e4-8392-f966a8fd7d14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1629380663-172.17.0.16-1595472538091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37813,DS-b4a887fd-098f-4f7c-a313-bef932c3927b,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-c4b0f0f8-d7aa-4646-864f-6e1a89e6396e,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-2d916a8e-71c2-416c-8484-4706f740bc67,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-8e3c83d5-9805-418d-b464-81d6f1f5624a,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-b4fd72c4-fbc7-4765-887a-8c6b7daf7ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-06d1805e-64b4-4873-8983-e61c109b106d,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-d2af1911-4cf7-4857-a980-89a4889784a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-e567cd67-5c5c-44e4-8392-f966a8fd7d14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1639558023-172.17.0.16-1595472764458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34461,DS-87b5ac1f-60c1-40a1-b2d8-25b884bcd00c,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-23af395c-6cfc-4f73-a874-b769d3d10e04,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-f6590222-67a4-4fce-9d03-7b41352b75d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40475,DS-0c9d12a8-334c-43bc-8e56-19912a8840bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-41bf80bb-04da-4d22-804b-8ff57e91cce6,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-0fb9f5b1-84eb-4e61-b2e5-650a47e3eb12,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-1cd4c061-1ef5-49bf-a895-a2bd578f4ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-51dc7b48-b2dd-4909-90e0-78b6b168449d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1639558023-172.17.0.16-1595472764458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34461,DS-87b5ac1f-60c1-40a1-b2d8-25b884bcd00c,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-23af395c-6cfc-4f73-a874-b769d3d10e04,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-f6590222-67a4-4fce-9d03-7b41352b75d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40475,DS-0c9d12a8-334c-43bc-8e56-19912a8840bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-41bf80bb-04da-4d22-804b-8ff57e91cce6,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-0fb9f5b1-84eb-4e61-b2e5-650a47e3eb12,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-1cd4c061-1ef5-49bf-a895-a2bd578f4ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-51dc7b48-b2dd-4909-90e0-78b6b168449d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851764769-172.17.0.16-1595472910326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44183,DS-b339dfc2-9549-4813-b795-3114e3d4ec80,DISK], DatanodeInfoWithStorage[127.0.0.1:45998,DS-3e9bf217-915a-4b0f-a3d3-aa67f8fc0045,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-70d5d702-a8fc-447d-a7e4-0be6827ec26d,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-101ad430-8c29-48e4-908e-285253731d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-b5b120a4-bfe7-4200-94e2-40755a10acb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-9dcbb52d-fbcd-40b4-80c7-8c4281bb4eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-9aac087e-7748-43b0-8b5d-07b1db90f859,DISK], DatanodeInfoWithStorage[127.0.0.1:41585,DS-aa564389-eb57-4f56-9363-c6acfbcaeae8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851764769-172.17.0.16-1595472910326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44183,DS-b339dfc2-9549-4813-b795-3114e3d4ec80,DISK], DatanodeInfoWithStorage[127.0.0.1:45998,DS-3e9bf217-915a-4b0f-a3d3-aa67f8fc0045,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-70d5d702-a8fc-447d-a7e4-0be6827ec26d,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-101ad430-8c29-48e4-908e-285253731d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-b5b120a4-bfe7-4200-94e2-40755a10acb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-9dcbb52d-fbcd-40b4-80c7-8c4281bb4eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-9aac087e-7748-43b0-8b5d-07b1db90f859,DISK], DatanodeInfoWithStorage[127.0.0.1:41585,DS-aa564389-eb57-4f56-9363-c6acfbcaeae8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1038207308-172.17.0.16-1595472992067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35227,DS-816907e9-e15b-4504-98b1-b0055847a650,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-803ecab0-77e6-4956-a545-14c4d4eedeb0,DISK], DatanodeInfoWithStorage[127.0.0.1:39340,DS-28ad2b95-705c-4411-8ee8-19e7b81fa06f,DISK], DatanodeInfoWithStorage[127.0.0.1:41410,DS-cb10dfba-4db5-4c47-af03-bb80c40b3177,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-8efaab2c-5883-49bb-98f4-c1f0df50857b,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-3025bfa3-a264-41be-8d25-1ec96b478318,DISK], DatanodeInfoWithStorage[127.0.0.1:43986,DS-3b7b8ab7-7a03-426a-b67f-816bebc6b0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-cffe8b49-79f3-4a6a-bb79-8d30047d4f5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1038207308-172.17.0.16-1595472992067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35227,DS-816907e9-e15b-4504-98b1-b0055847a650,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-803ecab0-77e6-4956-a545-14c4d4eedeb0,DISK], DatanodeInfoWithStorage[127.0.0.1:39340,DS-28ad2b95-705c-4411-8ee8-19e7b81fa06f,DISK], DatanodeInfoWithStorage[127.0.0.1:41410,DS-cb10dfba-4db5-4c47-af03-bb80c40b3177,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-8efaab2c-5883-49bb-98f4-c1f0df50857b,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-3025bfa3-a264-41be-8d25-1ec96b478318,DISK], DatanodeInfoWithStorage[127.0.0.1:43986,DS-3b7b8ab7-7a03-426a-b67f-816bebc6b0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-cffe8b49-79f3-4a6a-bb79-8d30047d4f5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1043074285-172.17.0.16-1595473068711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44321,DS-bc481254-e311-49da-8bc3-a788ce50f1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-7863ab2b-1beb-4ab8-b2b1-52401fbc223f,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-48e6ed88-1850-4fda-a66a-8bb88316cb97,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-b239b0f2-94e1-4df1-bf50-8abfcbde2603,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-460304af-e204-4e29-a067-38881f625393,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-bc578ab7-5446-459a-b4bb-0a0e00b155c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-d96d30e4-f86a-4d6d-a0ab-cea73c318c11,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-f88c5b1b-6e88-469d-a797-4410868f9a74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1043074285-172.17.0.16-1595473068711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44321,DS-bc481254-e311-49da-8bc3-a788ce50f1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-7863ab2b-1beb-4ab8-b2b1-52401fbc223f,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-48e6ed88-1850-4fda-a66a-8bb88316cb97,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-b239b0f2-94e1-4df1-bf50-8abfcbde2603,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-460304af-e204-4e29-a067-38881f625393,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-bc578ab7-5446-459a-b4bb-0a0e00b155c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-d96d30e4-f86a-4d6d-a0ab-cea73c318c11,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-f88c5b1b-6e88-469d-a797-4410868f9a74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-896265845-172.17.0.16-1595473261234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45941,DS-24a4aa6d-8dbe-41ae-83ff-ecc4a0ba5ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-dccb7d6e-a4dd-40bb-b822-730783e4ea44,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-48b60249-fe11-4928-a546-5a45a1864aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-edb68e84-8927-4b42-957e-3f4bb84e6965,DISK], DatanodeInfoWithStorage[127.0.0.1:36787,DS-523d725b-543a-4be0-941b-6016a86c59e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43986,DS-c8c57de2-ba60-49b5-9645-bdcc9937eaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:41861,DS-e7422714-73f7-4e34-a914-df6718ba7726,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-866046d1-1377-4225-9e72-0af5b051b169,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-896265845-172.17.0.16-1595473261234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45941,DS-24a4aa6d-8dbe-41ae-83ff-ecc4a0ba5ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-dccb7d6e-a4dd-40bb-b822-730783e4ea44,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-48b60249-fe11-4928-a546-5a45a1864aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-edb68e84-8927-4b42-957e-3f4bb84e6965,DISK], DatanodeInfoWithStorage[127.0.0.1:36787,DS-523d725b-543a-4be0-941b-6016a86c59e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43986,DS-c8c57de2-ba60-49b5-9645-bdcc9937eaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:41861,DS-e7422714-73f7-4e34-a914-df6718ba7726,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-866046d1-1377-4225-9e72-0af5b051b169,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1299703960-172.17.0.16-1595473707829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33877,DS-915efd69-ef0c-4722-a3e9-1f4a62318a09,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-a0e40bd1-5c95-4153-9a06-d26b0e2c0267,DISK], DatanodeInfoWithStorage[127.0.0.1:38984,DS-9df85c0f-5a14-4623-a21d-c3ebdf47f0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-5935f90e-1e46-4bd0-bcca-3fe978c39928,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-77c3a34c-3fcb-400c-b436-3b9ef4eebed7,DISK], DatanodeInfoWithStorage[127.0.0.1:39278,DS-627c1f96-d54a-4b9b-a80d-2132f23811e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-ab4ba1c3-f915-4ec2-a4f6-3ab6f6abc05e,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-0bf71fd2-696d-422b-84de-7ac07aaa6f83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1299703960-172.17.0.16-1595473707829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33877,DS-915efd69-ef0c-4722-a3e9-1f4a62318a09,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-a0e40bd1-5c95-4153-9a06-d26b0e2c0267,DISK], DatanodeInfoWithStorage[127.0.0.1:38984,DS-9df85c0f-5a14-4623-a21d-c3ebdf47f0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-5935f90e-1e46-4bd0-bcca-3fe978c39928,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-77c3a34c-3fcb-400c-b436-3b9ef4eebed7,DISK], DatanodeInfoWithStorage[127.0.0.1:39278,DS-627c1f96-d54a-4b9b-a80d-2132f23811e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-ab4ba1c3-f915-4ec2-a4f6-3ab6f6abc05e,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-0bf71fd2-696d-422b-84de-7ac07aaa6f83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-853560054-172.17.0.16-1595473746080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37300,DS-1c9fba5c-a247-4623-b5d9-4cceca435ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-7ab69af4-0e75-4f98-8bfe-0f892b17effa,DISK], DatanodeInfoWithStorage[127.0.0.1:35429,DS-f8dc5030-0ebc-4423-8e93-be20403c476c,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-47f6ec72-9d4a-4c6d-b567-7ff0a8c77230,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-504d36a9-52ca-4a9d-affe-3b50c336efa2,DISK], DatanodeInfoWithStorage[127.0.0.1:35612,DS-8335bab3-8728-4021-bd19-bbed7772a0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-377d5aa0-00cf-4b99-9276-7fc5e4d71902,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-3947108e-efc3-41d4-989e-fbaf3d512498,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-853560054-172.17.0.16-1595473746080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37300,DS-1c9fba5c-a247-4623-b5d9-4cceca435ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-7ab69af4-0e75-4f98-8bfe-0f892b17effa,DISK], DatanodeInfoWithStorage[127.0.0.1:35429,DS-f8dc5030-0ebc-4423-8e93-be20403c476c,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-47f6ec72-9d4a-4c6d-b567-7ff0a8c77230,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-504d36a9-52ca-4a9d-affe-3b50c336efa2,DISK], DatanodeInfoWithStorage[127.0.0.1:35612,DS-8335bab3-8728-4021-bd19-bbed7772a0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-377d5aa0-00cf-4b99-9276-7fc5e4d71902,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-3947108e-efc3-41d4-989e-fbaf3d512498,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-351093347-172.17.0.16-1595473919668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37152,DS-ee8141cb-b905-47aa-b3d1-98e3dde4c79c,DISK], DatanodeInfoWithStorage[127.0.0.1:46030,DS-e506d196-81b0-44c8-a3a6-b8348079e2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-e001949d-f2b0-4b56-903a-50a0951065c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-02a6d301-0e9b-4a48-b699-7f7ca8fcece4,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-0896b4d5-1a20-4498-8f9b-99c62026b98a,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-19df3031-e430-4c6d-adc8-8dc57623092a,DISK], DatanodeInfoWithStorage[127.0.0.1:35750,DS-9e3bef9c-21e4-4b8d-a3aa-ba5f4c453340,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-f188e23f-1efc-4a9f-936a-1fbaa960de50,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-351093347-172.17.0.16-1595473919668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37152,DS-ee8141cb-b905-47aa-b3d1-98e3dde4c79c,DISK], DatanodeInfoWithStorage[127.0.0.1:46030,DS-e506d196-81b0-44c8-a3a6-b8348079e2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-e001949d-f2b0-4b56-903a-50a0951065c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-02a6d301-0e9b-4a48-b699-7f7ca8fcece4,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-0896b4d5-1a20-4498-8f9b-99c62026b98a,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-19df3031-e430-4c6d-adc8-8dc57623092a,DISK], DatanodeInfoWithStorage[127.0.0.1:35750,DS-9e3bef9c-21e4-4b8d-a3aa-ba5f4c453340,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-f188e23f-1efc-4a9f-936a-1fbaa960de50,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-219128422-172.17.0.16-1595474056934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40787,DS-aacba0b1-afd3-4daa-9637-585862f12726,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-7b63176c-4566-41c9-bf6f-16e992275b78,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-74902525-cf62-4d2f-a5cb-eae18ed30401,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-b9bd82eb-6e90-488d-abd4-ba787e207d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35624,DS-bc4524e8-ff74-49b6-82cd-608b8cef97ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45468,DS-411b2ff5-3428-4461-8ed3-8466564dfe4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-f8e0dec0-b54b-4a26-a42b-34b56a8aa0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-5c5263ac-13de-4e39-b17a-317f35e48d2f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-219128422-172.17.0.16-1595474056934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40787,DS-aacba0b1-afd3-4daa-9637-585862f12726,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-7b63176c-4566-41c9-bf6f-16e992275b78,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-74902525-cf62-4d2f-a5cb-eae18ed30401,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-b9bd82eb-6e90-488d-abd4-ba787e207d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35624,DS-bc4524e8-ff74-49b6-82cd-608b8cef97ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45468,DS-411b2ff5-3428-4461-8ed3-8466564dfe4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-f8e0dec0-b54b-4a26-a42b-34b56a8aa0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-5c5263ac-13de-4e39-b17a-317f35e48d2f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-107934262-172.17.0.16-1595474125712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46766,DS-683f1acb-2d6f-40e4-b6b9-e05af2b53341,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-18c7f678-9032-4434-86ff-502fa52f5e32,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-95ab2e67-e8ad-49a7-b7fa-e2d18ea4d2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34404,DS-1f8c3baf-fb4a-408f-9d96-f7ba58acef5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-cf4a6d52-4b2a-4057-9b57-b453428669dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-092d199f-8d85-4b61-baad-0046515671ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-c14e207c-1f26-4718-ba25-5382a19e83e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-16c94a8f-44cf-4da0-a613-71017c1c39d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-107934262-172.17.0.16-1595474125712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46766,DS-683f1acb-2d6f-40e4-b6b9-e05af2b53341,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-18c7f678-9032-4434-86ff-502fa52f5e32,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-95ab2e67-e8ad-49a7-b7fa-e2d18ea4d2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34404,DS-1f8c3baf-fb4a-408f-9d96-f7ba58acef5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-cf4a6d52-4b2a-4057-9b57-b453428669dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-092d199f-8d85-4b61-baad-0046515671ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-c14e207c-1f26-4718-ba25-5382a19e83e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-16c94a8f-44cf-4da0-a613-71017c1c39d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1359530681-172.17.0.16-1595474211572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39210,DS-9bcd1a09-06f1-4fdd-8e1c-08ea9fa0c93a,DISK], DatanodeInfoWithStorage[127.0.0.1:43760,DS-29c122ab-6627-43fa-9e53-828df84cbcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41635,DS-640e70b4-bc9e-4203-b1e7-26feb5800e48,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-3c6e66bf-9fc4-41f2-9a6d-60b03d440d87,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-9abea8b7-b8d9-4d76-84c6-2d3aa1b70113,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-7936f2ac-291a-42e4-b9d8-f2354558efb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-c02ed579-746d-46d7-8da0-15a3d0393321,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-34c7a3c4-4e12-4ced-bc94-af174a23635a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1359530681-172.17.0.16-1595474211572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39210,DS-9bcd1a09-06f1-4fdd-8e1c-08ea9fa0c93a,DISK], DatanodeInfoWithStorage[127.0.0.1:43760,DS-29c122ab-6627-43fa-9e53-828df84cbcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41635,DS-640e70b4-bc9e-4203-b1e7-26feb5800e48,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-3c6e66bf-9fc4-41f2-9a6d-60b03d440d87,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-9abea8b7-b8d9-4d76-84c6-2d3aa1b70113,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-7936f2ac-291a-42e4-b9d8-f2354558efb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-c02ed579-746d-46d7-8da0-15a3d0393321,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-34c7a3c4-4e12-4ced-bc94-af174a23635a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1253963047-172.17.0.16-1595474317979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36381,DS-6a31a28d-ba0f-4587-bfeb-78c838b5b2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-8a183763-edf0-4d57-bc2e-dae521658638,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-b3d202a9-3b78-4d95-8c18-a7a77d921159,DISK], DatanodeInfoWithStorage[127.0.0.1:37228,DS-36cf9c5a-eb59-4e65-895e-7874aa2ae9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-1a803238-4166-4d13-a1fc-3d357e050325,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-943a319a-e4d9-4a72-bd8f-11370d9880d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-b1defffa-f5e8-43ed-b144-27b89ef81f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34687,DS-2034ca72-8565-4816-a113-fe6ef8764ded,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1253963047-172.17.0.16-1595474317979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36381,DS-6a31a28d-ba0f-4587-bfeb-78c838b5b2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-8a183763-edf0-4d57-bc2e-dae521658638,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-b3d202a9-3b78-4d95-8c18-a7a77d921159,DISK], DatanodeInfoWithStorage[127.0.0.1:37228,DS-36cf9c5a-eb59-4e65-895e-7874aa2ae9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-1a803238-4166-4d13-a1fc-3d357e050325,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-943a319a-e4d9-4a72-bd8f-11370d9880d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-b1defffa-f5e8-43ed-b144-27b89ef81f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34687,DS-2034ca72-8565-4816-a113-fe6ef8764ded,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1883714578-172.17.0.16-1595474489040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45888,DS-a22ce3ca-7969-452a-897c-e88aa2c12f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-7f99f32d-bef3-468d-8685-085be0dac133,DISK], DatanodeInfoWithStorage[127.0.0.1:36400,DS-9dd2da51-2705-482f-89f9-18cbeca5f8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-56d1636c-42dc-4723-ba29-154450eebce4,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-479a772f-66f7-4efe-993f-e46b00b232f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-066131dd-bf00-4eda-96fd-9be92d98f488,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-b2d546cd-5c93-4bba-b1bd-b692f3dd76ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-2e2625a3-9664-4fb4-b79f-dc45ff49f91c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1883714578-172.17.0.16-1595474489040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45888,DS-a22ce3ca-7969-452a-897c-e88aa2c12f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-7f99f32d-bef3-468d-8685-085be0dac133,DISK], DatanodeInfoWithStorage[127.0.0.1:36400,DS-9dd2da51-2705-482f-89f9-18cbeca5f8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-56d1636c-42dc-4723-ba29-154450eebce4,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-479a772f-66f7-4efe-993f-e46b00b232f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-066131dd-bf00-4eda-96fd-9be92d98f488,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-b2d546cd-5c93-4bba-b1bd-b692f3dd76ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-2e2625a3-9664-4fb4-b79f-dc45ff49f91c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-186849079-172.17.0.16-1595474565382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34865,DS-03e07bfb-d6df-49e0-804c-3b620ba9eeb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42665,DS-31b5900a-b71c-4ebd-a8a5-7ac6d34ac09b,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-6917447a-b02a-4dd7-b184-f50fac190424,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-4ad6c269-ef9a-4bdd-8bed-dd68a63a9d27,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-afae5369-79ab-4f3a-987c-5cf0574b5560,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-8be01876-1d8f-4417-8009-48c8c6518c34,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-3caa0b79-fa6a-4c97-8251-6fc6802d4b07,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-8ae30437-b125-4d20-9435-74feeb2e1907,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-186849079-172.17.0.16-1595474565382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34865,DS-03e07bfb-d6df-49e0-804c-3b620ba9eeb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42665,DS-31b5900a-b71c-4ebd-a8a5-7ac6d34ac09b,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-6917447a-b02a-4dd7-b184-f50fac190424,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-4ad6c269-ef9a-4bdd-8bed-dd68a63a9d27,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-afae5369-79ab-4f3a-987c-5cf0574b5560,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-8be01876-1d8f-4417-8009-48c8c6518c34,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-3caa0b79-fa6a-4c97-8251-6fc6802d4b07,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-8ae30437-b125-4d20-9435-74feeb2e1907,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-706703923-172.17.0.16-1595474789965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39739,DS-37dac816-6549-485c-8a46-5ce6caf69a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-687438f5-fdc9-43c1-bc82-b3b8d0812b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-b522ec94-d93c-41ad-b8ce-85f1a5b1b41a,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-2f6ced1e-06d5-4465-ad25-2ac6bf6620cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-a3df7a27-74b7-4395-9b65-7d8f939eb405,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-11041440-c4a2-457b-864e-4859b715f179,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-24a74a1f-11c8-4008-b45a-798b6c908a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-64280e74-8d74-4221-8f54-3bf29a19efc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-706703923-172.17.0.16-1595474789965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39739,DS-37dac816-6549-485c-8a46-5ce6caf69a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-687438f5-fdc9-43c1-bc82-b3b8d0812b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-b522ec94-d93c-41ad-b8ce-85f1a5b1b41a,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-2f6ced1e-06d5-4465-ad25-2ac6bf6620cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-a3df7a27-74b7-4395-9b65-7d8f939eb405,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-11041440-c4a2-457b-864e-4859b715f179,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-24a74a1f-11c8-4008-b45a-798b6c908a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-64280e74-8d74-4221-8f54-3bf29a19efc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-399098511-172.17.0.16-1595474868370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44088,DS-aa1d1ed2-358b-4068-b3d1-93a0302414f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-febefcf7-e7e1-445b-8791-c4ed546662b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-bd51fb4b-a833-4fcb-8e86-501948aa06b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-5e816ad6-f16c-4edd-8d75-2a3bb4b56fea,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-df6a53c2-ceda-44d0-852e-32116efc1820,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-e1078a52-148e-44fc-8140-e2f71426a784,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-e6914a88-10e3-4bce-b31b-3e09ca163a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-2e7b30aa-ae76-4ed2-b31f-de6a1c63252f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-399098511-172.17.0.16-1595474868370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44088,DS-aa1d1ed2-358b-4068-b3d1-93a0302414f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-febefcf7-e7e1-445b-8791-c4ed546662b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-bd51fb4b-a833-4fcb-8e86-501948aa06b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-5e816ad6-f16c-4edd-8d75-2a3bb4b56fea,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-df6a53c2-ceda-44d0-852e-32116efc1820,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-e1078a52-148e-44fc-8140-e2f71426a784,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-e6914a88-10e3-4bce-b31b-3e09ca163a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-2e7b30aa-ae76-4ed2-b31f-de6a1c63252f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2008661084-172.17.0.16-1595474946970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46508,DS-f7bb0d63-8193-4c8a-9911-3c87280b8d40,DISK], DatanodeInfoWithStorage[127.0.0.1:36082,DS-95cdbbf0-6129-4d46-be3b-7c74432fec06,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-e6354a84-1084-41ae-9c67-b919ae30b70f,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-6525dfbf-c64f-46eb-adba-1e49e0d97e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-d8420c74-5001-4c32-aa90-206cbf422cda,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-50414e60-18eb-42bd-b37a-7fac9f140c46,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-0a65c126-aba4-4b0c-9007-1630c5040ced,DISK], DatanodeInfoWithStorage[127.0.0.1:35121,DS-492ad943-fd54-4eeb-b644-a6b63eff5c64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2008661084-172.17.0.16-1595474946970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46508,DS-f7bb0d63-8193-4c8a-9911-3c87280b8d40,DISK], DatanodeInfoWithStorage[127.0.0.1:36082,DS-95cdbbf0-6129-4d46-be3b-7c74432fec06,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-e6354a84-1084-41ae-9c67-b919ae30b70f,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-6525dfbf-c64f-46eb-adba-1e49e0d97e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-d8420c74-5001-4c32-aa90-206cbf422cda,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-50414e60-18eb-42bd-b37a-7fac9f140c46,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-0a65c126-aba4-4b0c-9007-1630c5040ced,DISK], DatanodeInfoWithStorage[127.0.0.1:35121,DS-492ad943-fd54-4eeb-b644-a6b63eff5c64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1963464269-172.17.0.16-1595474988184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43348,DS-fcf0b601-84e5-40b6-a39e-26932ef43efa,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-0e3b8f58-7ad5-4f1c-93a4-4d77b9efe9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42215,DS-319f90bd-7f94-4874-b2c7-0efbb84be944,DISK], DatanodeInfoWithStorage[127.0.0.1:42433,DS-e706022e-816e-44db-9fc7-3e7c3c81342e,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-dc809dc0-12db-4477-8d4c-6615192aba44,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-39fcac66-e621-460d-8736-26b4aff9df7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-553722ae-b3e2-461e-afbb-3d777ce58fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-39cc7b5d-d37e-4d3c-9a04-72ad3a247d59,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1963464269-172.17.0.16-1595474988184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43348,DS-fcf0b601-84e5-40b6-a39e-26932ef43efa,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-0e3b8f58-7ad5-4f1c-93a4-4d77b9efe9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42215,DS-319f90bd-7f94-4874-b2c7-0efbb84be944,DISK], DatanodeInfoWithStorage[127.0.0.1:42433,DS-e706022e-816e-44db-9fc7-3e7c3c81342e,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-dc809dc0-12db-4477-8d4c-6615192aba44,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-39fcac66-e621-460d-8736-26b4aff9df7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-553722ae-b3e2-461e-afbb-3d777ce58fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-39cc7b5d-d37e-4d3c-9a04-72ad3a247d59,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130093969-172.17.0.16-1595475231633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46008,DS-4e852187-0ae4-447d-9347-185f15c5d001,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-268ba092-9ab6-405e-8a2d-3cbaac9e3bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-efb3b316-a1ef-4358-a7a3-3fb3b1ec3898,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-cfa26b76-8ccd-405f-aaa3-a68fb932beb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-729c45f3-e582-4345-94e1-1ba0122c6be0,DISK], DatanodeInfoWithStorage[127.0.0.1:41440,DS-b71f79a3-20af-4cea-853a-6f5d14173409,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-4a7282ff-ce70-48fe-a6f3-f13c74c46aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-2b02b289-e74c-4135-b3f2-cf9bfb1b61d8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130093969-172.17.0.16-1595475231633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46008,DS-4e852187-0ae4-447d-9347-185f15c5d001,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-268ba092-9ab6-405e-8a2d-3cbaac9e3bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-efb3b316-a1ef-4358-a7a3-3fb3b1ec3898,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-cfa26b76-8ccd-405f-aaa3-a68fb932beb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-729c45f3-e582-4345-94e1-1ba0122c6be0,DISK], DatanodeInfoWithStorage[127.0.0.1:41440,DS-b71f79a3-20af-4cea-853a-6f5d14173409,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-4a7282ff-ce70-48fe-a6f3-f13c74c46aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-2b02b289-e74c-4135-b3f2-cf9bfb1b61d8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-971359814-172.17.0.16-1595475439656:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45902,DS-325a7eb0-d399-416e-a0be-987939e99597,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-8cf01e87-4ac0-4241-8e0e-4950f6da7873,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-830e4d5d-a974-42f2-9168-161911f973e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-5424b909-db3a-49ad-bf25-84e03723a475,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-2536a052-96d2-4dbd-918b-d455d6b9a10f,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-30e98000-5203-4214-b014-3f2f7cc47049,DISK], DatanodeInfoWithStorage[127.0.0.1:41036,DS-23a72857-d2c1-4a03-a5b4-cd3ef88ae6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-5b0f2885-c6a1-4f5e-9e6f-0f595a166e66,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-971359814-172.17.0.16-1595475439656:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45902,DS-325a7eb0-d399-416e-a0be-987939e99597,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-8cf01e87-4ac0-4241-8e0e-4950f6da7873,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-830e4d5d-a974-42f2-9168-161911f973e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-5424b909-db3a-49ad-bf25-84e03723a475,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-2536a052-96d2-4dbd-918b-d455d6b9a10f,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-30e98000-5203-4214-b014-3f2f7cc47049,DISK], DatanodeInfoWithStorage[127.0.0.1:41036,DS-23a72857-d2c1-4a03-a5b4-cd3ef88ae6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-5b0f2885-c6a1-4f5e-9e6f-0f595a166e66,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1492650392-172.17.0.16-1595475548327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36552,DS-27127ae8-e119-447a-9d2f-73601b340eab,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-4dc7d389-542a-49f5-8d30-dee19db727cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-d2e15436-5721-4f24-a89a-a203e8e74bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-5e765042-5b04-4dca-8d96-896e03aff6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-8c4b83e1-950e-42a1-b8ec-11610c6b2acb,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-a105ab91-c55a-4e41-afdc-b09c74ac1b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-2e455fda-a724-46f2-bc45-cf9d2c6a85f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42960,DS-1fa1fb0a-0320-470a-bc12-5e335e720eb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1492650392-172.17.0.16-1595475548327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36552,DS-27127ae8-e119-447a-9d2f-73601b340eab,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-4dc7d389-542a-49f5-8d30-dee19db727cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-d2e15436-5721-4f24-a89a-a203e8e74bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-5e765042-5b04-4dca-8d96-896e03aff6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-8c4b83e1-950e-42a1-b8ec-11610c6b2acb,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-a105ab91-c55a-4e41-afdc-b09c74ac1b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-2e455fda-a724-46f2-bc45-cf9d2c6a85f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42960,DS-1fa1fb0a-0320-470a-bc12-5e335e720eb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2041002033-172.17.0.16-1595475803461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40614,DS-4eccb220-7810-4bb8-b5d4-f6314ff4cfb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-9561f31e-2e35-42d6-a0d8-3b4dce599bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-013317e2-c5cb-4097-9bd4-fb27f190cead,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-fe43d442-b393-4032-adf8-dde3e14fcbab,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-7bb58d78-c6b9-4c4e-829e-49afbd28d9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-463b9d2c-fc55-42cc-928c-63364d68fcfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40560,DS-565759cf-2fa5-4d16-ad0f-5eb537db8d35,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-e90bbd1b-3796-4bcd-b7df-846631470738,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2041002033-172.17.0.16-1595475803461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40614,DS-4eccb220-7810-4bb8-b5d4-f6314ff4cfb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-9561f31e-2e35-42d6-a0d8-3b4dce599bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-013317e2-c5cb-4097-9bd4-fb27f190cead,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-fe43d442-b393-4032-adf8-dde3e14fcbab,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-7bb58d78-c6b9-4c4e-829e-49afbd28d9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-463b9d2c-fc55-42cc-928c-63364d68fcfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40560,DS-565759cf-2fa5-4d16-ad0f-5eb537db8d35,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-e90bbd1b-3796-4bcd-b7df-846631470738,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1932053792-172.17.0.16-1595476181959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44645,DS-1bdd9452-0ddb-4d21-bfe3-6d88d8a6438d,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-a6af1ae9-2c31-4a06-81ba-be714fb3a391,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-5edbc072-d1f0-46fb-b0fb-b25b7085a3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-f29c8e4e-412b-401e-86ac-4b48dc88dcdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37285,DS-ab0d2b43-8d32-4680-9e33-10e1ad703e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-44cf1aa0-12d8-422e-8bdd-e71ee582b381,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-83d5f9a7-8969-455c-8e28-9f271c71746b,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-1c437e58-49b9-4da1-a61f-18e46bae6a76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1932053792-172.17.0.16-1595476181959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44645,DS-1bdd9452-0ddb-4d21-bfe3-6d88d8a6438d,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-a6af1ae9-2c31-4a06-81ba-be714fb3a391,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-5edbc072-d1f0-46fb-b0fb-b25b7085a3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-f29c8e4e-412b-401e-86ac-4b48dc88dcdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37285,DS-ab0d2b43-8d32-4680-9e33-10e1ad703e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-44cf1aa0-12d8-422e-8bdd-e71ee582b381,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-83d5f9a7-8969-455c-8e28-9f271c71746b,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-1c437e58-49b9-4da1-a61f-18e46bae6a76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-566481030-172.17.0.16-1595476260244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45556,DS-ea830702-70de-48b5-ab8c-3e7637bb4802,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-f509f96f-7463-47a0-9efb-49eb541a312a,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-70fc2f43-4996-4aee-a459-f140110ab3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42568,DS-9ed3caf2-aba2-488e-b51d-d5a052c3d20b,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-b0ee9fbd-c830-4f05-8f10-cc4970fd065d,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-905ea885-ce67-43d3-bbcd-2e2836ecbefb,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-be0d6089-65dd-429a-93ab-762e42f0e8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-e23ad817-4ba6-4dff-9546-769c7efa8935,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-566481030-172.17.0.16-1595476260244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45556,DS-ea830702-70de-48b5-ab8c-3e7637bb4802,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-f509f96f-7463-47a0-9efb-49eb541a312a,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-70fc2f43-4996-4aee-a459-f140110ab3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42568,DS-9ed3caf2-aba2-488e-b51d-d5a052c3d20b,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-b0ee9fbd-c830-4f05-8f10-cc4970fd065d,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-905ea885-ce67-43d3-bbcd-2e2836ecbefb,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-be0d6089-65dd-429a-93ab-762e42f0e8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-e23ad817-4ba6-4dff-9546-769c7efa8935,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1394992820-172.17.0.16-1595476663836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45716,DS-07982097-daaa-454c-9bb6-ea733e20f2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45449,DS-48486c23-1b1e-4d91-ab22-420fbe694e46,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-6707beef-34c7-492d-ad80-c1f2f7f9cddc,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-5b97285a-362c-4deb-806c-c4e0a3958619,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-30ac3d62-0fd6-458b-8618-3ac05dd76ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-d9eeaf16-8ebf-4e14-b788-a76e8c68e7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45068,DS-4a6f63ec-a3d0-4a5c-8b62-79344dfb0215,DISK], DatanodeInfoWithStorage[127.0.0.1:34696,DS-90b57a95-8d8e-4e3e-bb52-2bfcdd1852ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1394992820-172.17.0.16-1595476663836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45716,DS-07982097-daaa-454c-9bb6-ea733e20f2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45449,DS-48486c23-1b1e-4d91-ab22-420fbe694e46,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-6707beef-34c7-492d-ad80-c1f2f7f9cddc,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-5b97285a-362c-4deb-806c-c4e0a3958619,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-30ac3d62-0fd6-458b-8618-3ac05dd76ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-d9eeaf16-8ebf-4e14-b788-a76e8c68e7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45068,DS-4a6f63ec-a3d0-4a5c-8b62-79344dfb0215,DISK], DatanodeInfoWithStorage[127.0.0.1:34696,DS-90b57a95-8d8e-4e3e-bb52-2bfcdd1852ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1564448484-172.17.0.16-1595476702005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42878,DS-3fb5fc29-8292-40fd-aced-750f43fa287e,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-f8178765-1930-493c-95e3-4cb483ec0784,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-67027dfc-a06a-4131-bbac-2e44edbb464c,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-a3bc815e-45ce-4a4f-84e4-619b35ed6374,DISK], DatanodeInfoWithStorage[127.0.0.1:35774,DS-22fcba1e-1cec-4491-ba62-55a85c61a215,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-ac58ca3e-70c5-47fd-9686-f5906f33d5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34538,DS-e70f18d3-6a72-4b56-a2d2-7e3834c6060e,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-715c851c-a118-4b6d-987a-14d98644a9f1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1564448484-172.17.0.16-1595476702005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42878,DS-3fb5fc29-8292-40fd-aced-750f43fa287e,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-f8178765-1930-493c-95e3-4cb483ec0784,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-67027dfc-a06a-4131-bbac-2e44edbb464c,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-a3bc815e-45ce-4a4f-84e4-619b35ed6374,DISK], DatanodeInfoWithStorage[127.0.0.1:35774,DS-22fcba1e-1cec-4491-ba62-55a85c61a215,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-ac58ca3e-70c5-47fd-9686-f5906f33d5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34538,DS-e70f18d3-6a72-4b56-a2d2-7e3834c6060e,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-715c851c-a118-4b6d-987a-14d98644a9f1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-485585900-172.17.0.16-1595476740209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41351,DS-576b28cf-5c99-40aa-98e9-462dd4fc8fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:34674,DS-0a1c0225-52ba-464a-ac68-96eab1dad516,DISK], DatanodeInfoWithStorage[127.0.0.1:46467,DS-9e50da57-9583-458e-b341-0b89092c8423,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-71f05613-dcfc-4940-b796-293dc95facdf,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-b1ff4b36-49a5-4d25-94cb-f875e3332d93,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-cf091ea7-0e9b-4d9c-839f-cc0a057996c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-837abf5b-82a9-49f2-a1ab-82a28158fa92,DISK], DatanodeInfoWithStorage[127.0.0.1:46477,DS-bf24ebe9-f112-4665-9efc-37b43d0042d9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-485585900-172.17.0.16-1595476740209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41351,DS-576b28cf-5c99-40aa-98e9-462dd4fc8fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:34674,DS-0a1c0225-52ba-464a-ac68-96eab1dad516,DISK], DatanodeInfoWithStorage[127.0.0.1:46467,DS-9e50da57-9583-458e-b341-0b89092c8423,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-71f05613-dcfc-4940-b796-293dc95facdf,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-b1ff4b36-49a5-4d25-94cb-f875e3332d93,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-cf091ea7-0e9b-4d9c-839f-cc0a057996c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-837abf5b-82a9-49f2-a1ab-82a28158fa92,DISK], DatanodeInfoWithStorage[127.0.0.1:46477,DS-bf24ebe9-f112-4665-9efc-37b43d0042d9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1350021816-172.17.0.16-1595476847551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35982,DS-ff7ea39b-b0b3-422f-b4b2-1249984d4aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-c076b6fe-4dd5-4afe-a3bc-75bcd252bd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-ae7e8c5e-73b0-4c7b-961c-4c699616f148,DISK], DatanodeInfoWithStorage[127.0.0.1:35845,DS-7f89c7e1-f4ba-4b1c-8069-8fa951cd7629,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-9e6a483c-d2ce-445a-9bee-fa09f268b3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-b63714ea-df6f-4a19-9886-108e2e9248bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-ef2e7b1c-4acf-4352-9b3e-b7111f7ab167,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-9cea8f86-e959-4514-95ef-884cdcfaea35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1350021816-172.17.0.16-1595476847551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35982,DS-ff7ea39b-b0b3-422f-b4b2-1249984d4aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-c076b6fe-4dd5-4afe-a3bc-75bcd252bd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-ae7e8c5e-73b0-4c7b-961c-4c699616f148,DISK], DatanodeInfoWithStorage[127.0.0.1:35845,DS-7f89c7e1-f4ba-4b1c-8069-8fa951cd7629,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-9e6a483c-d2ce-445a-9bee-fa09f268b3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-b63714ea-df6f-4a19-9886-108e2e9248bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-ef2e7b1c-4acf-4352-9b3e-b7111f7ab167,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-9cea8f86-e959-4514-95ef-884cdcfaea35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-167635292-172.17.0.16-1595477096665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35227,DS-48076425-940f-4e52-8721-d6fbb5078e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-8ce1af2a-e0d6-4c64-bc90-ef4f59fca39d,DISK], DatanodeInfoWithStorage[127.0.0.1:34439,DS-6875d008-4945-4ea3-a2e1-1c4ff7f30bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:33546,DS-94556846-e1fb-496c-a5fb-88a3c77123ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-32666757-9f14-4107-88cd-c77d6f40b28c,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-3f20ff1b-a5e5-4395-b349-0df474d631b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-16c47936-6c21-4014-b113-b48b5c1063b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-723db171-9cc5-4ae2-a204-9ead182e3d2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-167635292-172.17.0.16-1595477096665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35227,DS-48076425-940f-4e52-8721-d6fbb5078e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-8ce1af2a-e0d6-4c64-bc90-ef4f59fca39d,DISK], DatanodeInfoWithStorage[127.0.0.1:34439,DS-6875d008-4945-4ea3-a2e1-1c4ff7f30bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:33546,DS-94556846-e1fb-496c-a5fb-88a3c77123ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-32666757-9f14-4107-88cd-c77d6f40b28c,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-3f20ff1b-a5e5-4395-b349-0df474d631b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-16c47936-6c21-4014-b113-b48b5c1063b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-723db171-9cc5-4ae2-a204-9ead182e3d2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1306004295-172.17.0.16-1595477334938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37489,DS-0ce8eb77-b965-4f34-8889-72d9bd357d20,DISK], DatanodeInfoWithStorage[127.0.0.1:40259,DS-4699d374-58e1-48c1-b869-2d5087c57463,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-d995368c-ea7e-4b8b-89f2-482da1404e45,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-f9db4447-c5a6-46b9-9757-3467db625a28,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-d79aa190-eb46-4ff2-b045-8edf9d81c7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-dc3e668d-2ece-48e5-8e46-ceed38cb0a80,DISK], DatanodeInfoWithStorage[127.0.0.1:36311,DS-58e494e7-0ade-4034-b055-7fcb22ce7bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-c6c81057-b214-4e61-ac7d-9be9fcc48703,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1306004295-172.17.0.16-1595477334938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37489,DS-0ce8eb77-b965-4f34-8889-72d9bd357d20,DISK], DatanodeInfoWithStorage[127.0.0.1:40259,DS-4699d374-58e1-48c1-b869-2d5087c57463,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-d995368c-ea7e-4b8b-89f2-482da1404e45,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-f9db4447-c5a6-46b9-9757-3467db625a28,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-d79aa190-eb46-4ff2-b045-8edf9d81c7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-dc3e668d-2ece-48e5-8e46-ceed38cb0a80,DISK], DatanodeInfoWithStorage[127.0.0.1:36311,DS-58e494e7-0ade-4034-b055-7fcb22ce7bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-c6c81057-b214-4e61-ac7d-9be9fcc48703,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1318949310-172.17.0.16-1595477505062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42280,DS-7ccb7b16-c707-47b5-b06e-d7edee4cb8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-fd2bf914-6c74-4813-bf32-0afcfa7eff9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-5778cefe-a4ec-43c4-a8ff-cb5959670e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-2fd63cf2-5687-4a13-92be-aa1d3194ddab,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-76ea6c11-8e5e-48aa-a309-66d815b11d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-12ab120f-40c7-4107-b708-91a1d974329e,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-23eb46cb-1314-426f-8cb0-4c58e8577ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-8f75d2f3-b174-4a36-96d4-593e6738a4dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1318949310-172.17.0.16-1595477505062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42280,DS-7ccb7b16-c707-47b5-b06e-d7edee4cb8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-fd2bf914-6c74-4813-bf32-0afcfa7eff9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-5778cefe-a4ec-43c4-a8ff-cb5959670e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-2fd63cf2-5687-4a13-92be-aa1d3194ddab,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-76ea6c11-8e5e-48aa-a309-66d815b11d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-12ab120f-40c7-4107-b708-91a1d974329e,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-23eb46cb-1314-426f-8cb0-4c58e8577ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-8f75d2f3-b174-4a36-96d4-593e6738a4dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1205742799-172.17.0.16-1595477741142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35398,DS-7c5488a3-cf92-4db0-8f40-a101ce56b0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-c6796ca0-7e57-4d44-8632-680245f0dfb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40564,DS-ed3d59d2-31e3-4802-86dc-f113987cf0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-33614b0c-8877-42f4-980a-93a5f84637f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-b981135f-42ee-45ac-9689-5598d3c37dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-fb0c6709-134c-4011-9e95-5ce18bebbe83,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-2baad1e9-76c2-4c7e-85d1-80dd3823f01c,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-e8dce180-0c1c-48ca-ba8b-9636ecf9a050,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1205742799-172.17.0.16-1595477741142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35398,DS-7c5488a3-cf92-4db0-8f40-a101ce56b0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-c6796ca0-7e57-4d44-8632-680245f0dfb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40564,DS-ed3d59d2-31e3-4802-86dc-f113987cf0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-33614b0c-8877-42f4-980a-93a5f84637f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-b981135f-42ee-45ac-9689-5598d3c37dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-fb0c6709-134c-4011-9e95-5ce18bebbe83,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-2baad1e9-76c2-4c7e-85d1-80dd3823f01c,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-e8dce180-0c1c-48ca-ba8b-9636ecf9a050,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-481231529-172.17.0.16-1595477775741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40251,DS-867cd122-09d9-4481-a08e-4b719093bf9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-a6faa572-b45d-4a5a-9cfd-0e4e15063a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-5831056a-07c2-46f1-b06d-df75f9e00ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-caf22876-ba26-4525-9d03-f6d02720f221,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-78656374-014d-45da-bed6-e47ac6b274d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-cec0273b-3e5d-4529-936b-ff6a3f6d1170,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-a8a0dcc0-35de-4b06-9eba-e893aa6563da,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-8fee1950-94bd-4d0c-ad66-9e913ae93865,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-481231529-172.17.0.16-1595477775741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40251,DS-867cd122-09d9-4481-a08e-4b719093bf9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-a6faa572-b45d-4a5a-9cfd-0e4e15063a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-5831056a-07c2-46f1-b06d-df75f9e00ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-caf22876-ba26-4525-9d03-f6d02720f221,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-78656374-014d-45da-bed6-e47ac6b274d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-cec0273b-3e5d-4529-936b-ff6a3f6d1170,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-a8a0dcc0-35de-4b06-9eba-e893aa6563da,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-8fee1950-94bd-4d0c-ad66-9e913ae93865,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 20 out of 50
result: false positive !!!
Total execution time in seconds : 5457
