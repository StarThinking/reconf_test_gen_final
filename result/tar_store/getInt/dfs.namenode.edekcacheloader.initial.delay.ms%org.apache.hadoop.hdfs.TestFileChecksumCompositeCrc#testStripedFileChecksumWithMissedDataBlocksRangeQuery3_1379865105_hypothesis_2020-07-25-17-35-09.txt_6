reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2145305654-172.17.0.2-1595698566575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39420,DS-ac817842-c7fe-4cb1-93e9-07ea98591edd,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-6ed3f682-7519-4ae0-80b2-f4dceee62bde,DISK], DatanodeInfoWithStorage[127.0.0.1:43257,DS-dd52be2f-9ff6-4380-acb0-ef602839fc05,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-d2090262-f543-4b85-b3b1-eabfe5135cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42364,DS-e14fab77-2028-4205-a04f-6188ae330348,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-f0038b9d-7fa8-4766-9cfa-700b7f2e267d,DISK], DatanodeInfoWithStorage[127.0.0.1:44226,DS-8c89487a-07d0-42b8-973d-ead98e4e7c20,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-9255ecf9-4cb0-4b4d-81c4-09c9b4b51ab2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2145305654-172.17.0.2-1595698566575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39420,DS-ac817842-c7fe-4cb1-93e9-07ea98591edd,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-6ed3f682-7519-4ae0-80b2-f4dceee62bde,DISK], DatanodeInfoWithStorage[127.0.0.1:43257,DS-dd52be2f-9ff6-4380-acb0-ef602839fc05,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-d2090262-f543-4b85-b3b1-eabfe5135cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42364,DS-e14fab77-2028-4205-a04f-6188ae330348,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-f0038b9d-7fa8-4766-9cfa-700b7f2e267d,DISK], DatanodeInfoWithStorage[127.0.0.1:44226,DS-8c89487a-07d0-42b8-973d-ead98e4e7c20,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-9255ecf9-4cb0-4b4d-81c4-09c9b4b51ab2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-213327827-172.17.0.2-1595698872097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36904,DS-218b9ac6-1fb2-4663-854d-23544ecd4bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-3790556b-6df4-4656-8217-23125a0b5f37,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-273c5927-6c78-451b-99b1-4523573a9cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-26e4c466-9db1-4d07-894f-8500b1c49a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-e50bf4ec-e2c1-4cae-b20e-e0e22fd7719c,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-b58c70ce-72bc-4910-94b0-7597c9fbc343,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-a3d1f994-1bf3-40b4-8524-bfa445dbeaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-df462390-ec92-49b2-854b-9ba65abaefd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-213327827-172.17.0.2-1595698872097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36904,DS-218b9ac6-1fb2-4663-854d-23544ecd4bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-3790556b-6df4-4656-8217-23125a0b5f37,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-273c5927-6c78-451b-99b1-4523573a9cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-26e4c466-9db1-4d07-894f-8500b1c49a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-e50bf4ec-e2c1-4cae-b20e-e0e22fd7719c,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-b58c70ce-72bc-4910-94b0-7597c9fbc343,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-a3d1f994-1bf3-40b4-8524-bfa445dbeaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-df462390-ec92-49b2-854b-9ba65abaefd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1545643367-172.17.0.2-1595699466304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46445,DS-2d78fba9-731a-489e-a454-87d0965de9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46849,DS-789e9261-b247-4ae3-abff-8da77ca1d5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-369a254e-3c51-4076-9d2f-15e204eb8975,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-e736ad8f-08a5-48ca-95fe-e529d3bb5175,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-5d318191-15c0-4164-8848-5101fb402dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-d7072475-b1eb-4472-9a78-8e9b3ea05d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39209,DS-716354a3-3a9d-41db-b2ac-a588562c9348,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-a726c017-6154-4c90-8611-7471f944089b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1545643367-172.17.0.2-1595699466304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46445,DS-2d78fba9-731a-489e-a454-87d0965de9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46849,DS-789e9261-b247-4ae3-abff-8da77ca1d5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-369a254e-3c51-4076-9d2f-15e204eb8975,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-e736ad8f-08a5-48ca-95fe-e529d3bb5175,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-5d318191-15c0-4164-8848-5101fb402dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-d7072475-b1eb-4472-9a78-8e9b3ea05d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39209,DS-716354a3-3a9d-41db-b2ac-a588562c9348,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-a726c017-6154-4c90-8611-7471f944089b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1636251417-172.17.0.2-1595699655031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34710,DS-26ccb9c6-abc0-48d4-83a4-5f4d5c8c47dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-1eefe99d-2d67-4df5-9060-7303b2878e57,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-435e9937-7e7a-4e89-8e01-c7750dd4410a,DISK], DatanodeInfoWithStorage[127.0.0.1:33624,DS-c97f41a8-08fa-4000-90d8-6955e1b9dd15,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-295160bc-e944-423a-afe4-9ee3e1f4734d,DISK], DatanodeInfoWithStorage[127.0.0.1:38554,DS-688779fd-4292-4575-b906-d0588d034665,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-e9805751-1a6f-4c37-b247-bdc70c40925a,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-9ef56458-73c1-4f8f-b26a-9a700afc0ec0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1636251417-172.17.0.2-1595699655031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34710,DS-26ccb9c6-abc0-48d4-83a4-5f4d5c8c47dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-1eefe99d-2d67-4df5-9060-7303b2878e57,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-435e9937-7e7a-4e89-8e01-c7750dd4410a,DISK], DatanodeInfoWithStorage[127.0.0.1:33624,DS-c97f41a8-08fa-4000-90d8-6955e1b9dd15,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-295160bc-e944-423a-afe4-9ee3e1f4734d,DISK], DatanodeInfoWithStorage[127.0.0.1:38554,DS-688779fd-4292-4575-b906-d0588d034665,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-e9805751-1a6f-4c37-b247-bdc70c40925a,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-9ef56458-73c1-4f8f-b26a-9a700afc0ec0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-120910448-172.17.0.2-1595700044225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41046,DS-5adc0c8f-ea2c-4268-abf9-f38671f568cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-9140b6f4-1854-4548-929d-73f6ccceadb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-30a1e1a3-c555-4527-8766-9dc02bd8200c,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-799ba1cd-0b5e-43ec-bafd-1a1995fa2f60,DISK], DatanodeInfoWithStorage[127.0.0.1:43125,DS-984fbace-7ea9-46ac-8aa3-20d759ae4a76,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-5fb84365-f67f-4f22-872f-44fee86503da,DISK], DatanodeInfoWithStorage[127.0.0.1:40602,DS-e7989a45-0dd5-4a16-8941-abc7e58699f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-91897d06-484c-4a3b-8a15-7e89dcb0cb05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-120910448-172.17.0.2-1595700044225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41046,DS-5adc0c8f-ea2c-4268-abf9-f38671f568cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-9140b6f4-1854-4548-929d-73f6ccceadb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-30a1e1a3-c555-4527-8766-9dc02bd8200c,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-799ba1cd-0b5e-43ec-bafd-1a1995fa2f60,DISK], DatanodeInfoWithStorage[127.0.0.1:43125,DS-984fbace-7ea9-46ac-8aa3-20d759ae4a76,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-5fb84365-f67f-4f22-872f-44fee86503da,DISK], DatanodeInfoWithStorage[127.0.0.1:40602,DS-e7989a45-0dd5-4a16-8941-abc7e58699f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-91897d06-484c-4a3b-8a15-7e89dcb0cb05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1902661804-172.17.0.2-1595700456788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40658,DS-fc935fe8-b7a7-4e5d-97f3-ecc592e4c5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-a664611e-de2b-47eb-8589-d64774c48c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-e7f80a60-7d81-402f-8921-d99f7f243a61,DISK], DatanodeInfoWithStorage[127.0.0.1:37296,DS-a9a57b79-e10e-41df-9049-8683afa84973,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-007f040d-72c3-4570-baba-4c80e65bb37e,DISK], DatanodeInfoWithStorage[127.0.0.1:37550,DS-a722c69d-b99b-4acf-b95a-3907bae37a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-2d3d71e7-4473-41f7-b623-c70427ba443a,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-6bef6ad9-0ab1-4553-a016-5abe2b8819ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1902661804-172.17.0.2-1595700456788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40658,DS-fc935fe8-b7a7-4e5d-97f3-ecc592e4c5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-a664611e-de2b-47eb-8589-d64774c48c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-e7f80a60-7d81-402f-8921-d99f7f243a61,DISK], DatanodeInfoWithStorage[127.0.0.1:37296,DS-a9a57b79-e10e-41df-9049-8683afa84973,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-007f040d-72c3-4570-baba-4c80e65bb37e,DISK], DatanodeInfoWithStorage[127.0.0.1:37550,DS-a722c69d-b99b-4acf-b95a-3907bae37a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-2d3d71e7-4473-41f7-b623-c70427ba443a,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-6bef6ad9-0ab1-4553-a016-5abe2b8819ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-530235548-172.17.0.2-1595700722178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41372,DS-12ab3f02-69d9-4592-8684-ccbcc53e8d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-5004b92e-83f8-46b0-af29-31ebe343dc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43173,DS-cae5a011-1f4f-444f-aabf-23e9cccfbd74,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-131f2718-f601-4b67-8608-6ab76980eb20,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-31b786ef-6971-4f77-a345-71f6b1979a76,DISK], DatanodeInfoWithStorage[127.0.0.1:37321,DS-dcc37840-32d1-4e28-80fd-6924a48e9752,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-fa90d331-5f11-4c7e-99ce-a4f61d7ad418,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-62c70a01-e09b-42be-83ed-be06a48d225a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-530235548-172.17.0.2-1595700722178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41372,DS-12ab3f02-69d9-4592-8684-ccbcc53e8d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-5004b92e-83f8-46b0-af29-31ebe343dc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43173,DS-cae5a011-1f4f-444f-aabf-23e9cccfbd74,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-131f2718-f601-4b67-8608-6ab76980eb20,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-31b786ef-6971-4f77-a345-71f6b1979a76,DISK], DatanodeInfoWithStorage[127.0.0.1:37321,DS-dcc37840-32d1-4e28-80fd-6924a48e9752,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-fa90d331-5f11-4c7e-99ce-a4f61d7ad418,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-62c70a01-e09b-42be-83ed-be06a48d225a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1573280390-172.17.0.2-1595701444947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42633,DS-7ba45a70-4269-4206-9888-90a73c27b179,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-9599dc2a-da4e-4196-9862-e2172e07e598,DISK], DatanodeInfoWithStorage[127.0.0.1:36222,DS-a1ad3811-da41-4eab-89ec-41c7805a272a,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-62a7057e-627c-45e1-9c77-46564bc0645b,DISK], DatanodeInfoWithStorage[127.0.0.1:35912,DS-31c206e0-3b23-4fc1-910a-8ee95099eae4,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-fe40f4a4-6dee-4a2a-b16c-cbdb81a4a363,DISK], DatanodeInfoWithStorage[127.0.0.1:39847,DS-1702be5b-8dbe-4a1c-85a1-84d5d2e6cd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-b2d47c21-e989-4fd1-ae9a-bcba23a5c337,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1573280390-172.17.0.2-1595701444947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42633,DS-7ba45a70-4269-4206-9888-90a73c27b179,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-9599dc2a-da4e-4196-9862-e2172e07e598,DISK], DatanodeInfoWithStorage[127.0.0.1:36222,DS-a1ad3811-da41-4eab-89ec-41c7805a272a,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-62a7057e-627c-45e1-9c77-46564bc0645b,DISK], DatanodeInfoWithStorage[127.0.0.1:35912,DS-31c206e0-3b23-4fc1-910a-8ee95099eae4,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-fe40f4a4-6dee-4a2a-b16c-cbdb81a4a363,DISK], DatanodeInfoWithStorage[127.0.0.1:39847,DS-1702be5b-8dbe-4a1c-85a1-84d5d2e6cd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-b2d47c21-e989-4fd1-ae9a-bcba23a5c337,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905823883-172.17.0.2-1595701736008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41156,DS-104bb8cb-b93d-4da2-a853-3e824cfdf072,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-85257cfb-60e6-45ae-b524-303f1f779edc,DISK], DatanodeInfoWithStorage[127.0.0.1:40335,DS-62865313-3fa3-4514-b8a0-9f2e6b1d64fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41374,DS-771d179b-fece-4a7d-a3cf-0f53aa29ca20,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-70341a82-6cb5-4c68-91d6-c24e0cc761ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-1b292923-cc73-44da-9d3b-b9ae31caa6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-3892ace3-6dae-4209-865a-4b3c94df1909,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-0f603349-ac3b-45f7-96aa-bea11ac50786,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905823883-172.17.0.2-1595701736008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41156,DS-104bb8cb-b93d-4da2-a853-3e824cfdf072,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-85257cfb-60e6-45ae-b524-303f1f779edc,DISK], DatanodeInfoWithStorage[127.0.0.1:40335,DS-62865313-3fa3-4514-b8a0-9f2e6b1d64fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41374,DS-771d179b-fece-4a7d-a3cf-0f53aa29ca20,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-70341a82-6cb5-4c68-91d6-c24e0cc761ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-1b292923-cc73-44da-9d3b-b9ae31caa6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-3892ace3-6dae-4209-865a-4b3c94df1909,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-0f603349-ac3b-45f7-96aa-bea11ac50786,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1716865653-172.17.0.2-1595701811011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38172,DS-910ad657-b67b-429a-a5ca-c9aacbc988fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-d8125e91-43e5-4cff-9e00-4af089eec437,DISK], DatanodeInfoWithStorage[127.0.0.1:38130,DS-eb317bf8-4f01-450a-a747-e0e6b9dd1348,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-bdae5ebb-aaf7-43c3-81fc-63ec80f0aef8,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-708e6354-4e54-4156-882a-e21205bb0dea,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-bab6495c-0bae-447d-b3c6-a51594e3c08f,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-b388a2f3-9787-4498-807f-b161e49a3eea,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-7149e30e-aa05-452a-b530-13794c3d7cdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1716865653-172.17.0.2-1595701811011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38172,DS-910ad657-b67b-429a-a5ca-c9aacbc988fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-d8125e91-43e5-4cff-9e00-4af089eec437,DISK], DatanodeInfoWithStorage[127.0.0.1:38130,DS-eb317bf8-4f01-450a-a747-e0e6b9dd1348,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-bdae5ebb-aaf7-43c3-81fc-63ec80f0aef8,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-708e6354-4e54-4156-882a-e21205bb0dea,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-bab6495c-0bae-447d-b3c6-a51594e3c08f,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-b388a2f3-9787-4498-807f-b161e49a3eea,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-7149e30e-aa05-452a-b530-13794c3d7cdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-656560443-172.17.0.2-1595702513941:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44462,DS-50804aac-feb9-4db1-be03-1041c11a8df1,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-b46c61a2-f9c3-4732-bb93-4dccabf5f6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-a760a21a-bc60-4905-a82f-5b81423dd41d,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-93922b75-802d-49aa-b32c-f6544d373363,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-c4a9029a-16c5-47a3-aeaa-03e41317613c,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-eca5856e-502f-4ddd-aff9-6c86952bf7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-40ca7a46-c5f5-4151-a598-d274e44327cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-175d000a-92eb-44af-9e7a-b7cb2549122e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-656560443-172.17.0.2-1595702513941:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44462,DS-50804aac-feb9-4db1-be03-1041c11a8df1,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-b46c61a2-f9c3-4732-bb93-4dccabf5f6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-a760a21a-bc60-4905-a82f-5b81423dd41d,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-93922b75-802d-49aa-b32c-f6544d373363,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-c4a9029a-16c5-47a3-aeaa-03e41317613c,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-eca5856e-502f-4ddd-aff9-6c86952bf7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-40ca7a46-c5f5-4151-a598-d274e44327cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-175d000a-92eb-44af-9e7a-b7cb2549122e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-611752684-172.17.0.2-1595702900218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43680,DS-1bef057c-8510-4e6f-95bd-419d60ff3447,DISK], DatanodeInfoWithStorage[127.0.0.1:37775,DS-90b1f4e7-83fa-4be2-b1eb-c556448c7664,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-ab72d9cf-432c-4746-9705-5792b938debc,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-40928d5a-3c29-4196-8e91-544bfc65e429,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-aad856f0-a3ad-418f-bba2-c2c9d988832a,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-098746a6-1672-46f2-9d1e-92a9b457ea22,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-78b60b18-cfae-4aac-8ddd-19bb794fc12b,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-0f81b705-10d6-4a27-8ff7-39009b218ad8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-611752684-172.17.0.2-1595702900218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43680,DS-1bef057c-8510-4e6f-95bd-419d60ff3447,DISK], DatanodeInfoWithStorage[127.0.0.1:37775,DS-90b1f4e7-83fa-4be2-b1eb-c556448c7664,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-ab72d9cf-432c-4746-9705-5792b938debc,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-40928d5a-3c29-4196-8e91-544bfc65e429,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-aad856f0-a3ad-418f-bba2-c2c9d988832a,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-098746a6-1672-46f2-9d1e-92a9b457ea22,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-78b60b18-cfae-4aac-8ddd-19bb794fc12b,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-0f81b705-10d6-4a27-8ff7-39009b218ad8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1486130139-172.17.0.2-1595703151376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38101,DS-d65a0f41-1640-44e6-911e-a61d83a2678b,DISK], DatanodeInfoWithStorage[127.0.0.1:43410,DS-59da5880-a739-4a1e-9d67-a52c4a2bbb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-5c5fec7f-fba8-4c4a-974a-e8974ad22c59,DISK], DatanodeInfoWithStorage[127.0.0.1:39677,DS-711d5b5f-e528-48c9-8ba3-6428b99793e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43613,DS-3179b492-a73b-4f61-8aab-3126f97b25f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-04b083ee-c2c6-48a5-ab58-599b304f47b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38483,DS-7f86a3aa-e703-44fa-a985-448270bcbb38,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-58456ac4-2be0-4684-8e72-8f130105f9f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1486130139-172.17.0.2-1595703151376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38101,DS-d65a0f41-1640-44e6-911e-a61d83a2678b,DISK], DatanodeInfoWithStorage[127.0.0.1:43410,DS-59da5880-a739-4a1e-9d67-a52c4a2bbb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-5c5fec7f-fba8-4c4a-974a-e8974ad22c59,DISK], DatanodeInfoWithStorage[127.0.0.1:39677,DS-711d5b5f-e528-48c9-8ba3-6428b99793e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43613,DS-3179b492-a73b-4f61-8aab-3126f97b25f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-04b083ee-c2c6-48a5-ab58-599b304f47b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38483,DS-7f86a3aa-e703-44fa-a985-448270bcbb38,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-58456ac4-2be0-4684-8e72-8f130105f9f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1937940051-172.17.0.2-1595703295290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45107,DS-f331d45b-929c-4ec6-804f-a4159ed6efa0,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-6c806c45-8bb7-4b7f-b732-85b02f0edc0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-e4dd5792-390f-4eee-8ccf-a4bfb188d18e,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-2d06552f-0d84-4911-ba3e-366f02ed1a83,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-5376e9fe-c40f-49ad-a23f-84c1b2d2f7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-7ccbe11d-ca76-4747-8e31-d0ab8bb050dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-4cc2fccd-64f4-4618-99de-61d884942336,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-a84e44ea-561d-4fe2-9730-7d35fdfb70ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1937940051-172.17.0.2-1595703295290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45107,DS-f331d45b-929c-4ec6-804f-a4159ed6efa0,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-6c806c45-8bb7-4b7f-b732-85b02f0edc0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-e4dd5792-390f-4eee-8ccf-a4bfb188d18e,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-2d06552f-0d84-4911-ba3e-366f02ed1a83,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-5376e9fe-c40f-49ad-a23f-84c1b2d2f7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-7ccbe11d-ca76-4747-8e31-d0ab8bb050dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-4cc2fccd-64f4-4618-99de-61d884942336,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-a84e44ea-561d-4fe2-9730-7d35fdfb70ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-552195729-172.17.0.2-1595703330416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41844,DS-ef19d6f5-c96e-4d3a-acf8-ec1637e71667,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-8563ce7e-b214-441d-af04-579a51556348,DISK], DatanodeInfoWithStorage[127.0.0.1:40873,DS-22d8133b-c60d-4ee1-9264-454316d973d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-8e02b30a-a981-48ee-92d6-d2b3ea647ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:43355,DS-4a0d9f07-69af-4c8d-9ab7-4a8475e6a082,DISK], DatanodeInfoWithStorage[127.0.0.1:45833,DS-d39ddf33-2976-4877-8f26-d51a924967bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37759,DS-02f3a5ad-8097-4dde-8a5d-5f5c9af6459a,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-84338fe7-f9e3-4b9f-bca3-a0ec45870705,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-552195729-172.17.0.2-1595703330416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41844,DS-ef19d6f5-c96e-4d3a-acf8-ec1637e71667,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-8563ce7e-b214-441d-af04-579a51556348,DISK], DatanodeInfoWithStorage[127.0.0.1:40873,DS-22d8133b-c60d-4ee1-9264-454316d973d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-8e02b30a-a981-48ee-92d6-d2b3ea647ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:43355,DS-4a0d9f07-69af-4c8d-9ab7-4a8475e6a082,DISK], DatanodeInfoWithStorage[127.0.0.1:45833,DS-d39ddf33-2976-4877-8f26-d51a924967bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37759,DS-02f3a5ad-8097-4dde-8a5d-5f5c9af6459a,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-84338fe7-f9e3-4b9f-bca3-a0ec45870705,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1038723918-172.17.0.2-1595703398392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42853,DS-46c02c62-ddde-4b78-8660-10f1f1272edf,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-c23e93f7-a467-4154-af05-fb91536e201a,DISK], DatanodeInfoWithStorage[127.0.0.1:38900,DS-d7ce73b9-224d-46d5-a85d-c13f9ad6f34b,DISK], DatanodeInfoWithStorage[127.0.0.1:42736,DS-ecc3afb1-840e-43e7-956c-9269383d464a,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-a061bc93-d2a7-44f6-ba1a-ba19e8339d61,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-f5796200-b111-479a-b72c-a57f4ee8487e,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-1cb818dc-9f6c-4c29-8567-5c02e932a207,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-24891978-11f2-49a8-bde9-3513b8f7e1e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1038723918-172.17.0.2-1595703398392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42853,DS-46c02c62-ddde-4b78-8660-10f1f1272edf,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-c23e93f7-a467-4154-af05-fb91536e201a,DISK], DatanodeInfoWithStorage[127.0.0.1:38900,DS-d7ce73b9-224d-46d5-a85d-c13f9ad6f34b,DISK], DatanodeInfoWithStorage[127.0.0.1:42736,DS-ecc3afb1-840e-43e7-956c-9269383d464a,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-a061bc93-d2a7-44f6-ba1a-ba19e8339d61,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-f5796200-b111-479a-b72c-a57f4ee8487e,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-1cb818dc-9f6c-4c29-8567-5c02e932a207,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-24891978-11f2-49a8-bde9-3513b8f7e1e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-216013507-172.17.0.2-1595703603399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34073,DS-519ec94a-3322-4ba8-8db1-ccf430b378a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-76037a91-2efd-4587-b9fa-ded2edf9e5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-1cc7bb1e-79b4-4210-8f00-50acb6961670,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-e1cffdc0-a2f2-4965-bf47-0d539c19191a,DISK], DatanodeInfoWithStorage[127.0.0.1:45688,DS-b54265ac-43d5-4bd2-b19c-3c30f3dd9cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-79a3bc7d-0b18-4d03-93c0-180f1062149a,DISK], DatanodeInfoWithStorage[127.0.0.1:42403,DS-98a0ccc1-d662-4d5b-aa56-de43ce308581,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-a3cac92d-e4e1-4de1-bf96-d81fdcaa6ee9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-216013507-172.17.0.2-1595703603399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34073,DS-519ec94a-3322-4ba8-8db1-ccf430b378a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-76037a91-2efd-4587-b9fa-ded2edf9e5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-1cc7bb1e-79b4-4210-8f00-50acb6961670,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-e1cffdc0-a2f2-4965-bf47-0d539c19191a,DISK], DatanodeInfoWithStorage[127.0.0.1:45688,DS-b54265ac-43d5-4bd2-b19c-3c30f3dd9cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-79a3bc7d-0b18-4d03-93c0-180f1062149a,DISK], DatanodeInfoWithStorage[127.0.0.1:42403,DS-98a0ccc1-d662-4d5b-aa56-de43ce308581,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-a3cac92d-e4e1-4de1-bf96-d81fdcaa6ee9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-174441471-172.17.0.2-1595703956872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38693,DS-1c2e3f02-b310-46ef-acd7-2ad5f7af6666,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-522f7d3e-ed38-47ef-bd36-4b9c597fdc54,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-52085de2-f339-4648-aca9-6b68ab5db680,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-2ec54f36-1903-40df-b4a3-6d49eb387c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-2183e48e-53d0-43ae-8676-d52bc5b1fba8,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-a2c65298-196f-4906-b450-f65f94f82b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-755434bc-882c-4482-bb38-af9a94fbc745,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-16da30d7-5fcf-4938-8a25-a5ce9dbdcd13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-174441471-172.17.0.2-1595703956872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38693,DS-1c2e3f02-b310-46ef-acd7-2ad5f7af6666,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-522f7d3e-ed38-47ef-bd36-4b9c597fdc54,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-52085de2-f339-4648-aca9-6b68ab5db680,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-2ec54f36-1903-40df-b4a3-6d49eb387c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-2183e48e-53d0-43ae-8676-d52bc5b1fba8,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-a2c65298-196f-4906-b450-f65f94f82b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-755434bc-882c-4482-bb38-af9a94fbc745,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-16da30d7-5fcf-4938-8a25-a5ce9dbdcd13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5468
