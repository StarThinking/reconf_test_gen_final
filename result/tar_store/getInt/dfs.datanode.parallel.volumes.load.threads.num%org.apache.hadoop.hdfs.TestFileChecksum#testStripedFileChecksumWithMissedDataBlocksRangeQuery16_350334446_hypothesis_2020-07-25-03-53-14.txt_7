reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1561438117-172.17.0.14-1595649929402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43562,DS-f174509c-2294-4b80-a900-e4065e8fbee2,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-9e69ef3c-7f56-4658-8489-f68fcf5f0fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40993,DS-ff330329-6aaf-4b12-aa06-f6d909d22952,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-ea24d582-beab-453b-a662-d156e093d6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-4af0cc6a-78d5-437b-aa92-92f88601fb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37440,DS-d11daa7d-d57c-444a-a70b-b007926f9df8,DISK], DatanodeInfoWithStorage[127.0.0.1:36559,DS-93ef24cb-85ad-4e02-a7e1-edc3a4779929,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-672c50c5-1542-4000-9afd-ef88c732efdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1561438117-172.17.0.14-1595649929402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43562,DS-f174509c-2294-4b80-a900-e4065e8fbee2,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-9e69ef3c-7f56-4658-8489-f68fcf5f0fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40993,DS-ff330329-6aaf-4b12-aa06-f6d909d22952,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-ea24d582-beab-453b-a662-d156e093d6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-4af0cc6a-78d5-437b-aa92-92f88601fb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37440,DS-d11daa7d-d57c-444a-a70b-b007926f9df8,DISK], DatanodeInfoWithStorage[127.0.0.1:36559,DS-93ef24cb-85ad-4e02-a7e1-edc3a4779929,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-672c50c5-1542-4000-9afd-ef88c732efdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1012799392-172.17.0.14-1595650127078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35804,DS-c596ecec-0ed5-43c0-bbe6-0bba77a5dbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-80514566-329c-43a7-ad01-aeac53be53f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36690,DS-3e107a9c-bb8b-45dd-bfc5-828d89d30bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-ab4fdcac-bce2-4e42-97ae-b3d7ecdbf640,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-1327b843-51f5-47ed-8581-01db9a48d60f,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-73eb534f-f7d7-4a20-a8b0-845c8b03c07a,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-9125a5b9-d6a9-4188-b3e0-c7278d489bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-0bf9d2be-3b67-458d-8f4b-1e1fe2cc683b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1012799392-172.17.0.14-1595650127078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35804,DS-c596ecec-0ed5-43c0-bbe6-0bba77a5dbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-80514566-329c-43a7-ad01-aeac53be53f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36690,DS-3e107a9c-bb8b-45dd-bfc5-828d89d30bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-ab4fdcac-bce2-4e42-97ae-b3d7ecdbf640,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-1327b843-51f5-47ed-8581-01db9a48d60f,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-73eb534f-f7d7-4a20-a8b0-845c8b03c07a,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-9125a5b9-d6a9-4188-b3e0-c7278d489bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-0bf9d2be-3b67-458d-8f4b-1e1fe2cc683b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2036861890-172.17.0.14-1595650331978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33182,DS-db641d1e-534f-4a95-9171-2d0563e41161,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-2e9d76b3-18bf-4bb1-bc5f-ef5006139e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33193,DS-ba9c7269-aeef-4b61-b391-b97c9aabb5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-12ae5a9f-cccc-4d60-b8d3-4b5b2ec417c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-5bfb1282-7f0e-483e-bf58-4c744c587d75,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-dfd95b9e-b0c7-4459-b377-5bc8f9dbbf72,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-51a6d6bb-6125-44db-8982-e18efb646565,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-5e1d072d-7565-4572-8f64-e6496fa8d498,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2036861890-172.17.0.14-1595650331978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33182,DS-db641d1e-534f-4a95-9171-2d0563e41161,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-2e9d76b3-18bf-4bb1-bc5f-ef5006139e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33193,DS-ba9c7269-aeef-4b61-b391-b97c9aabb5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-12ae5a9f-cccc-4d60-b8d3-4b5b2ec417c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-5bfb1282-7f0e-483e-bf58-4c744c587d75,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-dfd95b9e-b0c7-4459-b377-5bc8f9dbbf72,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-51a6d6bb-6125-44db-8982-e18efb646565,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-5e1d072d-7565-4572-8f64-e6496fa8d498,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-478576467-172.17.0.14-1595650366173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36526,DS-0d49d437-6591-4535-afc8-8923bf45ef02,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-10f37c85-b7c6-47c6-ab25-5e3fe9d16b26,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-91086944-7d4e-4ab4-a93b-44eb946952ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-02bd3fb4-bc84-4a77-8cf3-286bd5dbceb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41523,DS-70289ca3-be53-4950-bce4-d7c7f25d60ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-b8ff1303-c059-4537-838c-3dadfa27d29a,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-dde4dfd1-c02e-4c9b-a368-fa88bab88a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-55ab95bb-a10f-4363-85a4-be44119144ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-478576467-172.17.0.14-1595650366173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36526,DS-0d49d437-6591-4535-afc8-8923bf45ef02,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-10f37c85-b7c6-47c6-ab25-5e3fe9d16b26,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-91086944-7d4e-4ab4-a93b-44eb946952ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-02bd3fb4-bc84-4a77-8cf3-286bd5dbceb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41523,DS-70289ca3-be53-4950-bce4-d7c7f25d60ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-b8ff1303-c059-4537-838c-3dadfa27d29a,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-dde4dfd1-c02e-4c9b-a368-fa88bab88a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-55ab95bb-a10f-4363-85a4-be44119144ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-67639449-172.17.0.14-1595651436618:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40118,DS-c911818f-a83e-4bf2-a36b-8575409cbe8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33353,DS-adc73c0d-8013-4719-9118-f775793193e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-f8a157c7-3a32-462a-9602-366432a842b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-1c6d7f73-97c0-45ee-b5eb-ebc53cb05069,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-cf4ec11d-586d-40f7-8943-c07fb5cb9f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-e8c7377b-b414-44c4-98ed-456c4093df44,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-97cd1e1c-c57b-41d5-a24f-753a32ef4233,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-0dba60a4-bca5-4ea0-8b80-584cb552c60f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-67639449-172.17.0.14-1595651436618:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40118,DS-c911818f-a83e-4bf2-a36b-8575409cbe8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33353,DS-adc73c0d-8013-4719-9118-f775793193e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-f8a157c7-3a32-462a-9602-366432a842b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-1c6d7f73-97c0-45ee-b5eb-ebc53cb05069,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-cf4ec11d-586d-40f7-8943-c07fb5cb9f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-e8c7377b-b414-44c4-98ed-456c4093df44,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-97cd1e1c-c57b-41d5-a24f-753a32ef4233,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-0dba60a4-bca5-4ea0-8b80-584cb552c60f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1188751958-172.17.0.14-1595651472790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40375,DS-8f6cc6a6-da4c-46ba-86d1-6d2a835d3a28,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-15e55a61-1d3c-423d-836a-c9eb9391ad10,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-2b0016fb-0781-4f14-9ec2-de7ccbbe01c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-73406470-673b-4ab0-b687-15e15558daaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-5e456027-aa02-41e5-ac87-8fb37a919128,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-798b4812-4883-4423-b8fd-767e30dc3c65,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-a118559a-833b-4cd0-aec1-393284c72b33,DISK], DatanodeInfoWithStorage[127.0.0.1:39155,DS-1de961fb-51f7-4042-b977-32afe53a9591,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1188751958-172.17.0.14-1595651472790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40375,DS-8f6cc6a6-da4c-46ba-86d1-6d2a835d3a28,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-15e55a61-1d3c-423d-836a-c9eb9391ad10,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-2b0016fb-0781-4f14-9ec2-de7ccbbe01c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-73406470-673b-4ab0-b687-15e15558daaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-5e456027-aa02-41e5-ac87-8fb37a919128,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-798b4812-4883-4423-b8fd-767e30dc3c65,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-a118559a-833b-4cd0-aec1-393284c72b33,DISK], DatanodeInfoWithStorage[127.0.0.1:39155,DS-1de961fb-51f7-4042-b977-32afe53a9591,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2140857972-172.17.0.14-1595651509907:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38389,DS-fc3042e4-2c2b-4e6f-be11-e19e905b57ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-b8798486-69e7-4d4f-aedd-346b3b6c0287,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-b0568090-7120-4e7e-969c-0fddfa93c901,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-5682d109-c138-46c7-beb1-4f4074c398f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-0501a895-d165-4a5e-856d-a14a7b7ee662,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-cad0e6a4-f3bf-48b2-965e-63f6ae180bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-ceae71cf-3c61-4e57-9363-e3996e821336,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-4238e748-053c-4647-8368-18eed83621cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2140857972-172.17.0.14-1595651509907:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38389,DS-fc3042e4-2c2b-4e6f-be11-e19e905b57ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-b8798486-69e7-4d4f-aedd-346b3b6c0287,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-b0568090-7120-4e7e-969c-0fddfa93c901,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-5682d109-c138-46c7-beb1-4f4074c398f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-0501a895-d165-4a5e-856d-a14a7b7ee662,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-cad0e6a4-f3bf-48b2-965e-63f6ae180bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-ceae71cf-3c61-4e57-9363-e3996e821336,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-4238e748-053c-4647-8368-18eed83621cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-89541132-172.17.0.14-1595651731480:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35074,DS-be1b3422-04ea-4759-82b7-f6add7d29569,DISK], DatanodeInfoWithStorage[127.0.0.1:43231,DS-be721c1d-2bb0-45e9-a0a0-f47e519eed57,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-386fc8e0-5f42-4dc0-ac15-0ffb04b41c25,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-a51aaf8e-fa23-4cc5-aea4-19c5781ff7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-b2444481-33df-4c6c-ba7f-963b24ebb9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-9b6bfc84-918a-41bf-a953-35574c9cd873,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-6dc844cc-8dbb-4120-9b43-536152eabcee,DISK], DatanodeInfoWithStorage[127.0.0.1:42493,DS-46a24716-6662-4720-bc20-3ea1dff5ac09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-89541132-172.17.0.14-1595651731480:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35074,DS-be1b3422-04ea-4759-82b7-f6add7d29569,DISK], DatanodeInfoWithStorage[127.0.0.1:43231,DS-be721c1d-2bb0-45e9-a0a0-f47e519eed57,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-386fc8e0-5f42-4dc0-ac15-0ffb04b41c25,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-a51aaf8e-fa23-4cc5-aea4-19c5781ff7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-b2444481-33df-4c6c-ba7f-963b24ebb9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-9b6bfc84-918a-41bf-a953-35574c9cd873,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-6dc844cc-8dbb-4120-9b43-536152eabcee,DISK], DatanodeInfoWithStorage[127.0.0.1:42493,DS-46a24716-6662-4720-bc20-3ea1dff5ac09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1806781208-172.17.0.14-1595652253266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42646,DS-96d4f66f-07b0-4af0-841c-7c2b96d64d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33196,DS-a1c53696-380e-464d-85e3-9030f664529c,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-b6039138-b603-4e65-adaa-6b4ab5d32caa,DISK], DatanodeInfoWithStorage[127.0.0.1:35185,DS-e703d0fb-a9c7-44a4-86c0-e81d6019e1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-7a07a293-d49e-49dc-8398-062d936f47cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34657,DS-7df71fad-9fed-4735-b812-9602bf852d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33449,DS-db21e547-0caa-41f5-8779-1bd7ab0143b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-9502af7e-2311-4713-82dc-b27fd7c2eb57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1806781208-172.17.0.14-1595652253266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42646,DS-96d4f66f-07b0-4af0-841c-7c2b96d64d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33196,DS-a1c53696-380e-464d-85e3-9030f664529c,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-b6039138-b603-4e65-adaa-6b4ab5d32caa,DISK], DatanodeInfoWithStorage[127.0.0.1:35185,DS-e703d0fb-a9c7-44a4-86c0-e81d6019e1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-7a07a293-d49e-49dc-8398-062d936f47cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34657,DS-7df71fad-9fed-4735-b812-9602bf852d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33449,DS-db21e547-0caa-41f5-8779-1bd7ab0143b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-9502af7e-2311-4713-82dc-b27fd7c2eb57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-439730518-172.17.0.14-1595652284499:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38996,DS-196e8d23-fa80-4ee8-ade3-0a435baf5ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-a9739683-be9e-4ad5-8109-5972c6a09308,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-577ceea3-408d-44f5-96c6-d39c43c651df,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-75836457-54a4-4f30-8dbb-2a74fa44f740,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-ff2081bf-b039-4fc2-b81c-0af761d09bad,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-e6cb3f90-f4f8-4303-ab68-02011193fb37,DISK], DatanodeInfoWithStorage[127.0.0.1:45137,DS-6909059b-b333-41b0-b30d-677fe5c780b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-3ef88868-bca9-4236-81aa-4030ccac79ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-439730518-172.17.0.14-1595652284499:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38996,DS-196e8d23-fa80-4ee8-ade3-0a435baf5ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-a9739683-be9e-4ad5-8109-5972c6a09308,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-577ceea3-408d-44f5-96c6-d39c43c651df,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-75836457-54a4-4f30-8dbb-2a74fa44f740,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-ff2081bf-b039-4fc2-b81c-0af761d09bad,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-e6cb3f90-f4f8-4303-ab68-02011193fb37,DISK], DatanodeInfoWithStorage[127.0.0.1:45137,DS-6909059b-b333-41b0-b30d-677fe5c780b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-3ef88868-bca9-4236-81aa-4030ccac79ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-800915133-172.17.0.14-1595652826891:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46488,DS-32115b65-88a7-4c4e-b03a-6fd4ff2f6d97,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-7cf42114-6d85-442a-830a-42be3ab222b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-1dba86be-bca2-4d56-a310-b22fe6357338,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-4506e27d-84eb-4bc3-83f9-925f03b78203,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-e36317b1-5723-4e98-b7f2-dad313cfab02,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-1e0f0ece-9777-4a4a-8da2-b2674252aada,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-2166619e-dd57-4da6-bffb-c386dae4d61d,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-3c328a1a-00b5-47b4-88a4-397334d50905,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-800915133-172.17.0.14-1595652826891:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46488,DS-32115b65-88a7-4c4e-b03a-6fd4ff2f6d97,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-7cf42114-6d85-442a-830a-42be3ab222b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-1dba86be-bca2-4d56-a310-b22fe6357338,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-4506e27d-84eb-4bc3-83f9-925f03b78203,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-e36317b1-5723-4e98-b7f2-dad313cfab02,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-1e0f0ece-9777-4a4a-8da2-b2674252aada,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-2166619e-dd57-4da6-bffb-c386dae4d61d,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-3c328a1a-00b5-47b4-88a4-397334d50905,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-974088112-172.17.0.14-1595652965453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33374,DS-787c362d-dfaa-4b0f-904c-4c9f38c527db,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-270e39af-1ce3-459b-bdcd-e89a0efa4c25,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-0d4c9249-17e8-445d-ad6b-0ed64b3245e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-f62290d7-cc9c-47ca-99c6-c4a420a4cea3,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-697a77eb-9c59-44a0-abc6-b18c2eac4be9,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-e21e459c-4710-4355-ab23-8d9c78e298cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-505f3dee-99d9-4ccc-b54f-52e904ed1f27,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-2849468d-55ef-4fd2-a152-72d501b20fd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-974088112-172.17.0.14-1595652965453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33374,DS-787c362d-dfaa-4b0f-904c-4c9f38c527db,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-270e39af-1ce3-459b-bdcd-e89a0efa4c25,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-0d4c9249-17e8-445d-ad6b-0ed64b3245e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-f62290d7-cc9c-47ca-99c6-c4a420a4cea3,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-697a77eb-9c59-44a0-abc6-b18c2eac4be9,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-e21e459c-4710-4355-ab23-8d9c78e298cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-505f3dee-99d9-4ccc-b54f-52e904ed1f27,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-2849468d-55ef-4fd2-a152-72d501b20fd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-613451375-172.17.0.14-1595653000966:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44431,DS-dfc3d819-bd9a-4a50-8067-6050a4b0b7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-55a098bc-9cde-49f8-a552-addbb9a53183,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-12ceb978-5a19-4d64-b25d-33db33161463,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-60e2f4ac-0f66-4432-b456-7326a4148695,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-019c465f-4bca-446e-a55b-cecf45ec28e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-506712a8-f585-4d01-a73f-f015eefdecef,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-1559a3b5-9648-44d4-a030-741f9b497ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-a35da10d-3c3e-486c-9045-1beb56b785b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-613451375-172.17.0.14-1595653000966:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44431,DS-dfc3d819-bd9a-4a50-8067-6050a4b0b7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-55a098bc-9cde-49f8-a552-addbb9a53183,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-12ceb978-5a19-4d64-b25d-33db33161463,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-60e2f4ac-0f66-4432-b456-7326a4148695,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-019c465f-4bca-446e-a55b-cecf45ec28e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-506712a8-f585-4d01-a73f-f015eefdecef,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-1559a3b5-9648-44d4-a030-741f9b497ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-a35da10d-3c3e-486c-9045-1beb56b785b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2082346311-172.17.0.14-1595653133148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41618,DS-8556cc12-10f8-4150-b05d-b74247b600af,DISK], DatanodeInfoWithStorage[127.0.0.1:42127,DS-f3f454d1-958f-42a5-ba94-baaf7675aef4,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-061f7bb8-8707-494a-b435-fa5ceb986a22,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-2e67a55f-5c88-433c-968a-ac61787f62dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44372,DS-4dc722fa-8f7e-404d-a0af-21b53b66e5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34553,DS-3b66ae42-0b2d-46cd-b978-c6fdf54b88b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-390cb591-12c8-4995-b92e-ae884053ce03,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-06db2d47-439a-470a-b199-94850b5a4212,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2082346311-172.17.0.14-1595653133148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41618,DS-8556cc12-10f8-4150-b05d-b74247b600af,DISK], DatanodeInfoWithStorage[127.0.0.1:42127,DS-f3f454d1-958f-42a5-ba94-baaf7675aef4,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-061f7bb8-8707-494a-b435-fa5ceb986a22,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-2e67a55f-5c88-433c-968a-ac61787f62dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44372,DS-4dc722fa-8f7e-404d-a0af-21b53b66e5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34553,DS-3b66ae42-0b2d-46cd-b978-c6fdf54b88b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-390cb591-12c8-4995-b92e-ae884053ce03,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-06db2d47-439a-470a-b199-94850b5a4212,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1037230337-172.17.0.14-1595653435382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40582,DS-6ea30890-cf08-40da-90e3-d3be0c60ffcd,DISK], DatanodeInfoWithStorage[127.0.0.1:33998,DS-22a29987-1d1f-402d-bccc-842a3ae407cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39390,DS-1b2c5a60-005a-4b6c-b153-c25c39063dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36719,DS-89ad3a15-bfbd-4fd2-81b4-bf212bef024f,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-e63285a4-64ca-457e-82b4-99ee68d79665,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-48f295b3-83bf-4f7b-97a7-7e4ab8ba7ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-f29431dd-7b9d-4899-a9e3-d82dcbdcd527,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-d6254a22-4654-4151-b24a-cdddc4d77d47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1037230337-172.17.0.14-1595653435382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40582,DS-6ea30890-cf08-40da-90e3-d3be0c60ffcd,DISK], DatanodeInfoWithStorage[127.0.0.1:33998,DS-22a29987-1d1f-402d-bccc-842a3ae407cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39390,DS-1b2c5a60-005a-4b6c-b153-c25c39063dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36719,DS-89ad3a15-bfbd-4fd2-81b4-bf212bef024f,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-e63285a4-64ca-457e-82b4-99ee68d79665,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-48f295b3-83bf-4f7b-97a7-7e4ab8ba7ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-f29431dd-7b9d-4899-a9e3-d82dcbdcd527,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-d6254a22-4654-4151-b24a-cdddc4d77d47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1035695242-172.17.0.14-1595653749442:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36770,DS-a9e8e280-7e9a-4648-9910-c75245290640,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-5ec5f012-9d74-4c02-9e96-d194da83d4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-99600eb9-ca66-4867-b14a-9cd9a6beea62,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-db7d7a3a-6708-4b14-840e-a4d683ddab49,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-08257205-c4d7-46f4-858c-46ecdb686bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-9f25b69b-f33b-4505-a6e2-b53f835b200e,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-9410fb61-275a-49d8-83ff-5e7f06f06fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40072,DS-85c857a2-d22e-443c-8c2d-9ea2cf1a294f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1035695242-172.17.0.14-1595653749442:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36770,DS-a9e8e280-7e9a-4648-9910-c75245290640,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-5ec5f012-9d74-4c02-9e96-d194da83d4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-99600eb9-ca66-4867-b14a-9cd9a6beea62,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-db7d7a3a-6708-4b14-840e-a4d683ddab49,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-08257205-c4d7-46f4-858c-46ecdb686bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-9f25b69b-f33b-4505-a6e2-b53f835b200e,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-9410fb61-275a-49d8-83ff-5e7f06f06fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40072,DS-85c857a2-d22e-443c-8c2d-9ea2cf1a294f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-453746061-172.17.0.14-1595654024359:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36161,DS-6a035be9-1716-49f6-bebe-94e5cb489ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-65e1a5e8-6cbd-4bbb-b6df-f58b411357ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-4c3d43ec-3735-4ec8-87f3-3e09d444e59f,DISK], DatanodeInfoWithStorage[127.0.0.1:37744,DS-2f6b65f1-e693-487e-8b7a-81831fa46057,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-75fe819b-e99e-49c4-8951-3068eac904a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-cea1ed4e-86d9-4d6b-995e-ed9353e6cd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33288,DS-a3f990fa-61df-4b35-998f-563d27aebada,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-1a46561b-92f5-42be-a755-e132de82cf0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-453746061-172.17.0.14-1595654024359:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36161,DS-6a035be9-1716-49f6-bebe-94e5cb489ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-65e1a5e8-6cbd-4bbb-b6df-f58b411357ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-4c3d43ec-3735-4ec8-87f3-3e09d444e59f,DISK], DatanodeInfoWithStorage[127.0.0.1:37744,DS-2f6b65f1-e693-487e-8b7a-81831fa46057,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-75fe819b-e99e-49c4-8951-3068eac904a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-cea1ed4e-86d9-4d6b-995e-ed9353e6cd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33288,DS-a3f990fa-61df-4b35-998f-563d27aebada,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-1a46561b-92f5-42be-a755-e132de82cf0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5204
