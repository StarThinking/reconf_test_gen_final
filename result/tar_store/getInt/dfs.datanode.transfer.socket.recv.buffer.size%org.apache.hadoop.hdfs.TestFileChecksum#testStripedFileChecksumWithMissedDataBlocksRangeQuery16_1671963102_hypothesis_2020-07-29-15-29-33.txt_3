reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-585540377-172.17.0.17-1596037515580:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33869,DS-58cb306b-12d4-44fb-af44-78984ccb267c,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-eefb5085-d75e-4ef5-894a-190885adf2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-fa273f33-a984-4aeb-94f1-f2c3bd30bf4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-38c466a3-c075-4fb7-bdb7-77fd6215049f,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-14324715-81d9-4177-962d-e0b29f73b1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-a80a7617-e01e-4397-890e-2c85163e1de5,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-a3a47ff5-4155-4313-81c3-de6050708664,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-7e3aa166-a617-4bdb-8ce1-4e6b79457638,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-585540377-172.17.0.17-1596037515580:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33869,DS-58cb306b-12d4-44fb-af44-78984ccb267c,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-eefb5085-d75e-4ef5-894a-190885adf2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-fa273f33-a984-4aeb-94f1-f2c3bd30bf4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-38c466a3-c075-4fb7-bdb7-77fd6215049f,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-14324715-81d9-4177-962d-e0b29f73b1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-a80a7617-e01e-4397-890e-2c85163e1de5,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-a3a47ff5-4155-4313-81c3-de6050708664,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-7e3aa166-a617-4bdb-8ce1-4e6b79457638,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1597799236-172.17.0.17-1596037562404:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42466,DS-ab9e6059-278b-4eff-88fb-6847ecea49bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-05705f79-c3df-4316-8cf3-e73609cb6850,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-5829af00-207d-43e8-9462-6e7a9d384d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-21576e7d-cd0e-4a57-b3ab-0ec3f077b659,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-3ed7ee01-6a78-45ca-88ab-a672a528c99c,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-affb714d-c7f9-4b08-be87-e6c38b343f96,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-d2417a00-adbe-4c0e-abbc-b6bd87e1c181,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-c420bb9d-cf85-449f-8c43-72663c884e41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1597799236-172.17.0.17-1596037562404:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42466,DS-ab9e6059-278b-4eff-88fb-6847ecea49bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-05705f79-c3df-4316-8cf3-e73609cb6850,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-5829af00-207d-43e8-9462-6e7a9d384d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-21576e7d-cd0e-4a57-b3ab-0ec3f077b659,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-3ed7ee01-6a78-45ca-88ab-a672a528c99c,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-affb714d-c7f9-4b08-be87-e6c38b343f96,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-d2417a00-adbe-4c0e-abbc-b6bd87e1c181,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-c420bb9d-cf85-449f-8c43-72663c884e41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1184810030-172.17.0.17-1596037742422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46283,DS-3ffcfd0f-cfa9-4902-9bc1-90f5f70e7dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-6fdc062e-603c-4b67-a185-f392e5124260,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-27ce6f10-480d-4e8d-a68a-a5591dbc043a,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-f08a95bb-102d-4b42-bc6c-84227447092f,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-c1617c4c-9f0e-4cf6-a719-2db2f41cdb59,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-15b9c118-45b5-4ec6-a9a6-9b1326f21674,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-68b1e5ef-2795-41f3-b9f6-11f4dab5d452,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-b2480862-b695-42cc-a197-8664c4eff648,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1184810030-172.17.0.17-1596037742422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46283,DS-3ffcfd0f-cfa9-4902-9bc1-90f5f70e7dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-6fdc062e-603c-4b67-a185-f392e5124260,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-27ce6f10-480d-4e8d-a68a-a5591dbc043a,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-f08a95bb-102d-4b42-bc6c-84227447092f,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-c1617c4c-9f0e-4cf6-a719-2db2f41cdb59,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-15b9c118-45b5-4ec6-a9a6-9b1326f21674,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-68b1e5ef-2795-41f3-b9f6-11f4dab5d452,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-b2480862-b695-42cc-a197-8664c4eff648,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1832974637-172.17.0.17-1596038094493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34039,DS-73d9b9f8-944e-4788-bb6f-52c00a96a5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-e1c92721-5b44-420b-96b2-5bc8f7110113,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-f67ca5c8-e9ea-4ff7-8845-6ac9e25e8a32,DISK], DatanodeInfoWithStorage[127.0.0.1:39100,DS-1993f13d-5d12-41d4-862a-c3f3130c06bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42269,DS-4d75c1cc-f9b8-4f8d-99b8-1ed161495fff,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-302e417e-2b14-423f-b09d-4ce200be3ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-3c064dd5-6e98-4866-807b-973d3f347e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35362,DS-65319e9c-639e-43b5-9108-6fde83eca1ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1832974637-172.17.0.17-1596038094493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34039,DS-73d9b9f8-944e-4788-bb6f-52c00a96a5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-e1c92721-5b44-420b-96b2-5bc8f7110113,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-f67ca5c8-e9ea-4ff7-8845-6ac9e25e8a32,DISK], DatanodeInfoWithStorage[127.0.0.1:39100,DS-1993f13d-5d12-41d4-862a-c3f3130c06bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42269,DS-4d75c1cc-f9b8-4f8d-99b8-1ed161495fff,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-302e417e-2b14-423f-b09d-4ce200be3ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-3c064dd5-6e98-4866-807b-973d3f347e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35362,DS-65319e9c-639e-43b5-9108-6fde83eca1ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1511467764-172.17.0.17-1596038133879:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34906,DS-9f4c57e4-f618-422d-a352-f62a055a187f,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-bf4c411d-7c77-426c-aa22-52868d655c99,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-d070500c-8e43-4033-9b6b-6f9adabe0be3,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-1dff1d18-d657-4e36-9439-305c6544f771,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-ef15a8f1-fe6b-45a3-a9d0-5011feecedaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42508,DS-1f4a3902-3b76-47e8-8818-acdcbfafeed0,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-a8530652-4dba-412f-ac64-ff5ef03da12d,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-0a9a88c8-f70d-4880-ba47-807ebeff912e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1511467764-172.17.0.17-1596038133879:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34906,DS-9f4c57e4-f618-422d-a352-f62a055a187f,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-bf4c411d-7c77-426c-aa22-52868d655c99,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-d070500c-8e43-4033-9b6b-6f9adabe0be3,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-1dff1d18-d657-4e36-9439-305c6544f771,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-ef15a8f1-fe6b-45a3-a9d0-5011feecedaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42508,DS-1f4a3902-3b76-47e8-8818-acdcbfafeed0,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-a8530652-4dba-412f-ac64-ff5ef03da12d,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-0a9a88c8-f70d-4880-ba47-807ebeff912e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-836254032-172.17.0.17-1596038951072:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44353,DS-03413cfa-ee40-449d-927b-b6d89ccc9222,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-130d9919-1303-4946-ab4f-4359a1a28dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-de7cb564-62da-48e0-a615-def22a886a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-af16ffa5-bb21-4db5-927a-983ff1f49037,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-6183b59d-16bb-4181-943a-dc60208fd080,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-30968117-2d4c-4a51-af02-1034209214d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-2f35965f-44b5-4be7-81a8-925829901e38,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-1fd82ae1-ea21-410f-8ca0-8b0690cfb4e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-836254032-172.17.0.17-1596038951072:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44353,DS-03413cfa-ee40-449d-927b-b6d89ccc9222,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-130d9919-1303-4946-ab4f-4359a1a28dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-de7cb564-62da-48e0-a615-def22a886a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-af16ffa5-bb21-4db5-927a-983ff1f49037,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-6183b59d-16bb-4181-943a-dc60208fd080,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-30968117-2d4c-4a51-af02-1034209214d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-2f35965f-44b5-4be7-81a8-925829901e38,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-1fd82ae1-ea21-410f-8ca0-8b0690cfb4e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2123993999-172.17.0.17-1596039237732:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46227,DS-595823c5-49b9-4859-9aa5-8397d6bfbfff,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-46508b78-6920-4165-9711-ebccd80b9410,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-26608b28-e633-4d28-b50a-c4d03d9556c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-44a196b5-e3d5-46cf-892e-b66e08bc94c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-56a3d287-219f-495b-aa54-a982eadc769a,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-15173db0-5101-4334-b69c-8bd89305e405,DISK], DatanodeInfoWithStorage[127.0.0.1:41225,DS-4f6ae708-42b9-49b0-b95d-68557c3f0614,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-47f77fad-7d80-430e-becc-766f9ad670d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2123993999-172.17.0.17-1596039237732:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46227,DS-595823c5-49b9-4859-9aa5-8397d6bfbfff,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-46508b78-6920-4165-9711-ebccd80b9410,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-26608b28-e633-4d28-b50a-c4d03d9556c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-44a196b5-e3d5-46cf-892e-b66e08bc94c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-56a3d287-219f-495b-aa54-a982eadc769a,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-15173db0-5101-4334-b69c-8bd89305e405,DISK], DatanodeInfoWithStorage[127.0.0.1:41225,DS-4f6ae708-42b9-49b0-b95d-68557c3f0614,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-47f77fad-7d80-430e-becc-766f9ad670d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1995969358-172.17.0.17-1596040027502:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45504,DS-f001608a-2e55-4af8-90b6-fd2c6e2dcbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-d3ef35b3-dd24-4f42-96a1-90b143c5d54d,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-29ef0713-08f0-4837-963e-2e9e9a192668,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-9bd3fcbe-2275-490a-bd20-1ab75b089064,DISK], DatanodeInfoWithStorage[127.0.0.1:44820,DS-edf73fee-6966-43ce-80b5-c9899d284ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-ae2ba3b4-c533-4815-a288-cfeb46b172fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-983c55b8-5a24-4607-9ea9-bb0634b19021,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-c7e5311f-370a-4fa6-96b9-cffc790fcbbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1995969358-172.17.0.17-1596040027502:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45504,DS-f001608a-2e55-4af8-90b6-fd2c6e2dcbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-d3ef35b3-dd24-4f42-96a1-90b143c5d54d,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-29ef0713-08f0-4837-963e-2e9e9a192668,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-9bd3fcbe-2275-490a-bd20-1ab75b089064,DISK], DatanodeInfoWithStorage[127.0.0.1:44820,DS-edf73fee-6966-43ce-80b5-c9899d284ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-ae2ba3b4-c533-4815-a288-cfeb46b172fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-983c55b8-5a24-4607-9ea9-bb0634b19021,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-c7e5311f-370a-4fa6-96b9-cffc790fcbbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-214427256-172.17.0.17-1596040206688:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43454,DS-5e7f0923-7b55-4b9e-95df-be44afe20896,DISK], DatanodeInfoWithStorage[127.0.0.1:39659,DS-3b828601-f3b4-4130-92b2-28449369d44e,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-abb3ffaa-24c9-4edf-87ca-775d7577252d,DISK], DatanodeInfoWithStorage[127.0.0.1:38828,DS-de327c3a-7fe0-4891-be41-7c0c506ce66b,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-a856bbd4-1655-4ab6-9eb6-ecf08d5c4086,DISK], DatanodeInfoWithStorage[127.0.0.1:46234,DS-80161cbf-6e21-46df-9d84-a5c2835dedb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-25acebba-74f9-4f6c-9e6c-8128fa303f50,DISK], DatanodeInfoWithStorage[127.0.0.1:41009,DS-dfca348d-d374-468e-a4b3-b5d6f1c33966,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-214427256-172.17.0.17-1596040206688:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43454,DS-5e7f0923-7b55-4b9e-95df-be44afe20896,DISK], DatanodeInfoWithStorage[127.0.0.1:39659,DS-3b828601-f3b4-4130-92b2-28449369d44e,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-abb3ffaa-24c9-4edf-87ca-775d7577252d,DISK], DatanodeInfoWithStorage[127.0.0.1:38828,DS-de327c3a-7fe0-4891-be41-7c0c506ce66b,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-a856bbd4-1655-4ab6-9eb6-ecf08d5c4086,DISK], DatanodeInfoWithStorage[127.0.0.1:46234,DS-80161cbf-6e21-46df-9d84-a5c2835dedb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-25acebba-74f9-4f6c-9e6c-8128fa303f50,DISK], DatanodeInfoWithStorage[127.0.0.1:41009,DS-dfca348d-d374-468e-a4b3-b5d6f1c33966,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-62675082-172.17.0.17-1596040806916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33103,DS-2b9e93ca-2d69-4192-ab17-9f5f19a70a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-7381fac4-d0c9-4b48-a683-dddb758dcd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45624,DS-f114dd21-26bb-4f71-9cad-d8878563fe0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45871,DS-c189ff95-6fa3-4589-a75c-78f1b93e8972,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-f722d529-b3cc-4718-a353-5e985ed89120,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-cd585092-4d89-4a18-bd1f-9e2aaed434a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-d3946ee8-35f9-4451-9455-216f22f14dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-c7c7fdc2-913b-4094-9df1-310ab32eab51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-62675082-172.17.0.17-1596040806916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33103,DS-2b9e93ca-2d69-4192-ab17-9f5f19a70a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-7381fac4-d0c9-4b48-a683-dddb758dcd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45624,DS-f114dd21-26bb-4f71-9cad-d8878563fe0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45871,DS-c189ff95-6fa3-4589-a75c-78f1b93e8972,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-f722d529-b3cc-4718-a353-5e985ed89120,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-cd585092-4d89-4a18-bd1f-9e2aaed434a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-d3946ee8-35f9-4451-9455-216f22f14dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-c7c7fdc2-913b-4094-9df1-310ab32eab51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1526219066-172.17.0.17-1596041321254:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40406,DS-8849cd44-c747-478d-ac30-946dcc58b01a,DISK], DatanodeInfoWithStorage[127.0.0.1:43498,DS-baea7228-ede1-4b42-a19c-08a34056277e,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-16321e29-c907-49ca-af48-f0d6b89d255b,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-070b190d-1c3f-4f8c-befe-6ac4f080680a,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-20af17f6-33b8-4cb5-95b7-7c47e98fecb3,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-05dc5921-f660-4cfd-89d9-cf16e3feb930,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-79151d2b-c1e7-4e91-a197-1884b028bb64,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-d0cbf886-4def-47bb-9eec-75286a221026,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1526219066-172.17.0.17-1596041321254:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40406,DS-8849cd44-c747-478d-ac30-946dcc58b01a,DISK], DatanodeInfoWithStorage[127.0.0.1:43498,DS-baea7228-ede1-4b42-a19c-08a34056277e,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-16321e29-c907-49ca-af48-f0d6b89d255b,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-070b190d-1c3f-4f8c-befe-6ac4f080680a,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-20af17f6-33b8-4cb5-95b7-7c47e98fecb3,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-05dc5921-f660-4cfd-89d9-cf16e3feb930,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-79151d2b-c1e7-4e91-a197-1884b028bb64,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-d0cbf886-4def-47bb-9eec-75286a221026,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2083526188-172.17.0.17-1596041537595:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34951,DS-1777464a-53b7-498f-92be-4f5acea232f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-e936a37b-ebd4-4213-b2aa-7f0c35682ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-a506a1df-63bc-423e-848c-d4bd92cccea5,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-1747c311-efb6-4bd8-89fe-c6c994cf75b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-dd32f7f3-5bb0-4b84-83ca-3327d10a8baa,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-cf006b16-9c92-420d-adb5-15cbae18481a,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-1636f8fd-5059-45c2-b2ee-9f9d5b00b796,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-d87e8c83-158d-4b6f-aedc-3023446425d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2083526188-172.17.0.17-1596041537595:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34951,DS-1777464a-53b7-498f-92be-4f5acea232f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-e936a37b-ebd4-4213-b2aa-7f0c35682ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-a506a1df-63bc-423e-848c-d4bd92cccea5,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-1747c311-efb6-4bd8-89fe-c6c994cf75b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-dd32f7f3-5bb0-4b84-83ca-3327d10a8baa,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-cf006b16-9c92-420d-adb5-15cbae18481a,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-1636f8fd-5059-45c2-b2ee-9f9d5b00b796,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-d87e8c83-158d-4b6f-aedc-3023446425d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1674616227-172.17.0.17-1596042365017:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40068,DS-b2b05160-8389-4f48-815e-ed15f4fb6896,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-5154f116-7192-41ed-8f5c-91fb3b6c637b,DISK], DatanodeInfoWithStorage[127.0.0.1:43147,DS-de064c55-bdd9-4d0d-a31b-7a2ef62a8720,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-8e46da1a-e5a3-42dc-aa8c-3338fbb17be0,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-41aab165-cd6e-42b6-932c-5c068aeb1f35,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-48c58ace-8da8-4b9f-9fe3-b2f52ac65e64,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-b71b68e2-a2e9-4930-941e-983fe06935cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46308,DS-03497f7b-d868-47e3-8be3-f81d4d791e65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1674616227-172.17.0.17-1596042365017:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40068,DS-b2b05160-8389-4f48-815e-ed15f4fb6896,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-5154f116-7192-41ed-8f5c-91fb3b6c637b,DISK], DatanodeInfoWithStorage[127.0.0.1:43147,DS-de064c55-bdd9-4d0d-a31b-7a2ef62a8720,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-8e46da1a-e5a3-42dc-aa8c-3338fbb17be0,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-41aab165-cd6e-42b6-932c-5c068aeb1f35,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-48c58ace-8da8-4b9f-9fe3-b2f52ac65e64,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-b71b68e2-a2e9-4930-941e-983fe06935cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46308,DS-03497f7b-d868-47e3-8be3-f81d4d791e65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2010329763-172.17.0.17-1596043163188:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46108,DS-2a7b95c0-ae5c-45ec-9333-a47c6c0780da,DISK], DatanodeInfoWithStorage[127.0.0.1:41291,DS-c1affde3-1646-4b68-9f2c-b1dd95ad2c39,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-b754a9cf-68f1-4272-a985-2d49232ae959,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-30a17541-e3a9-4465-80a2-e905495151e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38182,DS-49a243b9-66ee-411b-9481-c10ab0ae6f62,DISK], DatanodeInfoWithStorage[127.0.0.1:44054,DS-eda35f82-1234-498a-a023-765985ceb5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-f8835aa2-c91e-432f-8018-2620fa1e1bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-b947cb39-fd96-4e02-a0ba-0a5f9d8b79dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2010329763-172.17.0.17-1596043163188:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46108,DS-2a7b95c0-ae5c-45ec-9333-a47c6c0780da,DISK], DatanodeInfoWithStorage[127.0.0.1:41291,DS-c1affde3-1646-4b68-9f2c-b1dd95ad2c39,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-b754a9cf-68f1-4272-a985-2d49232ae959,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-30a17541-e3a9-4465-80a2-e905495151e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38182,DS-49a243b9-66ee-411b-9481-c10ab0ae6f62,DISK], DatanodeInfoWithStorage[127.0.0.1:44054,DS-eda35f82-1234-498a-a023-765985ceb5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-f8835aa2-c91e-432f-8018-2620fa1e1bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-b947cb39-fd96-4e02-a0ba-0a5f9d8b79dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 6926
