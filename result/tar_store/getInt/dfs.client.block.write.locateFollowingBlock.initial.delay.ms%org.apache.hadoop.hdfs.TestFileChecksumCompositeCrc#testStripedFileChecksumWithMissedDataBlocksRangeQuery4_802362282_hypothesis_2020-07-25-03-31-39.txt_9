reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1676577995-172.17.0.18-1595648214916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42184,DS-659f4978-6ba7-4ef8-83f6-3ed7a0135632,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-b4cd2692-d338-462e-b822-f3d8db7f65a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-8a8ff7b6-38a0-4f71-a0dd-b7f3784d9e55,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-299f6857-3587-420b-99c7-713f3877dc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-427f123d-e857-4848-a846-dea6f819076a,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-62140830-5262-4685-81fa-ada3db316abe,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-73bc01ac-f0b5-4ca5-b797-46356ba6497d,DISK], DatanodeInfoWithStorage[127.0.0.1:40333,DS-a62766f9-fd2b-41e7-8732-813124ffc989,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1676577995-172.17.0.18-1595648214916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42184,DS-659f4978-6ba7-4ef8-83f6-3ed7a0135632,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-b4cd2692-d338-462e-b822-f3d8db7f65a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-8a8ff7b6-38a0-4f71-a0dd-b7f3784d9e55,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-299f6857-3587-420b-99c7-713f3877dc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-427f123d-e857-4848-a846-dea6f819076a,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-62140830-5262-4685-81fa-ada3db316abe,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-73bc01ac-f0b5-4ca5-b797-46356ba6497d,DISK], DatanodeInfoWithStorage[127.0.0.1:40333,DS-a62766f9-fd2b-41e7-8732-813124ffc989,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1461181179-172.17.0.18-1595648250254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39725,DS-b06074c7-4695-40c8-9452-17fcf0b36365,DISK], DatanodeInfoWithStorage[127.0.0.1:37675,DS-1cfced10-8228-46af-97bd-ab3e057762f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-46a65b79-6319-46b1-b680-9acc043c9bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-d875d3e3-bffd-4ba2-b35f-9d3e41aaf364,DISK], DatanodeInfoWithStorage[127.0.0.1:39118,DS-6daba85b-c6f2-4fa2-be40-28ef6c287480,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-6d5e0ca3-0574-4c29-9ee5-ba7c5fb34fce,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-8a862382-ac19-4136-b171-e55cebab9d90,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-8c1e0ec1-394f-44a9-998f-1eab2c94a2cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1461181179-172.17.0.18-1595648250254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39725,DS-b06074c7-4695-40c8-9452-17fcf0b36365,DISK], DatanodeInfoWithStorage[127.0.0.1:37675,DS-1cfced10-8228-46af-97bd-ab3e057762f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-46a65b79-6319-46b1-b680-9acc043c9bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-d875d3e3-bffd-4ba2-b35f-9d3e41aaf364,DISK], DatanodeInfoWithStorage[127.0.0.1:39118,DS-6daba85b-c6f2-4fa2-be40-28ef6c287480,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-6d5e0ca3-0574-4c29-9ee5-ba7c5fb34fce,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-8a862382-ac19-4136-b171-e55cebab9d90,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-8c1e0ec1-394f-44a9-998f-1eab2c94a2cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-542132790-172.17.0.18-1595648555535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33215,DS-be044893-1c81-43d7-80c4-73ca1cb6e4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-ca7a81be-d9cb-47da-931a-3e9313348f57,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-83117bc4-43b5-4752-808e-e17eb14c3d84,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-62a49863-229c-4fa6-951a-b9bad3a52a49,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-ac6dfbaf-45a6-478a-b918-905fefd8addc,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-5fbb90c9-e31d-4ac7-bb32-ee57d7550d02,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-e0a1628b-9248-4bbb-9370-5fed070db842,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-15b1fae8-9687-43c2-9039-f36075071ce3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-542132790-172.17.0.18-1595648555535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33215,DS-be044893-1c81-43d7-80c4-73ca1cb6e4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-ca7a81be-d9cb-47da-931a-3e9313348f57,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-83117bc4-43b5-4752-808e-e17eb14c3d84,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-62a49863-229c-4fa6-951a-b9bad3a52a49,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-ac6dfbaf-45a6-478a-b918-905fefd8addc,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-5fbb90c9-e31d-4ac7-bb32-ee57d7550d02,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-e0a1628b-9248-4bbb-9370-5fed070db842,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-15b1fae8-9687-43c2-9039-f36075071ce3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1486399246-172.17.0.18-1595649034169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41104,DS-bca85f67-e9f8-4d37-a89a-381af13bdfc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-b513fdde-ebaa-4292-903a-828978492b10,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-63406c95-4224-411d-84c7-a5324be3b6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:32972,DS-581be27c-66e1-4e53-8f11-eb4c57f37e02,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-190b7f41-ba73-43e8-b264-c1be4529325d,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-3c92a840-4bfa-4903-8205-99fce2ad4f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-14d1c51a-42d9-4f61-a320-80c7aa78c18e,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-49d348ec-4832-4f09-8cce-7dd19680e9ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1486399246-172.17.0.18-1595649034169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41104,DS-bca85f67-e9f8-4d37-a89a-381af13bdfc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-b513fdde-ebaa-4292-903a-828978492b10,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-63406c95-4224-411d-84c7-a5324be3b6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:32972,DS-581be27c-66e1-4e53-8f11-eb4c57f37e02,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-190b7f41-ba73-43e8-b264-c1be4529325d,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-3c92a840-4bfa-4903-8205-99fce2ad4f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-14d1c51a-42d9-4f61-a320-80c7aa78c18e,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-49d348ec-4832-4f09-8cce-7dd19680e9ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1046215200-172.17.0.18-1595649708453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34098,DS-0dbac602-d582-4d6e-94cb-a76d827f262c,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-7e042b93-dfef-4e77-a4f7-7610e96ae751,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-2a7fcd15-056c-4f7f-9db3-7fb5f00a506f,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-eaaf7ccc-aa77-4d29-a717-46617e7386ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-403a44e2-fcb5-42e2-b816-ce6004c98765,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-9ebe5129-ff7c-49db-af5f-1db8eaa075a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-5af67542-14c6-444b-ab15-0e7320a64a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-d79c1885-86a1-41b8-b390-c1fcc02dafe0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1046215200-172.17.0.18-1595649708453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34098,DS-0dbac602-d582-4d6e-94cb-a76d827f262c,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-7e042b93-dfef-4e77-a4f7-7610e96ae751,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-2a7fcd15-056c-4f7f-9db3-7fb5f00a506f,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-eaaf7ccc-aa77-4d29-a717-46617e7386ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-403a44e2-fcb5-42e2-b816-ce6004c98765,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-9ebe5129-ff7c-49db-af5f-1db8eaa075a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-5af67542-14c6-444b-ab15-0e7320a64a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-d79c1885-86a1-41b8-b390-c1fcc02dafe0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1836735539-172.17.0.18-1595650163698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45707,DS-8ea49a20-a131-4a08-adfd-2e4ae2d16fee,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-f46d926b-1b23-4503-94e8-4330daf9e73f,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-0b16dd0c-77cb-4786-8116-eb4fa80cbe88,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-d27c9739-b715-4fd8-8f41-0eb8052c11b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-67170ef0-e446-457e-9184-538a51327ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-55760646-cd4c-438c-b817-7ee970c9ea24,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-3384c507-3d4b-4b64-b14c-59c43cf2884a,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-7f8f147e-19fa-40f9-81cf-bae07f4d91a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1836735539-172.17.0.18-1595650163698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45707,DS-8ea49a20-a131-4a08-adfd-2e4ae2d16fee,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-f46d926b-1b23-4503-94e8-4330daf9e73f,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-0b16dd0c-77cb-4786-8116-eb4fa80cbe88,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-d27c9739-b715-4fd8-8f41-0eb8052c11b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-67170ef0-e446-457e-9184-538a51327ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-55760646-cd4c-438c-b817-7ee970c9ea24,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-3384c507-3d4b-4b64-b14c-59c43cf2884a,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-7f8f147e-19fa-40f9-81cf-bae07f4d91a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-932886370-172.17.0.18-1595650479510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36432,DS-97ce3552-1e7e-4b24-85c1-0335e46b3b51,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-97035371-7e97-4f82-a360-950702641b78,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-77d1ffcc-1f57-4207-9bbd-00747db8ee0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-7dc6bd41-c960-45cf-8d56-e8aeb5fd549e,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-d0b4e695-8e23-4534-a02b-a757f03eb4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-c842147e-93c8-4e9b-8056-a5b29291c31d,DISK], DatanodeInfoWithStorage[127.0.0.1:43503,DS-69c8e91e-d60f-4da9-85ee-9714829bc36f,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-c641f9b0-8f36-4635-aefc-566a474defe5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-932886370-172.17.0.18-1595650479510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36432,DS-97ce3552-1e7e-4b24-85c1-0335e46b3b51,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-97035371-7e97-4f82-a360-950702641b78,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-77d1ffcc-1f57-4207-9bbd-00747db8ee0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-7dc6bd41-c960-45cf-8d56-e8aeb5fd549e,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-d0b4e695-8e23-4534-a02b-a757f03eb4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-c842147e-93c8-4e9b-8056-a5b29291c31d,DISK], DatanodeInfoWithStorage[127.0.0.1:43503,DS-69c8e91e-d60f-4da9-85ee-9714829bc36f,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-c641f9b0-8f36-4635-aefc-566a474defe5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-618809890-172.17.0.18-1595650787648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36741,DS-9466e924-9e92-4f9f-ac4c-63bea96c5adb,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-f5cbd51e-636f-450f-98c9-1f0c6025efce,DISK], DatanodeInfoWithStorage[127.0.0.1:36944,DS-dd0d2549-9215-44da-9342-b73cf81f50d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-4e420a38-328c-46c2-b1f1-cbff28fbf90e,DISK], DatanodeInfoWithStorage[127.0.0.1:40430,DS-e31d22e0-1bbc-484c-a377-13d3bcceb227,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-b576c3c7-afe6-41e3-be2e-2930dbff4733,DISK], DatanodeInfoWithStorage[127.0.0.1:36913,DS-ddaac0e1-ddae-4d7c-b512-252af25673a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45134,DS-2c0c7b67-f7d0-4b35-b8a6-5ea1e9d95ea5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-618809890-172.17.0.18-1595650787648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36741,DS-9466e924-9e92-4f9f-ac4c-63bea96c5adb,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-f5cbd51e-636f-450f-98c9-1f0c6025efce,DISK], DatanodeInfoWithStorage[127.0.0.1:36944,DS-dd0d2549-9215-44da-9342-b73cf81f50d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-4e420a38-328c-46c2-b1f1-cbff28fbf90e,DISK], DatanodeInfoWithStorage[127.0.0.1:40430,DS-e31d22e0-1bbc-484c-a377-13d3bcceb227,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-b576c3c7-afe6-41e3-be2e-2930dbff4733,DISK], DatanodeInfoWithStorage[127.0.0.1:36913,DS-ddaac0e1-ddae-4d7c-b512-252af25673a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45134,DS-2c0c7b67-f7d0-4b35-b8a6-5ea1e9d95ea5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1268268438-172.17.0.18-1595651079772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36462,DS-8f9c1e8b-297b-41a3-937c-7618a0d476d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-97cc861d-2154-4fc5-9f78-dada9ffd9d77,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-e0902ffa-2c98-4b31-8821-c4f16915f46b,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-fd8c0c0e-6433-4176-841d-0890d4d64f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40272,DS-f35eb128-fe1f-4675-b177-d49c070b55f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-d6d73e4b-d31d-40c2-9196-a463e085029b,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-ad7238af-2c4d-41a1-b4bb-626d9ecc58ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-3c8df739-9f0a-46cf-a0bf-e3ffbfb5ad31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1268268438-172.17.0.18-1595651079772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36462,DS-8f9c1e8b-297b-41a3-937c-7618a0d476d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-97cc861d-2154-4fc5-9f78-dada9ffd9d77,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-e0902ffa-2c98-4b31-8821-c4f16915f46b,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-fd8c0c0e-6433-4176-841d-0890d4d64f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40272,DS-f35eb128-fe1f-4675-b177-d49c070b55f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-d6d73e4b-d31d-40c2-9196-a463e085029b,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-ad7238af-2c4d-41a1-b4bb-626d9ecc58ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-3c8df739-9f0a-46cf-a0bf-e3ffbfb5ad31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1210313142-172.17.0.18-1595651385845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39289,DS-27a6877c-4f19-48bd-b208-6400be7f5d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-c1f88696-8337-4740-87a0-344920bd4745,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-16357316-f5be-4adc-a96c-cf0d9ac986b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38137,DS-5f715ea9-5396-40ed-a18b-a2aec146934c,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-7e35df20-56b7-433a-a12c-121892949de2,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-5b0342ce-7f12-4811-9f2e-7065954af1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-b8f375c7-2e3e-4d39-9eb4-80a7d4095fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-7ecdecca-8ae7-40ca-9f0d-5559169ae6ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1210313142-172.17.0.18-1595651385845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39289,DS-27a6877c-4f19-48bd-b208-6400be7f5d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-c1f88696-8337-4740-87a0-344920bd4745,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-16357316-f5be-4adc-a96c-cf0d9ac986b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38137,DS-5f715ea9-5396-40ed-a18b-a2aec146934c,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-7e35df20-56b7-433a-a12c-121892949de2,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-5b0342ce-7f12-4811-9f2e-7065954af1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-b8f375c7-2e3e-4d39-9eb4-80a7d4095fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-7ecdecca-8ae7-40ca-9f0d-5559169ae6ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-196179336-172.17.0.18-1595651505878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32935,DS-5b080a95-7ac2-42af-bb7f-cb2f0347b585,DISK], DatanodeInfoWithStorage[127.0.0.1:46205,DS-4f485efc-15d7-41cc-9ef4-c4c165b4fd93,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-267c4a70-b9b0-458d-8fa2-f32ce72b051d,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-0048811c-4b25-4dd5-a015-bcf51b83774b,DISK], DatanodeInfoWithStorage[127.0.0.1:45544,DS-8d26c866-4b7d-4fa0-aadb-77fb50e8d0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-e3b1c4cb-f7e3-4b71-b8c8-49e4f54a246e,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-6e3e967a-f215-45ec-babb-b82a2092b5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-7a60be54-bdf3-4f33-8c2b-02af02e8dce6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-196179336-172.17.0.18-1595651505878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32935,DS-5b080a95-7ac2-42af-bb7f-cb2f0347b585,DISK], DatanodeInfoWithStorage[127.0.0.1:46205,DS-4f485efc-15d7-41cc-9ef4-c4c165b4fd93,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-267c4a70-b9b0-458d-8fa2-f32ce72b051d,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-0048811c-4b25-4dd5-a015-bcf51b83774b,DISK], DatanodeInfoWithStorage[127.0.0.1:45544,DS-8d26c866-4b7d-4fa0-aadb-77fb50e8d0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-e3b1c4cb-f7e3-4b71-b8c8-49e4f54a246e,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-6e3e967a-f215-45ec-babb-b82a2092b5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-7a60be54-bdf3-4f33-8c2b-02af02e8dce6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-751745684-172.17.0.18-1595651628983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34957,DS-b73da714-fc79-4b56-986e-b1f9b5093dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-2d174337-c0a4-4661-83a6-f8395fe53f37,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-e3f0c318-1de2-44ea-83c6-b4cde1e067b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-f6657924-f36c-4cfb-acf9-93e5b40675c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-78c16993-2aa8-4dcc-8a2b-c6bb7060a6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-a304270b-2785-4d06-be45-d4a4ca2d8139,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-a1bfa92e-1a5b-42c2-94aa-98114da63a35,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-ce513da2-7b7b-40fb-ae03-9366b04f8455,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-751745684-172.17.0.18-1595651628983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34957,DS-b73da714-fc79-4b56-986e-b1f9b5093dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-2d174337-c0a4-4661-83a6-f8395fe53f37,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-e3f0c318-1de2-44ea-83c6-b4cde1e067b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-f6657924-f36c-4cfb-acf9-93e5b40675c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-78c16993-2aa8-4dcc-8a2b-c6bb7060a6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-a304270b-2785-4d06-be45-d4a4ca2d8139,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-a1bfa92e-1a5b-42c2-94aa-98114da63a35,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-ce513da2-7b7b-40fb-ae03-9366b04f8455,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-200192711-172.17.0.18-1595652631125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41723,DS-16abb5fa-d0b4-471c-a831-ae0c67ebf094,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-8a623e2e-011d-48f1-b8fa-660b19ce7263,DISK], DatanodeInfoWithStorage[127.0.0.1:43692,DS-f855e021-6d4e-40b4-902e-ad38a436b3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-b7205556-f070-426f-9596-ab530dcd95be,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-6a48b6b5-3172-4e20-ae79-efe2db6c4da3,DISK], DatanodeInfoWithStorage[127.0.0.1:38789,DS-4c592b2a-5ad3-480c-954f-dc4a93e48691,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-d275ab1b-efb2-44d8-861b-a25444807210,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-9a150826-db50-44f5-acd2-3e10b97e4f50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-200192711-172.17.0.18-1595652631125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41723,DS-16abb5fa-d0b4-471c-a831-ae0c67ebf094,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-8a623e2e-011d-48f1-b8fa-660b19ce7263,DISK], DatanodeInfoWithStorage[127.0.0.1:43692,DS-f855e021-6d4e-40b4-902e-ad38a436b3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-b7205556-f070-426f-9596-ab530dcd95be,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-6a48b6b5-3172-4e20-ae79-efe2db6c4da3,DISK], DatanodeInfoWithStorage[127.0.0.1:38789,DS-4c592b2a-5ad3-480c-954f-dc4a93e48691,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-d275ab1b-efb2-44d8-861b-a25444807210,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-9a150826-db50-44f5-acd2-3e10b97e4f50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1954185496-172.17.0.18-1595652670819:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45494,DS-45343d57-9206-4664-af9a-1853c3115283,DISK], DatanodeInfoWithStorage[127.0.0.1:46359,DS-e7f05041-2b2b-47b3-8b56-e91628ba27fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-655531d3-2cd1-4ecb-97bf-994680bef6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-b307eef0-a00a-42db-b92f-703534703860,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-1ee37dd3-46e6-4211-bb91-26ca40b3be46,DISK], DatanodeInfoWithStorage[127.0.0.1:34560,DS-d8bf80cf-8326-40a9-8052-e6698b65be93,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-8852dbcc-aa64-48d1-8d66-f4cc5fbe6ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-8152e739-a959-45ab-8743-b686685ca10d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1954185496-172.17.0.18-1595652670819:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45494,DS-45343d57-9206-4664-af9a-1853c3115283,DISK], DatanodeInfoWithStorage[127.0.0.1:46359,DS-e7f05041-2b2b-47b3-8b56-e91628ba27fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-655531d3-2cd1-4ecb-97bf-994680bef6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-b307eef0-a00a-42db-b92f-703534703860,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-1ee37dd3-46e6-4211-bb91-26ca40b3be46,DISK], DatanodeInfoWithStorage[127.0.0.1:34560,DS-d8bf80cf-8326-40a9-8052-e6698b65be93,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-8852dbcc-aa64-48d1-8d66-f4cc5fbe6ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-8152e739-a959-45ab-8743-b686685ca10d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-82995427-172.17.0.18-1595652772269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43375,DS-3b13faac-d104-4a7b-bd6a-efe055e29427,DISK], DatanodeInfoWithStorage[127.0.0.1:45124,DS-b4ef917a-1926-45ae-8e8e-24719f0ddb73,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-97377511-36bc-4496-95ea-ea5d22f1caf9,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-64ea4cbf-4045-47e6-b996-8c8ddb270740,DISK], DatanodeInfoWithStorage[127.0.0.1:44167,DS-1fc32e00-c1fd-4474-afd4-234c9f941341,DISK], DatanodeInfoWithStorage[127.0.0.1:33352,DS-5f2a3ede-5f6d-44c9-b4f4-edf2aaf13ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:39356,DS-9a56f6a9-27ba-4568-9ffd-f90ba0b25dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-90cc0317-91f5-485b-8553-388cb83e8b97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-82995427-172.17.0.18-1595652772269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43375,DS-3b13faac-d104-4a7b-bd6a-efe055e29427,DISK], DatanodeInfoWithStorage[127.0.0.1:45124,DS-b4ef917a-1926-45ae-8e8e-24719f0ddb73,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-97377511-36bc-4496-95ea-ea5d22f1caf9,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-64ea4cbf-4045-47e6-b996-8c8ddb270740,DISK], DatanodeInfoWithStorage[127.0.0.1:44167,DS-1fc32e00-c1fd-4474-afd4-234c9f941341,DISK], DatanodeInfoWithStorage[127.0.0.1:33352,DS-5f2a3ede-5f6d-44c9-b4f4-edf2aaf13ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:39356,DS-9a56f6a9-27ba-4568-9ffd-f90ba0b25dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-90cc0317-91f5-485b-8553-388cb83e8b97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1613502305-172.17.0.18-1595652943817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42295,DS-7b273f59-798d-4ea1-893e-17f2fe6d556d,DISK], DatanodeInfoWithStorage[127.0.0.1:38248,DS-fbf06aaa-38a0-4468-b85d-27e911b92119,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-8a765977-69be-4267-a192-8689812219a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-53c72ba6-e4d6-4fd6-ba2c-365514f86dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-f3982e65-96ea-42dd-8802-335c415a8dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-f6b893cd-9b9e-49a6-812a-02b9af334167,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-ebe63642-a778-41b0-af77-679324889d49,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-a9c89ad5-4401-443a-811c-48fa3467aa99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1613502305-172.17.0.18-1595652943817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42295,DS-7b273f59-798d-4ea1-893e-17f2fe6d556d,DISK], DatanodeInfoWithStorage[127.0.0.1:38248,DS-fbf06aaa-38a0-4468-b85d-27e911b92119,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-8a765977-69be-4267-a192-8689812219a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-53c72ba6-e4d6-4fd6-ba2c-365514f86dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-f3982e65-96ea-42dd-8802-335c415a8dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-f6b893cd-9b9e-49a6-812a-02b9af334167,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-ebe63642-a778-41b0-af77-679324889d49,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-a9c89ad5-4401-443a-811c-48fa3467aa99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5565
