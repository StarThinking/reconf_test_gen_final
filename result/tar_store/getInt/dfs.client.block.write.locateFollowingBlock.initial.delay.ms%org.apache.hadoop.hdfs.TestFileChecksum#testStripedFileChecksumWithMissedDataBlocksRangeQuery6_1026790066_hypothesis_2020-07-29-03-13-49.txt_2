reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1862352934-172.17.0.13-1595992481549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38245,DS-a3bc7199-2e1c-44e0-bee4-bbc65471684f,DISK], DatanodeInfoWithStorage[127.0.0.1:39659,DS-5478792e-4048-43eb-adb7-e85cc1db0b44,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-aef12530-a0af-470d-8a36-508309b45d08,DISK], DatanodeInfoWithStorage[127.0.0.1:36458,DS-db86893b-a56d-49e9-b074-8496194d4d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-a0e171e4-a268-4bf1-82dd-bbea238c686d,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-b53bec99-d009-4509-b0b7-5f9b919e73bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-0de2c4a4-cf25-45b2-a002-aa903c525115,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-237762b7-6cef-4430-b854-dcf26d627926,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1862352934-172.17.0.13-1595992481549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38245,DS-a3bc7199-2e1c-44e0-bee4-bbc65471684f,DISK], DatanodeInfoWithStorage[127.0.0.1:39659,DS-5478792e-4048-43eb-adb7-e85cc1db0b44,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-aef12530-a0af-470d-8a36-508309b45d08,DISK], DatanodeInfoWithStorage[127.0.0.1:36458,DS-db86893b-a56d-49e9-b074-8496194d4d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-a0e171e4-a268-4bf1-82dd-bbea238c686d,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-b53bec99-d009-4509-b0b7-5f9b919e73bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-0de2c4a4-cf25-45b2-a002-aa903c525115,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-237762b7-6cef-4430-b854-dcf26d627926,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1628490732-172.17.0.13-1595992668390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38801,DS-d0f44aef-acb1-4a96-8fcc-232fbc02e1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33853,DS-88427a06-888e-41cc-a863-b0d3ed2d67c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36049,DS-498f57bd-bf00-4fc4-9fd6-d874aab7673a,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-5d2dab7f-2a66-4bb1-aceb-6643204b904f,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-8f4ffa71-61e1-466b-892e-cf19cb13eac1,DISK], DatanodeInfoWithStorage[127.0.0.1:40934,DS-5165c0d8-0347-45d4-b7a4-a58899770a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-72ac9b99-7c88-409b-a81a-8650b43cb817,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-0d1a1e23-b7ea-4ae9-b55a-f72326d49c8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1628490732-172.17.0.13-1595992668390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38801,DS-d0f44aef-acb1-4a96-8fcc-232fbc02e1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33853,DS-88427a06-888e-41cc-a863-b0d3ed2d67c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36049,DS-498f57bd-bf00-4fc4-9fd6-d874aab7673a,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-5d2dab7f-2a66-4bb1-aceb-6643204b904f,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-8f4ffa71-61e1-466b-892e-cf19cb13eac1,DISK], DatanodeInfoWithStorage[127.0.0.1:40934,DS-5165c0d8-0347-45d4-b7a4-a58899770a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-72ac9b99-7c88-409b-a81a-8650b43cb817,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-0d1a1e23-b7ea-4ae9-b55a-f72326d49c8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2027409293-172.17.0.13-1595992851968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36570,DS-6fe01a2e-050d-4e4a-aab9-66a909619971,DISK], DatanodeInfoWithStorage[127.0.0.1:45065,DS-44e5884f-190d-471a-b4a0-f21247ed46d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-5e7184e2-acde-491d-a61a-0f5f859c7b06,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-0baefc07-d6f8-415f-a78f-17d1dc0ec863,DISK], DatanodeInfoWithStorage[127.0.0.1:37824,DS-78a4f983-c513-41ab-8369-30ae6406bdec,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-e5fb0305-cbf3-41dc-b704-e424cb0e1b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-d5053d42-0f0d-4951-976b-ea1ef368e8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-0aaac18f-dc89-428b-b9de-32abc48f07e9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2027409293-172.17.0.13-1595992851968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36570,DS-6fe01a2e-050d-4e4a-aab9-66a909619971,DISK], DatanodeInfoWithStorage[127.0.0.1:45065,DS-44e5884f-190d-471a-b4a0-f21247ed46d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-5e7184e2-acde-491d-a61a-0f5f859c7b06,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-0baefc07-d6f8-415f-a78f-17d1dc0ec863,DISK], DatanodeInfoWithStorage[127.0.0.1:37824,DS-78a4f983-c513-41ab-8369-30ae6406bdec,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-e5fb0305-cbf3-41dc-b704-e424cb0e1b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-d5053d42-0f0d-4951-976b-ea1ef368e8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-0aaac18f-dc89-428b-b9de-32abc48f07e9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2136198557-172.17.0.13-1595993060285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39744,DS-d469cec7-597f-4c13-922a-0b1e39b0724e,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-0619a954-b3e9-4a68-8716-febb55504f28,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-560fc574-c64a-4424-ab3f-6b368a106225,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-be49e224-47da-4396-ba06-71b6cabae55e,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-ab95db87-abfb-47b9-b6eb-328758ddb201,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-b4f53904-bacf-4701-a6ee-c9166d2e7152,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-7a5c3ee0-17f7-475f-a055-5ef926707a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35136,DS-f9e55d0c-c1ba-4ae1-990c-1923bd28d524,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2136198557-172.17.0.13-1595993060285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39744,DS-d469cec7-597f-4c13-922a-0b1e39b0724e,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-0619a954-b3e9-4a68-8716-febb55504f28,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-560fc574-c64a-4424-ab3f-6b368a106225,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-be49e224-47da-4396-ba06-71b6cabae55e,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-ab95db87-abfb-47b9-b6eb-328758ddb201,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-b4f53904-bacf-4701-a6ee-c9166d2e7152,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-7a5c3ee0-17f7-475f-a055-5ef926707a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35136,DS-f9e55d0c-c1ba-4ae1-990c-1923bd28d524,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-143543318-172.17.0.13-1595993094211:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46208,DS-481ca1b5-cb2b-40b2-9413-4cfd369576b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-40511760-cfb2-41a4-8655-5e0ea54337f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-6f14da44-dc83-4c94-b3c0-207ddae2d7db,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-4347832b-6243-477a-ae36-c8cdfcc1f475,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-e78b57f6-6b93-4cbc-b8c3-d66ef1dffd85,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-c42df0d9-7161-4676-b528-5108eb618e28,DISK], DatanodeInfoWithStorage[127.0.0.1:33048,DS-b172aceb-e919-4bcb-9263-19644bb86d21,DISK], DatanodeInfoWithStorage[127.0.0.1:37211,DS-07fa7200-6eab-4ae8-b5d0-d8e0525f111c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-143543318-172.17.0.13-1595993094211:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46208,DS-481ca1b5-cb2b-40b2-9413-4cfd369576b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-40511760-cfb2-41a4-8655-5e0ea54337f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-6f14da44-dc83-4c94-b3c0-207ddae2d7db,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-4347832b-6243-477a-ae36-c8cdfcc1f475,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-e78b57f6-6b93-4cbc-b8c3-d66ef1dffd85,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-c42df0d9-7161-4676-b528-5108eb618e28,DISK], DatanodeInfoWithStorage[127.0.0.1:33048,DS-b172aceb-e919-4bcb-9263-19644bb86d21,DISK], DatanodeInfoWithStorage[127.0.0.1:37211,DS-07fa7200-6eab-4ae8-b5d0-d8e0525f111c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-61819577-172.17.0.13-1595993279319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46299,DS-b3d274f2-4849-4b49-8367-24c6e3e09fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-0272c095-e28a-4cfc-9072-4e3a5d0c435a,DISK], DatanodeInfoWithStorage[127.0.0.1:37773,DS-319d29d6-0843-485a-873d-1870128fec7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-d800aaa2-445b-492a-8be3-bcd11d2ba859,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-07361a40-b3ad-4023-9250-6b26cb6b6c35,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-0e4e3380-fc92-4f9a-bdfe-7e42cbad2f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-01a18bb2-9fa1-44ee-a16a-433704a8824c,DISK], DatanodeInfoWithStorage[127.0.0.1:34302,DS-846560eb-12af-41f7-9252-74339eff32b7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-61819577-172.17.0.13-1595993279319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46299,DS-b3d274f2-4849-4b49-8367-24c6e3e09fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-0272c095-e28a-4cfc-9072-4e3a5d0c435a,DISK], DatanodeInfoWithStorage[127.0.0.1:37773,DS-319d29d6-0843-485a-873d-1870128fec7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-d800aaa2-445b-492a-8be3-bcd11d2ba859,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-07361a40-b3ad-4023-9250-6b26cb6b6c35,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-0e4e3380-fc92-4f9a-bdfe-7e42cbad2f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-01a18bb2-9fa1-44ee-a16a-433704a8824c,DISK], DatanodeInfoWithStorage[127.0.0.1:34302,DS-846560eb-12af-41f7-9252-74339eff32b7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-298429307-172.17.0.13-1595993318607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36974,DS-7dc6b88f-965a-4560-8098-fda71d6b33cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-7a4cfc03-7e05-44cc-8ca0-e46820925990,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-390951ee-f745-4adb-9bad-2b6d7cb1a1df,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-587792c4-bc84-4272-854e-45a85b22080d,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-c6deba3f-0005-4f62-9559-6077886ce95c,DISK], DatanodeInfoWithStorage[127.0.0.1:36249,DS-b280f273-a786-4995-a756-d4f0d31bd8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-5b9f3f85-44e0-479b-87e1-a9a48a179057,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-27aeec71-093e-4689-9482-98d34d395b27,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-298429307-172.17.0.13-1595993318607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36974,DS-7dc6b88f-965a-4560-8098-fda71d6b33cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-7a4cfc03-7e05-44cc-8ca0-e46820925990,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-390951ee-f745-4adb-9bad-2b6d7cb1a1df,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-587792c4-bc84-4272-854e-45a85b22080d,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-c6deba3f-0005-4f62-9559-6077886ce95c,DISK], DatanodeInfoWithStorage[127.0.0.1:36249,DS-b280f273-a786-4995-a756-d4f0d31bd8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-5b9f3f85-44e0-479b-87e1-a9a48a179057,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-27aeec71-093e-4689-9482-98d34d395b27,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-778655323-172.17.0.13-1595993353667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46421,DS-21c5a706-61b3-40da-b8db-878409a8146a,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-fa107d7d-0eff-43ba-80db-3433dac50958,DISK], DatanodeInfoWithStorage[127.0.0.1:37440,DS-55393455-5ad6-446d-80a4-e63a7c92be58,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-a19d6998-57bb-459f-82b5-95fac53c5865,DISK], DatanodeInfoWithStorage[127.0.0.1:39102,DS-59b51df8-d728-4a77-a8e4-e4528604472b,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-cdb77b44-b072-41a0-b59e-ffc9d3a59029,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-d350e3e8-c626-4adb-9b95-9bb5ddfe8a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-62766734-293d-4a38-9e76-7f90a93acd55,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-778655323-172.17.0.13-1595993353667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46421,DS-21c5a706-61b3-40da-b8db-878409a8146a,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-fa107d7d-0eff-43ba-80db-3433dac50958,DISK], DatanodeInfoWithStorage[127.0.0.1:37440,DS-55393455-5ad6-446d-80a4-e63a7c92be58,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-a19d6998-57bb-459f-82b5-95fac53c5865,DISK], DatanodeInfoWithStorage[127.0.0.1:39102,DS-59b51df8-d728-4a77-a8e4-e4528604472b,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-cdb77b44-b072-41a0-b59e-ffc9d3a59029,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-d350e3e8-c626-4adb-9b95-9bb5ddfe8a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-62766734-293d-4a38-9e76-7f90a93acd55,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2112101221-172.17.0.13-1595993395223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42482,DS-8e0d2ff1-5439-4dca-bd5b-42d285527d56,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-02f3a52a-a16a-4d02-8c99-d8dff3bcc7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-051cda25-f240-4cb4-9964-2c52e39072e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-d866d695-af57-474a-b928-423709b1ae54,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-fa4abd55-82ac-470a-81c6-c9512e288d80,DISK], DatanodeInfoWithStorage[127.0.0.1:44281,DS-06f6e8ae-54d8-4144-8d07-1dc2223198af,DISK], DatanodeInfoWithStorage[127.0.0.1:44038,DS-0c6549f7-1ac8-438a-a49c-3b530c041b01,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-e9d60375-4abb-496c-acc8-24a04571833a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2112101221-172.17.0.13-1595993395223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42482,DS-8e0d2ff1-5439-4dca-bd5b-42d285527d56,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-02f3a52a-a16a-4d02-8c99-d8dff3bcc7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-051cda25-f240-4cb4-9964-2c52e39072e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-d866d695-af57-474a-b928-423709b1ae54,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-fa4abd55-82ac-470a-81c6-c9512e288d80,DISK], DatanodeInfoWithStorage[127.0.0.1:44281,DS-06f6e8ae-54d8-4144-8d07-1dc2223198af,DISK], DatanodeInfoWithStorage[127.0.0.1:44038,DS-0c6549f7-1ac8-438a-a49c-3b530c041b01,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-e9d60375-4abb-496c-acc8-24a04571833a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1580593345-172.17.0.13-1595993581203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43669,DS-30ea3bee-2029-4213-b611-16727c69860f,DISK], DatanodeInfoWithStorage[127.0.0.1:45651,DS-64f955f1-98f8-433d-81ab-b9c2c66cc298,DISK], DatanodeInfoWithStorage[127.0.0.1:37285,DS-b88f5b9b-5cca-4d41-ad63-d0bd7368074f,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-493120fc-b36f-4e93-8183-ed660ca8f129,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-033bc094-2916-465d-8e44-a5420d7fbace,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-50c0fddd-c81d-4b37-bd86-16b0ae5bb3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-c822a962-58c7-4160-b60d-a4927c069831,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-b52f1333-600b-4f98-88ce-f892c2213c27,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1580593345-172.17.0.13-1595993581203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43669,DS-30ea3bee-2029-4213-b611-16727c69860f,DISK], DatanodeInfoWithStorage[127.0.0.1:45651,DS-64f955f1-98f8-433d-81ab-b9c2c66cc298,DISK], DatanodeInfoWithStorage[127.0.0.1:37285,DS-b88f5b9b-5cca-4d41-ad63-d0bd7368074f,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-493120fc-b36f-4e93-8183-ed660ca8f129,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-033bc094-2916-465d-8e44-a5420d7fbace,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-50c0fddd-c81d-4b37-bd86-16b0ae5bb3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-c822a962-58c7-4160-b60d-a4927c069831,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-b52f1333-600b-4f98-88ce-f892c2213c27,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1626363683-172.17.0.13-1595993619956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41522,DS-facec608-eb0d-478d-989a-83509afa1752,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-183dd2b0-cc65-4af4-9019-9ddaaf5b956e,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-0c3d6c78-5e3c-4ba8-8cbf-de9e8f51b1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-6d0269c9-ff4e-4d00-aaf2-3fcae379d073,DISK], DatanodeInfoWithStorage[127.0.0.1:44291,DS-ee010d9f-6ea2-4d43-a410-ad75a5c10a94,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-27e92993-a3ef-4e55-aa4f-f46c777cdfcb,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-9676bbb2-a306-495f-8162-9072fef70e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-0817563e-cf18-4ee8-9391-5bf5365e3d03,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1626363683-172.17.0.13-1595993619956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41522,DS-facec608-eb0d-478d-989a-83509afa1752,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-183dd2b0-cc65-4af4-9019-9ddaaf5b956e,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-0c3d6c78-5e3c-4ba8-8cbf-de9e8f51b1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-6d0269c9-ff4e-4d00-aaf2-3fcae379d073,DISK], DatanodeInfoWithStorage[127.0.0.1:44291,DS-ee010d9f-6ea2-4d43-a410-ad75a5c10a94,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-27e92993-a3ef-4e55-aa4f-f46c777cdfcb,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-9676bbb2-a306-495f-8162-9072fef70e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-0817563e-cf18-4ee8-9391-5bf5365e3d03,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1754386885-172.17.0.13-1595993702153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38311,DS-9b21ce51-e27d-44a0-9cdf-5a58e954fda2,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-ec1d2874-19d6-4352-8274-ab79e34ecec6,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-64e1fc79-a261-4c8c-b70d-ab8345fd25d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-09845d3f-a659-4f6c-85e9-91e5563f7e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-ccab5a35-2695-4ad6-b309-01688c35749e,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-ceda0d3f-442b-44d6-ad33-606ac422880f,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-dcce8697-b537-498f-986e-f7a75c5e6030,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-b640e7de-150f-4833-ac57-d80f711b7018,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1754386885-172.17.0.13-1595993702153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38311,DS-9b21ce51-e27d-44a0-9cdf-5a58e954fda2,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-ec1d2874-19d6-4352-8274-ab79e34ecec6,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-64e1fc79-a261-4c8c-b70d-ab8345fd25d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-09845d3f-a659-4f6c-85e9-91e5563f7e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-ccab5a35-2695-4ad6-b309-01688c35749e,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-ceda0d3f-442b-44d6-ad33-606ac422880f,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-dcce8697-b537-498f-986e-f7a75c5e6030,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-b640e7de-150f-4833-ac57-d80f711b7018,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-807154871-172.17.0.13-1595993932850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36434,DS-fddb60df-28b6-429e-953f-b139b90de10a,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-e140e83f-37e4-44bf-83be-d022243b1e87,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-d7bc43da-3a88-4a1f-a0b8-0b29c192a8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44525,DS-8c0e666e-b9d8-4186-89fa-e5a429f2ed6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-c6ee9f29-7887-4449-9631-49faeb17e427,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-67f5fd99-2d01-4900-b7f9-780bae4708e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34919,DS-35aec36c-81ed-4479-9852-268c924b2d55,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-c6bc7243-34f0-4815-8e9a-6ee4ceab28d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-807154871-172.17.0.13-1595993932850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36434,DS-fddb60df-28b6-429e-953f-b139b90de10a,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-e140e83f-37e4-44bf-83be-d022243b1e87,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-d7bc43da-3a88-4a1f-a0b8-0b29c192a8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44525,DS-8c0e666e-b9d8-4186-89fa-e5a429f2ed6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-c6ee9f29-7887-4449-9631-49faeb17e427,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-67f5fd99-2d01-4900-b7f9-780bae4708e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34919,DS-35aec36c-81ed-4479-9852-268c924b2d55,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-c6bc7243-34f0-4815-8e9a-6ee4ceab28d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1690694606-172.17.0.13-1595994378688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32826,DS-1cbd345e-b98e-4850-adf4-1d95dfc172a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37000,DS-d0e5538d-79a0-4e65-a316-5f996fc44db1,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-89026820-5c84-45e4-88bf-b201628257e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-fe682b29-33ad-4826-80c4-726d5b45ea88,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-d27aa31e-fb0e-4eca-b449-bb045bf7f42f,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-d14f7530-834c-49e4-a147-3c13e886f03f,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-5666ab2a-26d7-48c6-8667-890532a3bc1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36348,DS-9672da38-8cfe-47f4-ae7f-81d5c359799b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1690694606-172.17.0.13-1595994378688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32826,DS-1cbd345e-b98e-4850-adf4-1d95dfc172a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37000,DS-d0e5538d-79a0-4e65-a316-5f996fc44db1,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-89026820-5c84-45e4-88bf-b201628257e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-fe682b29-33ad-4826-80c4-726d5b45ea88,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-d27aa31e-fb0e-4eca-b449-bb045bf7f42f,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-d14f7530-834c-49e4-a147-3c13e886f03f,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-5666ab2a-26d7-48c6-8667-890532a3bc1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36348,DS-9672da38-8cfe-47f4-ae7f-81d5c359799b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2050614394-172.17.0.13-1595994457692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43179,DS-3c8516d0-f1bf-4455-bcf9-3364493526b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-25cb5ca0-6b68-4155-a467-7d524410ac3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-3731ba31-7097-4661-80c7-7c9b31e9aa3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-ae415d84-e6cc-4e8c-9317-1d97feb3db24,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-7ddc193f-d4eb-4fcc-8448-07cb1d7ca5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43439,DS-c34f9d9a-714e-4a11-9d8a-232621b5397c,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-d8e4aed1-cd4a-4e04-91f0-f42a89ffb007,DISK], DatanodeInfoWithStorage[127.0.0.1:33067,DS-2a8ae6ab-5c3d-4321-acfd-ebdf1ba04fc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2050614394-172.17.0.13-1595994457692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43179,DS-3c8516d0-f1bf-4455-bcf9-3364493526b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-25cb5ca0-6b68-4155-a467-7d524410ac3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-3731ba31-7097-4661-80c7-7c9b31e9aa3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-ae415d84-e6cc-4e8c-9317-1d97feb3db24,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-7ddc193f-d4eb-4fcc-8448-07cb1d7ca5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43439,DS-c34f9d9a-714e-4a11-9d8a-232621b5397c,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-d8e4aed1-cd4a-4e04-91f0-f42a89ffb007,DISK], DatanodeInfoWithStorage[127.0.0.1:33067,DS-2a8ae6ab-5c3d-4321-acfd-ebdf1ba04fc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2029357308-172.17.0.13-1595994995010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41741,DS-b9c22713-ad2d-4253-a5a4-5079eafc9670,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-ba16b283-86f0-48c8-a1c2-2057c214b3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-a669d61a-2e8e-4c83-a337-2e156c77e52e,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-456f09f2-f728-4abc-b9a5-2d86f3b6703c,DISK], DatanodeInfoWithStorage[127.0.0.1:38509,DS-5ba6a19d-b2fb-49e7-8be3-39c945bd628d,DISK], DatanodeInfoWithStorage[127.0.0.1:46610,DS-b24c9a8e-14b0-4858-acc2-4b2717c8f6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-aa00726b-324b-4df7-be32-39df0750121c,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-6d2a6d79-4e02-4996-97f1-fae3f161ecb1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2029357308-172.17.0.13-1595994995010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41741,DS-b9c22713-ad2d-4253-a5a4-5079eafc9670,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-ba16b283-86f0-48c8-a1c2-2057c214b3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-a669d61a-2e8e-4c83-a337-2e156c77e52e,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-456f09f2-f728-4abc-b9a5-2d86f3b6703c,DISK], DatanodeInfoWithStorage[127.0.0.1:38509,DS-5ba6a19d-b2fb-49e7-8be3-39c945bd628d,DISK], DatanodeInfoWithStorage[127.0.0.1:46610,DS-b24c9a8e-14b0-4858-acc2-4b2717c8f6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-aa00726b-324b-4df7-be32-39df0750121c,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-6d2a6d79-4e02-4996-97f1-fae3f161ecb1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1726145584-172.17.0.13-1595995036445:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41927,DS-20d8a9c2-d139-4ceb-9c2c-a51f8498d5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-438e7c01-61b0-4c9d-b071-d8a4811007da,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-3be49e9e-1100-445a-9811-c2c495cbe8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-865340fc-3398-4ba5-8861-4c17e06765a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-6a52b430-bf14-4807-9fee-ff6541fab6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-9c76fb49-edad-44bf-afea-7a128615a59f,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-fa91fd49-7570-4df3-9b72-14ed20b94a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-5845ad7c-d293-418d-9d29-4ece93242ec7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1726145584-172.17.0.13-1595995036445:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41927,DS-20d8a9c2-d139-4ceb-9c2c-a51f8498d5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-438e7c01-61b0-4c9d-b071-d8a4811007da,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-3be49e9e-1100-445a-9811-c2c495cbe8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-865340fc-3398-4ba5-8861-4c17e06765a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-6a52b430-bf14-4807-9fee-ff6541fab6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-9c76fb49-edad-44bf-afea-7a128615a59f,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-fa91fd49-7570-4df3-9b72-14ed20b94a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-5845ad7c-d293-418d-9d29-4ece93242ec7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-13304072-172.17.0.13-1595995076200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37670,DS-9a2c9867-4aba-402f-9a6d-a01530ab73dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-5c3bf159-1572-4781-92d4-98ab99fad2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-482eca90-0ebc-4f47-8564-3f6a3466e9da,DISK], DatanodeInfoWithStorage[127.0.0.1:33410,DS-b6476407-3c2a-4455-8d61-070425f4b859,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-36ae0429-e30b-4a03-9ff5-8c4e7cc3b3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41384,DS-3278c473-764c-49ae-b339-328cb4133b02,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-08cacfd1-10d4-4750-b0e8-a7b4af2be385,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-0aa421a6-f4f7-4978-8752-abd35053c12e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-13304072-172.17.0.13-1595995076200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37670,DS-9a2c9867-4aba-402f-9a6d-a01530ab73dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-5c3bf159-1572-4781-92d4-98ab99fad2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-482eca90-0ebc-4f47-8564-3f6a3466e9da,DISK], DatanodeInfoWithStorage[127.0.0.1:33410,DS-b6476407-3c2a-4455-8d61-070425f4b859,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-36ae0429-e30b-4a03-9ff5-8c4e7cc3b3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41384,DS-3278c473-764c-49ae-b339-328cb4133b02,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-08cacfd1-10d4-4750-b0e8-a7b4af2be385,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-0aa421a6-f4f7-4978-8752-abd35053c12e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-928081341-172.17.0.13-1595995114439:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34784,DS-c5b5e9c2-7d30-4163-9cc8-54c7dc0e531a,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-59ef8675-d126-49d4-8e22-e0af6785b3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-e6274acf-b134-438f-ad8c-bde8fa9b0fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-2726dc16-12b0-41d0-afdc-d5db21e9bcbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-ab2bd776-66c3-4668-9ed6-fb7367d9df32,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-5cff5bd3-7158-40a4-8e18-a82f0cb15935,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-da849028-4820-41d4-94b0-461d8e351db6,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-4020fccf-7e2b-4732-9ab3-aeb0052cbfe9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-928081341-172.17.0.13-1595995114439:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34784,DS-c5b5e9c2-7d30-4163-9cc8-54c7dc0e531a,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-59ef8675-d126-49d4-8e22-e0af6785b3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-e6274acf-b134-438f-ad8c-bde8fa9b0fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-2726dc16-12b0-41d0-afdc-d5db21e9bcbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-ab2bd776-66c3-4668-9ed6-fb7367d9df32,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-5cff5bd3-7158-40a4-8e18-a82f0cb15935,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-da849028-4820-41d4-94b0-461d8e351db6,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-4020fccf-7e2b-4732-9ab3-aeb0052cbfe9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1830496440-172.17.0.13-1595995364968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35208,DS-969262ef-12fd-435b-a603-604c153d92ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-e91c640a-e5d6-4e6f-989e-ab90b411b9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-9869bb98-e634-43b2-a304-1b7bf659aa18,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-7302a94c-596a-4108-bfeb-1f1861896a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-6ec8b354-c127-4efc-90c3-5a42227f2b35,DISK], DatanodeInfoWithStorage[127.0.0.1:44026,DS-22c6b566-7e52-448c-bb35-51a3e8a1f6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-bee10bf5-d539-4ba2-b591-7fd477417f74,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-10681349-fe19-412b-a69d-b8957bc76f53,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1830496440-172.17.0.13-1595995364968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35208,DS-969262ef-12fd-435b-a603-604c153d92ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-e91c640a-e5d6-4e6f-989e-ab90b411b9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-9869bb98-e634-43b2-a304-1b7bf659aa18,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-7302a94c-596a-4108-bfeb-1f1861896a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-6ec8b354-c127-4efc-90c3-5a42227f2b35,DISK], DatanodeInfoWithStorage[127.0.0.1:44026,DS-22c6b566-7e52-448c-bb35-51a3e8a1f6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-bee10bf5-d539-4ba2-b591-7fd477417f74,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-10681349-fe19-412b-a69d-b8957bc76f53,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-62244028-172.17.0.13-1595995442807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40344,DS-cc700fa3-5305-44a8-adeb-7e89d3d7f6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-974ed5a3-14a2-434e-ade9-a698dd008023,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-da407a17-fcf3-4db6-a5b2-466f157ee5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-b6fa9afd-0b4d-43e0-81b1-98b1ad854027,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-75727caf-8d39-4dce-82a5-2defc1587075,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-7a3a17ac-4c54-412b-9262-e5e950d621f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-5f3be7cc-4224-4647-9d0e-7211c0cbb622,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-2e0c8669-fd06-482b-ab9a-40fec5675899,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-62244028-172.17.0.13-1595995442807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40344,DS-cc700fa3-5305-44a8-adeb-7e89d3d7f6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-974ed5a3-14a2-434e-ade9-a698dd008023,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-da407a17-fcf3-4db6-a5b2-466f157ee5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-b6fa9afd-0b4d-43e0-81b1-98b1ad854027,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-75727caf-8d39-4dce-82a5-2defc1587075,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-7a3a17ac-4c54-412b-9262-e5e950d621f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-5f3be7cc-4224-4647-9d0e-7211c0cbb622,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-2e0c8669-fd06-482b-ab9a-40fec5675899,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63070293-172.17.0.13-1595995478855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44677,DS-d5295714-959b-46ba-8f0c-0779104e85b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-21770c6a-3671-4e57-9c8a-4acd6730b1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-0283b71b-7884-4d55-9978-70b7a6eb406d,DISK], DatanodeInfoWithStorage[127.0.0.1:39904,DS-f0ad09b7-fc8a-49b8-9151-8f845175d455,DISK], DatanodeInfoWithStorage[127.0.0.1:36915,DS-0cfcca22-bd8b-4ff5-a66f-99f00a61d8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38628,DS-384ba656-b5e6-477c-a3c0-813a0a67bf2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-7f1e2af6-fe4d-40d3-b3e0-1f57ce004cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43186,DS-326299b9-611f-4813-b29e-64fd5ad606ff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63070293-172.17.0.13-1595995478855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44677,DS-d5295714-959b-46ba-8f0c-0779104e85b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-21770c6a-3671-4e57-9c8a-4acd6730b1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-0283b71b-7884-4d55-9978-70b7a6eb406d,DISK], DatanodeInfoWithStorage[127.0.0.1:39904,DS-f0ad09b7-fc8a-49b8-9151-8f845175d455,DISK], DatanodeInfoWithStorage[127.0.0.1:36915,DS-0cfcca22-bd8b-4ff5-a66f-99f00a61d8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38628,DS-384ba656-b5e6-477c-a3c0-813a0a67bf2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-7f1e2af6-fe4d-40d3-b3e0-1f57ce004cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43186,DS-326299b9-611f-4813-b29e-64fd5ad606ff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-353185552-172.17.0.13-1595995629328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43408,DS-ecafe95c-2503-4f09-bc8e-efb07839e054,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-abbe47e1-b0ca-493a-ba8d-2f9d3d74233c,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-7cc26073-756b-4736-9b18-9fa37cef5f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-663b19ef-06fe-4414-ac38-927b2bcb4bde,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-bfbb702a-5052-4bc8-8871-a2ecbd3d2376,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-b7938e80-99f2-45e4-8c83-54167cec8ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-844347bc-0a6d-4071-8e0f-63501cbdd8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-1eb02601-43ee-47f4-8780-95ca27edeeb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-353185552-172.17.0.13-1595995629328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43408,DS-ecafe95c-2503-4f09-bc8e-efb07839e054,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-abbe47e1-b0ca-493a-ba8d-2f9d3d74233c,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-7cc26073-756b-4736-9b18-9fa37cef5f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-663b19ef-06fe-4414-ac38-927b2bcb4bde,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-bfbb702a-5052-4bc8-8871-a2ecbd3d2376,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-b7938e80-99f2-45e4-8c83-54167cec8ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-844347bc-0a6d-4071-8e0f-63501cbdd8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-1eb02601-43ee-47f4-8780-95ca27edeeb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-885026832-172.17.0.13-1595995726669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38886,DS-7b2753ad-b7c7-4ad8-a764-1070464b296d,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-02396d22-00f0-4631-9ee1-902782216533,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-435bc32f-b27b-422e-b146-a41f9766e973,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-d6ad9e70-0789-4de9-afec-cb5bebf805d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42495,DS-be6935cc-3aeb-4e4d-bc8d-4c10aed2a379,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-bbcfefa4-a608-4b65-bd78-a5770527e803,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-550da62e-725f-4e46-a3d2-94a0c49419b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39659,DS-20504db4-a123-409c-acec-abc7bb2ba417,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-885026832-172.17.0.13-1595995726669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38886,DS-7b2753ad-b7c7-4ad8-a764-1070464b296d,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-02396d22-00f0-4631-9ee1-902782216533,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-435bc32f-b27b-422e-b146-a41f9766e973,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-d6ad9e70-0789-4de9-afec-cb5bebf805d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42495,DS-be6935cc-3aeb-4e4d-bc8d-4c10aed2a379,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-bbcfefa4-a608-4b65-bd78-a5770527e803,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-550da62e-725f-4e46-a3d2-94a0c49419b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39659,DS-20504db4-a123-409c-acec-abc7bb2ba417,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-818654709-172.17.0.13-1595995982338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36039,DS-7a858665-3793-4621-954e-6b0a7e3bd151,DISK], DatanodeInfoWithStorage[127.0.0.1:42114,DS-c88270d1-6aa9-4090-b1e3-62bda991fbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-10f684fc-270e-4c23-b0b2-8068a814a1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-9d55e5ce-3a58-40f7-96c7-3728ad9c65e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-372b7317-c3a8-4718-99bd-854f17c0981d,DISK], DatanodeInfoWithStorage[127.0.0.1:45355,DS-4e616ab5-b1d2-43a5-8087-5967eba97565,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-2ff788d4-fdea-4708-8fce-0265f6fab438,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-767d5704-6ecf-41f0-a248-47419b0f7e52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-818654709-172.17.0.13-1595995982338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36039,DS-7a858665-3793-4621-954e-6b0a7e3bd151,DISK], DatanodeInfoWithStorage[127.0.0.1:42114,DS-c88270d1-6aa9-4090-b1e3-62bda991fbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-10f684fc-270e-4c23-b0b2-8068a814a1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-9d55e5ce-3a58-40f7-96c7-3728ad9c65e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-372b7317-c3a8-4718-99bd-854f17c0981d,DISK], DatanodeInfoWithStorage[127.0.0.1:45355,DS-4e616ab5-b1d2-43a5-8087-5967eba97565,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-2ff788d4-fdea-4708-8fce-0265f6fab438,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-767d5704-6ecf-41f0-a248-47419b0f7e52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894463552-172.17.0.13-1595996019087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38230,DS-8d8e64a7-4661-4952-9198-4fa19661832e,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-42b0f4a5-5613-406d-9e6f-cda436e25d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-943949b4-46bb-4297-b5ec-06b72caf8d63,DISK], DatanodeInfoWithStorage[127.0.0.1:38541,DS-121eba12-6f99-4dc5-aa82-324114e84a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33279,DS-9fc21036-80ac-4c46-8bfe-7b63a85dbf6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-4ec0723e-a222-4190-a87b-c0dd845d2d42,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-9ded2785-fa13-4038-b903-5079b98bfb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-aee606c1-19fb-46ef-8b45-7621ea076f7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894463552-172.17.0.13-1595996019087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38230,DS-8d8e64a7-4661-4952-9198-4fa19661832e,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-42b0f4a5-5613-406d-9e6f-cda436e25d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-943949b4-46bb-4297-b5ec-06b72caf8d63,DISK], DatanodeInfoWithStorage[127.0.0.1:38541,DS-121eba12-6f99-4dc5-aa82-324114e84a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33279,DS-9fc21036-80ac-4c46-8bfe-7b63a85dbf6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-4ec0723e-a222-4190-a87b-c0dd845d2d42,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-9ded2785-fa13-4038-b903-5079b98bfb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-aee606c1-19fb-46ef-8b45-7621ea076f7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-169691553-172.17.0.13-1595996503421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41841,DS-0c37a24b-8cc6-4500-8c4c-f35b7f9384e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42152,DS-b0b61518-0801-42d3-b535-e05cf795afd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-2e6e253c-611c-4e1e-8c1d-4bfd5e0f7b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-82a529a1-5a44-4ee4-b1bb-493347698de4,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-1052b44b-73e8-48f5-a2d4-94af528b781b,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-4890f723-68a7-4a44-bffc-ebb51d695441,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-5bba2227-b43e-4eb2-a03a-e978ce83805d,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-f4c9fed0-7bf6-45d6-8073-eb2c33574c17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-169691553-172.17.0.13-1595996503421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41841,DS-0c37a24b-8cc6-4500-8c4c-f35b7f9384e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42152,DS-b0b61518-0801-42d3-b535-e05cf795afd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-2e6e253c-611c-4e1e-8c1d-4bfd5e0f7b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-82a529a1-5a44-4ee4-b1bb-493347698de4,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-1052b44b-73e8-48f5-a2d4-94af528b781b,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-4890f723-68a7-4a44-bffc-ebb51d695441,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-5bba2227-b43e-4eb2-a03a-e978ce83805d,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-f4c9fed0-7bf6-45d6-8073-eb2c33574c17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-768239874-172.17.0.13-1595996572777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45303,DS-8123738c-def6-4208-8142-aaaf7b30d483,DISK], DatanodeInfoWithStorage[127.0.0.1:42191,DS-12f5d7d9-2821-443a-b1ac-9ad61d33ad4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-7017b976-3e03-4e13-8d2b-5312e257afbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43891,DS-299bc5df-603d-4391-8165-a47cebcdbe0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-57bd22e7-eb3d-4053-ba85-c7a12b6975b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-6562bddf-a35f-4007-a48b-7c49a481fc5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-45c4613e-4dde-4ff5-8ed8-ae0ee0a5dedf,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-15989844-72ee-440c-a0ed-143a01886512,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-768239874-172.17.0.13-1595996572777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45303,DS-8123738c-def6-4208-8142-aaaf7b30d483,DISK], DatanodeInfoWithStorage[127.0.0.1:42191,DS-12f5d7d9-2821-443a-b1ac-9ad61d33ad4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-7017b976-3e03-4e13-8d2b-5312e257afbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43891,DS-299bc5df-603d-4391-8165-a47cebcdbe0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-57bd22e7-eb3d-4053-ba85-c7a12b6975b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-6562bddf-a35f-4007-a48b-7c49a481fc5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-45c4613e-4dde-4ff5-8ed8-ae0ee0a5dedf,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-15989844-72ee-440c-a0ed-143a01886512,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-790178902-172.17.0.13-1595996651212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33212,DS-889eb612-95bd-44cc-8236-ea934ffb06e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-4b2d9826-f0a6-4e22-8841-d1d214bc48be,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-7e1815af-b2ac-4f2e-aa4f-dbc6360f5f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44180,DS-e63ec68d-ebd0-4584-a665-073cc7077556,DISK], DatanodeInfoWithStorage[127.0.0.1:38406,DS-4687f17d-b6dc-406d-8953-3bdad2350458,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-aa1369de-d58d-4c10-b4bc-1f76835f0649,DISK], DatanodeInfoWithStorage[127.0.0.1:39418,DS-56e13e0f-f503-4a6a-97df-80e7356fbe1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-a2398186-1661-41c3-bc1b-43c3ae87f4d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-790178902-172.17.0.13-1595996651212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33212,DS-889eb612-95bd-44cc-8236-ea934ffb06e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-4b2d9826-f0a6-4e22-8841-d1d214bc48be,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-7e1815af-b2ac-4f2e-aa4f-dbc6360f5f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44180,DS-e63ec68d-ebd0-4584-a665-073cc7077556,DISK], DatanodeInfoWithStorage[127.0.0.1:38406,DS-4687f17d-b6dc-406d-8953-3bdad2350458,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-aa1369de-d58d-4c10-b4bc-1f76835f0649,DISK], DatanodeInfoWithStorage[127.0.0.1:39418,DS-56e13e0f-f503-4a6a-97df-80e7356fbe1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-a2398186-1661-41c3-bc1b-43c3ae87f4d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-643995655-172.17.0.13-1595996804248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38713,DS-fc1d15d0-08a7-4c3b-bf34-4160ff05c204,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-d7ef8d3d-8918-4522-a6d2-490eca80de80,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-edc93279-c470-4420-bc6b-21d3ab406823,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-442c6784-f78b-457f-a614-23c255f665ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-60a3f275-578e-48e6-9b76-fbcac6ceb8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36537,DS-6b6ee369-46fd-41e5-bf99-ee49ef546350,DISK], DatanodeInfoWithStorage[127.0.0.1:40111,DS-a58d9a76-03d7-43eb-8e02-27ac9dc0baf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-cc205500-4d59-4540-b2f2-d461a4e0564e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-643995655-172.17.0.13-1595996804248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38713,DS-fc1d15d0-08a7-4c3b-bf34-4160ff05c204,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-d7ef8d3d-8918-4522-a6d2-490eca80de80,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-edc93279-c470-4420-bc6b-21d3ab406823,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-442c6784-f78b-457f-a614-23c255f665ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-60a3f275-578e-48e6-9b76-fbcac6ceb8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36537,DS-6b6ee369-46fd-41e5-bf99-ee49ef546350,DISK], DatanodeInfoWithStorage[127.0.0.1:40111,DS-a58d9a76-03d7-43eb-8e02-27ac9dc0baf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-cc205500-4d59-4540-b2f2-d461a4e0564e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1154216604-172.17.0.13-1595996921173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44230,DS-f0e034ef-f3c1-47e1-bb4a-523341cce846,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-8d88f8a4-1e4a-4f98-9342-c6a10016659e,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-9732d7a9-018d-4506-bf23-29ae80a6792c,DISK], DatanodeInfoWithStorage[127.0.0.1:35919,DS-53e7e18e-1267-4119-be0b-9609640f1cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-aa45f5ee-0360-479a-8711-c064a6c4df89,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-e80f3359-b87a-484d-b91b-94d0953607ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-760e1df9-1476-41fb-81ee-67e8698938d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-5fd79b31-6832-481a-ac78-84d5c0ad7cb3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1154216604-172.17.0.13-1595996921173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44230,DS-f0e034ef-f3c1-47e1-bb4a-523341cce846,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-8d88f8a4-1e4a-4f98-9342-c6a10016659e,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-9732d7a9-018d-4506-bf23-29ae80a6792c,DISK], DatanodeInfoWithStorage[127.0.0.1:35919,DS-53e7e18e-1267-4119-be0b-9609640f1cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-aa45f5ee-0360-479a-8711-c064a6c4df89,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-e80f3359-b87a-484d-b91b-94d0953607ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-760e1df9-1476-41fb-81ee-67e8698938d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-5fd79b31-6832-481a-ac78-84d5c0ad7cb3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-516403042-172.17.0.13-1595997030051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33389,DS-623d4d61-15b9-4e49-9f6a-38f1c7616402,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-cacd2c20-da4e-4212-978a-c491ee47fdd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35560,DS-edbb1823-b82a-4341-b305-1df5dce82ece,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-cc0fdcf7-7c5f-4747-aaa8-510209d3ecd5,DISK], DatanodeInfoWithStorage[127.0.0.1:36044,DS-24b7a306-4d9d-45ad-b6b6-97ea56a6067e,DISK], DatanodeInfoWithStorage[127.0.0.1:41463,DS-e49777a8-ab92-4f01-a4a2-8b0e17fbf718,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-5159cb58-dfb4-4327-baeb-46835d579962,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-3cf48496-2aab-4c9a-811c-638c03d8a72a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-516403042-172.17.0.13-1595997030051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33389,DS-623d4d61-15b9-4e49-9f6a-38f1c7616402,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-cacd2c20-da4e-4212-978a-c491ee47fdd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35560,DS-edbb1823-b82a-4341-b305-1df5dce82ece,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-cc0fdcf7-7c5f-4747-aaa8-510209d3ecd5,DISK], DatanodeInfoWithStorage[127.0.0.1:36044,DS-24b7a306-4d9d-45ad-b6b6-97ea56a6067e,DISK], DatanodeInfoWithStorage[127.0.0.1:41463,DS-e49777a8-ab92-4f01-a4a2-8b0e17fbf718,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-5159cb58-dfb4-4327-baeb-46835d579962,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-3cf48496-2aab-4c9a-811c-638c03d8a72a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1288338865-172.17.0.13-1595997069061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43526,DS-1f21cafc-31b9-4778-9303-707018b2bf70,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-432b5d61-023e-4b5a-8efe-e4345a79a896,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-9d81961e-8808-4957-98e2-a887692497b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38132,DS-0570f1d9-c4dd-4991-8866-018987fb7dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-938c334c-6d11-4d21-bacd-d7bb5607b54c,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-69a42989-1af2-47a7-b0ce-46578b7e4dde,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-869f9950-3093-4192-90ff-36a6041c2953,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-31954f1b-1184-4934-bef5-6cc6ce56f8ad,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1288338865-172.17.0.13-1595997069061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43526,DS-1f21cafc-31b9-4778-9303-707018b2bf70,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-432b5d61-023e-4b5a-8efe-e4345a79a896,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-9d81961e-8808-4957-98e2-a887692497b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38132,DS-0570f1d9-c4dd-4991-8866-018987fb7dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-938c334c-6d11-4d21-bacd-d7bb5607b54c,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-69a42989-1af2-47a7-b0ce-46578b7e4dde,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-869f9950-3093-4192-90ff-36a6041c2953,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-31954f1b-1184-4934-bef5-6cc6ce56f8ad,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1152816376-172.17.0.13-1595997290318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37326,DS-e6c4dc6e-c6a3-49de-90c9-a695b4da7815,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-2957788c-b171-48b2-80a6-fda5a54948fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-842a5d72-e135-4f01-a989-405bd055bfcc,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-d71b5d40-c70e-4325-a63a-69b743df1fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-f5188c34-416b-4532-b5ff-b1c6d879fd59,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-ca74526c-f1b8-43d6-9f1e-071451761a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-d153f646-4e30-44de-ba57-b260c79f4fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-4219cff0-50c0-4bea-b2dd-016bb8517941,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1152816376-172.17.0.13-1595997290318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37326,DS-e6c4dc6e-c6a3-49de-90c9-a695b4da7815,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-2957788c-b171-48b2-80a6-fda5a54948fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-842a5d72-e135-4f01-a989-405bd055bfcc,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-d71b5d40-c70e-4325-a63a-69b743df1fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-f5188c34-416b-4532-b5ff-b1c6d879fd59,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-ca74526c-f1b8-43d6-9f1e-071451761a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-d153f646-4e30-44de-ba57-b260c79f4fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-4219cff0-50c0-4bea-b2dd-016bb8517941,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1969341714-172.17.0.13-1595997360922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42923,DS-90cdd824-e5ac-4429-89b6-c284ae6a277f,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-58fc9457-10be-49a7-a6bc-2103eb131887,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-304ee277-0662-4569-852f-5aea0ec93fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-223bd025-d7e4-4883-a978-160f26aa8915,DISK], DatanodeInfoWithStorage[127.0.0.1:40449,DS-59bb26bd-5607-462a-9b98-87c5b7b7d82a,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-e8fec121-123b-4ba6-a811-33804d5d7c25,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-7da82f72-37db-47b3-80c3-128e7989c4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-685df806-b22c-4a18-953f-a2e6e7f4e9f7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1969341714-172.17.0.13-1595997360922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42923,DS-90cdd824-e5ac-4429-89b6-c284ae6a277f,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-58fc9457-10be-49a7-a6bc-2103eb131887,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-304ee277-0662-4569-852f-5aea0ec93fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-223bd025-d7e4-4883-a978-160f26aa8915,DISK], DatanodeInfoWithStorage[127.0.0.1:40449,DS-59bb26bd-5607-462a-9b98-87c5b7b7d82a,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-e8fec121-123b-4ba6-a811-33804d5d7c25,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-7da82f72-37db-47b3-80c3-128e7989c4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-685df806-b22c-4a18-953f-a2e6e7f4e9f7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-614273730-172.17.0.13-1595997530519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43195,DS-b739779f-5ab9-4586-8b05-1e3c2dc738a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46396,DS-c8d95ba0-6367-4749-9291-8d3c0b79874c,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-47b5dd27-5378-4614-af89-95dccdc022b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-cf9fca5f-f7ba-4c38-9912-69c99a8fba94,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-6ebc99f3-3611-48ea-a4f3-e454b522a976,DISK], DatanodeInfoWithStorage[127.0.0.1:36783,DS-6fe455c1-804f-479f-827c-a09ebbe90ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-16d1d7ad-415a-4a92-bc06-24f591741bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-0aba4caf-ea09-4409-939b-ffd4014a7667,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-614273730-172.17.0.13-1595997530519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43195,DS-b739779f-5ab9-4586-8b05-1e3c2dc738a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46396,DS-c8d95ba0-6367-4749-9291-8d3c0b79874c,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-47b5dd27-5378-4614-af89-95dccdc022b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-cf9fca5f-f7ba-4c38-9912-69c99a8fba94,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-6ebc99f3-3611-48ea-a4f3-e454b522a976,DISK], DatanodeInfoWithStorage[127.0.0.1:36783,DS-6fe455c1-804f-479f-827c-a09ebbe90ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-16d1d7ad-415a-4a92-bc06-24f591741bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-0aba4caf-ea09-4409-939b-ffd4014a7667,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-895239054-172.17.0.13-1595997821184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45326,DS-ac615000-c97a-40cf-8f29-f37d01b1a670,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-89815f1b-ef9d-49a4-b6c9-5e86b3edd1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-b6133026-0028-4679-b3f3-18ee74371326,DISK], DatanodeInfoWithStorage[127.0.0.1:37685,DS-4f4e3711-ff6b-4462-b4e5-ab2363bac3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-8e83c2a4-959c-456c-8760-716cde443ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-67ef1df0-ece1-4174-bbd5-9f8f60b7232b,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-aff7be0c-447f-4ffc-8302-91ec21971cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-f1c78579-322f-4b4d-b267-b6106e7aaf9e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-895239054-172.17.0.13-1595997821184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45326,DS-ac615000-c97a-40cf-8f29-f37d01b1a670,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-89815f1b-ef9d-49a4-b6c9-5e86b3edd1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-b6133026-0028-4679-b3f3-18ee74371326,DISK], DatanodeInfoWithStorage[127.0.0.1:37685,DS-4f4e3711-ff6b-4462-b4e5-ab2363bac3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-8e83c2a4-959c-456c-8760-716cde443ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-67ef1df0-ece1-4174-bbd5-9f8f60b7232b,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-aff7be0c-447f-4ffc-8302-91ec21971cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-f1c78579-322f-4b4d-b267-b6106e7aaf9e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 1
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-319181433-172.17.0.13-1595997854382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41443,DS-fe2845e1-3656-4985-9ea2-fc2f1aef7f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-09dc8263-ed9c-40a7-aed0-a8945d10f728,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-6ee27611-644d-41f7-9177-47c894ce212f,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-af9e22a5-d99a-4ecd-bebb-ada7d7fd418b,DISK], DatanodeInfoWithStorage[127.0.0.1:35136,DS-60314600-0d9f-425c-8def-6751b2ff3ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-8c4e281b-841f-4a6c-89f5-7e8689d8ff33,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-452c99c4-3dcc-47cc-aa47-52ffbcac8aed,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-c2805555-06f5-4f93-831a-22e3fd176d29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-319181433-172.17.0.13-1595997854382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41443,DS-fe2845e1-3656-4985-9ea2-fc2f1aef7f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-09dc8263-ed9c-40a7-aed0-a8945d10f728,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-6ee27611-644d-41f7-9177-47c894ce212f,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-af9e22a5-d99a-4ecd-bebb-ada7d7fd418b,DISK], DatanodeInfoWithStorage[127.0.0.1:35136,DS-60314600-0d9f-425c-8def-6751b2ff3ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-8c4e281b-841f-4a6c-89f5-7e8689d8ff33,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-452c99c4-3dcc-47cc-aa47-52ffbcac8aed,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-c2805555-06f5-4f93-831a-22e3fd176d29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 23 out of 50
result: false positive !!!
Total execution time in seconds : 5514
