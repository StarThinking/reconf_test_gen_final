reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1107767379-172.17.0.19-1595932996273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46449,DS-e8a30497-4266-4e60-8f59-d5ae6c3bdc77,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-37e2b91a-2e55-44ae-8c04-90633faab328,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-1be7d895-a949-4767-b383-08e8f181b8af,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-65c59aae-884f-4f4f-bd34-3880191cd4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-8a714023-a2e6-44ad-8e9b-fd5522181662,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-3e85929c-89e5-4c4c-b79c-717784e30786,DISK], DatanodeInfoWithStorage[127.0.0.1:46534,DS-4c3c0fcc-bf19-4d0d-a2fa-d87ec424b122,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-8b3b2a24-d001-48a6-b035-f0278e54ab56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1107767379-172.17.0.19-1595932996273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46449,DS-e8a30497-4266-4e60-8f59-d5ae6c3bdc77,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-37e2b91a-2e55-44ae-8c04-90633faab328,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-1be7d895-a949-4767-b383-08e8f181b8af,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-65c59aae-884f-4f4f-bd34-3880191cd4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-8a714023-a2e6-44ad-8e9b-fd5522181662,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-3e85929c-89e5-4c4c-b79c-717784e30786,DISK], DatanodeInfoWithStorage[127.0.0.1:46534,DS-4c3c0fcc-bf19-4d0d-a2fa-d87ec424b122,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-8b3b2a24-d001-48a6-b035-f0278e54ab56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-924267410-172.17.0.19-1595933995504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43623,DS-074d1287-8d7d-4e6e-845e-09ce3f7e0245,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-c81f759d-8b83-4b46-8231-cd39bceb5ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-2ee23fd2-6e6e-4514-9948-15e3f8c6bbff,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-f5b09e5f-40e0-4a4e-b02d-2cbc2e6d7f92,DISK], DatanodeInfoWithStorage[127.0.0.1:40638,DS-75563d69-84c4-4e94-a264-e16be0745692,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-f91b8383-81ea-432a-91b1-6eef02a807c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-4fe2efaf-393f-44ad-9c46-b1d7249cbcca,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-108e0ff1-03c4-4815-8516-fc356fb877c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-924267410-172.17.0.19-1595933995504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43623,DS-074d1287-8d7d-4e6e-845e-09ce3f7e0245,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-c81f759d-8b83-4b46-8231-cd39bceb5ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-2ee23fd2-6e6e-4514-9948-15e3f8c6bbff,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-f5b09e5f-40e0-4a4e-b02d-2cbc2e6d7f92,DISK], DatanodeInfoWithStorage[127.0.0.1:40638,DS-75563d69-84c4-4e94-a264-e16be0745692,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-f91b8383-81ea-432a-91b1-6eef02a807c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-4fe2efaf-393f-44ad-9c46-b1d7249cbcca,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-108e0ff1-03c4-4815-8516-fc356fb877c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1644946240-172.17.0.19-1595934030259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46831,DS-259ec506-d7f2-4db1-86d6-0c04c0c6b5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-d35f6f95-f5c1-45a7-a04b-1c644163973b,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-1b0d60e1-5c1e-43b8-a12a-e79850628c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-dec5314b-85f2-4f36-a403-18ea34f67232,DISK], DatanodeInfoWithStorage[127.0.0.1:46488,DS-c09fb9ac-c94f-4f48-a94b-7f3bab5389f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-1ab467de-0734-484d-b54a-e82267a6d520,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-e9292744-58bb-4ad9-a7f3-6ef2f26fba0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-58734ce8-2ed6-4c05-a458-36f93405bdb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1644946240-172.17.0.19-1595934030259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46831,DS-259ec506-d7f2-4db1-86d6-0c04c0c6b5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-d35f6f95-f5c1-45a7-a04b-1c644163973b,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-1b0d60e1-5c1e-43b8-a12a-e79850628c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-dec5314b-85f2-4f36-a403-18ea34f67232,DISK], DatanodeInfoWithStorage[127.0.0.1:46488,DS-c09fb9ac-c94f-4f48-a94b-7f3bab5389f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-1ab467de-0734-484d-b54a-e82267a6d520,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-e9292744-58bb-4ad9-a7f3-6ef2f26fba0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-58734ce8-2ed6-4c05-a458-36f93405bdb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-324648499-172.17.0.19-1595934874675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35786,DS-39802320-a6f0-4e7e-a23a-520a2003a49c,DISK], DatanodeInfoWithStorage[127.0.0.1:38789,DS-ea0218be-4d33-47df-9d56-db59a212ad1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-99588437-329e-40c4-a217-3773297e8e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-d8e2c344-e2f3-4b52-8abf-e232b5cd4f00,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-c873e9d6-290a-43b1-99d0-2af5145d707d,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-ada16948-e56c-4085-a6ce-66027624cd29,DISK], DatanodeInfoWithStorage[127.0.0.1:40964,DS-eb28978a-a35d-4fb1-886a-b73d0e8e41b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41379,DS-87b4665f-b5b7-4541-af13-76a4d557397c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-324648499-172.17.0.19-1595934874675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35786,DS-39802320-a6f0-4e7e-a23a-520a2003a49c,DISK], DatanodeInfoWithStorage[127.0.0.1:38789,DS-ea0218be-4d33-47df-9d56-db59a212ad1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-99588437-329e-40c4-a217-3773297e8e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-d8e2c344-e2f3-4b52-8abf-e232b5cd4f00,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-c873e9d6-290a-43b1-99d0-2af5145d707d,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-ada16948-e56c-4085-a6ce-66027624cd29,DISK], DatanodeInfoWithStorage[127.0.0.1:40964,DS-eb28978a-a35d-4fb1-886a-b73d0e8e41b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41379,DS-87b4665f-b5b7-4541-af13-76a4d557397c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1652100146-172.17.0.19-1595934956282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40920,DS-83e46db1-4bd5-4c24-8fe8-3281aafb465b,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-50421f9a-42c5-46ed-964a-43cf3b12c7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-8660b58a-8307-4f25-a1c1-9854396b1745,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-09e2b835-dbbb-4fc7-9e44-929a21fce5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-eeeb949b-e66f-43b8-bd8f-ff23bd2b11f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42934,DS-cecabec5-d3c0-401f-b22a-a4b7f57ac180,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-785a4c9e-663d-422d-953c-fa7b7db213a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38591,DS-c96f6699-d29a-4e91-b411-44fdb89c0298,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1652100146-172.17.0.19-1595934956282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40920,DS-83e46db1-4bd5-4c24-8fe8-3281aafb465b,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-50421f9a-42c5-46ed-964a-43cf3b12c7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-8660b58a-8307-4f25-a1c1-9854396b1745,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-09e2b835-dbbb-4fc7-9e44-929a21fce5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-eeeb949b-e66f-43b8-bd8f-ff23bd2b11f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42934,DS-cecabec5-d3c0-401f-b22a-a4b7f57ac180,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-785a4c9e-663d-422d-953c-fa7b7db213a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38591,DS-c96f6699-d29a-4e91-b411-44fdb89c0298,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314498846-172.17.0.19-1595935001703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38767,DS-15c28f99-2545-46c2-b4eb-53e5fe8520eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39634,DS-f76b57b6-7725-4830-8a16-e86f46ec3a37,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-5122e24e-88f1-468a-9e70-7125c1805453,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-eb9ed150-76f9-45bf-a0f6-1bec020d0618,DISK], DatanodeInfoWithStorage[127.0.0.1:40487,DS-1a43542c-8140-43bf-b5df-836daa444d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-aeb8e260-9e24-4b52-9b4b-a811784c7c89,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-22760839-008e-4e4b-8baa-7a3b937356e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-e319ef76-71aa-46e1-9ae6-0b5ba8c9ecd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314498846-172.17.0.19-1595935001703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38767,DS-15c28f99-2545-46c2-b4eb-53e5fe8520eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39634,DS-f76b57b6-7725-4830-8a16-e86f46ec3a37,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-5122e24e-88f1-468a-9e70-7125c1805453,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-eb9ed150-76f9-45bf-a0f6-1bec020d0618,DISK], DatanodeInfoWithStorage[127.0.0.1:40487,DS-1a43542c-8140-43bf-b5df-836daa444d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-aeb8e260-9e24-4b52-9b4b-a811784c7c89,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-22760839-008e-4e4b-8baa-7a3b937356e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-e319ef76-71aa-46e1-9ae6-0b5ba8c9ecd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-547289308-172.17.0.19-1595935274216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44237,DS-0dfb469c-65cc-4f1f-816f-272240cbcd1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42040,DS-d2050af2-f813-4a96-a771-0f5b1bf7f947,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-3b9a4d08-4d36-4314-a843-63f6aea0b433,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-b71fbb09-23bb-4032-953f-8f65880812aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-68b8d7b2-9cbf-4965-952b-bf2dfda6f521,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-2407b1a9-9af3-4257-b569-c4e467eec6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-565044f6-ddd9-41cc-9aca-ff75920eef70,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-5bd0ea80-ad45-49c9-87a1-77246ffcff1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-547289308-172.17.0.19-1595935274216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44237,DS-0dfb469c-65cc-4f1f-816f-272240cbcd1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42040,DS-d2050af2-f813-4a96-a771-0f5b1bf7f947,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-3b9a4d08-4d36-4314-a843-63f6aea0b433,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-b71fbb09-23bb-4032-953f-8f65880812aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-68b8d7b2-9cbf-4965-952b-bf2dfda6f521,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-2407b1a9-9af3-4257-b569-c4e467eec6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-565044f6-ddd9-41cc-9aca-ff75920eef70,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-5bd0ea80-ad45-49c9-87a1-77246ffcff1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1813879041-172.17.0.19-1595935312611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45017,DS-10491f4d-e7bf-4883-8cf8-59ac2627edaf,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-a2b61920-f014-4234-a13e-9368845fb121,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-bb2ac499-05c6-4e6a-9070-d149b24678a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46025,DS-8c8a387d-6ed0-4190-bca3-73b94f221fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-7c6f9655-6862-4b35-859a-18d10419b6df,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-9bc1d2d3-2eb3-40bb-bb8f-bf25151cdfa8,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-cc87dd21-5431-409e-b178-0dfb92ecc115,DISK], DatanodeInfoWithStorage[127.0.0.1:43617,DS-84eecbd3-f704-4731-83d3-602ea6cfec73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1813879041-172.17.0.19-1595935312611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45017,DS-10491f4d-e7bf-4883-8cf8-59ac2627edaf,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-a2b61920-f014-4234-a13e-9368845fb121,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-bb2ac499-05c6-4e6a-9070-d149b24678a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46025,DS-8c8a387d-6ed0-4190-bca3-73b94f221fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-7c6f9655-6862-4b35-859a-18d10419b6df,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-9bc1d2d3-2eb3-40bb-bb8f-bf25151cdfa8,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-cc87dd21-5431-409e-b178-0dfb92ecc115,DISK], DatanodeInfoWithStorage[127.0.0.1:43617,DS-84eecbd3-f704-4731-83d3-602ea6cfec73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424136806-172.17.0.19-1595935771624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46236,DS-0571c3c6-16c5-470f-bb7c-02cc9fa92d06,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-35a724bd-5d04-4436-972b-575b5dfdbe03,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-007e3ea0-3bb0-4e7c-b919-9861694bed64,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-47b20b00-eb91-4492-9007-9e8597e648f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-67ebe8e7-a327-4345-8c54-99ae2ae9ac99,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-f3b0934c-7a42-4d24-b2d5-01afae9efedd,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-bb16e15f-46d1-43ca-bd71-a932f7edf18b,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-28996de3-6cf3-417f-a63b-ec4106688c9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424136806-172.17.0.19-1595935771624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46236,DS-0571c3c6-16c5-470f-bb7c-02cc9fa92d06,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-35a724bd-5d04-4436-972b-575b5dfdbe03,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-007e3ea0-3bb0-4e7c-b919-9861694bed64,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-47b20b00-eb91-4492-9007-9e8597e648f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-67ebe8e7-a327-4345-8c54-99ae2ae9ac99,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-f3b0934c-7a42-4d24-b2d5-01afae9efedd,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-bb16e15f-46d1-43ca-bd71-a932f7edf18b,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-28996de3-6cf3-417f-a63b-ec4106688c9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1910745398-172.17.0.19-1595936541543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43016,DS-1fa770e1-3917-4374-9656-e8e42bc816bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-36aaa720-1ef1-4653-bb07-7c0cf7055353,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-a9a7424a-3a74-430e-b8bb-7c2de8adbe64,DISK], DatanodeInfoWithStorage[127.0.0.1:39357,DS-d8d471c7-f50f-4995-80f8-4ef1ca340383,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-d061d82a-e41e-411f-87dc-9246dee99ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-652e5361-8a5c-4696-abb0-8481ba09ce0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40216,DS-dba772e8-b6be-4c78-ba88-caf67a51a53b,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-fec161b5-68ed-4ff0-9f0e-f730925e3832,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1910745398-172.17.0.19-1595936541543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43016,DS-1fa770e1-3917-4374-9656-e8e42bc816bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-36aaa720-1ef1-4653-bb07-7c0cf7055353,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-a9a7424a-3a74-430e-b8bb-7c2de8adbe64,DISK], DatanodeInfoWithStorage[127.0.0.1:39357,DS-d8d471c7-f50f-4995-80f8-4ef1ca340383,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-d061d82a-e41e-411f-87dc-9246dee99ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-652e5361-8a5c-4696-abb0-8481ba09ce0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40216,DS-dba772e8-b6be-4c78-ba88-caf67a51a53b,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-fec161b5-68ed-4ff0-9f0e-f730925e3832,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1673971094-172.17.0.19-1595937127182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42986,DS-6e7e8f49-0a0c-4c73-88a4-144770dae912,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-ddeff7c0-5e31-4666-b428-8c603ba80b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-8bd85541-903f-4afa-a806-950fa6168bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-03e62dc4-e5a5-4453-8f85-67e6b1e2ee5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-96e5eba6-5388-4853-b926-698787761902,DISK], DatanodeInfoWithStorage[127.0.0.1:45690,DS-4c80c3fd-946a-4741-b38f-ba7375d83201,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-92e65889-9ec9-4e7c-a066-24c202f2b8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-e283d481-d40a-4762-936b-881b8fcdada5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1673971094-172.17.0.19-1595937127182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42986,DS-6e7e8f49-0a0c-4c73-88a4-144770dae912,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-ddeff7c0-5e31-4666-b428-8c603ba80b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-8bd85541-903f-4afa-a806-950fa6168bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-03e62dc4-e5a5-4453-8f85-67e6b1e2ee5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-96e5eba6-5388-4853-b926-698787761902,DISK], DatanodeInfoWithStorage[127.0.0.1:45690,DS-4c80c3fd-946a-4741-b38f-ba7375d83201,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-92e65889-9ec9-4e7c-a066-24c202f2b8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-e283d481-d40a-4762-936b-881b8fcdada5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: false positive !!!
Total execution time in seconds : 5516
