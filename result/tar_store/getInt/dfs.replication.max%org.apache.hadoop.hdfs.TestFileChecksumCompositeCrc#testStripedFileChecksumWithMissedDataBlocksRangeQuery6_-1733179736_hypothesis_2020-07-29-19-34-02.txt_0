reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-563394433-172.17.0.21-1596051404213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34663,DS-f9cf0bf3-56c3-466b-a11f-934cc7fcbdbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-836232de-d50d-4e6f-a76d-c1af4a0492fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-0a7d74c0-9efe-4b1d-a14c-265181694156,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-364627e1-151c-470e-9bde-e56ef507f964,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-da621000-2ca9-4745-9c76-e57fa16bb9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-2d8c3bda-0cb4-4cd7-9627-d5da35f2dbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:41710,DS-28953497-209a-40d3-b8b5-022ac2070f54,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-b06a3d78-3fb6-4768-9d97-628367ee0970,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-563394433-172.17.0.21-1596051404213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34663,DS-f9cf0bf3-56c3-466b-a11f-934cc7fcbdbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-836232de-d50d-4e6f-a76d-c1af4a0492fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-0a7d74c0-9efe-4b1d-a14c-265181694156,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-364627e1-151c-470e-9bde-e56ef507f964,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-da621000-2ca9-4745-9c76-e57fa16bb9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-2d8c3bda-0cb4-4cd7-9627-d5da35f2dbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:41710,DS-28953497-209a-40d3-b8b5-022ac2070f54,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-b06a3d78-3fb6-4768-9d97-628367ee0970,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2009011305-172.17.0.21-1596051543910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43528,DS-36aa6a09-d46e-4b92-8f5c-7de6564b85b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-b63cfc51-5b91-45d3-bbf6-aa53010293df,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-acda7710-13e0-4415-ac0f-7e263ed7d912,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-a829dc03-8ce8-4d14-bb7d-6a40ada61a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-5f427783-512d-4b7c-a6da-503c0725500e,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-017be99f-5a58-403f-a3e2-5f9150a0a0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46138,DS-8551ffee-ca73-447b-a89f-c4817fde2521,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-1bca3a64-a1f1-4334-ac94-b1acb5e4654f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2009011305-172.17.0.21-1596051543910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43528,DS-36aa6a09-d46e-4b92-8f5c-7de6564b85b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-b63cfc51-5b91-45d3-bbf6-aa53010293df,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-acda7710-13e0-4415-ac0f-7e263ed7d912,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-a829dc03-8ce8-4d14-bb7d-6a40ada61a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-5f427783-512d-4b7c-a6da-503c0725500e,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-017be99f-5a58-403f-a3e2-5f9150a0a0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46138,DS-8551ffee-ca73-447b-a89f-c4817fde2521,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-1bca3a64-a1f1-4334-ac94-b1acb5e4654f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-268615149-172.17.0.21-1596051730760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33914,DS-3f6ab05a-fb97-441e-8dc7-142a05c67009,DISK], DatanodeInfoWithStorage[127.0.0.1:41117,DS-66c285d9-dece-45b4-bdd7-378dc9379192,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-c8df52d6-81fa-457f-b055-2f4f4b400b13,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-ff842eb7-3fef-474a-a032-acb840f82e56,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-a8b2958b-8eca-4a01-a94d-dea69182c7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-daa92b5a-3de1-4ce1-b08d-0c43301a13f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34244,DS-736a7507-4261-4f4a-ae57-e2bec2275533,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-e8f28bd9-d130-4218-bb07-66b0ac44033b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-268615149-172.17.0.21-1596051730760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33914,DS-3f6ab05a-fb97-441e-8dc7-142a05c67009,DISK], DatanodeInfoWithStorage[127.0.0.1:41117,DS-66c285d9-dece-45b4-bdd7-378dc9379192,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-c8df52d6-81fa-457f-b055-2f4f4b400b13,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-ff842eb7-3fef-474a-a032-acb840f82e56,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-a8b2958b-8eca-4a01-a94d-dea69182c7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-daa92b5a-3de1-4ce1-b08d-0c43301a13f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34244,DS-736a7507-4261-4f4a-ae57-e2bec2275533,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-e8f28bd9-d130-4218-bb07-66b0ac44033b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1207432434-172.17.0.21-1596051932818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43265,DS-bad0d2ce-b65e-4a75-9d80-f88216d41d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40199,DS-54ab823e-3da0-4a43-8982-cad98a487201,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-d8137298-a10a-4904-8ba5-ee6cb91f33be,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-d563a14e-f2ae-4383-95fe-f7f34d8183ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-65e8e20e-3019-4af7-a000-e23e02e39d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-054aa7c0-200f-48e5-8a51-d31b894dc99d,DISK], DatanodeInfoWithStorage[127.0.0.1:37325,DS-859a9cb4-6fa8-42c4-b3fd-be5272ebc44c,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-595c528c-6bcc-40ec-af52-29a944b2a1c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1207432434-172.17.0.21-1596051932818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43265,DS-bad0d2ce-b65e-4a75-9d80-f88216d41d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40199,DS-54ab823e-3da0-4a43-8982-cad98a487201,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-d8137298-a10a-4904-8ba5-ee6cb91f33be,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-d563a14e-f2ae-4383-95fe-f7f34d8183ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-65e8e20e-3019-4af7-a000-e23e02e39d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-054aa7c0-200f-48e5-8a51-d31b894dc99d,DISK], DatanodeInfoWithStorage[127.0.0.1:37325,DS-859a9cb4-6fa8-42c4-b3fd-be5272ebc44c,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-595c528c-6bcc-40ec-af52-29a944b2a1c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2107815617-172.17.0.21-1596052109183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45108,DS-fa79fc32-9d77-49bb-9226-003b57082ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:40205,DS-61f9a781-155e-4e68-8dc3-dc7213bf89a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36902,DS-67b907ba-9900-4b71-b23e-efebc4607323,DISK], DatanodeInfoWithStorage[127.0.0.1:37234,DS-d6768387-aeb8-4b66-8e84-7e2f4fdf5f26,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-34999be1-72bf-4136-bddd-65caef44ca5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-b4ce6af1-f04a-43a4-b1e7-c56723fab254,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-d9c2e709-2190-4e20-978e-527d2932aba6,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-55a2ab48-e552-480a-bd7e-924af65ef395,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2107815617-172.17.0.21-1596052109183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45108,DS-fa79fc32-9d77-49bb-9226-003b57082ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:40205,DS-61f9a781-155e-4e68-8dc3-dc7213bf89a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36902,DS-67b907ba-9900-4b71-b23e-efebc4607323,DISK], DatanodeInfoWithStorage[127.0.0.1:37234,DS-d6768387-aeb8-4b66-8e84-7e2f4fdf5f26,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-34999be1-72bf-4136-bddd-65caef44ca5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-b4ce6af1-f04a-43a4-b1e7-c56723fab254,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-d9c2e709-2190-4e20-978e-527d2932aba6,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-55a2ab48-e552-480a-bd7e-924af65ef395,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1658809216-172.17.0.21-1596052251351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41991,DS-969bb67a-1851-4807-bff9-89e2301d97c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33492,DS-2bcb8f3f-5265-4d26-b87d-13d2c6991c73,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-15a0cf0b-8040-4076-9eae-c4e68d8b13d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-c6276b7c-878f-497f-a825-7e26a5a38d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-84217812-c393-492e-b612-02f060fae855,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-81faeb59-5b10-4131-9ef4-ecb206ec551d,DISK], DatanodeInfoWithStorage[127.0.0.1:41719,DS-cb9222e8-d2dd-4bfa-ba74-67cd7edd626a,DISK], DatanodeInfoWithStorage[127.0.0.1:40685,DS-658f9c03-af22-4017-b35f-d3e40e563a12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1658809216-172.17.0.21-1596052251351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41991,DS-969bb67a-1851-4807-bff9-89e2301d97c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33492,DS-2bcb8f3f-5265-4d26-b87d-13d2c6991c73,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-15a0cf0b-8040-4076-9eae-c4e68d8b13d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-c6276b7c-878f-497f-a825-7e26a5a38d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-84217812-c393-492e-b612-02f060fae855,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-81faeb59-5b10-4131-9ef4-ecb206ec551d,DISK], DatanodeInfoWithStorage[127.0.0.1:41719,DS-cb9222e8-d2dd-4bfa-ba74-67cd7edd626a,DISK], DatanodeInfoWithStorage[127.0.0.1:40685,DS-658f9c03-af22-4017-b35f-d3e40e563a12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-167008822-172.17.0.21-1596052419166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41151,DS-a23a5b61-9d15-41f5-9287-1c4208f48ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-f009a69d-cf38-4bd5-903c-0585056dbf24,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-cb958342-73b5-4aaf-a576-31da84e911e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39844,DS-46c9ff59-e411-474f-89b0-b909d4230d25,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-7b0e1f32-0ced-4987-be0b-37edfbed0e14,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-a169660e-2d21-4e57-a835-582babaafde2,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-537dbd58-e71d-418d-9545-1460dd06bdb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-09dd60a8-4ad7-44a6-aa71-ff24ee319ad7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-167008822-172.17.0.21-1596052419166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41151,DS-a23a5b61-9d15-41f5-9287-1c4208f48ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-f009a69d-cf38-4bd5-903c-0585056dbf24,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-cb958342-73b5-4aaf-a576-31da84e911e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39844,DS-46c9ff59-e411-474f-89b0-b909d4230d25,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-7b0e1f32-0ced-4987-be0b-37edfbed0e14,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-a169660e-2d21-4e57-a835-582babaafde2,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-537dbd58-e71d-418d-9545-1460dd06bdb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-09dd60a8-4ad7-44a6-aa71-ff24ee319ad7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-984451622-172.17.0.21-1596052569465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35691,DS-7d11d9bd-31ae-4d48-a780-3cd4a5725362,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-46cf9e69-4b2a-4ebe-a34c-d276463733a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-6e735d26-72f9-44af-82d0-ebc3a9103c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-16e93040-a035-4ba6-874b-2665d9c7cb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-5d561288-803b-4f66-850c-f04884b032a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-12563a9f-d0db-4a34-a34e-e741186388a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-55129d55-4ab7-40ee-8612-e67fcb12d5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-88128a25-0014-459b-9da0-af1d71960971,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-984451622-172.17.0.21-1596052569465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35691,DS-7d11d9bd-31ae-4d48-a780-3cd4a5725362,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-46cf9e69-4b2a-4ebe-a34c-d276463733a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-6e735d26-72f9-44af-82d0-ebc3a9103c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-16e93040-a035-4ba6-874b-2665d9c7cb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-5d561288-803b-4f66-850c-f04884b032a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-12563a9f-d0db-4a34-a34e-e741186388a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-55129d55-4ab7-40ee-8612-e67fcb12d5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-88128a25-0014-459b-9da0-af1d71960971,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1902415382-172.17.0.21-1596052718103:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38447,DS-049f020b-cb94-4894-ad81-ea3fbb7b35bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-45acc292-3dbb-4c12-9ada-0b18fe0808e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-458edfd8-d20b-46fb-a6d8-9052afc7c1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-29e38a85-11f6-47aa-b31f-64ae59946d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44042,DS-987353b1-b757-44f6-bf5a-95d9e16be0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41862,DS-c17213a0-9d89-40a8-a607-b83f8171c1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-c366555a-87fe-48d0-b343-f017cb111fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-52e83b5a-7e59-47e1-a060-8ff28f86f20e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1902415382-172.17.0.21-1596052718103:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38447,DS-049f020b-cb94-4894-ad81-ea3fbb7b35bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-45acc292-3dbb-4c12-9ada-0b18fe0808e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-458edfd8-d20b-46fb-a6d8-9052afc7c1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-29e38a85-11f6-47aa-b31f-64ae59946d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44042,DS-987353b1-b757-44f6-bf5a-95d9e16be0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41862,DS-c17213a0-9d89-40a8-a607-b83f8171c1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-c366555a-87fe-48d0-b343-f017cb111fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-52e83b5a-7e59-47e1-a060-8ff28f86f20e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1122155791-172.17.0.21-1596052907126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39449,DS-72117f63-dad8-4f9a-919e-4734285abe71,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-17364583-bb02-4fe7-a8d7-c9d64a92c35f,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-272e2b8d-0030-4f5d-988d-b93cee93efe3,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-dd196304-b928-46da-8553-0b29e0e35a70,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-8c82dbf7-b381-4472-88ea-dde89d71020b,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-d8d0d754-d48b-4669-802c-b60e3b17f2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-8aad6dec-0b83-4b49-b791-ff1f4b5d4eee,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-b9fc27f6-5119-4ab5-9673-5db4b4f39172,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1122155791-172.17.0.21-1596052907126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39449,DS-72117f63-dad8-4f9a-919e-4734285abe71,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-17364583-bb02-4fe7-a8d7-c9d64a92c35f,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-272e2b8d-0030-4f5d-988d-b93cee93efe3,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-dd196304-b928-46da-8553-0b29e0e35a70,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-8c82dbf7-b381-4472-88ea-dde89d71020b,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-d8d0d754-d48b-4669-802c-b60e3b17f2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-8aad6dec-0b83-4b49-b791-ff1f4b5d4eee,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-b9fc27f6-5119-4ab5-9673-5db4b4f39172,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1984214777-172.17.0.21-1596052951406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36185,DS-10c0d925-abb2-455a-b109-cff4af82e4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-f92088e2-a13b-49c3-9511-822fd732cf12,DISK], DatanodeInfoWithStorage[127.0.0.1:34854,DS-12059c2a-b0cd-4494-8492-0f45108fa122,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-41574e3b-29d1-415a-9fe0-57624fb11dec,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-485efbdd-395e-4d3a-8471-647a1fde5b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-aa7f0232-55be-4c36-8086-a587e309aba1,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-a5b156af-cf6a-4990-b83a-a631cf4327fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41850,DS-49eb1499-5f9c-4a38-b073-a0a289e434f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1984214777-172.17.0.21-1596052951406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36185,DS-10c0d925-abb2-455a-b109-cff4af82e4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-f92088e2-a13b-49c3-9511-822fd732cf12,DISK], DatanodeInfoWithStorage[127.0.0.1:34854,DS-12059c2a-b0cd-4494-8492-0f45108fa122,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-41574e3b-29d1-415a-9fe0-57624fb11dec,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-485efbdd-395e-4d3a-8471-647a1fde5b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-aa7f0232-55be-4c36-8086-a587e309aba1,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-a5b156af-cf6a-4990-b83a-a631cf4327fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41850,DS-49eb1499-5f9c-4a38-b073-a0a289e434f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1676072756-172.17.0.21-1596053085381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34869,DS-ec70c8c6-df25-4b08-a0aa-f92afb144b77,DISK], DatanodeInfoWithStorage[127.0.0.1:34160,DS-8774384d-8ff2-4b33-8ab8-feff72c5afa2,DISK], DatanodeInfoWithStorage[127.0.0.1:43834,DS-29c6e8c9-1265-4e2c-8337-5b5ce3ec238c,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-a2a9d226-f59b-4423-9e12-a0f743aea47d,DISK], DatanodeInfoWithStorage[127.0.0.1:42312,DS-5f1fd9cb-6e9a-4f32-8709-ba8b1fbba2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-1533deca-768f-44ec-9f86-96fef94c07a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39305,DS-515c18f0-c15e-4eba-b296-b0cdfa9b791b,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-f4c3504b-679d-4501-8ce4-5ffd57ec6498,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1676072756-172.17.0.21-1596053085381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34869,DS-ec70c8c6-df25-4b08-a0aa-f92afb144b77,DISK], DatanodeInfoWithStorage[127.0.0.1:34160,DS-8774384d-8ff2-4b33-8ab8-feff72c5afa2,DISK], DatanodeInfoWithStorage[127.0.0.1:43834,DS-29c6e8c9-1265-4e2c-8337-5b5ce3ec238c,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-a2a9d226-f59b-4423-9e12-a0f743aea47d,DISK], DatanodeInfoWithStorage[127.0.0.1:42312,DS-5f1fd9cb-6e9a-4f32-8709-ba8b1fbba2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-1533deca-768f-44ec-9f86-96fef94c07a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39305,DS-515c18f0-c15e-4eba-b296-b0cdfa9b791b,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-f4c3504b-679d-4501-8ce4-5ffd57ec6498,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391186166-172.17.0.21-1596053193864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33328,DS-fc93d045-db3a-4791-92c4-7e5eb6ac2352,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-f9bac88f-420d-4d63-aed5-e43f727fbef3,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-62598ed0-be58-4ba5-8556-d04cefaa3b66,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-2b71daac-99f3-45a1-bc71-c9e3f69c7e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43842,DS-8809bede-4e6b-4907-8fff-273a1d8772d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-b040c685-d933-4b06-b8d9-b37ce172b31f,DISK], DatanodeInfoWithStorage[127.0.0.1:37676,DS-e20cdf7f-0453-4a26-98f1-f5eda247e8be,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-d6e16c37-fe9b-4a1b-8199-fb8965aad1fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391186166-172.17.0.21-1596053193864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33328,DS-fc93d045-db3a-4791-92c4-7e5eb6ac2352,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-f9bac88f-420d-4d63-aed5-e43f727fbef3,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-62598ed0-be58-4ba5-8556-d04cefaa3b66,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-2b71daac-99f3-45a1-bc71-c9e3f69c7e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43842,DS-8809bede-4e6b-4907-8fff-273a1d8772d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-b040c685-d933-4b06-b8d9-b37ce172b31f,DISK], DatanodeInfoWithStorage[127.0.0.1:37676,DS-e20cdf7f-0453-4a26-98f1-f5eda247e8be,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-d6e16c37-fe9b-4a1b-8199-fb8965aad1fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-407892985-172.17.0.21-1596053370645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38477,DS-70ccb06f-2269-4a8d-b5aa-5d61f928ab07,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-0d80bf57-0fae-47dd-b223-6f154cfaadf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-61bc66d5-504a-42a4-9ed6-ae51db9c63a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-55923d53-c77b-49e4-b853-17dbba30d58e,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-fee891e1-7a29-461e-acad-6f117f007fac,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-a9ed0ff5-8f95-4c14-8f8a-d6597e7e8e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-eec56b81-c8de-4841-a8ae-064563b0089e,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-25bc839e-964c-4ff5-98b5-a523592d6020,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-407892985-172.17.0.21-1596053370645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38477,DS-70ccb06f-2269-4a8d-b5aa-5d61f928ab07,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-0d80bf57-0fae-47dd-b223-6f154cfaadf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-61bc66d5-504a-42a4-9ed6-ae51db9c63a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-55923d53-c77b-49e4-b853-17dbba30d58e,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-fee891e1-7a29-461e-acad-6f117f007fac,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-a9ed0ff5-8f95-4c14-8f8a-d6597e7e8e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-eec56b81-c8de-4841-a8ae-064563b0089e,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-25bc839e-964c-4ff5-98b5-a523592d6020,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-388836016-172.17.0.21-1596053410502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36277,DS-8b6e396c-8ece-401a-847a-9af36787dc61,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-ef9c2a0f-b774-4ebe-8107-61a4262996ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42037,DS-6cffd308-ca5a-4cfd-9bd8-7c069f774a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38646,DS-90b44fc8-5199-490d-9ce5-18f9a26d005d,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-62ae758c-24ff-4f39-8d26-873da999d9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-2a15b6a0-63b0-4981-b6f5-0fac0fa81849,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-bfd08447-5d4a-4fcb-a0ef-585466b8fbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-2594f55a-95e6-4734-aa45-8aa9da0afc51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-388836016-172.17.0.21-1596053410502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36277,DS-8b6e396c-8ece-401a-847a-9af36787dc61,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-ef9c2a0f-b774-4ebe-8107-61a4262996ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42037,DS-6cffd308-ca5a-4cfd-9bd8-7c069f774a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38646,DS-90b44fc8-5199-490d-9ce5-18f9a26d005d,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-62ae758c-24ff-4f39-8d26-873da999d9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-2a15b6a0-63b0-4981-b6f5-0fac0fa81849,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-bfd08447-5d4a-4fcb-a0ef-585466b8fbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-2594f55a-95e6-4734-aa45-8aa9da0afc51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-616404211-172.17.0.21-1596053647108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34066,DS-34667318-3498-4988-91c4-4d4ed87fa43a,DISK], DatanodeInfoWithStorage[127.0.0.1:38148,DS-70b8c3ae-d985-4f7c-9209-a64d8ad5b2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-09ec9a90-fac9-4865-a1b5-84d7788d430d,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-92606516-8c4b-42dc-b8a3-1452eeed8cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-64570dd7-11f2-437e-b5de-f2d5e510e802,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-60bf9dae-24b0-49b4-ae4c-fc91d834b4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-304673b3-c1db-41a3-9129-7707f08ae3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-63380f8b-e85a-4d94-8b01-6fd01fcfc299,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-616404211-172.17.0.21-1596053647108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34066,DS-34667318-3498-4988-91c4-4d4ed87fa43a,DISK], DatanodeInfoWithStorage[127.0.0.1:38148,DS-70b8c3ae-d985-4f7c-9209-a64d8ad5b2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-09ec9a90-fac9-4865-a1b5-84d7788d430d,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-92606516-8c4b-42dc-b8a3-1452eeed8cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-64570dd7-11f2-437e-b5de-f2d5e510e802,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-60bf9dae-24b0-49b4-ae4c-fc91d834b4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-304673b3-c1db-41a3-9129-7707f08ae3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-63380f8b-e85a-4d94-8b01-6fd01fcfc299,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-976159723-172.17.0.21-1596053689091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44445,DS-6906c97d-9105-46bf-9e34-fe1e1bfd29ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-e02e4412-69ea-4478-b62d-c2de69aa9b16,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-015ccf71-819a-4f56-bbc8-66e51fac6cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-9677171f-851f-4fb6-b7ed-07db2455689c,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-b051fed2-758c-4df9-bdee-f36f95985637,DISK], DatanodeInfoWithStorage[127.0.0.1:46149,DS-884ba0c5-5bef-4f49-8b4e-3ed410b8bb17,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-449d4442-3ea8-468d-8c67-bc914252cc47,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-c02c4846-7ee8-43ac-ab12-1aec84198494,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-976159723-172.17.0.21-1596053689091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44445,DS-6906c97d-9105-46bf-9e34-fe1e1bfd29ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-e02e4412-69ea-4478-b62d-c2de69aa9b16,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-015ccf71-819a-4f56-bbc8-66e51fac6cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-9677171f-851f-4fb6-b7ed-07db2455689c,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-b051fed2-758c-4df9-bdee-f36f95985637,DISK], DatanodeInfoWithStorage[127.0.0.1:46149,DS-884ba0c5-5bef-4f49-8b4e-3ed410b8bb17,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-449d4442-3ea8-468d-8c67-bc914252cc47,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-c02c4846-7ee8-43ac-ab12-1aec84198494,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1519848978-172.17.0.21-1596054219534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37544,DS-72d56bb1-1ef6-4ee4-83c4-1e1dc9716973,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-2076e190-24e5-4044-a843-410ecbe7515b,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-dc8e9583-ef14-4e20-8faa-1ee7a391b3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-14675bb1-2029-4810-8e5c-ad35541c37e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-6f73687a-9d1d-4a43-b58b-de247205f3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-d27039ce-3e59-486d-9378-7fb5299842b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-33488c53-4d7c-4a6b-8468-d59faa87f4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-4a3e8c9e-1f61-4d9c-8354-9579317f390b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1519848978-172.17.0.21-1596054219534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37544,DS-72d56bb1-1ef6-4ee4-83c4-1e1dc9716973,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-2076e190-24e5-4044-a843-410ecbe7515b,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-dc8e9583-ef14-4e20-8faa-1ee7a391b3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-14675bb1-2029-4810-8e5c-ad35541c37e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-6f73687a-9d1d-4a43-b58b-de247205f3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-d27039ce-3e59-486d-9378-7fb5299842b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-33488c53-4d7c-4a6b-8468-d59faa87f4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-4a3e8c9e-1f61-4d9c-8354-9579317f390b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-660577037-172.17.0.21-1596054351076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37357,DS-2c20d093-6d8f-4e6c-aa74-e9f1445acc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37367,DS-937645a3-eb45-4ecb-9713-274c95034666,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-15b400b8-530a-40ee-a253-2b3ffa73f3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-386c484e-2187-4492-ab58-16f417cab7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-6f3de6d6-1caf-44ef-9cf8-3baa1d036043,DISK], DatanodeInfoWithStorage[127.0.0.1:42040,DS-d74db28e-1d4b-45f5-b6c6-8e9b2a3847ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-e533157b-3fc3-4c50-b77d-8598bb6adb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37218,DS-79893b74-6fc6-4d5e-b772-187fae2bbeeb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-660577037-172.17.0.21-1596054351076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37357,DS-2c20d093-6d8f-4e6c-aa74-e9f1445acc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37367,DS-937645a3-eb45-4ecb-9713-274c95034666,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-15b400b8-530a-40ee-a253-2b3ffa73f3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-386c484e-2187-4492-ab58-16f417cab7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-6f3de6d6-1caf-44ef-9cf8-3baa1d036043,DISK], DatanodeInfoWithStorage[127.0.0.1:42040,DS-d74db28e-1d4b-45f5-b6c6-8e9b2a3847ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-e533157b-3fc3-4c50-b77d-8598bb6adb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37218,DS-79893b74-6fc6-4d5e-b772-187fae2bbeeb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1265840829-172.17.0.21-1596054412592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39374,DS-a6fb9a21-b92e-4fc8-87c3-646951681a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46094,DS-cea739de-627e-46ec-a953-ae2805322c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-0891cf57-e900-4c4d-89e4-cf4f92cd93ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35919,DS-539a7d9e-6b32-499f-ab58-a7497b4bbc60,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-3440d991-5651-4f2b-9dc5-bf74b5d96d45,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-3a3f310a-6673-4e29-a3ef-02851f66b9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-c883844e-58c2-490b-8208-30978d6e8c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-1948d430-70b0-41f4-9e07-06405c496fd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1265840829-172.17.0.21-1596054412592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39374,DS-a6fb9a21-b92e-4fc8-87c3-646951681a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46094,DS-cea739de-627e-46ec-a953-ae2805322c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-0891cf57-e900-4c4d-89e4-cf4f92cd93ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35919,DS-539a7d9e-6b32-499f-ab58-a7497b4bbc60,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-3440d991-5651-4f2b-9dc5-bf74b5d96d45,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-3a3f310a-6673-4e29-a3ef-02851f66b9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-c883844e-58c2-490b-8208-30978d6e8c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-1948d430-70b0-41f4-9e07-06405c496fd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-600672198-172.17.0.21-1596054686897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45176,DS-ebf48182-ab64-4200-a228-eb48f23c03f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-019db739-6bcf-4302-a252-a88e575926c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-18b4fd8a-d5b5-453c-a95c-e0208637bc17,DISK], DatanodeInfoWithStorage[127.0.0.1:39979,DS-45b1a7fd-dd52-4bad-b512-54839e3c3339,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-e2ffb7cf-2d5e-4054-ae15-3cca7266033d,DISK], DatanodeInfoWithStorage[127.0.0.1:45324,DS-1fdb2a44-6f3a-4e52-9ce0-0a705f3cfbac,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-a9940ad2-fb71-49d7-9bab-d3e6fa44a6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-54dc8f25-a8f6-4652-b6d7-39ece7a02f71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-600672198-172.17.0.21-1596054686897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45176,DS-ebf48182-ab64-4200-a228-eb48f23c03f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-019db739-6bcf-4302-a252-a88e575926c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-18b4fd8a-d5b5-453c-a95c-e0208637bc17,DISK], DatanodeInfoWithStorage[127.0.0.1:39979,DS-45b1a7fd-dd52-4bad-b512-54839e3c3339,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-e2ffb7cf-2d5e-4054-ae15-3cca7266033d,DISK], DatanodeInfoWithStorage[127.0.0.1:45324,DS-1fdb2a44-6f3a-4e52-9ce0-0a705f3cfbac,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-a9940ad2-fb71-49d7-9bab-d3e6fa44a6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-54dc8f25-a8f6-4652-b6d7-39ece7a02f71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1380820943-172.17.0.21-1596055042529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33058,DS-49ffde5c-d152-45c6-9643-ad2eddaf96b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-eeb3d230-f905-49f4-b137-8fa3f5a05315,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-f0c8e4d0-463c-48cd-bd48-c9285be0a826,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-ca300881-55ef-4986-86ed-c5a82775af5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-6dd5e113-e671-4f50-9a34-994e28b8eb53,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-7a68eb96-9850-4722-9dba-e33fca69816d,DISK], DatanodeInfoWithStorage[127.0.0.1:34357,DS-01118372-9ecd-42b2-861c-bbbeecac841c,DISK], DatanodeInfoWithStorage[127.0.0.1:40182,DS-cef33666-5751-4ac0-8b5e-482508bf6f6f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1380820943-172.17.0.21-1596055042529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33058,DS-49ffde5c-d152-45c6-9643-ad2eddaf96b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-eeb3d230-f905-49f4-b137-8fa3f5a05315,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-f0c8e4d0-463c-48cd-bd48-c9285be0a826,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-ca300881-55ef-4986-86ed-c5a82775af5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-6dd5e113-e671-4f50-9a34-994e28b8eb53,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-7a68eb96-9850-4722-9dba-e33fca69816d,DISK], DatanodeInfoWithStorage[127.0.0.1:34357,DS-01118372-9ecd-42b2-861c-bbbeecac841c,DISK], DatanodeInfoWithStorage[127.0.0.1:40182,DS-cef33666-5751-4ac0-8b5e-482508bf6f6f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-355070815-172.17.0.21-1596055216113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34147,DS-4362d5d5-79cb-4d98-869f-e74d0bf6b7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36707,DS-2644c8d6-d78d-4943-a192-0456ab6c30ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-826e1be6-fe2b-42df-9369-fd2d82fa9232,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-fbc6a2ec-599b-45ed-b1c5-e9ece14aa238,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-cf2894ac-b306-4857-bbd2-a41080aabc0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-5bd184f7-a072-4194-89e0-eba0579037ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34596,DS-97b93fa7-6a13-4175-a612-591607903999,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-7560758f-acc8-46d2-b993-015e5915bad7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-355070815-172.17.0.21-1596055216113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34147,DS-4362d5d5-79cb-4d98-869f-e74d0bf6b7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36707,DS-2644c8d6-d78d-4943-a192-0456ab6c30ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-826e1be6-fe2b-42df-9369-fd2d82fa9232,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-fbc6a2ec-599b-45ed-b1c5-e9ece14aa238,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-cf2894ac-b306-4857-bbd2-a41080aabc0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-5bd184f7-a072-4194-89e0-eba0579037ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34596,DS-97b93fa7-6a13-4175-a612-591607903999,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-7560758f-acc8-46d2-b993-015e5915bad7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1244499523-172.17.0.21-1596055303001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33343,DS-1091001a-b9a6-4f5e-9b54-f49b685b103c,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-e66b9830-f0c6-4dff-84db-b5619804cb00,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-368eae81-d308-4335-81ec-9643d5115bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-7540aff2-4e8a-4116-a4f5-53e73042d788,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-c6daf7b6-7191-4e10-bbe8-4dc8ae750d38,DISK], DatanodeInfoWithStorage[127.0.0.1:34424,DS-239fef07-12c9-45bf-bee2-a25f6435f6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-3c77fdfb-3cb6-425f-96bc-8153069c9560,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-2c813ca1-9abd-466c-9445-74ac82738b6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1244499523-172.17.0.21-1596055303001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33343,DS-1091001a-b9a6-4f5e-9b54-f49b685b103c,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-e66b9830-f0c6-4dff-84db-b5619804cb00,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-368eae81-d308-4335-81ec-9643d5115bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-7540aff2-4e8a-4116-a4f5-53e73042d788,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-c6daf7b6-7191-4e10-bbe8-4dc8ae750d38,DISK], DatanodeInfoWithStorage[127.0.0.1:34424,DS-239fef07-12c9-45bf-bee2-a25f6435f6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-3c77fdfb-3cb6-425f-96bc-8153069c9560,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-2c813ca1-9abd-466c-9445-74ac82738b6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-297830788-172.17.0.21-1596055578002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45794,DS-9efe9c2f-528b-40c7-b9a0-78447bf7037d,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-78d3cafa-f467-461a-8243-3142d209beab,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-e27951b4-3892-4205-8699-88b5aaf03cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35333,DS-44178967-968b-4b7b-8c4f-700fd494c75f,DISK], DatanodeInfoWithStorage[127.0.0.1:44355,DS-f7ca1b97-0a56-4f7f-b1a6-62f524774875,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-91a8491e-d3b6-4742-87e2-78309c45895f,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-33e910b6-6f8e-4ca4-a91e-471e96d1f1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-d1ffe089-d266-41a4-bee6-a2188bf8712a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-297830788-172.17.0.21-1596055578002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45794,DS-9efe9c2f-528b-40c7-b9a0-78447bf7037d,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-78d3cafa-f467-461a-8243-3142d209beab,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-e27951b4-3892-4205-8699-88b5aaf03cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35333,DS-44178967-968b-4b7b-8c4f-700fd494c75f,DISK], DatanodeInfoWithStorage[127.0.0.1:44355,DS-f7ca1b97-0a56-4f7f-b1a6-62f524774875,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-91a8491e-d3b6-4742-87e2-78309c45895f,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-33e910b6-6f8e-4ca4-a91e-471e96d1f1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-d1ffe089-d266-41a4-bee6-a2188bf8712a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-832303448-172.17.0.21-1596055839518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41766,DS-c192dc6a-407e-4bb3-ab20-78249b8ee8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-11778245-403e-46d4-9cc6-27a247e6e8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-19b4128f-5a8b-499a-a3a2-24d93ccf2d10,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-8c64d0be-0a21-434b-a705-fc4b1ee6771e,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-dde4e8f8-5891-4926-9728-9d36f9496239,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-42b0e8ed-9e5c-497f-8735-68baed04a490,DISK], DatanodeInfoWithStorage[127.0.0.1:38022,DS-e54b7b60-b94f-4e46-9f5b-6431464b05ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-25c5e891-f6d5-46e0-b047-7680898cc587,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-832303448-172.17.0.21-1596055839518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41766,DS-c192dc6a-407e-4bb3-ab20-78249b8ee8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-11778245-403e-46d4-9cc6-27a247e6e8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-19b4128f-5a8b-499a-a3a2-24d93ccf2d10,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-8c64d0be-0a21-434b-a705-fc4b1ee6771e,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-dde4e8f8-5891-4926-9728-9d36f9496239,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-42b0e8ed-9e5c-497f-8735-68baed04a490,DISK], DatanodeInfoWithStorage[127.0.0.1:38022,DS-e54b7b60-b94f-4e46-9f5b-6431464b05ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-25c5e891-f6d5-46e0-b047-7680898cc587,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-634378459-172.17.0.21-1596055895259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38019,DS-86fedf3c-7132-40ae-a3e0-f8e250db0a38,DISK], DatanodeInfoWithStorage[127.0.0.1:39703,DS-909583f5-4e64-4c37-915a-5b3a98cb9cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-051c9172-af4a-40b0-9717-4e844b9ba59e,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-414d6975-4563-4b8c-9dcd-84df73d6b1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-9bff0ad7-7863-4849-89cb-79075853e655,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-f858cd6e-fb91-431d-9058-145163b56f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-1048cfbd-c9cc-405a-9f9c-e8b653c28c91,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-14880808-d618-49c8-a660-df24de91b628,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-634378459-172.17.0.21-1596055895259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38019,DS-86fedf3c-7132-40ae-a3e0-f8e250db0a38,DISK], DatanodeInfoWithStorage[127.0.0.1:39703,DS-909583f5-4e64-4c37-915a-5b3a98cb9cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-051c9172-af4a-40b0-9717-4e844b9ba59e,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-414d6975-4563-4b8c-9dcd-84df73d6b1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-9bff0ad7-7863-4849-89cb-79075853e655,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-f858cd6e-fb91-431d-9058-145163b56f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-1048cfbd-c9cc-405a-9f9c-e8b653c28c91,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-14880808-d618-49c8-a660-df24de91b628,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-663340160-172.17.0.21-1596056275940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38558,DS-6a7321cb-087a-4000-947e-47f47060607a,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-c0f07f12-c46e-4640-af49-e3e7128e195c,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-fb65fc0f-1c64-48bd-9a39-2c8034f6c4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-faab4a3e-2b12-4683-9d3c-dd75300109ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-771c5022-3db6-4831-ae65-fb42c1ca1d48,DISK], DatanodeInfoWithStorage[127.0.0.1:41529,DS-78e614fc-c2d2-4086-8aeb-c2c0f03acf90,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-9bcf60fb-cf6d-4eba-8fbc-35c215816119,DISK], DatanodeInfoWithStorage[127.0.0.1:44036,DS-5be95a8e-02ee-46be-91c4-ca55723f5265,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-663340160-172.17.0.21-1596056275940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38558,DS-6a7321cb-087a-4000-947e-47f47060607a,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-c0f07f12-c46e-4640-af49-e3e7128e195c,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-fb65fc0f-1c64-48bd-9a39-2c8034f6c4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-faab4a3e-2b12-4683-9d3c-dd75300109ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-771c5022-3db6-4831-ae65-fb42c1ca1d48,DISK], DatanodeInfoWithStorage[127.0.0.1:41529,DS-78e614fc-c2d2-4086-8aeb-c2c0f03acf90,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-9bcf60fb-cf6d-4eba-8fbc-35c215816119,DISK], DatanodeInfoWithStorage[127.0.0.1:44036,DS-5be95a8e-02ee-46be-91c4-ca55723f5265,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-442318035-172.17.0.21-1596056635645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44852,DS-11022ff8-c41f-46c7-a632-65b47df73ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:44692,DS-25c9781e-2771-44e5-af2b-8ebb85a290c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42761,DS-f9711425-e9ca-4a4e-83a8-b17ff850325e,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-38ee7596-7ca7-4c8d-bb0d-fcc758e560da,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-ffb3673c-a9cd-4c88-a71b-5ecea361566d,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-1df312ce-6ff5-4a4e-bd02-ade53eb53b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-d2708742-b958-4215-8e42-78fe621633a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-329e7fdc-ffaf-4c81-89d7-c1bae058bbe5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-442318035-172.17.0.21-1596056635645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44852,DS-11022ff8-c41f-46c7-a632-65b47df73ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:44692,DS-25c9781e-2771-44e5-af2b-8ebb85a290c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42761,DS-f9711425-e9ca-4a4e-83a8-b17ff850325e,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-38ee7596-7ca7-4c8d-bb0d-fcc758e560da,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-ffb3673c-a9cd-4c88-a71b-5ecea361566d,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-1df312ce-6ff5-4a4e-bd02-ade53eb53b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-d2708742-b958-4215-8e42-78fe621633a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-329e7fdc-ffaf-4c81-89d7-c1bae058bbe5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1994353048-172.17.0.21-1596056762581:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41804,DS-221ab1ed-5e68-4add-ba91-7a81b7b00f51,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-b7f05c05-1300-448e-bd2d-4114bdd5ef98,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-caf344aa-11cb-4c39-8d22-949bcdeb6a94,DISK], DatanodeInfoWithStorage[127.0.0.1:40094,DS-4498dcff-342a-4e5b-af21-2b446eb2f4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-c2df19a8-cb1e-41d5-9c96-5e01e0683dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-b3189bb3-de94-4759-84ed-216fc469e8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43213,DS-2ed1e3f8-c93f-4c80-bff6-afc1197b4a26,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-f8407375-adff-47be-9bbb-d52baef1ae91,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1994353048-172.17.0.21-1596056762581:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41804,DS-221ab1ed-5e68-4add-ba91-7a81b7b00f51,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-b7f05c05-1300-448e-bd2d-4114bdd5ef98,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-caf344aa-11cb-4c39-8d22-949bcdeb6a94,DISK], DatanodeInfoWithStorage[127.0.0.1:40094,DS-4498dcff-342a-4e5b-af21-2b446eb2f4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-c2df19a8-cb1e-41d5-9c96-5e01e0683dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-b3189bb3-de94-4759-84ed-216fc469e8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43213,DS-2ed1e3f8-c93f-4c80-bff6-afc1197b4a26,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-f8407375-adff-47be-9bbb-d52baef1ae91,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-202860557-172.17.0.21-1596056804399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35531,DS-f9050421-c86a-425d-8f43-011c228e38eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-78ecac59-0221-4d40-8b30-f26d7a871e69,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-45d5bb46-1372-409a-8db2-18d0a1969ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-a6010ad9-da8e-4201-81ef-121521bf1643,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-03e2d571-49f5-4d72-9fc8-152e7b8ad5da,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-b03e164a-1246-49ae-ab08-5b318ce618d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-6c78a5b0-c741-4adf-955a-37d394638749,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-d09a2775-433a-401f-9d40-0d98b1afd319,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-202860557-172.17.0.21-1596056804399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35531,DS-f9050421-c86a-425d-8f43-011c228e38eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-78ecac59-0221-4d40-8b30-f26d7a871e69,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-45d5bb46-1372-409a-8db2-18d0a1969ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-a6010ad9-da8e-4201-81ef-121521bf1643,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-03e2d571-49f5-4d72-9fc8-152e7b8ad5da,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-b03e164a-1246-49ae-ab08-5b318ce618d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-6c78a5b0-c741-4adf-955a-37d394638749,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-d09a2775-433a-401f-9d40-0d98b1afd319,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-475296359-172.17.0.21-1596056943431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43906,DS-f08748a0-e66e-4c2a-9e84-55fa59d81fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:33373,DS-cf33243e-619e-4dc1-bc70-1811fd445dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:39135,DS-7828e594-3532-4213-99a6-26a1db60420f,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-c6b87a4b-0459-4173-9097-9f400fb4b1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-9cf7e5b8-65cc-45be-9b37-36c62dfe061e,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-891e6b9a-2bc3-4f6f-b88c-50a88009aadb,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-92baf4d3-c0e9-4e0e-a049-0597825de0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-0ec7dae2-21ba-4148-8c8b-2e3cf3787964,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-475296359-172.17.0.21-1596056943431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43906,DS-f08748a0-e66e-4c2a-9e84-55fa59d81fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:33373,DS-cf33243e-619e-4dc1-bc70-1811fd445dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:39135,DS-7828e594-3532-4213-99a6-26a1db60420f,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-c6b87a4b-0459-4173-9097-9f400fb4b1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-9cf7e5b8-65cc-45be-9b37-36c62dfe061e,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-891e6b9a-2bc3-4f6f-b88c-50a88009aadb,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-92baf4d3-c0e9-4e0e-a049-0597825de0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-0ec7dae2-21ba-4148-8c8b-2e3cf3787964,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-710688350-172.17.0.21-1596056984608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33848,DS-4de45342-746b-45cd-9dd0-9151edce3bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:40609,DS-2c42c7ec-dc06-4ff0-87f3-68641eae7d11,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-c3bdeb78-7ac4-409d-ac85-ee570c14c30a,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-026211a7-af08-443a-9180-a22b6a8de8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-9216b77a-2935-47c1-8ddd-12a99ddb0e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43558,DS-9e114966-0dbe-4868-8fe6-d31b53a5b104,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-1ffd7c5e-a61d-40f5-99ca-c0c78d08914e,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-0358ca2b-973c-434f-99d8-8b68ed571a41,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-710688350-172.17.0.21-1596056984608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33848,DS-4de45342-746b-45cd-9dd0-9151edce3bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:40609,DS-2c42c7ec-dc06-4ff0-87f3-68641eae7d11,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-c3bdeb78-7ac4-409d-ac85-ee570c14c30a,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-026211a7-af08-443a-9180-a22b6a8de8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-9216b77a-2935-47c1-8ddd-12a99ddb0e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43558,DS-9e114966-0dbe-4868-8fe6-d31b53a5b104,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-1ffd7c5e-a61d-40f5-99ca-c0c78d08914e,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-0358ca2b-973c-434f-99d8-8b68ed571a41,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1317693204-172.17.0.21-1596057120395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34931,DS-79a87210-a391-4041-aaf0-fffdc23eb4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-9dbf1a0e-25fe-4057-bf72-7eb217cd2a15,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-e3d76b26-ac81-400a-a092-07e57a4587c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37372,DS-97311301-a759-4865-93aa-581affb4ae06,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-8d7912b6-1827-40a1-946f-3d5b0a941adb,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-2030eb0e-6e9c-4176-a314-54bbbc93bdb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-8189b8c1-1184-439b-8f0c-5b220942f332,DISK], DatanodeInfoWithStorage[127.0.0.1:38359,DS-4de57518-ef6a-4f5a-bb36-5af5ab974163,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1317693204-172.17.0.21-1596057120395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34931,DS-79a87210-a391-4041-aaf0-fffdc23eb4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-9dbf1a0e-25fe-4057-bf72-7eb217cd2a15,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-e3d76b26-ac81-400a-a092-07e57a4587c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37372,DS-97311301-a759-4865-93aa-581affb4ae06,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-8d7912b6-1827-40a1-946f-3d5b0a941adb,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-2030eb0e-6e9c-4176-a314-54bbbc93bdb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-8189b8c1-1184-439b-8f0c-5b220942f332,DISK], DatanodeInfoWithStorage[127.0.0.1:38359,DS-4de57518-ef6a-4f5a-bb36-5af5ab974163,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-171961994-172.17.0.21-1596057161448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43514,DS-6a67f4ba-787d-421b-9fa4-00a37d5622b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-90dea52d-831b-4c12-80cf-a1d969acbea6,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-becca7f2-0bcc-4c64-a015-474689741549,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-e3ea0701-9348-42c1-a2fb-5fbefe4e8bef,DISK], DatanodeInfoWithStorage[127.0.0.1:37774,DS-5923a97a-4cd4-44bd-aed5-2c84ab57f3da,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-409079ba-6cf9-4dde-81d7-8daab5f25f81,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-31441ab0-9014-4313-9eb2-35f90b7583ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-3024e104-2ddd-42e9-917e-4a1f43872d89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-171961994-172.17.0.21-1596057161448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43514,DS-6a67f4ba-787d-421b-9fa4-00a37d5622b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-90dea52d-831b-4c12-80cf-a1d969acbea6,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-becca7f2-0bcc-4c64-a015-474689741549,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-e3ea0701-9348-42c1-a2fb-5fbefe4e8bef,DISK], DatanodeInfoWithStorage[127.0.0.1:37774,DS-5923a97a-4cd4-44bd-aed5-2c84ab57f3da,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-409079ba-6cf9-4dde-81d7-8daab5f25f81,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-31441ab0-9014-4313-9eb2-35f90b7583ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-3024e104-2ddd-42e9-917e-4a1f43872d89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1385643704-172.17.0.21-1596057377207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33228,DS-63e28dcd-fd1e-4bd2-a02c-8ad32d3c946b,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-1d9aa719-9b27-4bfb-a92b-159b4ae61009,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-15a1d74b-d498-4d50-923c-84e00b93eef4,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-f66470ff-4135-4f1a-aa2a-8a30b44d10e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-57ed1aed-6e74-4c30-8a8b-a1a8c3df187e,DISK], DatanodeInfoWithStorage[127.0.0.1:37228,DS-26134368-f7b3-4809-b87c-3f16233527a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-dfcf8bb5-0003-4a9a-9394-16dbe5ffd0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37266,DS-35d3e30d-9c18-4370-8518-4dae417c3880,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1385643704-172.17.0.21-1596057377207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33228,DS-63e28dcd-fd1e-4bd2-a02c-8ad32d3c946b,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-1d9aa719-9b27-4bfb-a92b-159b4ae61009,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-15a1d74b-d498-4d50-923c-84e00b93eef4,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-f66470ff-4135-4f1a-aa2a-8a30b44d10e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-57ed1aed-6e74-4c30-8a8b-a1a8c3df187e,DISK], DatanodeInfoWithStorage[127.0.0.1:37228,DS-26134368-f7b3-4809-b87c-3f16233527a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-dfcf8bb5-0003-4a9a-9394-16dbe5ffd0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37266,DS-35d3e30d-9c18-4370-8518-4dae417c3880,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1645423750-172.17.0.21-1596057591254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35996,DS-b6262168-5a2a-409d-b91a-6c1ebecacda8,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-e45b5414-a7b1-4625-bfe2-bffebfcf8a87,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-604f9688-e0a6-4186-82ed-4388fbd12337,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-7f743a0b-5201-4c1b-89fe-4f1cb9181f04,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-92993a51-edf3-4061-8d11-98b249aeb038,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-7329af07-4596-4928-a44a-642eb8b9e58c,DISK], DatanodeInfoWithStorage[127.0.0.1:41427,DS-dc66ae02-38a7-48fe-a76b-d0b10d5dcbee,DISK], DatanodeInfoWithStorage[127.0.0.1:34704,DS-04d82a16-b760-4c48-a453-40463365784d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1645423750-172.17.0.21-1596057591254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35996,DS-b6262168-5a2a-409d-b91a-6c1ebecacda8,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-e45b5414-a7b1-4625-bfe2-bffebfcf8a87,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-604f9688-e0a6-4186-82ed-4388fbd12337,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-7f743a0b-5201-4c1b-89fe-4f1cb9181f04,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-92993a51-edf3-4061-8d11-98b249aeb038,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-7329af07-4596-4928-a44a-642eb8b9e58c,DISK], DatanodeInfoWithStorage[127.0.0.1:41427,DS-dc66ae02-38a7-48fe-a76b-d0b10d5dcbee,DISK], DatanodeInfoWithStorage[127.0.0.1:34704,DS-04d82a16-b760-4c48-a453-40463365784d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1623291170-172.17.0.21-1596057716445:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41943,DS-6da4bc06-1b38-45e2-8891-66522f2d061b,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-d32e6bb2-fb66-46cb-9fe8-231c527288a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-9b199baf-5e02-4261-a3b5-579ca18dbd47,DISK], DatanodeInfoWithStorage[127.0.0.1:33390,DS-30e7bbcf-4621-439d-acac-0d668288aa4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-71f3eede-6e39-4fc5-b955-20ad51777772,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-ce3e245a-7bcd-4cb1-9b61-2d4700ed78f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45430,DS-ffd9c70b-da13-483c-ac90-c8805f29ac68,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-c6360ce8-d3e2-485a-b0c3-8ac405a1aa1f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1623291170-172.17.0.21-1596057716445:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41943,DS-6da4bc06-1b38-45e2-8891-66522f2d061b,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-d32e6bb2-fb66-46cb-9fe8-231c527288a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-9b199baf-5e02-4261-a3b5-579ca18dbd47,DISK], DatanodeInfoWithStorage[127.0.0.1:33390,DS-30e7bbcf-4621-439d-acac-0d668288aa4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-71f3eede-6e39-4fc5-b955-20ad51777772,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-ce3e245a-7bcd-4cb1-9b61-2d4700ed78f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45430,DS-ffd9c70b-da13-483c-ac90-c8805f29ac68,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-c6360ce8-d3e2-485a-b0c3-8ac405a1aa1f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1625071027-172.17.0.21-1596057843638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45251,DS-ae6bc0e0-10b2-41c1-9a61-d369eb88bc00,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-1277a9cb-7f59-4c61-af70-889886bf2f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-f4c68359-8974-4481-9df6-dfe2704cd6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-b5c5b468-a292-4d39-a18d-505fa77eff58,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-9a18dfcd-ca65-43de-87c6-fd8518c93194,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-3c7b5d20-151a-4629-9e76-42b3027c3dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-b931f5b6-cbfa-47c4-90af-bcc5e760ff09,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-fd220b54-bbde-4951-95c4-b553c0c05313,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1625071027-172.17.0.21-1596057843638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45251,DS-ae6bc0e0-10b2-41c1-9a61-d369eb88bc00,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-1277a9cb-7f59-4c61-af70-889886bf2f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-f4c68359-8974-4481-9df6-dfe2704cd6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-b5c5b468-a292-4d39-a18d-505fa77eff58,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-9a18dfcd-ca65-43de-87c6-fd8518c93194,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-3c7b5d20-151a-4629-9e76-42b3027c3dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-b931f5b6-cbfa-47c4-90af-bcc5e760ff09,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-fd220b54-bbde-4951-95c4-b553c0c05313,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-913751424-172.17.0.21-1596058025273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33391,DS-dd7885c0-c8f4-4a1e-95c0-3790c86858c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-a7c819b5-eb96-4a30-9d5c-63a7b935935c,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-ad0c4bc7-c9b0-4143-9bb1-590b86ebff75,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-615af855-906b-4dd6-b65a-6ae2d5c45a35,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-3692dd30-a6d8-4b39-9154-b0d46b47b44a,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-4aa78553-99aa-4f95-b714-e0a4af98c507,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-1c4bca07-816a-4429-ab73-640a973bfed0,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-70670ecc-dc62-4a40-8717-c3a14c7e05b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-913751424-172.17.0.21-1596058025273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33391,DS-dd7885c0-c8f4-4a1e-95c0-3790c86858c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-a7c819b5-eb96-4a30-9d5c-63a7b935935c,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-ad0c4bc7-c9b0-4143-9bb1-590b86ebff75,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-615af855-906b-4dd6-b65a-6ae2d5c45a35,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-3692dd30-a6d8-4b39-9154-b0d46b47b44a,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-4aa78553-99aa-4f95-b714-e0a4af98c507,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-1c4bca07-816a-4429-ab73-640a973bfed0,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-70670ecc-dc62-4a40-8717-c3a14c7e05b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 17 out of 50
v1v1v2v2 failed with probability 22 out of 50
result: false positive !!!
Total execution time in seconds : 6813
