reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-273060382-172.17.0.5-1595897533010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41154,DS-be1178d1-4104-4bf5-a396-1a50825e5738,DISK], DatanodeInfoWithStorage[127.0.0.1:40258,DS-9a35470c-6281-4a9b-9a8b-7c66cef40692,DISK], DatanodeInfoWithStorage[127.0.0.1:36951,DS-11be68df-05c0-4d9c-830c-3820260a2839,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-48688802-ccd8-4ef5-a9c2-c453111ba2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42337,DS-8be0bdeb-de81-414d-a0e7-96d98d8516b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37764,DS-f399f8ac-9170-4809-bedf-e617194b4076,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-fb65a8da-7c70-4da5-b913-02f9d43e119f,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-3a145a79-fac4-4124-af6f-6874e8dc262f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-273060382-172.17.0.5-1595897533010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41154,DS-be1178d1-4104-4bf5-a396-1a50825e5738,DISK], DatanodeInfoWithStorage[127.0.0.1:40258,DS-9a35470c-6281-4a9b-9a8b-7c66cef40692,DISK], DatanodeInfoWithStorage[127.0.0.1:36951,DS-11be68df-05c0-4d9c-830c-3820260a2839,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-48688802-ccd8-4ef5-a9c2-c453111ba2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42337,DS-8be0bdeb-de81-414d-a0e7-96d98d8516b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37764,DS-f399f8ac-9170-4809-bedf-e617194b4076,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-fb65a8da-7c70-4da5-b913-02f9d43e119f,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-3a145a79-fac4-4124-af6f-6874e8dc262f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1540845924-172.17.0.5-1595897563972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43419,DS-2a44f9ee-f61c-4b32-ad49-b0a55f1e32d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-3b6d5206-fd75-4530-b953-73138b8e283a,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-f75302c5-667b-458b-89ed-11b30930adc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-134a8a77-e5b2-4a62-b48e-882f8bf87c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-d80f6f38-4f62-451c-a1db-d110b89894b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-05d703a8-9102-4d8b-ac20-d300f8acc262,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-b2e783fe-c2b3-458e-a130-450fc620fccd,DISK], DatanodeInfoWithStorage[127.0.0.1:40853,DS-984d2817-d36f-41c2-b9e4-9d22904ab574,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1540845924-172.17.0.5-1595897563972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43419,DS-2a44f9ee-f61c-4b32-ad49-b0a55f1e32d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-3b6d5206-fd75-4530-b953-73138b8e283a,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-f75302c5-667b-458b-89ed-11b30930adc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-134a8a77-e5b2-4a62-b48e-882f8bf87c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-d80f6f38-4f62-451c-a1db-d110b89894b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-05d703a8-9102-4d8b-ac20-d300f8acc262,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-b2e783fe-c2b3-458e-a130-450fc620fccd,DISK], DatanodeInfoWithStorage[127.0.0.1:40853,DS-984d2817-d36f-41c2-b9e4-9d22904ab574,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-354599898-172.17.0.5-1595897715386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39730,DS-fbf1557a-aa44-44a7-a8d2-10b9379d5867,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-7b9a0b16-9516-4a76-992d-1fd0732e7af1,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-c7baba36-5af7-45b3-a9f4-64c876cc47d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-785cc3bd-5022-4ac3-8bd2-bfc042dd4814,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-1e6cf117-1abd-4361-b5ce-750ddcd8e5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-3293ca38-127c-46ce-b67c-631cb52adb43,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-d914f566-e078-44ec-96d1-44d197a4c11d,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-1888491e-1556-4801-95b9-17fcc026243c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-354599898-172.17.0.5-1595897715386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39730,DS-fbf1557a-aa44-44a7-a8d2-10b9379d5867,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-7b9a0b16-9516-4a76-992d-1fd0732e7af1,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-c7baba36-5af7-45b3-a9f4-64c876cc47d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-785cc3bd-5022-4ac3-8bd2-bfc042dd4814,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-1e6cf117-1abd-4361-b5ce-750ddcd8e5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-3293ca38-127c-46ce-b67c-631cb52adb43,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-d914f566-e078-44ec-96d1-44d197a4c11d,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-1888491e-1556-4801-95b9-17fcc026243c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-673577750-172.17.0.5-1595898029753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37911,DS-0633945f-d8a6-4c0f-b973-de0593438326,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-cc58cdeb-88bf-4d59-b7ed-fe6c59c89cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-d8d34c31-829a-4ff9-98a1-6d47e6ecdb14,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-d7b660c4-d2f0-4434-ba7d-77d28175b82b,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-408575ab-9445-41f2-9e20-81f191c349fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-731a8505-96b6-4e41-92d8-67492bdc8c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-875a292d-42c1-4b57-ac3f-def9f013175b,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-89213fe9-6cd5-4ae9-9f30-d5f140553d17,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-673577750-172.17.0.5-1595898029753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37911,DS-0633945f-d8a6-4c0f-b973-de0593438326,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-cc58cdeb-88bf-4d59-b7ed-fe6c59c89cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-d8d34c31-829a-4ff9-98a1-6d47e6ecdb14,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-d7b660c4-d2f0-4434-ba7d-77d28175b82b,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-408575ab-9445-41f2-9e20-81f191c349fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-731a8505-96b6-4e41-92d8-67492bdc8c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-875a292d-42c1-4b57-ac3f-def9f013175b,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-89213fe9-6cd5-4ae9-9f30-d5f140553d17,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1850484105-172.17.0.5-1595898255644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43786,DS-c12186ec-a7ee-4fa2-ad99-99aa29d9ee3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35633,DS-227d62e7-b1ed-4e5c-8021-e9feb46c5b05,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-511667a5-5727-4d3f-8e1f-1d8185eb0289,DISK], DatanodeInfoWithStorage[127.0.0.1:40757,DS-80275514-f9fc-4ab8-b6be-7450b71a1ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-7894b107-7b9d-4056-a78e-351608cc7fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-33e220fc-4141-44a2-8e6b-1f5bf476b737,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-e60c646f-994c-4a66-929c-0152fc88ad88,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-af1789c9-d102-44c9-a926-ffe1048e5a49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1850484105-172.17.0.5-1595898255644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43786,DS-c12186ec-a7ee-4fa2-ad99-99aa29d9ee3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35633,DS-227d62e7-b1ed-4e5c-8021-e9feb46c5b05,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-511667a5-5727-4d3f-8e1f-1d8185eb0289,DISK], DatanodeInfoWithStorage[127.0.0.1:40757,DS-80275514-f9fc-4ab8-b6be-7450b71a1ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-7894b107-7b9d-4056-a78e-351608cc7fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-33e220fc-4141-44a2-8e6b-1f5bf476b737,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-e60c646f-994c-4a66-929c-0152fc88ad88,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-af1789c9-d102-44c9-a926-ffe1048e5a49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2143938639-172.17.0.5-1595898360237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39782,DS-8b953625-98f8-4d76-b965-14a68878c0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37626,DS-d9f1c22d-9bbf-400a-947e-d41d93c654ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-0bd22c03-b51a-4211-9d13-a4802643641e,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-1ef58aef-fa2a-4c19-b899-f32aba51d8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-c74bcd94-911a-41ab-9534-11bd3ede7a35,DISK], DatanodeInfoWithStorage[127.0.0.1:39794,DS-39f3741a-8070-4731-b524-be9fa8a75406,DISK], DatanodeInfoWithStorage[127.0.0.1:41842,DS-2c2d6ef6-4dbe-44f1-b1f8-05a3a634364d,DISK], DatanodeInfoWithStorage[127.0.0.1:42354,DS-3e0ebf79-3f60-41e9-8e2a-fc6f498dfffa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2143938639-172.17.0.5-1595898360237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39782,DS-8b953625-98f8-4d76-b965-14a68878c0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37626,DS-d9f1c22d-9bbf-400a-947e-d41d93c654ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-0bd22c03-b51a-4211-9d13-a4802643641e,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-1ef58aef-fa2a-4c19-b899-f32aba51d8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-c74bcd94-911a-41ab-9534-11bd3ede7a35,DISK], DatanodeInfoWithStorage[127.0.0.1:39794,DS-39f3741a-8070-4731-b524-be9fa8a75406,DISK], DatanodeInfoWithStorage[127.0.0.1:41842,DS-2c2d6ef6-4dbe-44f1-b1f8-05a3a634364d,DISK], DatanodeInfoWithStorage[127.0.0.1:42354,DS-3e0ebf79-3f60-41e9-8e2a-fc6f498dfffa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1051054454-172.17.0.5-1595898479288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40172,DS-bb87cadf-c5b0-4ef0-9ce2-32f619af2d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-720554e2-f20d-401f-b0d3-bcba3a8e865a,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-8abde0de-f9de-4746-a7f9-1dd205a21b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38907,DS-7b392dd2-75b4-4070-bee0-fbcdfa463009,DISK], DatanodeInfoWithStorage[127.0.0.1:46223,DS-b2e32b6e-b479-4a67-8da8-300fc35ae02b,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-52595a1b-b74e-48b8-84d1-5bc9b9b094ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-67fa8ba7-3e57-4333-898d-28652ae3eab7,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-8a320953-a8ea-4964-aea8-3823bf32576d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1051054454-172.17.0.5-1595898479288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40172,DS-bb87cadf-c5b0-4ef0-9ce2-32f619af2d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-720554e2-f20d-401f-b0d3-bcba3a8e865a,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-8abde0de-f9de-4746-a7f9-1dd205a21b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38907,DS-7b392dd2-75b4-4070-bee0-fbcdfa463009,DISK], DatanodeInfoWithStorage[127.0.0.1:46223,DS-b2e32b6e-b479-4a67-8da8-300fc35ae02b,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-52595a1b-b74e-48b8-84d1-5bc9b9b094ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-67fa8ba7-3e57-4333-898d-28652ae3eab7,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-8a320953-a8ea-4964-aea8-3823bf32576d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-873513448-172.17.0.5-1595898590166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44119,DS-260c0d17-d236-4a79-8c76-a40e8b48f600,DISK], DatanodeInfoWithStorage[127.0.0.1:40776,DS-1ee9fb83-4721-40d8-bc2e-db95a003c6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-42012340-e2c9-48c2-969c-29f6ac21d4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43580,DS-06fea269-7cbb-48dc-9028-58f81f42ca00,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-916a1520-b15e-4ba9-8148-9b01306b7876,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-50b545d6-d00c-4acb-a2ef-455a43ec273c,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-c2f67217-b2bb-4036-8cc7-54ece7e04e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-a2e797e5-8437-4ffa-8924-51a27de18250,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-873513448-172.17.0.5-1595898590166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44119,DS-260c0d17-d236-4a79-8c76-a40e8b48f600,DISK], DatanodeInfoWithStorage[127.0.0.1:40776,DS-1ee9fb83-4721-40d8-bc2e-db95a003c6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-42012340-e2c9-48c2-969c-29f6ac21d4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43580,DS-06fea269-7cbb-48dc-9028-58f81f42ca00,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-916a1520-b15e-4ba9-8148-9b01306b7876,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-50b545d6-d00c-4acb-a2ef-455a43ec273c,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-c2f67217-b2bb-4036-8cc7-54ece7e04e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-a2e797e5-8437-4ffa-8924-51a27de18250,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489461133-172.17.0.5-1595898664093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36513,DS-8835d14a-5e35-4572-a965-6650e30e746b,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-f32d43d7-e827-4548-a913-21cca9e2fe5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-d58a4a80-0add-407b-906d-9b79d19e7bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-fa9213cc-43f5-46af-9455-302fae1d0e48,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-70889cc0-8856-45c0-816e-ec4f5807579d,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-d625e991-2175-4f12-85ee-84c57dac477c,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-b81f7aaf-4b8c-4361-8345-ef322b8be392,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-bb863813-0661-48f1-84e4-f7714e2bed22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489461133-172.17.0.5-1595898664093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36513,DS-8835d14a-5e35-4572-a965-6650e30e746b,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-f32d43d7-e827-4548-a913-21cca9e2fe5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-d58a4a80-0add-407b-906d-9b79d19e7bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-fa9213cc-43f5-46af-9455-302fae1d0e48,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-70889cc0-8856-45c0-816e-ec4f5807579d,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-d625e991-2175-4f12-85ee-84c57dac477c,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-b81f7aaf-4b8c-4361-8345-ef322b8be392,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-bb863813-0661-48f1-84e4-f7714e2bed22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1991272311-172.17.0.5-1595898702117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36569,DS-e12b00b2-5286-41f7-9ce3-be58a651f8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-f1be1970-c3ec-43b6-a42f-fedc2b5dff5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-d8f53cc4-970b-4acc-a3b7-4bb670506942,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-a57f2b47-6497-4246-8424-eff5c9cec475,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-4191e6df-7f45-4328-baac-d3346240b341,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-faf9a141-a9d6-4b7b-9255-b170b19cce3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-182683de-08a8-4a3f-a163-91d7c3410756,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-de980804-cfeb-4753-ba13-7005b3aad2ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1991272311-172.17.0.5-1595898702117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36569,DS-e12b00b2-5286-41f7-9ce3-be58a651f8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-f1be1970-c3ec-43b6-a42f-fedc2b5dff5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-d8f53cc4-970b-4acc-a3b7-4bb670506942,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-a57f2b47-6497-4246-8424-eff5c9cec475,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-4191e6df-7f45-4328-baac-d3346240b341,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-faf9a141-a9d6-4b7b-9255-b170b19cce3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-182683de-08a8-4a3f-a163-91d7c3410756,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-de980804-cfeb-4753-ba13-7005b3aad2ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1442517755-172.17.0.5-1595899240751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45767,DS-7c13aeac-9ec7-44ef-bdc7-41f897b48bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-b3c5c4a4-03a7-466c-b388-d7b7a79a1778,DISK], DatanodeInfoWithStorage[127.0.0.1:37487,DS-c6b3437d-2a8c-497c-9f2f-97c4de6422ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-e3d75805-08fb-4812-afe3-e1552ce7fb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-bd14d355-09f0-4c6d-89f8-18757a8dba85,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-339f3ae2-336f-47dd-9181-8ea0b834b48d,DISK], DatanodeInfoWithStorage[127.0.0.1:39703,DS-e58d9378-dcc4-466a-9665-0105161c5b89,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-33cf153e-fd75-44e9-a3e6-eb5256e7b859,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1442517755-172.17.0.5-1595899240751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45767,DS-7c13aeac-9ec7-44ef-bdc7-41f897b48bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-b3c5c4a4-03a7-466c-b388-d7b7a79a1778,DISK], DatanodeInfoWithStorage[127.0.0.1:37487,DS-c6b3437d-2a8c-497c-9f2f-97c4de6422ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-e3d75805-08fb-4812-afe3-e1552ce7fb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-bd14d355-09f0-4c6d-89f8-18757a8dba85,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-339f3ae2-336f-47dd-9181-8ea0b834b48d,DISK], DatanodeInfoWithStorage[127.0.0.1:39703,DS-e58d9378-dcc4-466a-9665-0105161c5b89,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-33cf153e-fd75-44e9-a3e6-eb5256e7b859,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-348754079-172.17.0.5-1595899276262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38711,DS-3069dd93-e25f-4ea5-ade0-833fc08b14c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-1e47cc94-9f6f-414b-a0c0-26310f9bc353,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-dc30b007-3049-4ff1-83d8-b100c9b65443,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-f924e440-1378-4e67-b7ae-bd35f8a17d06,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-ff70c1d5-15c3-4c93-9474-3cf686f165ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-f10bbb56-05bd-43f3-bf5c-dd5661f14b11,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-294433a8-d80d-4ca3-9a98-ad1ca601034f,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-4f21e8c2-22f2-425c-b4e8-7f79322c0454,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-348754079-172.17.0.5-1595899276262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38711,DS-3069dd93-e25f-4ea5-ade0-833fc08b14c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-1e47cc94-9f6f-414b-a0c0-26310f9bc353,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-dc30b007-3049-4ff1-83d8-b100c9b65443,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-f924e440-1378-4e67-b7ae-bd35f8a17d06,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-ff70c1d5-15c3-4c93-9474-3cf686f165ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-f10bbb56-05bd-43f3-bf5c-dd5661f14b11,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-294433a8-d80d-4ca3-9a98-ad1ca601034f,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-4f21e8c2-22f2-425c-b4e8-7f79322c0454,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-539145058-172.17.0.5-1595899447708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42745,DS-5c58ff45-0ae6-400e-b5ce-9e39d5eb7d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-89ef70d1-2ae8-420f-b462-6cd2ef4a69fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-4ee2349e-a94e-47d8-a2ed-38c23b7b76ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-3cb1d379-e980-4931-9115-e7bfae7c2057,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-30d4989e-b222-4caf-aefb-3982c6c925b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-ee716172-d5bd-48c8-b4ad-1eeff5fc0c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-d758d878-405e-40fd-ae2c-69d114e6d062,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-273ac407-18cb-4a33-ae05-f983a3327e18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-539145058-172.17.0.5-1595899447708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42745,DS-5c58ff45-0ae6-400e-b5ce-9e39d5eb7d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-89ef70d1-2ae8-420f-b462-6cd2ef4a69fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-4ee2349e-a94e-47d8-a2ed-38c23b7b76ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-3cb1d379-e980-4931-9115-e7bfae7c2057,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-30d4989e-b222-4caf-aefb-3982c6c925b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-ee716172-d5bd-48c8-b4ad-1eeff5fc0c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-d758d878-405e-40fd-ae2c-69d114e6d062,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-273ac407-18cb-4a33-ae05-f983a3327e18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1341940793-172.17.0.5-1595899622702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45093,DS-458a3e57-e9c8-4630-99b4-d28ad48fdd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-a6dabbbb-afc7-48ed-8a5d-60ecb1ede237,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-9a66da5c-d4fe-42b3-b2b6-c3f65b721b55,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-5bd012d0-afc4-4122-9368-aeec54ead62f,DISK], DatanodeInfoWithStorage[127.0.0.1:43673,DS-6a2cda9b-72e6-4b96-ace2-699e673e7a05,DISK], DatanodeInfoWithStorage[127.0.0.1:41021,DS-7e220b92-f022-46a5-9e25-846cc95fcb5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-af26c4ed-39b6-4d28-b041-d39d1cb4bec6,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-0c2292bc-021b-42a4-9b26-93c293fc772b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1341940793-172.17.0.5-1595899622702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45093,DS-458a3e57-e9c8-4630-99b4-d28ad48fdd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-a6dabbbb-afc7-48ed-8a5d-60ecb1ede237,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-9a66da5c-d4fe-42b3-b2b6-c3f65b721b55,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-5bd012d0-afc4-4122-9368-aeec54ead62f,DISK], DatanodeInfoWithStorage[127.0.0.1:43673,DS-6a2cda9b-72e6-4b96-ace2-699e673e7a05,DISK], DatanodeInfoWithStorage[127.0.0.1:41021,DS-7e220b92-f022-46a5-9e25-846cc95fcb5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-af26c4ed-39b6-4d28-b041-d39d1cb4bec6,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-0c2292bc-021b-42a4-9b26-93c293fc772b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-185823029-172.17.0.5-1595899692562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40034,DS-0970e518-1cc3-48ee-abe4-3eb86435acc6,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-c1f100df-4463-4ab6-b6b5-87c8411f7454,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-a3284ac8-44ca-4d00-bb20-806307d8658a,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-947289b5-2d77-4a24-bbfb-e4f7cf1b0c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-ffd99b1b-d81e-4d82-8d68-a8637a546508,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-143b976e-4aa7-4d2c-97e9-cb5c8fbd83f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-e91cbe01-a664-4eb7-b601-3632acd66273,DISK], DatanodeInfoWithStorage[127.0.0.1:33795,DS-aab660a5-32c6-45f0-a99d-b11859cedd75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-185823029-172.17.0.5-1595899692562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40034,DS-0970e518-1cc3-48ee-abe4-3eb86435acc6,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-c1f100df-4463-4ab6-b6b5-87c8411f7454,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-a3284ac8-44ca-4d00-bb20-806307d8658a,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-947289b5-2d77-4a24-bbfb-e4f7cf1b0c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-ffd99b1b-d81e-4d82-8d68-a8637a546508,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-143b976e-4aa7-4d2c-97e9-cb5c8fbd83f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-e91cbe01-a664-4eb7-b601-3632acd66273,DISK], DatanodeInfoWithStorage[127.0.0.1:33795,DS-aab660a5-32c6-45f0-a99d-b11859cedd75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1100415836-172.17.0.5-1595899804339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32967,DS-4f5e5ffe-1b83-4df4-9f45-6a3eb27ec63b,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-a3d766c8-d725-460b-8bef-1c86105fc5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42382,DS-4310b8ad-7e53-4534-a57f-958059e265b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-d26e1edf-9a33-4944-9d0e-d92d4a71c26f,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-86935dbc-2566-4a0b-9738-00541832f33d,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-b63aa7a2-0563-4e01-a6ec-5cfca0764e33,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-aa0908b8-d2a6-426e-9e5e-6440dd08c414,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-6800f1be-64a8-4ba2-b94c-27482ba8d73c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1100415836-172.17.0.5-1595899804339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32967,DS-4f5e5ffe-1b83-4df4-9f45-6a3eb27ec63b,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-a3d766c8-d725-460b-8bef-1c86105fc5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42382,DS-4310b8ad-7e53-4534-a57f-958059e265b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-d26e1edf-9a33-4944-9d0e-d92d4a71c26f,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-86935dbc-2566-4a0b-9738-00541832f33d,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-b63aa7a2-0563-4e01-a6ec-5cfca0764e33,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-aa0908b8-d2a6-426e-9e5e-6440dd08c414,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-6800f1be-64a8-4ba2-b94c-27482ba8d73c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1095955176-172.17.0.5-1595899990596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46815,DS-1c49a1dc-59be-4c32-a194-ea7632dc4f07,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-b3c811a2-9984-4a3a-8357-4b2e2bcbff1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42808,DS-c8d079f3-0389-42e7-bd98-b145d404921e,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-5f7949f1-3a2d-447d-aada-07f9151fde8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-8757a58b-f6b4-41b5-b3a5-a70854f03de0,DISK], DatanodeInfoWithStorage[127.0.0.1:37234,DS-e9c46a9d-9c55-4f53-a6a1-3ebd280c2835,DISK], DatanodeInfoWithStorage[127.0.0.1:43824,DS-8b5186d8-cf5d-4552-b76b-1675f8d35745,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-e1c7ebd5-377f-4a74-885e-6311ce060f73,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1095955176-172.17.0.5-1595899990596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46815,DS-1c49a1dc-59be-4c32-a194-ea7632dc4f07,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-b3c811a2-9984-4a3a-8357-4b2e2bcbff1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42808,DS-c8d079f3-0389-42e7-bd98-b145d404921e,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-5f7949f1-3a2d-447d-aada-07f9151fde8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-8757a58b-f6b4-41b5-b3a5-a70854f03de0,DISK], DatanodeInfoWithStorage[127.0.0.1:37234,DS-e9c46a9d-9c55-4f53-a6a1-3ebd280c2835,DISK], DatanodeInfoWithStorage[127.0.0.1:43824,DS-8b5186d8-cf5d-4552-b76b-1675f8d35745,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-e1c7ebd5-377f-4a74-885e-6311ce060f73,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346776702-172.17.0.5-1595900068151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46850,DS-20b7db04-2107-404b-b576-aaa014b1c2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-e907c539-0655-4c9a-a870-5f7f51b3d60f,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-afbb34f1-3cbc-4a8f-8eac-5c14714ac1be,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-06365d8b-714a-4446-a3e9-5d069c6da4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-ebee79f3-815d-46a3-98f8-e58f0e3fb34f,DISK], DatanodeInfoWithStorage[127.0.0.1:42255,DS-9cf30a9d-de8b-4e57-86d7-86b26cf8cfb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-c5aeb7f4-0da1-4d3d-8520-68091d066508,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-b960d955-982c-41de-8845-887db5a0217d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346776702-172.17.0.5-1595900068151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46850,DS-20b7db04-2107-404b-b576-aaa014b1c2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-e907c539-0655-4c9a-a870-5f7f51b3d60f,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-afbb34f1-3cbc-4a8f-8eac-5c14714ac1be,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-06365d8b-714a-4446-a3e9-5d069c6da4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-ebee79f3-815d-46a3-98f8-e58f0e3fb34f,DISK], DatanodeInfoWithStorage[127.0.0.1:42255,DS-9cf30a9d-de8b-4e57-86d7-86b26cf8cfb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-c5aeb7f4-0da1-4d3d-8520-68091d066508,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-b960d955-982c-41de-8845-887db5a0217d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1704778961-172.17.0.5-1595900101037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44732,DS-a2d066a3-e540-4f09-85fb-63988f14b715,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-7cc58888-81d9-426d-942f-e6d9192ce2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-2510c2f7-f285-4c6c-9459-8438d038abf8,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-5395e812-7274-476f-84a5-09e9febe9f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-07d675ad-c887-4c62-87b5-63a2064f9f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-3823c045-c205-4f17-9a5b-5b036974da7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-c64f6e26-b1be-4551-a2b3-91ebaf66bf8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-b0969f2f-1e02-4469-a5cd-2a7a8c0588d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1704778961-172.17.0.5-1595900101037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44732,DS-a2d066a3-e540-4f09-85fb-63988f14b715,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-7cc58888-81d9-426d-942f-e6d9192ce2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-2510c2f7-f285-4c6c-9459-8438d038abf8,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-5395e812-7274-476f-84a5-09e9febe9f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-07d675ad-c887-4c62-87b5-63a2064f9f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-3823c045-c205-4f17-9a5b-5b036974da7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-c64f6e26-b1be-4551-a2b3-91ebaf66bf8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-b0969f2f-1e02-4469-a5cd-2a7a8c0588d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-645407227-172.17.0.5-1595900165906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38882,DS-476e205f-c8f4-40ce-b661-0c57e9da5a00,DISK], DatanodeInfoWithStorage[127.0.0.1:43980,DS-bba157d2-08ab-4e85-aacd-1d5dbc38ab36,DISK], DatanodeInfoWithStorage[127.0.0.1:34383,DS-9f0a0e2e-fa5e-481b-925c-cba26d90a7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-a5a77cb0-27c0-4227-921a-a423b6cdb9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-8c0dec5b-862c-4c6e-9730-873e48a38c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-58ee1536-b6eb-4bb1-a5b5-bdf7ee0e0c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34407,DS-302c5563-7627-45ef-a269-481bec8bbf9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-ad7292a5-e1a9-4571-ba76-9267211eb3a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-645407227-172.17.0.5-1595900165906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38882,DS-476e205f-c8f4-40ce-b661-0c57e9da5a00,DISK], DatanodeInfoWithStorage[127.0.0.1:43980,DS-bba157d2-08ab-4e85-aacd-1d5dbc38ab36,DISK], DatanodeInfoWithStorage[127.0.0.1:34383,DS-9f0a0e2e-fa5e-481b-925c-cba26d90a7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-a5a77cb0-27c0-4227-921a-a423b6cdb9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-8c0dec5b-862c-4c6e-9730-873e48a38c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-58ee1536-b6eb-4bb1-a5b5-bdf7ee0e0c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34407,DS-302c5563-7627-45ef-a269-481bec8bbf9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-ad7292a5-e1a9-4571-ba76-9267211eb3a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-727238615-172.17.0.5-1595900385969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38114,DS-fbb67120-0408-4eec-bbb5-f69470a7e033,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-f22cf461-e437-4d8c-ab89-d1a8260d1039,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-3dec7670-fc58-4db0-8c82-29f1da26c4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-92efbfd4-1d81-45ed-95f5-6a8dccdaee59,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-d46fd990-bbe0-4da3-8c6f-bcd933505b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-70ca1b04-5ac3-4a6a-902f-621e2946e67a,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-58d83b67-d4a7-4a13-aaad-5592e9a46724,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-409bd121-ab13-4644-8d21-1da9fc5e811e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-727238615-172.17.0.5-1595900385969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38114,DS-fbb67120-0408-4eec-bbb5-f69470a7e033,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-f22cf461-e437-4d8c-ab89-d1a8260d1039,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-3dec7670-fc58-4db0-8c82-29f1da26c4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-92efbfd4-1d81-45ed-95f5-6a8dccdaee59,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-d46fd990-bbe0-4da3-8c6f-bcd933505b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-70ca1b04-5ac3-4a6a-902f-621e2946e67a,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-58d83b67-d4a7-4a13-aaad-5592e9a46724,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-409bd121-ab13-4644-8d21-1da9fc5e811e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-783266854-172.17.0.5-1595900743517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38357,DS-f4319ff4-775d-4966-b8a9-e15d57099878,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-4371ce85-45eb-49a2-812e-669c9b9287cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-ead7b567-3322-4720-8c77-0020d1415e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-b2dec492-b0b1-42be-a5d9-2707c119fad2,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-52e191e8-546c-426d-a262-eb05673ede21,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-4832d425-d815-4dee-8d76-a976ee440c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-cd55f2b8-1292-4ae7-8080-ff18114c719a,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-0dde6073-77db-49b6-8f50-a9c1c520c448,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-783266854-172.17.0.5-1595900743517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38357,DS-f4319ff4-775d-4966-b8a9-e15d57099878,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-4371ce85-45eb-49a2-812e-669c9b9287cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-ead7b567-3322-4720-8c77-0020d1415e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-b2dec492-b0b1-42be-a5d9-2707c119fad2,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-52e191e8-546c-426d-a262-eb05673ede21,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-4832d425-d815-4dee-8d76-a976ee440c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-cd55f2b8-1292-4ae7-8080-ff18114c719a,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-0dde6073-77db-49b6-8f50-a9c1c520c448,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1541697829-172.17.0.5-1595900812325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34969,DS-12640026-df9e-4aee-953c-9b2bb980dde3,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-b5b1d0b4-ce9d-4898-9a2d-84a607640da0,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-df68fc9d-fa51-41ec-a970-0f30880846cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38582,DS-c3bda3a6-508f-4604-92e7-623bdf1e9f77,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-a6a96ff1-9b9c-4ab4-a187-b7920f629932,DISK], DatanodeInfoWithStorage[127.0.0.1:46165,DS-0a1c0bc4-5089-4212-92a8-820a3aaf853f,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-a097851e-1c13-478a-91cf-4e6c24bd947c,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-5a670798-5ef4-4ba0-8473-1cc4905abc5d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1541697829-172.17.0.5-1595900812325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34969,DS-12640026-df9e-4aee-953c-9b2bb980dde3,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-b5b1d0b4-ce9d-4898-9a2d-84a607640da0,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-df68fc9d-fa51-41ec-a970-0f30880846cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38582,DS-c3bda3a6-508f-4604-92e7-623bdf1e9f77,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-a6a96ff1-9b9c-4ab4-a187-b7920f629932,DISK], DatanodeInfoWithStorage[127.0.0.1:46165,DS-0a1c0bc4-5089-4212-92a8-820a3aaf853f,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-a097851e-1c13-478a-91cf-4e6c24bd947c,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-5a670798-5ef4-4ba0-8473-1cc4905abc5d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1974403596-172.17.0.5-1595900964574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34141,DS-ee1594f9-ff82-4509-a88b-6493a8b8f641,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-9eee9355-0e22-40a8-afde-4f357312cf41,DISK], DatanodeInfoWithStorage[127.0.0.1:44868,DS-f46ff45e-b83e-4ba4-bc64-4ba3fed6d104,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-76eeb909-204c-4528-96c3-55b30314392b,DISK], DatanodeInfoWithStorage[127.0.0.1:38293,DS-b628feb5-093f-4ba8-a070-a5607ca6f032,DISK], DatanodeInfoWithStorage[127.0.0.1:39934,DS-ed66ba2c-10d4-4114-85bb-7bc086b7f701,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-f8109a55-7449-4f37-8cd7-837c705aea22,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-e4792b12-63d2-4f61-b098-cb65ea23f640,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1974403596-172.17.0.5-1595900964574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34141,DS-ee1594f9-ff82-4509-a88b-6493a8b8f641,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-9eee9355-0e22-40a8-afde-4f357312cf41,DISK], DatanodeInfoWithStorage[127.0.0.1:44868,DS-f46ff45e-b83e-4ba4-bc64-4ba3fed6d104,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-76eeb909-204c-4528-96c3-55b30314392b,DISK], DatanodeInfoWithStorage[127.0.0.1:38293,DS-b628feb5-093f-4ba8-a070-a5607ca6f032,DISK], DatanodeInfoWithStorage[127.0.0.1:39934,DS-ed66ba2c-10d4-4114-85bb-7bc086b7f701,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-f8109a55-7449-4f37-8cd7-837c705aea22,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-e4792b12-63d2-4f61-b098-cb65ea23f640,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-348886314-172.17.0.5-1595901073629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36178,DS-b15ba5ff-5fd0-43c2-a7bc-113cf57dc2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-4a078b3f-5571-4e3a-835a-b2693a7a3a48,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-aca1876c-1865-4aed-9b88-a5a1cf4c59ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-f860d36e-ee20-4e3a-a52f-5a6f994c7ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-83b0c081-f011-4be3-8768-62508fe0fce2,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-dc1f6283-11fd-4488-b6a5-3dd83fed7950,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-57e2c291-3214-42e3-aa13-44b770b214cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-a60ed522-78ab-48f9-b820-a30d4990fb60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-348886314-172.17.0.5-1595901073629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36178,DS-b15ba5ff-5fd0-43c2-a7bc-113cf57dc2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-4a078b3f-5571-4e3a-835a-b2693a7a3a48,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-aca1876c-1865-4aed-9b88-a5a1cf4c59ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-f860d36e-ee20-4e3a-a52f-5a6f994c7ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-83b0c081-f011-4be3-8768-62508fe0fce2,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-dc1f6283-11fd-4488-b6a5-3dd83fed7950,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-57e2c291-3214-42e3-aa13-44b770b214cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-a60ed522-78ab-48f9-b820-a30d4990fb60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-801476975-172.17.0.5-1595901299060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36757,DS-3ef4434c-200d-4de9-b4fc-cbeb06bc3074,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-4e5ff329-6a38-4fc2-bb57-3951975d8c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37517,DS-258287a3-6f22-4070-854d-1d568464b5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37972,DS-602d5951-bce6-4c8d-8126-d9ad9641758f,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-9317ba25-36e4-47d2-88f0-9b8d2b38db55,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-2a28a92b-3017-4108-9ea4-fab984b52c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-55635052-d939-4e38-8126-064733939402,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-94f37e18-d8c8-4ce2-8d38-f34f0e8d6d88,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-801476975-172.17.0.5-1595901299060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36757,DS-3ef4434c-200d-4de9-b4fc-cbeb06bc3074,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-4e5ff329-6a38-4fc2-bb57-3951975d8c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37517,DS-258287a3-6f22-4070-854d-1d568464b5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37972,DS-602d5951-bce6-4c8d-8126-d9ad9641758f,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-9317ba25-36e4-47d2-88f0-9b8d2b38db55,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-2a28a92b-3017-4108-9ea4-fab984b52c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-55635052-d939-4e38-8126-064733939402,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-94f37e18-d8c8-4ce2-8d38-f34f0e8d6d88,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-863086589-172.17.0.5-1595901494437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39862,DS-d4469579-3d27-408a-9a45-07c3481b1292,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-4072ebc4-5c65-41a6-87f2-4c7fe34adbf1,DISK], DatanodeInfoWithStorage[127.0.0.1:44751,DS-c05a4d5d-f15a-45ff-ad51-ab324acc551e,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-bf949592-3e9f-462f-a248-e5aa1d60e310,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-e8c9dca9-4b3a-403d-9ba1-a2403ac58928,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-3b406d83-6645-4b9c-a868-85cee1e5fe8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43585,DS-f55f40eb-3bab-4210-946b-37b97ff6d163,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-44551023-673b-4635-9728-38bfa7a9903e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-863086589-172.17.0.5-1595901494437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39862,DS-d4469579-3d27-408a-9a45-07c3481b1292,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-4072ebc4-5c65-41a6-87f2-4c7fe34adbf1,DISK], DatanodeInfoWithStorage[127.0.0.1:44751,DS-c05a4d5d-f15a-45ff-ad51-ab324acc551e,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-bf949592-3e9f-462f-a248-e5aa1d60e310,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-e8c9dca9-4b3a-403d-9ba1-a2403ac58928,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-3b406d83-6645-4b9c-a868-85cee1e5fe8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43585,DS-f55f40eb-3bab-4210-946b-37b97ff6d163,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-44551023-673b-4635-9728-38bfa7a9903e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1218489315-172.17.0.5-1595901909067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35704,DS-5feecc09-88d5-46d7-b3d0-a88a42e2290d,DISK], DatanodeInfoWithStorage[127.0.0.1:40138,DS-59a46e33-1051-45ef-bb20-b4503563dc59,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-274ae156-efe8-4dc0-95bb-f8d68d46a0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-4156fb49-492d-4435-a5b7-6cfd4b14225f,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-994420d8-0209-4ced-a6ff-63fd2fa21eff,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-b471e168-fc77-467b-a00e-f59c9d7aa806,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-0856776b-1e10-49e5-a2dc-bc276cc2094b,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-0f58a0f5-47c1-414c-b164-aed797d179cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1218489315-172.17.0.5-1595901909067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35704,DS-5feecc09-88d5-46d7-b3d0-a88a42e2290d,DISK], DatanodeInfoWithStorage[127.0.0.1:40138,DS-59a46e33-1051-45ef-bb20-b4503563dc59,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-274ae156-efe8-4dc0-95bb-f8d68d46a0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-4156fb49-492d-4435-a5b7-6cfd4b14225f,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-994420d8-0209-4ced-a6ff-63fd2fa21eff,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-b471e168-fc77-467b-a00e-f59c9d7aa806,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-0856776b-1e10-49e5-a2dc-bc276cc2094b,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-0f58a0f5-47c1-414c-b164-aed797d179cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-683933045-172.17.0.5-1595901983655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39749,DS-d7a5e098-f0e3-4418-a0ef-f2ce7879da31,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-f6b7b1f0-8844-4b8e-b5e7-01a59238bcc0,DISK], DatanodeInfoWithStorage[127.0.0.1:44194,DS-1edc37ca-aa1a-47da-9d61-35f3386fc78f,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-fb27809d-653e-4cf4-ba61-30b1884acba1,DISK], DatanodeInfoWithStorage[127.0.0.1:45487,DS-a1e863f2-bd52-4c29-95cb-90c4ba8bb150,DISK], DatanodeInfoWithStorage[127.0.0.1:40075,DS-680d15f7-f761-4588-86cf-b3805be685b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41710,DS-c2c13607-f566-48fa-be14-d1344edefb57,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-4739dc7d-8897-44f3-a0a7-5353b594a772,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-683933045-172.17.0.5-1595901983655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39749,DS-d7a5e098-f0e3-4418-a0ef-f2ce7879da31,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-f6b7b1f0-8844-4b8e-b5e7-01a59238bcc0,DISK], DatanodeInfoWithStorage[127.0.0.1:44194,DS-1edc37ca-aa1a-47da-9d61-35f3386fc78f,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-fb27809d-653e-4cf4-ba61-30b1884acba1,DISK], DatanodeInfoWithStorage[127.0.0.1:45487,DS-a1e863f2-bd52-4c29-95cb-90c4ba8bb150,DISK], DatanodeInfoWithStorage[127.0.0.1:40075,DS-680d15f7-f761-4588-86cf-b3805be685b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41710,DS-c2c13607-f566-48fa-be14-d1344edefb57,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-4739dc7d-8897-44f3-a0a7-5353b594a772,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1609842843-172.17.0.5-1595902140607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46342,DS-a61e1509-8206-4494-b843-4dafbdf2ea09,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-8e8899f5-4b4f-4ba3-a84a-c15f868676b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-f4717657-29ae-4a01-91a8-6c2fbb0800b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-5e52ad41-999c-4217-a4d1-372582457e13,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-25ef6459-144c-4ea5-9221-4fb3c53f3be8,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-097bff35-7edc-4741-9224-267287cd1bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-45900598-acae-4ed1-bbfa-a624aa7ad574,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-fb1bc280-36ed-4975-9aaa-86bbcc273353,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1609842843-172.17.0.5-1595902140607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46342,DS-a61e1509-8206-4494-b843-4dafbdf2ea09,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-8e8899f5-4b4f-4ba3-a84a-c15f868676b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-f4717657-29ae-4a01-91a8-6c2fbb0800b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-5e52ad41-999c-4217-a4d1-372582457e13,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-25ef6459-144c-4ea5-9221-4fb3c53f3be8,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-097bff35-7edc-4741-9224-267287cd1bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-45900598-acae-4ed1-bbfa-a624aa7ad574,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-fb1bc280-36ed-4975-9aaa-86bbcc273353,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-988944644-172.17.0.5-1595902209038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44416,DS-846220e0-06ae-4911-ab49-c8bce198bf56,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-4f5780ea-b944-4134-a04a-9618df69799b,DISK], DatanodeInfoWithStorage[127.0.0.1:37254,DS-327b2f6e-3b67-41bd-bc3c-67377c28a849,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-fcbd6a94-0712-49ec-93a2-2538aae0805f,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-64c1de95-42a7-4acb-900f-fcde07db3cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-7596e3f3-8eb5-4c01-b25f-6ffd828814b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-d814baf8-3ade-4205-bdff-15d89772ae4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-9adca78f-d753-4f6c-8ccd-80b951706f32,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-988944644-172.17.0.5-1595902209038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44416,DS-846220e0-06ae-4911-ab49-c8bce198bf56,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-4f5780ea-b944-4134-a04a-9618df69799b,DISK], DatanodeInfoWithStorage[127.0.0.1:37254,DS-327b2f6e-3b67-41bd-bc3c-67377c28a849,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-fcbd6a94-0712-49ec-93a2-2538aae0805f,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-64c1de95-42a7-4acb-900f-fcde07db3cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-7596e3f3-8eb5-4c01-b25f-6ffd828814b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-d814baf8-3ade-4205-bdff-15d89772ae4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-9adca78f-d753-4f6c-8ccd-80b951706f32,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-343667299-172.17.0.5-1595902291067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45097,DS-a4b330c3-dfab-4c97-a9f5-775ec2df8b55,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-d01bae84-308c-41af-b68e-05c9f2e86db4,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-2dc8c4dc-da08-49ff-b9cd-b7408ded40b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-d93a058f-1651-4993-99ff-20e8eab9a8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39200,DS-27b89a0f-2b9a-4ec4-a2e1-6755bf9cf634,DISK], DatanodeInfoWithStorage[127.0.0.1:41755,DS-3c91da6d-26df-4c03-9a0d-1af8fa2dbcbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-6af90b6b-d34a-41fa-baf7-9781b789b2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-dbd598f0-6ac4-4114-ba27-4a6d8ae2265f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-343667299-172.17.0.5-1595902291067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45097,DS-a4b330c3-dfab-4c97-a9f5-775ec2df8b55,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-d01bae84-308c-41af-b68e-05c9f2e86db4,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-2dc8c4dc-da08-49ff-b9cd-b7408ded40b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-d93a058f-1651-4993-99ff-20e8eab9a8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39200,DS-27b89a0f-2b9a-4ec4-a2e1-6755bf9cf634,DISK], DatanodeInfoWithStorage[127.0.0.1:41755,DS-3c91da6d-26df-4c03-9a0d-1af8fa2dbcbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-6af90b6b-d34a-41fa-baf7-9781b789b2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-dbd598f0-6ac4-4114-ba27-4a6d8ae2265f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-496075510-172.17.0.5-1595902439108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43104,DS-32375ddd-9152-4a35-b00b-f74cc3931d62,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-e5e570eb-1dcf-436c-903d-3ca110184310,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-51b7a763-6e8f-494d-ac52-5bf409774094,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-50d565e0-9186-4d92-918e-12536460e8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-4a1dd3fa-7973-4a2c-b44f-f44b6f12f487,DISK], DatanodeInfoWithStorage[127.0.0.1:46356,DS-e45a575d-bb57-45d3-a05b-ccf4ac90d1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-b0772c85-1db5-4893-b2fc-5647abde6594,DISK], DatanodeInfoWithStorage[127.0.0.1:43832,DS-5d55b4da-e512-476a-8c36-dcf6173f1322,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-496075510-172.17.0.5-1595902439108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43104,DS-32375ddd-9152-4a35-b00b-f74cc3931d62,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-e5e570eb-1dcf-436c-903d-3ca110184310,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-51b7a763-6e8f-494d-ac52-5bf409774094,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-50d565e0-9186-4d92-918e-12536460e8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-4a1dd3fa-7973-4a2c-b44f-f44b6f12f487,DISK], DatanodeInfoWithStorage[127.0.0.1:46356,DS-e45a575d-bb57-45d3-a05b-ccf4ac90d1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-b0772c85-1db5-4893-b2fc-5647abde6594,DISK], DatanodeInfoWithStorage[127.0.0.1:43832,DS-5d55b4da-e512-476a-8c36-dcf6173f1322,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1357558529-172.17.0.5-1595902738151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33239,DS-d4751a19-dd48-481e-bf07-a1a5b0aeef59,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-4920fb86-f61d-4906-8837-73e665e23dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-cbba3cfe-ced4-4894-a90a-94547b7621c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41246,DS-d6f08192-cc47-49f0-aaa4-47b5cfd33d97,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-fa960f03-57c6-45d7-ab39-9fdcd77b5af3,DISK], DatanodeInfoWithStorage[127.0.0.1:39019,DS-d79d132e-7811-4d75-82c7-11eb96098ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:33697,DS-99a128e2-5a15-4492-a5dc-538b85dcbb42,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-3aed1660-cf31-480c-b568-51b4fdd62364,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1357558529-172.17.0.5-1595902738151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33239,DS-d4751a19-dd48-481e-bf07-a1a5b0aeef59,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-4920fb86-f61d-4906-8837-73e665e23dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-cbba3cfe-ced4-4894-a90a-94547b7621c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41246,DS-d6f08192-cc47-49f0-aaa4-47b5cfd33d97,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-fa960f03-57c6-45d7-ab39-9fdcd77b5af3,DISK], DatanodeInfoWithStorage[127.0.0.1:39019,DS-d79d132e-7811-4d75-82c7-11eb96098ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:33697,DS-99a128e2-5a15-4492-a5dc-538b85dcbb42,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-3aed1660-cf31-480c-b568-51b4fdd62364,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-795951246-172.17.0.5-1595902773951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43917,DS-4294567b-35f9-47cd-a781-36b40b6a3654,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-8b570564-004a-44d3-ba3b-74be1cb147f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-3eb4ac72-d7d7-41b6-98fe-d2166ecab805,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-492d0fe5-c283-459f-849c-a8bfff3397af,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-38bff2ba-e05b-42e0-a3ea-1d210d5fcd59,DISK], DatanodeInfoWithStorage[127.0.0.1:40702,DS-58ee0a15-d2e5-4d80-9482-967845766550,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-e0dc1329-c775-4434-a49d-afc0b83476ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36300,DS-5197929f-0dac-48f0-a96b-988f7761a813,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-795951246-172.17.0.5-1595902773951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43917,DS-4294567b-35f9-47cd-a781-36b40b6a3654,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-8b570564-004a-44d3-ba3b-74be1cb147f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-3eb4ac72-d7d7-41b6-98fe-d2166ecab805,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-492d0fe5-c283-459f-849c-a8bfff3397af,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-38bff2ba-e05b-42e0-a3ea-1d210d5fcd59,DISK], DatanodeInfoWithStorage[127.0.0.1:40702,DS-58ee0a15-d2e5-4d80-9482-967845766550,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-e0dc1329-c775-4434-a49d-afc0b83476ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36300,DS-5197929f-0dac-48f0-a96b-988f7761a813,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 100
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-415800094-172.17.0.5-1595902977852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43604,DS-3da9afc8-2627-4082-9ac3-ae81e038e43f,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-aac1c3df-16e5-4d76-91a6-b917331a1e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-322873e8-a452-41ca-8005-fcbb448129fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-42e609cd-c243-4c32-b507-c72c1a46e49d,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-3df94c26-d8d3-49f8-b61e-bb9669745892,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-a54ade04-a790-420b-bc16-ef8b77c70d09,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-935aaf92-0976-4b71-81c4-2fdb00b22e32,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-84251525-f28f-472a-946d-a753a90f1617,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-415800094-172.17.0.5-1595902977852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43604,DS-3da9afc8-2627-4082-9ac3-ae81e038e43f,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-aac1c3df-16e5-4d76-91a6-b917331a1e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-322873e8-a452-41ca-8005-fcbb448129fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-42e609cd-c243-4c32-b507-c72c1a46e49d,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-3df94c26-d8d3-49f8-b61e-bb9669745892,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-a54ade04-a790-420b-bc16-ef8b77c70d09,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-935aaf92-0976-4b71-81c4-2fdb00b22e32,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-84251525-f28f-472a-946d-a753a90f1617,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 27 out of 50
result: false positive !!!
Total execution time in seconds : 5478
