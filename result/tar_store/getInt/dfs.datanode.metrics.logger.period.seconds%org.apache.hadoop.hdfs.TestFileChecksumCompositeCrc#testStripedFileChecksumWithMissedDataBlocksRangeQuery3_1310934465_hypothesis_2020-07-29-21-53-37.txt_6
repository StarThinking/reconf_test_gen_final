reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2119162711-172.17.0.16-1596059881437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34015,DS-09f3dc0f-a2b5-451a-9a17-a5bbb4d684c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42329,DS-d85bc4c7-cbac-45f9-a4ed-c3a707b16f12,DISK], DatanodeInfoWithStorage[127.0.0.1:46384,DS-495a2b49-544b-468f-9097-36c90b8a389f,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-4662bcf5-13c2-4106-aa50-962e3c9b0a64,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-5690d404-ec93-43b8-b4ee-71c891fa4e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-48e2556e-887e-43a3-b8f1-e551ada6c8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-268b852b-b5b0-4afa-8f64-e77cd706ee53,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-a6fe8d2e-9f71-41c2-88e8-bcd66fa1052a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2119162711-172.17.0.16-1596059881437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34015,DS-09f3dc0f-a2b5-451a-9a17-a5bbb4d684c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42329,DS-d85bc4c7-cbac-45f9-a4ed-c3a707b16f12,DISK], DatanodeInfoWithStorage[127.0.0.1:46384,DS-495a2b49-544b-468f-9097-36c90b8a389f,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-4662bcf5-13c2-4106-aa50-962e3c9b0a64,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-5690d404-ec93-43b8-b4ee-71c891fa4e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-48e2556e-887e-43a3-b8f1-e551ada6c8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-268b852b-b5b0-4afa-8f64-e77cd706ee53,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-a6fe8d2e-9f71-41c2-88e8-bcd66fa1052a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-406128065-172.17.0.16-1596060463246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37289,DS-d46ce464-4626-4336-868b-0ff8d85f9bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-ad4d1ced-044d-4872-8e50-e04c64d4f1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-19838f84-e5f1-4dd9-9bec-81add8f1df5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-c172ddb7-097e-49b0-9dac-1f968fa69590,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-c6621e66-f3ba-4b11-a5f9-a2f9c039f7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-19e7e67b-82d7-42b6-a4c5-c61e4c1b5404,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-7bc8337a-76b2-4625-91cc-dbd1a179daa8,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-13250e92-d1e3-4c93-82e8-3f2489a144d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-406128065-172.17.0.16-1596060463246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37289,DS-d46ce464-4626-4336-868b-0ff8d85f9bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-ad4d1ced-044d-4872-8e50-e04c64d4f1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-19838f84-e5f1-4dd9-9bec-81add8f1df5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-c172ddb7-097e-49b0-9dac-1f968fa69590,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-c6621e66-f3ba-4b11-a5f9-a2f9c039f7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-19e7e67b-82d7-42b6-a4c5-c61e4c1b5404,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-7bc8337a-76b2-4625-91cc-dbd1a179daa8,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-13250e92-d1e3-4c93-82e8-3f2489a144d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1313694199-172.17.0.16-1596060548991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42336,DS-14d31aa9-e7b4-4b82-987b-8fdb1a85083e,DISK], DatanodeInfoWithStorage[127.0.0.1:42742,DS-dcb98f45-9eb6-40f4-ba51-7f9e44bd09e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33346,DS-86229ab0-3647-48a8-a19f-fe0ead5f0c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-e18b4449-82c4-4247-b96e-8c0002f6164a,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-a3e13847-6a88-43da-9e38-baa54108acdc,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-122eb543-c13c-45c0-9f41-348ed3e97942,DISK], DatanodeInfoWithStorage[127.0.0.1:41609,DS-6c9326e6-412c-432d-940e-1e7a6ae97a54,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-fd5654dc-5dca-42db-9373-4cb432a411e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1313694199-172.17.0.16-1596060548991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42336,DS-14d31aa9-e7b4-4b82-987b-8fdb1a85083e,DISK], DatanodeInfoWithStorage[127.0.0.1:42742,DS-dcb98f45-9eb6-40f4-ba51-7f9e44bd09e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33346,DS-86229ab0-3647-48a8-a19f-fe0ead5f0c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-e18b4449-82c4-4247-b96e-8c0002f6164a,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-a3e13847-6a88-43da-9e38-baa54108acdc,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-122eb543-c13c-45c0-9f41-348ed3e97942,DISK], DatanodeInfoWithStorage[127.0.0.1:41609,DS-6c9326e6-412c-432d-940e-1e7a6ae97a54,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-fd5654dc-5dca-42db-9373-4cb432a411e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1386579880-172.17.0.16-1596060827936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44738,DS-10a2ad4f-f5a1-4d9f-aece-c721c75f2a84,DISK], DatanodeInfoWithStorage[127.0.0.1:39829,DS-d56ac1f8-7f8a-41c3-9175-3b07b1e64283,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-008922ec-3056-4288-9360-cdf8efddd31c,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-c9cfaa53-8e3f-40b1-a9ae-e836c8c47e93,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-8b16ce38-31c2-4ae6-a247-f4c193f07047,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-0eac6877-9318-4640-b485-92a69fa4f904,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-c631a3da-08c8-408c-8591-fe8534ba8689,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-b575f635-4104-45b0-a042-3458569d1af5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1386579880-172.17.0.16-1596060827936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44738,DS-10a2ad4f-f5a1-4d9f-aece-c721c75f2a84,DISK], DatanodeInfoWithStorage[127.0.0.1:39829,DS-d56ac1f8-7f8a-41c3-9175-3b07b1e64283,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-008922ec-3056-4288-9360-cdf8efddd31c,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-c9cfaa53-8e3f-40b1-a9ae-e836c8c47e93,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-8b16ce38-31c2-4ae6-a247-f4c193f07047,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-0eac6877-9318-4640-b485-92a69fa4f904,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-c631a3da-08c8-408c-8591-fe8534ba8689,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-b575f635-4104-45b0-a042-3458569d1af5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1368505943-172.17.0.16-1596061743879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45287,DS-5a983b74-e926-4f24-bece-1ab215205f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-d831303a-2034-4d08-b102-323b8c414216,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-aec08178-0ef4-48af-a2ac-0e7a51f01329,DISK], DatanodeInfoWithStorage[127.0.0.1:42614,DS-9e5ebf06-5529-4660-ba5f-ea303683abb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42464,DS-dc73253a-cf39-479e-b5b1-08b6d8b61038,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-42f1535d-4548-43ac-b117-881dd0536f27,DISK], DatanodeInfoWithStorage[127.0.0.1:36187,DS-faa86afe-4491-40a8-9efd-b2db3d7da88c,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-ac73617f-a0f7-4332-b615-e37e1fadf6f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1368505943-172.17.0.16-1596061743879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45287,DS-5a983b74-e926-4f24-bece-1ab215205f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-d831303a-2034-4d08-b102-323b8c414216,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-aec08178-0ef4-48af-a2ac-0e7a51f01329,DISK], DatanodeInfoWithStorage[127.0.0.1:42614,DS-9e5ebf06-5529-4660-ba5f-ea303683abb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42464,DS-dc73253a-cf39-479e-b5b1-08b6d8b61038,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-42f1535d-4548-43ac-b117-881dd0536f27,DISK], DatanodeInfoWithStorage[127.0.0.1:36187,DS-faa86afe-4491-40a8-9efd-b2db3d7da88c,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-ac73617f-a0f7-4332-b615-e37e1fadf6f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-781079579-172.17.0.16-1596062067241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43903,DS-fae9fbd3-3190-4785-8adb-a8bf85bc68bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42269,DS-70749098-a793-47bd-a8a7-a835612e3409,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-dd776780-c2d0-4843-8553-740dd7f8dfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-fe570db1-6dba-467b-a6a9-ca442b97f5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45168,DS-8b949abe-9db6-45c3-8352-8708f056f48a,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-12ac7476-1823-444d-a004-05a682b76fac,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-0a12ce16-ae4c-4e83-b851-0c678f57ab6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-5a0a7034-90dd-4488-97b4-0f6c667186b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-781079579-172.17.0.16-1596062067241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43903,DS-fae9fbd3-3190-4785-8adb-a8bf85bc68bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42269,DS-70749098-a793-47bd-a8a7-a835612e3409,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-dd776780-c2d0-4843-8553-740dd7f8dfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-fe570db1-6dba-467b-a6a9-ca442b97f5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45168,DS-8b949abe-9db6-45c3-8352-8708f056f48a,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-12ac7476-1823-444d-a004-05a682b76fac,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-0a12ce16-ae4c-4e83-b851-0c678f57ab6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-5a0a7034-90dd-4488-97b4-0f6c667186b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-150550131-172.17.0.16-1596062847273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34440,DS-b389c382-dcf4-4526-a3b1-77aa378f06d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43448,DS-0f102d5a-53ec-4117-b155-e26a5d415c92,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-0e3e8882-fbf4-46f7-9206-38f12cfe6b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-ec5fcd1b-7943-46a1-a238-62282e40b87f,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-8768d602-44d0-4d69-a554-5627dc72a5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-a092b5da-8f9f-4585-a100-ac706df25de9,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-4f678268-17da-4f8f-8199-5105ec717e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-de028bf5-f2ed-474f-a0f4-4c7aff305cec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-150550131-172.17.0.16-1596062847273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34440,DS-b389c382-dcf4-4526-a3b1-77aa378f06d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43448,DS-0f102d5a-53ec-4117-b155-e26a5d415c92,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-0e3e8882-fbf4-46f7-9206-38f12cfe6b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-ec5fcd1b-7943-46a1-a238-62282e40b87f,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-8768d602-44d0-4d69-a554-5627dc72a5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-a092b5da-8f9f-4585-a100-ac706df25de9,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-4f678268-17da-4f8f-8199-5105ec717e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-de028bf5-f2ed-474f-a0f4-4c7aff305cec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1271362315-172.17.0.16-1596063234095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33328,DS-39f1b378-afed-4853-a49e-f732aee56c11,DISK], DatanodeInfoWithStorage[127.0.0.1:36047,DS-2be86eb3-7a0c-43ef-9119-ae0dfdff9126,DISK], DatanodeInfoWithStorage[127.0.0.1:34159,DS-b3507f82-004d-4f9e-995b-d41e244b682d,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-f510ec50-e7d0-4b58-928b-8000c9ea4f51,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-3831c760-440b-4c34-b917-bea2ae503915,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-811b3111-8a4f-4544-a182-1f3dacb64c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-1965c2ce-89e4-4ea2-8fa1-2ca8e3eab8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-62ba5700-041b-4bfd-a556-7e4363daf00f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1271362315-172.17.0.16-1596063234095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33328,DS-39f1b378-afed-4853-a49e-f732aee56c11,DISK], DatanodeInfoWithStorage[127.0.0.1:36047,DS-2be86eb3-7a0c-43ef-9119-ae0dfdff9126,DISK], DatanodeInfoWithStorage[127.0.0.1:34159,DS-b3507f82-004d-4f9e-995b-d41e244b682d,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-f510ec50-e7d0-4b58-928b-8000c9ea4f51,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-3831c760-440b-4c34-b917-bea2ae503915,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-811b3111-8a4f-4544-a182-1f3dacb64c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-1965c2ce-89e4-4ea2-8fa1-2ca8e3eab8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-62ba5700-041b-4bfd-a556-7e4363daf00f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-499905945-172.17.0.16-1596063593356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42922,DS-cd7662d2-e804-469d-a7b1-df38c0ee9f67,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-7d764427-6c08-4426-bb3a-96f2b57af230,DISK], DatanodeInfoWithStorage[127.0.0.1:46022,DS-cf512041-37a9-4899-b8b4-6099fbcaa38d,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-be844aa8-7e8f-40b7-9530-ddd04017a1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-3bd50345-f206-44e8-af48-df8ce62d0e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-1fbaa83c-a1c1-42d6-b7d7-eb022f585886,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-c5db4286-79d6-4efe-b88e-b6042594e10f,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-168cf1c3-2c8c-41d0-8e6b-a4e849b0033b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-499905945-172.17.0.16-1596063593356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42922,DS-cd7662d2-e804-469d-a7b1-df38c0ee9f67,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-7d764427-6c08-4426-bb3a-96f2b57af230,DISK], DatanodeInfoWithStorage[127.0.0.1:46022,DS-cf512041-37a9-4899-b8b4-6099fbcaa38d,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-be844aa8-7e8f-40b7-9530-ddd04017a1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-3bd50345-f206-44e8-af48-df8ce62d0e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-1fbaa83c-a1c1-42d6-b7d7-eb022f585886,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-c5db4286-79d6-4efe-b88e-b6042594e10f,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-168cf1c3-2c8c-41d0-8e6b-a4e849b0033b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2064438356-172.17.0.16-1596063763720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35369,DS-6f560739-b44b-4757-8781-6d8d5d1d2427,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-417eb3a8-e4dd-46bc-944a-f54c644d26d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-a238e92e-1185-4531-8fb7-05ce6c28f4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-7cee214e-e78b-46c9-b4fa-a5268ac762ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-2600a80e-edcf-4fe0-a510-209ce41a4a15,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-a05f5a09-8937-4feb-af24-ed0aca2abab7,DISK], DatanodeInfoWithStorage[127.0.0.1:40198,DS-eb827dba-4789-4523-a1c0-220d2dd0acc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-3d293cd7-a2fb-4e76-b0ca-43cdabc1e5fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2064438356-172.17.0.16-1596063763720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35369,DS-6f560739-b44b-4757-8781-6d8d5d1d2427,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-417eb3a8-e4dd-46bc-944a-f54c644d26d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-a238e92e-1185-4531-8fb7-05ce6c28f4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-7cee214e-e78b-46c9-b4fa-a5268ac762ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-2600a80e-edcf-4fe0-a510-209ce41a4a15,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-a05f5a09-8937-4feb-af24-ed0aca2abab7,DISK], DatanodeInfoWithStorage[127.0.0.1:40198,DS-eb827dba-4789-4523-a1c0-220d2dd0acc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-3d293cd7-a2fb-4e76-b0ca-43cdabc1e5fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1786611818-172.17.0.16-1596064130911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43816,DS-0c0411bd-1e68-4b04-b309-a754b8b2c478,DISK], DatanodeInfoWithStorage[127.0.0.1:40059,DS-b5434ed3-7cd8-411b-883c-aae3f081be28,DISK], DatanodeInfoWithStorage[127.0.0.1:39785,DS-a417de7c-4555-45c5-b93f-6a695e683fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:33154,DS-148ae0f2-3eb0-43af-a750-7e1b47695067,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-c7cdd0f1-3039-4f9e-9e81-84c925cbd726,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-f01be9c1-ed0a-4dbd-8ef0-5a19f2fca0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-561a6e4e-92f7-4fd7-be0b-5e2238e531c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33563,DS-0db2a8dd-dafa-487c-b6a9-115f0c8ca52e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1786611818-172.17.0.16-1596064130911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43816,DS-0c0411bd-1e68-4b04-b309-a754b8b2c478,DISK], DatanodeInfoWithStorage[127.0.0.1:40059,DS-b5434ed3-7cd8-411b-883c-aae3f081be28,DISK], DatanodeInfoWithStorage[127.0.0.1:39785,DS-a417de7c-4555-45c5-b93f-6a695e683fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:33154,DS-148ae0f2-3eb0-43af-a750-7e1b47695067,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-c7cdd0f1-3039-4f9e-9e81-84c925cbd726,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-f01be9c1-ed0a-4dbd-8ef0-5a19f2fca0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-561a6e4e-92f7-4fd7-be0b-5e2238e531c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33563,DS-0db2a8dd-dafa-487c-b6a9-115f0c8ca52e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-886464820-172.17.0.16-1596064252864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33379,DS-e6b3d12d-2021-45b7-bc20-839c84e68d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43433,DS-4cc3edb8-4e95-4ce4-ad00-fdeb036b45fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38108,DS-a5165052-91b4-48a5-8825-f057d566c240,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-10f8e5d1-6453-4f67-82f7-d866743216de,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-1dd5ba6f-0446-4401-8cd6-6292eecf190d,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-7c7a9af1-815a-48fd-8c77-ff432c83aa4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-569295ba-8c52-4a64-9fde-c9bad20f4615,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-df9659b9-a275-444d-ae68-d43066b3b3ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-886464820-172.17.0.16-1596064252864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33379,DS-e6b3d12d-2021-45b7-bc20-839c84e68d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43433,DS-4cc3edb8-4e95-4ce4-ad00-fdeb036b45fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38108,DS-a5165052-91b4-48a5-8825-f057d566c240,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-10f8e5d1-6453-4f67-82f7-d866743216de,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-1dd5ba6f-0446-4401-8cd6-6292eecf190d,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-7c7a9af1-815a-48fd-8c77-ff432c83aa4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-569295ba-8c52-4a64-9fde-c9bad20f4615,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-df9659b9-a275-444d-ae68-d43066b3b3ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2033648371-172.17.0.16-1596065045183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32769,DS-0fe248d5-045a-4473-8c33-3c362ca57d52,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-885526e0-6892-47e8-a266-1b5c3aabf008,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-aaf6f8d5-c0d9-4485-829a-f1939d72a31d,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-0885dcd3-d2de-4be9-9b94-ad11678af26e,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-b5c8f504-a4bc-4757-b037-030ba201253e,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-a3d5287b-77dd-4cc0-82b3-f070841ee6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-26927f0c-05e0-431a-b3c2-b74511ca89da,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-359668c4-bd96-4f05-a941-da55f0344adf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2033648371-172.17.0.16-1596065045183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32769,DS-0fe248d5-045a-4473-8c33-3c362ca57d52,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-885526e0-6892-47e8-a266-1b5c3aabf008,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-aaf6f8d5-c0d9-4485-829a-f1939d72a31d,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-0885dcd3-d2de-4be9-9b94-ad11678af26e,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-b5c8f504-a4bc-4757-b037-030ba201253e,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-a3d5287b-77dd-4cc0-82b3-f070841ee6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-26927f0c-05e0-431a-b3c2-b74511ca89da,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-359668c4-bd96-4f05-a941-da55f0344adf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-20124873-172.17.0.16-1596065269859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44241,DS-daf532b9-c9dc-45a9-a298-a1ff9952db8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-9df79220-5812-4c4c-a1c9-a153acf17d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-d2731469-b023-4271-8592-57706ebe2691,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-0e5e98b8-e7cd-4204-abc6-545e65a2bf9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-3388802c-0363-4b94-842c-df5e88921f78,DISK], DatanodeInfoWithStorage[127.0.0.1:39474,DS-6b6b65a1-0155-43fc-8560-e111c20fbb53,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-2922cb16-8b53-4831-b1f5-7d7948e5dcda,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-3e132fb4-0736-4e93-940a-59f220a18655,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-20124873-172.17.0.16-1596065269859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44241,DS-daf532b9-c9dc-45a9-a298-a1ff9952db8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-9df79220-5812-4c4c-a1c9-a153acf17d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-d2731469-b023-4271-8592-57706ebe2691,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-0e5e98b8-e7cd-4204-abc6-545e65a2bf9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-3388802c-0363-4b94-842c-df5e88921f78,DISK], DatanodeInfoWithStorage[127.0.0.1:39474,DS-6b6b65a1-0155-43fc-8560-e111c20fbb53,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-2922cb16-8b53-4831-b1f5-7d7948e5dcda,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-3e132fb4-0736-4e93-940a-59f220a18655,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1942226476-172.17.0.16-1596065364670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45175,DS-b86589b9-0001-48a5-9d8b-bf55f6a14d53,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-21bb3d1e-d697-4a0b-8ecf-ebfc0ba7dfcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-c3afeb0c-2339-4f4f-bd34-bdd3eac11cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-945e74fe-26b9-4596-b7b4-529898875a97,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-39856262-a8d1-4e46-9eb6-1e61176339b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-d3b0dbc5-950e-4446-aa92-fc9003134438,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-d75b7242-2ed2-41b8-b791-f50eefae0170,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-84db42f0-c148-4e8c-8568-1eec6802e590,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1942226476-172.17.0.16-1596065364670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45175,DS-b86589b9-0001-48a5-9d8b-bf55f6a14d53,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-21bb3d1e-d697-4a0b-8ecf-ebfc0ba7dfcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-c3afeb0c-2339-4f4f-bd34-bdd3eac11cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-945e74fe-26b9-4596-b7b4-529898875a97,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-39856262-a8d1-4e46-9eb6-1e61176339b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-d3b0dbc5-950e-4446-aa92-fc9003134438,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-d75b7242-2ed2-41b8-b791-f50eefae0170,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-84db42f0-c148-4e8c-8568-1eec6802e590,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-90881915-172.17.0.16-1596065446261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38621,DS-5902de5e-3fc2-45c0-9cb9-f6072737ea9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-9c63ad24-da98-4b4a-a799-d1c59a9c24ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-2448df52-8e72-44b7-bc4c-3f7934878af5,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-4f0ab7d2-ba30-4c23-8f5f-06a8637c4094,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-6f665a28-2597-4ceb-b912-5b85756e1376,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-0cb051bd-2d93-457b-84ac-153158349f24,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-a6fa6406-c05f-4ad5-930a-b751ae8ce911,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-84c2cee2-b73e-4b74-9a23-a67b9b948864,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-90881915-172.17.0.16-1596065446261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38621,DS-5902de5e-3fc2-45c0-9cb9-f6072737ea9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-9c63ad24-da98-4b4a-a799-d1c59a9c24ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-2448df52-8e72-44b7-bc4c-3f7934878af5,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-4f0ab7d2-ba30-4c23-8f5f-06a8637c4094,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-6f665a28-2597-4ceb-b912-5b85756e1376,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-0cb051bd-2d93-457b-84ac-153158349f24,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-a6fa6406-c05f-4ad5-930a-b751ae8ce911,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-84c2cee2-b73e-4b74-9a23-a67b9b948864,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314586624-172.17.0.16-1596065714737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41220,DS-b217837e-0909-4977-b159-2c9c56e1b8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45913,DS-5bbdbbbf-dc3f-41cd-b594-5da7e46d8b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-d1328c64-3f77-4272-b927-2e33f85105d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-db6f58a4-f360-44fe-8871-5d8e9fcd1517,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-bb484313-57e1-43d3-9c73-7c9b84c777f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42523,DS-fe6f38cc-78b1-4149-a8e4-aa189bedde5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-337245c3-3a1c-4bb0-b8cf-400b9726ac9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-5e81f02e-93b5-4de3-b289-cb7a363d1916,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314586624-172.17.0.16-1596065714737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41220,DS-b217837e-0909-4977-b159-2c9c56e1b8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45913,DS-5bbdbbbf-dc3f-41cd-b594-5da7e46d8b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-d1328c64-3f77-4272-b927-2e33f85105d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-db6f58a4-f360-44fe-8871-5d8e9fcd1517,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-bb484313-57e1-43d3-9c73-7c9b84c777f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42523,DS-fe6f38cc-78b1-4149-a8e4-aa189bedde5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-337245c3-3a1c-4bb0-b8cf-400b9726ac9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-5e81f02e-93b5-4de3-b289-cb7a363d1916,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1952807289-172.17.0.16-1596065997117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33978,DS-e88239fa-279d-4e6f-9670-97ce75d2ca3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-cf8461d8-6df0-4889-a449-06538a6d0d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-a893a74e-08d6-4f80-9e00-ccb04fbca543,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-3f83e0e0-b913-4eec-a49e-7ce91d4a7451,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-b0f7e252-55b9-4ce1-84cd-7bfb82858c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-7245365f-a8f0-4109-83ce-6286a235415e,DISK], DatanodeInfoWithStorage[127.0.0.1:35123,DS-c7117811-b9a8-4f9d-bbd8-aa39552a414c,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-757ffcf3-f159-4ce3-8070-ae358e6a3db8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1952807289-172.17.0.16-1596065997117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33978,DS-e88239fa-279d-4e6f-9670-97ce75d2ca3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-cf8461d8-6df0-4889-a449-06538a6d0d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-a893a74e-08d6-4f80-9e00-ccb04fbca543,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-3f83e0e0-b913-4eec-a49e-7ce91d4a7451,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-b0f7e252-55b9-4ce1-84cd-7bfb82858c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-7245365f-a8f0-4109-83ce-6286a235415e,DISK], DatanodeInfoWithStorage[127.0.0.1:35123,DS-c7117811-b9a8-4f9d-bbd8-aa39552a414c,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-757ffcf3-f159-4ce3-8070-ae358e6a3db8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 6412
