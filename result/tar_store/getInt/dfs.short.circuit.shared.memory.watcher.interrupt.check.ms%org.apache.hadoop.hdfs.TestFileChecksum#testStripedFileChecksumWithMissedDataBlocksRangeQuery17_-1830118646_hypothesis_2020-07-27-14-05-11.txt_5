reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-639470362-172.17.0.11-1595858797321:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41554,DS-8770b73f-616b-4a6c-97bd-74798a13389c,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-108f6a77-e099-4f10-96a8-b98b1c8748d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44302,DS-fbabd6e2-5455-4bbd-ae15-7dc7c07f5dad,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-94b2587c-17b8-418e-a65e-6ecd1d7f4b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38983,DS-df9c2484-0bff-4f68-a790-71d824c3c135,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-7a5d6c47-ccae-4c40-ac06-f222b358ddf7,DISK], DatanodeInfoWithStorage[127.0.0.1:39528,DS-e7f4ab45-12ec-4ba9-aa3b-4af6050d070a,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-c255580c-ac21-4e83-b922-ec716c7e6c2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-639470362-172.17.0.11-1595858797321:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41554,DS-8770b73f-616b-4a6c-97bd-74798a13389c,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-108f6a77-e099-4f10-96a8-b98b1c8748d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44302,DS-fbabd6e2-5455-4bbd-ae15-7dc7c07f5dad,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-94b2587c-17b8-418e-a65e-6ecd1d7f4b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38983,DS-df9c2484-0bff-4f68-a790-71d824c3c135,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-7a5d6c47-ccae-4c40-ac06-f222b358ddf7,DISK], DatanodeInfoWithStorage[127.0.0.1:39528,DS-e7f4ab45-12ec-4ba9-aa3b-4af6050d070a,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-c255580c-ac21-4e83-b922-ec716c7e6c2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2036335972-172.17.0.11-1595859058859:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37522,DS-8657293e-6049-4526-ab15-42cea26e60e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-7ee6f866-fd1c-42de-82bf-cf829a694bce,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-1acaeeca-907d-4662-ac5a-6a75dced7160,DISK], DatanodeInfoWithStorage[127.0.0.1:40785,DS-6193c502-3bcc-4908-9bb3-57ff6b1632b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44913,DS-e0fb705b-4021-426d-a6e1-d7df9cd1dc64,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-a9786945-4c1b-417f-854f-26ac1dfbd9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-3d8d4159-b83e-4a59-b8c8-d622122fe643,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-404c0653-eb0b-4b0f-a352-67bc41b70094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2036335972-172.17.0.11-1595859058859:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37522,DS-8657293e-6049-4526-ab15-42cea26e60e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-7ee6f866-fd1c-42de-82bf-cf829a694bce,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-1acaeeca-907d-4662-ac5a-6a75dced7160,DISK], DatanodeInfoWithStorage[127.0.0.1:40785,DS-6193c502-3bcc-4908-9bb3-57ff6b1632b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44913,DS-e0fb705b-4021-426d-a6e1-d7df9cd1dc64,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-a9786945-4c1b-417f-854f-26ac1dfbd9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-3d8d4159-b83e-4a59-b8c8-d622122fe643,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-404c0653-eb0b-4b0f-a352-67bc41b70094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1853923460-172.17.0.11-1595859376551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42701,DS-b3ec4fa4-1ada-49d1-8465-829eefcc986a,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-b57af828-4541-4660-a756-e913e5cdff8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-b37217c6-f420-48c7-a409-b0367d16d92b,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-99d31fc4-f1fa-4ec4-83ed-5041242cca2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39634,DS-f9ea5833-8a18-40bc-8dfe-b05753e8cb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-9c5fe12e-1b9d-4f13-8025-17bad03a1f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-b479e3fe-e401-4dd1-ac08-368d8af54921,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-0d1e5ba4-0e41-43f3-9d1f-b3202a9cad98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1853923460-172.17.0.11-1595859376551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42701,DS-b3ec4fa4-1ada-49d1-8465-829eefcc986a,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-b57af828-4541-4660-a756-e913e5cdff8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-b37217c6-f420-48c7-a409-b0367d16d92b,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-99d31fc4-f1fa-4ec4-83ed-5041242cca2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39634,DS-f9ea5833-8a18-40bc-8dfe-b05753e8cb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-9c5fe12e-1b9d-4f13-8025-17bad03a1f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-b479e3fe-e401-4dd1-ac08-368d8af54921,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-0d1e5ba4-0e41-43f3-9d1f-b3202a9cad98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1002671855-172.17.0.11-1595859443418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32854,DS-18fe2485-d7d5-418b-af01-560ec205dd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37051,DS-ac3ff0c6-16b5-4fc0-b73d-8c3cb362627c,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-8675f26f-8343-4bc0-a236-5ea77a238652,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-f648c274-e463-44ef-99e5-f49799c2e69b,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-5dca2807-ef57-456b-8158-67dead8826e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35050,DS-023f8f4a-01ba-4797-8de9-1b2149237d21,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-0cfe5c5a-f0c7-4519-b24f-b9cb01bf253f,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-649e0e1f-94a4-4bca-94cf-1b0d8be55b5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1002671855-172.17.0.11-1595859443418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32854,DS-18fe2485-d7d5-418b-af01-560ec205dd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37051,DS-ac3ff0c6-16b5-4fc0-b73d-8c3cb362627c,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-8675f26f-8343-4bc0-a236-5ea77a238652,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-f648c274-e463-44ef-99e5-f49799c2e69b,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-5dca2807-ef57-456b-8158-67dead8826e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35050,DS-023f8f4a-01ba-4797-8de9-1b2149237d21,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-0cfe5c5a-f0c7-4519-b24f-b9cb01bf253f,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-649e0e1f-94a4-4bca-94cf-1b0d8be55b5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1574959983-172.17.0.11-1595860091096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44859,DS-64f96467-c685-408d-a34d-d77bae2182ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34818,DS-443d828a-5cf1-4fee-99db-e57014669e07,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-a57b6e0d-f6be-4700-8421-09e7150201b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-e9c23537-7fc3-484d-a79b-f54fc50416ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46117,DS-e2413553-c0d2-4512-8d9e-358deeee3dff,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-7b7826bc-3cb9-4be4-80a6-06e80bd67a06,DISK], DatanodeInfoWithStorage[127.0.0.1:41012,DS-5381d6da-84af-4b72-bb4b-ac0575c9f9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:32904,DS-7dd08600-a887-47d7-b2fb-0aa21fa29978,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1574959983-172.17.0.11-1595860091096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44859,DS-64f96467-c685-408d-a34d-d77bae2182ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34818,DS-443d828a-5cf1-4fee-99db-e57014669e07,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-a57b6e0d-f6be-4700-8421-09e7150201b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-e9c23537-7fc3-484d-a79b-f54fc50416ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46117,DS-e2413553-c0d2-4512-8d9e-358deeee3dff,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-7b7826bc-3cb9-4be4-80a6-06e80bd67a06,DISK], DatanodeInfoWithStorage[127.0.0.1:41012,DS-5381d6da-84af-4b72-bb4b-ac0575c9f9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:32904,DS-7dd08600-a887-47d7-b2fb-0aa21fa29978,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1819413322-172.17.0.11-1595860201999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36950,DS-afc2700d-1d6e-445c-b08b-4b9ead4fdb14,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-6fbd3b1a-26b5-43cc-be0a-11e9105e4baf,DISK], DatanodeInfoWithStorage[127.0.0.1:46697,DS-b0a3093f-3550-4fa4-a3c8-bbd5020c296a,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-9b4efa0a-6a2a-48a3-a1ae-d8d4eee001fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-7fb9d234-5863-4e70-9e44-86f90a7190a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-57fcddd8-ab88-4fdd-a839-a6d4dae8926b,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-594a7ccb-8940-432a-a011-3cbe9d96d0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39681,DS-d2b8ecd7-ce20-42f5-897a-4bc84dc49234,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1819413322-172.17.0.11-1595860201999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36950,DS-afc2700d-1d6e-445c-b08b-4b9ead4fdb14,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-6fbd3b1a-26b5-43cc-be0a-11e9105e4baf,DISK], DatanodeInfoWithStorage[127.0.0.1:46697,DS-b0a3093f-3550-4fa4-a3c8-bbd5020c296a,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-9b4efa0a-6a2a-48a3-a1ae-d8d4eee001fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-7fb9d234-5863-4e70-9e44-86f90a7190a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-57fcddd8-ab88-4fdd-a839-a6d4dae8926b,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-594a7ccb-8940-432a-a011-3cbe9d96d0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39681,DS-d2b8ecd7-ce20-42f5-897a-4bc84dc49234,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2131264956-172.17.0.11-1595860386877:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46757,DS-6551ec81-c47e-41e2-87ed-f67610dc36c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-bd1db688-f662-4f18-b58f-67012d4d1055,DISK], DatanodeInfoWithStorage[127.0.0.1:37358,DS-80e080a1-b288-4357-9023-2f435285e3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-dcea63e6-7934-4d7c-a1e5-70bcc44deb5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-aee0deb3-9add-48c7-9886-fda8df4d2784,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-d1bcaa29-cca4-4f4c-9469-9fd420c38da8,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-6d9fed87-1260-4610-bf7c-3e334e1d6275,DISK], DatanodeInfoWithStorage[127.0.0.1:36355,DS-6c0d4995-68f6-4bf3-bea4-8dbc2b0dd3b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2131264956-172.17.0.11-1595860386877:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46757,DS-6551ec81-c47e-41e2-87ed-f67610dc36c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-bd1db688-f662-4f18-b58f-67012d4d1055,DISK], DatanodeInfoWithStorage[127.0.0.1:37358,DS-80e080a1-b288-4357-9023-2f435285e3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-dcea63e6-7934-4d7c-a1e5-70bcc44deb5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-aee0deb3-9add-48c7-9886-fda8df4d2784,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-d1bcaa29-cca4-4f4c-9469-9fd420c38da8,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-6d9fed87-1260-4610-bf7c-3e334e1d6275,DISK], DatanodeInfoWithStorage[127.0.0.1:36355,DS-6c0d4995-68f6-4bf3-bea4-8dbc2b0dd3b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-198150272-172.17.0.11-1595860531856:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45612,DS-0bc6db3a-9661-4e4c-8b10-1cba378a1338,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-13eb575f-cb97-47c7-89fd-72418258229c,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-95cce38e-2320-443d-a5ea-5bd824c84e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-ca503939-e82a-4d99-a14a-4eea97c18173,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-b21f6ff9-bd24-44d1-9726-f0111f6482ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-bfeb0149-5e52-4155-8de9-2202b372e5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-b8db4f48-dda3-4308-80f8-32c525df7a26,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-d5dcc96c-ccd2-4a02-b034-72e0903015b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-198150272-172.17.0.11-1595860531856:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45612,DS-0bc6db3a-9661-4e4c-8b10-1cba378a1338,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-13eb575f-cb97-47c7-89fd-72418258229c,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-95cce38e-2320-443d-a5ea-5bd824c84e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-ca503939-e82a-4d99-a14a-4eea97c18173,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-b21f6ff9-bd24-44d1-9726-f0111f6482ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-bfeb0149-5e52-4155-8de9-2202b372e5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-b8db4f48-dda3-4308-80f8-32c525df7a26,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-d5dcc96c-ccd2-4a02-b034-72e0903015b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1553228711-172.17.0.11-1595861359289:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44616,DS-7f8d846c-c98a-42ba-b4c3-28308d910126,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-7f031b94-993f-405d-8072-482792a28418,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-07898f49-f1aa-432d-aa51-425b00ae5fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-df2116ef-acb9-440d-bf25-7eee46af0247,DISK], DatanodeInfoWithStorage[127.0.0.1:41819,DS-ce16dfb4-3ff3-4d3c-8ecf-4adf10f4c729,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-93748bd6-c211-4f66-80ec-f319dfd406b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-74ea5178-401b-4304-a50f-e94e49510942,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-5696c1a0-87c0-4d7c-920c-92bee2b717cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1553228711-172.17.0.11-1595861359289:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44616,DS-7f8d846c-c98a-42ba-b4c3-28308d910126,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-7f031b94-993f-405d-8072-482792a28418,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-07898f49-f1aa-432d-aa51-425b00ae5fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-df2116ef-acb9-440d-bf25-7eee46af0247,DISK], DatanodeInfoWithStorage[127.0.0.1:41819,DS-ce16dfb4-3ff3-4d3c-8ecf-4adf10f4c729,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-93748bd6-c211-4f66-80ec-f319dfd406b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-74ea5178-401b-4304-a50f-e94e49510942,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-5696c1a0-87c0-4d7c-920c-92bee2b717cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1672263946-172.17.0.11-1595861691091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38966,DS-b3ebb8a1-a1c8-45ff-9316-3e3b2fd1b5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-34aefd19-decb-49e9-bf23-ec51961cbb61,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-0f1b31b9-fb8e-4b0e-b1de-efce9d9e8d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-99c7b4c7-8b06-4125-b062-a08477d7277d,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-4f15e225-e104-4c3c-a2ed-f1881714a16d,DISK], DatanodeInfoWithStorage[127.0.0.1:46606,DS-8ef04fb6-fa88-4262-935a-d0e123c03ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:43442,DS-d52a4bcf-3235-4491-941f-5d6a34537ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-d5926351-9c58-4143-baa7-6badf60b24d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1672263946-172.17.0.11-1595861691091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38966,DS-b3ebb8a1-a1c8-45ff-9316-3e3b2fd1b5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-34aefd19-decb-49e9-bf23-ec51961cbb61,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-0f1b31b9-fb8e-4b0e-b1de-efce9d9e8d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-99c7b4c7-8b06-4125-b062-a08477d7277d,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-4f15e225-e104-4c3c-a2ed-f1881714a16d,DISK], DatanodeInfoWithStorage[127.0.0.1:46606,DS-8ef04fb6-fa88-4262-935a-d0e123c03ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:43442,DS-d52a4bcf-3235-4491-941f-5d6a34537ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-d5926351-9c58-4143-baa7-6badf60b24d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-881165127-172.17.0.11-1595861725139:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45694,DS-45aac6ad-1460-4763-be00-261e81e7f160,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-5e391417-5423-4abd-9068-47ac71791898,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-e5fe0b58-9c98-4c14-a8f2-7c6a1c621111,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-c9ccf98d-1d5e-457d-8b8d-2cb26e707e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-77c4f1d7-f066-42c2-b316-56dfeae7aa91,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-26099804-c05c-455f-b3a7-4e654778fedd,DISK], DatanodeInfoWithStorage[127.0.0.1:40063,DS-fc2ba54b-8bd9-4ccb-8b05-073cce2ee2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38418,DS-7dfa59f5-40b0-49e0-8224-583bbd558ce1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-881165127-172.17.0.11-1595861725139:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45694,DS-45aac6ad-1460-4763-be00-261e81e7f160,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-5e391417-5423-4abd-9068-47ac71791898,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-e5fe0b58-9c98-4c14-a8f2-7c6a1c621111,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-c9ccf98d-1d5e-457d-8b8d-2cb26e707e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-77c4f1d7-f066-42c2-b316-56dfeae7aa91,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-26099804-c05c-455f-b3a7-4e654778fedd,DISK], DatanodeInfoWithStorage[127.0.0.1:40063,DS-fc2ba54b-8bd9-4ccb-8b05-073cce2ee2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38418,DS-7dfa59f5-40b0-49e0-8224-583bbd558ce1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1133482998-172.17.0.11-1595861932414:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40953,DS-995740e1-243e-4cf9-949f-db533aa57e59,DISK], DatanodeInfoWithStorage[127.0.0.1:45814,DS-75da1b65-2640-45b8-868a-3671980cbb41,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-668b68b5-7299-445a-bef2-121c8dbe1231,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-7491a5a3-eed5-4351-a94b-7a5f21ee5e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-2438258f-f376-446d-b178-05f200ded8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-55803b4a-6175-4635-bd54-97651763e490,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-42ccffcf-c9a7-4764-af99-43e345afe71d,DISK], DatanodeInfoWithStorage[127.0.0.1:44845,DS-2f6b9ea4-3636-4ff5-9322-11a5c7ea7a54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1133482998-172.17.0.11-1595861932414:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40953,DS-995740e1-243e-4cf9-949f-db533aa57e59,DISK], DatanodeInfoWithStorage[127.0.0.1:45814,DS-75da1b65-2640-45b8-868a-3671980cbb41,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-668b68b5-7299-445a-bef2-121c8dbe1231,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-7491a5a3-eed5-4351-a94b-7a5f21ee5e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-2438258f-f376-446d-b178-05f200ded8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-55803b4a-6175-4635-bd54-97651763e490,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-42ccffcf-c9a7-4764-af99-43e345afe71d,DISK], DatanodeInfoWithStorage[127.0.0.1:44845,DS-2f6b9ea4-3636-4ff5-9322-11a5c7ea7a54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-181458595-172.17.0.11-1595862573656:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43324,DS-e519b0da-343e-4e44-ae29-e2b71931d981,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-392dcdb2-dd11-4a97-8dab-b65c7185d335,DISK], DatanodeInfoWithStorage[127.0.0.1:46342,DS-d98e2d0c-28af-4be5-a450-750cee4f507e,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-b7985887-0253-4cbb-9156-29878d6098cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-59b82509-1767-404d-b241-0986c48aba12,DISK], DatanodeInfoWithStorage[127.0.0.1:39717,DS-4947c027-e93d-407b-a4ff-5329ffb7f712,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-ab3f8dfb-17fc-4a64-8f3a-55ed99a6ea17,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-3a03584a-8cb8-4a32-814b-becf69ac0a28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-181458595-172.17.0.11-1595862573656:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43324,DS-e519b0da-343e-4e44-ae29-e2b71931d981,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-392dcdb2-dd11-4a97-8dab-b65c7185d335,DISK], DatanodeInfoWithStorage[127.0.0.1:46342,DS-d98e2d0c-28af-4be5-a450-750cee4f507e,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-b7985887-0253-4cbb-9156-29878d6098cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-59b82509-1767-404d-b241-0986c48aba12,DISK], DatanodeInfoWithStorage[127.0.0.1:39717,DS-4947c027-e93d-407b-a4ff-5329ffb7f712,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-ab3f8dfb-17fc-4a64-8f3a-55ed99a6ea17,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-3a03584a-8cb8-4a32-814b-becf69ac0a28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1934261450-172.17.0.11-1595863336417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42368,DS-2d9ab4fd-23c4-4f6d-b93d-280a7a33fe17,DISK], DatanodeInfoWithStorage[127.0.0.1:39371,DS-d55a4f08-ce2f-4f36-9f30-0b4c21ef48bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-aef6d289-eb9a-407c-9707-d09f6f42a2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-8c4f014d-7e63-4c3b-86ef-5a7c3178aa96,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-0285b58c-bcab-4c24-8f03-de2f6cc58b53,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-cd11f6ca-59f2-48e9-87ce-b850c677c76b,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-96c0d5c6-e003-47a2-9789-8a55c1f4db58,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-5f391002-b2ef-442b-a34f-63ca6243f81e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1934261450-172.17.0.11-1595863336417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42368,DS-2d9ab4fd-23c4-4f6d-b93d-280a7a33fe17,DISK], DatanodeInfoWithStorage[127.0.0.1:39371,DS-d55a4f08-ce2f-4f36-9f30-0b4c21ef48bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-aef6d289-eb9a-407c-9707-d09f6f42a2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-8c4f014d-7e63-4c3b-86ef-5a7c3178aa96,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-0285b58c-bcab-4c24-8f03-de2f6cc58b53,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-cd11f6ca-59f2-48e9-87ce-b850c677c76b,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-96c0d5c6-e003-47a2-9789-8a55c1f4db58,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-5f391002-b2ef-442b-a34f-63ca6243f81e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-818024524-172.17.0.11-1595863559546:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38021,DS-b231897d-20a9-4f1d-bb5e-dfd678658478,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-3d74409a-58c2-41e7-8859-c6046f5050eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-8c55f305-5956-4899-907c-4d08ae9e3fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-b5af97e0-98cc-4102-80fb-9788340c7c68,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-0cc0097e-eb4f-431d-9614-45804f4cba0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-2868874b-61da-46cb-8c0d-5a1d141ae80a,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-b531eadc-a6ac-47d1-a362-50bc9abb3c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-1340de43-c578-47c1-938a-e0d53d4035d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-818024524-172.17.0.11-1595863559546:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38021,DS-b231897d-20a9-4f1d-bb5e-dfd678658478,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-3d74409a-58c2-41e7-8859-c6046f5050eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-8c55f305-5956-4899-907c-4d08ae9e3fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-b5af97e0-98cc-4102-80fb-9788340c7c68,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-0cc0097e-eb4f-431d-9614-45804f4cba0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-2868874b-61da-46cb-8c0d-5a1d141ae80a,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-b531eadc-a6ac-47d1-a362-50bc9abb3c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-1340de43-c578-47c1-938a-e0d53d4035d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1440553038-172.17.0.11-1595863596457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40765,DS-85bbae39-4d33-4ac9-b57c-91e730123011,DISK], DatanodeInfoWithStorage[127.0.0.1:42976,DS-0db30a88-016e-43c6-b77b-f3e1d5c87c59,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-1c569e1d-63e6-458c-8939-95fa046ef990,DISK], DatanodeInfoWithStorage[127.0.0.1:44167,DS-f8ae465c-2672-445f-ba88-6ddfd18227a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-1f2d4b6a-9869-4acd-8fb5-ed70af253c75,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-8a81a46d-25fd-4ddc-a71a-068b4a3aa94e,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-b158c14d-bc58-4c3b-a1d4-9ffdff70f774,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-8b08ff82-112c-4427-b518-9356c99614a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1440553038-172.17.0.11-1595863596457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40765,DS-85bbae39-4d33-4ac9-b57c-91e730123011,DISK], DatanodeInfoWithStorage[127.0.0.1:42976,DS-0db30a88-016e-43c6-b77b-f3e1d5c87c59,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-1c569e1d-63e6-458c-8939-95fa046ef990,DISK], DatanodeInfoWithStorage[127.0.0.1:44167,DS-f8ae465c-2672-445f-ba88-6ddfd18227a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-1f2d4b6a-9869-4acd-8fb5-ed70af253c75,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-8a81a46d-25fd-4ddc-a71a-068b4a3aa94e,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-b158c14d-bc58-4c3b-a1d4-9ffdff70f774,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-8b08ff82-112c-4427-b518-9356c99614a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1034118384-172.17.0.11-1595863834897:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37983,DS-c2cacbad-db2f-4b85-83ac-3a6536940c31,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-2d509edb-383a-4f7d-83af-a45fb35ae045,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-c5030b2c-9306-497c-91e6-14bd009f5a84,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-1ed31585-7c45-4284-ac2a-ad21f2741567,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-b4af25a8-aec6-407b-973b-9c84e84c934b,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-b9b1a945-eaa0-4361-b3f8-3d671e0c0c80,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-9679e227-d312-489b-867d-96b94bb8cecd,DISK], DatanodeInfoWithStorage[127.0.0.1:39021,DS-3030af20-2d3f-45b4-b30a-158d0b3c8c7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1034118384-172.17.0.11-1595863834897:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37983,DS-c2cacbad-db2f-4b85-83ac-3a6536940c31,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-2d509edb-383a-4f7d-83af-a45fb35ae045,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-c5030b2c-9306-497c-91e6-14bd009f5a84,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-1ed31585-7c45-4284-ac2a-ad21f2741567,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-b4af25a8-aec6-407b-973b-9c84e84c934b,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-b9b1a945-eaa0-4361-b3f8-3d671e0c0c80,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-9679e227-d312-489b-867d-96b94bb8cecd,DISK], DatanodeInfoWithStorage[127.0.0.1:39021,DS-3030af20-2d3f-45b4-b30a-158d0b3c8c7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5391
