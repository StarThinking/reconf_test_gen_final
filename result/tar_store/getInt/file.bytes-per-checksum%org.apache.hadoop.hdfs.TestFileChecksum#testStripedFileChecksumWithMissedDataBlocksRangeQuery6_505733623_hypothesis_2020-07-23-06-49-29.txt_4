reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-820651555-172.17.0.15-1595486984159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37730,DS-e5b5de8e-7578-4e5a-af59-36dfa167e46e,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-cc5a95f5-774c-4fc1-81c9-2f02e70bac16,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-1d160623-02a3-4b50-835b-1fdd7f3566b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-cef8249f-d7d9-4b21-941a-7e38798a9fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-dad66c94-42d7-43fe-8783-5669e047838a,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-2a469fa3-ef5b-4226-8765-2c6da1adcc82,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-969f5e59-3987-447c-b473-8531bd149a28,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-5d32ef41-8634-4228-b25a-1482a128f9bc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-820651555-172.17.0.15-1595486984159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37730,DS-e5b5de8e-7578-4e5a-af59-36dfa167e46e,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-cc5a95f5-774c-4fc1-81c9-2f02e70bac16,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-1d160623-02a3-4b50-835b-1fdd7f3566b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-cef8249f-d7d9-4b21-941a-7e38798a9fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-dad66c94-42d7-43fe-8783-5669e047838a,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-2a469fa3-ef5b-4226-8765-2c6da1adcc82,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-969f5e59-3987-447c-b473-8531bd149a28,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-5d32ef41-8634-4228-b25a-1482a128f9bc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1154497701-172.17.0.15-1595487133977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42276,DS-cbbc6b34-7fc1-4522-8d0c-5f9c74f5e9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37790,DS-782d1400-e7d7-4368-bed4-3557a8ba820a,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-5979c3ef-a7ff-43c4-ad89-89996f9892f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-58c62d7d-4018-4190-a1e9-afe8523d8758,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-c9b9540a-05f0-425b-9b08-8e049dd54a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-77004492-b251-43a9-a05a-eea377d90d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-6e678fb8-d10d-4bbe-8ecb-c9734adb9ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:46870,DS-7d42cb79-b303-4513-b92c-b0b20979b516,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1154497701-172.17.0.15-1595487133977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42276,DS-cbbc6b34-7fc1-4522-8d0c-5f9c74f5e9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37790,DS-782d1400-e7d7-4368-bed4-3557a8ba820a,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-5979c3ef-a7ff-43c4-ad89-89996f9892f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-58c62d7d-4018-4190-a1e9-afe8523d8758,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-c9b9540a-05f0-425b-9b08-8e049dd54a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-77004492-b251-43a9-a05a-eea377d90d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-6e678fb8-d10d-4bbe-8ecb-c9734adb9ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:46870,DS-7d42cb79-b303-4513-b92c-b0b20979b516,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1609644081-172.17.0.15-1595487483826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34578,DS-2e8d1aa8-ee3f-40f5-aab1-95dd15b88081,DISK], DatanodeInfoWithStorage[127.0.0.1:35333,DS-066228c0-8dce-4678-a5af-02eda81f94e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-68127670-5c62-4fb5-b7df-ff6b1a272aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-f4a6e6c3-5bc0-4e59-a5a5-4ec54b39fec0,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-acd18ad3-eee5-4281-bebf-4498f4b0a918,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-5116895a-095a-4147-ac21-048c1e6a8322,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-052a3cb4-45c4-4124-9f2d-c3f378c0a652,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-b87dc2c9-5905-4c31-9a05-c2437674e3bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1609644081-172.17.0.15-1595487483826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34578,DS-2e8d1aa8-ee3f-40f5-aab1-95dd15b88081,DISK], DatanodeInfoWithStorage[127.0.0.1:35333,DS-066228c0-8dce-4678-a5af-02eda81f94e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-68127670-5c62-4fb5-b7df-ff6b1a272aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-f4a6e6c3-5bc0-4e59-a5a5-4ec54b39fec0,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-acd18ad3-eee5-4281-bebf-4498f4b0a918,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-5116895a-095a-4147-ac21-048c1e6a8322,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-052a3cb4-45c4-4124-9f2d-c3f378c0a652,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-b87dc2c9-5905-4c31-9a05-c2437674e3bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1052514389-172.17.0.15-1595487600744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34842,DS-abd9a57e-8e75-48f0-855e-8b35062c7340,DISK], DatanodeInfoWithStorage[127.0.0.1:35338,DS-e7bae500-c205-439c-ab77-2d1f27db8e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-de2adc78-7199-437e-91da-0c84872b5f83,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-91af3e58-c634-41a8-ad08-718f7b1801e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-15b64d88-9b0d-403e-a1ed-f953d96de88e,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-fae4337a-a250-488e-a715-3ada297cc5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-f7c14625-358e-49ee-a3bd-d0aa08d22ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-a41cff14-2388-4be3-a912-2c9fd81b8cef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1052514389-172.17.0.15-1595487600744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34842,DS-abd9a57e-8e75-48f0-855e-8b35062c7340,DISK], DatanodeInfoWithStorage[127.0.0.1:35338,DS-e7bae500-c205-439c-ab77-2d1f27db8e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-de2adc78-7199-437e-91da-0c84872b5f83,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-91af3e58-c634-41a8-ad08-718f7b1801e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-15b64d88-9b0d-403e-a1ed-f953d96de88e,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-fae4337a-a250-488e-a715-3ada297cc5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-f7c14625-358e-49ee-a3bd-d0aa08d22ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-a41cff14-2388-4be3-a912-2c9fd81b8cef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1167079059-172.17.0.15-1595487763071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35171,DS-87150e49-f784-4748-93c6-08563a561dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-037ba35c-dab7-4cd2-b83a-a5fb527abe14,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-ed5767fc-060c-4eff-a921-0e95ffcf1d62,DISK], DatanodeInfoWithStorage[127.0.0.1:35740,DS-2672567c-9888-40fb-8c84-99f88de82ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-1e506875-34fa-4704-98d2-772da8714e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-ac856879-5230-42bc-a50f-f61e5a1d8a73,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-ba4e87d1-73fe-4e40-9651-acf89b327606,DISK], DatanodeInfoWithStorage[127.0.0.1:35036,DS-dc4a96bb-2888-41f6-886a-db38f7a058c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1167079059-172.17.0.15-1595487763071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35171,DS-87150e49-f784-4748-93c6-08563a561dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-037ba35c-dab7-4cd2-b83a-a5fb527abe14,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-ed5767fc-060c-4eff-a921-0e95ffcf1d62,DISK], DatanodeInfoWithStorage[127.0.0.1:35740,DS-2672567c-9888-40fb-8c84-99f88de82ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-1e506875-34fa-4704-98d2-772da8714e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-ac856879-5230-42bc-a50f-f61e5a1d8a73,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-ba4e87d1-73fe-4e40-9651-acf89b327606,DISK], DatanodeInfoWithStorage[127.0.0.1:35036,DS-dc4a96bb-2888-41f6-886a-db38f7a058c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-905612268-172.17.0.15-1595487881918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42811,DS-1c092ad2-2122-453e-b260-9a9b1855c58f,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-6373e440-8c10-46fb-ac31-833e73cfd33d,DISK], DatanodeInfoWithStorage[127.0.0.1:43597,DS-97b5a0ac-d598-4c70-8116-04ac9364ee1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-45662387-cea6-4c3d-98ba-45b62c3d1853,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-ddb3aa04-3c3b-414c-8648-a8050461a75a,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-b6a229cd-8db0-438a-bc81-9f044bbe1164,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-51fb4552-fab9-40f0-b637-aa64c3b5ad0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40623,DS-61f746ba-bbb7-47e3-9844-cdcc07c9241f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-905612268-172.17.0.15-1595487881918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42811,DS-1c092ad2-2122-453e-b260-9a9b1855c58f,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-6373e440-8c10-46fb-ac31-833e73cfd33d,DISK], DatanodeInfoWithStorage[127.0.0.1:43597,DS-97b5a0ac-d598-4c70-8116-04ac9364ee1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-45662387-cea6-4c3d-98ba-45b62c3d1853,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-ddb3aa04-3c3b-414c-8648-a8050461a75a,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-b6a229cd-8db0-438a-bc81-9f044bbe1164,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-51fb4552-fab9-40f0-b637-aa64c3b5ad0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40623,DS-61f746ba-bbb7-47e3-9844-cdcc07c9241f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2032567063-172.17.0.15-1595487991538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40401,DS-9382976f-c5ab-49f5-868f-bda1f57b8cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-d6c8f251-627e-4ec1-98b6-f3f63693c589,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-a5d43282-b233-4ac6-84cd-9d02e3e03ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-4c77f262-c5c8-47b8-8c6c-6c864088dba2,DISK], DatanodeInfoWithStorage[127.0.0.1:32953,DS-55276769-39fe-46a1-b8df-835e539a71ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-3efebac5-183c-4664-94e3-aac4b4fe3e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-a6116163-f577-4dd1-b7c0-1471ddfd8bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-faa9015b-6d51-4e98-9fbf-9e8699e89f3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2032567063-172.17.0.15-1595487991538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40401,DS-9382976f-c5ab-49f5-868f-bda1f57b8cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-d6c8f251-627e-4ec1-98b6-f3f63693c589,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-a5d43282-b233-4ac6-84cd-9d02e3e03ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-4c77f262-c5c8-47b8-8c6c-6c864088dba2,DISK], DatanodeInfoWithStorage[127.0.0.1:32953,DS-55276769-39fe-46a1-b8df-835e539a71ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-3efebac5-183c-4664-94e3-aac4b4fe3e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-a6116163-f577-4dd1-b7c0-1471ddfd8bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-faa9015b-6d51-4e98-9fbf-9e8699e89f3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-312847691-172.17.0.15-1595488068290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45125,DS-599f7da5-6625-442f-bfa7-298cab40b9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-4047cf7b-2409-492a-b71a-e3e38f377217,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-5885f5f4-fb4d-4299-8a08-3e4871ce29b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-b22c3482-1758-496b-8007-99fc9bb10c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46060,DS-b74d8ce0-a677-485f-9553-dd538fc22bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-0b40e68b-a9e2-45f6-9788-0233dcbe3ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-76ff750f-0b6c-4dc7-9ad8-204abac8be06,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-2ab56c8d-b1c9-41d3-873a-525808758a09,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-312847691-172.17.0.15-1595488068290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45125,DS-599f7da5-6625-442f-bfa7-298cab40b9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-4047cf7b-2409-492a-b71a-e3e38f377217,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-5885f5f4-fb4d-4299-8a08-3e4871ce29b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-b22c3482-1758-496b-8007-99fc9bb10c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46060,DS-b74d8ce0-a677-485f-9553-dd538fc22bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-0b40e68b-a9e2-45f6-9788-0233dcbe3ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-76ff750f-0b6c-4dc7-9ad8-204abac8be06,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-2ab56c8d-b1c9-41d3-873a-525808758a09,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-262200047-172.17.0.15-1595488174484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34782,DS-3e8c1941-1afd-4482-875a-a90c4128e788,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-add6671b-04bb-471b-ba11-3a36f294c37c,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-698ed6bd-34ab-4fca-bba0-d539bcfdc973,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-b03e9bc2-3744-4bcb-add1-d2b73bdd8005,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-a54c659d-47f1-424c-856a-2c1f129f83a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-0cc82a04-80f3-47b3-b9f7-150c7fc9d9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-8eaf25e4-8556-4f22-9486-5ab5694e57ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-86f8111a-f174-434c-8bb2-98f277dbf0ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-262200047-172.17.0.15-1595488174484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34782,DS-3e8c1941-1afd-4482-875a-a90c4128e788,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-add6671b-04bb-471b-ba11-3a36f294c37c,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-698ed6bd-34ab-4fca-bba0-d539bcfdc973,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-b03e9bc2-3744-4bcb-add1-d2b73bdd8005,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-a54c659d-47f1-424c-856a-2c1f129f83a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-0cc82a04-80f3-47b3-b9f7-150c7fc9d9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-8eaf25e4-8556-4f22-9486-5ab5694e57ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-86f8111a-f174-434c-8bb2-98f277dbf0ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1224272326-172.17.0.15-1595488246458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42569,DS-df661905-fb24-4a1b-aa02-4de6818755bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33164,DS-3f200cf1-eb6e-4da3-8ee7-eda95838b2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-311c4582-cb8a-43ca-88db-c687b1175953,DISK], DatanodeInfoWithStorage[127.0.0.1:37570,DS-0d6f614f-a89f-4af9-8f2b-615bdf87fdce,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-a489c0d4-432c-4b59-9c65-30d682547ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-12700549-1da4-4b11-b65c-6daab5a4b0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-071ee9f3-09b6-477f-8857-8924fca04caf,DISK], DatanodeInfoWithStorage[127.0.0.1:37338,DS-52e82b6d-2de8-47ba-9234-5548c498758d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1224272326-172.17.0.15-1595488246458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42569,DS-df661905-fb24-4a1b-aa02-4de6818755bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33164,DS-3f200cf1-eb6e-4da3-8ee7-eda95838b2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-311c4582-cb8a-43ca-88db-c687b1175953,DISK], DatanodeInfoWithStorage[127.0.0.1:37570,DS-0d6f614f-a89f-4af9-8f2b-615bdf87fdce,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-a489c0d4-432c-4b59-9c65-30d682547ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-12700549-1da4-4b11-b65c-6daab5a4b0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-071ee9f3-09b6-477f-8857-8924fca04caf,DISK], DatanodeInfoWithStorage[127.0.0.1:37338,DS-52e82b6d-2de8-47ba-9234-5548c498758d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-205554798-172.17.0.15-1595488288319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45912,DS-7faec7aa-4635-4375-9f95-ab4068e9d595,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-22d00564-b93f-47da-972e-99240bca4601,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-9a494f96-2cdc-4e3d-a408-b5c742bbeaef,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-fc9595d0-40f9-40f6-831b-857322155689,DISK], DatanodeInfoWithStorage[127.0.0.1:34786,DS-0d224105-f9e7-4491-b0d4-42c342ba6ace,DISK], DatanodeInfoWithStorage[127.0.0.1:46757,DS-375de64c-4548-4e4f-b76a-4e1fbe697ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-3af91ee5-f626-494b-9468-c526ce379aad,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-a1634253-343c-46a9-b7f6-9205f196d048,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-205554798-172.17.0.15-1595488288319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45912,DS-7faec7aa-4635-4375-9f95-ab4068e9d595,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-22d00564-b93f-47da-972e-99240bca4601,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-9a494f96-2cdc-4e3d-a408-b5c742bbeaef,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-fc9595d0-40f9-40f6-831b-857322155689,DISK], DatanodeInfoWithStorage[127.0.0.1:34786,DS-0d224105-f9e7-4491-b0d4-42c342ba6ace,DISK], DatanodeInfoWithStorage[127.0.0.1:46757,DS-375de64c-4548-4e4f-b76a-4e1fbe697ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-3af91ee5-f626-494b-9468-c526ce379aad,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-a1634253-343c-46a9-b7f6-9205f196d048,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1792668496-172.17.0.15-1595488324156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35273,DS-37ad1003-018c-4029-ba0c-bbbf547417f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-cb905472-477b-41a1-95f7-2732038df00c,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-52275351-fea9-40d7-b6bb-ea7dc08582df,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-c8088b11-b418-4ea9-a886-511486061297,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-4a22081e-3177-472c-996f-052ec6947f63,DISK], DatanodeInfoWithStorage[127.0.0.1:42631,DS-a45287a0-41a6-4782-9eb0-1cd2da8393b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-06d581ad-3e21-40a7-a873-201bd51d782c,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-9af794bd-5da4-439d-809c-bb8ffa63a60d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1792668496-172.17.0.15-1595488324156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35273,DS-37ad1003-018c-4029-ba0c-bbbf547417f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-cb905472-477b-41a1-95f7-2732038df00c,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-52275351-fea9-40d7-b6bb-ea7dc08582df,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-c8088b11-b418-4ea9-a886-511486061297,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-4a22081e-3177-472c-996f-052ec6947f63,DISK], DatanodeInfoWithStorage[127.0.0.1:42631,DS-a45287a0-41a6-4782-9eb0-1cd2da8393b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-06d581ad-3e21-40a7-a873-201bd51d782c,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-9af794bd-5da4-439d-809c-bb8ffa63a60d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2078844002-172.17.0.15-1595488447950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37111,DS-1f5e2d26-2296-467c-93c0-64f5a30818e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-1a14e6ad-f67f-4341-8902-2e3e040fc026,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-775b9ab8-7839-430d-a0ae-d47af0ecc11e,DISK], DatanodeInfoWithStorage[127.0.0.1:43690,DS-11e3f406-109d-4bef-8777-db17e5e54c06,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-0eed9fac-26da-4af6-830e-ec1554319eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-c2e7ab33-60ef-4eb0-bc1f-1de4d7b12a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-2aeadb03-4ac6-4fd5-80ab-ff4d53363c97,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-7fd5d7d1-713f-4ea3-9c0b-bbafffecb4a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2078844002-172.17.0.15-1595488447950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37111,DS-1f5e2d26-2296-467c-93c0-64f5a30818e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-1a14e6ad-f67f-4341-8902-2e3e040fc026,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-775b9ab8-7839-430d-a0ae-d47af0ecc11e,DISK], DatanodeInfoWithStorage[127.0.0.1:43690,DS-11e3f406-109d-4bef-8777-db17e5e54c06,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-0eed9fac-26da-4af6-830e-ec1554319eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-c2e7ab33-60ef-4eb0-bc1f-1de4d7b12a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-2aeadb03-4ac6-4fd5-80ab-ff4d53363c97,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-7fd5d7d1-713f-4ea3-9c0b-bbafffecb4a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1012254320-172.17.0.15-1595488522604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36493,DS-801a288f-8608-4d32-bbcb-cd3034a62abb,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-c753727b-fe90-4938-97e8-09e955f405ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-8edf2d15-c360-4155-9c6d-f60bb2b37755,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-e37fe219-dc8d-43ec-b26f-049b2a8873e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-b13d1d74-6f76-4ae7-8c01-b54e7966d244,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-3b118546-7084-4eb8-b111-d8ae5da12894,DISK], DatanodeInfoWithStorage[127.0.0.1:45354,DS-33455345-5c36-400a-ac81-4a3890a82f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-21c75127-0a64-4597-a369-6469c01354ea,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1012254320-172.17.0.15-1595488522604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36493,DS-801a288f-8608-4d32-bbcb-cd3034a62abb,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-c753727b-fe90-4938-97e8-09e955f405ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-8edf2d15-c360-4155-9c6d-f60bb2b37755,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-e37fe219-dc8d-43ec-b26f-049b2a8873e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-b13d1d74-6f76-4ae7-8c01-b54e7966d244,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-3b118546-7084-4eb8-b111-d8ae5da12894,DISK], DatanodeInfoWithStorage[127.0.0.1:45354,DS-33455345-5c36-400a-ac81-4a3890a82f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-21c75127-0a64-4597-a369-6469c01354ea,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1121279913-172.17.0.15-1595488711433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37203,DS-85125f38-ddb7-4d6c-b926-ed512cf9aeb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-cdc70cf6-b9a2-4395-b98c-e1c86e709322,DISK], DatanodeInfoWithStorage[127.0.0.1:34919,DS-9495098f-cacb-4390-bc35-ff9e18004e88,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-920f98bf-e1fe-40a1-9b03-664be4c71a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-cba20e6e-98c2-4f4d-95c5-9941822a7bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-a07e0987-51da-4854-b415-1aba59261bec,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-87a914d5-0aab-463b-9ccc-795ad220964e,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-d098043b-c16d-47ce-806f-01557a13b9c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1121279913-172.17.0.15-1595488711433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37203,DS-85125f38-ddb7-4d6c-b926-ed512cf9aeb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-cdc70cf6-b9a2-4395-b98c-e1c86e709322,DISK], DatanodeInfoWithStorage[127.0.0.1:34919,DS-9495098f-cacb-4390-bc35-ff9e18004e88,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-920f98bf-e1fe-40a1-9b03-664be4c71a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-cba20e6e-98c2-4f4d-95c5-9941822a7bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-a07e0987-51da-4854-b415-1aba59261bec,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-87a914d5-0aab-463b-9ccc-795ad220964e,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-d098043b-c16d-47ce-806f-01557a13b9c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-247494363-172.17.0.15-1595488749883:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46132,DS-69755b79-3e0c-4a51-99b5-6c8e49de0cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-61a5ecfa-1d88-436b-98f0-4786ee1da337,DISK], DatanodeInfoWithStorage[127.0.0.1:38191,DS-a3cc9263-0f79-4b6e-b6f5-8f733804bafb,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-554325af-ee51-4641-b046-78ed4057f910,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-736c248c-905c-4ae2-9598-2ed476513adf,DISK], DatanodeInfoWithStorage[127.0.0.1:38359,DS-e1501c88-5287-4f95-bb2f-a8a865b10520,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-7270c4c5-6f1d-4b57-9ac4-cc853f44f3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-758f8082-b5e3-4e56-a630-75fb5f27742f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-247494363-172.17.0.15-1595488749883:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46132,DS-69755b79-3e0c-4a51-99b5-6c8e49de0cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-61a5ecfa-1d88-436b-98f0-4786ee1da337,DISK], DatanodeInfoWithStorage[127.0.0.1:38191,DS-a3cc9263-0f79-4b6e-b6f5-8f733804bafb,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-554325af-ee51-4641-b046-78ed4057f910,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-736c248c-905c-4ae2-9598-2ed476513adf,DISK], DatanodeInfoWithStorage[127.0.0.1:38359,DS-e1501c88-5287-4f95-bb2f-a8a865b10520,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-7270c4c5-6f1d-4b57-9ac4-cc853f44f3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-758f8082-b5e3-4e56-a630-75fb5f27742f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2144581144-172.17.0.15-1595488943834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44862,DS-bdd7c1b9-d920-407c-9bfb-e1cbdbf0b0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-91e013b0-2788-4204-8609-e5f2fcda203a,DISK], DatanodeInfoWithStorage[127.0.0.1:42690,DS-a5367ebb-d94b-4bb0-b253-e4249a06af78,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-f0fd5bb9-1be2-435d-9888-d6a35c628ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-661f7d21-ec6d-4c9c-b5e0-5167b1f948e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-8c19fb67-300f-4542-acf1-cba190e9a4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-4ea9875e-28fb-448a-aaed-04677b6f0a65,DISK], DatanodeInfoWithStorage[127.0.0.1:45921,DS-1b5042b7-9d71-48ff-a1bc-4682136af94e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2144581144-172.17.0.15-1595488943834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44862,DS-bdd7c1b9-d920-407c-9bfb-e1cbdbf0b0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-91e013b0-2788-4204-8609-e5f2fcda203a,DISK], DatanodeInfoWithStorage[127.0.0.1:42690,DS-a5367ebb-d94b-4bb0-b253-e4249a06af78,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-f0fd5bb9-1be2-435d-9888-d6a35c628ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-661f7d21-ec6d-4c9c-b5e0-5167b1f948e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-8c19fb67-300f-4542-acf1-cba190e9a4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-4ea9875e-28fb-448a-aaed-04677b6f0a65,DISK], DatanodeInfoWithStorage[127.0.0.1:45921,DS-1b5042b7-9d71-48ff-a1bc-4682136af94e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184567838-172.17.0.15-1595489121086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34813,DS-371327ac-a141-448b-9548-c337c302b218,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-12868bd7-c2e6-45f4-8408-f2aa9a87aa84,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-64356269-a812-46a2-a774-bbbb884aaca6,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-edb3e506-fe99-4ff4-a422-ddcb09516959,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-dec15885-a40d-4a41-aef7-12adcd14382c,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-b7b4bce9-9d3f-4e63-b91b-a0f4f14e8104,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-0c2d841f-24b8-41fa-bd44-a75364448461,DISK], DatanodeInfoWithStorage[127.0.0.1:40314,DS-4bf7e50f-9a48-4158-8eb8-d71e848d2f4f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184567838-172.17.0.15-1595489121086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34813,DS-371327ac-a141-448b-9548-c337c302b218,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-12868bd7-c2e6-45f4-8408-f2aa9a87aa84,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-64356269-a812-46a2-a774-bbbb884aaca6,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-edb3e506-fe99-4ff4-a422-ddcb09516959,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-dec15885-a40d-4a41-aef7-12adcd14382c,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-b7b4bce9-9d3f-4e63-b91b-a0f4f14e8104,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-0c2d841f-24b8-41fa-bd44-a75364448461,DISK], DatanodeInfoWithStorage[127.0.0.1:40314,DS-4bf7e50f-9a48-4158-8eb8-d71e848d2f4f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-341317056-172.17.0.15-1595489273465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38613,DS-8b941d0d-ed0b-4500-8d92-932b9892974b,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-9ded2dc7-7624-4766-a7dc-f06f3e03cca2,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-2ba2cb7f-5927-4f1b-98b1-d094ca9bd3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46099,DS-ca183a4f-18f6-466c-849c-001ff8e64a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-297cd9a1-4d0f-458c-bd52-4194c4cc1ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-efdef192-6a7b-4312-8ad0-ea98ff0315d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-750eb69c-db0c-49c2-8293-fb73745b8545,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-637b6544-fa74-4725-9eb0-6d9269988215,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-341317056-172.17.0.15-1595489273465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38613,DS-8b941d0d-ed0b-4500-8d92-932b9892974b,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-9ded2dc7-7624-4766-a7dc-f06f3e03cca2,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-2ba2cb7f-5927-4f1b-98b1-d094ca9bd3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46099,DS-ca183a4f-18f6-466c-849c-001ff8e64a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-297cd9a1-4d0f-458c-bd52-4194c4cc1ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-efdef192-6a7b-4312-8ad0-ea98ff0315d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-750eb69c-db0c-49c2-8293-fb73745b8545,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-637b6544-fa74-4725-9eb0-6d9269988215,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-356852845-172.17.0.15-1595489384157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33874,DS-782a1e89-1dda-41bc-9382-83e6eb4d611c,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-53d72ed6-b801-42e0-b9b8-cf5a51541135,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-60819fdd-063a-4808-baba-e6ec0092fb41,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-ca746469-2fe1-491d-98a1-757f170d3079,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-e95e6091-6216-41fd-816f-efebc59ee223,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-1a114da4-cb05-4ad6-b8a9-a72a7101e7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-a3f096ce-0829-461c-8455-e8543d06feda,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-287cd620-6a4f-4405-961b-72024a31ed76,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-356852845-172.17.0.15-1595489384157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33874,DS-782a1e89-1dda-41bc-9382-83e6eb4d611c,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-53d72ed6-b801-42e0-b9b8-cf5a51541135,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-60819fdd-063a-4808-baba-e6ec0092fb41,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-ca746469-2fe1-491d-98a1-757f170d3079,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-e95e6091-6216-41fd-816f-efebc59ee223,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-1a114da4-cb05-4ad6-b8a9-a72a7101e7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-a3f096ce-0829-461c-8455-e8543d06feda,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-287cd620-6a4f-4405-961b-72024a31ed76,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-921920613-172.17.0.15-1595489898660:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38376,DS-4eb9b54c-26b1-4b1d-84a8-780524270486,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-e3b079cd-0da4-4600-9cc4-c16b14959daa,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-fe6a9f2f-7fe5-40e5-a580-fb6cca599c17,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-654e34d0-adff-44a9-a9b4-1645a3eca754,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-be9ffd98-5a7e-406b-ba0b-a63d65add0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34129,DS-a879b4b5-445b-47cb-a5e7-00a1b465642d,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-5d5e7270-c743-4839-8cc3-18da38be10ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46653,DS-093c5afe-c5f8-4168-bf9e-48517d0e3717,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-921920613-172.17.0.15-1595489898660:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38376,DS-4eb9b54c-26b1-4b1d-84a8-780524270486,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-e3b079cd-0da4-4600-9cc4-c16b14959daa,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-fe6a9f2f-7fe5-40e5-a580-fb6cca599c17,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-654e34d0-adff-44a9-a9b4-1645a3eca754,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-be9ffd98-5a7e-406b-ba0b-a63d65add0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34129,DS-a879b4b5-445b-47cb-a5e7-00a1b465642d,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-5d5e7270-c743-4839-8cc3-18da38be10ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46653,DS-093c5afe-c5f8-4168-bf9e-48517d0e3717,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1426005135-172.17.0.15-1595489981094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41436,DS-f0af0946-508b-4d8c-a250-19cfd05b2fda,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-c0461eca-1ad7-467d-a753-0eb1fbc09c19,DISK], DatanodeInfoWithStorage[127.0.0.1:40132,DS-71f6acab-8b21-4e95-aa25-55a5f2d9fd8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-81b447ad-3b01-4c8b-986f-995e2cb4b50d,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-8fcd7b36-9685-4341-961c-3b9695bd54b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46582,DS-bb1bea48-7506-47b4-b3cf-3079d5f5aac7,DISK], DatanodeInfoWithStorage[127.0.0.1:33953,DS-530127a6-c3c6-45bf-bff7-df372ed6f495,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-d0620731-a305-423c-bb6a-06cdc6e7fd8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1426005135-172.17.0.15-1595489981094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41436,DS-f0af0946-508b-4d8c-a250-19cfd05b2fda,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-c0461eca-1ad7-467d-a753-0eb1fbc09c19,DISK], DatanodeInfoWithStorage[127.0.0.1:40132,DS-71f6acab-8b21-4e95-aa25-55a5f2d9fd8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-81b447ad-3b01-4c8b-986f-995e2cb4b50d,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-8fcd7b36-9685-4341-961c-3b9695bd54b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46582,DS-bb1bea48-7506-47b4-b3cf-3079d5f5aac7,DISK], DatanodeInfoWithStorage[127.0.0.1:33953,DS-530127a6-c3c6-45bf-bff7-df372ed6f495,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-d0620731-a305-423c-bb6a-06cdc6e7fd8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-783786980-172.17.0.15-1595490059416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40466,DS-202aeaa4-998a-4246-a05a-f44a2aa6d405,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-de42214f-edba-4617-ba16-8a9aca4c6ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-edebc4e5-3d4e-40c3-9f05-a8ec2bd81664,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-66ae0109-2e50-4949-bc5f-45643c88d1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-5e6a861d-8a66-4443-9eb4-7f526b960e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38907,DS-2220cb6f-8b83-406a-bb09-6fcb1fc81ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:45623,DS-9d822bf7-602d-41a6-836a-6424467d3afd,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-1a008cbb-4a04-4479-b9df-af1dd66f51ef,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-783786980-172.17.0.15-1595490059416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40466,DS-202aeaa4-998a-4246-a05a-f44a2aa6d405,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-de42214f-edba-4617-ba16-8a9aca4c6ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-edebc4e5-3d4e-40c3-9f05-a8ec2bd81664,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-66ae0109-2e50-4949-bc5f-45643c88d1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-5e6a861d-8a66-4443-9eb4-7f526b960e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38907,DS-2220cb6f-8b83-406a-bb09-6fcb1fc81ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:45623,DS-9d822bf7-602d-41a6-836a-6424467d3afd,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-1a008cbb-4a04-4479-b9df-af1dd66f51ef,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1173981849-172.17.0.15-1595490454996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45323,DS-c1d66446-6471-4ade-93d6-2a8910c6ddf9,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-eb5512da-14f2-40fe-ab72-6200f81d3534,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-e3d3dcdd-5ae8-4959-b2b7-3cf99ec39cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-77d5807d-8fbc-4eef-b457-dce742fc2a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45370,DS-9f3cd80c-92a7-45e7-8024-7ffe4e183190,DISK], DatanodeInfoWithStorage[127.0.0.1:34755,DS-7f2b990b-49ab-4ef1-a78e-54d0a64420bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-3a2a70db-7551-4f61-9d52-f65548ef5ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-e23a56f5-1d38-4a1f-98b6-9e4a3b0f7f32,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1173981849-172.17.0.15-1595490454996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45323,DS-c1d66446-6471-4ade-93d6-2a8910c6ddf9,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-eb5512da-14f2-40fe-ab72-6200f81d3534,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-e3d3dcdd-5ae8-4959-b2b7-3cf99ec39cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-77d5807d-8fbc-4eef-b457-dce742fc2a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45370,DS-9f3cd80c-92a7-45e7-8024-7ffe4e183190,DISK], DatanodeInfoWithStorage[127.0.0.1:34755,DS-7f2b990b-49ab-4ef1-a78e-54d0a64420bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-3a2a70db-7551-4f61-9d52-f65548ef5ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-e23a56f5-1d38-4a1f-98b6-9e4a3b0f7f32,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1188342384-172.17.0.15-1595490536266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40117,DS-259f8271-68a9-4bc6-b8a4-ad3f0272ecd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-75c03e99-0cb7-423f-a9c2-eb9c65439a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-1e53a5aa-37fb-4aed-a2d1-6fa6f1a02b96,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-8423d2b1-7b72-4e75-a8ee-f0d4237fbc54,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-52fd61d7-d358-4544-bfb2-f62e9a210c69,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-18610b7e-c8c1-42fa-9069-05c6825eadde,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-17a14eb3-7c17-4732-b2c9-0d292e7d4cec,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-f5e6ee6d-ef06-4813-818c-2b8aebf9b7f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1188342384-172.17.0.15-1595490536266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40117,DS-259f8271-68a9-4bc6-b8a4-ad3f0272ecd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-75c03e99-0cb7-423f-a9c2-eb9c65439a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-1e53a5aa-37fb-4aed-a2d1-6fa6f1a02b96,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-8423d2b1-7b72-4e75-a8ee-f0d4237fbc54,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-52fd61d7-d358-4544-bfb2-f62e9a210c69,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-18610b7e-c8c1-42fa-9069-05c6825eadde,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-17a14eb3-7c17-4732-b2c9-0d292e7d4cec,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-f5e6ee6d-ef06-4813-818c-2b8aebf9b7f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-832798291-172.17.0.15-1595490618757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33270,DS-de71195d-d672-4153-a217-490028c71abd,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-c0d9a882-7037-4812-9934-5d3bc5c2d44d,DISK], DatanodeInfoWithStorage[127.0.0.1:40749,DS-cea97508-e5fa-40c4-8e8c-2d1289e2a9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-5daad614-5faa-455f-9190-cdf383a25db7,DISK], DatanodeInfoWithStorage[127.0.0.1:40660,DS-bc4288d8-43be-4010-bb90-e92ced72b5df,DISK], DatanodeInfoWithStorage[127.0.0.1:39473,DS-0ab6420d-aa09-4cd3-b903-4f11041e5c44,DISK], DatanodeInfoWithStorage[127.0.0.1:42801,DS-481ea7bb-c66b-4c63-904d-17425c3a45e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-206db3c1-ad54-4bcf-ac38-31edc68789e4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-832798291-172.17.0.15-1595490618757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33270,DS-de71195d-d672-4153-a217-490028c71abd,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-c0d9a882-7037-4812-9934-5d3bc5c2d44d,DISK], DatanodeInfoWithStorage[127.0.0.1:40749,DS-cea97508-e5fa-40c4-8e8c-2d1289e2a9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-5daad614-5faa-455f-9190-cdf383a25db7,DISK], DatanodeInfoWithStorage[127.0.0.1:40660,DS-bc4288d8-43be-4010-bb90-e92ced72b5df,DISK], DatanodeInfoWithStorage[127.0.0.1:39473,DS-0ab6420d-aa09-4cd3-b903-4f11041e5c44,DISK], DatanodeInfoWithStorage[127.0.0.1:42801,DS-481ea7bb-c66b-4c63-904d-17425c3a45e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-206db3c1-ad54-4bcf-ac38-31edc68789e4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144954596-172.17.0.15-1595490819038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34460,DS-c4ded451-a362-49cb-86ca-24aacb694057,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-2e506a49-d4be-48e6-b734-df6073bc7d49,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-9930d46c-531e-430d-bf7d-7299ed6b9bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-cd003b7d-1142-4212-be31-f525c94bea8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35743,DS-95821159-af3a-44da-accd-84144c64019d,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-269b3cbf-25be-479a-90ca-b31836e94a80,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-5c7cc70a-bc2b-4a90-ac78-72c2140ec251,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-89a9a326-0966-4212-9c68-6bac416a45c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144954596-172.17.0.15-1595490819038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34460,DS-c4ded451-a362-49cb-86ca-24aacb694057,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-2e506a49-d4be-48e6-b734-df6073bc7d49,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-9930d46c-531e-430d-bf7d-7299ed6b9bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-cd003b7d-1142-4212-be31-f525c94bea8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35743,DS-95821159-af3a-44da-accd-84144c64019d,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-269b3cbf-25be-479a-90ca-b31836e94a80,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-5c7cc70a-bc2b-4a90-ac78-72c2140ec251,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-89a9a326-0966-4212-9c68-6bac416a45c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-802048605-172.17.0.15-1595490934106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39667,DS-2158e77c-7133-4328-833b-611a70ca03e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-9ee59dd8-78d3-4251-b8a6-0f4614c317b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-1a53a856-3e3a-4b5c-9ff4-80fd3e4bb191,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-036e1855-e6af-4c32-81be-fd2ca3629457,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-d1a90ff3-cc7c-43d9-9daf-b99a8e2c0f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-522b6648-3b19-4372-9833-ffb6892f86cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-c6356e32-a3ac-4da8-9f90-2a60d174ef89,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-4b1cad2f-5725-4714-8f91-8c82863b7f2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-802048605-172.17.0.15-1595490934106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39667,DS-2158e77c-7133-4328-833b-611a70ca03e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-9ee59dd8-78d3-4251-b8a6-0f4614c317b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-1a53a856-3e3a-4b5c-9ff4-80fd3e4bb191,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-036e1855-e6af-4c32-81be-fd2ca3629457,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-d1a90ff3-cc7c-43d9-9daf-b99a8e2c0f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-522b6648-3b19-4372-9833-ffb6892f86cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-c6356e32-a3ac-4da8-9f90-2a60d174ef89,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-4b1cad2f-5725-4714-8f91-8c82863b7f2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-266728767-172.17.0.15-1595491092718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32918,DS-d52957d2-238d-4484-bc79-51f79facefb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-77444a88-e126-48b5-b72b-6043745db02f,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-61e1d187-5cbd-4e20-a69a-06ab276b604f,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-2aa317f8-ce00-4d03-9ccb-81095f5ecf89,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-97e1f5c6-d3b7-4194-8d04-6a9f208e8383,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-2738cb91-ac45-4a47-a64f-6aae2123c5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-2013a64f-8331-4058-b2b0-ed8e8af3fc81,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-cfceb39e-5064-4bf4-8b08-a4aad39d248d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-266728767-172.17.0.15-1595491092718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32918,DS-d52957d2-238d-4484-bc79-51f79facefb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-77444a88-e126-48b5-b72b-6043745db02f,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-61e1d187-5cbd-4e20-a69a-06ab276b604f,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-2aa317f8-ce00-4d03-9ccb-81095f5ecf89,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-97e1f5c6-d3b7-4194-8d04-6a9f208e8383,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-2738cb91-ac45-4a47-a64f-6aae2123c5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-2013a64f-8331-4058-b2b0-ed8e8af3fc81,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-cfceb39e-5064-4bf4-8b08-a4aad39d248d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1775171101-172.17.0.15-1595491350889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35700,DS-63f541c0-f0c4-4010-87b0-3fa8a55e9d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-b21b81c7-89f2-4c75-924e-def038393aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-96c6995c-69ba-4f3a-880c-cd744dad05bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-35eb2fe2-7449-4867-9439-428afcd2e8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-0fb7c827-a853-4106-8a8b-4e277227d1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-9acbaf6a-413c-46e7-b03d-091f5fb3af4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-47cb6076-cbdc-4ac7-8c8c-453e39529eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46405,DS-ee9b0779-8c98-4157-ba30-99d20f4407c0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1775171101-172.17.0.15-1595491350889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35700,DS-63f541c0-f0c4-4010-87b0-3fa8a55e9d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-b21b81c7-89f2-4c75-924e-def038393aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-96c6995c-69ba-4f3a-880c-cd744dad05bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-35eb2fe2-7449-4867-9439-428afcd2e8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-0fb7c827-a853-4106-8a8b-4e277227d1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-9acbaf6a-413c-46e7-b03d-091f5fb3af4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-47cb6076-cbdc-4ac7-8c8c-453e39529eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46405,DS-ee9b0779-8c98-4157-ba30-99d20f4407c0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-137444634-172.17.0.15-1595491454136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46063,DS-0c1724b5-0b08-4286-b5fb-2bbee503ec1c,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-379d8ecb-7dd1-4622-b354-47553b502483,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-20af9251-c363-443d-9c47-7c940c5790b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-418db3f0-0fd2-49e5-9215-0e710262f5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-3432fef0-57f2-4bb4-8c24-69bdd5884f05,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-faa46475-327e-434f-beaa-019fb4e09f00,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-78e0da9c-49ef-44a5-8ac5-ea1f833f4342,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-53813e9d-85c6-41ca-b5f0-aee14bd4ebbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-137444634-172.17.0.15-1595491454136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46063,DS-0c1724b5-0b08-4286-b5fb-2bbee503ec1c,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-379d8ecb-7dd1-4622-b354-47553b502483,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-20af9251-c363-443d-9c47-7c940c5790b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-418db3f0-0fd2-49e5-9215-0e710262f5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-3432fef0-57f2-4bb4-8c24-69bdd5884f05,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-faa46475-327e-434f-beaa-019fb4e09f00,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-78e0da9c-49ef-44a5-8ac5-ea1f833f4342,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-53813e9d-85c6-41ca-b5f0-aee14bd4ebbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1977706288-172.17.0.15-1595491921387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41236,DS-fc44d3bc-7b3b-4733-911f-b374ee1ad7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-8886db8d-96b0-4dc2-ab15-227de4c2565f,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-b19a76af-8989-4a7b-b6de-e43d358d38ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-b907bfaa-778d-4ea6-983a-8a5aba6dc9db,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-a22972c5-1f08-446a-b326-d10adfc82459,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-b72c54e9-a554-47be-9603-0ab7ee53256c,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-ebe3d465-d1fc-47e7-a739-266da5299bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-39022232-fb4e-4601-98b9-b3b10f89fb78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1977706288-172.17.0.15-1595491921387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41236,DS-fc44d3bc-7b3b-4733-911f-b374ee1ad7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-8886db8d-96b0-4dc2-ab15-227de4c2565f,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-b19a76af-8989-4a7b-b6de-e43d358d38ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-b907bfaa-778d-4ea6-983a-8a5aba6dc9db,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-a22972c5-1f08-446a-b326-d10adfc82459,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-b72c54e9-a554-47be-9603-0ab7ee53256c,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-ebe3d465-d1fc-47e7-a739-266da5299bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-39022232-fb4e-4601-98b9-b3b10f89fb78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1177311320-172.17.0.15-1595492088864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37335,DS-e1e46eec-1292-4d20-9250-bfa30a9c1b42,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-097114a8-0fc3-4599-bef0-9796da3785e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-46c85393-20ae-4847-b444-65f9322f7701,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-6af53aa8-8df8-4ea4-9994-e463e90ac6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-23a6018a-5c53-4841-9b25-0d57485b659b,DISK], DatanodeInfoWithStorage[127.0.0.1:33546,DS-72ae1439-b61f-4599-a56b-5471b0a51d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-2df97e3b-76a2-4c8a-8388-567f5e2a32ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41710,DS-af30cd7f-bf55-49d1-a871-0a9978499791,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1177311320-172.17.0.15-1595492088864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37335,DS-e1e46eec-1292-4d20-9250-bfa30a9c1b42,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-097114a8-0fc3-4599-bef0-9796da3785e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-46c85393-20ae-4847-b444-65f9322f7701,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-6af53aa8-8df8-4ea4-9994-e463e90ac6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-23a6018a-5c53-4841-9b25-0d57485b659b,DISK], DatanodeInfoWithStorage[127.0.0.1:33546,DS-72ae1439-b61f-4599-a56b-5471b0a51d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-2df97e3b-76a2-4c8a-8388-567f5e2a32ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41710,DS-af30cd7f-bf55-49d1-a871-0a9978499791,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-77423202-172.17.0.15-1595492417567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37707,DS-49a54052-788d-44b0-a346-4f3ba9c69d35,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-f44ae760-8c5c-4cda-80ba-1741928d3473,DISK], DatanodeInfoWithStorage[127.0.0.1:44155,DS-8b77c413-f5a1-4e3b-b62b-452a91953253,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-e4b4d6e9-ca9d-4dfe-8e41-9088ef5f3f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-61b71e33-c713-40ff-a17c-b4a63d052861,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-e2019a82-5b05-41ca-859f-de3711ab1ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:42426,DS-7a0cce1f-d8cb-49ae-beca-7d6793f4ec3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41463,DS-a2d3b52c-ce23-46dd-838e-a5e667435840,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-77423202-172.17.0.15-1595492417567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37707,DS-49a54052-788d-44b0-a346-4f3ba9c69d35,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-f44ae760-8c5c-4cda-80ba-1741928d3473,DISK], DatanodeInfoWithStorage[127.0.0.1:44155,DS-8b77c413-f5a1-4e3b-b62b-452a91953253,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-e4b4d6e9-ca9d-4dfe-8e41-9088ef5f3f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-61b71e33-c713-40ff-a17c-b4a63d052861,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-e2019a82-5b05-41ca-859f-de3711ab1ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:42426,DS-7a0cce1f-d8cb-49ae-beca-7d6793f4ec3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41463,DS-a2d3b52c-ce23-46dd-838e-a5e667435840,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-77576187-172.17.0.15-1595492451871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45460,DS-6bf9eda7-4c5b-47be-9d5b-35e0bf3d26ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-22f29913-960e-4c8c-8e8b-03d1dbfc111c,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-0152493c-5300-4e65-9557-030810059c48,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-f3d483a4-7fb5-40f7-80c8-e6b4e5a47c88,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-dc96e631-e8f0-4326-b60f-67935eb5feff,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-22a06488-1ff2-4013-a050-1d3c0db92a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45654,DS-0da88c61-66a6-4edb-a76b-4424aa0887d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-76d22d50-3f3f-4da1-9f7a-91564978685a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-77576187-172.17.0.15-1595492451871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45460,DS-6bf9eda7-4c5b-47be-9d5b-35e0bf3d26ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-22f29913-960e-4c8c-8e8b-03d1dbfc111c,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-0152493c-5300-4e65-9557-030810059c48,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-f3d483a4-7fb5-40f7-80c8-e6b4e5a47c88,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-dc96e631-e8f0-4326-b60f-67935eb5feff,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-22a06488-1ff2-4013-a050-1d3c0db92a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45654,DS-0da88c61-66a6-4edb-a76b-4424aa0887d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-76d22d50-3f3f-4da1-9f7a-91564978685a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 22 out of 50
result: false positive !!!
Total execution time in seconds : 5648
