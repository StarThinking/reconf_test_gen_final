reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 16
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 16
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-885194312-172.17.0.11-1595874763200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42195,DS-7113c1ce-19f9-425b-99de-703110836e67,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-5b7d2115-d52c-4233-bb91-598bb03c8375,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-98affad9-8d39-47f3-81f8-33abcc05d281,DISK], DatanodeInfoWithStorage[127.0.0.1:41190,DS-17a5ab99-5655-46f0-9c0f-276035575461,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-e7896d59-1dd2-4c8e-89bb-76196419d55c,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-aeee123f-b9ed-4e30-b0d5-53cead8f0ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-ebed6656-6765-4c89-8911-1cc0da83e48a,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-f23396c3-7ea1-4609-b1e0-e506e0db4cfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-885194312-172.17.0.11-1595874763200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42195,DS-7113c1ce-19f9-425b-99de-703110836e67,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-5b7d2115-d52c-4233-bb91-598bb03c8375,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-98affad9-8d39-47f3-81f8-33abcc05d281,DISK], DatanodeInfoWithStorage[127.0.0.1:41190,DS-17a5ab99-5655-46f0-9c0f-276035575461,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-e7896d59-1dd2-4c8e-89bb-76196419d55c,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-aeee123f-b9ed-4e30-b0d5-53cead8f0ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-ebed6656-6765-4c89-8911-1cc0da83e48a,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-f23396c3-7ea1-4609-b1e0-e506e0db4cfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 16
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2071417065-172.17.0.11-1595875079645:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41605,DS-eb794026-0fba-43a6-8437-94832385ef20,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-67825c0e-e75c-4c6c-8bbd-35eb694c6deb,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-a7258c17-117f-41e5-8001-742a1cb03a31,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-214bcbfb-a882-4f5b-ae99-a23917ec6c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-653c2ff7-78af-441b-a4e7-c4659572e25f,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-ebd82903-4fd1-4318-858f-081ae213ce66,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-30f77d09-6bb0-40a7-98dc-5e7b2663c52b,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-6323813a-a6f0-4d64-8388-4138b80f7af7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2071417065-172.17.0.11-1595875079645:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41605,DS-eb794026-0fba-43a6-8437-94832385ef20,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-67825c0e-e75c-4c6c-8bbd-35eb694c6deb,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-a7258c17-117f-41e5-8001-742a1cb03a31,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-214bcbfb-a882-4f5b-ae99-a23917ec6c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-653c2ff7-78af-441b-a4e7-c4659572e25f,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-ebd82903-4fd1-4318-858f-081ae213ce66,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-30f77d09-6bb0-40a7-98dc-5e7b2663c52b,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-6323813a-a6f0-4d64-8388-4138b80f7af7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 16
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1547479448-172.17.0.11-1595875591327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45791,DS-6780a09e-a326-44dc-98f8-b426cee759dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-1caaa2f0-6cd8-4410-bd31-82e38941b31c,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-7a905fb2-f215-4fc6-876c-e99c386a623c,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-184ed1d6-fa6b-4f93-b6e8-f03dc247b715,DISK], DatanodeInfoWithStorage[127.0.0.1:45468,DS-ffe57175-faa0-48a4-bb9d-50e103bae4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-d26a8470-2ecb-4897-8569-69ee77475cec,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-afe247fd-87e6-4864-b980-8f1a6999a8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-776fc8e7-2797-4f26-92e0-d8e46fa903cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1547479448-172.17.0.11-1595875591327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45791,DS-6780a09e-a326-44dc-98f8-b426cee759dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-1caaa2f0-6cd8-4410-bd31-82e38941b31c,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-7a905fb2-f215-4fc6-876c-e99c386a623c,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-184ed1d6-fa6b-4f93-b6e8-f03dc247b715,DISK], DatanodeInfoWithStorage[127.0.0.1:45468,DS-ffe57175-faa0-48a4-bb9d-50e103bae4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-d26a8470-2ecb-4897-8569-69ee77475cec,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-afe247fd-87e6-4864-b980-8f1a6999a8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-776fc8e7-2797-4f26-92e0-d8e46fa903cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 16
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-864269764-172.17.0.11-1595875844307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35507,DS-a4b353e6-206b-49b6-90d0-a90e6a86e35c,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-9cd3bd0a-d68c-483b-982d-b03f95b14857,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-0c061c48-8f99-4b72-8312-f7db64398c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-e1faebde-3e0a-482c-900b-0eb6e597bd46,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-aa080db5-85a2-4b27-99dd-9de0dd86e92d,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-1699cdb4-20f5-4c64-9ee5-ef228af49f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-ad1bac35-a86d-4f6c-992b-2bb1689bee4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-d52f03e7-db15-43c7-8c4e-d7bce6cb7152,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-864269764-172.17.0.11-1595875844307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35507,DS-a4b353e6-206b-49b6-90d0-a90e6a86e35c,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-9cd3bd0a-d68c-483b-982d-b03f95b14857,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-0c061c48-8f99-4b72-8312-f7db64398c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-e1faebde-3e0a-482c-900b-0eb6e597bd46,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-aa080db5-85a2-4b27-99dd-9de0dd86e92d,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-1699cdb4-20f5-4c64-9ee5-ef228af49f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-ad1bac35-a86d-4f6c-992b-2bb1689bee4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-d52f03e7-db15-43c7-8c4e-d7bce6cb7152,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 16
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1929200933-172.17.0.11-1595877220557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38623,DS-950f174a-2f65-4759-9b56-67e27e3f2aab,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-5581bd94-facd-4017-a282-65d1dba20744,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-20d35dad-e12a-4147-bc77-84b20789fc34,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-6a2475a4-bd27-4cf4-9898-e03a33f76776,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-246dba57-c6d7-4ff5-91fc-87cfd01bfe96,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-58014b5d-28a4-4fb1-927d-78da8dd68da1,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-90ba2732-8780-45a7-842c-533d72bb0c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-fe3c0d58-dd5e-4699-a9a9-12a9427174ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1929200933-172.17.0.11-1595877220557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38623,DS-950f174a-2f65-4759-9b56-67e27e3f2aab,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-5581bd94-facd-4017-a282-65d1dba20744,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-20d35dad-e12a-4147-bc77-84b20789fc34,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-6a2475a4-bd27-4cf4-9898-e03a33f76776,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-246dba57-c6d7-4ff5-91fc-87cfd01bfe96,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-58014b5d-28a4-4fb1-927d-78da8dd68da1,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-90ba2732-8780-45a7-842c-533d72bb0c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-fe3c0d58-dd5e-4699-a9a9-12a9427174ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 16
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1457943479-172.17.0.11-1595877383674:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36225,DS-d5d5e297-842e-4649-b0e0-dc10db1225fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-33023b9d-b330-4016-80b7-f0d5033fb426,DISK], DatanodeInfoWithStorage[127.0.0.1:35581,DS-8a685d31-39b2-40bd-94a1-00db9770962b,DISK], DatanodeInfoWithStorage[127.0.0.1:41813,DS-39bb6b15-7116-47ed-a484-46a1f1474c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-528bfa7e-ed19-47a7-84ef-aca843a4f5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-243466d1-36a6-4ad6-b9d1-e3f5183bdc3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-2205cbdb-99c0-40c8-a691-a94e2e0cb8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39817,DS-9fb99a59-fad6-4cea-a6f1-1412fe61b0d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1457943479-172.17.0.11-1595877383674:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36225,DS-d5d5e297-842e-4649-b0e0-dc10db1225fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-33023b9d-b330-4016-80b7-f0d5033fb426,DISK], DatanodeInfoWithStorage[127.0.0.1:35581,DS-8a685d31-39b2-40bd-94a1-00db9770962b,DISK], DatanodeInfoWithStorage[127.0.0.1:41813,DS-39bb6b15-7116-47ed-a484-46a1f1474c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-528bfa7e-ed19-47a7-84ef-aca843a4f5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-243466d1-36a6-4ad6-b9d1-e3f5183bdc3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-2205cbdb-99c0-40c8-a691-a94e2e0cb8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39817,DS-9fb99a59-fad6-4cea-a6f1-1412fe61b0d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 16
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1960816478-172.17.0.11-1595878205052:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35082,DS-f84907a6-c4de-42be-877b-034cdb4fc7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46757,DS-dfda458a-5d59-48a1-923d-576f82da2544,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-03850c33-e44d-4431-aa0f-ddbc0e585e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-c6759142-5173-4b88-b04d-d5cb9c5ca15b,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-8efe88a5-ece5-455f-9316-9190d941b2dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-de58d179-eab9-4368-9caf-fae1b2279b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-b075b70f-fd71-462e-bde1-42eaba2c48ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-864d54a1-2a63-4c97-b02a-a99ad4c19251,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1960816478-172.17.0.11-1595878205052:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35082,DS-f84907a6-c4de-42be-877b-034cdb4fc7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46757,DS-dfda458a-5d59-48a1-923d-576f82da2544,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-03850c33-e44d-4431-aa0f-ddbc0e585e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-c6759142-5173-4b88-b04d-d5cb9c5ca15b,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-8efe88a5-ece5-455f-9316-9190d941b2dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-de58d179-eab9-4368-9caf-fae1b2279b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-b075b70f-fd71-462e-bde1-42eaba2c48ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-864d54a1-2a63-4c97-b02a-a99ad4c19251,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 16
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-674702001-172.17.0.11-1595878253090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42238,DS-d24f63cc-4c54-42aa-aa4f-639b573fa5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-7f8e1df0-1ee0-43d6-9c70-564a33f1626a,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-88d929d8-c800-4d5c-8f2a-893822f859e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-e12260a1-ec89-441c-be52-35f9d4d9208a,DISK], DatanodeInfoWithStorage[127.0.0.1:40874,DS-c2b636aa-148f-4e1d-a95f-4183e8648dac,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-90d41dd3-46d7-40ae-97fe-3e20704406c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38860,DS-3f2ac28f-d91c-4918-9f50-4761e92cb5ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-c170a5e9-e433-4666-bbe2-c09146de68fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-674702001-172.17.0.11-1595878253090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42238,DS-d24f63cc-4c54-42aa-aa4f-639b573fa5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-7f8e1df0-1ee0-43d6-9c70-564a33f1626a,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-88d929d8-c800-4d5c-8f2a-893822f859e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-e12260a1-ec89-441c-be52-35f9d4d9208a,DISK], DatanodeInfoWithStorage[127.0.0.1:40874,DS-c2b636aa-148f-4e1d-a95f-4183e8648dac,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-90d41dd3-46d7-40ae-97fe-3e20704406c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38860,DS-3f2ac28f-d91c-4918-9f50-4761e92cb5ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-c170a5e9-e433-4666-bbe2-c09146de68fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 16
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1527801745-172.17.0.11-1595878605405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41930,DS-c5c5dd5d-9cb2-440b-88bc-f208c09c2d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-ff46db1e-338a-437a-80ad-c96fce2e6032,DISK], DatanodeInfoWithStorage[127.0.0.1:36218,DS-f2805ac7-9899-4063-800b-155c31582be9,DISK], DatanodeInfoWithStorage[127.0.0.1:45669,DS-8d7375ab-b044-4208-b972-27bfef32c022,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-b36c0e11-26bf-48ba-be65-47cc63ee4cce,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-95f025c8-66f7-47d0-977d-db8edf26a793,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-04d3796a-9669-4a54-98f3-c677bcd2ede1,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-d6b33d98-de26-41cf-8a49-36fa8d68aba4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1527801745-172.17.0.11-1595878605405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41930,DS-c5c5dd5d-9cb2-440b-88bc-f208c09c2d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-ff46db1e-338a-437a-80ad-c96fce2e6032,DISK], DatanodeInfoWithStorage[127.0.0.1:36218,DS-f2805ac7-9899-4063-800b-155c31582be9,DISK], DatanodeInfoWithStorage[127.0.0.1:45669,DS-8d7375ab-b044-4208-b972-27bfef32c022,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-b36c0e11-26bf-48ba-be65-47cc63ee4cce,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-95f025c8-66f7-47d0-977d-db8edf26a793,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-04d3796a-9669-4a54-98f3-c677bcd2ede1,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-d6b33d98-de26-41cf-8a49-36fa8d68aba4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 16
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1481277353-172.17.0.11-1595878807609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46067,DS-b85569ad-801d-4ed0-8e39-627d9357ba0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41898,DS-59fe94c6-c21f-40bb-a975-f5b8fba7415e,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-e86bf9fb-9ebc-4223-ac86-6257f3747b02,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-fde0c74a-1b9b-4232-a03f-804c3289f004,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-49e0a45b-0400-4f5d-9a5a-250e6cf9375d,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-d07acd46-30e6-4e50-99d6-0c37a22edd82,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-b303b1a6-4081-40cc-833a-fc770a5f70f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-51e365ce-de59-4c09-8d11-f09f96665d04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1481277353-172.17.0.11-1595878807609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46067,DS-b85569ad-801d-4ed0-8e39-627d9357ba0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41898,DS-59fe94c6-c21f-40bb-a975-f5b8fba7415e,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-e86bf9fb-9ebc-4223-ac86-6257f3747b02,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-fde0c74a-1b9b-4232-a03f-804c3289f004,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-49e0a45b-0400-4f5d-9a5a-250e6cf9375d,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-d07acd46-30e6-4e50-99d6-0c37a22edd82,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-b303b1a6-4081-40cc-833a-fc770a5f70f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-51e365ce-de59-4c09-8d11-f09f96665d04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 16
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-693952044-172.17.0.11-1595879040689:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43242,DS-6dbf505f-9ecc-4043-9d1b-ac23b3e0f04f,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-d32ccba4-b2d5-4b87-a573-70bbb7d488a6,DISK], DatanodeInfoWithStorage[127.0.0.1:32773,DS-fe879aa5-8cbb-4141-a161-59a5eccd00ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-df689c11-6885-4b15-a5d4-75637d2cbcd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-584cfa97-fad4-4541-9ce7-5bf457efebde,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-d27f00d9-7abc-4a59-8afc-612f75ca7152,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-d76fb07f-d685-4f43-b679-5d76870691b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-cdb4f0ca-0fa4-4c25-82bf-788a45770a15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-693952044-172.17.0.11-1595879040689:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43242,DS-6dbf505f-9ecc-4043-9d1b-ac23b3e0f04f,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-d32ccba4-b2d5-4b87-a573-70bbb7d488a6,DISK], DatanodeInfoWithStorage[127.0.0.1:32773,DS-fe879aa5-8cbb-4141-a161-59a5eccd00ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-df689c11-6885-4b15-a5d4-75637d2cbcd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-584cfa97-fad4-4541-9ce7-5bf457efebde,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-d27f00d9-7abc-4a59-8afc-612f75ca7152,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-d76fb07f-d685-4f43-b679-5d76870691b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-cdb4f0ca-0fa4-4c25-82bf-788a45770a15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 16
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-256642184-172.17.0.11-1595879446697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40850,DS-7fbf7b49-0a63-4a22-92e0-95a4d9c2eb54,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-073e8354-d206-4c4f-b01b-27e58efa8f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-fcfc0558-5ead-4272-a683-d3257c606e82,DISK], DatanodeInfoWithStorage[127.0.0.1:40405,DS-56227ec0-4767-4f8c-a569-193a1e363c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-282494b7-20ef-4866-9232-692c2b5ca356,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-bd1366fe-3a06-4688-9a51-a80677ca63f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-72de53e2-786d-4428-9a34-61c11ff38e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-e72cbb11-2c9c-4dd9-a396-e95097db327b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-256642184-172.17.0.11-1595879446697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40850,DS-7fbf7b49-0a63-4a22-92e0-95a4d9c2eb54,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-073e8354-d206-4c4f-b01b-27e58efa8f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-fcfc0558-5ead-4272-a683-d3257c606e82,DISK], DatanodeInfoWithStorage[127.0.0.1:40405,DS-56227ec0-4767-4f8c-a569-193a1e363c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-282494b7-20ef-4866-9232-692c2b5ca356,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-bd1366fe-3a06-4688-9a51-a80677ca63f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-72de53e2-786d-4428-9a34-61c11ff38e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-e72cbb11-2c9c-4dd9-a396-e95097db327b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 16
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1988893797-172.17.0.11-1595879881229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41804,DS-4e65f2c3-5ad4-4f1a-bee0-64742ad45d69,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-22f09159-bd1d-41f2-ad5b-26e13087ca48,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-86cee0d8-1efb-4909-8513-94d7d73510c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-b1b8da7f-eff5-4edd-b5ac-578a77c449b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-ec210d0e-a937-419d-a682-b7eed2c61281,DISK], DatanodeInfoWithStorage[127.0.0.1:40306,DS-4634e5dd-144b-4bda-b471-b018967893d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-e3db45a0-8357-4569-81cd-c4c8dbd325e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-3e66a304-f9ed-4c9d-9a6e-d098e2a9b706,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1988893797-172.17.0.11-1595879881229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41804,DS-4e65f2c3-5ad4-4f1a-bee0-64742ad45d69,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-22f09159-bd1d-41f2-ad5b-26e13087ca48,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-86cee0d8-1efb-4909-8513-94d7d73510c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-b1b8da7f-eff5-4edd-b5ac-578a77c449b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-ec210d0e-a937-419d-a682-b7eed2c61281,DISK], DatanodeInfoWithStorage[127.0.0.1:40306,DS-4634e5dd-144b-4bda-b471-b018967893d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-e3db45a0-8357-4569-81cd-c4c8dbd325e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-3e66a304-f9ed-4c9d-9a6e-d098e2a9b706,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 6162
