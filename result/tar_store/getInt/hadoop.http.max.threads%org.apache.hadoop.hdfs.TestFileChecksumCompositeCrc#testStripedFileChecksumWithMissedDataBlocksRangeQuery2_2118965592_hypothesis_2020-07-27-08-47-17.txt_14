reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 1000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 1000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-307196173-172.17.0.11-1595839750535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45141,DS-fcff86ab-6194-468d-b656-04eda134b8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38913,DS-a016521f-d50c-4fd2-8cd1-cfa6997a0a36,DISK], DatanodeInfoWithStorage[127.0.0.1:35785,DS-d9800061-3e7d-410a-802e-b720dd99a7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-40082c4c-6f7b-4906-a0c2-7f7ce0e53540,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-19db5ebf-3f04-41cc-a04a-8537040d314a,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-97fa9eb1-a36b-411b-8853-3f7f5cc3f99e,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-db6b149c-77e8-416f-b0d7-8f5be044cf15,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-c9b02cde-7406-4136-9283-0cf675b826c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-307196173-172.17.0.11-1595839750535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45141,DS-fcff86ab-6194-468d-b656-04eda134b8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38913,DS-a016521f-d50c-4fd2-8cd1-cfa6997a0a36,DISK], DatanodeInfoWithStorage[127.0.0.1:35785,DS-d9800061-3e7d-410a-802e-b720dd99a7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-40082c4c-6f7b-4906-a0c2-7f7ce0e53540,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-19db5ebf-3f04-41cc-a04a-8537040d314a,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-97fa9eb1-a36b-411b-8853-3f7f5cc3f99e,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-db6b149c-77e8-416f-b0d7-8f5be044cf15,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-c9b02cde-7406-4136-9283-0cf675b826c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 1000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1070209633-172.17.0.11-1595839805319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37243,DS-bd661a12-bb41-4802-a2e7-f4b1ed60b23e,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-65df7cc7-12f7-48bd-a01a-dc9aabb9add0,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-375cf6bb-ce2a-426f-bdfb-da512f1696a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-eb5275f7-02cd-4f82-b490-f2a46e5c427c,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-133dfddf-be5f-48ff-909c-8831801454ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-4ab4d790-ac46-4370-a2a6-8e33efd94020,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-dd0c59c2-ab6a-44d4-ae9c-45e3256b126a,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-95e12aaf-405f-428f-b1e8-8b95e8a18ff2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1070209633-172.17.0.11-1595839805319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37243,DS-bd661a12-bb41-4802-a2e7-f4b1ed60b23e,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-65df7cc7-12f7-48bd-a01a-dc9aabb9add0,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-375cf6bb-ce2a-426f-bdfb-da512f1696a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-eb5275f7-02cd-4f82-b490-f2a46e5c427c,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-133dfddf-be5f-48ff-909c-8831801454ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-4ab4d790-ac46-4370-a2a6-8e33efd94020,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-dd0c59c2-ab6a-44d4-ae9c-45e3256b126a,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-95e12aaf-405f-428f-b1e8-8b95e8a18ff2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 1000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-559264991-172.17.0.11-1595840036753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37552,DS-a7461a60-361c-495a-84c4-5945b940f6b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46613,DS-79af32c1-21cf-4816-a680-73aead47056e,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-7beafa02-70a1-4278-a0ff-c428f0ce791f,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-e5b0b7e6-45fa-4dae-a23b-d657e2819ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-17bd9df1-6fb1-431b-88a1-d46dd9d220c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-c6622ba8-fff2-4488-8281-e452871fba01,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-e5011973-7594-474d-a151-d2d3d3cf0b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36809,DS-5da64acc-d6f2-4ee1-9f61-6da5dd644495,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-559264991-172.17.0.11-1595840036753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37552,DS-a7461a60-361c-495a-84c4-5945b940f6b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46613,DS-79af32c1-21cf-4816-a680-73aead47056e,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-7beafa02-70a1-4278-a0ff-c428f0ce791f,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-e5b0b7e6-45fa-4dae-a23b-d657e2819ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-17bd9df1-6fb1-431b-88a1-d46dd9d220c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-c6622ba8-fff2-4488-8281-e452871fba01,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-e5011973-7594-474d-a151-d2d3d3cf0b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36809,DS-5da64acc-d6f2-4ee1-9f61-6da5dd644495,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 1000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1441220956-172.17.0.11-1595841063654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35613,DS-dd14bc96-ec0f-445d-b548-52b09fd45a17,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-699377b6-b790-484d-aa48-a41d36d56aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-719c9093-75ee-4069-a31e-69eda1fc242a,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-fc7acb19-1d58-4a2c-9874-91df5f632e24,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-4fa0af54-21eb-4153-93b4-dee16443a553,DISK], DatanodeInfoWithStorage[127.0.0.1:34521,DS-0a240a04-b143-47de-b17d-b6452efaffb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-e968c801-f7f9-4277-8141-6696e03aea26,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-f43c8d57-ff27-47af-b721-e3858801f621,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1441220956-172.17.0.11-1595841063654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35613,DS-dd14bc96-ec0f-445d-b548-52b09fd45a17,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-699377b6-b790-484d-aa48-a41d36d56aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-719c9093-75ee-4069-a31e-69eda1fc242a,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-fc7acb19-1d58-4a2c-9874-91df5f632e24,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-4fa0af54-21eb-4153-93b4-dee16443a553,DISK], DatanodeInfoWithStorage[127.0.0.1:34521,DS-0a240a04-b143-47de-b17d-b6452efaffb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-e968c801-f7f9-4277-8141-6696e03aea26,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-f43c8d57-ff27-47af-b721-e3858801f621,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 1000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2073728155-172.17.0.11-1595841100303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42853,DS-25430ef4-137c-44aa-a4d3-0c5d21d96d35,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-ee8a33f0-ad3e-4b3d-8a67-8bc8cc371012,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-43919ecb-12ee-4c85-b559-e43894320ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-62e6cfea-333c-4136-920a-af45bc2cf7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-aecabfa0-8e24-40cf-a7be-27086f4c3c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-cbd45676-9ab8-4663-9152-1883ab6a948a,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-05c1876d-d381-4a23-990d-a5b84d2806c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-ea568b72-953a-4f9e-8c2f-ac81ad755800,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2073728155-172.17.0.11-1595841100303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42853,DS-25430ef4-137c-44aa-a4d3-0c5d21d96d35,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-ee8a33f0-ad3e-4b3d-8a67-8bc8cc371012,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-43919ecb-12ee-4c85-b559-e43894320ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-62e6cfea-333c-4136-920a-af45bc2cf7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-aecabfa0-8e24-40cf-a7be-27086f4c3c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-cbd45676-9ab8-4663-9152-1883ab6a948a,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-05c1876d-d381-4a23-990d-a5b84d2806c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-ea568b72-953a-4f9e-8c2f-ac81ad755800,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 1000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1343285999-172.17.0.11-1595841480145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37361,DS-3b2e5a2f-d2c6-4844-83ea-e16427e3f7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-e23a3119-4322-4d90-af9d-7cbc417556b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45775,DS-4e2266ef-44fa-4a82-ad11-d1d8eef5fef2,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-1f99db6d-dee1-44f6-84ba-a0c34d2359f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-0bb88b5b-e9d1-4103-8604-48bb9cff822a,DISK], DatanodeInfoWithStorage[127.0.0.1:33463,DS-7895fd00-8738-42fb-89e2-5f13ceb3a290,DISK], DatanodeInfoWithStorage[127.0.0.1:43879,DS-bcfeca03-06d4-428a-a3d0-23619eef88b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-6466e6e8-82d2-4b3f-97d3-8fb5ec4a6c34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1343285999-172.17.0.11-1595841480145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37361,DS-3b2e5a2f-d2c6-4844-83ea-e16427e3f7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-e23a3119-4322-4d90-af9d-7cbc417556b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45775,DS-4e2266ef-44fa-4a82-ad11-d1d8eef5fef2,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-1f99db6d-dee1-44f6-84ba-a0c34d2359f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-0bb88b5b-e9d1-4103-8604-48bb9cff822a,DISK], DatanodeInfoWithStorage[127.0.0.1:33463,DS-7895fd00-8738-42fb-89e2-5f13ceb3a290,DISK], DatanodeInfoWithStorage[127.0.0.1:43879,DS-bcfeca03-06d4-428a-a3d0-23619eef88b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-6466e6e8-82d2-4b3f-97d3-8fb5ec4a6c34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 1000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1032318887-172.17.0.11-1595841516565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33845,DS-6f6fc5df-cf8e-47a8-aa78-8c2439622b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-cca110ec-dfb7-4b44-97f3-03f8288583a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-f5ac7e72-9ed4-4388-b9d8-bfecf519ee3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-ad812670-7216-4b60-8a68-c9195b7e8a55,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-98ace77a-6b25-4428-bd44-ce33bceed4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40667,DS-d0fd574f-fd33-42c1-be12-8fab0a5cdaa0,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-c2643050-3203-4e94-98b5-57a7cda4e118,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-1c06473a-30ae-47a6-b781-00e235ea08e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1032318887-172.17.0.11-1595841516565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33845,DS-6f6fc5df-cf8e-47a8-aa78-8c2439622b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-cca110ec-dfb7-4b44-97f3-03f8288583a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-f5ac7e72-9ed4-4388-b9d8-bfecf519ee3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-ad812670-7216-4b60-8a68-c9195b7e8a55,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-98ace77a-6b25-4428-bd44-ce33bceed4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40667,DS-d0fd574f-fd33-42c1-be12-8fab0a5cdaa0,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-c2643050-3203-4e94-98b5-57a7cda4e118,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-1c06473a-30ae-47a6-b781-00e235ea08e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 1000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1961432710-172.17.0.11-1595841821890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38339,DS-e41e5ef8-bc3d-4348-8296-f585f787b4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37844,DS-42fafad5-c166-4013-9042-de0fca41ebae,DISK], DatanodeInfoWithStorage[127.0.0.1:43386,DS-1b5c6001-6d2c-4e43-9460-a6d3f5f839d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-0af875f4-45db-47d3-bdf0-57ab22317fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-07edd206-e771-4848-b60b-a62e8244d7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37774,DS-cd3c032f-f014-4e1e-89f8-bbc23aebab79,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-4c83749f-2214-4ec6-9212-47bc0c353a20,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-2a88bdab-a2ee-4b55-9fc7-916326f5add6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1961432710-172.17.0.11-1595841821890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38339,DS-e41e5ef8-bc3d-4348-8296-f585f787b4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37844,DS-42fafad5-c166-4013-9042-de0fca41ebae,DISK], DatanodeInfoWithStorage[127.0.0.1:43386,DS-1b5c6001-6d2c-4e43-9460-a6d3f5f839d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-0af875f4-45db-47d3-bdf0-57ab22317fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-07edd206-e771-4848-b60b-a62e8244d7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37774,DS-cd3c032f-f014-4e1e-89f8-bbc23aebab79,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-4c83749f-2214-4ec6-9212-47bc0c353a20,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-2a88bdab-a2ee-4b55-9fc7-916326f5add6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 1000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-494054875-172.17.0.11-1595841930346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40533,DS-e1aae022-aa57-4025-8e34-4b9300e51029,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-ab1391d3-e2e0-4a8a-90d8-dd6728a7f152,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-8baac945-31bb-4d08-af52-9af18f5f690f,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-42403842-febc-4cf2-918e-1e626db0c0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34245,DS-5d41c78d-b1a1-402e-97a7-c2d2376a773c,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-c055f488-4db0-4798-aed1-d9ddae298c78,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-9fb10016-95a2-498b-8048-28659950898c,DISK], DatanodeInfoWithStorage[127.0.0.1:38408,DS-0a13b947-6fd2-48b1-ac83-571e6782b2d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-494054875-172.17.0.11-1595841930346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40533,DS-e1aae022-aa57-4025-8e34-4b9300e51029,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-ab1391d3-e2e0-4a8a-90d8-dd6728a7f152,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-8baac945-31bb-4d08-af52-9af18f5f690f,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-42403842-febc-4cf2-918e-1e626db0c0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34245,DS-5d41c78d-b1a1-402e-97a7-c2d2376a773c,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-c055f488-4db0-4798-aed1-d9ddae298c78,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-9fb10016-95a2-498b-8048-28659950898c,DISK], DatanodeInfoWithStorage[127.0.0.1:38408,DS-0a13b947-6fd2-48b1-ac83-571e6782b2d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 1000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2052087513-172.17.0.11-1595842132247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45730,DS-361d760d-a18c-4729-9705-f284bd5c74b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-c8b0076d-6054-4167-8ea8-b53a68f7e1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-54819506-50d5-4da2-bbab-5fe1433b0350,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-dbdac2e1-c59b-4952-b750-2e43f5969784,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-f234f2dc-0084-4820-b413-5622eed7c2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-d1752906-e887-4cc7-9961-54b998fd872d,DISK], DatanodeInfoWithStorage[127.0.0.1:44667,DS-67b05374-f7cf-4aed-b5a6-d2b3d46584ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41627,DS-3427cf41-2c61-4289-9fc0-2860381b1389,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2052087513-172.17.0.11-1595842132247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45730,DS-361d760d-a18c-4729-9705-f284bd5c74b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-c8b0076d-6054-4167-8ea8-b53a68f7e1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-54819506-50d5-4da2-bbab-5fe1433b0350,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-dbdac2e1-c59b-4952-b750-2e43f5969784,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-f234f2dc-0084-4820-b413-5622eed7c2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-d1752906-e887-4cc7-9961-54b998fd872d,DISK], DatanodeInfoWithStorage[127.0.0.1:44667,DS-67b05374-f7cf-4aed-b5a6-d2b3d46584ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41627,DS-3427cf41-2c61-4289-9fc0-2860381b1389,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 1000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1926184914-172.17.0.11-1595842257527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44644,DS-08b1c0b9-af45-47ef-941a-6d68a209a524,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-c5d81ee9-c3a1-440a-8c19-a4fd7b9ac3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-e68c5052-3920-4746-a2bf-c13b58c26d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36951,DS-7ac155c3-18bd-48ce-aa01-277926fbc029,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-ad2f70e7-f891-43f5-9600-08e971f38cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-c7026a33-082c-4421-b3a1-93e4e4cd039c,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-108eb23a-1367-40d7-bd7f-b2adb50ea062,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-4b3212aa-2cc0-47ca-a566-cfe4fb45c922,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1926184914-172.17.0.11-1595842257527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44644,DS-08b1c0b9-af45-47ef-941a-6d68a209a524,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-c5d81ee9-c3a1-440a-8c19-a4fd7b9ac3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-e68c5052-3920-4746-a2bf-c13b58c26d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36951,DS-7ac155c3-18bd-48ce-aa01-277926fbc029,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-ad2f70e7-f891-43f5-9600-08e971f38cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-c7026a33-082c-4421-b3a1-93e4e4cd039c,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-108eb23a-1367-40d7-bd7f-b2adb50ea062,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-4b3212aa-2cc0-47ca-a566-cfe4fb45c922,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 1000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1611806288-172.17.0.11-1595842313590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46419,DS-a30b9d6e-7a77-4fdf-973d-b5af16d18a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-e611bb9c-b53b-4b2c-9c1e-e718142d6c33,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-418531f6-498c-4b0a-ac19-e809a21f0960,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-463bf7be-f22b-4a5a-af21-a6587619e3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-df169e61-da9b-4e89-8b1c-7b9afccf7c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-a3856e45-1c03-4cf5-9e5e-6cbd22bcdc79,DISK], DatanodeInfoWithStorage[127.0.0.1:34854,DS-b762f8c1-fc72-4c05-9302-f14335741707,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-00b686f3-272c-40a0-b28b-1bb3ce393c70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1611806288-172.17.0.11-1595842313590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46419,DS-a30b9d6e-7a77-4fdf-973d-b5af16d18a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-e611bb9c-b53b-4b2c-9c1e-e718142d6c33,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-418531f6-498c-4b0a-ac19-e809a21f0960,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-463bf7be-f22b-4a5a-af21-a6587619e3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-df169e61-da9b-4e89-8b1c-7b9afccf7c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-a3856e45-1c03-4cf5-9e5e-6cbd22bcdc79,DISK], DatanodeInfoWithStorage[127.0.0.1:34854,DS-b762f8c1-fc72-4c05-9302-f14335741707,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-00b686f3-272c-40a0-b28b-1bb3ce393c70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 1000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2087378241-172.17.0.11-1595842352477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35487,DS-5d699ad1-0624-4c00-8d1c-0a25cc389d99,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-808c6004-6888-44b6-a4f9-11e8216280c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36605,DS-1eca9840-bbf8-45c9-b9af-52ff1ebd69c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41225,DS-ec6b191a-9136-45e9-8af7-40c5870ea24a,DISK], DatanodeInfoWithStorage[127.0.0.1:36116,DS-5d569a11-85fd-47c8-802a-e6587a2ee07a,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-cb53e0ed-590d-41ef-b6db-97b35d6875ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-00294b62-324f-4650-9b16-e37212b3462d,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-ac7a4352-93ae-46cf-b2f8-2c88fce16818,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2087378241-172.17.0.11-1595842352477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35487,DS-5d699ad1-0624-4c00-8d1c-0a25cc389d99,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-808c6004-6888-44b6-a4f9-11e8216280c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36605,DS-1eca9840-bbf8-45c9-b9af-52ff1ebd69c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41225,DS-ec6b191a-9136-45e9-8af7-40c5870ea24a,DISK], DatanodeInfoWithStorage[127.0.0.1:36116,DS-5d569a11-85fd-47c8-802a-e6587a2ee07a,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-cb53e0ed-590d-41ef-b6db-97b35d6875ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-00294b62-324f-4650-9b16-e37212b3462d,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-ac7a4352-93ae-46cf-b2f8-2c88fce16818,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 1000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1739172752-172.17.0.11-1595842490383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46491,DS-14a91237-404e-41af-a238-0ac0ebf1bd2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-a9a18763-ecd5-4e1e-944e-53e897ac4565,DISK], DatanodeInfoWithStorage[127.0.0.1:33464,DS-30a87526-9113-4454-9fea-b4b92c2fd932,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-0bf5e39e-6643-4198-9ad2-9b64f2750f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-ede1cfff-4a33-4658-be33-b7f2b263f5af,DISK], DatanodeInfoWithStorage[127.0.0.1:36910,DS-1eb4f703-122c-4508-a300-285ddb61a167,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-57ddd89f-cd89-4840-8084-cc288e957c93,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-80d5a220-f77e-492d-be1e-ed8111557f8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1739172752-172.17.0.11-1595842490383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46491,DS-14a91237-404e-41af-a238-0ac0ebf1bd2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-a9a18763-ecd5-4e1e-944e-53e897ac4565,DISK], DatanodeInfoWithStorage[127.0.0.1:33464,DS-30a87526-9113-4454-9fea-b4b92c2fd932,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-0bf5e39e-6643-4198-9ad2-9b64f2750f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-ede1cfff-4a33-4658-be33-b7f2b263f5af,DISK], DatanodeInfoWithStorage[127.0.0.1:36910,DS-1eb4f703-122c-4508-a300-285ddb61a167,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-57ddd89f-cd89-4840-8084-cc288e957c93,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-80d5a220-f77e-492d-be1e-ed8111557f8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 1000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1620895729-172.17.0.11-1595842827538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43649,DS-cff213ac-2f68-4352-9fb4-48c195f216ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-de23b3d2-7abe-4c5d-af12-6185e47bb105,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-600f71ac-d074-45f4-b5cd-ce6b55095041,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-3003b8d6-99fd-4a69-a388-85e87f1a8f98,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-aafdd786-f910-4038-ad3a-31e48f631f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-8af67f61-ddfe-4906-8c2e-4a5cac971e63,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-e572d2cc-c01c-4f3d-bf7d-3a271335078f,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-34dc4548-f1be-4969-b9c0-8803acc8bcc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1620895729-172.17.0.11-1595842827538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43649,DS-cff213ac-2f68-4352-9fb4-48c195f216ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-de23b3d2-7abe-4c5d-af12-6185e47bb105,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-600f71ac-d074-45f4-b5cd-ce6b55095041,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-3003b8d6-99fd-4a69-a388-85e87f1a8f98,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-aafdd786-f910-4038-ad3a-31e48f631f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-8af67f61-ddfe-4906-8c2e-4a5cac971e63,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-e572d2cc-c01c-4f3d-bf7d-3a271335078f,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-34dc4548-f1be-4969-b9c0-8803acc8bcc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 1000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1915985654-172.17.0.11-1595842969098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45633,DS-f3e47e16-7938-43f4-b39b-b1a002574ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-44fd7cc6-d5c0-47fb-b40d-c6badb4dd883,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-46f1f3a6-78e3-4ae5-ae6a-27d91e3ed7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-fd806520-42be-4bfd-8d9d-d5b7644602a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-2b809895-3971-4755-b95f-dde38a3927e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33086,DS-ffc10e30-df2d-40bf-907c-a50a345b2e69,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-a7527544-6c63-4030-96e4-774037ae327e,DISK], DatanodeInfoWithStorage[127.0.0.1:34648,DS-54e6a521-870d-4be7-bd08-b86d5b801634,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1915985654-172.17.0.11-1595842969098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45633,DS-f3e47e16-7938-43f4-b39b-b1a002574ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-44fd7cc6-d5c0-47fb-b40d-c6badb4dd883,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-46f1f3a6-78e3-4ae5-ae6a-27d91e3ed7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-fd806520-42be-4bfd-8d9d-d5b7644602a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-2b809895-3971-4755-b95f-dde38a3927e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33086,DS-ffc10e30-df2d-40bf-907c-a50a345b2e69,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-a7527544-6c63-4030-96e4-774037ae327e,DISK], DatanodeInfoWithStorage[127.0.0.1:34648,DS-54e6a521-870d-4be7-bd08-b86d5b801634,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 1000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-87602325-172.17.0.11-1595843183871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39567,DS-f53a3e1a-0688-47da-a8de-7a35cafbba24,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-6de40fca-100b-4d9e-a98b-47ea69ca75ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-c1fdbb66-73f1-4111-ba7e-d40def4aecfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-93f1d648-e74d-4758-b465-97943822071e,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-e5e215f6-ee35-409d-8908-98d059676cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-4d8cef0b-1edb-4e5b-994c-35eeeb74977e,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-66317654-7488-4637-95a2-b1314c8cc279,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-3509b718-d6d8-457b-a433-e50615459b4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-87602325-172.17.0.11-1595843183871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39567,DS-f53a3e1a-0688-47da-a8de-7a35cafbba24,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-6de40fca-100b-4d9e-a98b-47ea69ca75ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-c1fdbb66-73f1-4111-ba7e-d40def4aecfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-93f1d648-e74d-4758-b465-97943822071e,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-e5e215f6-ee35-409d-8908-98d059676cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-4d8cef0b-1edb-4e5b-994c-35eeeb74977e,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-66317654-7488-4637-95a2-b1314c8cc279,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-3509b718-d6d8-457b-a433-e50615459b4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 1000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-5261882-172.17.0.11-1595843699539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37248,DS-626c1b59-515c-407c-838e-fc79fe0190db,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-8e1d67c5-bb9f-4eb5-8f64-d7abef2c8be9,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-9e567f67-23a0-4587-a88d-d15787dfc08e,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-082fb1ea-5a2a-4b28-aacd-4707517e2fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-499c7bbc-0168-48b6-9410-d33dec023190,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-e6ce60e3-6db8-4983-af22-f587e984a5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37876,DS-1b380557-d36b-4547-b6e5-56ebe0154965,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-0a1a426b-56bc-4e67-b291-24bb7826648e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-5261882-172.17.0.11-1595843699539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37248,DS-626c1b59-515c-407c-838e-fc79fe0190db,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-8e1d67c5-bb9f-4eb5-8f64-d7abef2c8be9,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-9e567f67-23a0-4587-a88d-d15787dfc08e,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-082fb1ea-5a2a-4b28-aacd-4707517e2fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-499c7bbc-0168-48b6-9410-d33dec023190,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-e6ce60e3-6db8-4983-af22-f587e984a5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37876,DS-1b380557-d36b-4547-b6e5-56ebe0154965,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-0a1a426b-56bc-4e67-b291-24bb7826648e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 1000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1251941272-172.17.0.11-1595843761160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40354,DS-81e3edda-ad5f-4a74-b499-73183962ffe4,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-009d2cd4-8118-4936-8bf2-9000aed853cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-149e756d-75c0-4ac9-83c0-1ea391a5a843,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-3bce071e-141f-49d0-ab42-58eb188c505d,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-35f344e8-12ea-43fa-b1f0-79be0171f013,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-4498b7f0-e36e-4f9f-ba6c-ff4e8589a77b,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-c662ec1c-da04-47b9-818c-8f386872d8be,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-e4d3c17f-ff1a-4259-ab84-5fec9cbcb3be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1251941272-172.17.0.11-1595843761160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40354,DS-81e3edda-ad5f-4a74-b499-73183962ffe4,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-009d2cd4-8118-4936-8bf2-9000aed853cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-149e756d-75c0-4ac9-83c0-1ea391a5a843,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-3bce071e-141f-49d0-ab42-58eb188c505d,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-35f344e8-12ea-43fa-b1f0-79be0171f013,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-4498b7f0-e36e-4f9f-ba6c-ff4e8589a77b,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-c662ec1c-da04-47b9-818c-8f386872d8be,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-e4d3c17f-ff1a-4259-ab84-5fec9cbcb3be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 1000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1898294287-172.17.0.11-1595844409432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46446,DS-2638e7d0-fe6e-4fc6-9a4d-2be157bdcdfa,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-2dfca1b2-8f78-4321-813c-47b4b5708103,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-4fa39ce9-4b54-4046-9edb-f51e3cc67110,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-d86604e8-3f50-45bb-a90e-5987edc38be8,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-1cdf6934-9099-4a5d-8112-d001969c719d,DISK], DatanodeInfoWithStorage[127.0.0.1:37167,DS-18a463b4-22d9-4281-bd4f-45526abf5679,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-ee09d81c-aca6-4235-bedb-56485f036ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-010a4359-4b6e-4d54-8126-90b98aaa7145,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1898294287-172.17.0.11-1595844409432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46446,DS-2638e7d0-fe6e-4fc6-9a4d-2be157bdcdfa,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-2dfca1b2-8f78-4321-813c-47b4b5708103,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-4fa39ce9-4b54-4046-9edb-f51e3cc67110,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-d86604e8-3f50-45bb-a90e-5987edc38be8,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-1cdf6934-9099-4a5d-8112-d001969c719d,DISK], DatanodeInfoWithStorage[127.0.0.1:37167,DS-18a463b4-22d9-4281-bd4f-45526abf5679,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-ee09d81c-aca6-4235-bedb-56485f036ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-010a4359-4b6e-4d54-8126-90b98aaa7145,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 1000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553947053-172.17.0.11-1595844676545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33611,DS-a8c27ff7-e2ff-446b-9408-2d28323902e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-345a82f2-7b24-421b-9ea2-2f4cbc006e45,DISK], DatanodeInfoWithStorage[127.0.0.1:45992,DS-86a44ef6-f2af-44f8-8273-c7cb38192a27,DISK], DatanodeInfoWithStorage[127.0.0.1:42037,DS-90a66f7d-0986-4b49-ac00-1257f07dfe2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-79b4eb9d-2ebc-4ce2-b54f-52f863691031,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-8dfb1471-e7b2-4fc4-a1c1-d9d3c8e9f462,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-f8b8d867-4465-4687-94e8-1fda774c03cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-3b48d7d9-02ed-425c-ba0d-67e43b190950,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553947053-172.17.0.11-1595844676545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33611,DS-a8c27ff7-e2ff-446b-9408-2d28323902e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-345a82f2-7b24-421b-9ea2-2f4cbc006e45,DISK], DatanodeInfoWithStorage[127.0.0.1:45992,DS-86a44ef6-f2af-44f8-8273-c7cb38192a27,DISK], DatanodeInfoWithStorage[127.0.0.1:42037,DS-90a66f7d-0986-4b49-ac00-1257f07dfe2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-79b4eb9d-2ebc-4ce2-b54f-52f863691031,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-8dfb1471-e7b2-4fc4-a1c1-d9d3c8e9f462,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-f8b8d867-4465-4687-94e8-1fda774c03cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-3b48d7d9-02ed-425c-ba0d-67e43b190950,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5126
