reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2135596638-172.17.0.10-1595931537218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43548,DS-cdff864f-cfff-45d1-a55d-3887a12646b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-864600f6-7425-4854-a37d-603706ecf9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45798,DS-ca9bd313-eda5-4668-ad74-0e564089f6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-91dcef9c-3b87-45c6-b039-d6b62b65633b,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-fc0562dc-7734-4d3f-a2d0-2bbaa537eae8,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-9e114891-9ad4-4d22-8fad-d36aa374bb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-df6a306e-4cbf-4f08-a2f7-2824111b155b,DISK], DatanodeInfoWithStorage[127.0.0.1:38671,DS-d47efe39-6c60-4a53-96aa-1a1775fc63ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2135596638-172.17.0.10-1595931537218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43548,DS-cdff864f-cfff-45d1-a55d-3887a12646b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-864600f6-7425-4854-a37d-603706ecf9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45798,DS-ca9bd313-eda5-4668-ad74-0e564089f6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-91dcef9c-3b87-45c6-b039-d6b62b65633b,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-fc0562dc-7734-4d3f-a2d0-2bbaa537eae8,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-9e114891-9ad4-4d22-8fad-d36aa374bb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-df6a306e-4cbf-4f08-a2f7-2824111b155b,DISK], DatanodeInfoWithStorage[127.0.0.1:38671,DS-d47efe39-6c60-4a53-96aa-1a1775fc63ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-505933191-172.17.0.10-1595931680470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40751,DS-cddf01e5-8c59-46fd-a021-08f48895e046,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-f71c44cf-6bf7-4b41-a014-f63723b036b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33620,DS-dac8847a-c6bf-4775-9b6f-2ed0ea714802,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-3d23c363-cbcc-483e-801d-8b16757f3e69,DISK], DatanodeInfoWithStorage[127.0.0.1:44708,DS-8d8885d3-d5a4-473a-b3dc-514095b33986,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-4068b1ab-af29-4a77-8757-f2579d2566be,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-5edc4e1f-9156-41fc-947e-43718f7edd16,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-1843d678-526e-4a02-b3dd-9d7d05042b33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-505933191-172.17.0.10-1595931680470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40751,DS-cddf01e5-8c59-46fd-a021-08f48895e046,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-f71c44cf-6bf7-4b41-a014-f63723b036b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33620,DS-dac8847a-c6bf-4775-9b6f-2ed0ea714802,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-3d23c363-cbcc-483e-801d-8b16757f3e69,DISK], DatanodeInfoWithStorage[127.0.0.1:44708,DS-8d8885d3-d5a4-473a-b3dc-514095b33986,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-4068b1ab-af29-4a77-8757-f2579d2566be,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-5edc4e1f-9156-41fc-947e-43718f7edd16,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-1843d678-526e-4a02-b3dd-9d7d05042b33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851843337-172.17.0.10-1595932725110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40373,DS-906cd8c1-5bca-423a-aa5c-6a19580957bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-ff331120-3e54-4087-9893-4656735d8062,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-97ec9d9e-c015-496b-9f5f-4310ed27ebef,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-7117fe6d-a448-47e7-8c33-153dd219e33b,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-dd3ecceb-111a-4a43-b78a-67721c84c797,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-1c538e43-f2ba-4b42-b1b3-c8e379d81ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-6390c673-0385-4b34-a4ac-1dd6fd9c91ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-4753652f-37e8-4965-b47a-aa7201522104,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851843337-172.17.0.10-1595932725110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40373,DS-906cd8c1-5bca-423a-aa5c-6a19580957bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-ff331120-3e54-4087-9893-4656735d8062,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-97ec9d9e-c015-496b-9f5f-4310ed27ebef,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-7117fe6d-a448-47e7-8c33-153dd219e33b,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-dd3ecceb-111a-4a43-b78a-67721c84c797,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-1c538e43-f2ba-4b42-b1b3-c8e379d81ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-6390c673-0385-4b34-a4ac-1dd6fd9c91ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-4753652f-37e8-4965-b47a-aa7201522104,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-639178376-172.17.0.10-1595932764826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33117,DS-cd4360d9-c4f0-4392-9581-eebeffac79f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45287,DS-6cacc5d0-3c44-4688-ae9d-3a122b3d575d,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-4671a51c-25c5-4dc3-9ad6-2d6b01834ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-068b22b3-92a3-433c-8111-bbfdbcd6b616,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-5a370721-b0d7-4f6d-8d28-84515a30f550,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-5c2bb1e8-9b06-4080-9d25-93c0df0a2760,DISK], DatanodeInfoWithStorage[127.0.0.1:42571,DS-1351db2c-67e3-4b13-8bf4-7e246da0eb27,DISK], DatanodeInfoWithStorage[127.0.0.1:36088,DS-7b4b6390-4fc8-4019-9472-3e18925ae2ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-639178376-172.17.0.10-1595932764826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33117,DS-cd4360d9-c4f0-4392-9581-eebeffac79f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45287,DS-6cacc5d0-3c44-4688-ae9d-3a122b3d575d,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-4671a51c-25c5-4dc3-9ad6-2d6b01834ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-068b22b3-92a3-433c-8111-bbfdbcd6b616,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-5a370721-b0d7-4f6d-8d28-84515a30f550,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-5c2bb1e8-9b06-4080-9d25-93c0df0a2760,DISK], DatanodeInfoWithStorage[127.0.0.1:42571,DS-1351db2c-67e3-4b13-8bf4-7e246da0eb27,DISK], DatanodeInfoWithStorage[127.0.0.1:36088,DS-7b4b6390-4fc8-4019-9472-3e18925ae2ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1011630191-172.17.0.10-1595933313849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39295,DS-58413fba-d781-4700-b690-3832f4b9a272,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-c7428657-0762-4f31-94ce-093700db799d,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-293c6f0e-f876-4afd-9173-a2c8e66090e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40112,DS-8ea5cc30-fd98-4b81-8b74-38e683617f84,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-b543f94b-7918-4047-aabf-3d441dffb93a,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-b6641133-10c4-4b39-94a9-ac9364f61a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41146,DS-d62565f6-9528-47ea-8402-531a439606d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-da5854c0-a5b5-4f0c-bb22-0fda75821b00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1011630191-172.17.0.10-1595933313849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39295,DS-58413fba-d781-4700-b690-3832f4b9a272,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-c7428657-0762-4f31-94ce-093700db799d,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-293c6f0e-f876-4afd-9173-a2c8e66090e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40112,DS-8ea5cc30-fd98-4b81-8b74-38e683617f84,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-b543f94b-7918-4047-aabf-3d441dffb93a,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-b6641133-10c4-4b39-94a9-ac9364f61a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41146,DS-d62565f6-9528-47ea-8402-531a439606d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-da5854c0-a5b5-4f0c-bb22-0fda75821b00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1135115978-172.17.0.10-1595933352025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35018,DS-7accf2dc-da84-4ce6-8a0e-de896c69a83d,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-79dc7ce2-b079-4375-bce1-fc94abe3b27b,DISK], DatanodeInfoWithStorage[127.0.0.1:44243,DS-2510f30c-19f4-42c4-944b-442b5e937790,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-5a08831f-3fef-4c98-8115-3f9f088e3161,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-1f46de4e-0ba7-4e98-97b4-9ca1e0bf126a,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-96f0e199-07e3-4e1b-8e1d-a073bbe83150,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-951bd935-d3d2-4ba8-8832-16c00667b9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-b0488abd-2025-42c8-96ee-eb799e0c6e1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1135115978-172.17.0.10-1595933352025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35018,DS-7accf2dc-da84-4ce6-8a0e-de896c69a83d,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-79dc7ce2-b079-4375-bce1-fc94abe3b27b,DISK], DatanodeInfoWithStorage[127.0.0.1:44243,DS-2510f30c-19f4-42c4-944b-442b5e937790,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-5a08831f-3fef-4c98-8115-3f9f088e3161,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-1f46de4e-0ba7-4e98-97b4-9ca1e0bf126a,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-96f0e199-07e3-4e1b-8e1d-a073bbe83150,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-951bd935-d3d2-4ba8-8832-16c00667b9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-b0488abd-2025-42c8-96ee-eb799e0c6e1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-794543028-172.17.0.10-1595933388317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46383,DS-146b0cca-e5d9-4e5d-8f56-1498c8a8441b,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-eafd7215-e36d-4c77-8adc-756e926b98be,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-7fcd8e75-b2b0-4a96-87bd-35beed866753,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-b42210f6-97d6-4818-8e0c-0a19ed0068ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-82fcfb40-0cdc-466d-abb7-67f2db55a241,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-9fd6507f-6fe3-4670-a97c-444fce2a9965,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-fd77a635-be61-483f-ae76-4bf4e2e04aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36880,DS-ecfecd40-333c-4e48-988d-48de322a6bbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-794543028-172.17.0.10-1595933388317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46383,DS-146b0cca-e5d9-4e5d-8f56-1498c8a8441b,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-eafd7215-e36d-4c77-8adc-756e926b98be,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-7fcd8e75-b2b0-4a96-87bd-35beed866753,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-b42210f6-97d6-4818-8e0c-0a19ed0068ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-82fcfb40-0cdc-466d-abb7-67f2db55a241,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-9fd6507f-6fe3-4670-a97c-444fce2a9965,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-fd77a635-be61-483f-ae76-4bf4e2e04aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36880,DS-ecfecd40-333c-4e48-988d-48de322a6bbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1291326892-172.17.0.10-1595933686237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37429,DS-e99dbb6e-9f23-46cf-8916-90f8112a3b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-34185bbe-8c64-4218-8f5b-f278760ac35e,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-b8c958ef-040d-4cf6-892f-46452c77496b,DISK], DatanodeInfoWithStorage[127.0.0.1:38589,DS-7485d190-95dc-4ea5-b464-46c0bb36120b,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-f43e5b3a-31ac-4eee-977f-3e384b255718,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-d5860932-d252-4b0b-a835-f40b387c2ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:44747,DS-da34cafa-441d-45ef-bcd1-99abc1c0548c,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-492fd271-ad9a-4af2-acf2-c840e7a5a559,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1291326892-172.17.0.10-1595933686237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37429,DS-e99dbb6e-9f23-46cf-8916-90f8112a3b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-34185bbe-8c64-4218-8f5b-f278760ac35e,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-b8c958ef-040d-4cf6-892f-46452c77496b,DISK], DatanodeInfoWithStorage[127.0.0.1:38589,DS-7485d190-95dc-4ea5-b464-46c0bb36120b,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-f43e5b3a-31ac-4eee-977f-3e384b255718,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-d5860932-d252-4b0b-a835-f40b387c2ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:44747,DS-da34cafa-441d-45ef-bcd1-99abc1c0548c,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-492fd271-ad9a-4af2-acf2-c840e7a5a559,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1517540016-172.17.0.10-1595933726015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35218,DS-7d0ba190-36de-4b7e-b0ff-5c30cc957a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38467,DS-82eaa081-a2b1-4d17-be78-dbd33167b8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-8d6bbf3f-f9b1-4253-af9b-d13757221d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-bd86b2aa-bfe6-467a-bc89-1d261d15c3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-2736d98d-e47d-43d0-ac4b-6b15569bd09f,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-12d2e544-c513-4621-8dcf-200ce50ca19b,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-1625e7bc-c3be-4b98-9aec-ef1b60d1eb51,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-2d6d3e77-e20f-4e4a-81cf-dea80cdb3fe4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1517540016-172.17.0.10-1595933726015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35218,DS-7d0ba190-36de-4b7e-b0ff-5c30cc957a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38467,DS-82eaa081-a2b1-4d17-be78-dbd33167b8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-8d6bbf3f-f9b1-4253-af9b-d13757221d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-bd86b2aa-bfe6-467a-bc89-1d261d15c3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-2736d98d-e47d-43d0-ac4b-6b15569bd09f,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-12d2e544-c513-4621-8dcf-200ce50ca19b,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-1625e7bc-c3be-4b98-9aec-ef1b60d1eb51,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-2d6d3e77-e20f-4e4a-81cf-dea80cdb3fe4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-988090997-172.17.0.10-1595933896717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38933,DS-9470adec-7ad6-4578-9587-d2fec1313168,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-4dc65b2e-71f3-41c4-a1ab-29d85fa80277,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-758380f4-29d7-4a56-bfde-9a92ae272f87,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-03fa0a4e-5427-440d-bb34-aac9ff7254c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-b3ece168-1b03-44ad-bcfa-9051fe2e0113,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-0978962e-97bb-4b94-9d83-ee99c2c4b115,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-35d2577d-fd20-4a64-a574-bf24684b9ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-aa06b5e8-6015-4d82-afe6-680d8efba076,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-988090997-172.17.0.10-1595933896717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38933,DS-9470adec-7ad6-4578-9587-d2fec1313168,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-4dc65b2e-71f3-41c4-a1ab-29d85fa80277,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-758380f4-29d7-4a56-bfde-9a92ae272f87,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-03fa0a4e-5427-440d-bb34-aac9ff7254c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-b3ece168-1b03-44ad-bcfa-9051fe2e0113,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-0978962e-97bb-4b94-9d83-ee99c2c4b115,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-35d2577d-fd20-4a64-a574-bf24684b9ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-aa06b5e8-6015-4d82-afe6-680d8efba076,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-274246379-172.17.0.10-1595934250763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44846,DS-6104794a-e71b-495d-ab3c-d5c615138889,DISK], DatanodeInfoWithStorage[127.0.0.1:34214,DS-3f12baa8-af59-4597-8736-53e7470d6295,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-95d60277-582c-4734-9f54-11809867d043,DISK], DatanodeInfoWithStorage[127.0.0.1:35789,DS-01626f2e-16cf-4783-a695-ab47061b7730,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-f83ae291-6bcb-45c3-bc1b-562c89781405,DISK], DatanodeInfoWithStorage[127.0.0.1:44201,DS-16199813-3629-4960-8446-6dbd4d7328b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-310a36be-1ae0-468d-8811-463f2f46c3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-b0a5d1a7-8cc8-413c-9db4-e240d996d6e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-274246379-172.17.0.10-1595934250763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44846,DS-6104794a-e71b-495d-ab3c-d5c615138889,DISK], DatanodeInfoWithStorage[127.0.0.1:34214,DS-3f12baa8-af59-4597-8736-53e7470d6295,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-95d60277-582c-4734-9f54-11809867d043,DISK], DatanodeInfoWithStorage[127.0.0.1:35789,DS-01626f2e-16cf-4783-a695-ab47061b7730,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-f83ae291-6bcb-45c3-bc1b-562c89781405,DISK], DatanodeInfoWithStorage[127.0.0.1:44201,DS-16199813-3629-4960-8446-6dbd4d7328b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-310a36be-1ae0-468d-8811-463f2f46c3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-b0a5d1a7-8cc8-413c-9db4-e240d996d6e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1969520639-172.17.0.10-1595934469047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41545,DS-ad70a50d-4a08-4372-bb5d-cfb42b28bccb,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-433606a8-e921-452d-8991-2ad014cc89de,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-c40be9a9-7af0-4997-9ce0-c2dc0b61ca44,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-3ba9893b-e30b-4675-936a-4aab66762ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:34601,DS-0ec4ced5-ccc8-4a21-a291-b7b2e11e9994,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-dc05ff74-7b32-4150-932f-47ad4ceb9923,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-83f82059-98d5-4665-b413-3e1740afa521,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-e9c519d6-d0b8-44bb-bdf2-fcb01f801872,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1969520639-172.17.0.10-1595934469047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41545,DS-ad70a50d-4a08-4372-bb5d-cfb42b28bccb,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-433606a8-e921-452d-8991-2ad014cc89de,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-c40be9a9-7af0-4997-9ce0-c2dc0b61ca44,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-3ba9893b-e30b-4675-936a-4aab66762ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:34601,DS-0ec4ced5-ccc8-4a21-a291-b7b2e11e9994,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-dc05ff74-7b32-4150-932f-47ad4ceb9923,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-83f82059-98d5-4665-b413-3e1740afa521,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-e9c519d6-d0b8-44bb-bdf2-fcb01f801872,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1026934990-172.17.0.10-1595934770769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44313,DS-799845e8-0722-4a5a-8cae-c017c0428865,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-cd444afb-1a50-4929-9dd5-ce66a4e4119d,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-0e265cc3-202f-441f-b643-5a0ec970e0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-6ff33f2f-ad36-4eb5-b245-bc92472cc5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-a9b017ad-56fc-4494-a140-e06972e11b13,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-6c59b5fa-8bed-4c61-8f65-25c24d4f4969,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-140c19bf-27cf-447d-b989-d78fb565b674,DISK], DatanodeInfoWithStorage[127.0.0.1:37131,DS-bca7b8a2-9999-457c-8a76-a82c5c41bd95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1026934990-172.17.0.10-1595934770769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44313,DS-799845e8-0722-4a5a-8cae-c017c0428865,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-cd444afb-1a50-4929-9dd5-ce66a4e4119d,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-0e265cc3-202f-441f-b643-5a0ec970e0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-6ff33f2f-ad36-4eb5-b245-bc92472cc5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-a9b017ad-56fc-4494-a140-e06972e11b13,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-6c59b5fa-8bed-4c61-8f65-25c24d4f4969,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-140c19bf-27cf-447d-b989-d78fb565b674,DISK], DatanodeInfoWithStorage[127.0.0.1:37131,DS-bca7b8a2-9999-457c-8a76-a82c5c41bd95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-920213585-172.17.0.10-1595934852341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41959,DS-fd6f13aa-1470-4cb9-bbb8-5791f0beb72e,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-94450089-763a-4c74-9176-3e7a6d5fc7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-56b86da9-e168-4506-92cb-805d0cb897dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-d69d38cd-5640-4de2-90f4-925f7536c05a,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-92494d27-4366-49b2-aefe-56305552a0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-cb0cde2e-3f41-42e5-a6c2-8994f508237f,DISK], DatanodeInfoWithStorage[127.0.0.1:38087,DS-4b30c8f4-5a77-4f92-a02d-8a4439b5c090,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-22105c11-82f4-4f77-b9e9-4738777d778d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-920213585-172.17.0.10-1595934852341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41959,DS-fd6f13aa-1470-4cb9-bbb8-5791f0beb72e,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-94450089-763a-4c74-9176-3e7a6d5fc7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-56b86da9-e168-4506-92cb-805d0cb897dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-d69d38cd-5640-4de2-90f4-925f7536c05a,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-92494d27-4366-49b2-aefe-56305552a0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-cb0cde2e-3f41-42e5-a6c2-8994f508237f,DISK], DatanodeInfoWithStorage[127.0.0.1:38087,DS-4b30c8f4-5a77-4f92-a02d-8a4439b5c090,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-22105c11-82f4-4f77-b9e9-4738777d778d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-464850527-172.17.0.10-1595935000986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39744,DS-d3a9a802-6464-4c62-9d53-ebab39e5ed23,DISK], DatanodeInfoWithStorage[127.0.0.1:45692,DS-91abfd49-f4d4-410f-b93d-c4eb0fe9c977,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-42c93f1d-887e-4756-8b98-87ae1951edab,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-cb426fb2-367d-4736-975d-acc79402a509,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-5e1510a6-9359-4ac3-99ee-3bd3a834964a,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-3d252219-052e-4654-bd07-e4bad1b6790f,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-a35e4662-2c37-46e6-8559-46d05ec357eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-6d83b142-59a3-4cb5-ad06-4acd73e58900,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-464850527-172.17.0.10-1595935000986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39744,DS-d3a9a802-6464-4c62-9d53-ebab39e5ed23,DISK], DatanodeInfoWithStorage[127.0.0.1:45692,DS-91abfd49-f4d4-410f-b93d-c4eb0fe9c977,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-42c93f1d-887e-4756-8b98-87ae1951edab,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-cb426fb2-367d-4736-975d-acc79402a509,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-5e1510a6-9359-4ac3-99ee-3bd3a834964a,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-3d252219-052e-4654-bd07-e4bad1b6790f,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-a35e4662-2c37-46e6-8559-46d05ec357eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-6d83b142-59a3-4cb5-ad06-4acd73e58900,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1983692249-172.17.0.10-1595935224298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35013,DS-15a239c8-3696-410b-a471-71f461a95c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-7476d5b4-9855-4232-a3c1-18394d92f989,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-2b984a03-5884-416e-800b-9b0a2e38cdb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-cad099b0-4204-484e-b0c5-39218469ae49,DISK], DatanodeInfoWithStorage[127.0.0.1:39798,DS-7608d857-368a-40c4-8659-4c29380a47d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-5a55a1de-d498-4372-9615-b53375ebfe50,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-d062e70a-d097-4d06-9486-a3346afab863,DISK], DatanodeInfoWithStorage[127.0.0.1:41349,DS-7d287b0a-db60-48c7-bca9-5e2726734d84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1983692249-172.17.0.10-1595935224298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35013,DS-15a239c8-3696-410b-a471-71f461a95c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-7476d5b4-9855-4232-a3c1-18394d92f989,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-2b984a03-5884-416e-800b-9b0a2e38cdb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-cad099b0-4204-484e-b0c5-39218469ae49,DISK], DatanodeInfoWithStorage[127.0.0.1:39798,DS-7608d857-368a-40c4-8659-4c29380a47d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-5a55a1de-d498-4372-9615-b53375ebfe50,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-d062e70a-d097-4d06-9486-a3346afab863,DISK], DatanodeInfoWithStorage[127.0.0.1:41349,DS-7d287b0a-db60-48c7-bca9-5e2726734d84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-311603492-172.17.0.10-1595935493981:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39464,DS-d66cf2a3-d5c0-415d-9b00-85745ee2af1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-f2b33327-0ac4-4867-ac73-95231cfb89ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-7ccef7c3-c6e5-4526-a58f-79f6ecb7e725,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-153fd749-c7bb-4cc1-937e-e570c974b36a,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-8752e46a-7fca-4288-9f65-2086ec6f548c,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-11b132a0-20a7-451f-8b31-2c149ae1ab43,DISK], DatanodeInfoWithStorage[127.0.0.1:40470,DS-ac04fa95-f49c-49ff-92b8-37401fe86655,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-9a6fef41-b511-4758-839b-0f351ab8c072,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-311603492-172.17.0.10-1595935493981:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39464,DS-d66cf2a3-d5c0-415d-9b00-85745ee2af1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-f2b33327-0ac4-4867-ac73-95231cfb89ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-7ccef7c3-c6e5-4526-a58f-79f6ecb7e725,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-153fd749-c7bb-4cc1-937e-e570c974b36a,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-8752e46a-7fca-4288-9f65-2086ec6f548c,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-11b132a0-20a7-451f-8b31-2c149ae1ab43,DISK], DatanodeInfoWithStorage[127.0.0.1:40470,DS-ac04fa95-f49c-49ff-92b8-37401fe86655,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-9a6fef41-b511-4758-839b-0f351ab8c072,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1810689419-172.17.0.10-1595935723451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38487,DS-4e678245-486c-4071-859e-be4ea61e875f,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-0e3d6418-6848-4d7a-81a2-6f2d2e21594c,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-b8660735-32d4-4413-83c0-04ce592d4343,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-df0eb64e-cb29-41c1-add5-e0740c8c3ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-1c12c90f-b585-4ac3-93f8-d7354943dee6,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-6d34db4a-8050-4bff-951b-1e7b5ab070c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36475,DS-454a6103-fcdb-4d42-8fa2-da7f6eeaf296,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-60f428bf-2d09-47da-85b8-389ab4171da4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1810689419-172.17.0.10-1595935723451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38487,DS-4e678245-486c-4071-859e-be4ea61e875f,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-0e3d6418-6848-4d7a-81a2-6f2d2e21594c,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-b8660735-32d4-4413-83c0-04ce592d4343,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-df0eb64e-cb29-41c1-add5-e0740c8c3ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-1c12c90f-b585-4ac3-93f8-d7354943dee6,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-6d34db4a-8050-4bff-951b-1e7b5ab070c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36475,DS-454a6103-fcdb-4d42-8fa2-da7f6eeaf296,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-60f428bf-2d09-47da-85b8-389ab4171da4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-450365582-172.17.0.10-1595935764754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45954,DS-593c5d3f-c747-4c9e-9b7f-50696674a044,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-c7dc720d-b102-4564-ab56-94698e6feecb,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-26e23fb8-bfd2-4e01-8c6f-efe81f599278,DISK], DatanodeInfoWithStorage[127.0.0.1:40623,DS-f78fb0a4-4171-4cb0-af99-75aead4cc126,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-6c490d71-5dfc-4908-b3f4-743717463654,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-65263ea6-40e2-405e-8266-a7bdeaf686e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-f314ec3f-e20c-4bfe-95df-0c8c1e8fcac8,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-3be3bbde-dfd5-403d-8c37-84f7979607b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-450365582-172.17.0.10-1595935764754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45954,DS-593c5d3f-c747-4c9e-9b7f-50696674a044,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-c7dc720d-b102-4564-ab56-94698e6feecb,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-26e23fb8-bfd2-4e01-8c6f-efe81f599278,DISK], DatanodeInfoWithStorage[127.0.0.1:40623,DS-f78fb0a4-4171-4cb0-af99-75aead4cc126,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-6c490d71-5dfc-4908-b3f4-743717463654,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-65263ea6-40e2-405e-8266-a7bdeaf686e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-f314ec3f-e20c-4bfe-95df-0c8c1e8fcac8,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-3be3bbde-dfd5-403d-8c37-84f7979607b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1759570911-172.17.0.10-1595935830406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44124,DS-b3ba621b-561a-4a9d-8e09-ddf6d5897904,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-9deabd77-477d-442e-9234-d520781477a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-b3d8dcee-481a-4048-99f3-509e54713637,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-6aa877c9-1c97-4ac4-9915-7458e2d39d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-78bb02fa-794b-40e5-8f55-fd640218362f,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-9e02fb29-5a62-4b53-92a1-71e2d128d8df,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-6815e1e1-3949-4999-9fcd-6eb5344e5a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40833,DS-c5888cc4-92b4-4582-aff7-a9936c77dc45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1759570911-172.17.0.10-1595935830406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44124,DS-b3ba621b-561a-4a9d-8e09-ddf6d5897904,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-9deabd77-477d-442e-9234-d520781477a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-b3d8dcee-481a-4048-99f3-509e54713637,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-6aa877c9-1c97-4ac4-9915-7458e2d39d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-78bb02fa-794b-40e5-8f55-fd640218362f,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-9e02fb29-5a62-4b53-92a1-71e2d128d8df,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-6815e1e1-3949-4999-9fcd-6eb5344e5a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40833,DS-c5888cc4-92b4-4582-aff7-a9936c77dc45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-935907048-172.17.0.10-1595935907752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34146,DS-1571f77a-95e0-492a-b780-3897a69255a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38240,DS-9597859e-27bb-4ad5-a22c-521c7f4f3dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-d69fd6ff-d80e-487f-b9a4-97f1d7dbcbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-e5fc3dad-ec3a-46b2-b3d4-1864f120e070,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-387e24d0-5eb4-41b5-a78c-8e463d5b2806,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-b2c967a7-dbf5-482a-b53f-735cb8ba5560,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-45d7210a-48f4-48ed-9831-233207c6699f,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-4e494edd-c5ca-4d80-9a90-708fc55a56d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-935907048-172.17.0.10-1595935907752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34146,DS-1571f77a-95e0-492a-b780-3897a69255a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38240,DS-9597859e-27bb-4ad5-a22c-521c7f4f3dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-d69fd6ff-d80e-487f-b9a4-97f1d7dbcbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-e5fc3dad-ec3a-46b2-b3d4-1864f120e070,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-387e24d0-5eb4-41b5-a78c-8e463d5b2806,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-b2c967a7-dbf5-482a-b53f-735cb8ba5560,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-45d7210a-48f4-48ed-9831-233207c6699f,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-4e494edd-c5ca-4d80-9a90-708fc55a56d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1335698967-172.17.0.10-1595936112221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33306,DS-34e4d327-8d7e-4ba6-9e56-f154026eaacc,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-ccf719ad-9258-4256-8fd2-202552144e23,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-000f6e91-9796-48a1-ad4b-2fea15c2f90c,DISK], DatanodeInfoWithStorage[127.0.0.1:39221,DS-37ebc054-628c-47ba-9a06-72d50021a950,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-6a651bc7-14b2-4da3-87e4-1cbbf1cdebb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-28dfc069-964c-4698-8bf1-f4d2320af7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-7f63c966-c50c-4d6d-a7eb-3a3038e59e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-599b702e-a578-426d-b2d2-70a09af1f978,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1335698967-172.17.0.10-1595936112221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33306,DS-34e4d327-8d7e-4ba6-9e56-f154026eaacc,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-ccf719ad-9258-4256-8fd2-202552144e23,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-000f6e91-9796-48a1-ad4b-2fea15c2f90c,DISK], DatanodeInfoWithStorage[127.0.0.1:39221,DS-37ebc054-628c-47ba-9a06-72d50021a950,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-6a651bc7-14b2-4da3-87e4-1cbbf1cdebb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-28dfc069-964c-4698-8bf1-f4d2320af7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-7f63c966-c50c-4d6d-a7eb-3a3038e59e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-599b702e-a578-426d-b2d2-70a09af1f978,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5466
