reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-338068489-172.17.0.7-1595974751411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42642,DS-916ce5a2-480b-4d8e-ba01-97083a68a335,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-1fa7ec7b-a186-4746-abcc-856982506348,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-a0d67672-b960-443d-ab76-ad71e2ef2002,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-cc81caba-921a-4edb-ada4-e8d6838b0e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45100,DS-7f712b5a-408d-4a64-81f6-2d3892f7be49,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-af9f318f-b0e5-4b94-84dc-9bfe4dd1c493,DISK], DatanodeInfoWithStorage[127.0.0.1:45395,DS-206526f3-bc63-4a13-b1e3-062f030ee5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-c571950d-ee25-4682-bb6f-99be62363912,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-338068489-172.17.0.7-1595974751411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42642,DS-916ce5a2-480b-4d8e-ba01-97083a68a335,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-1fa7ec7b-a186-4746-abcc-856982506348,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-a0d67672-b960-443d-ab76-ad71e2ef2002,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-cc81caba-921a-4edb-ada4-e8d6838b0e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45100,DS-7f712b5a-408d-4a64-81f6-2d3892f7be49,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-af9f318f-b0e5-4b94-84dc-9bfe4dd1c493,DISK], DatanodeInfoWithStorage[127.0.0.1:45395,DS-206526f3-bc63-4a13-b1e3-062f030ee5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-c571950d-ee25-4682-bb6f-99be62363912,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-720950255-172.17.0.7-1595974899629:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44691,DS-04a9df4f-aa7b-4185-9d8a-793ea676293f,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-5c44d66b-d8be-4261-8688-a9079bc65903,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-4b376c82-1757-41de-9584-9c2a71c75d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-57ccb4ca-17d3-440a-889d-74a8ccac3734,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-7a527ee1-827f-4c59-89f5-b20146037377,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-b6032d42-2f94-4811-8c16-03b8b5e31f30,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-5a0e4ee3-f51d-4de6-aac7-f049fb96cab3,DISK], DatanodeInfoWithStorage[127.0.0.1:44541,DS-82e90605-d3a6-40dc-a85e-e8c883411177,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-720950255-172.17.0.7-1595974899629:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44691,DS-04a9df4f-aa7b-4185-9d8a-793ea676293f,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-5c44d66b-d8be-4261-8688-a9079bc65903,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-4b376c82-1757-41de-9584-9c2a71c75d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-57ccb4ca-17d3-440a-889d-74a8ccac3734,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-7a527ee1-827f-4c59-89f5-b20146037377,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-b6032d42-2f94-4811-8c16-03b8b5e31f30,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-5a0e4ee3-f51d-4de6-aac7-f049fb96cab3,DISK], DatanodeInfoWithStorage[127.0.0.1:44541,DS-82e90605-d3a6-40dc-a85e-e8c883411177,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1817086483-172.17.0.7-1595975224087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38071,DS-440f18e1-88d9-4f83-94be-5b33de1c0628,DISK], DatanodeInfoWithStorage[127.0.0.1:37021,DS-22eefc66-f300-4661-917b-92ab0eac748c,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-9d36843a-06a3-41ff-bd99-f19593a26dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-ec6e610e-8b57-447f-aecb-3fcebb6ab7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-88414e48-a43f-4df1-a3d6-353320356b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-e850c664-d22b-4cec-a9d4-18f8ed5302de,DISK], DatanodeInfoWithStorage[127.0.0.1:34900,DS-4e6b57d0-1465-4197-aa85-25698b0c2eac,DISK], DatanodeInfoWithStorage[127.0.0.1:33817,DS-9f6c0fca-7064-48f3-b475-a74191d99c94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1817086483-172.17.0.7-1595975224087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38071,DS-440f18e1-88d9-4f83-94be-5b33de1c0628,DISK], DatanodeInfoWithStorage[127.0.0.1:37021,DS-22eefc66-f300-4661-917b-92ab0eac748c,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-9d36843a-06a3-41ff-bd99-f19593a26dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-ec6e610e-8b57-447f-aecb-3fcebb6ab7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-88414e48-a43f-4df1-a3d6-353320356b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-e850c664-d22b-4cec-a9d4-18f8ed5302de,DISK], DatanodeInfoWithStorage[127.0.0.1:34900,DS-4e6b57d0-1465-4197-aa85-25698b0c2eac,DISK], DatanodeInfoWithStorage[127.0.0.1:33817,DS-9f6c0fca-7064-48f3-b475-a74191d99c94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-434997262-172.17.0.7-1595975338706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35254,DS-9b82c312-ae70-4168-8b12-b7b5d5d665e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-72d0ca85-b330-45d9-a5f0-51333a8382e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-40562623-569d-4b57-8603-ae50c07b79d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-4eb8deab-0ef1-41ae-a7e4-964a089b50e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44305,DS-eaf210f8-07e7-4cae-a7da-4c1567af05dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-5d2f2e4a-ec82-46fe-ba95-4fc988ef66df,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-bb2a049a-63dc-4aa3-a022-f6aff86d4f29,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-8a526705-93cc-4743-8656-3cc73cca8822,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-434997262-172.17.0.7-1595975338706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35254,DS-9b82c312-ae70-4168-8b12-b7b5d5d665e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-72d0ca85-b330-45d9-a5f0-51333a8382e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-40562623-569d-4b57-8603-ae50c07b79d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-4eb8deab-0ef1-41ae-a7e4-964a089b50e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44305,DS-eaf210f8-07e7-4cae-a7da-4c1567af05dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-5d2f2e4a-ec82-46fe-ba95-4fc988ef66df,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-bb2a049a-63dc-4aa3-a022-f6aff86d4f29,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-8a526705-93cc-4743-8656-3cc73cca8822,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-44150279-172.17.0.7-1595975720300:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41624,DS-aafa8a65-0d06-46c4-ba3b-5d87ef24a464,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-e75915cb-6c1e-4ad9-b547-6e7d71ab870d,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-6174fe44-d8c7-4a6d-8f70-3828a2d3e896,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-4f7d79b1-d475-4669-8dda-bafbd2eda85f,DISK], DatanodeInfoWithStorage[127.0.0.1:36044,DS-f59acdce-6870-4b7c-8764-d764effbc66e,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-11735c40-ad81-428f-8f6a-9fddeb5cdaec,DISK], DatanodeInfoWithStorage[127.0.0.1:46502,DS-6a954ca9-89f5-484b-9b0d-3a8441a15e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45984,DS-a272aedf-6585-4d2b-bf29-85a37dee20d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-44150279-172.17.0.7-1595975720300:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41624,DS-aafa8a65-0d06-46c4-ba3b-5d87ef24a464,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-e75915cb-6c1e-4ad9-b547-6e7d71ab870d,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-6174fe44-d8c7-4a6d-8f70-3828a2d3e896,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-4f7d79b1-d475-4669-8dda-bafbd2eda85f,DISK], DatanodeInfoWithStorage[127.0.0.1:36044,DS-f59acdce-6870-4b7c-8764-d764effbc66e,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-11735c40-ad81-428f-8f6a-9fddeb5cdaec,DISK], DatanodeInfoWithStorage[127.0.0.1:46502,DS-6a954ca9-89f5-484b-9b0d-3a8441a15e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45984,DS-a272aedf-6585-4d2b-bf29-85a37dee20d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1106666201-172.17.0.7-1595976165065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44850,DS-176ef0d9-8743-4cda-9587-a4858d49301e,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-9e1babb8-7ed1-4fac-9faf-a08246481685,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-3da8ec1d-89b5-4d70-bced-15c41db58c06,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-b5785afc-0f7d-4763-955d-83ddd237444e,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-db12b264-55dd-4632-bd1c-a6422982b713,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-d6764dd8-d8d8-4db3-8368-df8c9b6f1ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-02811082-8a0b-47f5-b0bc-586a80215389,DISK], DatanodeInfoWithStorage[127.0.0.1:34591,DS-765d2ec8-628e-4e7b-841b-dfb9ab1f7b02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1106666201-172.17.0.7-1595976165065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44850,DS-176ef0d9-8743-4cda-9587-a4858d49301e,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-9e1babb8-7ed1-4fac-9faf-a08246481685,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-3da8ec1d-89b5-4d70-bced-15c41db58c06,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-b5785afc-0f7d-4763-955d-83ddd237444e,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-db12b264-55dd-4632-bd1c-a6422982b713,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-d6764dd8-d8d8-4db3-8368-df8c9b6f1ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-02811082-8a0b-47f5-b0bc-586a80215389,DISK], DatanodeInfoWithStorage[127.0.0.1:34591,DS-765d2ec8-628e-4e7b-841b-dfb9ab1f7b02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1435904307-172.17.0.7-1595976197853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41106,DS-b7a573db-29dd-4d94-a664-bc422ea45cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-6da9ed08-ff54-41ab-9dae-69b1f30fe1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-faac5cd1-4ec8-426c-929b-0e10d7b5df29,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-c995e1a4-baf8-4cd8-9307-aec0af834bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:40854,DS-85ee92dc-593d-48de-ba50-782f3c14c6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-c65dd134-78ff-49d6-adea-3cf4628e0abd,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-39c7cf2e-e57f-49a4-b201-bd68af53dc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-14b88f0f-e3fd-4c51-8480-e6e5cc867812,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1435904307-172.17.0.7-1595976197853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41106,DS-b7a573db-29dd-4d94-a664-bc422ea45cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-6da9ed08-ff54-41ab-9dae-69b1f30fe1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-faac5cd1-4ec8-426c-929b-0e10d7b5df29,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-c995e1a4-baf8-4cd8-9307-aec0af834bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:40854,DS-85ee92dc-593d-48de-ba50-782f3c14c6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-c65dd134-78ff-49d6-adea-3cf4628e0abd,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-39c7cf2e-e57f-49a4-b201-bd68af53dc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-14b88f0f-e3fd-4c51-8480-e6e5cc867812,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-439766132-172.17.0.7-1595976275567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45241,DS-6010a76a-bf2d-4313-83f0-9dee4fc03d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-2808c909-58a5-4d96-9af5-11e84870daad,DISK], DatanodeInfoWithStorage[127.0.0.1:38182,DS-c9dde24b-6641-4335-b5bf-22bf20c5382f,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-998dea8e-00c8-4773-bf99-79aa9c90a87d,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-f38175b1-17e7-4f60-a65d-feeb1c32851c,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-d8afbfa8-eeb6-4e62-85e1-c2f9312c5a22,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-9096b354-bdbf-4383-9729-4ae191053111,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-8d81248c-10d9-4df4-a3ce-0ddc7ef9288c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-439766132-172.17.0.7-1595976275567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45241,DS-6010a76a-bf2d-4313-83f0-9dee4fc03d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-2808c909-58a5-4d96-9af5-11e84870daad,DISK], DatanodeInfoWithStorage[127.0.0.1:38182,DS-c9dde24b-6641-4335-b5bf-22bf20c5382f,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-998dea8e-00c8-4773-bf99-79aa9c90a87d,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-f38175b1-17e7-4f60-a65d-feeb1c32851c,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-d8afbfa8-eeb6-4e62-85e1-c2f9312c5a22,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-9096b354-bdbf-4383-9729-4ae191053111,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-8d81248c-10d9-4df4-a3ce-0ddc7ef9288c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-45263778-172.17.0.7-1595976490533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36301,DS-6199c994-6398-4c5e-b6cd-bd09a3f248ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42703,DS-707ec23e-7cb3-4af4-8781-6a19849488ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-7b547c01-e5dd-4f12-8e71-8acbaf39a68d,DISK], DatanodeInfoWithStorage[127.0.0.1:36900,DS-53f5bb72-3000-4b41-a574-01dbeaf9f5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-21af6cab-abb0-4bda-8c18-264fa087e5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-ba2ec3ac-5724-4914-9b22-b1f993526068,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-626f8acd-27be-44a0-ba8e-976f051d36b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-2ea7e8f6-f618-433e-acc7-4a2559b99523,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-45263778-172.17.0.7-1595976490533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36301,DS-6199c994-6398-4c5e-b6cd-bd09a3f248ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42703,DS-707ec23e-7cb3-4af4-8781-6a19849488ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-7b547c01-e5dd-4f12-8e71-8acbaf39a68d,DISK], DatanodeInfoWithStorage[127.0.0.1:36900,DS-53f5bb72-3000-4b41-a574-01dbeaf9f5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-21af6cab-abb0-4bda-8c18-264fa087e5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-ba2ec3ac-5724-4914-9b22-b1f993526068,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-626f8acd-27be-44a0-ba8e-976f051d36b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-2ea7e8f6-f618-433e-acc7-4a2559b99523,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-786367845-172.17.0.7-1595976849666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35778,DS-06698725-86e9-4b08-8a3d-a8bd96032bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-cc920fbe-28df-407f-8414-df91784cf633,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-8e97f15e-c10d-46c3-bd13-6e40cfe8faf1,DISK], DatanodeInfoWithStorage[127.0.0.1:33531,DS-4fba53a5-4c5e-496a-ad64-62dbd8b4c1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-0d47c0c8-0679-406b-8b73-e40d5d6087f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-6810e78a-8c07-437b-aaba-60a25b8f2448,DISK], DatanodeInfoWithStorage[127.0.0.1:38108,DS-b367fdda-64c8-4554-9053-d036f3b80c99,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-527ac5f1-8579-473f-91df-17d5302872ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-786367845-172.17.0.7-1595976849666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35778,DS-06698725-86e9-4b08-8a3d-a8bd96032bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-cc920fbe-28df-407f-8414-df91784cf633,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-8e97f15e-c10d-46c3-bd13-6e40cfe8faf1,DISK], DatanodeInfoWithStorage[127.0.0.1:33531,DS-4fba53a5-4c5e-496a-ad64-62dbd8b4c1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-0d47c0c8-0679-406b-8b73-e40d5d6087f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-6810e78a-8c07-437b-aaba-60a25b8f2448,DISK], DatanodeInfoWithStorage[127.0.0.1:38108,DS-b367fdda-64c8-4554-9053-d036f3b80c99,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-527ac5f1-8579-473f-91df-17d5302872ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1293892531-172.17.0.7-1595977604053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43318,DS-2fefe508-6574-4b9b-be47-244f89c0f78f,DISK], DatanodeInfoWithStorage[127.0.0.1:46467,DS-86e926ba-77e1-4b97-add1-20215e7c4ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-f3720dd7-4e74-4284-abae-e3bc2a1e6ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-d06180b3-a109-437b-aca7-d3712a12903a,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-772016b5-7c39-48db-9684-96edfd7fa097,DISK], DatanodeInfoWithStorage[127.0.0.1:33821,DS-2649b4a8-6de8-416d-89ef-9c7a117e4ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-795c4b51-c38f-4add-be0b-7a7b2ab74924,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-8c9282f2-369f-440a-916e-b50f2b33b6b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1293892531-172.17.0.7-1595977604053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43318,DS-2fefe508-6574-4b9b-be47-244f89c0f78f,DISK], DatanodeInfoWithStorage[127.0.0.1:46467,DS-86e926ba-77e1-4b97-add1-20215e7c4ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-f3720dd7-4e74-4284-abae-e3bc2a1e6ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-d06180b3-a109-437b-aca7-d3712a12903a,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-772016b5-7c39-48db-9684-96edfd7fa097,DISK], DatanodeInfoWithStorage[127.0.0.1:33821,DS-2649b4a8-6de8-416d-89ef-9c7a117e4ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-795c4b51-c38f-4add-be0b-7a7b2ab74924,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-8c9282f2-369f-440a-916e-b50f2b33b6b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1092948697-172.17.0.7-1595977785091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39138,DS-7f972245-b0d8-41a2-bd4f-1a6cadd8151a,DISK], DatanodeInfoWithStorage[127.0.0.1:34245,DS-d2a3c355-2b37-4b30-951a-9c28ea898e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46460,DS-fe02d68a-8fa2-4d84-bbb9-5bc81d4a5e87,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-e9155241-2046-4e8d-ba1e-eaf8c446e06b,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-6d1ddc85-920f-4873-b706-b42a849f13ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42191,DS-a0df9da4-99f6-4312-9bed-d7f469acb2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35082,DS-0200f763-2e51-46e9-b2fd-9249775be2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36389,DS-d54ebe37-1875-4084-812b-efaf48fa1ce5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1092948697-172.17.0.7-1595977785091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39138,DS-7f972245-b0d8-41a2-bd4f-1a6cadd8151a,DISK], DatanodeInfoWithStorage[127.0.0.1:34245,DS-d2a3c355-2b37-4b30-951a-9c28ea898e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46460,DS-fe02d68a-8fa2-4d84-bbb9-5bc81d4a5e87,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-e9155241-2046-4e8d-ba1e-eaf8c446e06b,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-6d1ddc85-920f-4873-b706-b42a849f13ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42191,DS-a0df9da4-99f6-4312-9bed-d7f469acb2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35082,DS-0200f763-2e51-46e9-b2fd-9249775be2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36389,DS-d54ebe37-1875-4084-812b-efaf48fa1ce5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1451818025-172.17.0.7-1595978112518:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36851,DS-f57bc1c9-8f6c-4f5b-b2a3-0464ff9b4aad,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-b7fdac22-143d-4014-9164-323be20575a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-a10c3877-0946-44af-8bae-7862cfed49f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-aca15159-146d-46d2-938b-344d07f6e019,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-514907e8-e2ac-4196-a191-54250142d549,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-4f0b7322-9bc0-4a7e-989b-a930ab1b3b44,DISK], DatanodeInfoWithStorage[127.0.0.1:45634,DS-839b070e-1a00-4b77-adc2-d301a651b8f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-d2424dfd-04d1-49f4-94d9-3852fba865ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1451818025-172.17.0.7-1595978112518:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36851,DS-f57bc1c9-8f6c-4f5b-b2a3-0464ff9b4aad,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-b7fdac22-143d-4014-9164-323be20575a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-a10c3877-0946-44af-8bae-7862cfed49f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-aca15159-146d-46d2-938b-344d07f6e019,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-514907e8-e2ac-4196-a191-54250142d549,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-4f0b7322-9bc0-4a7e-989b-a930ab1b3b44,DISK], DatanodeInfoWithStorage[127.0.0.1:45634,DS-839b070e-1a00-4b77-adc2-d301a651b8f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-d2424dfd-04d1-49f4-94d9-3852fba865ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-834082696-172.17.0.7-1595978418822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37594,DS-ad55e932-e723-4605-867d-e0e62de08d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-406c640e-e195-4433-abc6-24e7f1d65ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-cb03e74f-8814-4e81-a20d-e874fbeca64b,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-2323d40a-2607-4f66-86e9-60928b118106,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-1677eae6-c5eb-4196-83ce-80fb014798bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34159,DS-2b32ac9b-eed7-4314-89ef-80791f0748f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-a96eccbb-5c0b-42d5-92c5-2eedfca917a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-820167f4-eb37-4df1-8d8d-7181c89ce541,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-834082696-172.17.0.7-1595978418822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37594,DS-ad55e932-e723-4605-867d-e0e62de08d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-406c640e-e195-4433-abc6-24e7f1d65ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-cb03e74f-8814-4e81-a20d-e874fbeca64b,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-2323d40a-2607-4f66-86e9-60928b118106,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-1677eae6-c5eb-4196-83ce-80fb014798bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34159,DS-2b32ac9b-eed7-4314-89ef-80791f0748f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-a96eccbb-5c0b-42d5-92c5-2eedfca917a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-820167f4-eb37-4df1-8d8d-7181c89ce541,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-750282643-172.17.0.7-1595979100547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45695,DS-0f0f627c-4a5b-4e27-8721-9f6f481fe2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-8fc9486c-f0c5-48d8-b1e8-ca496de54ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-e57fc2d0-4971-489f-bd50-21e6205b2fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-8c8aea26-c349-40ed-a7bf-8a773eb9ede8,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-4cd5223c-b758-4d9f-998f-b4ea5ccb38a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-b5c98d08-5c10-4e46-9714-5cf3082c88d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-fed743cc-d6d0-4aec-a038-ecf63bd156b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-89c4bfa1-9c0d-4851-8d01-3adcca1efb5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-750282643-172.17.0.7-1595979100547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45695,DS-0f0f627c-4a5b-4e27-8721-9f6f481fe2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-8fc9486c-f0c5-48d8-b1e8-ca496de54ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-e57fc2d0-4971-489f-bd50-21e6205b2fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-8c8aea26-c349-40ed-a7bf-8a773eb9ede8,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-4cd5223c-b758-4d9f-998f-b4ea5ccb38a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-b5c98d08-5c10-4e46-9714-5cf3082c88d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-fed743cc-d6d0-4aec-a038-ecf63bd156b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-89c4bfa1-9c0d-4851-8d01-3adcca1efb5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5417
