reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2107761885-172.17.0.2-1595928023884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35987,DS-83d15bcc-4b99-4f0d-9fc4-d082fa84b91e,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-db86f909-a49b-4ad9-b114-0ec888176014,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-d8449de6-d9ea-422a-a8ff-7d3710220719,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-230c1af8-b5b2-481f-a99e-1c014fbbaca4,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-022ef13d-f636-41e4-a3d2-0efdeeba84d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-b9bc1aa2-e432-4b7c-90e8-5410108284ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-ace120f5-074d-45b9-a682-27831cfc7b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-6aa61451-9fd9-4577-9b6b-266344a77e98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2107761885-172.17.0.2-1595928023884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35987,DS-83d15bcc-4b99-4f0d-9fc4-d082fa84b91e,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-db86f909-a49b-4ad9-b114-0ec888176014,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-d8449de6-d9ea-422a-a8ff-7d3710220719,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-230c1af8-b5b2-481f-a99e-1c014fbbaca4,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-022ef13d-f636-41e4-a3d2-0efdeeba84d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-b9bc1aa2-e432-4b7c-90e8-5410108284ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-ace120f5-074d-45b9-a682-27831cfc7b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-6aa61451-9fd9-4577-9b6b-266344a77e98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1099084107-172.17.0.2-1595928276270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36942,DS-cbec5aa8-de8b-427b-aae4-1bfcf64bb6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-e24edc77-5a94-4f22-b74e-12a3b1b6af88,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-6d5caa0c-0061-4f33-9b3d-1e9bf141601a,DISK], DatanodeInfoWithStorage[127.0.0.1:32817,DS-90ed959a-f212-4ce3-9846-8cc7fa1e36e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-3f948933-2403-4324-88a3-e982af314e89,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-e398d834-3c63-4273-a1f4-24c62268cfee,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-392832b7-a0e2-4bc2-8e40-9740c717973b,DISK], DatanodeInfoWithStorage[127.0.0.1:44615,DS-8dd84f1a-cdeb-4d04-8dd7-e3d1ccb7ddcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1099084107-172.17.0.2-1595928276270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36942,DS-cbec5aa8-de8b-427b-aae4-1bfcf64bb6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-e24edc77-5a94-4f22-b74e-12a3b1b6af88,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-6d5caa0c-0061-4f33-9b3d-1e9bf141601a,DISK], DatanodeInfoWithStorage[127.0.0.1:32817,DS-90ed959a-f212-4ce3-9846-8cc7fa1e36e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-3f948933-2403-4324-88a3-e982af314e89,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-e398d834-3c63-4273-a1f4-24c62268cfee,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-392832b7-a0e2-4bc2-8e40-9740c717973b,DISK], DatanodeInfoWithStorage[127.0.0.1:44615,DS-8dd84f1a-cdeb-4d04-8dd7-e3d1ccb7ddcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1652911650-172.17.0.2-1595928354200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41010,DS-a3bee7bb-ccd0-4fde-a663-3694f41758a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-d2b0c9c7-36f0-4d3f-a017-cc8941fc6e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-764d6a74-8098-40ec-970b-f6dd228e8b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-7b0aef5c-111f-4b72-8ad7-131d1cfc06be,DISK], DatanodeInfoWithStorage[127.0.0.1:41682,DS-5e621fbf-840c-4568-b7ad-b98447545dac,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-9c5beb60-483a-4c48-ae8a-fc0ea2c7b6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-c997f789-a0db-49ab-ba48-d07d909f6b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-09a0dae5-04fb-49c3-a6e9-b032e0d724ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1652911650-172.17.0.2-1595928354200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41010,DS-a3bee7bb-ccd0-4fde-a663-3694f41758a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-d2b0c9c7-36f0-4d3f-a017-cc8941fc6e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-764d6a74-8098-40ec-970b-f6dd228e8b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-7b0aef5c-111f-4b72-8ad7-131d1cfc06be,DISK], DatanodeInfoWithStorage[127.0.0.1:41682,DS-5e621fbf-840c-4568-b7ad-b98447545dac,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-9c5beb60-483a-4c48-ae8a-fc0ea2c7b6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-c997f789-a0db-49ab-ba48-d07d909f6b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-09a0dae5-04fb-49c3-a6e9-b032e0d724ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1302524697-172.17.0.2-1595928615587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40912,DS-2167e450-6ba9-4db1-9c2b-1cf785020bba,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-1a4e17f3-3bc5-4597-9811-62717707261d,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-bfe4b969-4bc5-436a-9516-9c4c085a022d,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-1c7dae14-c555-458c-978f-c131bbce22cd,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-963cfec9-6a7c-4df8-820a-cf952dd4f7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-8e3e0dec-4c63-48c6-99c8-df53362a133e,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-20a0991f-f98e-41fd-b20f-39e1ef64fe33,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-4b1bb9ab-9a16-4e96-bb03-862b51dac1cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1302524697-172.17.0.2-1595928615587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40912,DS-2167e450-6ba9-4db1-9c2b-1cf785020bba,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-1a4e17f3-3bc5-4597-9811-62717707261d,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-bfe4b969-4bc5-436a-9516-9c4c085a022d,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-1c7dae14-c555-458c-978f-c131bbce22cd,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-963cfec9-6a7c-4df8-820a-cf952dd4f7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-8e3e0dec-4c63-48c6-99c8-df53362a133e,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-20a0991f-f98e-41fd-b20f-39e1ef64fe33,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-4b1bb9ab-9a16-4e96-bb03-862b51dac1cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1579364063-172.17.0.2-1595929565752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33487,DS-c901d189-7a58-4b83-891e-43b9e2da64ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45823,DS-d312a12c-83f5-42b6-96a2-e4df13a1ffc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-5c7bf3b5-c89c-4368-b338-f7e8080f77bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40320,DS-0b79a853-c0cc-42d0-bb7c-9336ae7086f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-8f240fee-508d-47aa-94bb-05b9441eec1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35797,DS-ec08c7c9-817f-4977-9a85-03654e9d7539,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-8075482f-4f86-4695-8940-85ea8249f86b,DISK], DatanodeInfoWithStorage[127.0.0.1:46868,DS-36d17126-8d18-4109-bd5f-ee03dde70a4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1579364063-172.17.0.2-1595929565752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33487,DS-c901d189-7a58-4b83-891e-43b9e2da64ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45823,DS-d312a12c-83f5-42b6-96a2-e4df13a1ffc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-5c7bf3b5-c89c-4368-b338-f7e8080f77bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40320,DS-0b79a853-c0cc-42d0-bb7c-9336ae7086f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-8f240fee-508d-47aa-94bb-05b9441eec1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35797,DS-ec08c7c9-817f-4977-9a85-03654e9d7539,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-8075482f-4f86-4695-8940-85ea8249f86b,DISK], DatanodeInfoWithStorage[127.0.0.1:46868,DS-36d17126-8d18-4109-bd5f-ee03dde70a4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-847724484-172.17.0.2-1595929688078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34188,DS-9eed89ea-7fa0-47a0-b03d-9bd7b46c349b,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-e7572205-0ef6-443c-afbc-da1a903c5f88,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-6f9be15f-c429-4018-960f-d1155f93afd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42646,DS-a0727b8f-d142-462a-8cee-9aae7e383f65,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-43e1a414-db65-4c9f-a9c1-a523cd49a123,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-f3d5086b-6180-4cd9-a466-65c5846d9798,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-0e42fbea-614b-4aec-a5b4-98e21d4d29d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-b0257ebd-91fa-47b4-88e3-a2e5948153b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-847724484-172.17.0.2-1595929688078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34188,DS-9eed89ea-7fa0-47a0-b03d-9bd7b46c349b,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-e7572205-0ef6-443c-afbc-da1a903c5f88,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-6f9be15f-c429-4018-960f-d1155f93afd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42646,DS-a0727b8f-d142-462a-8cee-9aae7e383f65,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-43e1a414-db65-4c9f-a9c1-a523cd49a123,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-f3d5086b-6180-4cd9-a466-65c5846d9798,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-0e42fbea-614b-4aec-a5b4-98e21d4d29d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-b0257ebd-91fa-47b4-88e3-a2e5948153b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1563741224-172.17.0.2-1595930342703:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36214,DS-28f86087-54f9-4b81-94ca-f3ec351a092c,DISK], DatanodeInfoWithStorage[127.0.0.1:41139,DS-1c33cb62-fccc-432b-bc84-0ce79ad4ae0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-f7483dfa-2f60-4d0a-85ce-a5f1021ed76f,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-da389f1e-3723-4c49-ae59-b9beabbbaa67,DISK], DatanodeInfoWithStorage[127.0.0.1:33623,DS-554bf543-f572-436a-afe9-e6dcf92e60e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-1a155cf2-f196-4c5a-bbde-7454abee2a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-2a5ddd38-bfb5-4a83-9e04-42b603a72374,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-335bef41-f8b3-4c5c-a169-36d31711efc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1563741224-172.17.0.2-1595930342703:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36214,DS-28f86087-54f9-4b81-94ca-f3ec351a092c,DISK], DatanodeInfoWithStorage[127.0.0.1:41139,DS-1c33cb62-fccc-432b-bc84-0ce79ad4ae0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-f7483dfa-2f60-4d0a-85ce-a5f1021ed76f,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-da389f1e-3723-4c49-ae59-b9beabbbaa67,DISK], DatanodeInfoWithStorage[127.0.0.1:33623,DS-554bf543-f572-436a-afe9-e6dcf92e60e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-1a155cf2-f196-4c5a-bbde-7454abee2a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-2a5ddd38-bfb5-4a83-9e04-42b603a72374,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-335bef41-f8b3-4c5c-a169-36d31711efc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-378209962-172.17.0.2-1595930490392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34824,DS-3a881684-0060-4c39-9d7c-dd11379135af,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-846bcd50-8a51-40f4-a5c2-9e2cee8a1611,DISK], DatanodeInfoWithStorage[127.0.0.1:43941,DS-2acd69f8-7ad7-4e0c-8481-4a1780125dea,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-219cbe18-d13a-4e1f-97fe-872d563825d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-143feab6-5eed-4451-95dc-283bcc709349,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-3674dbc7-4e96-4ab0-adbb-3e27d54aa99f,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-82396024-90bc-4d87-9dd9-e4715830254e,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-544edc64-dee4-4ec7-9be7-a9ca888fdd2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-378209962-172.17.0.2-1595930490392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34824,DS-3a881684-0060-4c39-9d7c-dd11379135af,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-846bcd50-8a51-40f4-a5c2-9e2cee8a1611,DISK], DatanodeInfoWithStorage[127.0.0.1:43941,DS-2acd69f8-7ad7-4e0c-8481-4a1780125dea,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-219cbe18-d13a-4e1f-97fe-872d563825d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-143feab6-5eed-4451-95dc-283bcc709349,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-3674dbc7-4e96-4ab0-adbb-3e27d54aa99f,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-82396024-90bc-4d87-9dd9-e4715830254e,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-544edc64-dee4-4ec7-9be7-a9ca888fdd2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1210340718-172.17.0.2-1595930642586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34067,DS-2a97a691-1dbd-4f69-ab1a-36b4fa01a886,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-ff465eb4-b787-44c6-a612-6623923a6a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46309,DS-66edadfb-d206-49df-ba2e-e3e40899cb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-0305eb5e-2f3b-427c-be7f-8202cfb62aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-f0f7ed24-e5f0-4fc3-a9b0-1bd7b6eaf282,DISK], DatanodeInfoWithStorage[127.0.0.1:44355,DS-3a40f97a-80c4-464d-9f8a-ce348ca3427e,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-e96aea6e-35c2-41ce-b8bb-b4bada8588bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-7fee5a73-ddcc-4f45-a8da-085080d13104,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1210340718-172.17.0.2-1595930642586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34067,DS-2a97a691-1dbd-4f69-ab1a-36b4fa01a886,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-ff465eb4-b787-44c6-a612-6623923a6a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46309,DS-66edadfb-d206-49df-ba2e-e3e40899cb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-0305eb5e-2f3b-427c-be7f-8202cfb62aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-f0f7ed24-e5f0-4fc3-a9b0-1bd7b6eaf282,DISK], DatanodeInfoWithStorage[127.0.0.1:44355,DS-3a40f97a-80c4-464d-9f8a-ce348ca3427e,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-e96aea6e-35c2-41ce-b8bb-b4bada8588bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-7fee5a73-ddcc-4f45-a8da-085080d13104,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1549277084-172.17.0.2-1595930711880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38310,DS-26a65ec8-467b-45af-8570-2e112bb155d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-bb2cfdb2-bec9-4eb3-93a8-9a7b99b9d979,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-f5101906-526c-4ead-ade1-9b08025283c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36088,DS-7407f456-a44d-40d6-90f4-7eee4d9969e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42433,DS-f869e120-f148-4351-a8b3-b878adba5524,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-3726d429-247c-4f31-9cb5-77c70190e1e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-b333c751-014b-4607-a763-5dfff1070864,DISK], DatanodeInfoWithStorage[127.0.0.1:41590,DS-56c74c7a-bc41-4564-9c0d-633e32e33fdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1549277084-172.17.0.2-1595930711880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38310,DS-26a65ec8-467b-45af-8570-2e112bb155d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-bb2cfdb2-bec9-4eb3-93a8-9a7b99b9d979,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-f5101906-526c-4ead-ade1-9b08025283c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36088,DS-7407f456-a44d-40d6-90f4-7eee4d9969e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42433,DS-f869e120-f148-4351-a8b3-b878adba5524,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-3726d429-247c-4f31-9cb5-77c70190e1e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-b333c751-014b-4607-a763-5dfff1070864,DISK], DatanodeInfoWithStorage[127.0.0.1:41590,DS-56c74c7a-bc41-4564-9c0d-633e32e33fdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1679751715-172.17.0.2-1595930807364:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36052,DS-fdd6a9c7-b65d-468f-84e3-05c1d2f53661,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-8778dfdd-5ada-45df-996a-b0abb7bce598,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-a098f547-9387-4eb3-9b91-cd3327cf70ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-5128b0d3-65b9-4ac9-a35b-fa06241e6a76,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-e2391acf-9869-406f-b1eb-886514907a93,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-d926da38-721a-4880-b081-4c16932922da,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-5a91b9c1-0dfb-4ee6-b63b-55179d35b568,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-067f4d1e-141a-4ca4-b374-381e78493552,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1679751715-172.17.0.2-1595930807364:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36052,DS-fdd6a9c7-b65d-468f-84e3-05c1d2f53661,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-8778dfdd-5ada-45df-996a-b0abb7bce598,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-a098f547-9387-4eb3-9b91-cd3327cf70ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-5128b0d3-65b9-4ac9-a35b-fa06241e6a76,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-e2391acf-9869-406f-b1eb-886514907a93,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-d926da38-721a-4880-b081-4c16932922da,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-5a91b9c1-0dfb-4ee6-b63b-55179d35b568,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-067f4d1e-141a-4ca4-b374-381e78493552,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1693048527-172.17.0.2-1595931302055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36655,DS-428f6c13-eba0-4731-98e3-f9ee6dc66b17,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-cd557898-7b6f-4356-9ca2-01b377381470,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-22cf1610-a321-480c-8b90-e23166789cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-c039674c-59e4-4293-aaa8-0ebeff351780,DISK], DatanodeInfoWithStorage[127.0.0.1:44639,DS-e4dd2b2a-659e-4c6a-bd2e-89b32d68fe47,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-59c995fc-d7ed-4e58-860d-4990924962ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-39f03ee6-30f0-42fc-9167-f234eada2a37,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-66ca8f25-3aa3-4199-9d43-1816aeccd085,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1693048527-172.17.0.2-1595931302055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36655,DS-428f6c13-eba0-4731-98e3-f9ee6dc66b17,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-cd557898-7b6f-4356-9ca2-01b377381470,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-22cf1610-a321-480c-8b90-e23166789cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-c039674c-59e4-4293-aaa8-0ebeff351780,DISK], DatanodeInfoWithStorage[127.0.0.1:44639,DS-e4dd2b2a-659e-4c6a-bd2e-89b32d68fe47,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-59c995fc-d7ed-4e58-860d-4990924962ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-39f03ee6-30f0-42fc-9167-f234eada2a37,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-66ca8f25-3aa3-4199-9d43-1816aeccd085,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-574769353-172.17.0.2-1595931473712:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43853,DS-e39b01e9-15bd-4447-8fed-ae6345337529,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-dd8e27d6-60f0-4388-8898-0ee64776678a,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-83c5e9cd-aa17-4198-acdd-d405d1a9ab70,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-bf2ba7e4-d03f-46ec-8bb6-c146806e9d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-d4fccc88-e99e-460c-98d7-172184c27f11,DISK], DatanodeInfoWithStorage[127.0.0.1:42528,DS-44c09da3-c16a-4f60-89e8-dc5db77ca145,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-b7aa1df4-aec0-42b8-b471-5a71ab7fc90b,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-dbb342bc-bd52-4f60-bb77-e86754a4803d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-574769353-172.17.0.2-1595931473712:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43853,DS-e39b01e9-15bd-4447-8fed-ae6345337529,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-dd8e27d6-60f0-4388-8898-0ee64776678a,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-83c5e9cd-aa17-4198-acdd-d405d1a9ab70,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-bf2ba7e4-d03f-46ec-8bb6-c146806e9d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-d4fccc88-e99e-460c-98d7-172184c27f11,DISK], DatanodeInfoWithStorage[127.0.0.1:42528,DS-44c09da3-c16a-4f60-89e8-dc5db77ca145,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-b7aa1df4-aec0-42b8-b471-5a71ab7fc90b,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-dbb342bc-bd52-4f60-bb77-e86754a4803d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1529699064-172.17.0.2-1595931610596:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45564,DS-bd1d3ea8-9995-4bc1-addd-2c9a6d224cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-9cf32fdb-46de-4ec2-82de-b295ecdbf365,DISK], DatanodeInfoWithStorage[127.0.0.1:34429,DS-14612c89-bf7c-4218-871c-d470dc45c20b,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-90949aef-4537-4f8f-b561-b89005a9d1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-19cbf79f-ff12-4777-a626-da3ab4ec6711,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-ce6163db-7e8e-4bfa-a4a0-981ee75282af,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-ce4a3dad-d31f-4c4f-b842-cf5212ad3b15,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-c0cf1c2e-243e-48ee-ba57-089cf40b53eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1529699064-172.17.0.2-1595931610596:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45564,DS-bd1d3ea8-9995-4bc1-addd-2c9a6d224cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-9cf32fdb-46de-4ec2-82de-b295ecdbf365,DISK], DatanodeInfoWithStorage[127.0.0.1:34429,DS-14612c89-bf7c-4218-871c-d470dc45c20b,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-90949aef-4537-4f8f-b561-b89005a9d1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-19cbf79f-ff12-4777-a626-da3ab4ec6711,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-ce6163db-7e8e-4bfa-a4a0-981ee75282af,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-ce4a3dad-d31f-4c4f-b842-cf5212ad3b15,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-c0cf1c2e-243e-48ee-ba57-089cf40b53eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1629776174-172.17.0.2-1595931888234:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41626,DS-11ad9bb9-0dda-4b4c-b8e4-5ed32a320f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-26eef45f-b599-4400-9626-e1776b210b37,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-cf80551a-a1b7-4330-8fc0-91427c33b763,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-bcb69582-52aa-43b4-93a0-b0f84582808b,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-79293d72-eba2-4b60-9005-29fbab244d70,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-ae677a85-882b-4a96-8dea-f3ff6495b12c,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-33b2baab-b4f6-4544-ae7d-743f093dce30,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-7f73b9c3-62f3-4be8-8e1a-c02868d688b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1629776174-172.17.0.2-1595931888234:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41626,DS-11ad9bb9-0dda-4b4c-b8e4-5ed32a320f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-26eef45f-b599-4400-9626-e1776b210b37,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-cf80551a-a1b7-4330-8fc0-91427c33b763,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-bcb69582-52aa-43b4-93a0-b0f84582808b,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-79293d72-eba2-4b60-9005-29fbab244d70,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-ae677a85-882b-4a96-8dea-f3ff6495b12c,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-33b2baab-b4f6-4544-ae7d-743f093dce30,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-7f73b9c3-62f3-4be8-8e1a-c02868d688b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1083142959-172.17.0.2-1595931926111:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44636,DS-2377f37c-f18b-4cc1-bdde-3321bbc81e43,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-9cf9358a-a57a-4741-b70a-35789175cdbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-7c96bc8e-0996-45f4-9430-881422acab93,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-28b46c54-2840-4ac2-8e73-9efbe65a280a,DISK], DatanodeInfoWithStorage[127.0.0.1:34788,DS-d43dd593-213a-428f-b0eb-7ee01cc9a323,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-f1365bf0-4aab-4ef6-a008-131471c270e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-24f68ca6-03d5-4511-a24d-bcf89658baae,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-f8c0883e-ed9d-4531-a162-c68c47f7234f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1083142959-172.17.0.2-1595931926111:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44636,DS-2377f37c-f18b-4cc1-bdde-3321bbc81e43,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-9cf9358a-a57a-4741-b70a-35789175cdbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-7c96bc8e-0996-45f4-9430-881422acab93,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-28b46c54-2840-4ac2-8e73-9efbe65a280a,DISK], DatanodeInfoWithStorage[127.0.0.1:34788,DS-d43dd593-213a-428f-b0eb-7ee01cc9a323,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-f1365bf0-4aab-4ef6-a008-131471c270e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-24f68ca6-03d5-4511-a24d-bcf89658baae,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-f8c0883e-ed9d-4531-a162-c68c47f7234f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1748004343-172.17.0.2-1595932588697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40674,DS-1cef5be5-04f0-4fd6-8783-79795e635975,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-41da7ad3-72f7-4e51-9d8c-cb0a7c487e18,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-4e9ebae6-c463-45ce-95a6-eb27bb58efa4,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-9dd361c6-ffb8-4040-888e-eac8d9c21a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-9b532c98-5332-4978-b3c5-8c655ceec2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-41ee4abd-38fa-4bae-a014-77636ce62b08,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-268c2d96-2b69-40f6-bb12-428648b811f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-90a0202c-bffd-472d-9f1c-b2112a21a908,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1748004343-172.17.0.2-1595932588697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40674,DS-1cef5be5-04f0-4fd6-8783-79795e635975,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-41da7ad3-72f7-4e51-9d8c-cb0a7c487e18,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-4e9ebae6-c463-45ce-95a6-eb27bb58efa4,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-9dd361c6-ffb8-4040-888e-eac8d9c21a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-9b532c98-5332-4978-b3c5-8c655ceec2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-41ee4abd-38fa-4bae-a014-77636ce62b08,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-268c2d96-2b69-40f6-bb12-428648b811f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-90a0202c-bffd-472d-9f1c-b2112a21a908,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5388
