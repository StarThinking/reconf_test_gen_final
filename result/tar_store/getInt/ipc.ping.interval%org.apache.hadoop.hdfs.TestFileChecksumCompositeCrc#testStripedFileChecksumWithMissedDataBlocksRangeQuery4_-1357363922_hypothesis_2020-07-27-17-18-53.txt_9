reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1669567903-172.17.0.3-1595870349563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34483,DS-139ab9ec-af05-4057-bbd1-c12009d72674,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-6cb4fe2e-41d8-47a7-b8de-ea4c4bf64154,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-99308f3a-64d9-4cf0-abfd-f79280fc095d,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-f91b5216-9df7-4a52-a873-699ce462e2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-1e504bc4-e0e8-4048-b472-93c7727e5a26,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-99f96353-e5f5-4c9c-91ce-95f566a7bafb,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-4949e80d-191a-4e9f-92c5-5e5e82248eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-a1f558a6-ea81-48ad-b65c-68f9b21c3d36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1669567903-172.17.0.3-1595870349563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34483,DS-139ab9ec-af05-4057-bbd1-c12009d72674,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-6cb4fe2e-41d8-47a7-b8de-ea4c4bf64154,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-99308f3a-64d9-4cf0-abfd-f79280fc095d,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-f91b5216-9df7-4a52-a873-699ce462e2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-1e504bc4-e0e8-4048-b472-93c7727e5a26,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-99f96353-e5f5-4c9c-91ce-95f566a7bafb,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-4949e80d-191a-4e9f-92c5-5e5e82248eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-a1f558a6-ea81-48ad-b65c-68f9b21c3d36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1166035251-172.17.0.3-1595870689922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39103,DS-635a0844-8719-4544-a58a-d9a8a2988e40,DISK], DatanodeInfoWithStorage[127.0.0.1:42190,DS-adfff22a-a328-49eb-9825-5bbd82b1be63,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-ce6747c2-08eb-4806-b8f5-23486edfe68a,DISK], DatanodeInfoWithStorage[127.0.0.1:43986,DS-5105f58d-5598-448d-8290-fb33deb39b40,DISK], DatanodeInfoWithStorage[127.0.0.1:39137,DS-e189b532-faae-4c8a-a301-9fb1bd40883a,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-91ab8026-7e16-4d3c-b4c0-d2e9fde92a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34959,DS-7096179f-bddb-4359-b622-e7e9d779833e,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-81ff5d3e-6c43-48e8-81a7-13288fc7a9c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1166035251-172.17.0.3-1595870689922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39103,DS-635a0844-8719-4544-a58a-d9a8a2988e40,DISK], DatanodeInfoWithStorage[127.0.0.1:42190,DS-adfff22a-a328-49eb-9825-5bbd82b1be63,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-ce6747c2-08eb-4806-b8f5-23486edfe68a,DISK], DatanodeInfoWithStorage[127.0.0.1:43986,DS-5105f58d-5598-448d-8290-fb33deb39b40,DISK], DatanodeInfoWithStorage[127.0.0.1:39137,DS-e189b532-faae-4c8a-a301-9fb1bd40883a,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-91ab8026-7e16-4d3c-b4c0-d2e9fde92a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34959,DS-7096179f-bddb-4359-b622-e7e9d779833e,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-81ff5d3e-6c43-48e8-81a7-13288fc7a9c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1067969300-172.17.0.3-1595870721026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37029,DS-119ca229-5bb2-46dc-9e3b-c7fea16e5cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-0a6809da-a772-459b-9f20-0359019a2116,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-66b3fc19-5eb9-4244-bffb-3a1c800109e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37350,DS-3af2d9bb-fec9-4bd6-9816-1c90f0b37013,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-c8fb4253-34bd-4976-9c0b-1505c5e58fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-2d8451e9-d2e2-4645-85d0-7005d06166ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-9c8eb623-b59f-47a8-bdf0-cc134818b7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38350,DS-4f9f921d-82bf-48a6-9a89-f66d8e51035f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1067969300-172.17.0.3-1595870721026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37029,DS-119ca229-5bb2-46dc-9e3b-c7fea16e5cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-0a6809da-a772-459b-9f20-0359019a2116,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-66b3fc19-5eb9-4244-bffb-3a1c800109e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37350,DS-3af2d9bb-fec9-4bd6-9816-1c90f0b37013,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-c8fb4253-34bd-4976-9c0b-1505c5e58fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-2d8451e9-d2e2-4645-85d0-7005d06166ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-9c8eb623-b59f-47a8-bdf0-cc134818b7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38350,DS-4f9f921d-82bf-48a6-9a89-f66d8e51035f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1013444657-172.17.0.3-1595870796859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33404,DS-ea02aeaa-761a-4c61-8d26-35d0ec8efc8a,DISK], DatanodeInfoWithStorage[127.0.0.1:32798,DS-fb1961fc-b920-4c49-9f32-e525c12a5840,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-cb68be41-79eb-49d3-88a8-2381243626d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40664,DS-1201ae27-9dfa-477b-a091-e029a85037e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-948bd4c1-9daa-45ea-8c65-be094fca7bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-abd61b43-da7a-4378-a591-7c12960727f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-02d8701f-fd6e-44f6-8c2f-255086d559e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38191,DS-c15a6292-6b91-4432-bd0c-ffd660bed5cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1013444657-172.17.0.3-1595870796859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33404,DS-ea02aeaa-761a-4c61-8d26-35d0ec8efc8a,DISK], DatanodeInfoWithStorage[127.0.0.1:32798,DS-fb1961fc-b920-4c49-9f32-e525c12a5840,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-cb68be41-79eb-49d3-88a8-2381243626d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40664,DS-1201ae27-9dfa-477b-a091-e029a85037e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-948bd4c1-9daa-45ea-8c65-be094fca7bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-abd61b43-da7a-4378-a591-7c12960727f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-02d8701f-fd6e-44f6-8c2f-255086d559e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38191,DS-c15a6292-6b91-4432-bd0c-ffd660bed5cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1996617479-172.17.0.3-1595870906834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41705,DS-0804768f-9c1e-4e45-bcd4-5ca8f9f96455,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-9bd1db7c-3194-4120-875d-ef2f1d73cace,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-66405778-2418-4820-a63b-88bc78f5c9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38436,DS-ed0a59de-5a85-4d43-95b1-a9017182fca8,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-cdcb916e-2d45-44f3-9fbd-fcd110154eba,DISK], DatanodeInfoWithStorage[127.0.0.1:42426,DS-f7f6edd0-3c6c-4904-9f57-7f0dbec8e99a,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-eee7a70e-5fbd-4041-86c4-9f4bf180e01f,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-87abf777-3672-4d35-aa88-fe44ed90b33f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1996617479-172.17.0.3-1595870906834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41705,DS-0804768f-9c1e-4e45-bcd4-5ca8f9f96455,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-9bd1db7c-3194-4120-875d-ef2f1d73cace,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-66405778-2418-4820-a63b-88bc78f5c9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38436,DS-ed0a59de-5a85-4d43-95b1-a9017182fca8,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-cdcb916e-2d45-44f3-9fbd-fcd110154eba,DISK], DatanodeInfoWithStorage[127.0.0.1:42426,DS-f7f6edd0-3c6c-4904-9f57-7f0dbec8e99a,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-eee7a70e-5fbd-4041-86c4-9f4bf180e01f,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-87abf777-3672-4d35-aa88-fe44ed90b33f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-932189929-172.17.0.3-1595871215942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34917,DS-3ccc1a97-b245-4d8b-8dc5-28688944d52e,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-0b52cab2-5c69-4de0-8e3c-567229f85892,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-38c534a9-7b6d-4666-b242-5daa297a6cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-bd5d7447-9098-4360-8818-cd6ff22a6c33,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-ff5f25b3-5bf0-4245-a5b2-64c7eafb3e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-91660005-c4fd-412a-b048-16996d98ef34,DISK], DatanodeInfoWithStorage[127.0.0.1:36108,DS-2606c6ea-c3dd-4e16-be24-226f7ff8b4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-b7eaa656-f04c-476b-8dbf-84834e87d641,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-932189929-172.17.0.3-1595871215942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34917,DS-3ccc1a97-b245-4d8b-8dc5-28688944d52e,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-0b52cab2-5c69-4de0-8e3c-567229f85892,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-38c534a9-7b6d-4666-b242-5daa297a6cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-bd5d7447-9098-4360-8818-cd6ff22a6c33,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-ff5f25b3-5bf0-4245-a5b2-64c7eafb3e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-91660005-c4fd-412a-b048-16996d98ef34,DISK], DatanodeInfoWithStorage[127.0.0.1:36108,DS-2606c6ea-c3dd-4e16-be24-226f7ff8b4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-b7eaa656-f04c-476b-8dbf-84834e87d641,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314439000-172.17.0.3-1595871528608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41113,DS-d58c06b3-a2e6-4c7b-9014-d9213f1f73df,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-b8d0bb25-3621-4e9d-83c7-84f1899b00cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-85e72aa9-ee6d-4056-a8cd-bf674036141c,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-f5094915-f72d-482b-b1da-41bb2256e97c,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-709f556c-2b8a-4534-9724-f5698431a482,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-2af736d6-d9c8-4cd1-98c0-89cf10e81c16,DISK], DatanodeInfoWithStorage[127.0.0.1:37889,DS-8ff21688-9114-4d0a-b116-5cb426696fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-3f41454c-6004-459b-ba3b-e5ce0428d02e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314439000-172.17.0.3-1595871528608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41113,DS-d58c06b3-a2e6-4c7b-9014-d9213f1f73df,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-b8d0bb25-3621-4e9d-83c7-84f1899b00cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-85e72aa9-ee6d-4056-a8cd-bf674036141c,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-f5094915-f72d-482b-b1da-41bb2256e97c,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-709f556c-2b8a-4534-9724-f5698431a482,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-2af736d6-d9c8-4cd1-98c0-89cf10e81c16,DISK], DatanodeInfoWithStorage[127.0.0.1:37889,DS-8ff21688-9114-4d0a-b116-5cb426696fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-3f41454c-6004-459b-ba3b-e5ce0428d02e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1326313450-172.17.0.3-1595871696617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40195,DS-3020e55e-07bb-4c64-920d-445e7e12b8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-ff2ffb17-f84b-40db-89e2-ee8bab7cccf6,DISK], DatanodeInfoWithStorage[127.0.0.1:33394,DS-3c124f33-e1ed-4b83-8478-f8a9453cd8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-674873e5-00f1-448d-8b94-9695d115ebb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-2c016491-c321-4c1f-8f39-09359608d50b,DISK], DatanodeInfoWithStorage[127.0.0.1:41130,DS-732a5b4b-6a71-4d32-a1ad-d4f27498bffd,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-28a1fffd-f5aa-47c6-8021-40d248647bba,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-0de34b5c-f995-4fdd-9745-9e507003ab48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1326313450-172.17.0.3-1595871696617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40195,DS-3020e55e-07bb-4c64-920d-445e7e12b8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-ff2ffb17-f84b-40db-89e2-ee8bab7cccf6,DISK], DatanodeInfoWithStorage[127.0.0.1:33394,DS-3c124f33-e1ed-4b83-8478-f8a9453cd8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-674873e5-00f1-448d-8b94-9695d115ebb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-2c016491-c321-4c1f-8f39-09359608d50b,DISK], DatanodeInfoWithStorage[127.0.0.1:41130,DS-732a5b4b-6a71-4d32-a1ad-d4f27498bffd,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-28a1fffd-f5aa-47c6-8021-40d248647bba,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-0de34b5c-f995-4fdd-9745-9e507003ab48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1338792707-172.17.0.3-1595871741284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46434,DS-b1d0e3e6-e678-4925-889d-802c7d060f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-dc2da05a-3cd7-4b03-9762-fc9514ec6ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:32913,DS-d372e0e5-1fce-4dcf-9518-dd38d21d5f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40173,DS-8c31839d-4521-43c2-a94a-67527d2eaa47,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-840cdb2e-825c-4b60-b58d-fa9ebc302e74,DISK], DatanodeInfoWithStorage[127.0.0.1:44853,DS-09e60f05-ce6a-4d2b-89fd-35a63ada96f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-cc793501-dce4-48cd-a119-2b5a0ed6d1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-72f464bc-34ad-44c6-99ef-cb8c30297a4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1338792707-172.17.0.3-1595871741284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46434,DS-b1d0e3e6-e678-4925-889d-802c7d060f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-dc2da05a-3cd7-4b03-9762-fc9514ec6ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:32913,DS-d372e0e5-1fce-4dcf-9518-dd38d21d5f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40173,DS-8c31839d-4521-43c2-a94a-67527d2eaa47,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-840cdb2e-825c-4b60-b58d-fa9ebc302e74,DISK], DatanodeInfoWithStorage[127.0.0.1:44853,DS-09e60f05-ce6a-4d2b-89fd-35a63ada96f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-cc793501-dce4-48cd-a119-2b5a0ed6d1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-72f464bc-34ad-44c6-99ef-cb8c30297a4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2014483761-172.17.0.3-1595871798198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36820,DS-bb75bb5d-8ef8-44f6-9cfb-5eec1507e996,DISK], DatanodeInfoWithStorage[127.0.0.1:43749,DS-517ab299-1a8c-4f13-81dd-34f9499ec8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-1753124d-fbe9-45e5-968a-6f6ff586457c,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-769d520a-48f1-4e46-8454-a8e8bf06be55,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-9a13a4cd-d58a-40f4-93e2-6fc72ba5a896,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-5eac6d2f-3826-42cc-a695-9369833e4418,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-6d287600-4e35-4c71-970e-aae32b1294fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-7debd245-c0b4-4ecd-b5eb-067c23561d1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2014483761-172.17.0.3-1595871798198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36820,DS-bb75bb5d-8ef8-44f6-9cfb-5eec1507e996,DISK], DatanodeInfoWithStorage[127.0.0.1:43749,DS-517ab299-1a8c-4f13-81dd-34f9499ec8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-1753124d-fbe9-45e5-968a-6f6ff586457c,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-769d520a-48f1-4e46-8454-a8e8bf06be55,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-9a13a4cd-d58a-40f4-93e2-6fc72ba5a896,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-5eac6d2f-3826-42cc-a695-9369833e4418,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-6d287600-4e35-4c71-970e-aae32b1294fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-7debd245-c0b4-4ecd-b5eb-067c23561d1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1019145387-172.17.0.3-1595872269767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42333,DS-7e6f7ce0-0e8b-4b9e-b7e1-59b333f7ca38,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-7f86b891-9c63-488f-af56-ed26e4fb2ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:37750,DS-96596624-0dcd-4899-9c93-0a595233a95d,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-e2aa7f24-2b34-422c-8ba5-27437c1a9794,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-c840c78f-a67f-4345-ac8c-6c775fc6649d,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-e2915d11-26c1-46ef-a104-32c008d06fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-30957b9a-5365-4bfe-83c5-6bf0a5e650d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-7b80095b-a815-415e-b67c-a06b7b76b496,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1019145387-172.17.0.3-1595872269767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42333,DS-7e6f7ce0-0e8b-4b9e-b7e1-59b333f7ca38,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-7f86b891-9c63-488f-af56-ed26e4fb2ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:37750,DS-96596624-0dcd-4899-9c93-0a595233a95d,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-e2aa7f24-2b34-422c-8ba5-27437c1a9794,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-c840c78f-a67f-4345-ac8c-6c775fc6649d,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-e2915d11-26c1-46ef-a104-32c008d06fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-30957b9a-5365-4bfe-83c5-6bf0a5e650d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-7b80095b-a815-415e-b67c-a06b7b76b496,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1532371204-172.17.0.3-1595872310132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39391,DS-6b3c6d56-4b29-477a-b91e-892d88a5ecc9,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-13bddf2a-eb7e-4781-a121-6f718f60c5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-bf917a63-19ef-4830-89dc-e5382703a2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39684,DS-21a8925d-7726-4da6-8440-7fed51872078,DISK], DatanodeInfoWithStorage[127.0.0.1:43847,DS-439261e9-8c0f-4df3-884c-3b26fd3fa811,DISK], DatanodeInfoWithStorage[127.0.0.1:39979,DS-d55bfa3f-236e-403f-a06d-3ca81ce0a9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-8199d77c-a254-4518-a64c-adfb9366bc12,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-61948f71-6b18-48e2-9bbf-7998c065eb9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1532371204-172.17.0.3-1595872310132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39391,DS-6b3c6d56-4b29-477a-b91e-892d88a5ecc9,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-13bddf2a-eb7e-4781-a121-6f718f60c5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-bf917a63-19ef-4830-89dc-e5382703a2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39684,DS-21a8925d-7726-4da6-8440-7fed51872078,DISK], DatanodeInfoWithStorage[127.0.0.1:43847,DS-439261e9-8c0f-4df3-884c-3b26fd3fa811,DISK], DatanodeInfoWithStorage[127.0.0.1:39979,DS-d55bfa3f-236e-403f-a06d-3ca81ce0a9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-8199d77c-a254-4518-a64c-adfb9366bc12,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-61948f71-6b18-48e2-9bbf-7998c065eb9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-831926165-172.17.0.3-1595872838863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38712,DS-20eaf059-4182-4ee9-af5e-5a52e0901f64,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-4a907655-1d2b-44c0-940a-9091f462ce71,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-335b7d56-5001-4df6-8a6c-fd1b5d9229aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-b480c45f-c837-4c37-8b47-37352f420a33,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-5732d123-6acb-4cb0-8fc9-8c3893b931b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-17aa5198-732a-49f9-b1fb-8bdf9cd4400a,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-86b513a3-3a5c-46db-871d-b15ae4b624b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-c9c899ce-438d-49ef-b1ea-c1478f7ab80e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-831926165-172.17.0.3-1595872838863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38712,DS-20eaf059-4182-4ee9-af5e-5a52e0901f64,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-4a907655-1d2b-44c0-940a-9091f462ce71,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-335b7d56-5001-4df6-8a6c-fd1b5d9229aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-b480c45f-c837-4c37-8b47-37352f420a33,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-5732d123-6acb-4cb0-8fc9-8c3893b931b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-17aa5198-732a-49f9-b1fb-8bdf9cd4400a,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-86b513a3-3a5c-46db-871d-b15ae4b624b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-c9c899ce-438d-49ef-b1ea-c1478f7ab80e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489343488-172.17.0.3-1595872878167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43067,DS-e7c3c6f7-e2fe-4ff5-97f0-c48cf480b48c,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-598d2833-8965-41a5-b65f-7e111e4b9315,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-913b787f-b822-4609-8866-7203bed5ff89,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-9a5a17dc-0e20-40d1-9cee-536c2764d6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33410,DS-a9b009d5-e1c4-4846-81b0-c768e2f9a50b,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-66e27aa5-6277-4b8a-b1b8-d2e4e2b64290,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-4584dc75-0d87-40a8-b83c-10ea7742c3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-c5c4c73b-6d27-4025-a650-f6378af09768,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489343488-172.17.0.3-1595872878167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43067,DS-e7c3c6f7-e2fe-4ff5-97f0-c48cf480b48c,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-598d2833-8965-41a5-b65f-7e111e4b9315,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-913b787f-b822-4609-8866-7203bed5ff89,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-9a5a17dc-0e20-40d1-9cee-536c2764d6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33410,DS-a9b009d5-e1c4-4846-81b0-c768e2f9a50b,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-66e27aa5-6277-4b8a-b1b8-d2e4e2b64290,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-4584dc75-0d87-40a8-b83c-10ea7742c3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-c5c4c73b-6d27-4025-a650-f6378af09768,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-151441761-172.17.0.3-1595873270264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40414,DS-3c30964d-6f58-415e-b4d6-23065469aac9,DISK], DatanodeInfoWithStorage[127.0.0.1:40397,DS-663f1c5f-09a3-44f0-99d4-4beafffeb715,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-d404e8fd-7bbc-4610-b1d1-d568f954f199,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-1880cb4d-10a0-4248-a174-dd99abcc2b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-0d5a408e-2867-442a-83ca-58a7a5a8e8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43670,DS-b0db5203-43dd-4315-b506-080586429374,DISK], DatanodeInfoWithStorage[127.0.0.1:39615,DS-2e0697ce-aba2-40cd-acce-c148feef1ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-0c5b0a50-a0f0-4f0a-bb19-267292736245,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-151441761-172.17.0.3-1595873270264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40414,DS-3c30964d-6f58-415e-b4d6-23065469aac9,DISK], DatanodeInfoWithStorage[127.0.0.1:40397,DS-663f1c5f-09a3-44f0-99d4-4beafffeb715,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-d404e8fd-7bbc-4610-b1d1-d568f954f199,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-1880cb4d-10a0-4248-a174-dd99abcc2b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-0d5a408e-2867-442a-83ca-58a7a5a8e8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43670,DS-b0db5203-43dd-4315-b506-080586429374,DISK], DatanodeInfoWithStorage[127.0.0.1:39615,DS-2e0697ce-aba2-40cd-acce-c148feef1ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-0c5b0a50-a0f0-4f0a-bb19-267292736245,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-837231319-172.17.0.3-1595873671346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45557,DS-bf1c4dee-d947-4b3e-a3a5-158b3d404cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-4f55deb8-7720-49c8-b181-5a26f0b6c641,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-0635361a-86bf-46ad-a88c-f743675fe12c,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-16635bcf-7533-42a7-810a-fe2c7c3b2ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-0b2a1636-520d-4024-a519-c9c9f69ea275,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-3b7f8330-64eb-41d8-b566-b750dfd66371,DISK], DatanodeInfoWithStorage[127.0.0.1:37151,DS-d0baa95e-e9b5-4d93-8fa1-4759951b4737,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-4a86dc4f-976a-4f18-b621-61d82e1dd473,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-837231319-172.17.0.3-1595873671346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45557,DS-bf1c4dee-d947-4b3e-a3a5-158b3d404cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-4f55deb8-7720-49c8-b181-5a26f0b6c641,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-0635361a-86bf-46ad-a88c-f743675fe12c,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-16635bcf-7533-42a7-810a-fe2c7c3b2ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-0b2a1636-520d-4024-a519-c9c9f69ea275,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-3b7f8330-64eb-41d8-b566-b750dfd66371,DISK], DatanodeInfoWithStorage[127.0.0.1:37151,DS-d0baa95e-e9b5-4d93-8fa1-4759951b4737,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-4a86dc4f-976a-4f18-b621-61d82e1dd473,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1884825229-172.17.0.3-1595873739433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36705,DS-6b88e9de-bea6-4d0e-8b11-894aef36ead0,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-53b99bda-332c-49eb-94f5-d6f581df867e,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-2f1af8f7-5f97-44e2-9736-8ee991c75a39,DISK], DatanodeInfoWithStorage[127.0.0.1:35121,DS-444e1cff-0808-468a-9d09-84800272286d,DISK], DatanodeInfoWithStorage[127.0.0.1:35893,DS-544ea10f-0c9f-4715-9371-90995fadedbe,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-e11a0962-2a70-468e-93d1-168bfa23f098,DISK], DatanodeInfoWithStorage[127.0.0.1:36900,DS-7f5bd357-4cf4-43ac-9ad0-e03ee871c7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-b89e7443-0a23-4e6c-9f73-bd63c45d9466,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1884825229-172.17.0.3-1595873739433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36705,DS-6b88e9de-bea6-4d0e-8b11-894aef36ead0,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-53b99bda-332c-49eb-94f5-d6f581df867e,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-2f1af8f7-5f97-44e2-9736-8ee991c75a39,DISK], DatanodeInfoWithStorage[127.0.0.1:35121,DS-444e1cff-0808-468a-9d09-84800272286d,DISK], DatanodeInfoWithStorage[127.0.0.1:35893,DS-544ea10f-0c9f-4715-9371-90995fadedbe,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-e11a0962-2a70-468e-93d1-168bfa23f098,DISK], DatanodeInfoWithStorage[127.0.0.1:36900,DS-7f5bd357-4cf4-43ac-9ad0-e03ee871c7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-b89e7443-0a23-4e6c-9f73-bd63c45d9466,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-374150233-172.17.0.3-1595873944066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36143,DS-c97b9fde-76d9-4d66-aa34-c6b52a095413,DISK], DatanodeInfoWithStorage[127.0.0.1:39585,DS-2499ab20-d6f0-4f3c-9fdd-5ba50256731c,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-dddeeac9-6804-48b5-8c93-c50c02a97f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33696,DS-dea86855-e5f3-4111-b928-e44e02424893,DISK], DatanodeInfoWithStorage[127.0.0.1:44673,DS-30465d1b-c06d-4568-84a9-8463d67d3940,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-da2b5f49-38c4-4317-a986-c15c4e485ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:45814,DS-d6e034ee-ef36-4356-8ed7-c139e8536332,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-e338b46a-1e5c-43c9-b208-fc0fd7ef1101,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-374150233-172.17.0.3-1595873944066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36143,DS-c97b9fde-76d9-4d66-aa34-c6b52a095413,DISK], DatanodeInfoWithStorage[127.0.0.1:39585,DS-2499ab20-d6f0-4f3c-9fdd-5ba50256731c,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-dddeeac9-6804-48b5-8c93-c50c02a97f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33696,DS-dea86855-e5f3-4111-b928-e44e02424893,DISK], DatanodeInfoWithStorage[127.0.0.1:44673,DS-30465d1b-c06d-4568-84a9-8463d67d3940,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-da2b5f49-38c4-4317-a986-c15c4e485ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:45814,DS-d6e034ee-ef36-4356-8ed7-c139e8536332,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-e338b46a-1e5c-43c9-b208-fc0fd7ef1101,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-884307547-172.17.0.3-1595874141089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36551,DS-efa1b7ce-1191-4fdc-af11-ea8f6a3aee7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-e08d01d7-d979-4585-ab29-4c755bad7e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46155,DS-37ee51f3-6ca2-4acc-b698-fc5357a4db28,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-7bb2f2d8-72fb-4e9e-bdc1-6f0ca65e7665,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-b1f70c92-4f2b-450c-8f6e-8b1027d84cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-778b679e-eb60-4bd4-8b45-1c04730f74d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-35986aec-d9e3-4463-a448-51904bf94c26,DISK], DatanodeInfoWithStorage[127.0.0.1:46093,DS-113fa3a1-7c84-49b9-8584-2c93760e83c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-884307547-172.17.0.3-1595874141089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36551,DS-efa1b7ce-1191-4fdc-af11-ea8f6a3aee7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-e08d01d7-d979-4585-ab29-4c755bad7e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46155,DS-37ee51f3-6ca2-4acc-b698-fc5357a4db28,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-7bb2f2d8-72fb-4e9e-bdc1-6f0ca65e7665,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-b1f70c92-4f2b-450c-8f6e-8b1027d84cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-778b679e-eb60-4bd4-8b45-1c04730f74d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-35986aec-d9e3-4463-a448-51904bf94c26,DISK], DatanodeInfoWithStorage[127.0.0.1:46093,DS-113fa3a1-7c84-49b9-8584-2c93760e83c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2012387733-172.17.0.3-1595874177065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36358,DS-33bcb795-3e14-49a9-8ae2-c2c76409b1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43505,DS-de77c6e5-eb00-42d6-8735-d5e985ed8b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-2edf655c-24e4-4e3a-a8e8-d190dd99b4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-19563f7f-7c5e-4d09-b94c-f10d854ed12d,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-9e9070c3-83d6-4cf5-8c83-182a2b82609b,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-c794018d-07b1-49db-b301-b3d1dc21f7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-725bac3a-8542-4080-8ed0-e0c01eb4fecd,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-e6c133cc-ab60-4afd-a069-63fc7f010d9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2012387733-172.17.0.3-1595874177065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36358,DS-33bcb795-3e14-49a9-8ae2-c2c76409b1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43505,DS-de77c6e5-eb00-42d6-8735-d5e985ed8b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-2edf655c-24e4-4e3a-a8e8-d190dd99b4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-19563f7f-7c5e-4d09-b94c-f10d854ed12d,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-9e9070c3-83d6-4cf5-8c83-182a2b82609b,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-c794018d-07b1-49db-b301-b3d1dc21f7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-725bac3a-8542-4080-8ed0-e0c01eb4fecd,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-e6c133cc-ab60-4afd-a069-63fc7f010d9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1003289357-172.17.0.3-1595874214270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36339,DS-ac313658-dd40-4792-b51e-6acc187b53ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-dfafb49d-d4e4-4d0c-8222-a224475d150c,DISK], DatanodeInfoWithStorage[127.0.0.1:42792,DS-296db9ae-d903-4e80-95a8-588e0e76dfa5,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-0b24b678-e007-4021-b4eb-686402023781,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-12a7c1d1-5a8e-4b11-883d-a59de2a322a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-05210ad5-270c-477f-8fc4-b18be43d3f10,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-7150fd4b-e93a-439e-a952-3f1b7357d8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-5c8b5566-671f-49f8-9a2b-1d75af768bd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1003289357-172.17.0.3-1595874214270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36339,DS-ac313658-dd40-4792-b51e-6acc187b53ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-dfafb49d-d4e4-4d0c-8222-a224475d150c,DISK], DatanodeInfoWithStorage[127.0.0.1:42792,DS-296db9ae-d903-4e80-95a8-588e0e76dfa5,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-0b24b678-e007-4021-b4eb-686402023781,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-12a7c1d1-5a8e-4b11-883d-a59de2a322a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-05210ad5-270c-477f-8fc4-b18be43d3f10,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-7150fd4b-e93a-439e-a952-3f1b7357d8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-5c8b5566-671f-49f8-9a2b-1d75af768bd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1739202196-172.17.0.3-1595874329022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45743,DS-adbbc23b-8ff2-4a43-bc4c-6f9045f68f02,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-db3e2375-21cc-41f3-8765-fce401133609,DISK], DatanodeInfoWithStorage[127.0.0.1:46359,DS-37f69a0e-5488-4f36-bade-02c71903d0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37678,DS-d273d5bf-f0cf-41c3-9be0-d9c038fe39a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-2bd144ff-10d9-4980-a296-05f79e164068,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-4a55ea21-3cfe-46dc-914b-0cbd29fc6330,DISK], DatanodeInfoWithStorage[127.0.0.1:41225,DS-39254a0e-cf72-4957-8db2-8b1d9ea38efe,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-d71f5124-b95c-4316-8fa8-c87f59121eaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1739202196-172.17.0.3-1595874329022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45743,DS-adbbc23b-8ff2-4a43-bc4c-6f9045f68f02,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-db3e2375-21cc-41f3-8765-fce401133609,DISK], DatanodeInfoWithStorage[127.0.0.1:46359,DS-37f69a0e-5488-4f36-bade-02c71903d0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37678,DS-d273d5bf-f0cf-41c3-9be0-d9c038fe39a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-2bd144ff-10d9-4980-a296-05f79e164068,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-4a55ea21-3cfe-46dc-914b-0cbd29fc6330,DISK], DatanodeInfoWithStorage[127.0.0.1:41225,DS-39254a0e-cf72-4957-8db2-8b1d9ea38efe,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-d71f5124-b95c-4316-8fa8-c87f59121eaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-656581506-172.17.0.3-1595874808000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34360,DS-25fc9341-11ba-4ab6-8d76-87394ef67230,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-83c63604-1c8c-44f5-af7a-7695179ac3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-5b4f562e-bc7e-45ac-9a1a-49804933454a,DISK], DatanodeInfoWithStorage[127.0.0.1:43613,DS-c8af1389-c8ee-4fe6-a836-e09bd35c8a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-cca37b9a-1fe8-49b0-b8b1-a69d81a1b683,DISK], DatanodeInfoWithStorage[127.0.0.1:40344,DS-0228843c-4134-4fbd-8aa6-7ee47b33f7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-c372e42b-f21b-4511-97f8-6c1a75bdf55d,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-866cd84b-5d88-4c31-bf87-f9a27cc4941b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-656581506-172.17.0.3-1595874808000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34360,DS-25fc9341-11ba-4ab6-8d76-87394ef67230,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-83c63604-1c8c-44f5-af7a-7695179ac3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-5b4f562e-bc7e-45ac-9a1a-49804933454a,DISK], DatanodeInfoWithStorage[127.0.0.1:43613,DS-c8af1389-c8ee-4fe6-a836-e09bd35c8a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-cca37b9a-1fe8-49b0-b8b1-a69d81a1b683,DISK], DatanodeInfoWithStorage[127.0.0.1:40344,DS-0228843c-4134-4fbd-8aa6-7ee47b33f7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-c372e42b-f21b-4511-97f8-6c1a75bdf55d,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-866cd84b-5d88-4c31-bf87-f9a27cc4941b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-743925764-172.17.0.3-1595875141218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43776,DS-0a69ba97-412c-49c4-bd28-09a26f66fb63,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-b69a1a65-41c1-4398-b2ce-0d3d6c36c3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-7938e796-68f7-4650-84f8-3390b27275aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-69791db8-0ffb-4ef5-a633-1dd0a234b29e,DISK], DatanodeInfoWithStorage[127.0.0.1:40475,DS-1a9a59ad-70b9-41a5-855f-cdc4f2e3f84b,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-e1f728d1-d1e9-4f95-a2c8-d95982df541a,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-df14b8ca-32bb-4e4c-9f22-0500c4882c96,DISK], DatanodeInfoWithStorage[127.0.0.1:45540,DS-fee93d3d-f468-459e-a3cb-ac34e798a6b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-743925764-172.17.0.3-1595875141218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43776,DS-0a69ba97-412c-49c4-bd28-09a26f66fb63,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-b69a1a65-41c1-4398-b2ce-0d3d6c36c3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-7938e796-68f7-4650-84f8-3390b27275aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-69791db8-0ffb-4ef5-a633-1dd0a234b29e,DISK], DatanodeInfoWithStorage[127.0.0.1:40475,DS-1a9a59ad-70b9-41a5-855f-cdc4f2e3f84b,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-e1f728d1-d1e9-4f95-a2c8-d95982df541a,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-df14b8ca-32bb-4e4c-9f22-0500c4882c96,DISK], DatanodeInfoWithStorage[127.0.0.1:45540,DS-fee93d3d-f468-459e-a3cb-ac34e798a6b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1710553852-172.17.0.3-1595875407529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40014,DS-8f0ef244-02c0-4ec4-bc11-5f1780e1f25a,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-db9d9647-84b1-43f4-9f5c-d79b5e982cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-80208a3a-bbd9-465b-a2de-ae4288438ace,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-1048b018-1e98-45c7-aad6-8befb05d6432,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-8ad87646-1b1f-402f-a5bd-b792b77106b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-f4c18c5c-3b9d-4786-8c01-b1106fa500e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-36dca0c2-32ec-4bd1-bd61-93230c9176bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-a7bc85e9-0fa2-45ac-8ab4-553d78e5430f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1710553852-172.17.0.3-1595875407529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40014,DS-8f0ef244-02c0-4ec4-bc11-5f1780e1f25a,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-db9d9647-84b1-43f4-9f5c-d79b5e982cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-80208a3a-bbd9-465b-a2de-ae4288438ace,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-1048b018-1e98-45c7-aad6-8befb05d6432,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-8ad87646-1b1f-402f-a5bd-b792b77106b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-f4c18c5c-3b9d-4786-8c01-b1106fa500e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-36dca0c2-32ec-4bd1-bd61-93230c9176bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-a7bc85e9-0fa2-45ac-8ab4-553d78e5430f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5349
