reconf_parameter: dfs.namenode.list.cache.directives.num.responses
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.directives.num.responses
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1675105300-172.17.0.2-1595589350410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42949,DS-f5b70725-e51d-4a6a-ab46-4c8764956a79,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-459cdcaf-864b-4a27-9237-37b135d3e2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-636b341c-4037-46b1-8f2b-8ea0a38d268e,DISK], DatanodeInfoWithStorage[127.0.0.1:39545,DS-3e0dfbcb-fb31-484d-a1ff-6d5cd278c121,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-e45b7f96-2ff1-4b1c-8d51-edfb403bc9df,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-85db3a04-0c1e-4e76-a39f-7eec55e77998,DISK], DatanodeInfoWithStorage[127.0.0.1:45186,DS-23c5de7a-c5aa-4e5f-8553-e5fbe9f2b42b,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-1c77906f-0a77-4dbd-983c-d5c460f67098,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1675105300-172.17.0.2-1595589350410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42949,DS-f5b70725-e51d-4a6a-ab46-4c8764956a79,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-459cdcaf-864b-4a27-9237-37b135d3e2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-636b341c-4037-46b1-8f2b-8ea0a38d268e,DISK], DatanodeInfoWithStorage[127.0.0.1:39545,DS-3e0dfbcb-fb31-484d-a1ff-6d5cd278c121,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-e45b7f96-2ff1-4b1c-8d51-edfb403bc9df,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-85db3a04-0c1e-4e76-a39f-7eec55e77998,DISK], DatanodeInfoWithStorage[127.0.0.1:45186,DS-23c5de7a-c5aa-4e5f-8553-e5fbe9f2b42b,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-1c77906f-0a77-4dbd-983c-d5c460f67098,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.directives.num.responses
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-547134743-172.17.0.2-1595590074695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34719,DS-af89b211-1936-443a-8f0a-3d9033fee88c,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-d76025e4-0614-4d22-b156-7ddc228d97df,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-a2f78022-251d-469f-b135-ce4454f638d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-edbb88d4-bad8-49ae-81b7-cd05a217d05e,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-29a43756-805c-4a8a-99a7-5b405916fbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-ab183d8f-2604-47f7-8aff-3f0e1d4cb910,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-4d6386bc-0625-4dc9-9ca9-d8504a3b9e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-eeeda6e0-606f-4af0-aadf-7951730ec060,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-547134743-172.17.0.2-1595590074695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34719,DS-af89b211-1936-443a-8f0a-3d9033fee88c,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-d76025e4-0614-4d22-b156-7ddc228d97df,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-a2f78022-251d-469f-b135-ce4454f638d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-edbb88d4-bad8-49ae-81b7-cd05a217d05e,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-29a43756-805c-4a8a-99a7-5b405916fbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-ab183d8f-2604-47f7-8aff-3f0e1d4cb910,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-4d6386bc-0625-4dc9-9ca9-d8504a3b9e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-eeeda6e0-606f-4af0-aadf-7951730ec060,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.directives.num.responses
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-192259239-172.17.0.2-1595590383588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43463,DS-fb58592b-2335-48e0-a9a0-4b0858a5a246,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-9dafd7f8-8738-430f-8674-32ff5a4a9fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-47461746-2b65-419f-b282-0c15f85d05bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33139,DS-d4b135ad-e547-4360-8a20-668b632f49e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-7729f0f1-b61b-47b1-ac7b-28314edc8092,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-bb2ff7c9-6602-4d41-b537-1ffb84b38d04,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-ac02eced-998a-4369-bf07-6e3d7cb0ef02,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-ee2fe23c-adf5-41d6-aef2-0239139db616,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-192259239-172.17.0.2-1595590383588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43463,DS-fb58592b-2335-48e0-a9a0-4b0858a5a246,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-9dafd7f8-8738-430f-8674-32ff5a4a9fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-47461746-2b65-419f-b282-0c15f85d05bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33139,DS-d4b135ad-e547-4360-8a20-668b632f49e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-7729f0f1-b61b-47b1-ac7b-28314edc8092,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-bb2ff7c9-6602-4d41-b537-1ffb84b38d04,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-ac02eced-998a-4369-bf07-6e3d7cb0ef02,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-ee2fe23c-adf5-41d6-aef2-0239139db616,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.directives.num.responses
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1907262618-172.17.0.2-1595590615630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33739,DS-cec3d29a-7498-4a1d-96e5-891170fc969c,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-0d0b4c56-c493-45ce-b70a-2bc1b93c92f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-3f6bcb57-0659-46a1-983b-cd0e29fa9b29,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-abac46bf-c33a-48d3-aee8-746ccc405da3,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-d201a65f-15e9-4c16-b25b-fd4888ec62a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-c35ae533-d902-4e05-aa6c-46161a00c1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-6033eb37-eeba-4cef-a3b6-9daff3ae5261,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-80cd5c83-73ee-444c-9a45-f2552b130109,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1907262618-172.17.0.2-1595590615630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33739,DS-cec3d29a-7498-4a1d-96e5-891170fc969c,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-0d0b4c56-c493-45ce-b70a-2bc1b93c92f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-3f6bcb57-0659-46a1-983b-cd0e29fa9b29,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-abac46bf-c33a-48d3-aee8-746ccc405da3,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-d201a65f-15e9-4c16-b25b-fd4888ec62a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-c35ae533-d902-4e05-aa6c-46161a00c1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-6033eb37-eeba-4cef-a3b6-9daff3ae5261,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-80cd5c83-73ee-444c-9a45-f2552b130109,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.directives.num.responses
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-68309454-172.17.0.2-1595590697884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38279,DS-c0cca2d3-0f60-4f91-8109-2fe42f895e17,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-05d91121-2cce-4cc2-8bcb-80f7077c711e,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-f3068e0d-1cb9-4fd0-85e5-dca4ee863792,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-d1f5de01-86d5-4df0-ac27-a7d032ddfc68,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-6cb5bcd2-4310-46cf-bbf6-d65823825bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-d033f013-7025-4383-a771-a44ca711eeed,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-02dfb17b-2b09-4f96-8e86-844b1b84f629,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-93aaa18a-3413-4b5d-bee0-9de140990f19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-68309454-172.17.0.2-1595590697884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38279,DS-c0cca2d3-0f60-4f91-8109-2fe42f895e17,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-05d91121-2cce-4cc2-8bcb-80f7077c711e,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-f3068e0d-1cb9-4fd0-85e5-dca4ee863792,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-d1f5de01-86d5-4df0-ac27-a7d032ddfc68,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-6cb5bcd2-4310-46cf-bbf6-d65823825bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-d033f013-7025-4383-a771-a44ca711eeed,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-02dfb17b-2b09-4f96-8e86-844b1b84f629,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-93aaa18a-3413-4b5d-bee0-9de140990f19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.list.cache.directives.num.responses
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1164138253-172.17.0.2-1595590740992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34305,DS-76ffbf96-22b3-46d9-bfe9-0ae5d07adb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-d80f2d96-450d-44d2-8274-55b3516ad427,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-691b7457-78b2-456f-baf3-019632013273,DISK], DatanodeInfoWithStorage[127.0.0.1:40142,DS-cf14740a-3208-47fa-9e7d-474e1027734f,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-2c2a6ee0-6a97-402b-8a89-52b8115f1c71,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-390139dc-1b58-4ffe-ab07-41890b24028c,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-5867c289-2825-41ff-9252-fe98c560a0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44370,DS-0839d7e9-74ca-42d5-a317-d2acdb4bad2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1164138253-172.17.0.2-1595590740992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34305,DS-76ffbf96-22b3-46d9-bfe9-0ae5d07adb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-d80f2d96-450d-44d2-8274-55b3516ad427,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-691b7457-78b2-456f-baf3-019632013273,DISK], DatanodeInfoWithStorage[127.0.0.1:40142,DS-cf14740a-3208-47fa-9e7d-474e1027734f,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-2c2a6ee0-6a97-402b-8a89-52b8115f1c71,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-390139dc-1b58-4ffe-ab07-41890b24028c,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-5867c289-2825-41ff-9252-fe98c560a0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44370,DS-0839d7e9-74ca-42d5-a317-d2acdb4bad2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.directives.num.responses
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-39273544-172.17.0.2-1595591152964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38415,DS-241dd38a-5c00-4389-9f1b-0de5ad939735,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-f0f2ea7f-51f7-4d49-b86c-3994ceda9d69,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-4f676ea9-194e-442c-87e6-b7c524c0f2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-1d3ec5a0-f0f3-4b77-872d-761941b94db7,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-7b72cbdb-b63d-48bc-b17b-b0bdc621f409,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-f8b3eb5e-c831-4204-a7ac-aa87161b742e,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-1c02901f-2724-433a-85c5-63f3ff112d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-bcdb6e96-4c11-4116-a643-0e659242d437,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-39273544-172.17.0.2-1595591152964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38415,DS-241dd38a-5c00-4389-9f1b-0de5ad939735,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-f0f2ea7f-51f7-4d49-b86c-3994ceda9d69,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-4f676ea9-194e-442c-87e6-b7c524c0f2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-1d3ec5a0-f0f3-4b77-872d-761941b94db7,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-7b72cbdb-b63d-48bc-b17b-b0bdc621f409,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-f8b3eb5e-c831-4204-a7ac-aa87161b742e,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-1c02901f-2724-433a-85c5-63f3ff112d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-bcdb6e96-4c11-4116-a643-0e659242d437,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.directives.num.responses
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1565594915-172.17.0.2-1595591801818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33596,DS-536fc3d0-02a2-4055-aebf-3605cf368aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-529d154a-d237-424a-9421-2b531ff8b655,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-89027648-bfd4-4e18-9e86-327584e63063,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-326246d7-5bea-4b7e-bb51-6a536ead37fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35368,DS-0b464029-ccb6-4aab-b7a1-7e0001c2b44c,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-264173e7-694f-40c4-8e78-4669766bff0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-d218c38f-98d0-4309-908b-136ecec36c20,DISK], DatanodeInfoWithStorage[127.0.0.1:32977,DS-5f72d13f-f7d0-4869-859e-335c98e8bd0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1565594915-172.17.0.2-1595591801818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33596,DS-536fc3d0-02a2-4055-aebf-3605cf368aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-529d154a-d237-424a-9421-2b531ff8b655,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-89027648-bfd4-4e18-9e86-327584e63063,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-326246d7-5bea-4b7e-bb51-6a536ead37fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35368,DS-0b464029-ccb6-4aab-b7a1-7e0001c2b44c,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-264173e7-694f-40c4-8e78-4669766bff0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-d218c38f-98d0-4309-908b-136ecec36c20,DISK], DatanodeInfoWithStorage[127.0.0.1:32977,DS-5f72d13f-f7d0-4869-859e-335c98e8bd0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.directives.num.responses
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2012321902-172.17.0.2-1595593665364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42091,DS-64608119-3ca7-4071-9080-8d1fc8c950e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-b570b467-f229-4d0d-b4f7-c7efa1892da2,DISK], DatanodeInfoWithStorage[127.0.0.1:45182,DS-667f01c0-d0fb-4e88-9ea6-e749d71f1a81,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-7b241561-d33c-4470-b5aa-4c0f0cfd0406,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-d6f7d862-9124-4ee1-9463-7c5d57d7dac4,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-2a29b7cd-19cc-4504-a8a0-8b9bfefbb910,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-917605e5-f730-4692-87d7-de32d68deed7,DISK], DatanodeInfoWithStorage[127.0.0.1:40050,DS-268b73bc-770a-4da6-803f-1c2ef9ef6d48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2012321902-172.17.0.2-1595593665364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42091,DS-64608119-3ca7-4071-9080-8d1fc8c950e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-b570b467-f229-4d0d-b4f7-c7efa1892da2,DISK], DatanodeInfoWithStorage[127.0.0.1:45182,DS-667f01c0-d0fb-4e88-9ea6-e749d71f1a81,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-7b241561-d33c-4470-b5aa-4c0f0cfd0406,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-d6f7d862-9124-4ee1-9463-7c5d57d7dac4,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-2a29b7cd-19cc-4504-a8a0-8b9bfefbb910,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-917605e5-f730-4692-87d7-de32d68deed7,DISK], DatanodeInfoWithStorage[127.0.0.1:40050,DS-268b73bc-770a-4da6-803f-1c2ef9ef6d48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.directives.num.responses
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2053569684-172.17.0.2-1595593745039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39401,DS-cabd3240-c921-4ffa-8997-aff505088427,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-3bb2af28-0ad1-4be1-ba6b-e61c6a77b0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-08888a3c-450c-4ccd-aa29-6ed0195366b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-26b2662e-10e5-4321-8726-554af46526de,DISK], DatanodeInfoWithStorage[127.0.0.1:42202,DS-5f30422b-f1cb-4048-88c6-6728830c15d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-ab2e54b1-a867-436f-bb71-04eaed1f82e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-421d766a-0e9b-4439-959d-d27523880518,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-ad36feac-c853-4264-88c5-26fba3d43113,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2053569684-172.17.0.2-1595593745039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39401,DS-cabd3240-c921-4ffa-8997-aff505088427,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-3bb2af28-0ad1-4be1-ba6b-e61c6a77b0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-08888a3c-450c-4ccd-aa29-6ed0195366b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-26b2662e-10e5-4321-8726-554af46526de,DISK], DatanodeInfoWithStorage[127.0.0.1:42202,DS-5f30422b-f1cb-4048-88c6-6728830c15d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-ab2e54b1-a867-436f-bb71-04eaed1f82e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-421d766a-0e9b-4439-959d-d27523880518,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-ad36feac-c853-4264-88c5-26fba3d43113,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5657
