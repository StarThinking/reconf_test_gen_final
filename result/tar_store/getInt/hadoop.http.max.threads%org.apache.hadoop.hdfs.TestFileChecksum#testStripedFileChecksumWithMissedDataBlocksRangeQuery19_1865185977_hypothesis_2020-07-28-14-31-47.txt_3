reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 1000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 1000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1581494733-172.17.0.16-1595947273422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45006,DS-8822893b-bd30-4ee2-9e0f-c64e7fcbee8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-9a3fab85-8a65-4d64-b25e-fdbb71243659,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-79efa58d-0a12-43b7-a204-4f5ac18447c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-5e00d037-86fa-4c6c-85fe-3b8a063d4811,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-ad020c24-3b71-4391-b5de-81ed10046168,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-0918a1f7-2319-49e6-9a9c-fb8982f53727,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-87306d01-cda9-4893-90c7-ac338783dee0,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-f15b5188-821b-4969-8b56-40d6dc0619a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1581494733-172.17.0.16-1595947273422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45006,DS-8822893b-bd30-4ee2-9e0f-c64e7fcbee8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-9a3fab85-8a65-4d64-b25e-fdbb71243659,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-79efa58d-0a12-43b7-a204-4f5ac18447c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-5e00d037-86fa-4c6c-85fe-3b8a063d4811,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-ad020c24-3b71-4391-b5de-81ed10046168,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-0918a1f7-2319-49e6-9a9c-fb8982f53727,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-87306d01-cda9-4893-90c7-ac338783dee0,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-f15b5188-821b-4969-8b56-40d6dc0619a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 1000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1254959236-172.17.0.16-1595948006810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41060,DS-232e1cfb-c1ad-44ed-96f4-78b8f1d555cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-d4f5b46e-ac19-4e27-bc7e-3e6c73f33135,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-75b618da-fb88-4d9f-a394-fc4f2bfe985c,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-7ea78cd7-6559-4f4c-8275-10a342065854,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-251c4155-8dbe-4cdc-b84f-cbdf98da37a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-12dabb81-04a5-4a0a-9e14-1a4eb7ca6f23,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-4885e0df-b0ec-4a27-b9c1-ba1c4a541c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-87f342f4-f8c0-4794-b75d-dc65e8c14d50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1254959236-172.17.0.16-1595948006810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41060,DS-232e1cfb-c1ad-44ed-96f4-78b8f1d555cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-d4f5b46e-ac19-4e27-bc7e-3e6c73f33135,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-75b618da-fb88-4d9f-a394-fc4f2bfe985c,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-7ea78cd7-6559-4f4c-8275-10a342065854,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-251c4155-8dbe-4cdc-b84f-cbdf98da37a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-12dabb81-04a5-4a0a-9e14-1a4eb7ca6f23,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-4885e0df-b0ec-4a27-b9c1-ba1c4a541c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-87f342f4-f8c0-4794-b75d-dc65e8c14d50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 1000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1424215479-172.17.0.16-1595948477154:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45084,DS-9df7d501-f6ba-4df6-b7b6-0fdcb3f1e069,DISK], DatanodeInfoWithStorage[127.0.0.1:44646,DS-806cc08e-9f08-4ac3-8456-f513e43e3759,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-def91aa9-323f-4ba5-b2d1-ee50082dce74,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-ace47ab2-f551-4eba-908a-9317100f0388,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-ab1d5094-8c3e-4030-8b63-d16a53818b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43553,DS-a9d76af8-1bd2-4f9b-8aac-c4f15e8becc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35842,DS-4a68066d-72e2-4ebb-b5d1-27760681a0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-a41c371d-a5b2-4527-8553-f0b85abfbb1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1424215479-172.17.0.16-1595948477154:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45084,DS-9df7d501-f6ba-4df6-b7b6-0fdcb3f1e069,DISK], DatanodeInfoWithStorage[127.0.0.1:44646,DS-806cc08e-9f08-4ac3-8456-f513e43e3759,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-def91aa9-323f-4ba5-b2d1-ee50082dce74,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-ace47ab2-f551-4eba-908a-9317100f0388,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-ab1d5094-8c3e-4030-8b63-d16a53818b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43553,DS-a9d76af8-1bd2-4f9b-8aac-c4f15e8becc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35842,DS-4a68066d-72e2-4ebb-b5d1-27760681a0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-a41c371d-a5b2-4527-8553-f0b85abfbb1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 1000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1369641367-172.17.0.16-1595948622795:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42239,DS-e9fb5cdb-38c1-425e-8748-e8616449e78c,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-73ee2e4b-2ddb-4be3-b0c2-60bc7eac08c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-1012c603-c563-4789-88e7-f88907e91d24,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-cfa38232-9102-47d6-9746-512b7a48d342,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-26070b9b-dbe7-4d72-baf6-240f4fb37252,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-f951513c-f1c1-4bc9-be80-569b82905eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-847ece77-9b61-47ac-b5f8-22d86ef447bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40614,DS-eaa805bc-1ca6-400d-a9ea-752e3a5f64fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1369641367-172.17.0.16-1595948622795:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42239,DS-e9fb5cdb-38c1-425e-8748-e8616449e78c,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-73ee2e4b-2ddb-4be3-b0c2-60bc7eac08c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-1012c603-c563-4789-88e7-f88907e91d24,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-cfa38232-9102-47d6-9746-512b7a48d342,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-26070b9b-dbe7-4d72-baf6-240f4fb37252,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-f951513c-f1c1-4bc9-be80-569b82905eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-847ece77-9b61-47ac-b5f8-22d86ef447bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40614,DS-eaa805bc-1ca6-400d-a9ea-752e3a5f64fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 1000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1444100428-172.17.0.16-1595948744458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38406,DS-1d51857c-e676-457c-ad4a-9f0ae926e389,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-11d03092-f36c-4753-956a-fdd14921d9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-31f45a37-5f13-4138-8de6-f5e5e4077a13,DISK], DatanodeInfoWithStorage[127.0.0.1:46379,DS-9c21bac6-128f-4cf8-81ae-7dbe1eddc300,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-ec9a768a-eec0-4113-ab15-83238e8d9ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-fa6ad1b3-3c85-4a2a-af55-0ca39ce24d04,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-57b30d70-97a2-4de3-b6ae-2b7af5c2ce0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36743,DS-428fa6e3-98d5-43bf-89e2-9191378f3e34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1444100428-172.17.0.16-1595948744458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38406,DS-1d51857c-e676-457c-ad4a-9f0ae926e389,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-11d03092-f36c-4753-956a-fdd14921d9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-31f45a37-5f13-4138-8de6-f5e5e4077a13,DISK], DatanodeInfoWithStorage[127.0.0.1:46379,DS-9c21bac6-128f-4cf8-81ae-7dbe1eddc300,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-ec9a768a-eec0-4113-ab15-83238e8d9ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-fa6ad1b3-3c85-4a2a-af55-0ca39ce24d04,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-57b30d70-97a2-4de3-b6ae-2b7af5c2ce0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36743,DS-428fa6e3-98d5-43bf-89e2-9191378f3e34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 1000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1089047172-172.17.0.16-1595949909490:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36082,DS-7935a82a-f44f-4486-ae44-6a85e9c4cc00,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-6ba59b1d-2d4e-479c-98fc-d3c7fbecb976,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-8d20977d-aca7-4610-a627-ea377a84cb08,DISK], DatanodeInfoWithStorage[127.0.0.1:36634,DS-cc4704dc-1200-4f54-8ece-9fed85946f81,DISK], DatanodeInfoWithStorage[127.0.0.1:41935,DS-064cc31a-9031-4beb-9ffc-c8b159b8cc71,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-51c39e2f-9580-442e-b5d3-bc5d39d85f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-caf90bca-823e-484e-b73c-edad9ed6f3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-c496c2f8-231b-42ca-8c66-655b38d18ee3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1089047172-172.17.0.16-1595949909490:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36082,DS-7935a82a-f44f-4486-ae44-6a85e9c4cc00,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-6ba59b1d-2d4e-479c-98fc-d3c7fbecb976,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-8d20977d-aca7-4610-a627-ea377a84cb08,DISK], DatanodeInfoWithStorage[127.0.0.1:36634,DS-cc4704dc-1200-4f54-8ece-9fed85946f81,DISK], DatanodeInfoWithStorage[127.0.0.1:41935,DS-064cc31a-9031-4beb-9ffc-c8b159b8cc71,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-51c39e2f-9580-442e-b5d3-bc5d39d85f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-caf90bca-823e-484e-b73c-edad9ed6f3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-c496c2f8-231b-42ca-8c66-655b38d18ee3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 1000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2142079739-172.17.0.16-1595950293172:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41701,DS-ea058426-5c86-4afa-ba49-23c011e73e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36936,DS-2de2ad47-6dd0-428f-80f6-e5f6726d8753,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-1f1e3561-4133-4a2c-bf05-7f6faa52e602,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-a367d51f-01cf-4db9-8052-e93551fb9037,DISK], DatanodeInfoWithStorage[127.0.0.1:38191,DS-09ca5896-d130-4b98-a6b1-4a74f4b3f4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-9febb20a-dc07-4bf5-af84-34580e984788,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-ef9175f0-90c4-4770-a385-0bf307bb9252,DISK], DatanodeInfoWithStorage[127.0.0.1:42973,DS-b4439340-90b9-4b5e-a56a-3a5d22f61e43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2142079739-172.17.0.16-1595950293172:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41701,DS-ea058426-5c86-4afa-ba49-23c011e73e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36936,DS-2de2ad47-6dd0-428f-80f6-e5f6726d8753,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-1f1e3561-4133-4a2c-bf05-7f6faa52e602,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-a367d51f-01cf-4db9-8052-e93551fb9037,DISK], DatanodeInfoWithStorage[127.0.0.1:38191,DS-09ca5896-d130-4b98-a6b1-4a74f4b3f4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-9febb20a-dc07-4bf5-af84-34580e984788,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-ef9175f0-90c4-4770-a385-0bf307bb9252,DISK], DatanodeInfoWithStorage[127.0.0.1:42973,DS-b4439340-90b9-4b5e-a56a-3a5d22f61e43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 1000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1710354122-172.17.0.16-1595950954131:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37307,DS-58a03b7b-3705-4fc0-99dd-d1d94c0dfb78,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-e6f2d0af-7949-4de0-99fc-9a83cc9d0427,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-519242bf-1d86-4d7e-9c77-898d2bf23e67,DISK], DatanodeInfoWithStorage[127.0.0.1:35420,DS-5fbde123-434d-4704-96e6-f55a44d4d9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44795,DS-f2c2623d-449c-4e31-ad46-733babc7f4df,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-d1e8cceb-ef7e-4fcf-8d5c-dcf9fe82d9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35052,DS-37c17733-f649-465c-bbfd-7b38742c3d37,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-a5d08ed1-07c9-457d-9092-777b50fd466e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1710354122-172.17.0.16-1595950954131:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37307,DS-58a03b7b-3705-4fc0-99dd-d1d94c0dfb78,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-e6f2d0af-7949-4de0-99fc-9a83cc9d0427,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-519242bf-1d86-4d7e-9c77-898d2bf23e67,DISK], DatanodeInfoWithStorage[127.0.0.1:35420,DS-5fbde123-434d-4704-96e6-f55a44d4d9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44795,DS-f2c2623d-449c-4e31-ad46-733babc7f4df,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-d1e8cceb-ef7e-4fcf-8d5c-dcf9fe82d9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35052,DS-37c17733-f649-465c-bbfd-7b38742c3d37,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-a5d08ed1-07c9-457d-9092-777b50fd466e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 1000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1519333535-172.17.0.16-1595951288446:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39227,DS-9394b9c7-46f1-45e4-8901-7f9293b825ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-1723cea3-cf69-4914-ac3b-6044004a367f,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-b2db994b-9f5a-4144-afee-f02a500d9f87,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-3ab022d2-562e-43f4-a54f-3d117c183ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-201737e0-1f51-4193-83f5-31383fad5095,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-9b1c7a85-61b2-4e3e-b389-83df01184234,DISK], DatanodeInfoWithStorage[127.0.0.1:39623,DS-22dfc0d0-3144-4ee9-ae91-4664f3d026a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-299d4326-7e7a-49a7-8513-5b2b634fa0e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1519333535-172.17.0.16-1595951288446:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39227,DS-9394b9c7-46f1-45e4-8901-7f9293b825ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-1723cea3-cf69-4914-ac3b-6044004a367f,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-b2db994b-9f5a-4144-afee-f02a500d9f87,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-3ab022d2-562e-43f4-a54f-3d117c183ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-201737e0-1f51-4193-83f5-31383fad5095,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-9b1c7a85-61b2-4e3e-b389-83df01184234,DISK], DatanodeInfoWithStorage[127.0.0.1:39623,DS-22dfc0d0-3144-4ee9-ae91-4664f3d026a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-299d4326-7e7a-49a7-8513-5b2b634fa0e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 1000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-172681610-172.17.0.16-1595951779646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46339,DS-e59364a4-dc2a-437e-a4cd-ebeb1d71f2be,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-04a933be-ff31-46bd-bf50-377d835b6687,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-8feb0b15-7f9c-4e74-a673-e7f47965087e,DISK], DatanodeInfoWithStorage[127.0.0.1:41467,DS-def340b2-d6a1-4b65-9294-453dd02c39e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41388,DS-a00d9b2d-c5d1-4a9f-94d4-25ed65413f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34979,DS-d1d184a6-9e05-4d49-a63e-95da4b523298,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-5fb12f92-d84d-4778-9181-64cae9c11ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:44864,DS-cf4502e4-68db-4ecc-bf2f-ad2efd0b1a3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-172681610-172.17.0.16-1595951779646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46339,DS-e59364a4-dc2a-437e-a4cd-ebeb1d71f2be,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-04a933be-ff31-46bd-bf50-377d835b6687,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-8feb0b15-7f9c-4e74-a673-e7f47965087e,DISK], DatanodeInfoWithStorage[127.0.0.1:41467,DS-def340b2-d6a1-4b65-9294-453dd02c39e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41388,DS-a00d9b2d-c5d1-4a9f-94d4-25ed65413f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34979,DS-d1d184a6-9e05-4d49-a63e-95da4b523298,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-5fb12f92-d84d-4778-9181-64cae9c11ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:44864,DS-cf4502e4-68db-4ecc-bf2f-ad2efd0b1a3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 1000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-700471091-172.17.0.16-1595951824445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34187,DS-591d7de9-bceb-498d-ad90-db5ce77a37e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-88eb3fad-c670-43c5-9ff5-e9ee5f7f10db,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-2dd08376-2b2c-4705-b967-2042277d8cab,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-173534c3-b483-4dda-a2ac-fdea9830bdf2,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-2243abe5-c315-47c0-9164-bcb33944b141,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-d1396d0a-3226-4d03-9714-b7f8ecef3840,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-4d2f68ad-be92-4e6a-8dce-920739abe1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35429,DS-89c0bdd8-a3ec-4305-94b9-c906dad2a5e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-700471091-172.17.0.16-1595951824445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34187,DS-591d7de9-bceb-498d-ad90-db5ce77a37e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-88eb3fad-c670-43c5-9ff5-e9ee5f7f10db,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-2dd08376-2b2c-4705-b967-2042277d8cab,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-173534c3-b483-4dda-a2ac-fdea9830bdf2,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-2243abe5-c315-47c0-9164-bcb33944b141,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-d1396d0a-3226-4d03-9714-b7f8ecef3840,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-4d2f68ad-be92-4e6a-8dce-920739abe1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35429,DS-89c0bdd8-a3ec-4305-94b9-c906dad2a5e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 1000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2068046720-172.17.0.16-1595952336642:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46175,DS-a72167d0-c14a-4eab-b9be-1d85cee6b2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-f0baebae-3cb4-4cd0-bbd9-f341607790f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-828e5e53-5e22-4e25-bac2-bcb57d47c7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36628,DS-5c424ff7-521d-4fef-8619-fabc3a3cdbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:41674,DS-4137753e-9812-44d1-863b-c8586731a075,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-d7edb8a9-2730-4e8e-831b-bb6b32cc0bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-48a5e52d-5d9c-4e64-8141-56f487871153,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-7985f6d4-7133-4102-8545-79b6011c402a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2068046720-172.17.0.16-1595952336642:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46175,DS-a72167d0-c14a-4eab-b9be-1d85cee6b2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-f0baebae-3cb4-4cd0-bbd9-f341607790f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-828e5e53-5e22-4e25-bac2-bcb57d47c7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36628,DS-5c424ff7-521d-4fef-8619-fabc3a3cdbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:41674,DS-4137753e-9812-44d1-863b-c8586731a075,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-d7edb8a9-2730-4e8e-831b-bb6b32cc0bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-48a5e52d-5d9c-4e64-8141-56f487871153,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-7985f6d4-7133-4102-8545-79b6011c402a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 1000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-721573409-172.17.0.16-1595952678662:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42826,DS-a6bd77d4-3cb8-4d1a-8c79-332e05cc8aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:38202,DS-a3174c2c-fbd3-490b-87f4-b6b588ad8768,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-cb8adf80-f476-427b-a70d-298af7e79039,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-d7e7ed97-d156-44da-b72e-2d306fd56067,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-6557c6c1-c28b-46c0-809e-8a848b524c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-30ea3f94-ae51-4fce-bad8-443cc09c1c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-b0df5195-1eff-4118-9860-feda295c0224,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-334593a9-b39d-40a9-9032-018e7f20e5a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-721573409-172.17.0.16-1595952678662:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42826,DS-a6bd77d4-3cb8-4d1a-8c79-332e05cc8aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:38202,DS-a3174c2c-fbd3-490b-87f4-b6b588ad8768,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-cb8adf80-f476-427b-a70d-298af7e79039,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-d7e7ed97-d156-44da-b72e-2d306fd56067,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-6557c6c1-c28b-46c0-809e-8a848b524c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-30ea3f94-ae51-4fce-bad8-443cc09c1c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-b0df5195-1eff-4118-9860-feda295c0224,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-334593a9-b39d-40a9-9032-018e7f20e5a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 1000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-683351430-172.17.0.16-1595953182436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36430,DS-93774951-987d-4bab-aa3b-783b8cc2708c,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-fb7efeae-f495-4909-b709-fef4175b46b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-b2a3d0c1-cc65-4ca9-a135-1e5d092cf9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-9c0c232a-07e6-49ce-b372-533e9e184f40,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-2a5c65b3-9022-4962-a999-24bc9c1db15b,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-84cef441-0978-4d7f-9f70-844a4152082a,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-2f62d7db-4c44-4a4b-b52e-93b1352cb1ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-5d9e62c4-708c-44da-8830-faa6c7ab2349,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-683351430-172.17.0.16-1595953182436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36430,DS-93774951-987d-4bab-aa3b-783b8cc2708c,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-fb7efeae-f495-4909-b709-fef4175b46b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-b2a3d0c1-cc65-4ca9-a135-1e5d092cf9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-9c0c232a-07e6-49ce-b372-533e9e184f40,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-2a5c65b3-9022-4962-a999-24bc9c1db15b,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-84cef441-0978-4d7f-9f70-844a4152082a,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-2f62d7db-4c44-4a4b-b52e-93b1352cb1ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-5d9e62c4-708c-44da-8830-faa6c7ab2349,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: might be true error
Total execution time in seconds : 6588
