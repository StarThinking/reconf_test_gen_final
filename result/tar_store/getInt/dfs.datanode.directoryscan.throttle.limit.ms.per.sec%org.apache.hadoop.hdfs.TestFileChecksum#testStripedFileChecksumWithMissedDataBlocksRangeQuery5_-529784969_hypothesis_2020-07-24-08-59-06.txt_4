reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1235907873-172.17.0.2-1595582083154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41423,DS-304c47a1-547a-45ac-a8d7-7e09cb284dea,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-395a95cc-d6ca-4481-b119-2cbbfd793e13,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-51ed33c0-46ed-46c9-bbc2-4156757c93bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-9a782d79-a38c-453b-b6fa-49cdb25ef718,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-018fb5d0-bb7b-477a-8fc9-7f616beb7250,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-8d9c47d4-ad5e-4ea0-93b9-4d5aa15f0337,DISK], DatanodeInfoWithStorage[127.0.0.1:39006,DS-e4a00c2d-4b2d-4920-8c32-1c7f5ffcd6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-7fbac39d-9c92-4265-ba6d-9624989efc4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1235907873-172.17.0.2-1595582083154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41423,DS-304c47a1-547a-45ac-a8d7-7e09cb284dea,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-395a95cc-d6ca-4481-b119-2cbbfd793e13,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-51ed33c0-46ed-46c9-bbc2-4156757c93bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-9a782d79-a38c-453b-b6fa-49cdb25ef718,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-018fb5d0-bb7b-477a-8fc9-7f616beb7250,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-8d9c47d4-ad5e-4ea0-93b9-4d5aa15f0337,DISK], DatanodeInfoWithStorage[127.0.0.1:39006,DS-e4a00c2d-4b2d-4920-8c32-1c7f5ffcd6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-7fbac39d-9c92-4265-ba6d-9624989efc4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1123169543-172.17.0.2-1595582261334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42710,DS-a19ee54a-b748-434f-aba0-ea1fd87d0339,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-6bc00470-41c9-4996-8e46-fc9c3c20c323,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-7b94cfa0-833a-4cfb-b06c-8fa6f6094d92,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-63247862-3273-4a64-b6e5-69fe0d43e541,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-c70c614c-12b9-435c-ba04-97564322d847,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-c09dc621-67e2-4b83-9626-d3c9ad280395,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-6382ecb6-e5f2-426f-84e5-b92ae4fee67c,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-c8a6a507-55af-4d94-9ce3-20b283a69b71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1123169543-172.17.0.2-1595582261334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42710,DS-a19ee54a-b748-434f-aba0-ea1fd87d0339,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-6bc00470-41c9-4996-8e46-fc9c3c20c323,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-7b94cfa0-833a-4cfb-b06c-8fa6f6094d92,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-63247862-3273-4a64-b6e5-69fe0d43e541,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-c70c614c-12b9-435c-ba04-97564322d847,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-c09dc621-67e2-4b83-9626-d3c9ad280395,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-6382ecb6-e5f2-426f-84e5-b92ae4fee67c,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-c8a6a507-55af-4d94-9ce3-20b283a69b71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-596520301-172.17.0.2-1595583124160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33084,DS-2f09e8f7-f813-4116-9084-6d91eef46538,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-7b31b935-4551-4830-b9bb-af659b983a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-e2aa1f64-92cb-40db-b4b3-6a26a7724fda,DISK], DatanodeInfoWithStorage[127.0.0.1:42677,DS-74856f01-7745-4ed4-956c-f682d0880faf,DISK], DatanodeInfoWithStorage[127.0.0.1:40853,DS-f485550b-d02a-4b03-bb4d-9b58d411b070,DISK], DatanodeInfoWithStorage[127.0.0.1:36540,DS-dbe9ecdc-3bf2-4a4d-b300-39109ec751f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-98dbdc85-a666-414d-90f4-14b8c4a1a494,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-7772d671-675c-4714-acbf-5980b1197f1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-596520301-172.17.0.2-1595583124160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33084,DS-2f09e8f7-f813-4116-9084-6d91eef46538,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-7b31b935-4551-4830-b9bb-af659b983a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-e2aa1f64-92cb-40db-b4b3-6a26a7724fda,DISK], DatanodeInfoWithStorage[127.0.0.1:42677,DS-74856f01-7745-4ed4-956c-f682d0880faf,DISK], DatanodeInfoWithStorage[127.0.0.1:40853,DS-f485550b-d02a-4b03-bb4d-9b58d411b070,DISK], DatanodeInfoWithStorage[127.0.0.1:36540,DS-dbe9ecdc-3bf2-4a4d-b300-39109ec751f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-98dbdc85-a666-414d-90f4-14b8c4a1a494,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-7772d671-675c-4714-acbf-5980b1197f1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424083431-172.17.0.2-1595584258887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39417,DS-b8d5e05c-68d8-4467-b4b0-8a8321524575,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-7f13c913-2c87-440b-9df0-c7a65a5688d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34607,DS-be8a912a-7f52-4199-8615-7029b0da0e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-078ffa4b-ee25-44a3-b400-c96d43e3cba6,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-807b774d-d651-4293-a898-5ccdab419822,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-86d48158-bf70-440d-9d84-4eea4d4d5f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-706e2a79-a532-420a-8e55-462b0ff298e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-662bfab7-c0d5-4c11-985d-c1748d65a36a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424083431-172.17.0.2-1595584258887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39417,DS-b8d5e05c-68d8-4467-b4b0-8a8321524575,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-7f13c913-2c87-440b-9df0-c7a65a5688d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34607,DS-be8a912a-7f52-4199-8615-7029b0da0e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-078ffa4b-ee25-44a3-b400-c96d43e3cba6,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-807b774d-d651-4293-a898-5ccdab419822,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-86d48158-bf70-440d-9d84-4eea4d4d5f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-706e2a79-a532-420a-8e55-462b0ff298e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-662bfab7-c0d5-4c11-985d-c1748d65a36a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1407871701-172.17.0.2-1595584334999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34938,DS-0e924392-731d-43b4-a8ba-2f34a980cad3,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-9d4762e1-9bba-423e-8c86-c566851a22b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-f0bd5f38-90ae-4b4e-a3ea-aaebdd1c29a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-97c682d6-d2e3-46d9-a2ae-7baaa88dfaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-f9bd9782-997e-4b3e-aad1-91369fb53111,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-4a680bed-5872-4d63-afb6-15373ae4a376,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-11bbede8-ab15-40b1-9d38-26d577d9480a,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-274e423f-a733-4f13-8a51-56b55a9d017e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1407871701-172.17.0.2-1595584334999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34938,DS-0e924392-731d-43b4-a8ba-2f34a980cad3,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-9d4762e1-9bba-423e-8c86-c566851a22b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-f0bd5f38-90ae-4b4e-a3ea-aaebdd1c29a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-97c682d6-d2e3-46d9-a2ae-7baaa88dfaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-f9bd9782-997e-4b3e-aad1-91369fb53111,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-4a680bed-5872-4d63-afb6-15373ae4a376,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-11bbede8-ab15-40b1-9d38-26d577d9480a,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-274e423f-a733-4f13-8a51-56b55a9d017e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1707509252-172.17.0.2-1595584517527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42095,DS-02ef5d67-b3ef-46d6-ac95-b82465e1fd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-c3b68882-89bf-4054-bac9-b99f6be9b6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-f7bb49a4-430f-42a0-a740-350b89db647a,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-68aec92b-2f36-42b6-81a9-2ce34bb04118,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-01d67b98-ac8e-405d-a393-cc95b035b374,DISK], DatanodeInfoWithStorage[127.0.0.1:33648,DS-b7a7b89d-f351-4685-a316-a16299195ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-3a8f379f-7ce9-4246-855e-0940867d4858,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-193b5633-fff1-4453-9173-a546ed6ef764,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1707509252-172.17.0.2-1595584517527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42095,DS-02ef5d67-b3ef-46d6-ac95-b82465e1fd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-c3b68882-89bf-4054-bac9-b99f6be9b6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-f7bb49a4-430f-42a0-a740-350b89db647a,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-68aec92b-2f36-42b6-81a9-2ce34bb04118,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-01d67b98-ac8e-405d-a393-cc95b035b374,DISK], DatanodeInfoWithStorage[127.0.0.1:33648,DS-b7a7b89d-f351-4685-a316-a16299195ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-3a8f379f-7ce9-4246-855e-0940867d4858,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-193b5633-fff1-4453-9173-a546ed6ef764,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2019973273-172.17.0.2-1595585126154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35721,DS-1194ef48-d047-4224-97e2-5d0852d0c7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-fb49ec9d-4b8f-472c-8a8e-8fc331117e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-6463689f-1afa-46d9-84fb-5db27104ce99,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-02bb9d15-fdbe-4a2d-ad5b-31a2004b9915,DISK], DatanodeInfoWithStorage[127.0.0.1:45068,DS-1c0644a4-6d5a-4e8e-a432-2391f6ca1288,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-77edf570-1834-42f0-8c43-057a20af9149,DISK], DatanodeInfoWithStorage[127.0.0.1:33022,DS-67d7d3a8-e95b-47e7-aeb1-a4b601bc4f07,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-2e3a2318-e53a-46e2-a929-ea2f7983158b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2019973273-172.17.0.2-1595585126154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35721,DS-1194ef48-d047-4224-97e2-5d0852d0c7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-fb49ec9d-4b8f-472c-8a8e-8fc331117e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-6463689f-1afa-46d9-84fb-5db27104ce99,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-02bb9d15-fdbe-4a2d-ad5b-31a2004b9915,DISK], DatanodeInfoWithStorage[127.0.0.1:45068,DS-1c0644a4-6d5a-4e8e-a432-2391f6ca1288,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-77edf570-1834-42f0-8c43-057a20af9149,DISK], DatanodeInfoWithStorage[127.0.0.1:33022,DS-67d7d3a8-e95b-47e7-aeb1-a4b601bc4f07,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-2e3a2318-e53a-46e2-a929-ea2f7983158b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1573483494-172.17.0.2-1595585485728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45509,DS-3bc028ef-71cb-4667-83b2-8092f11f304e,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-28352509-5924-48b3-abc1-a79906e4e54a,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-31255100-9c77-4932-a979-259db0c8851f,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-ad8765eb-4d40-4bc0-8772-1e79c0938969,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-f6690979-01ae-461b-a1c7-bc2e8cb49447,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-eec29f87-5b6c-400e-a526-644859204276,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-0e810afe-0a26-45cd-bfa3-57bf814cc122,DISK], DatanodeInfoWithStorage[127.0.0.1:40251,DS-286fe155-6276-442d-b9fd-c9f7952755b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1573483494-172.17.0.2-1595585485728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45509,DS-3bc028ef-71cb-4667-83b2-8092f11f304e,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-28352509-5924-48b3-abc1-a79906e4e54a,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-31255100-9c77-4932-a979-259db0c8851f,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-ad8765eb-4d40-4bc0-8772-1e79c0938969,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-f6690979-01ae-461b-a1c7-bc2e8cb49447,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-eec29f87-5b6c-400e-a526-644859204276,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-0e810afe-0a26-45cd-bfa3-57bf814cc122,DISK], DatanodeInfoWithStorage[127.0.0.1:40251,DS-286fe155-6276-442d-b9fd-c9f7952755b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1007542140-172.17.0.2-1595585650976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41428,DS-37d94b98-00bf-4f59-b714-27e1cc585599,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-c29daedd-c20e-436a-b6e5-aa6cdd01658b,DISK], DatanodeInfoWithStorage[127.0.0.1:33954,DS-e370cb23-54b1-408c-9264-49ac76d6825a,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-33d51f33-f8c9-421b-90fa-36dc08ec62bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-d54aeb09-7d1d-4f0b-b8b6-bae1dbfb09ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-52e56860-bc9b-4c46-adf2-21ba24a0faf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37338,DS-7effba47-380e-4a23-8669-71f70fb9eae6,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-23897da1-a0b1-49f8-89ef-cb01c89ec14b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1007542140-172.17.0.2-1595585650976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41428,DS-37d94b98-00bf-4f59-b714-27e1cc585599,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-c29daedd-c20e-436a-b6e5-aa6cdd01658b,DISK], DatanodeInfoWithStorage[127.0.0.1:33954,DS-e370cb23-54b1-408c-9264-49ac76d6825a,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-33d51f33-f8c9-421b-90fa-36dc08ec62bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-d54aeb09-7d1d-4f0b-b8b6-bae1dbfb09ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-52e56860-bc9b-4c46-adf2-21ba24a0faf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37338,DS-7effba47-380e-4a23-8669-71f70fb9eae6,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-23897da1-a0b1-49f8-89ef-cb01c89ec14b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1272180731-172.17.0.2-1595586018084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35402,DS-7e76e369-a22c-4149-a6d3-2cb01a93be22,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-564cb8a2-47a0-4167-b23d-a4e7c1f41210,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-ab17df68-06dc-4e69-b891-5145fd6a8963,DISK], DatanodeInfoWithStorage[127.0.0.1:41346,DS-535aabbf-80bc-42af-b174-1baa6edc8f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-ca50be9e-d616-4231-aac7-2cc6cd8fb93d,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-a5731755-a409-4918-ac5a-6ecb78190fee,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-24978b97-b99d-434a-9db4-f5b6a4e67d91,DISK], DatanodeInfoWithStorage[127.0.0.1:42715,DS-5e3bb2e4-5e25-404e-b246-3f3e7dc3ff78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1272180731-172.17.0.2-1595586018084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35402,DS-7e76e369-a22c-4149-a6d3-2cb01a93be22,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-564cb8a2-47a0-4167-b23d-a4e7c1f41210,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-ab17df68-06dc-4e69-b891-5145fd6a8963,DISK], DatanodeInfoWithStorage[127.0.0.1:41346,DS-535aabbf-80bc-42af-b174-1baa6edc8f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-ca50be9e-d616-4231-aac7-2cc6cd8fb93d,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-a5731755-a409-4918-ac5a-6ecb78190fee,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-24978b97-b99d-434a-9db4-f5b6a4e67d91,DISK], DatanodeInfoWithStorage[127.0.0.1:42715,DS-5e3bb2e4-5e25-404e-b246-3f3e7dc3ff78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1250514207-172.17.0.2-1595586333655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34109,DS-e202b5b4-8d59-4dd1-9246-8c1e331ae52a,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-09283d3d-5954-47a8-b1ba-c159e16aaac3,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-de11d936-b735-489a-b376-f140018829eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-dcb67e73-e5d9-4fba-8eb9-9ca0e8ffbb5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-461205fb-8f4f-409c-8b8d-fffa3248012e,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-d62a6311-47b0-48da-b4a0-13cf79e88c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-012d6d8e-2dcb-4af3-aee7-2e96b0a321c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-60180e9c-d861-4815-8049-127b95ab187c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1250514207-172.17.0.2-1595586333655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34109,DS-e202b5b4-8d59-4dd1-9246-8c1e331ae52a,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-09283d3d-5954-47a8-b1ba-c159e16aaac3,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-de11d936-b735-489a-b376-f140018829eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-dcb67e73-e5d9-4fba-8eb9-9ca0e8ffbb5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-461205fb-8f4f-409c-8b8d-fffa3248012e,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-d62a6311-47b0-48da-b4a0-13cf79e88c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-012d6d8e-2dcb-4af3-aee7-2e96b0a321c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-60180e9c-d861-4815-8049-127b95ab187c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1152463046-172.17.0.2-1595586411578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35957,DS-93f7c837-6611-47e7-b769-58d4fb146f18,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-50e53133-d1d5-429c-bbb5-d1f25b07d180,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-f12cbb43-cc2b-4c01-82f6-0fe2daff9f20,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-cef2130e-5dad-4a34-b606-c07193eea32b,DISK], DatanodeInfoWithStorage[127.0.0.1:35773,DS-08c7e22a-569d-4221-9c07-c41c47bff127,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-9b8bf983-5c71-45e9-a002-59a246ddff4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40549,DS-0d52989b-b431-4457-9502-bd644c18a398,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-3edca443-3487-4ac8-a964-9d5dfcd73892,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1152463046-172.17.0.2-1595586411578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35957,DS-93f7c837-6611-47e7-b769-58d4fb146f18,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-50e53133-d1d5-429c-bbb5-d1f25b07d180,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-f12cbb43-cc2b-4c01-82f6-0fe2daff9f20,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-cef2130e-5dad-4a34-b606-c07193eea32b,DISK], DatanodeInfoWithStorage[127.0.0.1:35773,DS-08c7e22a-569d-4221-9c07-c41c47bff127,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-9b8bf983-5c71-45e9-a002-59a246ddff4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40549,DS-0d52989b-b431-4457-9502-bd644c18a398,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-3edca443-3487-4ac8-a964-9d5dfcd73892,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5496
