reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1188435833-172.17.0.10-1595909018283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37746,DS-dcb8a2ae-96b5-4c91-bb38-de1995196692,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-bd9b60f9-58ec-43e2-ae47-e65dc36dc22d,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-3be866f0-0a5c-4b8b-a186-6510474c596c,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-5d5b7994-bf05-4ead-8718-e880da9809ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-b59f21e1-2d8e-461b-ad2d-db1a3db9e21b,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-54632538-e402-48ac-ace1-9f0c6fcc1a12,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-f611e25c-87e1-4eb8-9437-a97da32f750c,DISK], DatanodeInfoWithStorage[127.0.0.1:39896,DS-ae0cddb1-7549-4446-bca3-5ac131c3b15a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1188435833-172.17.0.10-1595909018283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37746,DS-dcb8a2ae-96b5-4c91-bb38-de1995196692,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-bd9b60f9-58ec-43e2-ae47-e65dc36dc22d,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-3be866f0-0a5c-4b8b-a186-6510474c596c,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-5d5b7994-bf05-4ead-8718-e880da9809ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-b59f21e1-2d8e-461b-ad2d-db1a3db9e21b,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-54632538-e402-48ac-ace1-9f0c6fcc1a12,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-f611e25c-87e1-4eb8-9437-a97da32f750c,DISK], DatanodeInfoWithStorage[127.0.0.1:39896,DS-ae0cddb1-7549-4446-bca3-5ac131c3b15a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-211545697-172.17.0.10-1595909085734:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36523,DS-078b3266-ad5e-488a-900f-aa08fe6678d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43233,DS-e8c1c23d-e9d5-4b94-8588-174d3fb6f28a,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-178432a2-cc19-4425-98c4-e1ff0a0ed4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-1df4542c-a934-4682-bb0a-93e0950ef534,DISK], DatanodeInfoWithStorage[127.0.0.1:33407,DS-6870aa94-3854-44b4-90f7-bebd3d353645,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-88ba4cfb-4baa-493e-9e30-9100873c558c,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-65af7b50-5777-4bc5-a44b-b77a3756628b,DISK], DatanodeInfoWithStorage[127.0.0.1:44669,DS-c8ece5bd-8e22-496f-968c-77e724ede5b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-211545697-172.17.0.10-1595909085734:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36523,DS-078b3266-ad5e-488a-900f-aa08fe6678d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43233,DS-e8c1c23d-e9d5-4b94-8588-174d3fb6f28a,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-178432a2-cc19-4425-98c4-e1ff0a0ed4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-1df4542c-a934-4682-bb0a-93e0950ef534,DISK], DatanodeInfoWithStorage[127.0.0.1:33407,DS-6870aa94-3854-44b4-90f7-bebd3d353645,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-88ba4cfb-4baa-493e-9e30-9100873c558c,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-65af7b50-5777-4bc5-a44b-b77a3756628b,DISK], DatanodeInfoWithStorage[127.0.0.1:44669,DS-c8ece5bd-8e22-496f-968c-77e724ede5b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-347168717-172.17.0.10-1595909127496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37965,DS-25d51fec-f1aa-4498-80fe-ec6512f92732,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-de43e2e4-9b55-43dd-876f-f5c4f27d3dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-b09be3e2-fd70-45ec-95b2-2eb5df015e62,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-6ee865b1-4bb0-4d67-8bf0-86f2e49b9111,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-4985d0ff-c968-4d73-86c1-1bf42aea819f,DISK], DatanodeInfoWithStorage[127.0.0.1:34674,DS-ac38b0a3-2c28-4a70-8af9-4d0a112b2ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:34046,DS-a6a955bc-dc6e-4804-98ea-58e02a7e3fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:43172,DS-63d07554-b36f-43de-9e43-c951ec23c56a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-347168717-172.17.0.10-1595909127496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37965,DS-25d51fec-f1aa-4498-80fe-ec6512f92732,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-de43e2e4-9b55-43dd-876f-f5c4f27d3dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-b09be3e2-fd70-45ec-95b2-2eb5df015e62,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-6ee865b1-4bb0-4d67-8bf0-86f2e49b9111,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-4985d0ff-c968-4d73-86c1-1bf42aea819f,DISK], DatanodeInfoWithStorage[127.0.0.1:34674,DS-ac38b0a3-2c28-4a70-8af9-4d0a112b2ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:34046,DS-a6a955bc-dc6e-4804-98ea-58e02a7e3fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:43172,DS-63d07554-b36f-43de-9e43-c951ec23c56a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-254649886-172.17.0.10-1595909198101:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33182,DS-eba24f2c-4127-454c-bcb9-6f84a544fbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-1f26932a-e49d-417a-a63b-44dfedc9cece,DISK], DatanodeInfoWithStorage[127.0.0.1:36545,DS-b4016d9f-2860-40de-a1c0-6621c5fcb037,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-e8217b5c-cd7a-498c-a595-7bd9256296df,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-922a3a96-b87e-4a4c-950c-ccbf3282bc37,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-365da7b5-0ecc-4b49-bcd7-5c9462d52eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37903,DS-1bc1e00c-c9f8-452c-a492-b3979199a54b,DISK], DatanodeInfoWithStorage[127.0.0.1:35414,DS-6b7ca5d7-90f9-45c3-afb5-0396da7ac88c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-254649886-172.17.0.10-1595909198101:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33182,DS-eba24f2c-4127-454c-bcb9-6f84a544fbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-1f26932a-e49d-417a-a63b-44dfedc9cece,DISK], DatanodeInfoWithStorage[127.0.0.1:36545,DS-b4016d9f-2860-40de-a1c0-6621c5fcb037,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-e8217b5c-cd7a-498c-a595-7bd9256296df,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-922a3a96-b87e-4a4c-950c-ccbf3282bc37,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-365da7b5-0ecc-4b49-bcd7-5c9462d52eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37903,DS-1bc1e00c-c9f8-452c-a492-b3979199a54b,DISK], DatanodeInfoWithStorage[127.0.0.1:35414,DS-6b7ca5d7-90f9-45c3-afb5-0396da7ac88c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1419952521-172.17.0.10-1595909379881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41376,DS-ffc48bb6-f2ff-4fa3-a3b4-0c7893e240a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-7cbb4860-51c2-4574-b3de-e696cfacb542,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-dd217057-18e4-4076-944c-42afc87ec009,DISK], DatanodeInfoWithStorage[127.0.0.1:41015,DS-6fd93ae6-f927-4487-a433-515172866051,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-5be9bee1-2832-4385-a6a5-e1f264caefb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37250,DS-7efdbcb9-dc22-4783-af4b-375be4af9b70,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-38b1d364-3abc-4e26-a842-3605d49b5558,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-97e25947-e000-460e-9ee8-8c5b0d48cce9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1419952521-172.17.0.10-1595909379881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41376,DS-ffc48bb6-f2ff-4fa3-a3b4-0c7893e240a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-7cbb4860-51c2-4574-b3de-e696cfacb542,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-dd217057-18e4-4076-944c-42afc87ec009,DISK], DatanodeInfoWithStorage[127.0.0.1:41015,DS-6fd93ae6-f927-4487-a433-515172866051,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-5be9bee1-2832-4385-a6a5-e1f264caefb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37250,DS-7efdbcb9-dc22-4783-af4b-375be4af9b70,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-38b1d364-3abc-4e26-a842-3605d49b5558,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-97e25947-e000-460e-9ee8-8c5b0d48cce9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1644023718-172.17.0.10-1595909493026:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38304,DS-1428ea82-564c-4f34-83ed-edba0ff4f076,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-b4bfa4ba-cc31-44d8-9890-d584e63a9b68,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-63366ae9-cb63-4581-a6be-5c87808864a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-2a546630-9ca5-4838-b6ac-519c9cff8117,DISK], DatanodeInfoWithStorage[127.0.0.1:46817,DS-b9ca5988-acd9-42a2-8e63-9a73ae289766,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-85fbd75b-30f0-4529-93e3-18cfd9888775,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-402e00e5-1f0e-4421-aa67-a811c824277c,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-dcf66505-7958-4f1c-9011-870b8d5e0f78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1644023718-172.17.0.10-1595909493026:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38304,DS-1428ea82-564c-4f34-83ed-edba0ff4f076,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-b4bfa4ba-cc31-44d8-9890-d584e63a9b68,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-63366ae9-cb63-4581-a6be-5c87808864a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-2a546630-9ca5-4838-b6ac-519c9cff8117,DISK], DatanodeInfoWithStorage[127.0.0.1:46817,DS-b9ca5988-acd9-42a2-8e63-9a73ae289766,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-85fbd75b-30f0-4529-93e3-18cfd9888775,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-402e00e5-1f0e-4421-aa67-a811c824277c,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-dcf66505-7958-4f1c-9011-870b8d5e0f78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1675715428-172.17.0.10-1595909531728:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43953,DS-491f08b1-2abb-4963-a17f-2771dfb9477b,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-3f633a5e-afc3-4eed-8197-b43bd7261763,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-30509242-3ee2-447d-9f8e-04abff6bc2da,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-b2d3b145-9ebc-47a1-bdb8-c0b6aff6391b,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-d2c8ec26-dfbf-4851-8bea-07d2bc9d6484,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-e6029076-56a1-4346-a681-e8e12460e3de,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-252801be-1e61-4e77-b09f-48d2d48b1bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-90ccf186-af02-4d3a-9868-4614069b2f40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1675715428-172.17.0.10-1595909531728:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43953,DS-491f08b1-2abb-4963-a17f-2771dfb9477b,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-3f633a5e-afc3-4eed-8197-b43bd7261763,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-30509242-3ee2-447d-9f8e-04abff6bc2da,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-b2d3b145-9ebc-47a1-bdb8-c0b6aff6391b,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-d2c8ec26-dfbf-4851-8bea-07d2bc9d6484,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-e6029076-56a1-4346-a681-e8e12460e3de,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-252801be-1e61-4e77-b09f-48d2d48b1bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-90ccf186-af02-4d3a-9868-4614069b2f40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-93011913-172.17.0.10-1595909681615:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36662,DS-f8703471-aa84-4d54-a55f-ec9771bca9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-a41c7897-74cb-4ebd-87f0-564006f1393e,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-967fa707-c474-4fa7-a2b1-12abfc21363f,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-39b4d4c7-f5e5-4860-8d8a-4557a595cfdc,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-3ab7f1ca-f619-415f-b5ec-d9a800044771,DISK], DatanodeInfoWithStorage[127.0.0.1:38194,DS-6aef8381-059c-4a04-ba9b-5cc7354bbe64,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-a79fba5c-9932-479b-914c-36bb4e3d96f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44283,DS-f16e371f-c914-48cf-ad2f-5fc99f25022d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-93011913-172.17.0.10-1595909681615:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36662,DS-f8703471-aa84-4d54-a55f-ec9771bca9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-a41c7897-74cb-4ebd-87f0-564006f1393e,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-967fa707-c474-4fa7-a2b1-12abfc21363f,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-39b4d4c7-f5e5-4860-8d8a-4557a595cfdc,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-3ab7f1ca-f619-415f-b5ec-d9a800044771,DISK], DatanodeInfoWithStorage[127.0.0.1:38194,DS-6aef8381-059c-4a04-ba9b-5cc7354bbe64,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-a79fba5c-9932-479b-914c-36bb4e3d96f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44283,DS-f16e371f-c914-48cf-ad2f-5fc99f25022d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-204918977-172.17.0.10-1595909714689:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33177,DS-d5dc9135-e7d1-4423-a84b-e13c8d2626f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-0c71a070-21df-4339-a920-99fe7f63e10b,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-939637ec-cb7f-433f-a977-742c9cd79daf,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-61a3f11e-8295-45d9-9b5b-39a0c1995579,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-4f769e73-5127-417c-8939-746923d91b67,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-2906a7f9-ada7-4a65-81c0-4de89138bb15,DISK], DatanodeInfoWithStorage[127.0.0.1:46438,DS-6692ff31-6b9a-4734-80cb-adb48f333c26,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-3808f31e-a298-4a5c-9246-d7791bb29ced,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-204918977-172.17.0.10-1595909714689:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33177,DS-d5dc9135-e7d1-4423-a84b-e13c8d2626f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-0c71a070-21df-4339-a920-99fe7f63e10b,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-939637ec-cb7f-433f-a977-742c9cd79daf,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-61a3f11e-8295-45d9-9b5b-39a0c1995579,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-4f769e73-5127-417c-8939-746923d91b67,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-2906a7f9-ada7-4a65-81c0-4de89138bb15,DISK], DatanodeInfoWithStorage[127.0.0.1:46438,DS-6692ff31-6b9a-4734-80cb-adb48f333c26,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-3808f31e-a298-4a5c-9246-d7791bb29ced,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-520175119-172.17.0.10-1595910311981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37032,DS-ff1ccebc-35e8-4601-a319-6be053044b91,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-ac45e1e5-11cb-461a-9ed8-409cc8da6c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39580,DS-e91c2ffb-7d47-4bf7-8754-4ff4f2fae7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-3c7c35b5-e373-43ef-95d7-f17eaa57c7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-9ec544a9-fd9f-42d3-8ab5-4225902aa803,DISK], DatanodeInfoWithStorage[127.0.0.1:37146,DS-edc5b6fc-e41d-43c8-8db4-c00ea0fcba85,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-3c213e95-1b1c-4874-a639-15209a515c07,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-23835500-eb26-4601-bfc3-43bc0fa58398,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-520175119-172.17.0.10-1595910311981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37032,DS-ff1ccebc-35e8-4601-a319-6be053044b91,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-ac45e1e5-11cb-461a-9ed8-409cc8da6c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39580,DS-e91c2ffb-7d47-4bf7-8754-4ff4f2fae7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-3c7c35b5-e373-43ef-95d7-f17eaa57c7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-9ec544a9-fd9f-42d3-8ab5-4225902aa803,DISK], DatanodeInfoWithStorage[127.0.0.1:37146,DS-edc5b6fc-e41d-43c8-8db4-c00ea0fcba85,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-3c213e95-1b1c-4874-a639-15209a515c07,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-23835500-eb26-4601-bfc3-43bc0fa58398,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2085023256-172.17.0.10-1595910412299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39825,DS-638875d5-05a6-4dca-b61b-1939efc6d977,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-2f0e2207-ad69-4066-88fc-43befe4a32fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-54726f16-ccda-4188-8a36-326d91225b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-3d1b09c9-3782-4842-84ac-b78650627565,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-a6fe9455-e37b-4d2a-b751-8bee30611a89,DISK], DatanodeInfoWithStorage[127.0.0.1:34153,DS-b75d80fd-8d88-496f-af78-a10259313abe,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-19131768-1766-46d1-a0e7-8a1211f5797c,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-d91105ca-e667-4854-9342-7a91dce2f9f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2085023256-172.17.0.10-1595910412299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39825,DS-638875d5-05a6-4dca-b61b-1939efc6d977,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-2f0e2207-ad69-4066-88fc-43befe4a32fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-54726f16-ccda-4188-8a36-326d91225b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-3d1b09c9-3782-4842-84ac-b78650627565,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-a6fe9455-e37b-4d2a-b751-8bee30611a89,DISK], DatanodeInfoWithStorage[127.0.0.1:34153,DS-b75d80fd-8d88-496f-af78-a10259313abe,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-19131768-1766-46d1-a0e7-8a1211f5797c,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-d91105ca-e667-4854-9342-7a91dce2f9f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1241251408-172.17.0.10-1595910664628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41023,DS-21328786-8e60-49f9-9329-9c370770ffc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-47f2a962-c0c7-4a0e-9bb9-385b5fba5b23,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-4da1304a-9e1a-4999-b1ee-38f1cf33dfdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-845df7b9-5471-4104-b392-c74979696b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43784,DS-147f1007-764b-44d2-9472-b965e3e918ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-dd6bf00c-c150-445b-8f4a-b70087efe58a,DISK], DatanodeInfoWithStorage[127.0.0.1:41240,DS-dad6a00d-4938-4994-acce-bbcf37f92ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:42937,DS-0271a96a-6251-4c41-a133-d8d5ada72a2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1241251408-172.17.0.10-1595910664628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41023,DS-21328786-8e60-49f9-9329-9c370770ffc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-47f2a962-c0c7-4a0e-9bb9-385b5fba5b23,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-4da1304a-9e1a-4999-b1ee-38f1cf33dfdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-845df7b9-5471-4104-b392-c74979696b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43784,DS-147f1007-764b-44d2-9472-b965e3e918ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-dd6bf00c-c150-445b-8f4a-b70087efe58a,DISK], DatanodeInfoWithStorage[127.0.0.1:41240,DS-dad6a00d-4938-4994-acce-bbcf37f92ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:42937,DS-0271a96a-6251-4c41-a133-d8d5ada72a2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1125688481-172.17.0.10-1595910991426:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33066,DS-1c000cfd-e9dd-4252-9370-b11928de91cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-d1a0fb4a-f71e-4f46-a62c-2083e54de083,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-6d65cfe2-5de6-4710-a249-e72e9c14f546,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-35beb873-2c43-41d4-b505-87113f0556ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-ae07381f-77b1-4a88-b267-4c6a39130153,DISK], DatanodeInfoWithStorage[127.0.0.1:46500,DS-c2aff54d-33d1-412c-ae37-88e58231224a,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-fb624358-739e-47c9-aecf-74421ed2807e,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-0f1cf95b-8f0f-4d40-94e7-0513570e6ae1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1125688481-172.17.0.10-1595910991426:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33066,DS-1c000cfd-e9dd-4252-9370-b11928de91cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-d1a0fb4a-f71e-4f46-a62c-2083e54de083,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-6d65cfe2-5de6-4710-a249-e72e9c14f546,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-35beb873-2c43-41d4-b505-87113f0556ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-ae07381f-77b1-4a88-b267-4c6a39130153,DISK], DatanodeInfoWithStorage[127.0.0.1:46500,DS-c2aff54d-33d1-412c-ae37-88e58231224a,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-fb624358-739e-47c9-aecf-74421ed2807e,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-0f1cf95b-8f0f-4d40-94e7-0513570e6ae1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1859928655-172.17.0.10-1595911550659:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34638,DS-cc60564d-d839-4eb2-8b7b-1928c84d8e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-640d4244-3fb6-4ffc-9854-3dbac0dd1257,DISK], DatanodeInfoWithStorage[127.0.0.1:42684,DS-cafc8453-53c1-46e0-9bec-b989c57eedb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37749,DS-23e50a9d-46e2-429f-b611-0bb943efc76f,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-b1656efb-5473-4a43-8efa-42869c97a82c,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-7b46f3db-2943-431a-8fd9-3e40eb7ce54b,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-4dc62c2d-7325-4dc9-b33f-56b81f08f44a,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-74f8ce4b-28dc-49f7-bb35-546f26e247a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1859928655-172.17.0.10-1595911550659:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34638,DS-cc60564d-d839-4eb2-8b7b-1928c84d8e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-640d4244-3fb6-4ffc-9854-3dbac0dd1257,DISK], DatanodeInfoWithStorage[127.0.0.1:42684,DS-cafc8453-53c1-46e0-9bec-b989c57eedb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37749,DS-23e50a9d-46e2-429f-b611-0bb943efc76f,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-b1656efb-5473-4a43-8efa-42869c97a82c,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-7b46f3db-2943-431a-8fd9-3e40eb7ce54b,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-4dc62c2d-7325-4dc9-b33f-56b81f08f44a,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-74f8ce4b-28dc-49f7-bb35-546f26e247a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-340848747-172.17.0.10-1595911585061:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43153,DS-83f243e1-0166-4fd9-a256-0f8ec5388efd,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-57c83f21-3fe6-4f92-8abf-c680a8024970,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-43bc044c-0ea7-4313-a909-2c8b17fef8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-1e217bf5-340c-4285-adf8-ea433774e6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-4333b02e-a9e3-4556-8bed-aeeb0532d4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-41b0d3f7-fc19-43f7-8322-77c7f04a0ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-f5ad2040-b374-4b82-95d5-055201fb621a,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-6f49c194-1a45-458b-ba2e-0595b532b775,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-340848747-172.17.0.10-1595911585061:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43153,DS-83f243e1-0166-4fd9-a256-0f8ec5388efd,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-57c83f21-3fe6-4f92-8abf-c680a8024970,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-43bc044c-0ea7-4313-a909-2c8b17fef8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-1e217bf5-340c-4285-adf8-ea433774e6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-4333b02e-a9e3-4556-8bed-aeeb0532d4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-41b0d3f7-fc19-43f7-8322-77c7f04a0ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-f5ad2040-b374-4b82-95d5-055201fb621a,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-6f49c194-1a45-458b-ba2e-0595b532b775,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1071772052-172.17.0.10-1595911618827:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34466,DS-d88b4fbb-6dee-4c84-a6ca-a0fd67a69735,DISK], DatanodeInfoWithStorage[127.0.0.1:43173,DS-4679f8bc-756f-4dfa-8bb2-beac58394271,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-68c3b142-724c-4754-ab4e-ea7156843452,DISK], DatanodeInfoWithStorage[127.0.0.1:41935,DS-64947161-d8d0-4251-b215-082d80b972e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-c4777785-c0bb-43c8-ae97-fb46e4a03566,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-9e75703f-5318-4758-b22a-ef0feed81d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-f09eb348-5331-4eef-a84c-4242b12c2096,DISK], DatanodeInfoWithStorage[127.0.0.1:41328,DS-80c0f04b-8eb9-4c5b-9525-0385404c9f3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1071772052-172.17.0.10-1595911618827:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34466,DS-d88b4fbb-6dee-4c84-a6ca-a0fd67a69735,DISK], DatanodeInfoWithStorage[127.0.0.1:43173,DS-4679f8bc-756f-4dfa-8bb2-beac58394271,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-68c3b142-724c-4754-ab4e-ea7156843452,DISK], DatanodeInfoWithStorage[127.0.0.1:41935,DS-64947161-d8d0-4251-b215-082d80b972e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-c4777785-c0bb-43c8-ae97-fb46e4a03566,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-9e75703f-5318-4758-b22a-ef0feed81d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-f09eb348-5331-4eef-a84c-4242b12c2096,DISK], DatanodeInfoWithStorage[127.0.0.1:41328,DS-80c0f04b-8eb9-4c5b-9525-0385404c9f3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1325033883-172.17.0.10-1595911908900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44477,DS-02b965bc-0b39-4bdb-a996-08e85d538071,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-d2f01c92-a476-40ce-99b7-87d88a1bad7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-3a0767cd-fc54-42d6-9b4e-da72488b3a63,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-bbeb76c8-bc66-4ed9-acf5-281143638e41,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-f2f78727-1356-4f76-af7b-8bf23cfc4e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34646,DS-72e036e4-cd5a-4144-b6fc-a1598947f0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-d707af94-364d-4be0-86bd-819fb083ce5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-96d5122b-15db-4a1f-a43a-2fce6972158f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1325033883-172.17.0.10-1595911908900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44477,DS-02b965bc-0b39-4bdb-a996-08e85d538071,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-d2f01c92-a476-40ce-99b7-87d88a1bad7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-3a0767cd-fc54-42d6-9b4e-da72488b3a63,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-bbeb76c8-bc66-4ed9-acf5-281143638e41,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-f2f78727-1356-4f76-af7b-8bf23cfc4e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34646,DS-72e036e4-cd5a-4144-b6fc-a1598947f0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-d707af94-364d-4be0-86bd-819fb083ce5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-96d5122b-15db-4a1f-a43a-2fce6972158f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1903541892-172.17.0.10-1595912395119:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40446,DS-52b6ac9f-c000-477a-9f4a-90e555c995cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-d7a7a5d9-96f0-4568-8d2f-b42541fa3eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-2e75cd5b-e9e8-4d0e-a31a-e5163bd000af,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-d4a0c0bb-f703-411c-ae57-6b8ee02a30de,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-d9e714ff-2437-4281-b7c9-060fa3841f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-edb41f21-32bd-4e13-9192-eac057a40213,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-b1627ab8-b7b0-4534-b474-1f71c2b6e465,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-e1ddf176-4cac-466f-8b2b-97e008dc6290,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1903541892-172.17.0.10-1595912395119:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40446,DS-52b6ac9f-c000-477a-9f4a-90e555c995cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-d7a7a5d9-96f0-4568-8d2f-b42541fa3eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-2e75cd5b-e9e8-4d0e-a31a-e5163bd000af,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-d4a0c0bb-f703-411c-ae57-6b8ee02a30de,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-d9e714ff-2437-4281-b7c9-060fa3841f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-edb41f21-32bd-4e13-9192-eac057a40213,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-b1627ab8-b7b0-4534-b474-1f71c2b6e465,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-e1ddf176-4cac-466f-8b2b-97e008dc6290,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-874892849-172.17.0.10-1595912430282:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44672,DS-44616094-298b-4b1d-8266-ce6e90c202db,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-4ba68e78-33e4-4632-914b-d7b88a7ef91d,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-2bac3997-fe8e-4874-9d5c-7326cea8b6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-5ec3db5c-9705-4fc5-a825-40e2e8078c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-99a22db6-d91a-4ff3-bb7b-5baa7cad3442,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-51b19c2d-0e1d-455e-a384-12fbd78fe5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-8ce20225-cf19-4679-beaf-bb68b8152d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-108e1971-dc0c-4dbb-bc00-a4538c928fc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-874892849-172.17.0.10-1595912430282:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44672,DS-44616094-298b-4b1d-8266-ce6e90c202db,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-4ba68e78-33e4-4632-914b-d7b88a7ef91d,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-2bac3997-fe8e-4874-9d5c-7326cea8b6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-5ec3db5c-9705-4fc5-a825-40e2e8078c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-99a22db6-d91a-4ff3-bb7b-5baa7cad3442,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-51b19c2d-0e1d-455e-a384-12fbd78fe5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-8ce20225-cf19-4679-beaf-bb68b8152d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-108e1971-dc0c-4dbb-bc00-a4538c928fc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-426833749-172.17.0.10-1595913084910:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39097,DS-f93c7a7f-a9bd-47d2-be5b-2d6b0b4f6fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-5ea4c6b2-e18b-43bc-99da-2be0ac77c000,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-0fbf81b7-9e29-41fd-b5e3-9a9aebb48839,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-f53b1565-b1e7-4bf9-8dc2-0d8a7e95fdfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-425c3466-a510-4baa-a9a1-d19d7a031184,DISK], DatanodeInfoWithStorage[127.0.0.1:39798,DS-88ab0a60-59ea-4ae5-bfe6-77b4628edfba,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-40dc4e81-4e08-4bf9-8dae-2368ac2234d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33031,DS-086421b1-86b0-499f-9608-2faa637241d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-426833749-172.17.0.10-1595913084910:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39097,DS-f93c7a7f-a9bd-47d2-be5b-2d6b0b4f6fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-5ea4c6b2-e18b-43bc-99da-2be0ac77c000,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-0fbf81b7-9e29-41fd-b5e3-9a9aebb48839,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-f53b1565-b1e7-4bf9-8dc2-0d8a7e95fdfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-425c3466-a510-4baa-a9a1-d19d7a031184,DISK], DatanodeInfoWithStorage[127.0.0.1:39798,DS-88ab0a60-59ea-4ae5-bfe6-77b4628edfba,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-40dc4e81-4e08-4bf9-8dae-2368ac2234d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33031,DS-086421b1-86b0-499f-9608-2faa637241d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5362
