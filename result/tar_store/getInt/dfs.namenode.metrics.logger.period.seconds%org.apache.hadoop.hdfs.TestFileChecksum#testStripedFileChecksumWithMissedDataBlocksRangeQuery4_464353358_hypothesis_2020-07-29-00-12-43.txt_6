reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-93545883-172.17.0.7-1595981574556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42980,DS-b977a3be-1fd7-4467-8a40-dd6b7ea543a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-b04b7148-5e3c-4462-8954-9a7750591afc,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-b13a110b-169a-49bb-8732-601dbf6c4eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-319de46c-12ee-4fa4-adba-f4207728e8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-47dd0441-c486-4449-abfe-8dadf01eb77f,DISK], DatanodeInfoWithStorage[127.0.0.1:46457,DS-9e637b48-4ce4-408b-ba4a-22104d1eb3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-0098b45c-c229-4457-9e1d-3b2464e88452,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-07d413df-339b-46ed-a199-5143066e11f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-93545883-172.17.0.7-1595981574556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42980,DS-b977a3be-1fd7-4467-8a40-dd6b7ea543a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-b04b7148-5e3c-4462-8954-9a7750591afc,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-b13a110b-169a-49bb-8732-601dbf6c4eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-319de46c-12ee-4fa4-adba-f4207728e8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-47dd0441-c486-4449-abfe-8dadf01eb77f,DISK], DatanodeInfoWithStorage[127.0.0.1:46457,DS-9e637b48-4ce4-408b-ba4a-22104d1eb3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-0098b45c-c229-4457-9e1d-3b2464e88452,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-07d413df-339b-46ed-a199-5143066e11f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1739060532-172.17.0.7-1595981776658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45148,DS-cc3a077b-5ae0-4e29-9fe4-2b679ee79b53,DISK], DatanodeInfoWithStorage[127.0.0.1:36443,DS-fe1ba889-d328-4d8d-a881-b11f7a2b5bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39946,DS-8c3e9ddc-4c0e-4da1-b062-c01ec3933d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-3c77a070-a30b-421b-9032-d81964656695,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-3b2ff7fc-76f5-4a18-929e-843a8589cda8,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-dba4907f-711f-4b46-a113-4f42d341dbb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-ee2daf72-8efe-48b7-903e-5720fab6fae6,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-d5ccddca-8e99-4b9b-85dd-1eb8b268bef7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1739060532-172.17.0.7-1595981776658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45148,DS-cc3a077b-5ae0-4e29-9fe4-2b679ee79b53,DISK], DatanodeInfoWithStorage[127.0.0.1:36443,DS-fe1ba889-d328-4d8d-a881-b11f7a2b5bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39946,DS-8c3e9ddc-4c0e-4da1-b062-c01ec3933d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-3c77a070-a30b-421b-9032-d81964656695,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-3b2ff7fc-76f5-4a18-929e-843a8589cda8,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-dba4907f-711f-4b46-a113-4f42d341dbb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-ee2daf72-8efe-48b7-903e-5720fab6fae6,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-d5ccddca-8e99-4b9b-85dd-1eb8b268bef7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905183247-172.17.0.7-1595982250221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40227,DS-4abdd946-b955-4b6e-9994-f2330684c483,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-90dd2714-516c-401b-99be-e502c3a826a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-f2ec293c-9668-40ba-b954-0e71546275af,DISK], DatanodeInfoWithStorage[127.0.0.1:34400,DS-c871fef4-a41e-489f-8d0c-13bede54e9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-4437f093-cc86-480a-b866-f5e7b07a63f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-a84fa857-3ecf-4863-9a9f-a7f8ef1daed1,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-c2645f16-4434-4bdf-b643-7b726c6edab5,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-e19843f9-6bab-442a-b4e4-2b8e8ee56e43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905183247-172.17.0.7-1595982250221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40227,DS-4abdd946-b955-4b6e-9994-f2330684c483,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-90dd2714-516c-401b-99be-e502c3a826a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-f2ec293c-9668-40ba-b954-0e71546275af,DISK], DatanodeInfoWithStorage[127.0.0.1:34400,DS-c871fef4-a41e-489f-8d0c-13bede54e9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-4437f093-cc86-480a-b866-f5e7b07a63f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-a84fa857-3ecf-4863-9a9f-a7f8ef1daed1,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-c2645f16-4434-4bdf-b643-7b726c6edab5,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-e19843f9-6bab-442a-b4e4-2b8e8ee56e43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1610166690-172.17.0.7-1595982354524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38830,DS-e78b8bdb-e01d-40c6-a76c-a7ae62a4b3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-dcd5fbd7-e46a-4249-bee8-8648b9a30ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-8970cc7e-1ec1-47df-ba05-8e683ce6566f,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-6c71d13d-c64a-456e-8998-a559dfd9a620,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-6bab277f-e832-4250-b0ae-242646734ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-7270c4cc-c2f3-4483-b33f-934dccc936b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-206cd6cd-c946-4394-bafc-ff450f9a89ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43879,DS-816df9f9-c8bf-492f-b55c-48f7d269255f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1610166690-172.17.0.7-1595982354524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38830,DS-e78b8bdb-e01d-40c6-a76c-a7ae62a4b3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-dcd5fbd7-e46a-4249-bee8-8648b9a30ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-8970cc7e-1ec1-47df-ba05-8e683ce6566f,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-6c71d13d-c64a-456e-8998-a559dfd9a620,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-6bab277f-e832-4250-b0ae-242646734ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-7270c4cc-c2f3-4483-b33f-934dccc936b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-206cd6cd-c946-4394-bafc-ff450f9a89ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43879,DS-816df9f9-c8bf-492f-b55c-48f7d269255f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1612997881-172.17.0.7-1595982738925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37138,DS-eb97d553-e985-40f3-8f71-4ea13eb6a270,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-c2e0d048-acd0-40b4-8adf-d4fd330aae5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-43fc6151-93fb-420f-8644-defdd4406cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-e8d981a9-b664-4619-a911-5c609a8cf0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-0cdf234b-ebf8-4a59-9187-f64abba0f54a,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-71cc77df-ab31-4020-ab9e-c8a3b8ef29cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-ae6f511e-f796-437e-81c7-53dfe43f4ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-6fcf3b8d-f5e1-4eb3-85ef-e48f3d422b2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1612997881-172.17.0.7-1595982738925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37138,DS-eb97d553-e985-40f3-8f71-4ea13eb6a270,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-c2e0d048-acd0-40b4-8adf-d4fd330aae5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-43fc6151-93fb-420f-8644-defdd4406cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-e8d981a9-b664-4619-a911-5c609a8cf0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-0cdf234b-ebf8-4a59-9187-f64abba0f54a,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-71cc77df-ab31-4020-ab9e-c8a3b8ef29cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-ae6f511e-f796-437e-81c7-53dfe43f4ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-6fcf3b8d-f5e1-4eb3-85ef-e48f3d422b2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1132679561-172.17.0.7-1595982951719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42026,DS-53e2f0ca-cc6c-463a-8800-5c0b8e9d6939,DISK], DatanodeInfoWithStorage[127.0.0.1:37184,DS-c1c5ce47-1a28-4414-88d6-3d6aed053d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40077,DS-c6e89b60-da49-4f10-baf8-17f1364d4da9,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-c17173d0-3379-4b97-a23b-4289cfeb8a48,DISK], DatanodeInfoWithStorage[127.0.0.1:38330,DS-6994b66e-a1d3-4ca0-b5b7-6fceb3e55a98,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-2b930ea8-6169-45e3-a73a-0cfece5e694e,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-beb2298b-e11e-45e2-a563-c406c31f8174,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-6be951a1-c432-4270-9053-4e9aab2af0fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1132679561-172.17.0.7-1595982951719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42026,DS-53e2f0ca-cc6c-463a-8800-5c0b8e9d6939,DISK], DatanodeInfoWithStorage[127.0.0.1:37184,DS-c1c5ce47-1a28-4414-88d6-3d6aed053d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40077,DS-c6e89b60-da49-4f10-baf8-17f1364d4da9,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-c17173d0-3379-4b97-a23b-4289cfeb8a48,DISK], DatanodeInfoWithStorage[127.0.0.1:38330,DS-6994b66e-a1d3-4ca0-b5b7-6fceb3e55a98,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-2b930ea8-6169-45e3-a73a-0cfece5e694e,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-beb2298b-e11e-45e2-a563-c406c31f8174,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-6be951a1-c432-4270-9053-4e9aab2af0fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-78931869-172.17.0.7-1595983022115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36484,DS-bcd5d752-8a34-4058-a6b6-c0594b6745a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-4789d793-08a2-4bd5-b46d-d2a7a59f49d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45490,DS-8f1e045f-fba2-4221-91b9-9c45bc810979,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-70f85211-8950-4432-9ef7-8992ab2b2236,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-1d0a5f01-dca3-4473-b39b-763a80f2a550,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-b7ecb6fe-b7fa-43d7-a3e1-f6726d94ef5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43386,DS-c43bd477-a1f2-4861-8011-3a2903968ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-c7060ada-0a57-42ab-b0c4-b6118b5d990f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-78931869-172.17.0.7-1595983022115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36484,DS-bcd5d752-8a34-4058-a6b6-c0594b6745a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-4789d793-08a2-4bd5-b46d-d2a7a59f49d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45490,DS-8f1e045f-fba2-4221-91b9-9c45bc810979,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-70f85211-8950-4432-9ef7-8992ab2b2236,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-1d0a5f01-dca3-4473-b39b-763a80f2a550,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-b7ecb6fe-b7fa-43d7-a3e1-f6726d94ef5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43386,DS-c43bd477-a1f2-4861-8011-3a2903968ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-c7060ada-0a57-42ab-b0c4-b6118b5d990f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2102846271-172.17.0.7-1595983109945:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36856,DS-f75a9eeb-e11e-4307-8881-13f2849f488e,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-35527437-5892-4232-b4ee-023e0d7c38a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-b09b3520-050a-4c75-917e-8bac331ed79b,DISK], DatanodeInfoWithStorage[127.0.0.1:44364,DS-1eadff8b-66ea-4ac3-920a-f8e81a41e734,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-7b2326a7-8094-4192-9780-ad659fe67152,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-d680927d-b52a-4db1-bee4-0519fab2db5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35056,DS-8c6f89fc-ac90-4fc0-b985-1b8c7bec73df,DISK], DatanodeInfoWithStorage[127.0.0.1:34111,DS-16866937-80b2-47b1-bd4e-2e3f842afa7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2102846271-172.17.0.7-1595983109945:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36856,DS-f75a9eeb-e11e-4307-8881-13f2849f488e,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-35527437-5892-4232-b4ee-023e0d7c38a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-b09b3520-050a-4c75-917e-8bac331ed79b,DISK], DatanodeInfoWithStorage[127.0.0.1:44364,DS-1eadff8b-66ea-4ac3-920a-f8e81a41e734,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-7b2326a7-8094-4192-9780-ad659fe67152,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-d680927d-b52a-4db1-bee4-0519fab2db5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35056,DS-8c6f89fc-ac90-4fc0-b985-1b8c7bec73df,DISK], DatanodeInfoWithStorage[127.0.0.1:34111,DS-16866937-80b2-47b1-bd4e-2e3f842afa7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1389197259-172.17.0.7-1595983475809:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35541,DS-0060503f-519a-42b1-ba5a-44e56fb5e263,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-a70109e5-2c2a-4f24-8d0a-b599b4c42676,DISK], DatanodeInfoWithStorage[127.0.0.1:42784,DS-d8e93053-93ea-46f4-8665-b073baff838a,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-618e7649-796a-463d-bbc2-2b987807c8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-4627d813-a8e1-4d17-becc-dac60c75a14c,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-b2a312e8-13da-4574-bbed-033a916c70af,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-4f82b4ad-c1b5-467c-a07c-2d5aa9a56dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-8d48deb6-d069-4ff6-bb80-358b33382dfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1389197259-172.17.0.7-1595983475809:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35541,DS-0060503f-519a-42b1-ba5a-44e56fb5e263,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-a70109e5-2c2a-4f24-8d0a-b599b4c42676,DISK], DatanodeInfoWithStorage[127.0.0.1:42784,DS-d8e93053-93ea-46f4-8665-b073baff838a,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-618e7649-796a-463d-bbc2-2b987807c8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-4627d813-a8e1-4d17-becc-dac60c75a14c,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-b2a312e8-13da-4574-bbed-033a916c70af,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-4f82b4ad-c1b5-467c-a07c-2d5aa9a56dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-8d48deb6-d069-4ff6-bb80-358b33382dfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-327243701-172.17.0.7-1595983815093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43519,DS-8b2f432d-1f1a-455e-a155-9278c97d89cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-64da5e23-7b09-4fba-85a3-b96e304aab13,DISK], DatanodeInfoWithStorage[127.0.0.1:39609,DS-dd809159-f34e-42a3-a6fb-8871fbc1d95a,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-654d411b-6c36-4c02-86bf-06c519fcb9da,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-a261a15d-b7d8-4e35-a4a0-acc281307aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-1fccf8bf-6310-48b2-8421-f0b0cdfab023,DISK], DatanodeInfoWithStorage[127.0.0.1:38862,DS-241dc785-d614-46ca-aef0-8f53412e1c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-c6e3005c-7d10-4c40-834e-5d1d5b380493,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-327243701-172.17.0.7-1595983815093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43519,DS-8b2f432d-1f1a-455e-a155-9278c97d89cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-64da5e23-7b09-4fba-85a3-b96e304aab13,DISK], DatanodeInfoWithStorage[127.0.0.1:39609,DS-dd809159-f34e-42a3-a6fb-8871fbc1d95a,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-654d411b-6c36-4c02-86bf-06c519fcb9da,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-a261a15d-b7d8-4e35-a4a0-acc281307aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-1fccf8bf-6310-48b2-8421-f0b0cdfab023,DISK], DatanodeInfoWithStorage[127.0.0.1:38862,DS-241dc785-d614-46ca-aef0-8f53412e1c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-c6e3005c-7d10-4c40-834e-5d1d5b380493,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-183307138-172.17.0.7-1595983919852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33254,DS-5f09970e-f8cf-4f67-a8d8-be01514be2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-314e8c87-0958-49ba-ba5f-118377908e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-4c3742a1-8a74-40c9-8cae-d79b41b9bcd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-09cc3922-2bf2-42d2-b487-0d6b80e78a49,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-7e8d9635-5506-4ff2-8567-b2033b95625f,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-a151c6e7-20b2-4620-a6ad-692a2b889ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-6af45e8c-fef4-477f-956b-db2b239077f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-b60e7d7c-18e0-409d-ac3c-a5a896955854,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-183307138-172.17.0.7-1595983919852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33254,DS-5f09970e-f8cf-4f67-a8d8-be01514be2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-314e8c87-0958-49ba-ba5f-118377908e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-4c3742a1-8a74-40c9-8cae-d79b41b9bcd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-09cc3922-2bf2-42d2-b487-0d6b80e78a49,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-7e8d9635-5506-4ff2-8567-b2033b95625f,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-a151c6e7-20b2-4620-a6ad-692a2b889ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-6af45e8c-fef4-477f-956b-db2b239077f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-b60e7d7c-18e0-409d-ac3c-a5a896955854,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1748856901-172.17.0.7-1595984289323:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37035,DS-95420e56-c67a-469a-9363-2d0bb10dd4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-360efdcd-fd9d-44c6-8e38-85c8b076aa30,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-fae0aa26-9b4b-49ec-8020-f79c2079016d,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-8e5128bd-8a91-41a0-a0d5-98bb8f5a37e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40421,DS-883267ee-b6b2-4635-b8f4-6cf20290336c,DISK], DatanodeInfoWithStorage[127.0.0.1:41361,DS-778147cf-bd8a-47b3-ac17-dbb63c2581a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44211,DS-cbe6b715-6eb8-43c9-8bae-cd13eb85c26d,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-cdb0091b-8c9c-4eb1-8462-614b06d6ddaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1748856901-172.17.0.7-1595984289323:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37035,DS-95420e56-c67a-469a-9363-2d0bb10dd4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-360efdcd-fd9d-44c6-8e38-85c8b076aa30,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-fae0aa26-9b4b-49ec-8020-f79c2079016d,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-8e5128bd-8a91-41a0-a0d5-98bb8f5a37e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40421,DS-883267ee-b6b2-4635-b8f4-6cf20290336c,DISK], DatanodeInfoWithStorage[127.0.0.1:41361,DS-778147cf-bd8a-47b3-ac17-dbb63c2581a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44211,DS-cbe6b715-6eb8-43c9-8bae-cd13eb85c26d,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-cdb0091b-8c9c-4eb1-8462-614b06d6ddaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1555825811-172.17.0.7-1595984605334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34549,DS-5e00fb8f-f6be-4c3e-b398-6b8557c414a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-c0a0236f-27c1-4938-81ae-3933ba7cc854,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-f0cd46a9-7f22-4dc1-b2fc-05f021af7d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-a55c48f8-189b-4abb-aa7a-675d25998f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43760,DS-36535005-75d8-4467-a47a-08da03d71afa,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-23d19377-cccb-445a-b000-b44c07d5855b,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-96043682-64a9-4552-b314-958a128d0102,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-a769bf8f-cf49-40e9-a2d4-df6615a1abd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1555825811-172.17.0.7-1595984605334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34549,DS-5e00fb8f-f6be-4c3e-b398-6b8557c414a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-c0a0236f-27c1-4938-81ae-3933ba7cc854,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-f0cd46a9-7f22-4dc1-b2fc-05f021af7d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-a55c48f8-189b-4abb-aa7a-675d25998f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43760,DS-36535005-75d8-4467-a47a-08da03d71afa,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-23d19377-cccb-445a-b000-b44c07d5855b,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-96043682-64a9-4552-b314-958a128d0102,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-a769bf8f-cf49-40e9-a2d4-df6615a1abd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-793504815-172.17.0.7-1595984678321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36560,DS-c2bce3ce-6709-479b-88a7-19aff2850f71,DISK], DatanodeInfoWithStorage[127.0.0.1:43498,DS-0e259687-ee53-46a0-87c6-bdf80fb3b790,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-63866373-e4a4-4304-b8dc-4d3f9fedde2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36084,DS-d8ae6b57-2da7-41fa-8b35-61e4f0c4ac93,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-cb4209a6-a6ee-456d-ae2b-8dccc839aaac,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-22478162-bccd-4f9a-9d3e-103d0c8c72cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39408,DS-4dae693b-41a6-402b-808a-871d9e86b05e,DISK], DatanodeInfoWithStorage[127.0.0.1:46510,DS-5f63c23e-46c6-4560-ae75-6120aded5153,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-793504815-172.17.0.7-1595984678321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36560,DS-c2bce3ce-6709-479b-88a7-19aff2850f71,DISK], DatanodeInfoWithStorage[127.0.0.1:43498,DS-0e259687-ee53-46a0-87c6-bdf80fb3b790,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-63866373-e4a4-4304-b8dc-4d3f9fedde2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36084,DS-d8ae6b57-2da7-41fa-8b35-61e4f0c4ac93,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-cb4209a6-a6ee-456d-ae2b-8dccc839aaac,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-22478162-bccd-4f9a-9d3e-103d0c8c72cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39408,DS-4dae693b-41a6-402b-808a-871d9e86b05e,DISK], DatanodeInfoWithStorage[127.0.0.1:46510,DS-5f63c23e-46c6-4560-ae75-6120aded5153,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2090272415-172.17.0.7-1595985421786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41900,DS-2017fd82-5753-4a30-8889-50ac98ee486f,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-29cb32b3-e842-4489-b3ad-feb345083315,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-637e579b-3d63-4d93-ae42-2c9681b23573,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-3d1ec3f5-3b1e-4218-8230-46d19e15b663,DISK], DatanodeInfoWithStorage[127.0.0.1:40575,DS-05b90934-4d01-4493-8d5a-df31c890f69e,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-af837a0b-be47-41f4-87e5-79ea315721d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-f38cd654-38f6-4b45-8108-731a60c453ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-b5287d03-0d7b-4af9-83a0-e3730a6d208c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2090272415-172.17.0.7-1595985421786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41900,DS-2017fd82-5753-4a30-8889-50ac98ee486f,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-29cb32b3-e842-4489-b3ad-feb345083315,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-637e579b-3d63-4d93-ae42-2c9681b23573,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-3d1ec3f5-3b1e-4218-8230-46d19e15b663,DISK], DatanodeInfoWithStorage[127.0.0.1:40575,DS-05b90934-4d01-4493-8d5a-df31c890f69e,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-af837a0b-be47-41f4-87e5-79ea315721d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-f38cd654-38f6-4b45-8108-731a60c453ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-b5287d03-0d7b-4af9-83a0-e3730a6d208c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2016398840-172.17.0.7-1595985910263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44668,DS-04e97c0b-0c48-45ba-a718-36229e980f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-9f4c6a10-a97a-42c5-bba6-b9ca35eeaa04,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-68e1c95b-5cf2-432c-bb57-e23d47856c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-4359b69d-e345-401a-94c5-94d9ca03288f,DISK], DatanodeInfoWithStorage[127.0.0.1:34513,DS-6c28e55b-5a87-47c4-9af7-6e2bdba0785c,DISK], DatanodeInfoWithStorage[127.0.0.1:36272,DS-89ea1f30-7cfe-4bc6-9b96-583ba33d9be6,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-82046559-ce8d-4209-82b4-55709fa45798,DISK], DatanodeInfoWithStorage[127.0.0.1:36168,DS-a854964b-dfb3-424b-9a9a-0d9872488237,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2016398840-172.17.0.7-1595985910263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44668,DS-04e97c0b-0c48-45ba-a718-36229e980f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-9f4c6a10-a97a-42c5-bba6-b9ca35eeaa04,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-68e1c95b-5cf2-432c-bb57-e23d47856c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-4359b69d-e345-401a-94c5-94d9ca03288f,DISK], DatanodeInfoWithStorage[127.0.0.1:34513,DS-6c28e55b-5a87-47c4-9af7-6e2bdba0785c,DISK], DatanodeInfoWithStorage[127.0.0.1:36272,DS-89ea1f30-7cfe-4bc6-9b96-583ba33d9be6,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-82046559-ce8d-4209-82b4-55709fa45798,DISK], DatanodeInfoWithStorage[127.0.0.1:36168,DS-a854964b-dfb3-424b-9a9a-0d9872488237,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-433310184-172.17.0.7-1595986141607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45514,DS-06155bbc-a649-494c-bd2f-d9211e0efaa6,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-45b24a88-1118-495e-841a-e70fb799bbb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-0a76e9a5-83a0-4b73-9ef2-c7b5b11e4a29,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-7a9a971c-35c9-4878-a866-0f9134cf2aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-48abd96f-c198-48e1-b054-f234bd86d254,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-83691423-fbe8-48d8-af09-8cebe702eddf,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-b3848df8-df18-4e54-9220-904d91eab34d,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-f196c3ca-ed89-45bd-9650-99ad27e26d4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-433310184-172.17.0.7-1595986141607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45514,DS-06155bbc-a649-494c-bd2f-d9211e0efaa6,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-45b24a88-1118-495e-841a-e70fb799bbb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-0a76e9a5-83a0-4b73-9ef2-c7b5b11e4a29,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-7a9a971c-35c9-4878-a866-0f9134cf2aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-48abd96f-c198-48e1-b054-f234bd86d254,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-83691423-fbe8-48d8-af09-8cebe702eddf,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-b3848df8-df18-4e54-9220-904d91eab34d,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-f196c3ca-ed89-45bd-9650-99ad27e26d4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-895619757-172.17.0.7-1595986473185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37109,DS-12b26039-b9e4-4168-959b-b149e8b2a6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44679,DS-162bf270-d3e9-4126-ad6b-1ce8b63e6504,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-5cb04a11-50a8-40ab-bd0b-70799b04797e,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-e708f241-1a97-4659-a0e3-e4402ea00eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-ded9b986-5497-44b3-beb6-a733590d38b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-108c9ced-b737-439a-870e-d200711e3930,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-5f09abf7-24b1-46c3-a237-98f4ebed84cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-94a66212-9515-4294-84e6-6d91a6bde082,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-895619757-172.17.0.7-1595986473185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37109,DS-12b26039-b9e4-4168-959b-b149e8b2a6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44679,DS-162bf270-d3e9-4126-ad6b-1ce8b63e6504,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-5cb04a11-50a8-40ab-bd0b-70799b04797e,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-e708f241-1a97-4659-a0e3-e4402ea00eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-ded9b986-5497-44b3-beb6-a733590d38b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-108c9ced-b737-439a-870e-d200711e3930,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-5f09abf7-24b1-46c3-a237-98f4ebed84cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-94a66212-9515-4294-84e6-6d91a6bde082,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1119027320-172.17.0.7-1595986545694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43795,DS-f9f11f8a-78c1-4682-be72-b6d4067e912f,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-90c0ca63-78ea-4a94-b75f-def6647aba69,DISK], DatanodeInfoWithStorage[127.0.0.1:32958,DS-1ef43ad8-f11b-416d-bc57-b580a114f58e,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-cc8f8da3-afc0-4407-a217-36b038f05faf,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-46a2ecb5-8653-4241-8f27-a728a7d30691,DISK], DatanodeInfoWithStorage[127.0.0.1:38600,DS-b7b9fa97-1345-44b6-a5bb-04e11192b57d,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-4ae09d8a-e507-48b9-80d1-64825d178107,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-2b07a95a-86a7-48d0-9b30-2ad03f92a654,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1119027320-172.17.0.7-1595986545694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43795,DS-f9f11f8a-78c1-4682-be72-b6d4067e912f,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-90c0ca63-78ea-4a94-b75f-def6647aba69,DISK], DatanodeInfoWithStorage[127.0.0.1:32958,DS-1ef43ad8-f11b-416d-bc57-b580a114f58e,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-cc8f8da3-afc0-4407-a217-36b038f05faf,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-46a2ecb5-8653-4241-8f27-a728a7d30691,DISK], DatanodeInfoWithStorage[127.0.0.1:38600,DS-b7b9fa97-1345-44b6-a5bb-04e11192b57d,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-4ae09d8a-e507-48b9-80d1-64825d178107,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-2b07a95a-86a7-48d0-9b30-2ad03f92a654,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5389
