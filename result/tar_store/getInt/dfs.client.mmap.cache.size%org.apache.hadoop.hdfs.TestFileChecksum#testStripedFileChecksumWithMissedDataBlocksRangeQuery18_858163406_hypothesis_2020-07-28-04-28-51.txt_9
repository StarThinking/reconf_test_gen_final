reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1127502133-172.17.0.18-1595910575401:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37957,DS-4ff1c2a7-6790-4e30-b2cc-8945e11b7d51,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-df1dbf7d-742c-4966-bf56-291ddef139e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-1e6bbb36-8bdd-4191-8a64-d3b07fab02de,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-344f2917-19c2-46d3-bf84-69e53cde2060,DISK], DatanodeInfoWithStorage[127.0.0.1:40548,DS-8275755c-5116-4729-a673-5316ca54c665,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-435de54f-b2da-41ed-8da4-d13181018999,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-66f6f6db-2f65-4244-8c92-1ce42dd9e0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-7a84f066-61c2-4db4-87d0-316164a50c3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1127502133-172.17.0.18-1595910575401:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37957,DS-4ff1c2a7-6790-4e30-b2cc-8945e11b7d51,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-df1dbf7d-742c-4966-bf56-291ddef139e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-1e6bbb36-8bdd-4191-8a64-d3b07fab02de,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-344f2917-19c2-46d3-bf84-69e53cde2060,DISK], DatanodeInfoWithStorage[127.0.0.1:40548,DS-8275755c-5116-4729-a673-5316ca54c665,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-435de54f-b2da-41ed-8da4-d13181018999,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-66f6f6db-2f65-4244-8c92-1ce42dd9e0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-7a84f066-61c2-4db4-87d0-316164a50c3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1417457892-172.17.0.18-1595910635363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35006,DS-c15d5642-9851-42fa-a3c7-e26d8f4d8287,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-52a2ca94-4346-4466-9d64-978ad5797640,DISK], DatanodeInfoWithStorage[127.0.0.1:35118,DS-044b70d8-b860-41f3-ba1a-affca5399bad,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-904fc2ed-95ae-4209-a754-193703ba71e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36211,DS-7108e00e-3bc7-4846-9dc0-8626215a0553,DISK], DatanodeInfoWithStorage[127.0.0.1:36088,DS-a546695b-a5b3-4546-8ae2-14c58c364fad,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-51ed67fd-c520-4c93-943b-7785d1ab37d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33950,DS-e95786a0-bc2f-46dd-9c8c-08c105266034,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1417457892-172.17.0.18-1595910635363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35006,DS-c15d5642-9851-42fa-a3c7-e26d8f4d8287,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-52a2ca94-4346-4466-9d64-978ad5797640,DISK], DatanodeInfoWithStorage[127.0.0.1:35118,DS-044b70d8-b860-41f3-ba1a-affca5399bad,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-904fc2ed-95ae-4209-a754-193703ba71e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36211,DS-7108e00e-3bc7-4846-9dc0-8626215a0553,DISK], DatanodeInfoWithStorage[127.0.0.1:36088,DS-a546695b-a5b3-4546-8ae2-14c58c364fad,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-51ed67fd-c520-4c93-943b-7785d1ab37d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33950,DS-e95786a0-bc2f-46dd-9c8c-08c105266034,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1414279317-172.17.0.18-1595910665458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36738,DS-bfac3e70-1802-4b47-afc6-45b7ae929960,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-e85a29c7-4bbb-4fb9-8be5-4c0f345b130f,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-15654642-22bc-4722-be5a-96def44cf5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-63def22b-b058-4fda-882a-edb34ac5cf49,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-99160a55-3f03-488c-a08e-e91576884395,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-1337c7ac-4c93-4033-83a5-4213b61e1e16,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-a9b1edb2-5821-4c9f-b881-9daca263dba1,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-f695348e-df55-42d9-a32b-cb27c5570b9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1414279317-172.17.0.18-1595910665458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36738,DS-bfac3e70-1802-4b47-afc6-45b7ae929960,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-e85a29c7-4bbb-4fb9-8be5-4c0f345b130f,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-15654642-22bc-4722-be5a-96def44cf5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-63def22b-b058-4fda-882a-edb34ac5cf49,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-99160a55-3f03-488c-a08e-e91576884395,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-1337c7ac-4c93-4033-83a5-4213b61e1e16,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-a9b1edb2-5821-4c9f-b881-9daca263dba1,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-f695348e-df55-42d9-a32b-cb27c5570b9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-315019911-172.17.0.18-1595910793911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38026,DS-b456a487-3172-457f-bfbc-8464ca71c431,DISK], DatanodeInfoWithStorage[127.0.0.1:45109,DS-0eb36647-a565-493a-af94-1995940432ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-78b302e1-a6b3-43c5-b6a0-7241eef01d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-71df4fc1-c811-4462-b799-9ae8224bfa3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-28c7f402-a20e-4e3a-b95d-e54f67ef265d,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-30746f3c-7642-40c0-a7cd-b59be85da1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-56cfc132-cf2d-4ee4-9910-ae7fc934b051,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-81cd36dd-16eb-4069-8eb4-319b9b426470,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-315019911-172.17.0.18-1595910793911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38026,DS-b456a487-3172-457f-bfbc-8464ca71c431,DISK], DatanodeInfoWithStorage[127.0.0.1:45109,DS-0eb36647-a565-493a-af94-1995940432ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-78b302e1-a6b3-43c5-b6a0-7241eef01d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-71df4fc1-c811-4462-b799-9ae8224bfa3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-28c7f402-a20e-4e3a-b95d-e54f67ef265d,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-30746f3c-7642-40c0-a7cd-b59be85da1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-56cfc132-cf2d-4ee4-9910-ae7fc934b051,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-81cd36dd-16eb-4069-8eb4-319b9b426470,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2026254520-172.17.0.18-1595910820573:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40285,DS-3916a25a-7ca3-4c9b-97ae-dc1453dd7aee,DISK], DatanodeInfoWithStorage[127.0.0.1:34208,DS-c356a2bc-61d8-45d5-9ccb-94d6af5878cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-764cee5b-96cf-45b9-b482-8bba376d220d,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-24d903d7-6b29-415a-8f82-f190b76af34e,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-8d8cb809-bb62-4140-981e-9f75f4a555aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-41fd9df9-fddf-4786-b3ed-988efb6a76a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-4b8fd819-7dd7-4e9c-a88d-af1ab49eec6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-71752885-b12e-493a-b707-9b079aeddf4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2026254520-172.17.0.18-1595910820573:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40285,DS-3916a25a-7ca3-4c9b-97ae-dc1453dd7aee,DISK], DatanodeInfoWithStorage[127.0.0.1:34208,DS-c356a2bc-61d8-45d5-9ccb-94d6af5878cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-764cee5b-96cf-45b9-b482-8bba376d220d,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-24d903d7-6b29-415a-8f82-f190b76af34e,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-8d8cb809-bb62-4140-981e-9f75f4a555aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-41fd9df9-fddf-4786-b3ed-988efb6a76a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-4b8fd819-7dd7-4e9c-a88d-af1ab49eec6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-71752885-b12e-493a-b707-9b079aeddf4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-585492623-172.17.0.18-1595911060686:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43431,DS-b5c1efc6-b00f-4c13-b87e-efd8ac492b73,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-0279cf26-6dd6-47f6-af27-ac0120e9fd10,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-1731cb9e-9532-4d4d-bd0b-5380f5a2d9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42353,DS-a1a139e4-2e5f-4b72-a1cc-d0c87606846f,DISK], DatanodeInfoWithStorage[127.0.0.1:39807,DS-78435b41-39b2-4c02-bd76-4594ea07afd6,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-69b31dd3-885d-41c1-b186-3cda9c533813,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-a1808007-e1e9-4a54-a3c8-22ef4e4fba7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-4c242c10-6c5c-4d8f-8d63-f8b1c3733ff0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-585492623-172.17.0.18-1595911060686:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43431,DS-b5c1efc6-b00f-4c13-b87e-efd8ac492b73,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-0279cf26-6dd6-47f6-af27-ac0120e9fd10,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-1731cb9e-9532-4d4d-bd0b-5380f5a2d9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42353,DS-a1a139e4-2e5f-4b72-a1cc-d0c87606846f,DISK], DatanodeInfoWithStorage[127.0.0.1:39807,DS-78435b41-39b2-4c02-bd76-4594ea07afd6,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-69b31dd3-885d-41c1-b186-3cda9c533813,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-a1808007-e1e9-4a54-a3c8-22ef4e4fba7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-4c242c10-6c5c-4d8f-8d63-f8b1c3733ff0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-659279688-172.17.0.18-1595911255650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40620,DS-ab10baeb-dd61-40aa-b01a-bcc01ef2a673,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-69ca5b28-ad32-409b-b0e8-4a9659cdcf7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46814,DS-7a15733e-bef3-49d7-a35d-e519c8d8ad6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-39a2715c-bb3b-4d02-9fbb-016ea54ed7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-31429435-1a09-4b18-9ebe-bcd128eb1168,DISK], DatanodeInfoWithStorage[127.0.0.1:35427,DS-b1b734a3-2bd1-4262-a381-c220f96f8845,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-c2f3c10a-def4-46a9-a34a-b7bbdbe82821,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-ccf4173a-0e6c-4bc4-9f03-5c9b8988faa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-659279688-172.17.0.18-1595911255650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40620,DS-ab10baeb-dd61-40aa-b01a-bcc01ef2a673,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-69ca5b28-ad32-409b-b0e8-4a9659cdcf7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46814,DS-7a15733e-bef3-49d7-a35d-e519c8d8ad6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-39a2715c-bb3b-4d02-9fbb-016ea54ed7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-31429435-1a09-4b18-9ebe-bcd128eb1168,DISK], DatanodeInfoWithStorage[127.0.0.1:35427,DS-b1b734a3-2bd1-4262-a381-c220f96f8845,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-c2f3c10a-def4-46a9-a34a-b7bbdbe82821,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-ccf4173a-0e6c-4bc4-9f03-5c9b8988faa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1903789462-172.17.0.18-1595911325654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46435,DS-4546883d-e3aa-4afd-a610-85839669ef4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-bc89f0e8-da6e-4bdf-b3e7-68519b85d969,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-5d65d27c-7226-4838-86ca-2d9e66e9ea56,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-f2dd537b-8ae0-4987-a135-5ea7fb773245,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-903f4bd0-c45e-4f7b-a55d-b425f3fa0047,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-5c01144a-0ac1-48c3-948a-47758a391610,DISK], DatanodeInfoWithStorage[127.0.0.1:33682,DS-0d900324-a462-46e1-94f1-2e0673f65837,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-59a071d1-cdd3-4ff6-9164-5cf76ec8c095,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1903789462-172.17.0.18-1595911325654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46435,DS-4546883d-e3aa-4afd-a610-85839669ef4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-bc89f0e8-da6e-4bdf-b3e7-68519b85d969,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-5d65d27c-7226-4838-86ca-2d9e66e9ea56,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-f2dd537b-8ae0-4987-a135-5ea7fb773245,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-903f4bd0-c45e-4f7b-a55d-b425f3fa0047,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-5c01144a-0ac1-48c3-948a-47758a391610,DISK], DatanodeInfoWithStorage[127.0.0.1:33682,DS-0d900324-a462-46e1-94f1-2e0673f65837,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-59a071d1-cdd3-4ff6-9164-5cf76ec8c095,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1110291847-172.17.0.18-1595911589252:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44730,DS-c6ccd2b1-0f90-474e-b4f5-0f1346f4e867,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-48a30213-6f41-432f-a9d3-17ec57680f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-a744e4e7-fa56-4ece-930c-2b50047a7961,DISK], DatanodeInfoWithStorage[127.0.0.1:38554,DS-55bae5e0-bc76-4610-86d5-38c030725592,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-f3cbbd66-6c7f-4725-88f3-29144e9a2982,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-f0e10baa-9388-4373-bab1-18f2e44bf7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35872,DS-2b5ec67c-3950-4e2d-80ed-a0239711d19f,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-5a6dd67a-ce72-4d15-8b6f-f0de2018265e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1110291847-172.17.0.18-1595911589252:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44730,DS-c6ccd2b1-0f90-474e-b4f5-0f1346f4e867,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-48a30213-6f41-432f-a9d3-17ec57680f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-a744e4e7-fa56-4ece-930c-2b50047a7961,DISK], DatanodeInfoWithStorage[127.0.0.1:38554,DS-55bae5e0-bc76-4610-86d5-38c030725592,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-f3cbbd66-6c7f-4725-88f3-29144e9a2982,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-f0e10baa-9388-4373-bab1-18f2e44bf7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35872,DS-2b5ec67c-3950-4e2d-80ed-a0239711d19f,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-5a6dd67a-ce72-4d15-8b6f-f0de2018265e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1834918164-172.17.0.18-1595911909107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46149,DS-14dd79ce-681d-49e0-bf4d-229e12449688,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-b2d052e5-8443-4558-91f0-eab47eda03ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-70d8ad95-0be2-43f1-82c0-edf90dd47ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-843b3f90-715e-40ea-90d0-a74537d6564e,DISK], DatanodeInfoWithStorage[127.0.0.1:41997,DS-59284c56-f719-443a-be6a-7bbc1ff8d6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-ad2b48e5-bc9f-47db-8053-9514c7c8bdb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-118d7d8f-8b29-4253-953a-151a7425b3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-9ba04735-893e-402f-91eb-95a1c6550a12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1834918164-172.17.0.18-1595911909107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46149,DS-14dd79ce-681d-49e0-bf4d-229e12449688,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-b2d052e5-8443-4558-91f0-eab47eda03ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-70d8ad95-0be2-43f1-82c0-edf90dd47ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-843b3f90-715e-40ea-90d0-a74537d6564e,DISK], DatanodeInfoWithStorage[127.0.0.1:41997,DS-59284c56-f719-443a-be6a-7bbc1ff8d6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-ad2b48e5-bc9f-47db-8053-9514c7c8bdb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-118d7d8f-8b29-4253-953a-151a7425b3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-9ba04735-893e-402f-91eb-95a1c6550a12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-710773143-172.17.0.18-1595912495122:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35830,DS-401ab011-f224-4619-9e1d-a8d40e436e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-cc991c8e-b8e1-49c0-9546-1529bb633fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-ad449d37-c448-4bf9-a7d6-8cabcf3972d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40805,DS-d7fbb94d-d8ce-4d89-90c5-910c5d84ff97,DISK], DatanodeInfoWithStorage[127.0.0.1:37023,DS-c1c318a7-24ab-4eeb-91cc-b8ec116103c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40851,DS-0764ae24-0193-42ed-b367-def9c579918f,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-51292ce0-f026-4f7b-8bde-76f106b64467,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-bacf1aa1-a627-4e3d-b874-3fc2b9ea6f4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-710773143-172.17.0.18-1595912495122:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35830,DS-401ab011-f224-4619-9e1d-a8d40e436e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-cc991c8e-b8e1-49c0-9546-1529bb633fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-ad449d37-c448-4bf9-a7d6-8cabcf3972d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40805,DS-d7fbb94d-d8ce-4d89-90c5-910c5d84ff97,DISK], DatanodeInfoWithStorage[127.0.0.1:37023,DS-c1c318a7-24ab-4eeb-91cc-b8ec116103c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40851,DS-0764ae24-0193-42ed-b367-def9c579918f,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-51292ce0-f026-4f7b-8bde-76f106b64467,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-bacf1aa1-a627-4e3d-b874-3fc2b9ea6f4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-665429977-172.17.0.18-1595912922463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43805,DS-744cd84f-6b79-4c62-899a-38c029567d22,DISK], DatanodeInfoWithStorage[127.0.0.1:46789,DS-3bc8d234-a2c8-4737-8ce3-7e177b78d3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-a3b234cf-f384-4868-97e1-64934206647b,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-8b386612-83b9-4e03-8ad6-1f31e31a4966,DISK], DatanodeInfoWithStorage[127.0.0.1:40487,DS-94422ff3-324e-4f44-bc32-b2c0fc66b0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-f4cf9c0d-5b0e-47b8-a0fb-b4657ce8192f,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-f2762e90-640f-44c2-8582-c23e87bcea08,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-58e42df0-2105-4474-b7b6-453b697d4203,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-665429977-172.17.0.18-1595912922463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43805,DS-744cd84f-6b79-4c62-899a-38c029567d22,DISK], DatanodeInfoWithStorage[127.0.0.1:46789,DS-3bc8d234-a2c8-4737-8ce3-7e177b78d3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-a3b234cf-f384-4868-97e1-64934206647b,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-8b386612-83b9-4e03-8ad6-1f31e31a4966,DISK], DatanodeInfoWithStorage[127.0.0.1:40487,DS-94422ff3-324e-4f44-bc32-b2c0fc66b0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-f4cf9c0d-5b0e-47b8-a0fb-b4657ce8192f,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-f2762e90-640f-44c2-8582-c23e87bcea08,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-58e42df0-2105-4474-b7b6-453b697d4203,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1798638501-172.17.0.18-1595913316983:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35420,DS-66393b05-044f-4667-b1e7-0a337103042f,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-3554d347-a305-46be-9235-11d4da8e5158,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-db32944d-e8ba-4973-9c97-388892318337,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-c1fc4506-7ff4-410f-858d-035ebe164ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-fd31bb98-69db-4563-abed-6457af498865,DISK], DatanodeInfoWithStorage[127.0.0.1:45788,DS-dd7142f3-f8c1-4c4e-b356-1e08bd1897a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-901ec506-56ad-45dc-b1ed-bd0e1636bf01,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-d1c322eb-6a82-4b70-89b2-2832e6502258,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1798638501-172.17.0.18-1595913316983:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35420,DS-66393b05-044f-4667-b1e7-0a337103042f,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-3554d347-a305-46be-9235-11d4da8e5158,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-db32944d-e8ba-4973-9c97-388892318337,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-c1fc4506-7ff4-410f-858d-035ebe164ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-fd31bb98-69db-4563-abed-6457af498865,DISK], DatanodeInfoWithStorage[127.0.0.1:45788,DS-dd7142f3-f8c1-4c4e-b356-1e08bd1897a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-901ec506-56ad-45dc-b1ed-bd0e1636bf01,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-d1c322eb-6a82-4b70-89b2-2832e6502258,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-994544477-172.17.0.18-1595913388162:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37274,DS-3b2d0dec-97f5-4653-9959-3ffa2c0a2271,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-db66bfa1-4475-4902-b70c-a5b061ce718a,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-5a629e54-dfaa-408e-a033-eee47299368b,DISK], DatanodeInfoWithStorage[127.0.0.1:38350,DS-1704962c-e2e4-4f2a-a798-5bfd905bfa06,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-e7aae9bc-b5f4-459d-b1a9-f7f0065e9372,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-25803fc6-c631-459c-8346-2d616d2e0f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-6ea5641a-fb0e-4284-8027-a907b526269b,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-f2dcf166-880e-421c-90d5-50fd49de4d3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-994544477-172.17.0.18-1595913388162:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37274,DS-3b2d0dec-97f5-4653-9959-3ffa2c0a2271,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-db66bfa1-4475-4902-b70c-a5b061ce718a,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-5a629e54-dfaa-408e-a033-eee47299368b,DISK], DatanodeInfoWithStorage[127.0.0.1:38350,DS-1704962c-e2e4-4f2a-a798-5bfd905bfa06,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-e7aae9bc-b5f4-459d-b1a9-f7f0065e9372,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-25803fc6-c631-459c-8346-2d616d2e0f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-6ea5641a-fb0e-4284-8027-a907b526269b,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-f2dcf166-880e-421c-90d5-50fd49de4d3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1945120606-172.17.0.18-1595913420947:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39066,DS-f83be661-b013-4a97-985e-71437cd62c07,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-bd047e09-86d4-4cd0-a05a-664c99d49b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-d04e7319-2cb3-457b-922d-a688d6110693,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-7aa17642-3c59-4d13-bf92-568f503df4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-23042779-0abd-4c6b-997e-5f1eca424308,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-54378b09-6399-470c-9997-2dac7de65b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36637,DS-d32e5347-f21d-4428-848d-d4c60fb4c702,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-8281b04a-c5a0-49a0-b5e5-cf8bad77be2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1945120606-172.17.0.18-1595913420947:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39066,DS-f83be661-b013-4a97-985e-71437cd62c07,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-bd047e09-86d4-4cd0-a05a-664c99d49b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-d04e7319-2cb3-457b-922d-a688d6110693,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-7aa17642-3c59-4d13-bf92-568f503df4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-23042779-0abd-4c6b-997e-5f1eca424308,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-54378b09-6399-470c-9997-2dac7de65b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36637,DS-d32e5347-f21d-4428-848d-d4c60fb4c702,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-8281b04a-c5a0-49a0-b5e5-cf8bad77be2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-450156129-172.17.0.18-1595914731882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46680,DS-9e49347a-eee2-4dc9-8d17-cefc1aa2640f,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-dc5528e3-504d-4418-ab65-a7e0a27f5cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33768,DS-5debc24d-cf2c-434b-b6f9-f3c711123082,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-a4014ef1-5c2e-4de0-910f-13e9a4a4dec9,DISK], DatanodeInfoWithStorage[127.0.0.1:43363,DS-21db9f18-4d81-407c-af9a-a66b7a671c47,DISK], DatanodeInfoWithStorage[127.0.0.1:33229,DS-de3a42ba-9bf0-44d3-beb9-406a0c7efecb,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-65a66c5e-20cc-456b-8e2a-d58524c2a96b,DISK], DatanodeInfoWithStorage[127.0.0.1:35712,DS-28992e0e-88c8-4d40-9f89-e5352044ec08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-450156129-172.17.0.18-1595914731882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46680,DS-9e49347a-eee2-4dc9-8d17-cefc1aa2640f,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-dc5528e3-504d-4418-ab65-a7e0a27f5cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33768,DS-5debc24d-cf2c-434b-b6f9-f3c711123082,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-a4014ef1-5c2e-4de0-910f-13e9a4a4dec9,DISK], DatanodeInfoWithStorage[127.0.0.1:43363,DS-21db9f18-4d81-407c-af9a-a66b7a671c47,DISK], DatanodeInfoWithStorage[127.0.0.1:33229,DS-de3a42ba-9bf0-44d3-beb9-406a0c7efecb,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-65a66c5e-20cc-456b-8e2a-d58524c2a96b,DISK], DatanodeInfoWithStorage[127.0.0.1:35712,DS-28992e0e-88c8-4d40-9f89-e5352044ec08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1147917790-172.17.0.18-1595915163985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43630,DS-380d8b6a-8d05-422e-b536-165fe71c4455,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-eabd8f35-541a-4b3c-b9e2-bf74e415a2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40995,DS-ae810929-680e-4c25-80f2-7b2bc45ebbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35370,DS-6bd4fee3-3297-4676-bc8b-b117269d95a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-229284a5-eac7-4888-9cf7-c6975ee7f8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-ab41147a-3d4e-43c0-853c-b7dd5bd6b138,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-0f394ada-311e-4203-8288-38a4871e8a36,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-d5e2f74e-aa66-41ef-bd8c-b615e2a8d550,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1147917790-172.17.0.18-1595915163985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43630,DS-380d8b6a-8d05-422e-b536-165fe71c4455,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-eabd8f35-541a-4b3c-b9e2-bf74e415a2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40995,DS-ae810929-680e-4c25-80f2-7b2bc45ebbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35370,DS-6bd4fee3-3297-4676-bc8b-b117269d95a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-229284a5-eac7-4888-9cf7-c6975ee7f8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-ab41147a-3d4e-43c0-853c-b7dd5bd6b138,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-0f394ada-311e-4203-8288-38a4871e8a36,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-d5e2f74e-aa66-41ef-bd8c-b615e2a8d550,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-996771833-172.17.0.18-1595915229967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37983,DS-fab0bf30-f464-4adf-aa2c-eb269cf3fb61,DISK], DatanodeInfoWithStorage[127.0.0.1:43918,DS-f8d5b39d-3839-4f4b-9450-5eab56dd6de9,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-0ad14276-c911-4bef-a8ca-1b52912b2c04,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-71ead66c-465c-4bfa-b20b-92ba1e62bffa,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-5b949a54-e93e-4a5c-935d-d918386baf63,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-f3770828-c21f-44c7-9436-61a1203ed6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-e244e627-a625-4192-a8fa-76a71921f55e,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-1cb48595-89f3-4e0f-9d41-70d7821177f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-996771833-172.17.0.18-1595915229967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37983,DS-fab0bf30-f464-4adf-aa2c-eb269cf3fb61,DISK], DatanodeInfoWithStorage[127.0.0.1:43918,DS-f8d5b39d-3839-4f4b-9450-5eab56dd6de9,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-0ad14276-c911-4bef-a8ca-1b52912b2c04,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-71ead66c-465c-4bfa-b20b-92ba1e62bffa,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-5b949a54-e93e-4a5c-935d-d918386baf63,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-f3770828-c21f-44c7-9436-61a1203ed6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-e244e627-a625-4192-a8fa-76a71921f55e,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-1cb48595-89f3-4e0f-9d41-70d7821177f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 256
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-689320464-172.17.0.18-1595915302023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35468,DS-573bec04-58f5-4446-84be-4496436c1224,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-38857039-f450-4905-b3d5-0fbc96183398,DISK], DatanodeInfoWithStorage[127.0.0.1:35431,DS-e4af3c26-3f59-4cfc-b756-f4938f0f6ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-5eb46cd8-02e4-4ce7-83c5-a79c4c7ef117,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-f3dbcf7c-fbe0-4c32-98a1-d97566dc8a10,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-d44ae95b-32d4-4fcd-8aff-1b2fce07abd9,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-77416a1d-763c-4bf1-b15d-012f5d17c83b,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-9f2ad4d6-0a9b-47b3-839f-570886592575,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-689320464-172.17.0.18-1595915302023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35468,DS-573bec04-58f5-4446-84be-4496436c1224,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-38857039-f450-4905-b3d5-0fbc96183398,DISK], DatanodeInfoWithStorage[127.0.0.1:35431,DS-e4af3c26-3f59-4cfc-b756-f4938f0f6ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-5eb46cd8-02e4-4ce7-83c5-a79c4c7ef117,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-f3dbcf7c-fbe0-4c32-98a1-d97566dc8a10,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-d44ae95b-32d4-4fcd-8aff-1b2fce07abd9,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-77416a1d-763c-4bf1-b15d-012f5d17c83b,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-9f2ad4d6-0a9b-47b3-839f-570886592575,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5223
