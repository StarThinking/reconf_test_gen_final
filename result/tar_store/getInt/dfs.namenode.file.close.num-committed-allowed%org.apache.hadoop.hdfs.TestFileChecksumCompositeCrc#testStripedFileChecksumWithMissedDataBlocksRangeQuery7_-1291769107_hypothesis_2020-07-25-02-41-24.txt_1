reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1018395175-172.17.0.13-1595645113997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46657,DS-05c68144-67ae-49fe-963f-9a61c98efc00,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-2c8362a7-3197-4fc8-8e80-fd23da452d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-692f344a-a71c-44d9-926a-1cc1dfe26f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-a6233d66-b0b0-471a-9c87-07834f305538,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-d13e0795-d1ef-43b2-9c48-e28c4ae4b64e,DISK], DatanodeInfoWithStorage[127.0.0.1:44732,DS-e7c73c07-3775-45d4-9bb9-4a46b273c181,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-b5145b0b-477d-423e-bf94-acebcc52e44a,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-bf2664ee-5649-4480-a630-af9f156fc7cf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1018395175-172.17.0.13-1595645113997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46657,DS-05c68144-67ae-49fe-963f-9a61c98efc00,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-2c8362a7-3197-4fc8-8e80-fd23da452d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-692f344a-a71c-44d9-926a-1cc1dfe26f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-a6233d66-b0b0-471a-9c87-07834f305538,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-d13e0795-d1ef-43b2-9c48-e28c4ae4b64e,DISK], DatanodeInfoWithStorage[127.0.0.1:44732,DS-e7c73c07-3775-45d4-9bb9-4a46b273c181,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-b5145b0b-477d-423e-bf94-acebcc52e44a,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-bf2664ee-5649-4480-a630-af9f156fc7cf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1245655949-172.17.0.13-1595645378984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33069,DS-a0f72ed9-4dda-4f3b-bfd1-8ac2a5d1594b,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-5108b64b-a814-4a0d-87b4-5baf6baa4f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-253a4cc5-5e8a-4565-8a51-8dd97e29b12c,DISK], DatanodeInfoWithStorage[127.0.0.1:34839,DS-1a0c6b3f-5a15-428f-9be9-c0f26c6469ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-7fd2cb74-2c30-4aaa-ac6a-18ed7a223eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-dae73a63-8b07-43a5-9fb4-6ee1ff0dc3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-b39dba9d-e590-4cd5-be83-9127a7d20d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36841,DS-0e009acc-6fd6-4138-b0f9-c7386a7fc226,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1245655949-172.17.0.13-1595645378984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33069,DS-a0f72ed9-4dda-4f3b-bfd1-8ac2a5d1594b,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-5108b64b-a814-4a0d-87b4-5baf6baa4f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-253a4cc5-5e8a-4565-8a51-8dd97e29b12c,DISK], DatanodeInfoWithStorage[127.0.0.1:34839,DS-1a0c6b3f-5a15-428f-9be9-c0f26c6469ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-7fd2cb74-2c30-4aaa-ac6a-18ed7a223eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-dae73a63-8b07-43a5-9fb4-6ee1ff0dc3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-b39dba9d-e590-4cd5-be83-9127a7d20d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36841,DS-0e009acc-6fd6-4138-b0f9-c7386a7fc226,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1214704095-172.17.0.13-1595645460610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34699,DS-7ecf35c5-42b6-4abc-8f84-16cd9882df22,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-93ceaa8e-f098-4749-aedf-d6f0109cdf44,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-3527ed4b-16cb-4342-93c6-de8676ede1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-61b36be1-0e58-4695-a11a-b229b813293e,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-d31ba1ac-763c-4497-8b8a-b24dc1c7f5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-fdb4723c-d098-48d5-ba85-54fe2c53b33c,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-fea35c2b-18f2-4f74-9a8a-9b9fae1ac45d,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-da0f1240-2cef-44c4-a984-fdc9d869486a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1214704095-172.17.0.13-1595645460610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34699,DS-7ecf35c5-42b6-4abc-8f84-16cd9882df22,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-93ceaa8e-f098-4749-aedf-d6f0109cdf44,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-3527ed4b-16cb-4342-93c6-de8676ede1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-61b36be1-0e58-4695-a11a-b229b813293e,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-d31ba1ac-763c-4497-8b8a-b24dc1c7f5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-fdb4723c-d098-48d5-ba85-54fe2c53b33c,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-fea35c2b-18f2-4f74-9a8a-9b9fae1ac45d,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-da0f1240-2cef-44c4-a984-fdc9d869486a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-204177555-172.17.0.13-1595645575610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46290,DS-e4a30255-b6ec-430e-b195-f9368deca091,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-09c54be0-e59c-4efb-9cb7-34c671a646d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37199,DS-5143ba6b-a4cc-46a2-90e3-73f359b0e929,DISK], DatanodeInfoWithStorage[127.0.0.1:42113,DS-1f7152bd-5d84-438e-aa94-726c9ad17235,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-b311fb2e-fcd5-4d26-ac64-7fd3cb88ae75,DISK], DatanodeInfoWithStorage[127.0.0.1:40685,DS-c639d4c0-c9d8-44f8-8f3f-ab303bbbd642,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-aae7d14d-c9e0-4c36-bc13-d84660a173c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-e19a18dd-4efb-4359-96b9-f93da4c0ffdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-204177555-172.17.0.13-1595645575610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46290,DS-e4a30255-b6ec-430e-b195-f9368deca091,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-09c54be0-e59c-4efb-9cb7-34c671a646d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37199,DS-5143ba6b-a4cc-46a2-90e3-73f359b0e929,DISK], DatanodeInfoWithStorage[127.0.0.1:42113,DS-1f7152bd-5d84-438e-aa94-726c9ad17235,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-b311fb2e-fcd5-4d26-ac64-7fd3cb88ae75,DISK], DatanodeInfoWithStorage[127.0.0.1:40685,DS-c639d4c0-c9d8-44f8-8f3f-ab303bbbd642,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-aae7d14d-c9e0-4c36-bc13-d84660a173c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-e19a18dd-4efb-4359-96b9-f93da4c0ffdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-618818475-172.17.0.13-1595645817589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45483,DS-c2ab0b6f-98d6-4541-a6cc-2d7238bca3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-b0159e67-ad59-4050-a7cd-72e6a0b5b8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46510,DS-427f28f6-8f85-480a-9f1d-2b000aed89d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-ad4863c8-40b2-497a-bbf3-552732d5f2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35467,DS-fcb3cb50-213a-4244-bc59-fca99ade41ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-b96fabce-3374-403b-9528-2e1605534dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-0597d7c1-3d06-4272-b892-628ee9ccc483,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-9124ce46-7fa3-4544-bd62-ed9afe63aa5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-618818475-172.17.0.13-1595645817589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45483,DS-c2ab0b6f-98d6-4541-a6cc-2d7238bca3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-b0159e67-ad59-4050-a7cd-72e6a0b5b8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46510,DS-427f28f6-8f85-480a-9f1d-2b000aed89d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-ad4863c8-40b2-497a-bbf3-552732d5f2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35467,DS-fcb3cb50-213a-4244-bc59-fca99ade41ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-b96fabce-3374-403b-9528-2e1605534dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-0597d7c1-3d06-4272-b892-628ee9ccc483,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-9124ce46-7fa3-4544-bd62-ed9afe63aa5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1622853742-172.17.0.13-1595645999860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44545,DS-e50b1054-b005-46fe-8990-d775912a62e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-16acbcd0-4dac-4395-a74c-bc69a8ac1b63,DISK], DatanodeInfoWithStorage[127.0.0.1:40344,DS-e308ec67-d0f3-4e90-909a-a0999fd2e352,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-bda1c5f5-c769-4aba-93ad-15cef735c433,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-563bcac2-1670-43b6-8f89-c6eb89124a98,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-e629cd8e-dc79-427e-8321-d371f5c43c20,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-e0a51976-7394-49c3-a510-e4816292f2c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39258,DS-34dd31d1-0660-4035-879e-f8f2e45f9cb1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1622853742-172.17.0.13-1595645999860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44545,DS-e50b1054-b005-46fe-8990-d775912a62e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-16acbcd0-4dac-4395-a74c-bc69a8ac1b63,DISK], DatanodeInfoWithStorage[127.0.0.1:40344,DS-e308ec67-d0f3-4e90-909a-a0999fd2e352,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-bda1c5f5-c769-4aba-93ad-15cef735c433,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-563bcac2-1670-43b6-8f89-c6eb89124a98,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-e629cd8e-dc79-427e-8321-d371f5c43c20,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-e0a51976-7394-49c3-a510-e4816292f2c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39258,DS-34dd31d1-0660-4035-879e-f8f2e45f9cb1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-615759090-172.17.0.13-1595646219221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43413,DS-18acbfcc-13a1-445d-9189-c739fb4106ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-9a4a0912-cb52-4ef0-8bb4-86fc0c45c8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-ef042795-f4c4-4b0e-a8bd-8e4da851ebab,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-5f9c1ef0-8ae4-4805-b627-0ba375389443,DISK], DatanodeInfoWithStorage[127.0.0.1:45532,DS-1c7839b3-6362-4860-aa9a-84457a07c0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43110,DS-a439e0ba-1a9d-4274-9a49-a7d44bbb644f,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-eb25573a-a48f-428e-8b89-e541bfb99a19,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-7154d44d-bbf1-41f4-a24f-e71e15cb7487,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-615759090-172.17.0.13-1595646219221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43413,DS-18acbfcc-13a1-445d-9189-c739fb4106ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-9a4a0912-cb52-4ef0-8bb4-86fc0c45c8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-ef042795-f4c4-4b0e-a8bd-8e4da851ebab,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-5f9c1ef0-8ae4-4805-b627-0ba375389443,DISK], DatanodeInfoWithStorage[127.0.0.1:45532,DS-1c7839b3-6362-4860-aa9a-84457a07c0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43110,DS-a439e0ba-1a9d-4274-9a49-a7d44bbb644f,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-eb25573a-a48f-428e-8b89-e541bfb99a19,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-7154d44d-bbf1-41f4-a24f-e71e15cb7487,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1201291291-172.17.0.13-1595646249218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41107,DS-5bf9a27d-12e7-48cb-80a5-b3509bb7d579,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-f59fc23c-8408-4d8f-828c-40c92c06d40e,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-c67ac557-a3e7-4100-813f-08cc4b4e2d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-bd05c1d1-ab28-4b91-a54c-3551d7234c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-aadc2b0e-f3b5-4407-b07c-4566a58778f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-141ec7ac-e436-4b0f-be6e-42492ba917bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-30e0c7c2-9ecf-47d7-85e7-3c943ca7c166,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-1224a687-124b-4466-846e-ecc6012b13c8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1201291291-172.17.0.13-1595646249218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41107,DS-5bf9a27d-12e7-48cb-80a5-b3509bb7d579,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-f59fc23c-8408-4d8f-828c-40c92c06d40e,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-c67ac557-a3e7-4100-813f-08cc4b4e2d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-bd05c1d1-ab28-4b91-a54c-3551d7234c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-aadc2b0e-f3b5-4407-b07c-4566a58778f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-141ec7ac-e436-4b0f-be6e-42492ba917bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-30e0c7c2-9ecf-47d7-85e7-3c943ca7c166,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-1224a687-124b-4466-846e-ecc6012b13c8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1665223854-172.17.0.13-1595646353012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32949,DS-4b27ec05-3d92-458c-ad98-01a317b3b9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-e239acff-acd6-43e0-9771-e5d1214b4660,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-8fb533c1-018f-445e-baf2-8355200ac637,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-e9568849-37bd-4a81-ba10-66e35ecc96ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-65992664-a288-43f7-8a55-3195cd0884ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-36e4a3be-b311-42a7-8aa8-3305c226e88c,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-de3c0aef-68a9-4504-9e72-be0e16868e16,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-0530fd00-3eaf-41f2-ad4a-d4a658cde762,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1665223854-172.17.0.13-1595646353012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32949,DS-4b27ec05-3d92-458c-ad98-01a317b3b9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-e239acff-acd6-43e0-9771-e5d1214b4660,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-8fb533c1-018f-445e-baf2-8355200ac637,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-e9568849-37bd-4a81-ba10-66e35ecc96ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-65992664-a288-43f7-8a55-3195cd0884ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-36e4a3be-b311-42a7-8aa8-3305c226e88c,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-de3c0aef-68a9-4504-9e72-be0e16868e16,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-0530fd00-3eaf-41f2-ad4a-d4a658cde762,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-864828756-172.17.0.13-1595646673592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46867,DS-b54556e3-dd35-446b-a291-240c5c4cbc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-c41a7281-5aa0-4398-8734-3524cba8ac16,DISK], DatanodeInfoWithStorage[127.0.0.1:42759,DS-e5b48985-e05f-4c84-baa0-d60a0f48fafc,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-4b672e41-0d47-4ed7-bb9a-ba01dfb1b879,DISK], DatanodeInfoWithStorage[127.0.0.1:42057,DS-1358bb17-8996-439e-a4fe-38444469e185,DISK], DatanodeInfoWithStorage[127.0.0.1:36400,DS-0b6bff97-7a5d-4b01-858f-80c1ce42ca94,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-225c618e-5295-4c9a-8294-e3aa7ba9c672,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-435bec44-fe17-4d98-b19c-8032c57d0b2f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-864828756-172.17.0.13-1595646673592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46867,DS-b54556e3-dd35-446b-a291-240c5c4cbc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-c41a7281-5aa0-4398-8734-3524cba8ac16,DISK], DatanodeInfoWithStorage[127.0.0.1:42759,DS-e5b48985-e05f-4c84-baa0-d60a0f48fafc,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-4b672e41-0d47-4ed7-bb9a-ba01dfb1b879,DISK], DatanodeInfoWithStorage[127.0.0.1:42057,DS-1358bb17-8996-439e-a4fe-38444469e185,DISK], DatanodeInfoWithStorage[127.0.0.1:36400,DS-0b6bff97-7a5d-4b01-858f-80c1ce42ca94,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-225c618e-5295-4c9a-8294-e3aa7ba9c672,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-435bec44-fe17-4d98-b19c-8032c57d0b2f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-398790168-172.17.0.13-1595646849712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39607,DS-7bbadbeb-6de8-4646-908b-f768f02b255e,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-1b545a44-d762-46a0-8c59-3e2a19844c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-c8821154-4924-4fdf-96e5-597fca6a6398,DISK], DatanodeInfoWithStorage[127.0.0.1:38132,DS-c544b3c9-0e4d-440b-b5d5-adbab76812c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-9596a156-84c1-4ea0-a494-3ba93a88bfa9,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-b251e63a-dae3-434f-8f2c-8af256536dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38860,DS-656144d6-c611-41a1-ae72-09c53558390e,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-9f189257-7b3a-464a-b602-7595215e6b90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-398790168-172.17.0.13-1595646849712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39607,DS-7bbadbeb-6de8-4646-908b-f768f02b255e,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-1b545a44-d762-46a0-8c59-3e2a19844c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-c8821154-4924-4fdf-96e5-597fca6a6398,DISK], DatanodeInfoWithStorage[127.0.0.1:38132,DS-c544b3c9-0e4d-440b-b5d5-adbab76812c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-9596a156-84c1-4ea0-a494-3ba93a88bfa9,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-b251e63a-dae3-434f-8f2c-8af256536dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38860,DS-656144d6-c611-41a1-ae72-09c53558390e,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-9f189257-7b3a-464a-b602-7595215e6b90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1302942375-172.17.0.13-1595647486101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45838,DS-9fa73c18-f87e-483b-9028-247526d2d92c,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-f1207125-8fb4-4d47-8336-d537c4e90730,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-b0269196-f249-4819-8571-c6fccbf32300,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-c8dd2681-41a3-48f0-bfee-dca20a8a4f02,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-b0c9e1f5-2ca0-4e7d-902e-19e2b7c44141,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-27de3e5f-835f-44a5-88ff-47f3a81bf477,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-63ce4596-bd18-44c9-94bc-853f26a5208b,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-0b49ab81-4b9d-4ba6-8f1b-653040952253,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1302942375-172.17.0.13-1595647486101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45838,DS-9fa73c18-f87e-483b-9028-247526d2d92c,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-f1207125-8fb4-4d47-8336-d537c4e90730,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-b0269196-f249-4819-8571-c6fccbf32300,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-c8dd2681-41a3-48f0-bfee-dca20a8a4f02,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-b0c9e1f5-2ca0-4e7d-902e-19e2b7c44141,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-27de3e5f-835f-44a5-88ff-47f3a81bf477,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-63ce4596-bd18-44c9-94bc-853f26a5208b,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-0b49ab81-4b9d-4ba6-8f1b-653040952253,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-167612202-172.17.0.13-1595647558514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43380,DS-5abece92-09ef-498c-8712-86c01f580fde,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-89e6ed78-2e00-4365-899e-4d53b2327ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:38421,DS-d7ea2ad7-1fdf-4655-83c7-7e139fa51c19,DISK], DatanodeInfoWithStorage[127.0.0.1:33012,DS-0b8284cd-cf4e-4501-b363-e4253bf490ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36552,DS-807bcf6f-a73f-4c02-9833-65f4020407a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-2d7b6613-3333-44f1-a742-d43fcdbd7c07,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-e2bce00d-1f89-4032-82eb-a239c3aae1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-35d01404-64d9-4b64-82c7-56bb5b44722e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-167612202-172.17.0.13-1595647558514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43380,DS-5abece92-09ef-498c-8712-86c01f580fde,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-89e6ed78-2e00-4365-899e-4d53b2327ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:38421,DS-d7ea2ad7-1fdf-4655-83c7-7e139fa51c19,DISK], DatanodeInfoWithStorage[127.0.0.1:33012,DS-0b8284cd-cf4e-4501-b363-e4253bf490ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36552,DS-807bcf6f-a73f-4c02-9833-65f4020407a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-2d7b6613-3333-44f1-a742-d43fcdbd7c07,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-e2bce00d-1f89-4032-82eb-a239c3aae1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-35d01404-64d9-4b64-82c7-56bb5b44722e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-834006981-172.17.0.13-1595647634748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39513,DS-b9a552df-9070-49de-8d56-7b0a50e3dbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-66f7a674-3dec-405f-9e59-b6eaacb42124,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-e5526e73-973a-4a89-91a4-0c5152114ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-4cfbb88e-804b-4576-9acb-15a33e0cc8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35788,DS-8f2b8262-626c-40b1-bc72-5153e2614b83,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-fd4c2ece-d193-41ab-9be5-7d91ad3d5aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:35069,DS-8fb0f4dc-31fc-477f-ab69-b3e2c4312f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42477,DS-5d09f731-2ae5-454c-bbbf-940537d575c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-834006981-172.17.0.13-1595647634748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39513,DS-b9a552df-9070-49de-8d56-7b0a50e3dbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-66f7a674-3dec-405f-9e59-b6eaacb42124,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-e5526e73-973a-4a89-91a4-0c5152114ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-4cfbb88e-804b-4576-9acb-15a33e0cc8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35788,DS-8f2b8262-626c-40b1-bc72-5153e2614b83,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-fd4c2ece-d193-41ab-9be5-7d91ad3d5aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:35069,DS-8fb0f4dc-31fc-477f-ab69-b3e2c4312f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42477,DS-5d09f731-2ae5-454c-bbbf-940537d575c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-261222595-172.17.0.13-1595647886194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38613,DS-19aad1c6-27c0-453b-8c87-d0881f898786,DISK], DatanodeInfoWithStorage[127.0.0.1:37802,DS-ea34d216-532b-4da4-94cf-8e205da3bb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37784,DS-d2af5bbf-132e-4e4c-865d-b74c9763cd64,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-d247398b-c469-4af3-9417-ea68269fb8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40222,DS-0849c835-dbb8-4f44-9664-3752bfdd083c,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-d639b0aa-1826-4a9e-aaa9-451155fcfa69,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-ecf31829-c876-4f42-893a-1b9d4306faf6,DISK], DatanodeInfoWithStorage[127.0.0.1:41291,DS-d5c22d42-beeb-41b1-bcfa-e1e8821a7965,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-261222595-172.17.0.13-1595647886194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38613,DS-19aad1c6-27c0-453b-8c87-d0881f898786,DISK], DatanodeInfoWithStorage[127.0.0.1:37802,DS-ea34d216-532b-4da4-94cf-8e205da3bb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37784,DS-d2af5bbf-132e-4e4c-865d-b74c9763cd64,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-d247398b-c469-4af3-9417-ea68269fb8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40222,DS-0849c835-dbb8-4f44-9664-3752bfdd083c,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-d639b0aa-1826-4a9e-aaa9-451155fcfa69,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-ecf31829-c876-4f42-893a-1b9d4306faf6,DISK], DatanodeInfoWithStorage[127.0.0.1:41291,DS-d5c22d42-beeb-41b1-bcfa-e1e8821a7965,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1394725543-172.17.0.13-1595648109644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40580,DS-c2f350fb-8a1c-4bc1-be6f-55d3f03a3941,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-d4f97efc-f653-4a8a-8064-9218335694f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-6aa9e086-cbf7-40cf-886c-231b31b62cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-474271b7-fc68-44a6-bba8-20eba1a2efec,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-f46ca1c6-ee28-4402-a06a-00db5d194e44,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-00bb7909-bf7f-4057-9a61-ee7ec8286120,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-0dc75dee-220d-4b68-afa0-a8854cabc3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-c74aa59a-08e1-4913-a8ad-549d792473b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1394725543-172.17.0.13-1595648109644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40580,DS-c2f350fb-8a1c-4bc1-be6f-55d3f03a3941,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-d4f97efc-f653-4a8a-8064-9218335694f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-6aa9e086-cbf7-40cf-886c-231b31b62cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-474271b7-fc68-44a6-bba8-20eba1a2efec,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-f46ca1c6-ee28-4402-a06a-00db5d194e44,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-00bb7909-bf7f-4057-9a61-ee7ec8286120,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-0dc75dee-220d-4b68-afa0-a8854cabc3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-c74aa59a-08e1-4913-a8ad-549d792473b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-332400287-172.17.0.13-1595648467270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42705,DS-2bb65cd7-fd44-4357-8e8a-66288c97b2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-1bedc5b0-b34c-4c0f-a6af-61045c185ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-2f5fdf0d-1919-4c5c-8834-84de2f5800cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-25953146-af0a-4536-94f0-ed47180382d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-aac01446-5ad7-41f6-8017-7b2f96a32572,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-ba4b74d5-7a5f-468a-8ad4-f947241a065a,DISK], DatanodeInfoWithStorage[127.0.0.1:38108,DS-9a439354-e3ad-4348-a955-2f22bf6cb96f,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-21d0e3b2-a5f3-4da4-8b52-6901659343da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-332400287-172.17.0.13-1595648467270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42705,DS-2bb65cd7-fd44-4357-8e8a-66288c97b2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-1bedc5b0-b34c-4c0f-a6af-61045c185ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-2f5fdf0d-1919-4c5c-8834-84de2f5800cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-25953146-af0a-4536-94f0-ed47180382d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-aac01446-5ad7-41f6-8017-7b2f96a32572,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-ba4b74d5-7a5f-468a-8ad4-f947241a065a,DISK], DatanodeInfoWithStorage[127.0.0.1:38108,DS-9a439354-e3ad-4348-a955-2f22bf6cb96f,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-21d0e3b2-a5f3-4da4-8b52-6901659343da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-595889078-172.17.0.13-1595648609321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39358,DS-d743fff7-716f-4351-ae39-efe8ec66ad3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-f81f86a5-2c5e-4eb6-b165-e471975b8a10,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-2df1ca4b-b8ff-4dfe-a217-a9bfcd1b4fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-75695195-7d8a-452c-9ec9-0296c0dfcc84,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-0eb8a02f-8c5f-47f5-b62e-8430dbffeeed,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-90d47c0d-add5-4023-8469-684a201c05d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-dc4d178f-c5be-4be0-8ba4-9ad60f3b0671,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-a4adf7bf-3c57-46ec-ac6c-bace0439bcca,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-595889078-172.17.0.13-1595648609321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39358,DS-d743fff7-716f-4351-ae39-efe8ec66ad3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-f81f86a5-2c5e-4eb6-b165-e471975b8a10,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-2df1ca4b-b8ff-4dfe-a217-a9bfcd1b4fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-75695195-7d8a-452c-9ec9-0296c0dfcc84,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-0eb8a02f-8c5f-47f5-b62e-8430dbffeeed,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-90d47c0d-add5-4023-8469-684a201c05d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-dc4d178f-c5be-4be0-8ba4-9ad60f3b0671,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-a4adf7bf-3c57-46ec-ac6c-bace0439bcca,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-212455628-172.17.0.13-1595648718842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33593,DS-94f1eb2e-c8c7-461d-bb0c-1a5fa90b57be,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-4aa9f553-7f8c-4c60-bd9f-18122392d1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44667,DS-968546ba-f4e4-4616-a871-fc3868cb467e,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-14ce12b3-7cc9-45bf-966b-cd25f9199b77,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-a8d29836-c7cc-4ad4-b503-9c32fa5a2d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-1e4e74d8-b734-4541-b755-92f40cf78016,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-a39c686a-7c06-4093-aced-f25077d9e216,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-e8b3a367-6194-45e7-9ed1-f4662862e297,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-212455628-172.17.0.13-1595648718842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33593,DS-94f1eb2e-c8c7-461d-bb0c-1a5fa90b57be,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-4aa9f553-7f8c-4c60-bd9f-18122392d1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44667,DS-968546ba-f4e4-4616-a871-fc3868cb467e,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-14ce12b3-7cc9-45bf-966b-cd25f9199b77,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-a8d29836-c7cc-4ad4-b503-9c32fa5a2d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-1e4e74d8-b734-4541-b755-92f40cf78016,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-a39c686a-7c06-4093-aced-f25077d9e216,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-e8b3a367-6194-45e7-9ed1-f4662862e297,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1115927696-172.17.0.13-1595648755996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33183,DS-056cf3d6-ce60-452b-aa3d-3764466ea16d,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-4856a73c-0a89-481e-96c2-2ba737be59c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-8d7cdaa7-7fbf-4179-9145-19c5aa7e0c86,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-bb317589-d207-429f-90c3-ab66b6c347ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-c0020d66-585c-404d-a302-bd6aaba6c631,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-2a707c2e-ec29-4160-a48a-8c1671929634,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-f882c9c5-aa5f-4f7e-b4d6-f2d693a249e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-8a151f60-1d80-4005-8392-aa4bf730e38b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1115927696-172.17.0.13-1595648755996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33183,DS-056cf3d6-ce60-452b-aa3d-3764466ea16d,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-4856a73c-0a89-481e-96c2-2ba737be59c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-8d7cdaa7-7fbf-4179-9145-19c5aa7e0c86,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-bb317589-d207-429f-90c3-ab66b6c347ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-c0020d66-585c-404d-a302-bd6aaba6c631,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-2a707c2e-ec29-4160-a48a-8c1671929634,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-f882c9c5-aa5f-4f7e-b4d6-f2d693a249e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-8a151f60-1d80-4005-8392-aa4bf730e38b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-405870896-172.17.0.13-1595648931965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44959,DS-e81fe24b-f7cd-496a-a439-dac70a407790,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-4ab8770a-86a0-4284-81c3-d5d0b8b5ac0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34062,DS-78108465-87ab-4a4f-8d8c-8ea935a59223,DISK], DatanodeInfoWithStorage[127.0.0.1:38859,DS-82ea0378-f06e-4fe0-b90c-28cf460906b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42949,DS-ccd3e839-6ad5-4371-a871-b7eb1f398dba,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-92b358de-d5fe-4eb2-a93d-9ffba298dba0,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-fc6cc1c3-02ea-4004-a00f-9e272928cf64,DISK], DatanodeInfoWithStorage[127.0.0.1:38832,DS-f61a750d-0c13-4f0c-8286-f4141ad58bc4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-405870896-172.17.0.13-1595648931965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44959,DS-e81fe24b-f7cd-496a-a439-dac70a407790,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-4ab8770a-86a0-4284-81c3-d5d0b8b5ac0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34062,DS-78108465-87ab-4a4f-8d8c-8ea935a59223,DISK], DatanodeInfoWithStorage[127.0.0.1:38859,DS-82ea0378-f06e-4fe0-b90c-28cf460906b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42949,DS-ccd3e839-6ad5-4371-a871-b7eb1f398dba,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-92b358de-d5fe-4eb2-a93d-9ffba298dba0,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-fc6cc1c3-02ea-4004-a00f-9e272928cf64,DISK], DatanodeInfoWithStorage[127.0.0.1:38832,DS-f61a750d-0c13-4f0c-8286-f4141ad58bc4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1891201408-172.17.0.13-1595649311087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42673,DS-e5b6d8fa-9888-44f6-a7f4-e75b77e0bff0,DISK], DatanodeInfoWithStorage[127.0.0.1:34492,DS-9679eae0-ccc4-4f4e-b09a-d59b99c59936,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-7806c913-d8a6-4ab9-a9cd-6ea3e00011d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-ebb71817-ba56-4f8f-bbc2-6a8cbd966cee,DISK], DatanodeInfoWithStorage[127.0.0.1:44864,DS-8992bd6c-c28f-40f2-99af-ededbdcc0f51,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-e9a746ce-d44d-4b99-8d92-424fb0a58e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-61b0c50f-9c56-4e2b-b7ef-b23b866e585e,DISK], DatanodeInfoWithStorage[127.0.0.1:43386,DS-5a4546e5-1f6d-4f87-b58d-00e09840330c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1891201408-172.17.0.13-1595649311087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42673,DS-e5b6d8fa-9888-44f6-a7f4-e75b77e0bff0,DISK], DatanodeInfoWithStorage[127.0.0.1:34492,DS-9679eae0-ccc4-4f4e-b09a-d59b99c59936,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-7806c913-d8a6-4ab9-a9cd-6ea3e00011d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-ebb71817-ba56-4f8f-bbc2-6a8cbd966cee,DISK], DatanodeInfoWithStorage[127.0.0.1:44864,DS-8992bd6c-c28f-40f2-99af-ededbdcc0f51,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-e9a746ce-d44d-4b99-8d92-424fb0a58e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-61b0c50f-9c56-4e2b-b7ef-b23b866e585e,DISK], DatanodeInfoWithStorage[127.0.0.1:43386,DS-5a4546e5-1f6d-4f87-b58d-00e09840330c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1995833644-172.17.0.13-1595649453779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40566,DS-967ba302-5226-466e-9596-48a5935a725e,DISK], DatanodeInfoWithStorage[127.0.0.1:41144,DS-4e0443d5-5a29-470a-99a0-d4292476df7c,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-2835ceda-5404-4b92-a2d9-0cd8cdd4c67a,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-c80219fc-39dd-474c-850f-6ce98fdd2ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-c2ee4269-2477-4fc2-9362-acd16057586e,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-de9c127c-22cd-49e0-a699-75ed13ae51db,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-17e631ff-1d0f-4bf8-851b-8aaf5dc46d81,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-9226309d-c768-4fe7-8e86-dd146968e17a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1995833644-172.17.0.13-1595649453779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40566,DS-967ba302-5226-466e-9596-48a5935a725e,DISK], DatanodeInfoWithStorage[127.0.0.1:41144,DS-4e0443d5-5a29-470a-99a0-d4292476df7c,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-2835ceda-5404-4b92-a2d9-0cd8cdd4c67a,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-c80219fc-39dd-474c-850f-6ce98fdd2ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-c2ee4269-2477-4fc2-9362-acd16057586e,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-de9c127c-22cd-49e0-a699-75ed13ae51db,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-17e631ff-1d0f-4bf8-851b-8aaf5dc46d81,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-9226309d-c768-4fe7-8e86-dd146968e17a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2053438191-172.17.0.13-1595649519523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34765,DS-a4028cc4-352e-4829-8b94-a35e296158e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35284,DS-7be27dcc-4d80-41f6-8e9e-f3a13cf439ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-ce04ca7e-be35-4e7e-83a4-9f4c48d618e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35348,DS-8a8a16c5-9d96-460b-a248-f0b981cc846a,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-62e1f54e-ba3c-426b-87db-510ffbcc3222,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-6da64b88-0db7-47ad-a4ec-19bf1d90763c,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-3744c88f-47d4-4544-bc4a-6eca762c9110,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-9cf682e4-964c-411f-8d07-d4a4f799e883,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2053438191-172.17.0.13-1595649519523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34765,DS-a4028cc4-352e-4829-8b94-a35e296158e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35284,DS-7be27dcc-4d80-41f6-8e9e-f3a13cf439ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-ce04ca7e-be35-4e7e-83a4-9f4c48d618e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35348,DS-8a8a16c5-9d96-460b-a248-f0b981cc846a,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-62e1f54e-ba3c-426b-87db-510ffbcc3222,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-6da64b88-0db7-47ad-a4ec-19bf1d90763c,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-3744c88f-47d4-4544-bc4a-6eca762c9110,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-9cf682e4-964c-411f-8d07-d4a4f799e883,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-344153200-172.17.0.13-1595649785636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42982,DS-38322d3f-3c0a-48fb-abbb-0a23454e57f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-bd65437e-3ca7-471e-921c-8534eac0c269,DISK], DatanodeInfoWithStorage[127.0.0.1:37922,DS-d8e380c9-dc15-49e6-b32d-008ca8a0d8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-83216069-bcb5-4fbb-af28-4f0afde5c684,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-fb04c13d-e538-429f-8a24-160fc7d50b70,DISK], DatanodeInfoWithStorage[127.0.0.1:36944,DS-bad3fc90-8ee1-4238-a768-25c822379aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-3e7eb6ce-52fe-4c40-8036-a138b261fe40,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-f7966cc5-d845-4fbf-9d07-bafb6c831923,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-344153200-172.17.0.13-1595649785636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42982,DS-38322d3f-3c0a-48fb-abbb-0a23454e57f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-bd65437e-3ca7-471e-921c-8534eac0c269,DISK], DatanodeInfoWithStorage[127.0.0.1:37922,DS-d8e380c9-dc15-49e6-b32d-008ca8a0d8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-83216069-bcb5-4fbb-af28-4f0afde5c684,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-fb04c13d-e538-429f-8a24-160fc7d50b70,DISK], DatanodeInfoWithStorage[127.0.0.1:36944,DS-bad3fc90-8ee1-4238-a768-25c822379aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-3e7eb6ce-52fe-4c40-8036-a138b261fe40,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-f7966cc5-d845-4fbf-9d07-bafb6c831923,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1096648450-172.17.0.13-1595649816063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45651,DS-5c1f747e-1ae5-4dee-b0cd-ca7ab2893080,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-b971e9cb-aa30-4c29-bf2e-8a22c1552cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-dfcd5399-6b36-4798-9623-b5941606ca1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-f8d8bde3-e8e6-404a-860f-ea8ec9bcb466,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-8452b4b5-fc9d-45ba-8b46-e84f2137c7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-c5e39344-b0a8-43ff-a4f6-87face5a623e,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-482d99e7-36cf-4a6f-945d-39035c9f71e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-3456d49a-0760-4b30-bab4-d3f41d370005,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1096648450-172.17.0.13-1595649816063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45651,DS-5c1f747e-1ae5-4dee-b0cd-ca7ab2893080,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-b971e9cb-aa30-4c29-bf2e-8a22c1552cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-dfcd5399-6b36-4798-9623-b5941606ca1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-f8d8bde3-e8e6-404a-860f-ea8ec9bcb466,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-8452b4b5-fc9d-45ba-8b46-e84f2137c7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-c5e39344-b0a8-43ff-a4f6-87face5a623e,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-482d99e7-36cf-4a6f-945d-39035c9f71e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-3456d49a-0760-4b30-bab4-d3f41d370005,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951161133-172.17.0.13-1595650109394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41474,DS-5f081b39-443a-48f0-ba10-1f3595ecb339,DISK], DatanodeInfoWithStorage[127.0.0.1:43933,DS-80b43e55-b9aa-4aa7-be9c-8e5533cea804,DISK], DatanodeInfoWithStorage[127.0.0.1:39357,DS-c1719652-fa96-4a3c-a6fe-5ed2aa6d4d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-3bc4b1ac-af36-4025-bfd3-6b6a2323ea7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-d6ab63b9-1b95-4a06-9e49-b07f6b87595a,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-ccaad91a-da24-43a9-a50a-2cb51d52c814,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-10c6fd50-b64c-4127-aa46-b863f15feed2,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-567418b2-df1e-41d7-9e2f-a3e1a416049f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951161133-172.17.0.13-1595650109394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41474,DS-5f081b39-443a-48f0-ba10-1f3595ecb339,DISK], DatanodeInfoWithStorage[127.0.0.1:43933,DS-80b43e55-b9aa-4aa7-be9c-8e5533cea804,DISK], DatanodeInfoWithStorage[127.0.0.1:39357,DS-c1719652-fa96-4a3c-a6fe-5ed2aa6d4d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-3bc4b1ac-af36-4025-bfd3-6b6a2323ea7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-d6ab63b9-1b95-4a06-9e49-b07f6b87595a,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-ccaad91a-da24-43a9-a50a-2cb51d52c814,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-10c6fd50-b64c-4127-aa46-b863f15feed2,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-567418b2-df1e-41d7-9e2f-a3e1a416049f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1215722492-172.17.0.13-1595650175137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35482,DS-f680c3ff-5202-4df9-a883-3c430dd5fb59,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-6c515dff-a91f-47e2-845e-c36608b05a13,DISK], DatanodeInfoWithStorage[127.0.0.1:46403,DS-d687e3f8-d27f-4cc0-92fa-5a9883a30e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-7f39d737-80f4-44f2-98cb-bd864c72db22,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-aed3a59e-d99a-45f7-9c45-762808302b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-85a08bf8-e1ad-4857-9391-56bc30c120aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41477,DS-30b3a0db-60cf-4c79-96a7-c7af553f2f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33541,DS-b6c94f9e-0153-4e8f-b2f9-0ae3d4211e7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1215722492-172.17.0.13-1595650175137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35482,DS-f680c3ff-5202-4df9-a883-3c430dd5fb59,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-6c515dff-a91f-47e2-845e-c36608b05a13,DISK], DatanodeInfoWithStorage[127.0.0.1:46403,DS-d687e3f8-d27f-4cc0-92fa-5a9883a30e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-7f39d737-80f4-44f2-98cb-bd864c72db22,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-aed3a59e-d99a-45f7-9c45-762808302b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-85a08bf8-e1ad-4857-9391-56bc30c120aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41477,DS-30b3a0db-60cf-4c79-96a7-c7af553f2f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33541,DS-b6c94f9e-0153-4e8f-b2f9-0ae3d4211e7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5412
