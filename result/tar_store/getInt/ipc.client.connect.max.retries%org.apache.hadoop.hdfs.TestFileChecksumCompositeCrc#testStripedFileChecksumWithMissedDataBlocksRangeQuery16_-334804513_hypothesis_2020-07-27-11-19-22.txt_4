reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-77157201-172.17.0.8-1595848888174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46047,DS-37b5e7b3-3ac8-4a85-9f68-555b58b85985,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-d277d59b-87ff-40d2-89b0-0ea33a302d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-aa459039-8aa3-48bc-9310-5e954ff882d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-c8ae960b-8b1c-4fda-aa4e-dd711f4e3640,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-7e233320-fc77-4b4f-ada6-5ead35aafdae,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-949e9166-15c5-4c77-b445-c3f29c1d9a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-2b5d4dce-2b37-4f49-aa88-888150a3e8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-6c32b2c5-3231-4168-8e78-3a5215433f1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-77157201-172.17.0.8-1595848888174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46047,DS-37b5e7b3-3ac8-4a85-9f68-555b58b85985,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-d277d59b-87ff-40d2-89b0-0ea33a302d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-aa459039-8aa3-48bc-9310-5e954ff882d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-c8ae960b-8b1c-4fda-aa4e-dd711f4e3640,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-7e233320-fc77-4b4f-ada6-5ead35aafdae,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-949e9166-15c5-4c77-b445-c3f29c1d9a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-2b5d4dce-2b37-4f49-aa88-888150a3e8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-6c32b2c5-3231-4168-8e78-3a5215433f1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1172939258-172.17.0.8-1595848962943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43559,DS-9a159e64-6414-4880-a16b-d441e9f55ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:42268,DS-7d5910e9-3c06-4738-b37d-b3bfec7379d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-25a768a6-dfe5-4679-a656-bb316dffa07d,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-525fc34f-603b-4f8e-a18d-bfdab97e4454,DISK], DatanodeInfoWithStorage[127.0.0.1:34568,DS-d1edfa2b-6761-4184-9a04-75d7ecaee9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42981,DS-e82fbd89-8744-4602-ad29-190945eedf06,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-3113270d-6758-472a-874f-2c24fe9450f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-149e5822-4a9f-467e-86a9-f64b71780530,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1172939258-172.17.0.8-1595848962943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43559,DS-9a159e64-6414-4880-a16b-d441e9f55ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:42268,DS-7d5910e9-3c06-4738-b37d-b3bfec7379d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-25a768a6-dfe5-4679-a656-bb316dffa07d,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-525fc34f-603b-4f8e-a18d-bfdab97e4454,DISK], DatanodeInfoWithStorage[127.0.0.1:34568,DS-d1edfa2b-6761-4184-9a04-75d7ecaee9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42981,DS-e82fbd89-8744-4602-ad29-190945eedf06,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-3113270d-6758-472a-874f-2c24fe9450f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-149e5822-4a9f-467e-86a9-f64b71780530,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-835599817-172.17.0.8-1595849328155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41717,DS-65488e99-8e3a-4ccc-890e-41c1454a1fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-f74e072f-c506-4c98-a087-dfbaa6565792,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-ba19489f-5f53-402a-adb0-0d77b328113c,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-b5ab3cb5-047f-4c2d-8305-f84d5fb725c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-0240656d-4cbb-4232-b0a6-508ffcfaa529,DISK], DatanodeInfoWithStorage[127.0.0.1:34262,DS-3b570769-67a3-4eff-bec9-6ad1cfb0883a,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-99f69369-ce8a-40da-a51a-6c796293ca60,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-cb7b42b2-a7ab-479e-92ff-ce5e859de8e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-835599817-172.17.0.8-1595849328155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41717,DS-65488e99-8e3a-4ccc-890e-41c1454a1fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-f74e072f-c506-4c98-a087-dfbaa6565792,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-ba19489f-5f53-402a-adb0-0d77b328113c,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-b5ab3cb5-047f-4c2d-8305-f84d5fb725c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-0240656d-4cbb-4232-b0a6-508ffcfaa529,DISK], DatanodeInfoWithStorage[127.0.0.1:34262,DS-3b570769-67a3-4eff-bec9-6ad1cfb0883a,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-99f69369-ce8a-40da-a51a-6c796293ca60,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-cb7b42b2-a7ab-479e-92ff-ce5e859de8e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-29879784-172.17.0.8-1595849859564:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38232,DS-ac3e237a-c621-429f-bfb4-79b94d620c92,DISK], DatanodeInfoWithStorage[127.0.0.1:45182,DS-01f6f126-c9c0-45d8-833a-53344ab0a86b,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-e590c901-e458-435b-b96e-b3152e868426,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-de1e8713-59ac-4079-855e-c96dd457a601,DISK], DatanodeInfoWithStorage[127.0.0.1:42128,DS-99746137-1d5b-49cb-a018-6e0ad9771665,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-e1613997-9a33-4ac6-a922-394160a2c3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-71ba1085-28d5-41ab-866c-ef2e699eee64,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-de58b76a-fc3f-415d-b05b-8ffde7ce82f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-29879784-172.17.0.8-1595849859564:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38232,DS-ac3e237a-c621-429f-bfb4-79b94d620c92,DISK], DatanodeInfoWithStorage[127.0.0.1:45182,DS-01f6f126-c9c0-45d8-833a-53344ab0a86b,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-e590c901-e458-435b-b96e-b3152e868426,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-de1e8713-59ac-4079-855e-c96dd457a601,DISK], DatanodeInfoWithStorage[127.0.0.1:42128,DS-99746137-1d5b-49cb-a018-6e0ad9771665,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-e1613997-9a33-4ac6-a922-394160a2c3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-71ba1085-28d5-41ab-866c-ef2e699eee64,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-de58b76a-fc3f-415d-b05b-8ffde7ce82f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-802684189-172.17.0.8-1595849899881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46621,DS-6fad7212-3955-4e25-8cff-ed69253a0f62,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-3ba249d3-a8c3-406f-98e8-ac2bb7e0d49b,DISK], DatanodeInfoWithStorage[127.0.0.1:39817,DS-f4f59ee0-b0f6-42e6-a150-199c89d833d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-b368b6c0-7d5f-4653-9107-cd9c888d6651,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-5f8074fc-9034-442a-8295-8f88dd83d40e,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-be023410-1fab-4b92-bdb0-e60abc4385ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-2d14ae12-5204-4a3f-98a1-ccda6b0f7268,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-48ebc9e8-9d87-43f4-8190-3e96a5b6e485,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-802684189-172.17.0.8-1595849899881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46621,DS-6fad7212-3955-4e25-8cff-ed69253a0f62,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-3ba249d3-a8c3-406f-98e8-ac2bb7e0d49b,DISK], DatanodeInfoWithStorage[127.0.0.1:39817,DS-f4f59ee0-b0f6-42e6-a150-199c89d833d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-b368b6c0-7d5f-4653-9107-cd9c888d6651,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-5f8074fc-9034-442a-8295-8f88dd83d40e,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-be023410-1fab-4b92-bdb0-e60abc4385ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-2d14ae12-5204-4a3f-98a1-ccda6b0f7268,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-48ebc9e8-9d87-43f4-8190-3e96a5b6e485,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1690416252-172.17.0.8-1595849943123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41735,DS-65c0550c-2b31-49fe-ba81-2699b7d4fbf3,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-9d790130-fb52-477e-88cd-fd2dfacf0d67,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-b92b5a04-6561-4c09-89e0-c186f3ccf946,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-fd2887e8-9291-4a9f-a12c-0892ac9f9936,DISK], DatanodeInfoWithStorage[127.0.0.1:35090,DS-be691ebe-ca06-45c8-8fb2-3574bc1e2055,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-641b22a4-4b8f-421d-8871-ad5e1091b907,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-33ae469a-5540-47ba-8733-f564f92631ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-4664f2ac-92c5-436f-9735-65f99d12dd1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1690416252-172.17.0.8-1595849943123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41735,DS-65c0550c-2b31-49fe-ba81-2699b7d4fbf3,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-9d790130-fb52-477e-88cd-fd2dfacf0d67,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-b92b5a04-6561-4c09-89e0-c186f3ccf946,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-fd2887e8-9291-4a9f-a12c-0892ac9f9936,DISK], DatanodeInfoWithStorage[127.0.0.1:35090,DS-be691ebe-ca06-45c8-8fb2-3574bc1e2055,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-641b22a4-4b8f-421d-8871-ad5e1091b907,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-33ae469a-5540-47ba-8733-f564f92631ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-4664f2ac-92c5-436f-9735-65f99d12dd1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1779618744-172.17.0.8-1595850086724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45271,DS-72ae6d31-5b17-4c59-844e-6a602b2d055a,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-00ecbbec-be91-4fc8-aa69-08c427d2847c,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-46882023-238f-488b-ad36-f2d991cff517,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-a154275b-a1f2-4fc1-8c75-673c7fa6c630,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-c84bf2b0-22b1-479c-b849-6101e01bd18c,DISK], DatanodeInfoWithStorage[127.0.0.1:46795,DS-e5c6fb66-9a8f-4a8d-b525-62d4bff26f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-0e7b4055-706d-4e40-beed-b3a14a9d019e,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-0b738d79-6498-4771-801f-aad5f9aa2a0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1779618744-172.17.0.8-1595850086724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45271,DS-72ae6d31-5b17-4c59-844e-6a602b2d055a,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-00ecbbec-be91-4fc8-aa69-08c427d2847c,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-46882023-238f-488b-ad36-f2d991cff517,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-a154275b-a1f2-4fc1-8c75-673c7fa6c630,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-c84bf2b0-22b1-479c-b849-6101e01bd18c,DISK], DatanodeInfoWithStorage[127.0.0.1:46795,DS-e5c6fb66-9a8f-4a8d-b525-62d4bff26f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-0e7b4055-706d-4e40-beed-b3a14a9d019e,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-0b738d79-6498-4771-801f-aad5f9aa2a0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1536697457-172.17.0.8-1595850385556:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38947,DS-3359724d-65cc-4e2b-921c-246e12e265b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33196,DS-b1ae67bc-60b0-4d25-9900-7392a8c48fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-1e6d68b1-7a2c-4cae-b707-8b1b5d106efc,DISK], DatanodeInfoWithStorage[127.0.0.1:34890,DS-d8eef3b5-ddc5-486f-bbb1-4d64dc66b393,DISK], DatanodeInfoWithStorage[127.0.0.1:40889,DS-a69d0491-974b-4d43-91d8-12b6857f4281,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-c4f28655-8198-453a-bb54-2e038ec35f40,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-d4ffa0ab-c0de-48ec-b9e9-bf8fb2bb300f,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-eb6c65a1-82c7-4a2e-9be3-535a2e7ac123,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1536697457-172.17.0.8-1595850385556:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38947,DS-3359724d-65cc-4e2b-921c-246e12e265b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33196,DS-b1ae67bc-60b0-4d25-9900-7392a8c48fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-1e6d68b1-7a2c-4cae-b707-8b1b5d106efc,DISK], DatanodeInfoWithStorage[127.0.0.1:34890,DS-d8eef3b5-ddc5-486f-bbb1-4d64dc66b393,DISK], DatanodeInfoWithStorage[127.0.0.1:40889,DS-a69d0491-974b-4d43-91d8-12b6857f4281,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-c4f28655-8198-453a-bb54-2e038ec35f40,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-d4ffa0ab-c0de-48ec-b9e9-bf8fb2bb300f,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-eb6c65a1-82c7-4a2e-9be3-535a2e7ac123,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-290440653-172.17.0.8-1595850620059:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40911,DS-e93ec9e4-eab6-4164-8f69-4127808066e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-3d73b238-23ee-4fbd-aa3a-af4704e35fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:39269,DS-6d9a25da-e267-4813-8f5f-1309fa35c518,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-a9aafcfa-898d-4453-97bf-3dfb1918da43,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-969c2330-f316-4ff3-9328-40e600d3b50e,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-8fac9935-ba10-4738-adec-2f09a35c1a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33229,DS-dcedc30c-44ab-4cb8-be9f-26d925407b73,DISK], DatanodeInfoWithStorage[127.0.0.1:41888,DS-7332f5b4-1acf-45bc-bc46-13eb2f4ad845,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-290440653-172.17.0.8-1595850620059:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40911,DS-e93ec9e4-eab6-4164-8f69-4127808066e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-3d73b238-23ee-4fbd-aa3a-af4704e35fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:39269,DS-6d9a25da-e267-4813-8f5f-1309fa35c518,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-a9aafcfa-898d-4453-97bf-3dfb1918da43,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-969c2330-f316-4ff3-9328-40e600d3b50e,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-8fac9935-ba10-4738-adec-2f09a35c1a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33229,DS-dcedc30c-44ab-4cb8-be9f-26d925407b73,DISK], DatanodeInfoWithStorage[127.0.0.1:41888,DS-7332f5b4-1acf-45bc-bc46-13eb2f4ad845,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-927737370-172.17.0.8-1595850944923:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44193,DS-0b5c9b12-365f-4531-a80e-524ff09bab0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-00b06b9b-a686-44ef-bb96-53ae917bb967,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-a186f437-4acf-4a54-939a-9c926a167238,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-82893e88-fd4a-4bdf-ba3e-a6b8972b5e87,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-b1dac49a-fca5-4c0d-8f57-736d61ced329,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-a0b05459-490e-4ae2-a1cf-942fda737268,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-6620c976-e21e-4a78-875b-4c98a7f10449,DISK], DatanodeInfoWithStorage[127.0.0.1:42329,DS-b3a79a3e-93d1-4d13-9fa7-c1edb88add0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-927737370-172.17.0.8-1595850944923:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44193,DS-0b5c9b12-365f-4531-a80e-524ff09bab0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-00b06b9b-a686-44ef-bb96-53ae917bb967,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-a186f437-4acf-4a54-939a-9c926a167238,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-82893e88-fd4a-4bdf-ba3e-a6b8972b5e87,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-b1dac49a-fca5-4c0d-8f57-736d61ced329,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-a0b05459-490e-4ae2-a1cf-942fda737268,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-6620c976-e21e-4a78-875b-4c98a7f10449,DISK], DatanodeInfoWithStorage[127.0.0.1:42329,DS-b3a79a3e-93d1-4d13-9fa7-c1edb88add0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1070201679-172.17.0.8-1595851125179:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40184,DS-86ff5113-73d5-4377-b3cb-e3cb0b3cee80,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-4f95be52-f5f3-416d-a1ff-aa0e4d09fa90,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-eb185547-3bab-4783-b139-ccb046ee5ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-3fc86981-c2ff-41ff-bbe8-e356dfa63079,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-a8f9942a-ff40-4053-9fb9-1827b7f65736,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-043cddfc-1cc1-489d-9a18-149d9708fd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-fdf1c56e-6738-47d6-8336-990940ad660d,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-d7003b06-11c5-4e7e-aecd-e83221f8e84f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1070201679-172.17.0.8-1595851125179:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40184,DS-86ff5113-73d5-4377-b3cb-e3cb0b3cee80,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-4f95be52-f5f3-416d-a1ff-aa0e4d09fa90,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-eb185547-3bab-4783-b139-ccb046ee5ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-3fc86981-c2ff-41ff-bbe8-e356dfa63079,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-a8f9942a-ff40-4053-9fb9-1827b7f65736,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-043cddfc-1cc1-489d-9a18-149d9708fd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-fdf1c56e-6738-47d6-8336-990940ad660d,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-d7003b06-11c5-4e7e-aecd-e83221f8e84f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2034852477-172.17.0.8-1595852474187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34450,DS-63be1b29-f208-44eb-ad9e-9d74234e6732,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-3e6d5327-72aa-4aa9-a7b8-486d40e21626,DISK], DatanodeInfoWithStorage[127.0.0.1:39624,DS-aaf7cc44-d1b4-4b61-91c4-fd2eda706c88,DISK], DatanodeInfoWithStorage[127.0.0.1:33483,DS-9e3da3d3-d860-4137-ac8f-6bae9bbe3628,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-391f215b-6ad0-4723-ae09-5950b950a86b,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-6bb0962b-4008-47b1-b7e6-19abf012b9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-69a072b0-c557-4bfb-aab6-b75461bcb044,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-b52d1a88-33c1-408f-b666-ba71f7c7cbc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2034852477-172.17.0.8-1595852474187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34450,DS-63be1b29-f208-44eb-ad9e-9d74234e6732,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-3e6d5327-72aa-4aa9-a7b8-486d40e21626,DISK], DatanodeInfoWithStorage[127.0.0.1:39624,DS-aaf7cc44-d1b4-4b61-91c4-fd2eda706c88,DISK], DatanodeInfoWithStorage[127.0.0.1:33483,DS-9e3da3d3-d860-4137-ac8f-6bae9bbe3628,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-391f215b-6ad0-4723-ae09-5950b950a86b,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-6bb0962b-4008-47b1-b7e6-19abf012b9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-69a072b0-c557-4bfb-aab6-b75461bcb044,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-b52d1a88-33c1-408f-b666-ba71f7c7cbc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-84923655-172.17.0.8-1595852590230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41605,DS-65da602d-b889-4b1b-9c6a-349a68756bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41868,DS-78c4d48c-cf58-419a-936e-fc4b9115af8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-63656a93-c3c6-4909-b90b-9631a77e051d,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-5aac0c5e-86bc-43fa-852a-2ffd5e4244d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46390,DS-49f4d80f-391c-4545-b5a5-15ec872bbc29,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-7f12ec19-50f8-4ad8-8a8f-79de73d60100,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-e9db3906-4a26-4646-abce-ad94bc23224b,DISK], DatanodeInfoWithStorage[127.0.0.1:37678,DS-0f757390-08ff-4d61-8001-633759513937,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-84923655-172.17.0.8-1595852590230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41605,DS-65da602d-b889-4b1b-9c6a-349a68756bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41868,DS-78c4d48c-cf58-419a-936e-fc4b9115af8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-63656a93-c3c6-4909-b90b-9631a77e051d,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-5aac0c5e-86bc-43fa-852a-2ffd5e4244d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46390,DS-49f4d80f-391c-4545-b5a5-15ec872bbc29,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-7f12ec19-50f8-4ad8-8a8f-79de73d60100,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-e9db3906-4a26-4646-abce-ad94bc23224b,DISK], DatanodeInfoWithStorage[127.0.0.1:37678,DS-0f757390-08ff-4d61-8001-633759513937,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-237206782-172.17.0.8-1595852629500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35109,DS-2d161c70-1841-4673-80ce-c683f0bccb57,DISK], DatanodeInfoWithStorage[127.0.0.1:40836,DS-2c77f6dc-82c7-4cf1-be67-a53a487e2de2,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-3f16125e-a6e1-43f0-b78c-e3d88ea8b55f,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-72cff291-fe12-4481-b40b-432803beb29a,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-6156f316-07a3-44a7-be4d-8d8cca3e0424,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-4309e30d-de76-4a14-8b17-b3263d494321,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-e525167e-8bf3-4f80-8a1d-194fcb1fa2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-176e44e1-adb5-4d09-b82a-5b768bd761c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-237206782-172.17.0.8-1595852629500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35109,DS-2d161c70-1841-4673-80ce-c683f0bccb57,DISK], DatanodeInfoWithStorage[127.0.0.1:40836,DS-2c77f6dc-82c7-4cf1-be67-a53a487e2de2,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-3f16125e-a6e1-43f0-b78c-e3d88ea8b55f,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-72cff291-fe12-4481-b40b-432803beb29a,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-6156f316-07a3-44a7-be4d-8d8cca3e0424,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-4309e30d-de76-4a14-8b17-b3263d494321,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-e525167e-8bf3-4f80-8a1d-194fcb1fa2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-176e44e1-adb5-4d09-b82a-5b768bd761c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1441685813-172.17.0.8-1595853448504:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33470,DS-819444b4-bee9-42d8-82ba-7586856691c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35021,DS-fa7cac53-b8cf-44b4-a32e-b909e0628768,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-ac35dcd5-b6e5-4caa-8f7b-c8a844113e18,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-40f6167f-b8d0-408d-a0fa-ec2ca6a43809,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-c773405d-8fff-40f0-9932-ed48c64bf7f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-6c6620fa-d0cd-4237-baa9-adeef38d0b22,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-309fc735-ca61-4929-8565-7467bfba6433,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-50c1e16f-8c4f-432c-b6dc-caed453f1a9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1441685813-172.17.0.8-1595853448504:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33470,DS-819444b4-bee9-42d8-82ba-7586856691c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35021,DS-fa7cac53-b8cf-44b4-a32e-b909e0628768,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-ac35dcd5-b6e5-4caa-8f7b-c8a844113e18,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-40f6167f-b8d0-408d-a0fa-ec2ca6a43809,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-c773405d-8fff-40f0-9932-ed48c64bf7f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-6c6620fa-d0cd-4237-baa9-adeef38d0b22,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-309fc735-ca61-4929-8565-7467bfba6433,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-50c1e16f-8c4f-432c-b6dc-caed453f1a9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1197356514-172.17.0.8-1595853507064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45595,DS-aa08e429-eaa9-4ddb-aa18-3c09e12e45f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-5d943507-1f5d-4641-90f3-49ae8ea7a721,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-1dd692c8-93b2-4b2d-a8c0-0fd4d0d16224,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-35866af6-9793-483f-9a07-8f8f5a2cb439,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-b997ae4f-e407-4714-ad12-f0e80c690110,DISK], DatanodeInfoWithStorage[127.0.0.1:34244,DS-213790d0-733d-4b7e-9a72-300e1052b49e,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-51e86846-d94e-4866-9f81-2d7289254c49,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-0a57a1a2-6fc0-4b42-9aad-754a50a18293,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1197356514-172.17.0.8-1595853507064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45595,DS-aa08e429-eaa9-4ddb-aa18-3c09e12e45f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-5d943507-1f5d-4641-90f3-49ae8ea7a721,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-1dd692c8-93b2-4b2d-a8c0-0fd4d0d16224,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-35866af6-9793-483f-9a07-8f8f5a2cb439,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-b997ae4f-e407-4714-ad12-f0e80c690110,DISK], DatanodeInfoWithStorage[127.0.0.1:34244,DS-213790d0-733d-4b7e-9a72-300e1052b49e,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-51e86846-d94e-4866-9f81-2d7289254c49,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-0a57a1a2-6fc0-4b42-9aad-754a50a18293,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1460601817-172.17.0.8-1595853742028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41647,DS-d50e335b-4357-46e3-a4e7-da1606f55077,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-9f86058e-0e04-4eae-b41f-631bb07e2e59,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-49be9515-7d3f-42e8-a02f-7e35d6df9a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45955,DS-d81fd41c-5286-4722-8d59-02dfa62f694e,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-0222219d-d7d4-4f39-a051-5edc8e2bbf66,DISK], DatanodeInfoWithStorage[127.0.0.1:38054,DS-6b3dc2a3-2dfa-42c6-965f-ec99099479a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-f578439d-fec5-4056-8432-975491ddc405,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-95d660c4-8b66-4a39-94df-397746068f23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1460601817-172.17.0.8-1595853742028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41647,DS-d50e335b-4357-46e3-a4e7-da1606f55077,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-9f86058e-0e04-4eae-b41f-631bb07e2e59,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-49be9515-7d3f-42e8-a02f-7e35d6df9a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45955,DS-d81fd41c-5286-4722-8d59-02dfa62f694e,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-0222219d-d7d4-4f39-a051-5edc8e2bbf66,DISK], DatanodeInfoWithStorage[127.0.0.1:38054,DS-6b3dc2a3-2dfa-42c6-965f-ec99099479a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-f578439d-fec5-4056-8432-975491ddc405,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-95d660c4-8b66-4a39-94df-397746068f23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1904147918-172.17.0.8-1595853777060:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46047,DS-3dbc882f-e0bd-4078-809a-ec70e4d47924,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-17a9b05f-158c-4b73-b8ad-72e08a0a105d,DISK], DatanodeInfoWithStorage[127.0.0.1:42391,DS-c9bdfc5f-c7be-455a-9ebd-1c8409fe39ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-516e1af8-a49e-406d-a23f-8b6223d5a1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-e7eac9ba-9ec4-4794-971c-13d18c908e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40506,DS-e9629df9-d077-42fb-964c-d2d0140ae831,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-3a86e71b-c492-4e6a-a5b5-fdfce83d61c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-4630a1ce-8bc1-48f9-9883-d467d2d334a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1904147918-172.17.0.8-1595853777060:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46047,DS-3dbc882f-e0bd-4078-809a-ec70e4d47924,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-17a9b05f-158c-4b73-b8ad-72e08a0a105d,DISK], DatanodeInfoWithStorage[127.0.0.1:42391,DS-c9bdfc5f-c7be-455a-9ebd-1c8409fe39ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-516e1af8-a49e-406d-a23f-8b6223d5a1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-e7eac9ba-9ec4-4794-971c-13d18c908e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40506,DS-e9629df9-d077-42fb-964c-d2d0140ae831,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-3a86e71b-c492-4e6a-a5b5-fdfce83d61c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-4630a1ce-8bc1-48f9-9883-d467d2d334a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1126972962-172.17.0.8-1595853811729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42910,DS-7a585a79-7be6-4a35-a5c1-b747143bf305,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-11098854-ae24-4240-9b9d-591bd9694fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-e3cae61c-9f9f-4152-b7d7-19015076ea0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-4a1b47f5-08a4-4efc-8fe5-3ac0d8268325,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-dd0ccf60-2e87-4d69-94d4-aebfec3e583e,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-893ef048-1bb3-4120-9567-b1b7dd795615,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-f9e32bc8-b843-4ee2-8bad-122f9d666adf,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-3e043df7-d4b5-4b4c-8162-526e59d00a5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1126972962-172.17.0.8-1595853811729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42910,DS-7a585a79-7be6-4a35-a5c1-b747143bf305,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-11098854-ae24-4240-9b9d-591bd9694fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-e3cae61c-9f9f-4152-b7d7-19015076ea0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-4a1b47f5-08a4-4efc-8fe5-3ac0d8268325,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-dd0ccf60-2e87-4d69-94d4-aebfec3e583e,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-893ef048-1bb3-4120-9567-b1b7dd795615,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-f9e32bc8-b843-4ee2-8bad-122f9d666adf,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-3e043df7-d4b5-4b4c-8162-526e59d00a5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5392
