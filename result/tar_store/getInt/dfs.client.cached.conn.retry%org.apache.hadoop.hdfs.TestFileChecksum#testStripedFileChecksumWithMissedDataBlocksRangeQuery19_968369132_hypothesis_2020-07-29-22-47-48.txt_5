reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-741777656-172.17.0.7-1596063045522:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37725,DS-1966476d-29c8-46b8-b7b5-898b9e7e5d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-c063cda1-66bc-4034-a1a0-3a77c2e012e0,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-686ea11c-9dfd-4430-9c2e-40ce102a58b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-39b2208b-0615-4cc7-9d2c-a6a9ff047033,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-315fae5a-30af-4a8b-ad6a-88ee0530ac98,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-8c95fb7d-beeb-4ea9-9aa9-38ede87d35a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38437,DS-8bf354bd-c17d-4122-a09a-bc115765243a,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-5b864f0f-5da9-47b8-9d35-0adf81d2e079,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-741777656-172.17.0.7-1596063045522:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37725,DS-1966476d-29c8-46b8-b7b5-898b9e7e5d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-c063cda1-66bc-4034-a1a0-3a77c2e012e0,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-686ea11c-9dfd-4430-9c2e-40ce102a58b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-39b2208b-0615-4cc7-9d2c-a6a9ff047033,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-315fae5a-30af-4a8b-ad6a-88ee0530ac98,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-8c95fb7d-beeb-4ea9-9aa9-38ede87d35a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38437,DS-8bf354bd-c17d-4122-a09a-bc115765243a,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-5b864f0f-5da9-47b8-9d35-0adf81d2e079,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-112247875-172.17.0.7-1596063773213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41397,DS-c1fee5db-17e6-4846-b095-398a8cfaa8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-515b56ae-3fb6-42b4-ba75-30c81147710f,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-61664f7e-e3f6-46cb-8b12-d1fc747626e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40138,DS-d018bed1-403e-4067-bb39-cff18e2bd331,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-5f2f7725-c411-4220-87aa-b9d80eedd14b,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-c51ebd19-5479-447c-b156-c09aebd8d072,DISK], DatanodeInfoWithStorage[127.0.0.1:38095,DS-87f7ff27-e8ba-4ff6-a1e0-4d8464f32b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-29d74065-c158-41f0-8606-5d6cb7b05b49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-112247875-172.17.0.7-1596063773213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41397,DS-c1fee5db-17e6-4846-b095-398a8cfaa8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-515b56ae-3fb6-42b4-ba75-30c81147710f,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-61664f7e-e3f6-46cb-8b12-d1fc747626e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40138,DS-d018bed1-403e-4067-bb39-cff18e2bd331,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-5f2f7725-c411-4220-87aa-b9d80eedd14b,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-c51ebd19-5479-447c-b156-c09aebd8d072,DISK], DatanodeInfoWithStorage[127.0.0.1:38095,DS-87f7ff27-e8ba-4ff6-a1e0-4d8464f32b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-29d74065-c158-41f0-8606-5d6cb7b05b49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2079087415-172.17.0.7-1596064076373:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36847,DS-84e6b26c-3fc2-44a7-8b41-9106d5f63ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-757cd57b-343e-46d8-97c1-1cf173915c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-560dd52d-a184-4748-b60f-59d4d2381bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-399fbc89-0592-4bee-9c3a-72d5022b601b,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-c623f1a4-92ed-4ee7-87b5-b3660e2b312e,DISK], DatanodeInfoWithStorage[127.0.0.1:40382,DS-bb00033d-434b-4bf7-b6ca-1fd37869cbf3,DISK], DatanodeInfoWithStorage[127.0.0.1:33463,DS-4dffb3b0-fbda-4d93-a5c2-3dc18b9f7572,DISK], DatanodeInfoWithStorage[127.0.0.1:40186,DS-2d8c39d0-110e-4678-aa7a-a4843f087da5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2079087415-172.17.0.7-1596064076373:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36847,DS-84e6b26c-3fc2-44a7-8b41-9106d5f63ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-757cd57b-343e-46d8-97c1-1cf173915c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-560dd52d-a184-4748-b60f-59d4d2381bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-399fbc89-0592-4bee-9c3a-72d5022b601b,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-c623f1a4-92ed-4ee7-87b5-b3660e2b312e,DISK], DatanodeInfoWithStorage[127.0.0.1:40382,DS-bb00033d-434b-4bf7-b6ca-1fd37869cbf3,DISK], DatanodeInfoWithStorage[127.0.0.1:33463,DS-4dffb3b0-fbda-4d93-a5c2-3dc18b9f7572,DISK], DatanodeInfoWithStorage[127.0.0.1:40186,DS-2d8c39d0-110e-4678-aa7a-a4843f087da5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1092381881-172.17.0.7-1596064806377:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41366,DS-f79bfa59-5133-4f9c-9b49-87d5b0410e63,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-4e926be0-0086-4845-b6cd-d535a1e21e40,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-d352729e-300c-4039-a7b4-eeba32a46844,DISK], DatanodeInfoWithStorage[127.0.0.1:38766,DS-aa81c557-c139-4de3-b1ca-baa246893263,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-409916bb-8b94-4b63-a20f-fae0cc359cab,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-8da2cb36-52c1-46ac-be43-4b72756ff6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-09212c6a-3284-4210-a342-1b39cbed8ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-4f8c7307-1648-46e5-a039-546ff167a402,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1092381881-172.17.0.7-1596064806377:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41366,DS-f79bfa59-5133-4f9c-9b49-87d5b0410e63,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-4e926be0-0086-4845-b6cd-d535a1e21e40,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-d352729e-300c-4039-a7b4-eeba32a46844,DISK], DatanodeInfoWithStorage[127.0.0.1:38766,DS-aa81c557-c139-4de3-b1ca-baa246893263,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-409916bb-8b94-4b63-a20f-fae0cc359cab,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-8da2cb36-52c1-46ac-be43-4b72756ff6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-09212c6a-3284-4210-a342-1b39cbed8ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-4f8c7307-1648-46e5-a039-546ff167a402,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2101898582-172.17.0.7-1596065449577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40867,DS-39443d86-369d-4381-b6ec-f38427139da5,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-793cd224-99a1-4751-bc7d-4f4cfc46389b,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-c89c7819-b68a-4003-91a5-628abf9f291c,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-cf1f27fe-2182-4624-9f70-a2847dff3b86,DISK], DatanodeInfoWithStorage[127.0.0.1:35622,DS-447b4cd5-b2f2-456c-9c88-92ed5f85de14,DISK], DatanodeInfoWithStorage[127.0.0.1:38697,DS-68629d06-3d20-4ff5-bec1-cd0862e3ce0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41157,DS-a45d76ad-8426-4b0f-b3eb-67edc1165783,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-53f64615-0220-4ade-92b5-8dedce3c10c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2101898582-172.17.0.7-1596065449577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40867,DS-39443d86-369d-4381-b6ec-f38427139da5,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-793cd224-99a1-4751-bc7d-4f4cfc46389b,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-c89c7819-b68a-4003-91a5-628abf9f291c,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-cf1f27fe-2182-4624-9f70-a2847dff3b86,DISK], DatanodeInfoWithStorage[127.0.0.1:35622,DS-447b4cd5-b2f2-456c-9c88-92ed5f85de14,DISK], DatanodeInfoWithStorage[127.0.0.1:38697,DS-68629d06-3d20-4ff5-bec1-cd0862e3ce0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41157,DS-a45d76ad-8426-4b0f-b3eb-67edc1165783,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-53f64615-0220-4ade-92b5-8dedce3c10c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1742151038-172.17.0.7-1596065526289:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44389,DS-85956a7b-c39d-4816-86a8-e1c3e8b99b81,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-70dcac27-5c6c-47a6-b9a2-7ca9f50eae6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-329c4816-ab26-4624-a9c2-0ffe9c71fea1,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-e010225b-3782-4b53-b452-3270eff7e95f,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-b6aeb722-7b6e-4e87-9ad2-c2759929fa9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-69f0c70b-3003-4a76-b4fa-b03dd4e4af26,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-30f13015-ae7e-472a-8e45-320ca491940f,DISK], DatanodeInfoWithStorage[127.0.0.1:33084,DS-28fb7d88-6924-42cc-8e37-4f4697158e0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1742151038-172.17.0.7-1596065526289:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44389,DS-85956a7b-c39d-4816-86a8-e1c3e8b99b81,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-70dcac27-5c6c-47a6-b9a2-7ca9f50eae6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-329c4816-ab26-4624-a9c2-0ffe9c71fea1,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-e010225b-3782-4b53-b452-3270eff7e95f,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-b6aeb722-7b6e-4e87-9ad2-c2759929fa9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-69f0c70b-3003-4a76-b4fa-b03dd4e4af26,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-30f13015-ae7e-472a-8e45-320ca491940f,DISK], DatanodeInfoWithStorage[127.0.0.1:33084,DS-28fb7d88-6924-42cc-8e37-4f4697158e0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1436826527-172.17.0.7-1596065803064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40448,DS-f0ef42bb-c1ca-4cf5-9105-6974b20413a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-5bd51828-5372-4814-b8a1-19d16a5206bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44365,DS-192f50c8-d1e7-4193-bfa6-0caf2dd3f0db,DISK], DatanodeInfoWithStorage[127.0.0.1:38578,DS-8b0913b2-ca68-49cd-9889-3e4796c1b4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-a13c28e7-149a-4b9e-bf73-0eef93a7cb64,DISK], DatanodeInfoWithStorage[127.0.0.1:35276,DS-c43a20fb-b0ff-42e9-997f-599b6eb0886e,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-050ecf4d-f421-4da1-aaa4-4db8501e0dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:39145,DS-78655daa-30f4-44d4-bfaf-244d02a9ab4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1436826527-172.17.0.7-1596065803064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40448,DS-f0ef42bb-c1ca-4cf5-9105-6974b20413a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-5bd51828-5372-4814-b8a1-19d16a5206bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44365,DS-192f50c8-d1e7-4193-bfa6-0caf2dd3f0db,DISK], DatanodeInfoWithStorage[127.0.0.1:38578,DS-8b0913b2-ca68-49cd-9889-3e4796c1b4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-a13c28e7-149a-4b9e-bf73-0eef93a7cb64,DISK], DatanodeInfoWithStorage[127.0.0.1:35276,DS-c43a20fb-b0ff-42e9-997f-599b6eb0886e,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-050ecf4d-f421-4da1-aaa4-4db8501e0dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:39145,DS-78655daa-30f4-44d4-bfaf-244d02a9ab4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1466558338-172.17.0.7-1596066015790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34798,DS-995a81a3-5db6-4e91-86bb-27189e8e45bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-3bf21666-6a3a-4dde-a0b8-24b6a333aa19,DISK], DatanodeInfoWithStorage[127.0.0.1:43875,DS-abb7cc8a-0e6e-4fff-bdb3-06a9c440264a,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-5ea1c378-329a-426b-8096-56be41a1d681,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-235a1ece-11d4-400b-90a0-1ecaa92e3fba,DISK], DatanodeInfoWithStorage[127.0.0.1:34242,DS-bb526b36-c6de-4311-aff3-141caecc893b,DISK], DatanodeInfoWithStorage[127.0.0.1:34646,DS-9bf229a8-4eac-4da4-b3b4-a864830188b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-de86a995-b6a7-4b6d-95b3-cf9a25816678,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1466558338-172.17.0.7-1596066015790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34798,DS-995a81a3-5db6-4e91-86bb-27189e8e45bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-3bf21666-6a3a-4dde-a0b8-24b6a333aa19,DISK], DatanodeInfoWithStorage[127.0.0.1:43875,DS-abb7cc8a-0e6e-4fff-bdb3-06a9c440264a,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-5ea1c378-329a-426b-8096-56be41a1d681,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-235a1ece-11d4-400b-90a0-1ecaa92e3fba,DISK], DatanodeInfoWithStorage[127.0.0.1:34242,DS-bb526b36-c6de-4311-aff3-141caecc893b,DISK], DatanodeInfoWithStorage[127.0.0.1:34646,DS-9bf229a8-4eac-4da4-b3b4-a864830188b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-de86a995-b6a7-4b6d-95b3-cf9a25816678,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1213169567-172.17.0.7-1596066904327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34578,DS-56d74f54-5cdc-4662-a8d6-27d5db3c18fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-a12ac723-400d-4827-88cb-742fce59ae72,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-5766028a-8917-47df-8ff5-0d1486e746ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-79cc6fcf-4107-4a72-99e5-6025da067aea,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-7dd4558c-f72b-498d-86b4-855da2074f78,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-17fa00a8-a875-4eef-9c90-8ccedfd2d770,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-cd85fd9a-92c0-4aec-a30c-02af6053f140,DISK], DatanodeInfoWithStorage[127.0.0.1:37768,DS-cf32f968-1f57-4e4f-8435-edd1d9c5a5cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1213169567-172.17.0.7-1596066904327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34578,DS-56d74f54-5cdc-4662-a8d6-27d5db3c18fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-a12ac723-400d-4827-88cb-742fce59ae72,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-5766028a-8917-47df-8ff5-0d1486e746ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-79cc6fcf-4107-4a72-99e5-6025da067aea,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-7dd4558c-f72b-498d-86b4-855da2074f78,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-17fa00a8-a875-4eef-9c90-8ccedfd2d770,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-cd85fd9a-92c0-4aec-a30c-02af6053f140,DISK], DatanodeInfoWithStorage[127.0.0.1:37768,DS-cf32f968-1f57-4e4f-8435-edd1d9c5a5cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-135754956-172.17.0.7-1596066942745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35714,DS-d0c35ceb-8b59-47a1-9156-30f91e362f87,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-ff3bc88b-d936-4364-b144-c1750be996af,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-23a0f3d0-ee90-4f59-961c-51efec95bfed,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-b5b80836-8740-42a5-8c1a-ff947ffd106d,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-3bed808b-d108-436c-8eb3-4b770fdd4023,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-241b8d15-f5da-4ee5-8064-168777e03bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-a2a58c52-2e67-423e-8971-d3bceb203074,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-ff9ba230-dc8f-4c41-bcf5-abece4c08b5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-135754956-172.17.0.7-1596066942745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35714,DS-d0c35ceb-8b59-47a1-9156-30f91e362f87,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-ff3bc88b-d936-4364-b144-c1750be996af,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-23a0f3d0-ee90-4f59-961c-51efec95bfed,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-b5b80836-8740-42a5-8c1a-ff947ffd106d,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-3bed808b-d108-436c-8eb3-4b770fdd4023,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-241b8d15-f5da-4ee5-8064-168777e03bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-a2a58c52-2e67-423e-8971-d3bceb203074,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-ff9ba230-dc8f-4c41-bcf5-abece4c08b5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-986344189-172.17.0.7-1596067062732:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46691,DS-4bf685b1-d656-4783-a04b-c5b994461673,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-f2f7ca87-75e5-4cb5-9de6-424f7d7492b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-b3e64588-b862-428d-934f-b81e0024de28,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-7702bdf9-fd9b-45c7-89c1-b00f4c4a1abc,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-a4aee20d-0618-40fb-886f-3b09bcca232f,DISK], DatanodeInfoWithStorage[127.0.0.1:43765,DS-04e92e51-b8fd-4a71-a95a-f86afe70a9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-3bb90b20-2b1a-4553-a1ec-19a6b5885d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-57ee447e-e996-4958-8a33-839b27ac3698,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-986344189-172.17.0.7-1596067062732:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46691,DS-4bf685b1-d656-4783-a04b-c5b994461673,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-f2f7ca87-75e5-4cb5-9de6-424f7d7492b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-b3e64588-b862-428d-934f-b81e0024de28,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-7702bdf9-fd9b-45c7-89c1-b00f4c4a1abc,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-a4aee20d-0618-40fb-886f-3b09bcca232f,DISK], DatanodeInfoWithStorage[127.0.0.1:43765,DS-04e92e51-b8fd-4a71-a95a-f86afe70a9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-3bb90b20-2b1a-4553-a1ec-19a6b5885d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-57ee447e-e996-4958-8a33-839b27ac3698,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1838809734-172.17.0.7-1596067111343:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34142,DS-0c21ec14-7879-45b3-b5aa-0578d2b782e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-97a80ec0-a04d-485b-9557-6939d5f05cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-637633a8-3a34-42df-b830-b305f5102e55,DISK], DatanodeInfoWithStorage[127.0.0.1:34923,DS-7b172946-935e-442e-b297-e57945c4c8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-462a1b44-5d4d-4389-a003-11a494117a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-927097ae-132c-441a-86bd-85a5c2b09a01,DISK], DatanodeInfoWithStorage[127.0.0.1:38386,DS-f5771b50-2550-480a-a922-6b5686fabc7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-ebbd643d-a6c5-4dd8-9f80-622e7667b932,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1838809734-172.17.0.7-1596067111343:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34142,DS-0c21ec14-7879-45b3-b5aa-0578d2b782e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-97a80ec0-a04d-485b-9557-6939d5f05cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-637633a8-3a34-42df-b830-b305f5102e55,DISK], DatanodeInfoWithStorage[127.0.0.1:34923,DS-7b172946-935e-442e-b297-e57945c4c8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-462a1b44-5d4d-4389-a003-11a494117a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-927097ae-132c-441a-86bd-85a5c2b09a01,DISK], DatanodeInfoWithStorage[127.0.0.1:38386,DS-f5771b50-2550-480a-a922-6b5686fabc7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-ebbd643d-a6c5-4dd8-9f80-622e7667b932,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1531458739-172.17.0.7-1596067315945:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44528,DS-3c4a5521-8480-4615-b6a2-5b6961df5091,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-5ad8f1ad-f042-4912-9d24-1432e127cab7,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-e93ffa69-0e4d-4c88-9002-1d6bf70d1c00,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-d79143a8-b459-4cfb-8b30-68b4875dfa88,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-3e069925-8d57-44d2-baa4-f987e6b30e20,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-72965b16-8d72-48e5-b73d-32606b9d20e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-c7746be5-7a48-45d1-b9e3-a51416ef925e,DISK], DatanodeInfoWithStorage[127.0.0.1:35065,DS-6648a5ed-dd24-4e48-909d-bfefa43cf191,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1531458739-172.17.0.7-1596067315945:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44528,DS-3c4a5521-8480-4615-b6a2-5b6961df5091,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-5ad8f1ad-f042-4912-9d24-1432e127cab7,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-e93ffa69-0e4d-4c88-9002-1d6bf70d1c00,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-d79143a8-b459-4cfb-8b30-68b4875dfa88,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-3e069925-8d57-44d2-baa4-f987e6b30e20,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-72965b16-8d72-48e5-b73d-32606b9d20e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-c7746be5-7a48-45d1-b9e3-a51416ef925e,DISK], DatanodeInfoWithStorage[127.0.0.1:35065,DS-6648a5ed-dd24-4e48-909d-bfefa43cf191,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-347504916-172.17.0.7-1596067353619:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46220,DS-a2b9bbc8-5fb0-4504-b76c-376a22df55b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-aa4abcef-5ee5-42ff-96ce-675effde33ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-1f9f0faa-8737-4039-aa70-a604646fc92e,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-63a4145c-2634-4549-9526-397c8b12e08b,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-96b70e51-1578-4684-bdf7-b966dafdc813,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-63b72d20-1377-4cb9-aca5-0c121e2d3746,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-ba189dfc-d791-4001-9457-421aa71cd07a,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-c33a8c28-daef-473c-9290-fa00124d75db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-347504916-172.17.0.7-1596067353619:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46220,DS-a2b9bbc8-5fb0-4504-b76c-376a22df55b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-aa4abcef-5ee5-42ff-96ce-675effde33ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-1f9f0faa-8737-4039-aa70-a604646fc92e,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-63a4145c-2634-4549-9526-397c8b12e08b,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-96b70e51-1578-4684-bdf7-b966dafdc813,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-63b72d20-1377-4cb9-aca5-0c121e2d3746,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-ba189dfc-d791-4001-9457-421aa71cd07a,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-c33a8c28-daef-473c-9290-fa00124d75db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2132811974-172.17.0.7-1596067676513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45417,DS-550f7025-09d6-407b-b368-e1603ca0e490,DISK], DatanodeInfoWithStorage[127.0.0.1:35889,DS-be663751-fb22-4e5e-bb78-384f402e1113,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-6ebe46d5-669d-4cb5-8f77-cbfa370c2006,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-516eb00d-01c8-4e9e-bf6d-868a5220d99e,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-298d97bd-0f90-4789-96e6-73a85cca2187,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-7e971338-739e-437c-a4a4-9eb6b07ecd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-cd46abb4-b64d-41ef-b60e-792d2675476b,DISK], DatanodeInfoWithStorage[127.0.0.1:39425,DS-6ab46493-2a08-448e-a532-56d399e7a8ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2132811974-172.17.0.7-1596067676513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45417,DS-550f7025-09d6-407b-b368-e1603ca0e490,DISK], DatanodeInfoWithStorage[127.0.0.1:35889,DS-be663751-fb22-4e5e-bb78-384f402e1113,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-6ebe46d5-669d-4cb5-8f77-cbfa370c2006,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-516eb00d-01c8-4e9e-bf6d-868a5220d99e,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-298d97bd-0f90-4789-96e6-73a85cca2187,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-7e971338-739e-437c-a4a4-9eb6b07ecd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-cd46abb4-b64d-41ef-b60e-792d2675476b,DISK], DatanodeInfoWithStorage[127.0.0.1:39425,DS-6ab46493-2a08-448e-a532-56d399e7a8ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1104517158-172.17.0.7-1596068366418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34706,DS-b97c9a22-7b8b-495e-8714-6f2ed0b34cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-b6199762-1099-45ac-bb52-60ffcd454c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40932,DS-ca271647-fc7f-4511-8b01-a297ccd1fd06,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-98dde295-bd18-4173-9c56-d50cb49ef60c,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-842e3509-22e1-41f4-a7f8-68d5b8b71c27,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-83128b81-b380-4004-bed9-2c70e66122ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-30c0e4cf-ea2c-4635-93dc-44131113e963,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-840fa953-ddb5-455c-a07c-990da6fad27a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1104517158-172.17.0.7-1596068366418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34706,DS-b97c9a22-7b8b-495e-8714-6f2ed0b34cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-b6199762-1099-45ac-bb52-60ffcd454c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40932,DS-ca271647-fc7f-4511-8b01-a297ccd1fd06,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-98dde295-bd18-4173-9c56-d50cb49ef60c,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-842e3509-22e1-41f4-a7f8-68d5b8b71c27,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-83128b81-b380-4004-bed9-2c70e66122ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-30c0e4cf-ea2c-4635-93dc-44131113e963,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-840fa953-ddb5-455c-a07c-990da6fad27a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1152668837-172.17.0.7-1596069055993:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41908,DS-60fb8d98-68bb-4fa5-89de-13343d248a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-5345f5dd-5064-46df-a6e0-f920a85e71ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-582254c3-a994-41da-bb03-7322f1ac6c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42387,DS-294183a5-a4aa-4601-b3d8-9652abc576c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-7c456829-7c5e-489c-bbc1-58deff551ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-a0d3f4c6-9c41-4cbb-9d2e-4064734243ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-1a318b0d-7f35-428b-b5c9-8cb881b5ea07,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-f963f089-413f-494e-901d-a34fcb02d017,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1152668837-172.17.0.7-1596069055993:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41908,DS-60fb8d98-68bb-4fa5-89de-13343d248a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-5345f5dd-5064-46df-a6e0-f920a85e71ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-582254c3-a994-41da-bb03-7322f1ac6c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42387,DS-294183a5-a4aa-4601-b3d8-9652abc576c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-7c456829-7c5e-489c-bbc1-58deff551ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-a0d3f4c6-9c41-4cbb-9d2e-4064734243ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-1a318b0d-7f35-428b-b5c9-8cb881b5ea07,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-f963f089-413f-494e-901d-a34fcb02d017,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6334
