reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092417063-172.17.0.20-1595976384391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33925,DS-4b779a6a-2032-44cb-b62c-95d4de072b22,DISK], DatanodeInfoWithStorage[127.0.0.1:41431,DS-babe896c-3987-476b-84e0-70a747b798b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-2a454a42-6cac-42c4-8773-46248638803d,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-11426555-0fbd-4110-b772-ff81f790d0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46697,DS-3b879cd6-74e6-4589-8b50-c1a628cd28ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-4112a127-ef73-4a00-b17f-81e1745cb91c,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-5e4fb300-0973-49d5-b66c-4c41dd8968c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40851,DS-34d0af64-0bc3-4f7d-be3e-2ddc0ac7fc86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092417063-172.17.0.20-1595976384391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33925,DS-4b779a6a-2032-44cb-b62c-95d4de072b22,DISK], DatanodeInfoWithStorage[127.0.0.1:41431,DS-babe896c-3987-476b-84e0-70a747b798b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-2a454a42-6cac-42c4-8773-46248638803d,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-11426555-0fbd-4110-b772-ff81f790d0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46697,DS-3b879cd6-74e6-4589-8b50-c1a628cd28ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-4112a127-ef73-4a00-b17f-81e1745cb91c,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-5e4fb300-0973-49d5-b66c-4c41dd8968c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40851,DS-34d0af64-0bc3-4f7d-be3e-2ddc0ac7fc86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-482411983-172.17.0.20-1595976512647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34773,DS-ada491e4-9609-44c1-b0ae-f10e6f30c33c,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-5519dbaa-84d8-4863-8597-9012bcb2257b,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-047927ab-c189-493b-bb5e-c32bb6d3b278,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-66ddbc9c-9f52-49cb-b381-1b7413d65c62,DISK], DatanodeInfoWithStorage[127.0.0.1:45254,DS-1cd84a5e-442d-4ae5-986f-43f72052b103,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-8cee6e0c-33f7-40a0-a6b2-6eafeacf6644,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-5141629f-25fc-4e61-b294-227a570ac6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-98c65e6a-cc7b-4fdc-a593-5770690ea7c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-482411983-172.17.0.20-1595976512647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34773,DS-ada491e4-9609-44c1-b0ae-f10e6f30c33c,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-5519dbaa-84d8-4863-8597-9012bcb2257b,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-047927ab-c189-493b-bb5e-c32bb6d3b278,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-66ddbc9c-9f52-49cb-b381-1b7413d65c62,DISK], DatanodeInfoWithStorage[127.0.0.1:45254,DS-1cd84a5e-442d-4ae5-986f-43f72052b103,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-8cee6e0c-33f7-40a0-a6b2-6eafeacf6644,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-5141629f-25fc-4e61-b294-227a570ac6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-98c65e6a-cc7b-4fdc-a593-5770690ea7c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1993352988-172.17.0.20-1595976704718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36578,DS-4968f739-051a-447d-9427-690182124452,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-227588c8-715c-450b-880f-8694fd5e519a,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-1fe3dfd4-eb80-4c2d-a8f9-40902208fc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-d21c3fa5-d2e8-4d26-a3f9-a89df75906b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-b5476b20-ca84-4b8a-b954-45b98926a973,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-0a6174a5-68ea-4d22-ba34-ccb5af1d0787,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-1421da32-e951-42ae-8f34-a70dfca4bd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-594744b1-ffdb-46c6-9479-7acfddf17217,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1993352988-172.17.0.20-1595976704718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36578,DS-4968f739-051a-447d-9427-690182124452,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-227588c8-715c-450b-880f-8694fd5e519a,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-1fe3dfd4-eb80-4c2d-a8f9-40902208fc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-d21c3fa5-d2e8-4d26-a3f9-a89df75906b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-b5476b20-ca84-4b8a-b954-45b98926a973,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-0a6174a5-68ea-4d22-ba34-ccb5af1d0787,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-1421da32-e951-42ae-8f34-a70dfca4bd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-594744b1-ffdb-46c6-9479-7acfddf17217,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-963559991-172.17.0.20-1595976740337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38571,DS-b9e5e1fa-bd5b-4b3c-8a3f-d90ec2589c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-03b393dd-b386-4254-aa55-33f617cdf79b,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-47880a13-2a57-40d3-b1cf-55318852f7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39850,DS-be56e8a6-c370-46a8-b78a-c67ab80cc852,DISK], DatanodeInfoWithStorage[127.0.0.1:43790,DS-8344d346-05d7-41f1-9e91-ee45014bc843,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-d4ee1730-8258-4c76-b0cd-fd8c8929b82a,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-1b648adb-5ed7-4760-9cb3-ce8a91fe9484,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-e1b3f803-53cf-4e57-afdc-44cf8f6b7477,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-963559991-172.17.0.20-1595976740337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38571,DS-b9e5e1fa-bd5b-4b3c-8a3f-d90ec2589c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-03b393dd-b386-4254-aa55-33f617cdf79b,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-47880a13-2a57-40d3-b1cf-55318852f7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39850,DS-be56e8a6-c370-46a8-b78a-c67ab80cc852,DISK], DatanodeInfoWithStorage[127.0.0.1:43790,DS-8344d346-05d7-41f1-9e91-ee45014bc843,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-d4ee1730-8258-4c76-b0cd-fd8c8929b82a,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-1b648adb-5ed7-4760-9cb3-ce8a91fe9484,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-e1b3f803-53cf-4e57-afdc-44cf8f6b7477,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1503874009-172.17.0.20-1595976783967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39014,DS-18323830-d762-474b-bb97-2ac753cd79dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-9b11eb7d-d391-4108-8164-e48f3f3af0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-bf664efa-9d8f-432c-9fb0-f1bf0880fdcd,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-e00a3bd3-6ccf-4def-ac34-6b889a453e82,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-e2addf9b-ae0f-4105-b015-44d8994a3c73,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-4f031bf9-3b6e-486a-8fcb-ca87f66f7de2,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-84413171-764a-4195-af49-f3a886d27338,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-ef6f464c-7a2e-48af-81a5-00d8d452e2ce,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1503874009-172.17.0.20-1595976783967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39014,DS-18323830-d762-474b-bb97-2ac753cd79dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-9b11eb7d-d391-4108-8164-e48f3f3af0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-bf664efa-9d8f-432c-9fb0-f1bf0880fdcd,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-e00a3bd3-6ccf-4def-ac34-6b889a453e82,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-e2addf9b-ae0f-4105-b015-44d8994a3c73,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-4f031bf9-3b6e-486a-8fcb-ca87f66f7de2,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-84413171-764a-4195-af49-f3a886d27338,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-ef6f464c-7a2e-48af-81a5-00d8d452e2ce,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-925950269-172.17.0.20-1595976903150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41148,DS-7ae3c657-7984-4236-9ef1-c55dfcdda3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-c21f76bf-f3e4-43b0-a743-3af1e6fb29e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-77d073ec-eab8-4b2f-aa3f-42c92f0e9be9,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-42e952e7-122d-41c2-aaec-632e304f3124,DISK], DatanodeInfoWithStorage[127.0.0.1:43860,DS-798aa726-8c83-4e0c-8632-301019ceba7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-e604932e-7257-4fa0-a975-5417711469ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-4c7ff801-3923-46b6-9d42-082c96f1ae33,DISK], DatanodeInfoWithStorage[127.0.0.1:35763,DS-8a08848d-a33e-432e-aae6-e18d7ec30d44,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-925950269-172.17.0.20-1595976903150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41148,DS-7ae3c657-7984-4236-9ef1-c55dfcdda3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-c21f76bf-f3e4-43b0-a743-3af1e6fb29e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-77d073ec-eab8-4b2f-aa3f-42c92f0e9be9,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-42e952e7-122d-41c2-aaec-632e304f3124,DISK], DatanodeInfoWithStorage[127.0.0.1:43860,DS-798aa726-8c83-4e0c-8632-301019ceba7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-e604932e-7257-4fa0-a975-5417711469ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-4c7ff801-3923-46b6-9d42-082c96f1ae33,DISK], DatanodeInfoWithStorage[127.0.0.1:35763,DS-8a08848d-a33e-432e-aae6-e18d7ec30d44,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1161191283-172.17.0.20-1595977016229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44709,DS-58f33d5a-e16c-4cd9-b0ae-acb2fd90d383,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-6914516f-7f1d-4d6d-bae8-ca1470ca69e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-6cb5558d-a07e-40ce-be0f-bbb3df12f359,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-da977eb7-437b-45ce-a854-2c1d2bb07755,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-e658693c-3d47-471f-8ce1-3ba8e5ca70e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-2d5c48b6-693e-4582-a734-75b7269e6bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:45921,DS-a08934b6-29f6-4254-a524-f809b707116c,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-999c8315-f42f-4133-9732-6f0316ae1554,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1161191283-172.17.0.20-1595977016229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44709,DS-58f33d5a-e16c-4cd9-b0ae-acb2fd90d383,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-6914516f-7f1d-4d6d-bae8-ca1470ca69e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-6cb5558d-a07e-40ce-be0f-bbb3df12f359,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-da977eb7-437b-45ce-a854-2c1d2bb07755,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-e658693c-3d47-471f-8ce1-3ba8e5ca70e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-2d5c48b6-693e-4582-a734-75b7269e6bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:45921,DS-a08934b6-29f6-4254-a524-f809b707116c,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-999c8315-f42f-4133-9732-6f0316ae1554,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2109592869-172.17.0.20-1595977379184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35234,DS-9d7ee2ca-6708-4710-88bc-818e56b6fdbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-6ce41375-aca8-4904-86cd-b785106f71d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-67a4f176-247b-4f8d-a916-1aff81e14eac,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-574cc085-6d6f-45bc-9609-756fad458b12,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-c9af1f33-3449-4dcf-bff8-dfdda65020bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-bd1de4ac-9f85-48b9-a6a1-1a317e721fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-bf0de2d2-0f3f-4664-aa8b-a766cc3f843b,DISK], DatanodeInfoWithStorage[127.0.0.1:44590,DS-fb474495-2098-4d25-9ba5-47f3a29313d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2109592869-172.17.0.20-1595977379184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35234,DS-9d7ee2ca-6708-4710-88bc-818e56b6fdbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-6ce41375-aca8-4904-86cd-b785106f71d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-67a4f176-247b-4f8d-a916-1aff81e14eac,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-574cc085-6d6f-45bc-9609-756fad458b12,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-c9af1f33-3449-4dcf-bff8-dfdda65020bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-bd1de4ac-9f85-48b9-a6a1-1a317e721fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-bf0de2d2-0f3f-4664-aa8b-a766cc3f843b,DISK], DatanodeInfoWithStorage[127.0.0.1:44590,DS-fb474495-2098-4d25-9ba5-47f3a29313d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-173442085-172.17.0.20-1595977633008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42456,DS-d96540b0-36c1-4c20-b262-4ccfeef3d380,DISK], DatanodeInfoWithStorage[127.0.0.1:39710,DS-86aa31ce-8bd5-4e18-b12e-f56a5f6107f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-186ac477-420a-4908-b4e9-2df53270a858,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-184cd449-aeaa-4c75-aa8b-6271fcebff33,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-ebf3dcf8-5055-4982-a2b8-66a48a532eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44542,DS-d25b864f-e11e-4c51-9ff4-472f5f0d117b,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-5f470660-846f-4bf7-b0d8-4ff14ca8bcde,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-63381b33-a9f4-435c-8d99-c14c084f8bdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-173442085-172.17.0.20-1595977633008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42456,DS-d96540b0-36c1-4c20-b262-4ccfeef3d380,DISK], DatanodeInfoWithStorage[127.0.0.1:39710,DS-86aa31ce-8bd5-4e18-b12e-f56a5f6107f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-186ac477-420a-4908-b4e9-2df53270a858,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-184cd449-aeaa-4c75-aa8b-6271fcebff33,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-ebf3dcf8-5055-4982-a2b8-66a48a532eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44542,DS-d25b864f-e11e-4c51-9ff4-472f5f0d117b,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-5f470660-846f-4bf7-b0d8-4ff14ca8bcde,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-63381b33-a9f4-435c-8d99-c14c084f8bdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-540736715-172.17.0.20-1595977701345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36207,DS-ac1d123b-1a07-4f1e-97e3-fe1fe54ad1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43832,DS-7f47fa5f-2185-4229-a6e3-f2e15f61198c,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-6d869868-2eb9-41b8-a227-7d534b46e765,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-12044461-c60a-458e-a4a3-01b0a7aa610d,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-97a5793a-cb28-4271-9bb9-72c035f913e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45725,DS-8b905b24-face-4bbd-8224-0cdd6423ec78,DISK], DatanodeInfoWithStorage[127.0.0.1:41046,DS-4073fbfb-ad2d-434e-989f-651a8d810451,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-7b45224f-c4a7-495c-b0e3-819435c44340,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-540736715-172.17.0.20-1595977701345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36207,DS-ac1d123b-1a07-4f1e-97e3-fe1fe54ad1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43832,DS-7f47fa5f-2185-4229-a6e3-f2e15f61198c,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-6d869868-2eb9-41b8-a227-7d534b46e765,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-12044461-c60a-458e-a4a3-01b0a7aa610d,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-97a5793a-cb28-4271-9bb9-72c035f913e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45725,DS-8b905b24-face-4bbd-8224-0cdd6423ec78,DISK], DatanodeInfoWithStorage[127.0.0.1:41046,DS-4073fbfb-ad2d-434e-989f-651a8d810451,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-7b45224f-c4a7-495c-b0e3-819435c44340,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-215076588-172.17.0.20-1595977814044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45899,DS-9abfd9c9-bcbb-4b28-b45b-ac7b89420e28,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-d8eb1779-e497-4cf0-a1b0-ab26efd3e07b,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-3c492bbd-75a1-4639-8414-445b8e46cf2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44419,DS-18c9800b-897c-4212-92d7-c102be12ea33,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-7405c37a-2ffc-4e3a-a60e-398b635dbca8,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-fad9ec27-13aa-44ec-a595-5458b1adfae0,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-c09320e9-be9a-4ced-9aac-8de4f2a30229,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-58b3fbd9-82f4-4f41-8204-719a18a0b944,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-215076588-172.17.0.20-1595977814044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45899,DS-9abfd9c9-bcbb-4b28-b45b-ac7b89420e28,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-d8eb1779-e497-4cf0-a1b0-ab26efd3e07b,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-3c492bbd-75a1-4639-8414-445b8e46cf2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44419,DS-18c9800b-897c-4212-92d7-c102be12ea33,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-7405c37a-2ffc-4e3a-a60e-398b635dbca8,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-fad9ec27-13aa-44ec-a595-5458b1adfae0,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-c09320e9-be9a-4ced-9aac-8de4f2a30229,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-58b3fbd9-82f4-4f41-8204-719a18a0b944,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1678503674-172.17.0.20-1595977990522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32881,DS-a6c59803-18d9-4168-a210-de2ab2db288a,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-f2c89c03-bad4-46fa-9ecb-b31f1989a089,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-98879f4f-ad1e-4489-88a2-3104d3e7588f,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-aa59ce8f-fe1d-4d88-82ab-0eb6d02fa50f,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-0f9753b8-3856-4518-92e8-dcea4a89884b,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-98d542e1-8aa4-4326-9e43-df4218e6fec4,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-cab2d0aa-cde0-4d39-a564-e480ea251f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-a12d2694-90b8-429b-adfd-2a9416e1703d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1678503674-172.17.0.20-1595977990522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32881,DS-a6c59803-18d9-4168-a210-de2ab2db288a,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-f2c89c03-bad4-46fa-9ecb-b31f1989a089,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-98879f4f-ad1e-4489-88a2-3104d3e7588f,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-aa59ce8f-fe1d-4d88-82ab-0eb6d02fa50f,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-0f9753b8-3856-4518-92e8-dcea4a89884b,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-98d542e1-8aa4-4326-9e43-df4218e6fec4,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-cab2d0aa-cde0-4d39-a564-e480ea251f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-a12d2694-90b8-429b-adfd-2a9416e1703d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1103129616-172.17.0.20-1595978029342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38575,DS-d97dd464-25b7-47c1-b7a2-59f46cab8145,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-954caaf1-6338-445c-80aa-22343f4a2b54,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-1a328527-afce-4b1c-9aeb-7fcf852bd698,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-b1ce6c3a-70d5-47b1-8124-c7490474d5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-286921eb-24c3-411f-8ce5-dc8ac70aca05,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-ece35c58-f4e4-46cb-bc3a-aa294a441d59,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-dc25b9bb-f0c1-439e-be06-df45caff93da,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-64d424e4-24b5-46f9-8de6-791d1a8cace1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1103129616-172.17.0.20-1595978029342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38575,DS-d97dd464-25b7-47c1-b7a2-59f46cab8145,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-954caaf1-6338-445c-80aa-22343f4a2b54,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-1a328527-afce-4b1c-9aeb-7fcf852bd698,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-b1ce6c3a-70d5-47b1-8124-c7490474d5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-286921eb-24c3-411f-8ce5-dc8ac70aca05,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-ece35c58-f4e4-46cb-bc3a-aa294a441d59,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-dc25b9bb-f0c1-439e-be06-df45caff93da,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-64d424e4-24b5-46f9-8de6-791d1a8cace1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1219117626-172.17.0.20-1595978189054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45164,DS-3a3abad3-b7ae-4012-b2cf-0d397f45a057,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-95c52834-b688-43c3-87a2-49622afe2634,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-603005b0-0a84-4ac1-b8fc-c67a35c63971,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-f3a5dbd9-e416-41ec-88d4-08d81b2e78fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-318a05ac-1b88-4c22-9e9e-4577acea6c69,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-3c4ef53f-bd93-4ada-b037-d38d2045d156,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-b1ce0d1b-e588-4ccb-b9bf-d2ae8c462da8,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-6e3d5abc-76fa-49b2-820b-74cbf4a5725b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1219117626-172.17.0.20-1595978189054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45164,DS-3a3abad3-b7ae-4012-b2cf-0d397f45a057,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-95c52834-b688-43c3-87a2-49622afe2634,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-603005b0-0a84-4ac1-b8fc-c67a35c63971,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-f3a5dbd9-e416-41ec-88d4-08d81b2e78fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-318a05ac-1b88-4c22-9e9e-4577acea6c69,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-3c4ef53f-bd93-4ada-b037-d38d2045d156,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-b1ce0d1b-e588-4ccb-b9bf-d2ae8c462da8,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-6e3d5abc-76fa-49b2-820b-74cbf4a5725b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2050657126-172.17.0.20-1595978286244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44875,DS-ce8195c3-dea1-4d30-ae7b-4f951cc7c569,DISK], DatanodeInfoWithStorage[127.0.0.1:34310,DS-9fa34aa0-41ff-4659-badd-6952a061770e,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-97814a7e-f9a9-4fae-bdda-dc882bcf3650,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-965daecb-1b0f-423e-aa68-89a88eb12ede,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-a85e70d4-238e-4350-8fd7-b1de2373bba4,DISK], DatanodeInfoWithStorage[127.0.0.1:40470,DS-1bde8f0a-6755-490a-9b30-7f65ec1a7ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-dbe86fab-83ad-4abd-a93a-a5bbf7ad7f84,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-733af772-35b1-43de-9add-4c49413097f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2050657126-172.17.0.20-1595978286244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44875,DS-ce8195c3-dea1-4d30-ae7b-4f951cc7c569,DISK], DatanodeInfoWithStorage[127.0.0.1:34310,DS-9fa34aa0-41ff-4659-badd-6952a061770e,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-97814a7e-f9a9-4fae-bdda-dc882bcf3650,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-965daecb-1b0f-423e-aa68-89a88eb12ede,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-a85e70d4-238e-4350-8fd7-b1de2373bba4,DISK], DatanodeInfoWithStorage[127.0.0.1:40470,DS-1bde8f0a-6755-490a-9b30-7f65ec1a7ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-dbe86fab-83ad-4abd-a93a-a5bbf7ad7f84,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-733af772-35b1-43de-9add-4c49413097f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1858119546-172.17.0.20-1595978322912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43352,DS-6973863b-aaf0-4f9d-a990-57e05e2fc74a,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-dc3caaca-3e12-49f3-9abc-92dc5a9116b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-66eef2b4-83aa-4957-bfe2-67e41a643ded,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-3c643982-6410-4646-bf39-97164518d22e,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-82ddbaaa-81c2-4f4b-b572-46fcade0ed2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36908,DS-ad195bfb-4dbb-46bc-a0c8-782439d7eda2,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-e93f1311-8462-42c1-9402-b0ced5058659,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-4c768b12-b967-4bb9-a15c-bc8e93059947,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1858119546-172.17.0.20-1595978322912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43352,DS-6973863b-aaf0-4f9d-a990-57e05e2fc74a,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-dc3caaca-3e12-49f3-9abc-92dc5a9116b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-66eef2b4-83aa-4957-bfe2-67e41a643ded,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-3c643982-6410-4646-bf39-97164518d22e,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-82ddbaaa-81c2-4f4b-b572-46fcade0ed2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36908,DS-ad195bfb-4dbb-46bc-a0c8-782439d7eda2,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-e93f1311-8462-42c1-9402-b0ced5058659,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-4c768b12-b967-4bb9-a15c-bc8e93059947,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1246405137-172.17.0.20-1595978361024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45249,DS-99745452-d5cc-4317-a2de-bb911703ba2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-3653dcb1-f6b0-4d97-87e7-253a43b9097e,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-aa9ab053-24f4-47c7-80d4-5eb17468dc71,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-0f12a1dc-a51d-4816-8343-a9ae1aa84a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-c131ed4e-af3c-4fb6-bb6d-8c72d0394833,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-72220340-289f-4278-aa6b-aa4052a107e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-3563c7c4-b857-459a-9028-63a38045d290,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-1da7c71f-b5bc-4fd2-9732-ea4c7fdd0cba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1246405137-172.17.0.20-1595978361024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45249,DS-99745452-d5cc-4317-a2de-bb911703ba2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-3653dcb1-f6b0-4d97-87e7-253a43b9097e,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-aa9ab053-24f4-47c7-80d4-5eb17468dc71,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-0f12a1dc-a51d-4816-8343-a9ae1aa84a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-c131ed4e-af3c-4fb6-bb6d-8c72d0394833,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-72220340-289f-4278-aa6b-aa4052a107e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-3563c7c4-b857-459a-9028-63a38045d290,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-1da7c71f-b5bc-4fd2-9732-ea4c7fdd0cba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-782493287-172.17.0.20-1595978394181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38215,DS-7ffee0f0-f6e8-4fff-9bd1-005b0a19d369,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-a85a9167-8873-4597-8d0b-9a9673c7bd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-8a6240c0-94ec-4ab3-9b2c-59cf2e66d4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39523,DS-03e5adaa-4754-442c-aa9c-bd9e2ff923e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-ead3e4e8-4f8d-422c-8da2-572130dbb314,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-3107d4fb-93f6-4934-a424-198722f1c0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-ec2a8b5d-d8f4-49c9-9553-666c60fdee5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-828b39ed-13fe-4752-bcb0-9bd43b6dd7b1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-782493287-172.17.0.20-1595978394181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38215,DS-7ffee0f0-f6e8-4fff-9bd1-005b0a19d369,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-a85a9167-8873-4597-8d0b-9a9673c7bd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-8a6240c0-94ec-4ab3-9b2c-59cf2e66d4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39523,DS-03e5adaa-4754-442c-aa9c-bd9e2ff923e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-ead3e4e8-4f8d-422c-8da2-572130dbb314,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-3107d4fb-93f6-4934-a424-198722f1c0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-ec2a8b5d-d8f4-49c9-9553-666c60fdee5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-828b39ed-13fe-4752-bcb0-9bd43b6dd7b1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-665519646-172.17.0.20-1595978503758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46375,DS-c098ad8d-e5d3-4515-80a4-6e70a2742395,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-7afa31f0-c0a0-49f0-a54a-b660e0844aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:43370,DS-eef8c38a-1a04-45fe-9dcc-c5b72b9acc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36447,DS-95d935c6-db16-4dee-a9e5-248c2ba36040,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-ac44e702-607d-41c3-9d6d-a45d5666aeb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-9c912572-6b69-4490-96a5-8f360e467ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-ac7e9839-29ad-465f-8b7b-499233b884dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-04c00cc7-59e3-4515-81c9-dd82848c1d8e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-665519646-172.17.0.20-1595978503758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46375,DS-c098ad8d-e5d3-4515-80a4-6e70a2742395,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-7afa31f0-c0a0-49f0-a54a-b660e0844aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:43370,DS-eef8c38a-1a04-45fe-9dcc-c5b72b9acc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36447,DS-95d935c6-db16-4dee-a9e5-248c2ba36040,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-ac44e702-607d-41c3-9d6d-a45d5666aeb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-9c912572-6b69-4490-96a5-8f360e467ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-ac7e9839-29ad-465f-8b7b-499233b884dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-04c00cc7-59e3-4515-81c9-dd82848c1d8e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-780452683-172.17.0.20-1595978574498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46041,DS-ca681bcd-af9f-4288-8ab8-316a7944f6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-2e8a5803-4159-4027-b0fa-4d028359ee27,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-3a69c4bf-c37a-4e5b-ac16-c1754059f23d,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-9ecd041c-a2c7-4973-ba16-4a0cdcbbb201,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-d5baac60-ecbe-4521-9f51-301e803440b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-01224b2b-e1c1-4c3d-b11e-ac31a75180e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-c7ca8e2b-6fdb-48dc-bd7d-df4c64129a48,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-5d1249d2-3fc3-47f8-bdb6-d4ab8de0a4a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-780452683-172.17.0.20-1595978574498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46041,DS-ca681bcd-af9f-4288-8ab8-316a7944f6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-2e8a5803-4159-4027-b0fa-4d028359ee27,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-3a69c4bf-c37a-4e5b-ac16-c1754059f23d,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-9ecd041c-a2c7-4973-ba16-4a0cdcbbb201,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-d5baac60-ecbe-4521-9f51-301e803440b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-01224b2b-e1c1-4c3d-b11e-ac31a75180e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-c7ca8e2b-6fdb-48dc-bd7d-df4c64129a48,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-5d1249d2-3fc3-47f8-bdb6-d4ab8de0a4a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-106771477-172.17.0.20-1595978713899:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44999,DS-631d945d-9127-484c-8989-3ebe8b219ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:38684,DS-8163e731-8cc1-41d1-9b10-b32ad46b6b80,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-bf483b43-9e87-4705-96b5-4ddd8af6cc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-1837be2e-5150-4e15-90c2-834cbccef54f,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-1faf71fa-0d78-48c7-bc54-8f562015c747,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-84c0e8c9-18b8-43bb-83a3-69564c771fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45749,DS-ee9ec4d2-3d94-4585-8ce7-af4e1cf4c9fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-2dd932f7-31a2-4fa0-b8f7-f76b50bfc603,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-106771477-172.17.0.20-1595978713899:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44999,DS-631d945d-9127-484c-8989-3ebe8b219ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:38684,DS-8163e731-8cc1-41d1-9b10-b32ad46b6b80,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-bf483b43-9e87-4705-96b5-4ddd8af6cc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-1837be2e-5150-4e15-90c2-834cbccef54f,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-1faf71fa-0d78-48c7-bc54-8f562015c747,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-84c0e8c9-18b8-43bb-83a3-69564c771fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45749,DS-ee9ec4d2-3d94-4585-8ce7-af4e1cf4c9fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-2dd932f7-31a2-4fa0-b8f7-f76b50bfc603,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218640002-172.17.0.20-1595978927985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38035,DS-c0cf43ab-8a28-437e-985c-a0a94bc1d1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-ae953f65-f074-4ab9-8a33-fb3e1b50af43,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-eda20d8c-a0b4-40a5-b8cf-893680da6e12,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-1a34466b-bf84-4df9-a1e9-53c3e8e27fca,DISK], DatanodeInfoWithStorage[127.0.0.1:36704,DS-c92e3fa0-e4f7-4ea0-ad23-51f31ea81971,DISK], DatanodeInfoWithStorage[127.0.0.1:37458,DS-a9e1bcd4-305a-4719-90ec-49a67f8cf0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-93d6a1ae-5004-495d-a536-284cbbfe519a,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-fe7be32a-b560-4910-b236-d818466448ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218640002-172.17.0.20-1595978927985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38035,DS-c0cf43ab-8a28-437e-985c-a0a94bc1d1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-ae953f65-f074-4ab9-8a33-fb3e1b50af43,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-eda20d8c-a0b4-40a5-b8cf-893680da6e12,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-1a34466b-bf84-4df9-a1e9-53c3e8e27fca,DISK], DatanodeInfoWithStorage[127.0.0.1:36704,DS-c92e3fa0-e4f7-4ea0-ad23-51f31ea81971,DISK], DatanodeInfoWithStorage[127.0.0.1:37458,DS-a9e1bcd4-305a-4719-90ec-49a67f8cf0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-93d6a1ae-5004-495d-a536-284cbbfe519a,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-fe7be32a-b560-4910-b236-d818466448ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1917658858-172.17.0.20-1595979072252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38126,DS-bb7ccd20-d584-4674-9cd4-afded1efd209,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-fc07874d-704b-4941-b905-d235818ca40d,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-d63624c9-a944-41bc-8415-4ab6489bd393,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-2dab4277-3a7c-4030-bef7-254c1b9feb36,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-f9b06450-5fef-4a2a-a523-75dbd9134bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-572bbe5f-dd99-4ce7-99e5-b519ccf24cab,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-5a779b71-f262-4987-b7c1-381b34bdb996,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-680ac298-b912-41aa-b63c-36c5f27ecc06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1917658858-172.17.0.20-1595979072252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38126,DS-bb7ccd20-d584-4674-9cd4-afded1efd209,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-fc07874d-704b-4941-b905-d235818ca40d,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-d63624c9-a944-41bc-8415-4ab6489bd393,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-2dab4277-3a7c-4030-bef7-254c1b9feb36,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-f9b06450-5fef-4a2a-a523-75dbd9134bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-572bbe5f-dd99-4ce7-99e5-b519ccf24cab,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-5a779b71-f262-4987-b7c1-381b34bdb996,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-680ac298-b912-41aa-b63c-36c5f27ecc06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-844616910-172.17.0.20-1595979339705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35163,DS-2bc087fc-e5a0-4c90-97f7-8bb73584b423,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-12c8791c-848e-4802-8a1d-f152268236a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-584ea96b-f978-4c6e-9db2-920d87c8efd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-7906e54d-9ee6-41de-992a-ae6b6a05a987,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-36d707f3-1ad2-4562-9c9c-9e4a0c185c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-efb5c2a4-8f96-4a3c-8907-22f5d899ba7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-2f85a4f3-94c5-4982-a3cf-8734a30516c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-a1dee516-dc5a-48fa-9926-f68072c223f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-844616910-172.17.0.20-1595979339705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35163,DS-2bc087fc-e5a0-4c90-97f7-8bb73584b423,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-12c8791c-848e-4802-8a1d-f152268236a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-584ea96b-f978-4c6e-9db2-920d87c8efd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-7906e54d-9ee6-41de-992a-ae6b6a05a987,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-36d707f3-1ad2-4562-9c9c-9e4a0c185c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-efb5c2a4-8f96-4a3c-8907-22f5d899ba7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-2f85a4f3-94c5-4982-a3cf-8734a30516c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-a1dee516-dc5a-48fa-9926-f68072c223f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-5334798-172.17.0.20-1595979410070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40470,DS-705e5213-b4fa-4bf2-ad7e-00526391a635,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-11d53d4d-1764-48cb-91c3-41fff788e462,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-51e49a52-f481-447f-9346-5fc5f7ed61a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41502,DS-56a4e87c-14ed-498b-81e8-6540d1b72722,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-b6cfe4d5-a216-43cb-8235-ebcff554468d,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-ede51d54-4073-4f86-83ce-679abea7ba33,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-448f333c-f6b5-4c4e-ad78-682599053e12,DISK], DatanodeInfoWithStorage[127.0.0.1:38142,DS-18ef163c-6064-4dc9-a658-a571f5b30d65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-5334798-172.17.0.20-1595979410070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40470,DS-705e5213-b4fa-4bf2-ad7e-00526391a635,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-11d53d4d-1764-48cb-91c3-41fff788e462,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-51e49a52-f481-447f-9346-5fc5f7ed61a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41502,DS-56a4e87c-14ed-498b-81e8-6540d1b72722,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-b6cfe4d5-a216-43cb-8235-ebcff554468d,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-ede51d54-4073-4f86-83ce-679abea7ba33,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-448f333c-f6b5-4c4e-ad78-682599053e12,DISK], DatanodeInfoWithStorage[127.0.0.1:38142,DS-18ef163c-6064-4dc9-a658-a571f5b30d65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-796505444-172.17.0.20-1595979850762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33070,DS-0966234c-3fba-497d-a675-dd37c7b582b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-f3922909-756a-4d5a-a79d-72695c202e18,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-7a3dba87-80c8-46e3-bc1a-126e4fd22f98,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-06b82ed2-dae7-48d1-931f-a84e6d38ce2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-a6a584f6-3d54-4ccb-95bf-d9369f7c0d84,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-7afb3dcc-b400-42cd-a1dc-8fc7b42ecfc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-8e8a39ab-8431-43e5-b461-dd6828d406f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-3fe38ebe-00fb-4058-9d06-8a1aab57288a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-796505444-172.17.0.20-1595979850762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33070,DS-0966234c-3fba-497d-a675-dd37c7b582b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-f3922909-756a-4d5a-a79d-72695c202e18,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-7a3dba87-80c8-46e3-bc1a-126e4fd22f98,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-06b82ed2-dae7-48d1-931f-a84e6d38ce2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-a6a584f6-3d54-4ccb-95bf-d9369f7c0d84,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-7afb3dcc-b400-42cd-a1dc-8fc7b42ecfc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-8e8a39ab-8431-43e5-b461-dd6828d406f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-3fe38ebe-00fb-4058-9d06-8a1aab57288a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1687096377-172.17.0.20-1595980006818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33642,DS-c71bb153-3149-4fdf-b950-dbcdd9ae8d26,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-bca4d2f7-a8ea-4d3a-be22-b3e01445f88f,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-83054663-9711-4f4e-ae8b-697067ffc824,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-a983d12a-1e82-40b2-b317-71c14c504bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-a112789b-3880-4058-822b-6111cef054b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-cd589a1c-080b-4286-8f3b-43aa6dab4d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-85bac059-2149-4245-b782-a4df2e44bb43,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-5c9042a6-b3ed-454a-876a-10973d5a56a0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1687096377-172.17.0.20-1595980006818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33642,DS-c71bb153-3149-4fdf-b950-dbcdd9ae8d26,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-bca4d2f7-a8ea-4d3a-be22-b3e01445f88f,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-83054663-9711-4f4e-ae8b-697067ffc824,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-a983d12a-1e82-40b2-b317-71c14c504bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-a112789b-3880-4058-822b-6111cef054b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-cd589a1c-080b-4286-8f3b-43aa6dab4d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-85bac059-2149-4245-b782-a4df2e44bb43,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-5c9042a6-b3ed-454a-876a-10973d5a56a0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2060261414-172.17.0.20-1595980048548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37852,DS-5d09205e-1347-45dd-ae29-49fcab12cd07,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-76b9afcb-c53d-4c4f-954f-c6abf01e7fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-31d02e6f-5939-4415-91f5-f92cacbed6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41502,DS-7322af69-533a-444c-9015-6f1adbc7731b,DISK], DatanodeInfoWithStorage[127.0.0.1:42561,DS-22a9d682-d08e-48da-9227-ac6cfa848e07,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-2cb23267-7bf4-4f49-8410-ccc7806a5044,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-7864b85a-ac43-4890-b192-873fd9750111,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-c036b183-e292-4b75-a009-d71de882aede,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2060261414-172.17.0.20-1595980048548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37852,DS-5d09205e-1347-45dd-ae29-49fcab12cd07,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-76b9afcb-c53d-4c4f-954f-c6abf01e7fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-31d02e6f-5939-4415-91f5-f92cacbed6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41502,DS-7322af69-533a-444c-9015-6f1adbc7731b,DISK], DatanodeInfoWithStorage[127.0.0.1:42561,DS-22a9d682-d08e-48da-9227-ac6cfa848e07,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-2cb23267-7bf4-4f49-8410-ccc7806a5044,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-7864b85a-ac43-4890-b192-873fd9750111,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-c036b183-e292-4b75-a009-d71de882aede,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2082960106-172.17.0.20-1595980119112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37305,DS-20647ca3-7cde-405c-b766-7a611c1e0a37,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-ed4007c3-483d-4483-bc34-8c860842bfad,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-ad688b5a-239d-49dc-b684-7afc0daa6910,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-1e40defe-1a17-4dd3-9fdc-d7c720bafc38,DISK], DatanodeInfoWithStorage[127.0.0.1:40604,DS-f1d706de-5238-4b29-9e28-a306b64a165d,DISK], DatanodeInfoWithStorage[127.0.0.1:34734,DS-226fb769-fbb8-46d5-8682-33f32ca2736e,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-06ee0935-9ef5-43d5-b7e2-2438794bafb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-78e97f69-5fe3-4542-838c-a57544c137d9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2082960106-172.17.0.20-1595980119112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37305,DS-20647ca3-7cde-405c-b766-7a611c1e0a37,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-ed4007c3-483d-4483-bc34-8c860842bfad,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-ad688b5a-239d-49dc-b684-7afc0daa6910,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-1e40defe-1a17-4dd3-9fdc-d7c720bafc38,DISK], DatanodeInfoWithStorage[127.0.0.1:40604,DS-f1d706de-5238-4b29-9e28-a306b64a165d,DISK], DatanodeInfoWithStorage[127.0.0.1:34734,DS-226fb769-fbb8-46d5-8682-33f32ca2736e,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-06ee0935-9ef5-43d5-b7e2-2438794bafb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-78e97f69-5fe3-4542-838c-a57544c137d9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1283492822-172.17.0.20-1595980259942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42480,DS-75d15c93-eec5-489b-9f50-3d2f6ab29d49,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-8ba97293-3957-4f56-801c-03ef6b5571e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-97648979-338e-49f0-86ac-dd52f1a51ced,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-528e6912-4d16-4cdf-9f6e-17ded8e27242,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-b62fcc64-db9d-4f1d-85cd-464336db388c,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-2f87d3f8-afec-4eec-b78c-a4cb81c11280,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-6986d126-9e03-449e-9f64-385a8eb2117f,DISK], DatanodeInfoWithStorage[127.0.0.1:44440,DS-83caffbe-ec63-4031-8bc2-dbaf1e5703c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1283492822-172.17.0.20-1595980259942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42480,DS-75d15c93-eec5-489b-9f50-3d2f6ab29d49,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-8ba97293-3957-4f56-801c-03ef6b5571e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-97648979-338e-49f0-86ac-dd52f1a51ced,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-528e6912-4d16-4cdf-9f6e-17ded8e27242,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-b62fcc64-db9d-4f1d-85cd-464336db388c,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-2f87d3f8-afec-4eec-b78c-a4cb81c11280,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-6986d126-9e03-449e-9f64-385a8eb2117f,DISK], DatanodeInfoWithStorage[127.0.0.1:44440,DS-83caffbe-ec63-4031-8bc2-dbaf1e5703c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1847989265-172.17.0.20-1595980301342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46226,DS-5489e031-3bb2-49c8-9388-909e7f44479c,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-91de8137-169d-4d27-b4e8-2e38d45cc288,DISK], DatanodeInfoWithStorage[127.0.0.1:40127,DS-94c62167-bf8d-4fa3-b7f3-d3f4dae56143,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-ce59e8c7-ebf0-4405-8fe5-b81e2bd027ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-3be03998-2779-408d-ac1e-230c80883433,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-1de6b8d7-739f-4806-80f9-16591c422742,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-7797c9b1-14df-4dca-88fb-21fa7ea5edd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-d4456962-3881-4a19-aeca-df7579292fed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1847989265-172.17.0.20-1595980301342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46226,DS-5489e031-3bb2-49c8-9388-909e7f44479c,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-91de8137-169d-4d27-b4e8-2e38d45cc288,DISK], DatanodeInfoWithStorage[127.0.0.1:40127,DS-94c62167-bf8d-4fa3-b7f3-d3f4dae56143,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-ce59e8c7-ebf0-4405-8fe5-b81e2bd027ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-3be03998-2779-408d-ac1e-230c80883433,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-1de6b8d7-739f-4806-80f9-16591c422742,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-7797c9b1-14df-4dca-88fb-21fa7ea5edd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-d4456962-3881-4a19-aeca-df7579292fed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-107125380-172.17.0.20-1595980477783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40611,DS-6ec444bd-99c2-45d7-abc4-9d985f00c1af,DISK], DatanodeInfoWithStorage[127.0.0.1:43041,DS-304caa69-e107-4672-8ca8-126d06ac7099,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-c7d18a64-8120-4f46-97bf-7cac1fc7ddac,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-55c5dd39-1970-4299-8123-b107fe75319b,DISK], DatanodeInfoWithStorage[127.0.0.1:34587,DS-4d615720-24fe-47c4-8df3-0afcd1112be4,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-fe7237c7-d5ac-432f-87e4-67c7afec8fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-d52b6ff1-912e-4bcd-a5d1-ed8140077b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-dbc9a770-212d-4cb6-893c-b9dc6829685d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-107125380-172.17.0.20-1595980477783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40611,DS-6ec444bd-99c2-45d7-abc4-9d985f00c1af,DISK], DatanodeInfoWithStorage[127.0.0.1:43041,DS-304caa69-e107-4672-8ca8-126d06ac7099,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-c7d18a64-8120-4f46-97bf-7cac1fc7ddac,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-55c5dd39-1970-4299-8123-b107fe75319b,DISK], DatanodeInfoWithStorage[127.0.0.1:34587,DS-4d615720-24fe-47c4-8df3-0afcd1112be4,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-fe7237c7-d5ac-432f-87e4-67c7afec8fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-d52b6ff1-912e-4bcd-a5d1-ed8140077b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-dbc9a770-212d-4cb6-893c-b9dc6829685d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-728978989-172.17.0.20-1595980512383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44501,DS-d72363f4-f6fe-4682-9da6-4e00c499ef1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-c475d11a-b3b2-4051-a002-1bcb67ee3600,DISK], DatanodeInfoWithStorage[127.0.0.1:33497,DS-10e6418a-4be5-4a4a-984d-44c2949b4ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-058ee15a-931d-4227-9212-a95d38b151c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-54abac8a-bb71-4ad7-bcc7-27243a1c87d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43025,DS-80e00f73-0929-44f3-8259-d3a374989097,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-54785ab8-424e-478d-9f29-3455f3495496,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-1124b52d-8528-4bc4-8317-762cc2929af8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-728978989-172.17.0.20-1595980512383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44501,DS-d72363f4-f6fe-4682-9da6-4e00c499ef1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-c475d11a-b3b2-4051-a002-1bcb67ee3600,DISK], DatanodeInfoWithStorage[127.0.0.1:33497,DS-10e6418a-4be5-4a4a-984d-44c2949b4ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-058ee15a-931d-4227-9212-a95d38b151c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-54abac8a-bb71-4ad7-bcc7-27243a1c87d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43025,DS-80e00f73-0929-44f3-8259-d3a374989097,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-54785ab8-424e-478d-9f29-3455f3495496,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-1124b52d-8528-4bc4-8317-762cc2929af8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-87838146-172.17.0.20-1595980624666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33580,DS-3d7bc25f-7a10-495b-b825-4f01020fcc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-63dbeb2d-c48f-4ab0-8857-debde5c5c528,DISK], DatanodeInfoWithStorage[127.0.0.1:46438,DS-372a31f6-8856-4c96-b043-755926497d80,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-18bccb2e-5cca-4a38-ad34-d299e080b65b,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-1654ac8b-2cf5-40af-abc7-7800f66dabff,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-e7c44e0c-99d3-497b-83b8-08a1dd6d6873,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-aa954419-8ebd-4e14-8e9f-5e875dea729e,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-33698e71-25b2-4f7b-bb5b-54f5b0ba5781,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-87838146-172.17.0.20-1595980624666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33580,DS-3d7bc25f-7a10-495b-b825-4f01020fcc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-63dbeb2d-c48f-4ab0-8857-debde5c5c528,DISK], DatanodeInfoWithStorage[127.0.0.1:46438,DS-372a31f6-8856-4c96-b043-755926497d80,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-18bccb2e-5cca-4a38-ad34-d299e080b65b,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-1654ac8b-2cf5-40af-abc7-7800f66dabff,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-e7c44e0c-99d3-497b-83b8-08a1dd6d6873,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-aa954419-8ebd-4e14-8e9f-5e875dea729e,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-33698e71-25b2-4f7b-bb5b-54f5b0ba5781,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2102891098-172.17.0.20-1595980665254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41840,DS-1c55885f-ce35-4abd-9999-ebdc6510a79f,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-5add1d15-50d2-4d44-9922-9826d9330738,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-64daa683-4908-45a2-b933-e1b76385a900,DISK], DatanodeInfoWithStorage[127.0.0.1:33006,DS-7b0bd35d-959f-4c6c-b885-4a8213152512,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-ddb673e4-d98b-40d9-8948-1241bed17a71,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-66ffe5c6-9d89-4848-9796-3d15a38cfd67,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-fd5a1823-e17d-4e5d-83ea-f3dbdac3c4af,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-052e698c-797b-4e14-95e9-1ffad7da6d67,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2102891098-172.17.0.20-1595980665254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41840,DS-1c55885f-ce35-4abd-9999-ebdc6510a79f,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-5add1d15-50d2-4d44-9922-9826d9330738,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-64daa683-4908-45a2-b933-e1b76385a900,DISK], DatanodeInfoWithStorage[127.0.0.1:33006,DS-7b0bd35d-959f-4c6c-b885-4a8213152512,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-ddb673e4-d98b-40d9-8948-1241bed17a71,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-66ffe5c6-9d89-4848-9796-3d15a38cfd67,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-fd5a1823-e17d-4e5d-83ea-f3dbdac3c4af,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-052e698c-797b-4e14-95e9-1ffad7da6d67,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-817278809-172.17.0.20-1595980957990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42181,DS-5f93c868-d827-46aa-b00c-24587c1e78c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35823,DS-0f1e12eb-2619-4f8c-80e8-bfe045398e89,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-cee5071b-52eb-4a21-985a-5d634dd5c944,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-c61104a2-7f26-4c5f-89dc-9ce030eb25a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-a2abfef8-f659-4e7a-8a11-64b143484c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38578,DS-2a28bed8-569e-4730-8417-fc3e170f1b65,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-406977d7-4f38-435b-afe9-89ae87796851,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-ab6eeff7-a793-496b-a5d5-19dd521d9e08,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-817278809-172.17.0.20-1595980957990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42181,DS-5f93c868-d827-46aa-b00c-24587c1e78c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35823,DS-0f1e12eb-2619-4f8c-80e8-bfe045398e89,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-cee5071b-52eb-4a21-985a-5d634dd5c944,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-c61104a2-7f26-4c5f-89dc-9ce030eb25a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-a2abfef8-f659-4e7a-8a11-64b143484c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38578,DS-2a28bed8-569e-4730-8417-fc3e170f1b65,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-406977d7-4f38-435b-afe9-89ae87796851,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-ab6eeff7-a793-496b-a5d5-19dd521d9e08,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1540911727-172.17.0.20-1595980992710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39526,DS-d61dcdc1-7f5e-41fc-bb75-bcf1d596ab46,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-fadadaaf-5554-48bf-8fe6-f84cc20df582,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-2b52ead2-6443-4248-9c6c-5eec9a1a745e,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-3b6b97a2-d42a-4fbf-b0ee-03c6a491b623,DISK], DatanodeInfoWithStorage[127.0.0.1:33410,DS-9cb02d2d-98bd-4a77-bd0d-8ad3320c9edc,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-d73cf76f-725e-4e15-98f0-87ad54778e42,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-46783eda-c9a4-40e2-a249-07bb9dc2d3db,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-2f42a27f-3fd1-4378-9125-c41da24b71c7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1540911727-172.17.0.20-1595980992710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39526,DS-d61dcdc1-7f5e-41fc-bb75-bcf1d596ab46,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-fadadaaf-5554-48bf-8fe6-f84cc20df582,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-2b52ead2-6443-4248-9c6c-5eec9a1a745e,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-3b6b97a2-d42a-4fbf-b0ee-03c6a491b623,DISK], DatanodeInfoWithStorage[127.0.0.1:33410,DS-9cb02d2d-98bd-4a77-bd0d-8ad3320c9edc,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-d73cf76f-725e-4e15-98f0-87ad54778e42,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-46783eda-c9a4-40e2-a249-07bb9dc2d3db,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-2f42a27f-3fd1-4378-9125-c41da24b71c7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391782050-172.17.0.20-1595981468530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36565,DS-4d8efaa1-36a5-4e60-bead-92ad6f127d22,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-1b2b9bfa-3591-46bd-83f7-68957b54b25d,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-61cbc278-1d50-416f-92d4-b78c89456f15,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-09181a72-b8d9-44f9-a46a-a0bc0fe5aaef,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-5a8023a3-6f49-45c4-9bc4-67325e9d284f,DISK], DatanodeInfoWithStorage[127.0.0.1:40138,DS-62e83e64-e0c6-477d-865f-5d018f494964,DISK], DatanodeInfoWithStorage[127.0.0.1:37784,DS-a9343b06-7d08-4fc8-8e8c-35c37adf3fce,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-ee239119-201f-4e93-8c37-2ea934856b4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391782050-172.17.0.20-1595981468530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36565,DS-4d8efaa1-36a5-4e60-bead-92ad6f127d22,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-1b2b9bfa-3591-46bd-83f7-68957b54b25d,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-61cbc278-1d50-416f-92d4-b78c89456f15,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-09181a72-b8d9-44f9-a46a-a0bc0fe5aaef,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-5a8023a3-6f49-45c4-9bc4-67325e9d284f,DISK], DatanodeInfoWithStorage[127.0.0.1:40138,DS-62e83e64-e0c6-477d-865f-5d018f494964,DISK], DatanodeInfoWithStorage[127.0.0.1:37784,DS-a9343b06-7d08-4fc8-8e8c-35c37adf3fce,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-ee239119-201f-4e93-8c37-2ea934856b4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1687070016-172.17.0.20-1595981506476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46642,DS-41308998-65c1-43f6-be75-34aa8e32fd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38427,DS-2442945c-d8a4-4a30-bd9a-5b1269904573,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-155ecc6d-5bbd-4359-a5b4-2fc7399673b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-17c0e9bd-676c-4b49-a181-18afd468f662,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-34641da2-5979-45b7-8c79-70b506a3c389,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-e0ad4075-a5a5-4999-80db-afb9e300a8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-f52cb32f-8e46-4d7d-b5a0-91edf713395e,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-8584b9fb-53d2-48ac-8f77-aad76ed5fdbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1687070016-172.17.0.20-1595981506476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46642,DS-41308998-65c1-43f6-be75-34aa8e32fd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38427,DS-2442945c-d8a4-4a30-bd9a-5b1269904573,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-155ecc6d-5bbd-4359-a5b4-2fc7399673b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-17c0e9bd-676c-4b49-a181-18afd468f662,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-34641da2-5979-45b7-8c79-70b506a3c389,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-e0ad4075-a5a5-4999-80db-afb9e300a8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-f52cb32f-8e46-4d7d-b5a0-91edf713395e,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-8584b9fb-53d2-48ac-8f77-aad76ed5fdbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 600
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1362716894-172.17.0.20-1595981704222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34484,DS-f320068a-bf67-407e-82cf-940f9b54dda9,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-0a2587c8-accb-43a1-a283-92b5e934e1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-d2ee9365-8430-4185-8282-5acaf65645ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-1894833e-3153-43a0-a6a3-fcb84cecc33e,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-7f0b03af-84c0-4766-bafd-fa32d637b96b,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-50fc4ab8-8429-485e-8c0e-45f2ab212d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-6270344b-4ea6-4e09-80fc-bdb02e9bb7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-e269b6bf-003a-43b3-911e-8542fce3838c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1362716894-172.17.0.20-1595981704222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34484,DS-f320068a-bf67-407e-82cf-940f9b54dda9,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-0a2587c8-accb-43a1-a283-92b5e934e1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-d2ee9365-8430-4185-8282-5acaf65645ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-1894833e-3153-43a0-a6a3-fcb84cecc33e,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-7f0b03af-84c0-4766-bafd-fa32d637b96b,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-50fc4ab8-8429-485e-8c0e-45f2ab212d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-6270344b-4ea6-4e09-80fc-bdb02e9bb7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-e269b6bf-003a-43b3-911e-8542fce3838c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 15 out of 50
v1v1v2v2 failed with probability 21 out of 50
result: false positive !!!
Total execution time in seconds : 5520
