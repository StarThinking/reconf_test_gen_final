reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 2000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 2000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-957048512-172.17.0.21-1595975195478:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40768,DS-3233a635-b32e-49e2-8434-5f8fe83d3492,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-bb6a47d5-3ae6-4be7-ad7c-06f09669627a,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-560224f9-982e-4b17-8377-7f9aba151e28,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-c6afca19-8caa-451a-a659-a0cfad3293ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-ccd22f8e-5f42-449a-b466-1e3dd5a4ab80,DISK], DatanodeInfoWithStorage[127.0.0.1:40222,DS-f563b706-fe22-4409-81c5-f42cf4392838,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-7f5f7320-bbf2-4b84-9668-f255f487280e,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-da74579f-528f-4144-9b6a-e9874c44c225,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-957048512-172.17.0.21-1595975195478:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40768,DS-3233a635-b32e-49e2-8434-5f8fe83d3492,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-bb6a47d5-3ae6-4be7-ad7c-06f09669627a,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-560224f9-982e-4b17-8377-7f9aba151e28,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-c6afca19-8caa-451a-a659-a0cfad3293ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-ccd22f8e-5f42-449a-b466-1e3dd5a4ab80,DISK], DatanodeInfoWithStorage[127.0.0.1:40222,DS-f563b706-fe22-4409-81c5-f42cf4392838,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-7f5f7320-bbf2-4b84-9668-f255f487280e,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-da74579f-528f-4144-9b6a-e9874c44c225,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 2000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1140089647-172.17.0.21-1595976107911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42514,DS-ee96b18d-da4a-46cc-8089-77dadf980dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-25c127b5-de0b-47eb-ac62-74da704f1c30,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-98c53fda-83c3-4e8b-a254-a3f2595f7655,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-c2716e23-e2ad-4fe1-bcf8-2be135c8f972,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-a6070493-b364-4ef7-813c-b924bbff225f,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-839861aa-b4a7-467e-a12d-399af8840e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38099,DS-bc6a5039-4441-480e-aee6-4229a06d174b,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-bb86d9ea-806b-44c6-a9f2-475352e64002,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1140089647-172.17.0.21-1595976107911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42514,DS-ee96b18d-da4a-46cc-8089-77dadf980dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-25c127b5-de0b-47eb-ac62-74da704f1c30,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-98c53fda-83c3-4e8b-a254-a3f2595f7655,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-c2716e23-e2ad-4fe1-bcf8-2be135c8f972,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-a6070493-b364-4ef7-813c-b924bbff225f,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-839861aa-b4a7-467e-a12d-399af8840e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38099,DS-bc6a5039-4441-480e-aee6-4229a06d174b,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-bb86d9ea-806b-44c6-a9f2-475352e64002,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 2000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-119300542-172.17.0.21-1595976272493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42738,DS-314198cb-46e4-4985-9925-af43d16c0a61,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-f51f6544-d268-4812-8004-8666dc8bdc61,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-ef28c01a-8588-440b-8714-63add4e9ee1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42749,DS-6ddc522d-757e-4ab7-b369-450041b97c95,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-187bb4c0-cc87-4267-acd6-11a40d265ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-556517af-0302-40b9-be26-67f9cc803e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-5bc3d535-83bc-45d7-8284-5c7bd50ef0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-430380c6-9b6c-47d9-9f02-cb7e5f875148,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-119300542-172.17.0.21-1595976272493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42738,DS-314198cb-46e4-4985-9925-af43d16c0a61,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-f51f6544-d268-4812-8004-8666dc8bdc61,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-ef28c01a-8588-440b-8714-63add4e9ee1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42749,DS-6ddc522d-757e-4ab7-b369-450041b97c95,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-187bb4c0-cc87-4267-acd6-11a40d265ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-556517af-0302-40b9-be26-67f9cc803e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-5bc3d535-83bc-45d7-8284-5c7bd50ef0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-430380c6-9b6c-47d9-9f02-cb7e5f875148,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 2000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1860618668-172.17.0.21-1595976531395:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34251,DS-ab03a8e7-7167-4529-8c75-1edd53fa1e75,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-c3b79ae0-4bd6-4e7d-9641-0716e5b3bfe1,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-8be1fda2-2ca6-411b-8a19-42b7daf7dc66,DISK], DatanodeInfoWithStorage[127.0.0.1:34867,DS-177ad512-d59a-411a-85a4-38e2c4703296,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-52baeb50-39a2-458e-853c-b10846f48518,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-98bd15bb-35d8-43c8-b8bd-54ecf507c84a,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-63ebad7c-dd65-4fc9-9cac-e2b7f5021038,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-7bd988d1-73d6-4b06-a81a-ee9324ea9901,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1860618668-172.17.0.21-1595976531395:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34251,DS-ab03a8e7-7167-4529-8c75-1edd53fa1e75,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-c3b79ae0-4bd6-4e7d-9641-0716e5b3bfe1,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-8be1fda2-2ca6-411b-8a19-42b7daf7dc66,DISK], DatanodeInfoWithStorage[127.0.0.1:34867,DS-177ad512-d59a-411a-85a4-38e2c4703296,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-52baeb50-39a2-458e-853c-b10846f48518,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-98bd15bb-35d8-43c8-b8bd-54ecf507c84a,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-63ebad7c-dd65-4fc9-9cac-e2b7f5021038,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-7bd988d1-73d6-4b06-a81a-ee9324ea9901,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 2000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1907192221-172.17.0.21-1595976565170:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45956,DS-d9faaa6a-4228-41e8-95e6-08097b43258a,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-c666b850-4d06-40a0-a1a3-5534164d9b04,DISK], DatanodeInfoWithStorage[127.0.0.1:43647,DS-24a70fa4-eb92-440e-94c7-4cce30d417db,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-d2e08c26-0417-45af-b3a2-5e624bc15dba,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-f1ab50e3-6dae-4cad-ae47-5603b82e85d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-436ec915-9289-4ffb-ba6b-1abe2d7c5d75,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-f1d99eef-2f94-4ea6-b44a-89892c99d403,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-c98c2239-5b52-442b-819d-d6292413ae3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1907192221-172.17.0.21-1595976565170:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45956,DS-d9faaa6a-4228-41e8-95e6-08097b43258a,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-c666b850-4d06-40a0-a1a3-5534164d9b04,DISK], DatanodeInfoWithStorage[127.0.0.1:43647,DS-24a70fa4-eb92-440e-94c7-4cce30d417db,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-d2e08c26-0417-45af-b3a2-5e624bc15dba,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-f1ab50e3-6dae-4cad-ae47-5603b82e85d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-436ec915-9289-4ffb-ba6b-1abe2d7c5d75,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-f1d99eef-2f94-4ea6-b44a-89892c99d403,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-c98c2239-5b52-442b-819d-d6292413ae3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 2000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1171164930-172.17.0.21-1595977180535:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33351,DS-82fe4e2f-2629-4379-9271-397b36a9c2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-fff8b731-c9b1-435b-9fd8-e33ba7500ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-11ef1e6f-b7a2-40a9-8e71-d3205175d3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-3342b6b3-05f9-4f47-a3f7-5112e86668f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-84801776-ea94-4225-8a27-d2584499cb19,DISK], DatanodeInfoWithStorage[127.0.0.1:44041,DS-9807c3c6-0fe1-4b3e-84ed-8e29ba2951dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-6e13c257-edf9-4bcd-a56c-0493bdc08acf,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-9ea7acea-0620-4ce2-8cbe-946bf941d408,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1171164930-172.17.0.21-1595977180535:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33351,DS-82fe4e2f-2629-4379-9271-397b36a9c2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-fff8b731-c9b1-435b-9fd8-e33ba7500ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-11ef1e6f-b7a2-40a9-8e71-d3205175d3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-3342b6b3-05f9-4f47-a3f7-5112e86668f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-84801776-ea94-4225-8a27-d2584499cb19,DISK], DatanodeInfoWithStorage[127.0.0.1:44041,DS-9807c3c6-0fe1-4b3e-84ed-8e29ba2951dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-6e13c257-edf9-4bcd-a56c-0493bdc08acf,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-9ea7acea-0620-4ce2-8cbe-946bf941d408,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 2000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-823015606-172.17.0.21-1595977284809:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41484,DS-ee81a537-313b-468c-bfa3-8477809a60c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36040,DS-9921e2ef-6dab-4cd7-925b-b5bb95ef1c89,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-c0a8180b-adb1-4233-a65f-a6b200fc2cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-d4595d0c-0bfc-4fb0-9713-9c8c117f913d,DISK], DatanodeInfoWithStorage[127.0.0.1:46346,DS-a5b94097-10bf-49d4-90c6-2da540bd30b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-8aa5678c-62b1-4db7-808d-f3928c5b5e84,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-4d7569f0-68c8-43b2-8243-d21e32af0031,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-15bb6d9d-001b-4d90-a101-420ed6ebfe3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-823015606-172.17.0.21-1595977284809:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41484,DS-ee81a537-313b-468c-bfa3-8477809a60c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36040,DS-9921e2ef-6dab-4cd7-925b-b5bb95ef1c89,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-c0a8180b-adb1-4233-a65f-a6b200fc2cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-d4595d0c-0bfc-4fb0-9713-9c8c117f913d,DISK], DatanodeInfoWithStorage[127.0.0.1:46346,DS-a5b94097-10bf-49d4-90c6-2da540bd30b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-8aa5678c-62b1-4db7-808d-f3928c5b5e84,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-4d7569f0-68c8-43b2-8243-d21e32af0031,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-15bb6d9d-001b-4d90-a101-420ed6ebfe3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 2000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-165258534-172.17.0.21-1595977353342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42104,DS-81821d34-f28d-439a-a7fb-a208511b0761,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-56c56133-b258-4e43-acda-35fee6d7fae2,DISK], DatanodeInfoWithStorage[127.0.0.1:44201,DS-147a6030-48c0-4ed2-b436-ba3996a481a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-e8a28187-67f0-4498-96e5-063744a17d30,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-01ba3075-90bf-444b-8c2b-b37d9167c9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-5dc45b0b-488e-469c-9a6a-c1b422c54478,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-f738cd9b-da92-443a-a315-58f0c262f01f,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-9b84327f-4919-4d53-86c9-d2533cb60320,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-165258534-172.17.0.21-1595977353342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42104,DS-81821d34-f28d-439a-a7fb-a208511b0761,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-56c56133-b258-4e43-acda-35fee6d7fae2,DISK], DatanodeInfoWithStorage[127.0.0.1:44201,DS-147a6030-48c0-4ed2-b436-ba3996a481a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-e8a28187-67f0-4498-96e5-063744a17d30,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-01ba3075-90bf-444b-8c2b-b37d9167c9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-5dc45b0b-488e-469c-9a6a-c1b422c54478,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-f738cd9b-da92-443a-a315-58f0c262f01f,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-9b84327f-4919-4d53-86c9-d2533cb60320,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 2000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-600196556-172.17.0.21-1595977546607:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44496,DS-bc1a4935-8e44-4d5a-9315-5f765766962b,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-c23d12ac-324f-45b6-b214-101aed87dd0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-e0e6fccf-ca96-4cd9-9eee-7efdf2c45340,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-4e5b4333-b68c-481e-a399-2b4c8b0328d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-1effa12a-7d95-4c18-a026-cbb37b89e75e,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-7ce77d01-5ef0-4f3a-9e75-9e698b5a7357,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-8246ba88-ca4d-494b-be42-2f7d07a8b20a,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-fa4c5bd2-2643-4c91-88e7-1f9e906a2d34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-600196556-172.17.0.21-1595977546607:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44496,DS-bc1a4935-8e44-4d5a-9315-5f765766962b,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-c23d12ac-324f-45b6-b214-101aed87dd0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-e0e6fccf-ca96-4cd9-9eee-7efdf2c45340,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-4e5b4333-b68c-481e-a399-2b4c8b0328d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-1effa12a-7d95-4c18-a026-cbb37b89e75e,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-7ce77d01-5ef0-4f3a-9e75-9e698b5a7357,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-8246ba88-ca4d-494b-be42-2f7d07a8b20a,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-fa4c5bd2-2643-4c91-88e7-1f9e906a2d34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 2000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1899189977-172.17.0.21-1595977607509:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34676,DS-497b6ece-95f6-47ae-821a-17f986c6bc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38963,DS-45c58a84-d16a-4574-951c-6eae2a93d532,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-08a72374-9b71-4dc1-b565-9ba3d6e15cec,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-e9a00ee1-5a98-41ed-b986-bd2cf391c8af,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-06a88897-85ca-46b6-94b1-27ce69c0c55b,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-1c08d3b2-cc0d-4bf0-a1d3-4775215351d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35893,DS-a114b9f6-1c13-4121-aede-da558124a578,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-7ab9a9b1-7fc8-4bd4-945c-effc3954dd8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1899189977-172.17.0.21-1595977607509:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34676,DS-497b6ece-95f6-47ae-821a-17f986c6bc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38963,DS-45c58a84-d16a-4574-951c-6eae2a93d532,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-08a72374-9b71-4dc1-b565-9ba3d6e15cec,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-e9a00ee1-5a98-41ed-b986-bd2cf391c8af,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-06a88897-85ca-46b6-94b1-27ce69c0c55b,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-1c08d3b2-cc0d-4bf0-a1d3-4775215351d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35893,DS-a114b9f6-1c13-4121-aede-da558124a578,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-7ab9a9b1-7fc8-4bd4-945c-effc3954dd8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 2000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-298268959-172.17.0.21-1595977645813:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39899,DS-de455cdb-5eeb-4f56-bc18-36b382df0d63,DISK], DatanodeInfoWithStorage[127.0.0.1:44144,DS-de94d421-119e-45de-88d9-a71c9c777210,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-7f5ea9c4-b668-4e1c-b6fd-fd3086aa7716,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-25d41256-555c-437e-874d-19fac0f032ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-209b47a3-39c0-4e97-9a23-503dac55d1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33595,DS-bde06d79-f948-4c58-9237-d4fb49ace35d,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-dd2aca48-0393-4276-b92c-0b0f91407938,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-fc05687d-87a7-4ddb-a425-bfbd54e6adf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-298268959-172.17.0.21-1595977645813:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39899,DS-de455cdb-5eeb-4f56-bc18-36b382df0d63,DISK], DatanodeInfoWithStorage[127.0.0.1:44144,DS-de94d421-119e-45de-88d9-a71c9c777210,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-7f5ea9c4-b668-4e1c-b6fd-fd3086aa7716,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-25d41256-555c-437e-874d-19fac0f032ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-209b47a3-39c0-4e97-9a23-503dac55d1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33595,DS-bde06d79-f948-4c58-9237-d4fb49ace35d,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-dd2aca48-0393-4276-b92c-0b0f91407938,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-fc05687d-87a7-4ddb-a425-bfbd54e6adf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 2000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-31818082-172.17.0.21-1595977758811:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45298,DS-55aac159-0ae2-4a22-aa1d-1b3322a34e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-bce62d75-7f0c-4da7-bfb6-e354570682d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-eb9f59be-1fd6-4592-aada-29afa51844ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44473,DS-99f85c88-5b9a-4a42-8998-39db69a1cc44,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-0948c27c-1d36-4fba-b29c-f4d132415dee,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-c1bb47b4-c6ce-469d-9e7c-e7a6c9109318,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-091f0df6-3a38-4dd4-b7d6-3d508d9929e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-1e97f0b7-7513-45b2-b516-87493e95e2c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-31818082-172.17.0.21-1595977758811:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45298,DS-55aac159-0ae2-4a22-aa1d-1b3322a34e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-bce62d75-7f0c-4da7-bfb6-e354570682d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-eb9f59be-1fd6-4592-aada-29afa51844ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44473,DS-99f85c88-5b9a-4a42-8998-39db69a1cc44,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-0948c27c-1d36-4fba-b29c-f4d132415dee,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-c1bb47b4-c6ce-469d-9e7c-e7a6c9109318,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-091f0df6-3a38-4dd4-b7d6-3d508d9929e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-1e97f0b7-7513-45b2-b516-87493e95e2c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 2000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-989435810-172.17.0.21-1595978196905:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38219,DS-7dc783c7-2744-4607-9c44-a205a31c23a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-2e52de00-6796-48ee-9fba-debe121fbae1,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-519df449-f2ca-434b-8b5e-a2e9afa8af61,DISK], DatanodeInfoWithStorage[127.0.0.1:46804,DS-d5f9cc54-4308-424b-8faf-97d467149b83,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-6a650319-3952-496c-a44b-d24b0629a4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-66642b91-8282-4e27-b397-223ba5d56ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:40772,DS-d9595c07-8cba-4ebf-a587-15d1074415d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-186da4c4-435f-48ce-bef7-f0539f7b5146,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-989435810-172.17.0.21-1595978196905:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38219,DS-7dc783c7-2744-4607-9c44-a205a31c23a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-2e52de00-6796-48ee-9fba-debe121fbae1,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-519df449-f2ca-434b-8b5e-a2e9afa8af61,DISK], DatanodeInfoWithStorage[127.0.0.1:46804,DS-d5f9cc54-4308-424b-8faf-97d467149b83,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-6a650319-3952-496c-a44b-d24b0629a4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-66642b91-8282-4e27-b397-223ba5d56ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:40772,DS-d9595c07-8cba-4ebf-a587-15d1074415d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-186da4c4-435f-48ce-bef7-f0539f7b5146,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 2000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1893094564-172.17.0.21-1595978690711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34510,DS-b3a4fffa-0325-4784-a531-9daa069d8380,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-656c6d6b-068a-4168-9e27-5a1e583e98d6,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-5dcfbcfc-25e8-462f-befb-294af3a6fea4,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-bb510221-42f0-4c86-828e-7bd70f64c441,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-e88ab697-284f-4203-9696-e1e61ba67745,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-0db3b7f3-db63-4939-a3ce-3cf7e9789b66,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-6a9401c9-2567-4a4b-99cd-a741ba2f5500,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-d08e6dc7-3b7a-426f-ab23-caefae20c3db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1893094564-172.17.0.21-1595978690711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34510,DS-b3a4fffa-0325-4784-a531-9daa069d8380,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-656c6d6b-068a-4168-9e27-5a1e583e98d6,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-5dcfbcfc-25e8-462f-befb-294af3a6fea4,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-bb510221-42f0-4c86-828e-7bd70f64c441,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-e88ab697-284f-4203-9696-e1e61ba67745,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-0db3b7f3-db63-4939-a3ce-3cf7e9789b66,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-6a9401c9-2567-4a4b-99cd-a741ba2f5500,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-d08e6dc7-3b7a-426f-ab23-caefae20c3db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 2000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1271945516-172.17.0.21-1595978938996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35857,DS-452e73e1-4f37-471f-9fef-447000d994f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-f670c041-441e-4408-bd1e-8c53db1d4869,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-1d9b5f27-a896-4a65-b932-2546185fd8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41417,DS-4cc89fee-4017-4a55-94ef-9a3c4d052aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-b09e4753-6da1-4210-a948-828ebc696013,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-43a332af-9c03-44f2-8783-690d822587b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-173fb09b-5969-4aa1-b719-beb54a583072,DISK], DatanodeInfoWithStorage[127.0.0.1:42280,DS-7465797b-a312-4c69-bdf9-2b93cd5d78c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1271945516-172.17.0.21-1595978938996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35857,DS-452e73e1-4f37-471f-9fef-447000d994f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-f670c041-441e-4408-bd1e-8c53db1d4869,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-1d9b5f27-a896-4a65-b932-2546185fd8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41417,DS-4cc89fee-4017-4a55-94ef-9a3c4d052aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-b09e4753-6da1-4210-a948-828ebc696013,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-43a332af-9c03-44f2-8783-690d822587b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-173fb09b-5969-4aa1-b719-beb54a583072,DISK], DatanodeInfoWithStorage[127.0.0.1:42280,DS-7465797b-a312-4c69-bdf9-2b93cd5d78c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 2000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-544686086-172.17.0.21-1595980038527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42525,DS-2c7aa10c-f1c9-453e-af89-c203a9ed35fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-bf39dd90-531c-4c74-b89d-15b228c8ad52,DISK], DatanodeInfoWithStorage[127.0.0.1:45544,DS-91486d9c-d269-45ac-a92c-d91b708403bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-0b433b1f-c3fa-417b-9b15-9c079771fd3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-bc1ee358-4232-4484-ac02-8e526ba1c10a,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-f4021fa5-d31f-4e9b-b27d-0faa63caf8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40510,DS-73e701dc-9a87-4513-b252-4abf3d8b85c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-6d6da10a-e545-41c5-a963-3fdf36312310,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-544686086-172.17.0.21-1595980038527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42525,DS-2c7aa10c-f1c9-453e-af89-c203a9ed35fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-bf39dd90-531c-4c74-b89d-15b228c8ad52,DISK], DatanodeInfoWithStorage[127.0.0.1:45544,DS-91486d9c-d269-45ac-a92c-d91b708403bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-0b433b1f-c3fa-417b-9b15-9c079771fd3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-bc1ee358-4232-4484-ac02-8e526ba1c10a,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-f4021fa5-d31f-4e9b-b27d-0faa63caf8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40510,DS-73e701dc-9a87-4513-b252-4abf3d8b85c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-6d6da10a-e545-41c5-a963-3fdf36312310,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 2000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1478660316-172.17.0.21-1595980206060:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35867,DS-7c621d0b-a63c-477a-baa2-fc72886256c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-fde6b467-a5eb-4bd0-934f-387565c337aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-8c4b953a-689f-4d95-af53-03bff3b16e40,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-78019d4d-5b33-49b1-9ba0-724bd262e7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38191,DS-19b24b31-4c6a-4088-b9a3-fa5e8d0a4b24,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-dabf91b7-c40b-4fa0-8ddb-ce9d6df34471,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-866cdc6f-20f3-4981-ac54-df94c12171f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-d2b2d23b-90c3-4095-98b5-2066517c8057,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1478660316-172.17.0.21-1595980206060:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35867,DS-7c621d0b-a63c-477a-baa2-fc72886256c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-fde6b467-a5eb-4bd0-934f-387565c337aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-8c4b953a-689f-4d95-af53-03bff3b16e40,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-78019d4d-5b33-49b1-9ba0-724bd262e7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38191,DS-19b24b31-4c6a-4088-b9a3-fa5e8d0a4b24,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-dabf91b7-c40b-4fa0-8ddb-ce9d6df34471,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-866cdc6f-20f3-4981-ac54-df94c12171f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-d2b2d23b-90c3-4095-98b5-2066517c8057,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 2000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1435851-172.17.0.21-1595980317467:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39113,DS-aa82163f-0feb-42be-b260-517be5aa2511,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-61598b25-0753-4a4c-9fe0-93956fc98e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-3c1eb610-a394-4a63-9593-935d20fca096,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-43de1ce1-3946-49f1-8cc1-3e96fc903530,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-b70ef00a-3912-48d1-9869-6ba328ede298,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-dd62f7bb-bd79-4d56-a33e-d3ebb70f658c,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-bbc2ff36-b3e8-42e6-b8df-132eec00ccfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-a528d4e9-ead6-490e-a58c-51737936c558,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1435851-172.17.0.21-1595980317467:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39113,DS-aa82163f-0feb-42be-b260-517be5aa2511,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-61598b25-0753-4a4c-9fe0-93956fc98e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-3c1eb610-a394-4a63-9593-935d20fca096,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-43de1ce1-3946-49f1-8cc1-3e96fc903530,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-b70ef00a-3912-48d1-9869-6ba328ede298,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-dd62f7bb-bd79-4d56-a33e-d3ebb70f658c,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-bbc2ff36-b3e8-42e6-b8df-132eec00ccfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-a528d4e9-ead6-490e-a58c-51737936c558,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5332
