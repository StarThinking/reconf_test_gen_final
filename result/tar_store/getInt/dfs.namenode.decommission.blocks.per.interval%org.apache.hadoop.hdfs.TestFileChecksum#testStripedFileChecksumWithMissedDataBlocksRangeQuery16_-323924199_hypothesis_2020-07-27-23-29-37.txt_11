reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-485593043-172.17.0.7-1595893647634:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33409,DS-f4c03cdc-307b-4b55-ab56-55c344da832d,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-f91b0d4a-b3e0-4427-a204-db1f157e9003,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-f3da9291-6147-462f-b6dd-f2bd0b57c042,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-68545c27-23d6-4f2a-9263-c707fda11a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-6a16dfd6-ff08-46f6-9328-06b136624d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-9874d458-67b1-47f4-910e-ae59a366f3af,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-81c7d7cb-7bca-487f-94b2-906eaae6b8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-1f898246-332a-461a-b1ad-0a2f79c243cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-485593043-172.17.0.7-1595893647634:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33409,DS-f4c03cdc-307b-4b55-ab56-55c344da832d,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-f91b0d4a-b3e0-4427-a204-db1f157e9003,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-f3da9291-6147-462f-b6dd-f2bd0b57c042,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-68545c27-23d6-4f2a-9263-c707fda11a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-6a16dfd6-ff08-46f6-9328-06b136624d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-9874d458-67b1-47f4-910e-ae59a366f3af,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-81c7d7cb-7bca-487f-94b2-906eaae6b8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-1f898246-332a-461a-b1ad-0a2f79c243cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-678497545-172.17.0.7-1595893723680:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46803,DS-39db4717-fde9-4d73-a25b-7997da20847a,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-231bde9c-e8a5-4077-82f6-8491933dcf74,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-59321068-f34a-49bb-a835-3edb9f1b323b,DISK], DatanodeInfoWithStorage[127.0.0.1:46535,DS-4ac555d1-af52-4fad-8686-af400906f8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40831,DS-506d6f21-4126-45e0-80e6-810a1fabca01,DISK], DatanodeInfoWithStorage[127.0.0.1:45814,DS-702eb844-8af8-4a76-8d0c-c10e900a55ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-70e1e7ef-74a8-42fa-8405-d4e23a302a16,DISK], DatanodeInfoWithStorage[127.0.0.1:42622,DS-fd68780d-47c4-4153-b8bb-91a510de20ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-678497545-172.17.0.7-1595893723680:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46803,DS-39db4717-fde9-4d73-a25b-7997da20847a,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-231bde9c-e8a5-4077-82f6-8491933dcf74,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-59321068-f34a-49bb-a835-3edb9f1b323b,DISK], DatanodeInfoWithStorage[127.0.0.1:46535,DS-4ac555d1-af52-4fad-8686-af400906f8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40831,DS-506d6f21-4126-45e0-80e6-810a1fabca01,DISK], DatanodeInfoWithStorage[127.0.0.1:45814,DS-702eb844-8af8-4a76-8d0c-c10e900a55ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-70e1e7ef-74a8-42fa-8405-d4e23a302a16,DISK], DatanodeInfoWithStorage[127.0.0.1:42622,DS-fd68780d-47c4-4153-b8bb-91a510de20ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-585495770-172.17.0.7-1595894319292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42447,DS-3d956216-38c4-43ef-9502-32968f7f0a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-ed18134c-aeeb-40f8-8043-0e123cf56b39,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-53eda230-1034-4762-876c-bf5b23956f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-716171ce-19f3-4555-bf79-26585d6aa7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-c2ffe591-b933-45dd-8620-781d214d5d27,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-7eac2191-a4da-40ed-8db3-60d647f3ee64,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-eeb5522d-5201-4a0d-8aa7-f05911fc0734,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-c4df398a-6516-4991-8e58-f12bd1756c46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-585495770-172.17.0.7-1595894319292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42447,DS-3d956216-38c4-43ef-9502-32968f7f0a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-ed18134c-aeeb-40f8-8043-0e123cf56b39,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-53eda230-1034-4762-876c-bf5b23956f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-716171ce-19f3-4555-bf79-26585d6aa7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-c2ffe591-b933-45dd-8620-781d214d5d27,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-7eac2191-a4da-40ed-8db3-60d647f3ee64,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-eeb5522d-5201-4a0d-8aa7-f05911fc0734,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-c4df398a-6516-4991-8e58-f12bd1756c46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2047095955-172.17.0.7-1595894580186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44066,DS-b041c3d2-d363-45b3-8501-3b0b966ca83f,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-2f35b852-4c81-4d29-b17a-3d82803dbbe7,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-a739c6ec-69b5-4827-9000-b42affb2c743,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-dac236d9-641d-4224-ab23-5e49a76b50bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34047,DS-6b9e80fc-a6c6-493a-a457-6b1f89a45a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-f560573d-8e66-47cf-afee-cb4e1497972f,DISK], DatanodeInfoWithStorage[127.0.0.1:37051,DS-8cf19b19-09b5-4ee3-8343-11f9e502e3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-e3d365f1-0485-45fa-8f46-67cfdd291815,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2047095955-172.17.0.7-1595894580186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44066,DS-b041c3d2-d363-45b3-8501-3b0b966ca83f,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-2f35b852-4c81-4d29-b17a-3d82803dbbe7,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-a739c6ec-69b5-4827-9000-b42affb2c743,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-dac236d9-641d-4224-ab23-5e49a76b50bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34047,DS-6b9e80fc-a6c6-493a-a457-6b1f89a45a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-f560573d-8e66-47cf-afee-cb4e1497972f,DISK], DatanodeInfoWithStorage[127.0.0.1:37051,DS-8cf19b19-09b5-4ee3-8343-11f9e502e3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-e3d365f1-0485-45fa-8f46-67cfdd291815,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1947069448-172.17.0.7-1595895354261:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34699,DS-65764106-d23c-48f3-9cea-3554a3cabfcd,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-48a43aeb-951d-48c8-8866-35b6060008c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-320db869-31b7-49e3-82ab-2b6922b5ac4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-50335b94-caa1-497d-9ff1-8c256a78aac6,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-84b87a6f-2a5f-49b4-ad2a-d743acb73bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-3686dd64-c0c1-44ef-b4f9-33d30449f1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-3c8bd77c-ea07-40f5-89a1-51e6c4b05867,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-c8c432c1-0aeb-4219-b7c2-88ad2be566b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1947069448-172.17.0.7-1595895354261:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34699,DS-65764106-d23c-48f3-9cea-3554a3cabfcd,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-48a43aeb-951d-48c8-8866-35b6060008c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-320db869-31b7-49e3-82ab-2b6922b5ac4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-50335b94-caa1-497d-9ff1-8c256a78aac6,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-84b87a6f-2a5f-49b4-ad2a-d743acb73bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-3686dd64-c0c1-44ef-b4f9-33d30449f1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-3c8bd77c-ea07-40f5-89a1-51e6c4b05867,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-c8c432c1-0aeb-4219-b7c2-88ad2be566b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-139388713-172.17.0.7-1595895387388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39987,DS-a42ab88b-fcc0-4342-a501-93911b6d851e,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-0e688c08-ec56-417f-9595-f7f9858e85a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-6f2ae6d1-313a-4ba2-afd2-8ccb13b8e79b,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-f8e3762b-2034-41ed-8040-5de198842e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42333,DS-6095377d-771e-4d72-92e7-116e59c12b75,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-310c7f5d-c98d-4ef7-a1d3-5c695271b239,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-6f839794-fe58-4076-b585-985fecbb1535,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-f33cf755-d019-46bb-8bfd-f50daf031c55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-139388713-172.17.0.7-1595895387388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39987,DS-a42ab88b-fcc0-4342-a501-93911b6d851e,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-0e688c08-ec56-417f-9595-f7f9858e85a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-6f2ae6d1-313a-4ba2-afd2-8ccb13b8e79b,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-f8e3762b-2034-41ed-8040-5de198842e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42333,DS-6095377d-771e-4d72-92e7-116e59c12b75,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-310c7f5d-c98d-4ef7-a1d3-5c695271b239,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-6f839794-fe58-4076-b585-985fecbb1535,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-f33cf755-d019-46bb-8bfd-f50daf031c55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1164609741-172.17.0.7-1595895496967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33612,DS-a6d36657-cddc-411c-b8f6-f237570bf914,DISK], DatanodeInfoWithStorage[127.0.0.1:39507,DS-5c25b137-7867-4c54-9250-7d59b616e1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35779,DS-bb62b11f-8cdc-44a5-b69f-0bc0bc69cb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-bb28e6ab-0ba1-40ac-8703-35edba87ee1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-64d2c04a-2540-4886-8ad1-21bffd424556,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-47407c6e-be32-4817-bcf3-ecaeca80884d,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-5052438e-737d-40ae-a2b1-cc90d9ca68d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-363590d9-8f5a-40d0-9c4f-b56fe7dbeb76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1164609741-172.17.0.7-1595895496967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33612,DS-a6d36657-cddc-411c-b8f6-f237570bf914,DISK], DatanodeInfoWithStorage[127.0.0.1:39507,DS-5c25b137-7867-4c54-9250-7d59b616e1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35779,DS-bb62b11f-8cdc-44a5-b69f-0bc0bc69cb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-bb28e6ab-0ba1-40ac-8703-35edba87ee1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-64d2c04a-2540-4886-8ad1-21bffd424556,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-47407c6e-be32-4817-bcf3-ecaeca80884d,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-5052438e-737d-40ae-a2b1-cc90d9ca68d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-363590d9-8f5a-40d0-9c4f-b56fe7dbeb76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1094283053-172.17.0.7-1595895857396:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44469,DS-62c8a6af-1e3b-4af5-af8b-a30e4b011b81,DISK], DatanodeInfoWithStorage[127.0.0.1:41251,DS-941c19d0-d4ec-4b8d-837f-3bdf5c771527,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-bfff43c8-6a95-4b0f-b6dd-a94b9cdbbf4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-50c7ecfa-a811-4cb6-aac3-d290330401e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-3677b329-078d-4df5-b8ad-fbc8d447dc06,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-8f7fee71-6d32-426a-813e-1451c888c169,DISK], DatanodeInfoWithStorage[127.0.0.1:36333,DS-99696bc1-5651-4d39-821a-dc21f256fc3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-b8817f4f-c235-4f6d-9b74-7114be4d005e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1094283053-172.17.0.7-1595895857396:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44469,DS-62c8a6af-1e3b-4af5-af8b-a30e4b011b81,DISK], DatanodeInfoWithStorage[127.0.0.1:41251,DS-941c19d0-d4ec-4b8d-837f-3bdf5c771527,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-bfff43c8-6a95-4b0f-b6dd-a94b9cdbbf4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-50c7ecfa-a811-4cb6-aac3-d290330401e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-3677b329-078d-4df5-b8ad-fbc8d447dc06,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-8f7fee71-6d32-426a-813e-1451c888c169,DISK], DatanodeInfoWithStorage[127.0.0.1:36333,DS-99696bc1-5651-4d39-821a-dc21f256fc3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-b8817f4f-c235-4f6d-9b74-7114be4d005e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1506632114-172.17.0.7-1595896005342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37679,DS-8df00236-baab-4afd-a1f3-d7f2b3235473,DISK], DatanodeInfoWithStorage[127.0.0.1:42251,DS-27683547-fde7-46f7-b5ff-91140ff6de5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-5e516e53-30f8-4919-aa36-024907f601e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-bd4304a5-d4bb-4c17-9040-629dbe028c83,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-53fd39b0-9eac-4623-a88e-faa8124c3df3,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-985721ea-98a6-471d-bc5f-cde3338f56ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-7f603ba7-d65c-4873-832c-7593309bbe87,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-08c0a1d7-379c-488d-b710-d326648d02c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1506632114-172.17.0.7-1595896005342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37679,DS-8df00236-baab-4afd-a1f3-d7f2b3235473,DISK], DatanodeInfoWithStorage[127.0.0.1:42251,DS-27683547-fde7-46f7-b5ff-91140ff6de5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-5e516e53-30f8-4919-aa36-024907f601e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-bd4304a5-d4bb-4c17-9040-629dbe028c83,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-53fd39b0-9eac-4623-a88e-faa8124c3df3,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-985721ea-98a6-471d-bc5f-cde3338f56ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-7f603ba7-d65c-4873-832c-7593309bbe87,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-08c0a1d7-379c-488d-b710-d326648d02c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-856105103-172.17.0.7-1595896070604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34998,DS-934dd740-9bc9-4cf0-9cee-b6a316341634,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-50414203-0444-4ca4-82dc-91e426eb89fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-e77d8f5a-7cb1-453b-aa98-bec0919f2d02,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-5307b332-d8cb-4c10-9831-13d7f41d3f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-0ee4d465-2826-4360-8af8-47d7898dcf48,DISK], DatanodeInfoWithStorage[127.0.0.1:42183,DS-5bd69927-0f58-4e36-8cb3-667ff2e70bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41762,DS-113a2243-f2dd-410a-acea-70fe8973cb25,DISK], DatanodeInfoWithStorage[127.0.0.1:45820,DS-d8d0cedb-c87a-4d5f-89d8-4ca9c2f198d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-856105103-172.17.0.7-1595896070604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34998,DS-934dd740-9bc9-4cf0-9cee-b6a316341634,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-50414203-0444-4ca4-82dc-91e426eb89fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-e77d8f5a-7cb1-453b-aa98-bec0919f2d02,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-5307b332-d8cb-4c10-9831-13d7f41d3f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-0ee4d465-2826-4360-8af8-47d7898dcf48,DISK], DatanodeInfoWithStorage[127.0.0.1:42183,DS-5bd69927-0f58-4e36-8cb3-667ff2e70bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41762,DS-113a2243-f2dd-410a-acea-70fe8973cb25,DISK], DatanodeInfoWithStorage[127.0.0.1:45820,DS-d8d0cedb-c87a-4d5f-89d8-4ca9c2f198d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1448331853-172.17.0.7-1595896138832:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33523,DS-c5597624-ea39-4e19-8e75-1a44b48a4735,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-215e2fe0-8b85-4703-be1d-c69a68ab1580,DISK], DatanodeInfoWithStorage[127.0.0.1:39485,DS-38597cc1-ce52-4591-b628-52251d307d63,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-10db4148-71df-49b2-8689-b0c5939454b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-0e043f12-7e41-4aa2-ac7c-b24f0834fa31,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-e78987cf-c936-4b0f-bc47-5f8a6f5416af,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-797728ae-d285-40a9-b43c-bbadb5f717c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38291,DS-ab0198e1-d93b-4e84-ba5f-d05c7bd1a581,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1448331853-172.17.0.7-1595896138832:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33523,DS-c5597624-ea39-4e19-8e75-1a44b48a4735,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-215e2fe0-8b85-4703-be1d-c69a68ab1580,DISK], DatanodeInfoWithStorage[127.0.0.1:39485,DS-38597cc1-ce52-4591-b628-52251d307d63,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-10db4148-71df-49b2-8689-b0c5939454b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-0e043f12-7e41-4aa2-ac7c-b24f0834fa31,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-e78987cf-c936-4b0f-bc47-5f8a6f5416af,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-797728ae-d285-40a9-b43c-bbadb5f717c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38291,DS-ab0198e1-d93b-4e84-ba5f-d05c7bd1a581,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-669542561-172.17.0.7-1595896313758:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34219,DS-6977b2c2-416b-4d69-9cd7-62d721540176,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-57049174-9e2e-4885-8808-0c5d8b51d0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-94e5ad5f-ffb9-4057-ab25-36ea132a4138,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-f81067dd-7f11-464f-b1cc-e6f7005e4b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:32983,DS-b123165b-27ba-48bd-a719-77a23bfc3695,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-7b8b1173-6dd8-4478-93dd-8dc5d0b5d575,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-0f3d1366-ac33-41f9-8359-4b198221c256,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-98e995b2-bce4-4e03-8095-a9d61bff71f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-669542561-172.17.0.7-1595896313758:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34219,DS-6977b2c2-416b-4d69-9cd7-62d721540176,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-57049174-9e2e-4885-8808-0c5d8b51d0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-94e5ad5f-ffb9-4057-ab25-36ea132a4138,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-f81067dd-7f11-464f-b1cc-e6f7005e4b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:32983,DS-b123165b-27ba-48bd-a719-77a23bfc3695,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-7b8b1173-6dd8-4478-93dd-8dc5d0b5d575,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-0f3d1366-ac33-41f9-8359-4b198221c256,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-98e995b2-bce4-4e03-8095-a9d61bff71f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-54052562-172.17.0.7-1595896386601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43504,DS-19bbb59d-0f52-4a02-a047-92e04fcb4344,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-54005e81-16ed-4c9c-af7c-e7a86758461c,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-a243ed3c-aff4-4052-83ab-35943cf2fdab,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-e11b19cf-084c-46ea-9996-2f0105cdb8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36406,DS-2e276884-6d3c-4ad7-88f7-ed9b0c06fe30,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-c701fc23-5fea-4839-9067-066c8e429e69,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-548a225b-6324-45f1-b16f-bd465529bb47,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-a653207d-e328-4870-8b80-daf4208d8380,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-54052562-172.17.0.7-1595896386601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43504,DS-19bbb59d-0f52-4a02-a047-92e04fcb4344,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-54005e81-16ed-4c9c-af7c-e7a86758461c,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-a243ed3c-aff4-4052-83ab-35943cf2fdab,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-e11b19cf-084c-46ea-9996-2f0105cdb8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36406,DS-2e276884-6d3c-4ad7-88f7-ed9b0c06fe30,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-c701fc23-5fea-4839-9067-066c8e429e69,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-548a225b-6324-45f1-b16f-bd465529bb47,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-a653207d-e328-4870-8b80-daf4208d8380,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-809015797-172.17.0.7-1595896897069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44932,DS-ec0f6289-0479-40de-924c-e403aeae15bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-d8be46d0-db95-4fa2-ad00-fecb72c8a7f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-aa005b65-8f12-4a42-92ea-04fd0c018a12,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-af964477-4ad6-405c-9c88-8a92d5b43029,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-83281c64-441f-4577-aca7-42a5e9676464,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-d38b39e7-1024-4461-8661-1b409070ea6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-019630fc-ece7-47fb-abcf-b69ddccc59d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37205,DS-d2ff6b8c-7f2c-4653-8946-df981327d4af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-809015797-172.17.0.7-1595896897069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44932,DS-ec0f6289-0479-40de-924c-e403aeae15bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-d8be46d0-db95-4fa2-ad00-fecb72c8a7f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-aa005b65-8f12-4a42-92ea-04fd0c018a12,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-af964477-4ad6-405c-9c88-8a92d5b43029,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-83281c64-441f-4577-aca7-42a5e9676464,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-d38b39e7-1024-4461-8661-1b409070ea6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-019630fc-ece7-47fb-abcf-b69ddccc59d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37205,DS-d2ff6b8c-7f2c-4653-8946-df981327d4af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1255015928-172.17.0.7-1595897290880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42625,DS-d65b7117-5d9e-4a6c-b014-c61c457be7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-0a593dbd-baf9-45cd-9bd1-bbf8e0593011,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-effa1a0c-c5e3-4717-bced-b4588c283be9,DISK], DatanodeInfoWithStorage[127.0.0.1:43025,DS-26b1ed59-8323-4df2-9d59-ba2c740b021f,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-97aab819-71e9-462a-9292-dc6babe73ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-67d24245-63f6-4709-90a2-76c90b999615,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-de0b9460-ad34-4de3-837d-fdfac12dad4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-760d7f4c-b7aa-40e9-9cbe-c10328eb9005,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1255015928-172.17.0.7-1595897290880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42625,DS-d65b7117-5d9e-4a6c-b014-c61c457be7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-0a593dbd-baf9-45cd-9bd1-bbf8e0593011,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-effa1a0c-c5e3-4717-bced-b4588c283be9,DISK], DatanodeInfoWithStorage[127.0.0.1:43025,DS-26b1ed59-8323-4df2-9d59-ba2c740b021f,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-97aab819-71e9-462a-9292-dc6babe73ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-67d24245-63f6-4709-90a2-76c90b999615,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-de0b9460-ad34-4de3-837d-fdfac12dad4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-760d7f4c-b7aa-40e9-9cbe-c10328eb9005,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-892393803-172.17.0.7-1595897360167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44319,DS-1806e026-9f51-42b7-b3f3-c980bf1203c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-4a7f2876-3a29-4530-b0ac-2d8cedfd5d26,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-c1e53e93-7ef3-4190-84f0-4bd1a1cf39a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-e7e98cee-faa1-4950-847c-3e2a4e388f61,DISK], DatanodeInfoWithStorage[127.0.0.1:44389,DS-24dd87b3-dfa5-414a-a9a7-32264fef7916,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-1f185bb8-756f-400b-a530-b718722f6958,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-3de20270-ef90-485a-8be9-fe9589a99a87,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-9d8ff245-9ddc-49a6-be1f-eb2e028d3f47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-892393803-172.17.0.7-1595897360167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44319,DS-1806e026-9f51-42b7-b3f3-c980bf1203c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-4a7f2876-3a29-4530-b0ac-2d8cedfd5d26,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-c1e53e93-7ef3-4190-84f0-4bd1a1cf39a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-e7e98cee-faa1-4950-847c-3e2a4e388f61,DISK], DatanodeInfoWithStorage[127.0.0.1:44389,DS-24dd87b3-dfa5-414a-a9a7-32264fef7916,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-1f185bb8-756f-400b-a530-b718722f6958,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-3de20270-ef90-485a-8be9-fe9589a99a87,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-9d8ff245-9ddc-49a6-be1f-eb2e028d3f47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-456741403-172.17.0.7-1595897813436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32816,DS-e113ef1e-8aba-4224-bc03-185e134ccc78,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-723b3c97-c149-41cb-a62f-e872e871ed8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-9c2031ca-9cc2-48d3-a70a-bfbdda94a115,DISK], DatanodeInfoWithStorage[127.0.0.1:45092,DS-57fb6ec9-d672-44a0-9404-9766dd2e76c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-30cc63ea-b9c3-4c34-8e48-8f2304125f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-c3d5b6f3-93c2-44fb-9895-10d1ca695df8,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-8ec06ec2-d429-4c2d-a4ad-53bc5911679c,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-4f58b208-5cdc-4e79-a32d-e8a58fea4992,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-456741403-172.17.0.7-1595897813436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32816,DS-e113ef1e-8aba-4224-bc03-185e134ccc78,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-723b3c97-c149-41cb-a62f-e872e871ed8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-9c2031ca-9cc2-48d3-a70a-bfbdda94a115,DISK], DatanodeInfoWithStorage[127.0.0.1:45092,DS-57fb6ec9-d672-44a0-9404-9766dd2e76c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-30cc63ea-b9c3-4c34-8e48-8f2304125f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-c3d5b6f3-93c2-44fb-9895-10d1ca695df8,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-8ec06ec2-d429-4c2d-a4ad-53bc5911679c,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-4f58b208-5cdc-4e79-a32d-e8a58fea4992,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5256
