reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1042957811-172.17.0.13-1595584096818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37562,DS-934813e4-e648-4781-ad0b-fd8f74616b93,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-84e4f8ba-106c-4ebb-9253-bfb894795bce,DISK], DatanodeInfoWithStorage[127.0.0.1:41380,DS-5b57a1dc-92d4-4aec-8e53-5a9152fd6a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45651,DS-753c847b-db85-431d-9de9-3e17742cce08,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-c67267cb-6fd3-4f94-b0eb-efd5cd513b22,DISK], DatanodeInfoWithStorage[127.0.0.1:39562,DS-11b93982-ba39-4086-a457-f540128807d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-5b69d09c-a788-4519-b7cf-8c1c8970e79a,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-f0bf78fe-c180-4551-9fcb-ad17cd9c8f54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1042957811-172.17.0.13-1595584096818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37562,DS-934813e4-e648-4781-ad0b-fd8f74616b93,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-84e4f8ba-106c-4ebb-9253-bfb894795bce,DISK], DatanodeInfoWithStorage[127.0.0.1:41380,DS-5b57a1dc-92d4-4aec-8e53-5a9152fd6a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45651,DS-753c847b-db85-431d-9de9-3e17742cce08,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-c67267cb-6fd3-4f94-b0eb-efd5cd513b22,DISK], DatanodeInfoWithStorage[127.0.0.1:39562,DS-11b93982-ba39-4086-a457-f540128807d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-5b69d09c-a788-4519-b7cf-8c1c8970e79a,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-f0bf78fe-c180-4551-9fcb-ad17cd9c8f54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-143517489-172.17.0.13-1595584319927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37162,DS-7f98148a-a29d-4340-8f24-06d65d06ece9,DISK], DatanodeInfoWithStorage[127.0.0.1:34437,DS-1868add6-e7f2-4b80-bced-af751bce65b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-acce846d-8562-4410-84ea-3bec0e213501,DISK], DatanodeInfoWithStorage[127.0.0.1:44675,DS-126b0111-7600-4c3f-8a84-e0a515e8724d,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-c5d4acb2-d450-4a7c-8da2-1ff24ed96b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-c601ee8c-fbb1-4846-813c-7914e6580da5,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-21e79f7a-94cc-464a-b66e-1c515c7ebd87,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-a302b9da-9df6-49f5-ae39-c6abb08b9d36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-143517489-172.17.0.13-1595584319927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37162,DS-7f98148a-a29d-4340-8f24-06d65d06ece9,DISK], DatanodeInfoWithStorage[127.0.0.1:34437,DS-1868add6-e7f2-4b80-bced-af751bce65b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-acce846d-8562-4410-84ea-3bec0e213501,DISK], DatanodeInfoWithStorage[127.0.0.1:44675,DS-126b0111-7600-4c3f-8a84-e0a515e8724d,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-c5d4acb2-d450-4a7c-8da2-1ff24ed96b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-c601ee8c-fbb1-4846-813c-7914e6580da5,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-21e79f7a-94cc-464a-b66e-1c515c7ebd87,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-a302b9da-9df6-49f5-ae39-c6abb08b9d36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1349651698-172.17.0.13-1595585538531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43922,DS-0212c8e0-2e39-4c1a-9f26-5e48fe1c7452,DISK], DatanodeInfoWithStorage[127.0.0.1:41028,DS-c5efb9fc-2c46-4911-abc7-26707e42e086,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-cde035ac-fa8a-4852-bf33-ec2a68a42882,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-c10ebcb7-e7e1-459e-af09-f41aa0e58a90,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-5eab49c2-6fb9-44b7-bcbe-64baaae3d403,DISK], DatanodeInfoWithStorage[127.0.0.1:35136,DS-717f5db2-7b74-48e6-82d5-5e470fb80f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44202,DS-adbd3415-27d9-49eb-8c6a-11a7b3c9c343,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-182bba49-76fd-4428-b2e1-e972831d23e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1349651698-172.17.0.13-1595585538531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43922,DS-0212c8e0-2e39-4c1a-9f26-5e48fe1c7452,DISK], DatanodeInfoWithStorage[127.0.0.1:41028,DS-c5efb9fc-2c46-4911-abc7-26707e42e086,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-cde035ac-fa8a-4852-bf33-ec2a68a42882,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-c10ebcb7-e7e1-459e-af09-f41aa0e58a90,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-5eab49c2-6fb9-44b7-bcbe-64baaae3d403,DISK], DatanodeInfoWithStorage[127.0.0.1:35136,DS-717f5db2-7b74-48e6-82d5-5e470fb80f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44202,DS-adbd3415-27d9-49eb-8c6a-11a7b3c9c343,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-182bba49-76fd-4428-b2e1-e972831d23e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-788300849-172.17.0.13-1595586300576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44581,DS-bffe8f1a-ca70-4ffe-ae07-0a00d8c179e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-455aeb47-49d7-46e8-8c34-b2f015b4dfbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-775ee6ef-3da9-479a-a90c-9c2b3803f2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-ada383d4-eb3b-4fd3-bcb8-4eb581cc969e,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-1acdab98-efa2-4e4b-8510-5afb1af02456,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-5cbfc1f3-4a10-446c-bedc-c5f21a6496bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-6b909638-c067-425f-ab9b-02fc0d98f256,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-2b47fae6-8558-4ee1-a7f8-86b564765558,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-788300849-172.17.0.13-1595586300576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44581,DS-bffe8f1a-ca70-4ffe-ae07-0a00d8c179e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-455aeb47-49d7-46e8-8c34-b2f015b4dfbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-775ee6ef-3da9-479a-a90c-9c2b3803f2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-ada383d4-eb3b-4fd3-bcb8-4eb581cc969e,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-1acdab98-efa2-4e4b-8510-5afb1af02456,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-5cbfc1f3-4a10-446c-bedc-c5f21a6496bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-6b909638-c067-425f-ab9b-02fc0d98f256,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-2b47fae6-8558-4ee1-a7f8-86b564765558,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-212678079-172.17.0.13-1595586439382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45547,DS-7c2619b4-eec5-45b2-be35-6af44a2bbfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-2e735036-7b62-43d4-aeb9-774c98ad0038,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-0fca487f-1df8-4ab4-b366-2dd60e3eb787,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-48a90ffa-5c11-43d9-a7b2-275439d54449,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-e5e25f15-0c00-4bce-9592-69bed7cf9454,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-336e12bf-227d-4836-ad14-744356c1c051,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-37f36f3d-36f1-47b8-9cd9-fcbe6f060a59,DISK], DatanodeInfoWithStorage[127.0.0.1:43423,DS-87773328-18e9-4c05-9928-65d8c6e19f50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-212678079-172.17.0.13-1595586439382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45547,DS-7c2619b4-eec5-45b2-be35-6af44a2bbfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-2e735036-7b62-43d4-aeb9-774c98ad0038,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-0fca487f-1df8-4ab4-b366-2dd60e3eb787,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-48a90ffa-5c11-43d9-a7b2-275439d54449,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-e5e25f15-0c00-4bce-9592-69bed7cf9454,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-336e12bf-227d-4836-ad14-744356c1c051,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-37f36f3d-36f1-47b8-9cd9-fcbe6f060a59,DISK], DatanodeInfoWithStorage[127.0.0.1:43423,DS-87773328-18e9-4c05-9928-65d8c6e19f50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1650467135-172.17.0.13-1595586593541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38571,DS-152a360b-cfc8-4664-b869-196040c95954,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-d52256f5-ad56-4202-8c05-34ae3dc9fa49,DISK], DatanodeInfoWithStorage[127.0.0.1:36900,DS-4e94be34-29b1-4e09-b95a-bc96a25907e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-793f89c4-8dae-4977-b192-074d0f0761df,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-be305a50-a109-44b9-b0dc-f8866c4583dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-97634365-e651-4e29-8f39-0a5a0d49c9df,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-d57ed495-d8d6-4d0b-9d9a-7a586d247007,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-fa561294-dc4e-4da9-9b4e-99fc4d35f742,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1650467135-172.17.0.13-1595586593541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38571,DS-152a360b-cfc8-4664-b869-196040c95954,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-d52256f5-ad56-4202-8c05-34ae3dc9fa49,DISK], DatanodeInfoWithStorage[127.0.0.1:36900,DS-4e94be34-29b1-4e09-b95a-bc96a25907e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-793f89c4-8dae-4977-b192-074d0f0761df,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-be305a50-a109-44b9-b0dc-f8866c4583dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-97634365-e651-4e29-8f39-0a5a0d49c9df,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-d57ed495-d8d6-4d0b-9d9a-7a586d247007,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-fa561294-dc4e-4da9-9b4e-99fc4d35f742,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1846963967-172.17.0.13-1595587904145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38665,DS-48815e33-2e70-4512-866f-db10f2a5c951,DISK], DatanodeInfoWithStorage[127.0.0.1:43640,DS-0842af2a-96eb-4359-af94-aaf93dac313e,DISK], DatanodeInfoWithStorage[127.0.0.1:34515,DS-6d860c06-1fc1-4bd7-9682-bd144a7dc9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-7fb28f82-af8b-4b5c-95db-479b528f2f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35508,DS-d62816b3-3716-4fa6-988f-d1118fa07268,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-95f89702-f618-4974-8fd1-75feea2df529,DISK], DatanodeInfoWithStorage[127.0.0.1:35004,DS-531508a6-ccb2-4ab4-a115-52bc7a9919be,DISK], DatanodeInfoWithStorage[127.0.0.1:41209,DS-8c3cce01-0541-4f25-b4a8-857820aaa670,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1846963967-172.17.0.13-1595587904145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38665,DS-48815e33-2e70-4512-866f-db10f2a5c951,DISK], DatanodeInfoWithStorage[127.0.0.1:43640,DS-0842af2a-96eb-4359-af94-aaf93dac313e,DISK], DatanodeInfoWithStorage[127.0.0.1:34515,DS-6d860c06-1fc1-4bd7-9682-bd144a7dc9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-7fb28f82-af8b-4b5c-95db-479b528f2f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35508,DS-d62816b3-3716-4fa6-988f-d1118fa07268,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-95f89702-f618-4974-8fd1-75feea2df529,DISK], DatanodeInfoWithStorage[127.0.0.1:35004,DS-531508a6-ccb2-4ab4-a115-52bc7a9919be,DISK], DatanodeInfoWithStorage[127.0.0.1:41209,DS-8c3cce01-0541-4f25-b4a8-857820aaa670,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1700749756-172.17.0.13-1595588575124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35888,DS-91d4429f-6d77-4683-9e33-2c1983fe06e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-b83f31e1-7892-42cc-9c32-18f3c0c3b53f,DISK], DatanodeInfoWithStorage[127.0.0.1:38063,DS-7930e564-7b45-4882-bda6-b501df23a14b,DISK], DatanodeInfoWithStorage[127.0.0.1:42773,DS-ccbdc397-5bb7-4060-b332-ccca0b238cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-69135223-a921-41ca-bd55-af50a1079a15,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-5d1f4a0a-4810-4293-be69-5630b8dba007,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-07bc9032-aca0-4069-9a5a-c24ed1d1c56b,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-671e0ef1-d762-4688-a501-b5e1cf658a91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1700749756-172.17.0.13-1595588575124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35888,DS-91d4429f-6d77-4683-9e33-2c1983fe06e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-b83f31e1-7892-42cc-9c32-18f3c0c3b53f,DISK], DatanodeInfoWithStorage[127.0.0.1:38063,DS-7930e564-7b45-4882-bda6-b501df23a14b,DISK], DatanodeInfoWithStorage[127.0.0.1:42773,DS-ccbdc397-5bb7-4060-b332-ccca0b238cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-69135223-a921-41ca-bd55-af50a1079a15,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-5d1f4a0a-4810-4293-be69-5630b8dba007,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-07bc9032-aca0-4069-9a5a-c24ed1d1c56b,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-671e0ef1-d762-4688-a501-b5e1cf658a91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-452954178-172.17.0.13-1595588610959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33274,DS-c57fcb10-ec35-4a53-9ced-1e616f940e90,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-1c56d187-add3-465f-91c0-472be4e0e008,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-f132bacc-01a7-482c-a4bc-359d79691bec,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-1ec17d90-91ed-498f-ae11-9eccdeaaa872,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-ada73cb2-1a68-4e70-b256-5ae176dc9c68,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-69ef8f5f-10e5-4162-8a53-660d8af52773,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-6fbcc97a-804f-43a4-97c6-20512cbcf5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-3fd46e4e-6ecd-4e16-b95d-e226dae6493f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-452954178-172.17.0.13-1595588610959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33274,DS-c57fcb10-ec35-4a53-9ced-1e616f940e90,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-1c56d187-add3-465f-91c0-472be4e0e008,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-f132bacc-01a7-482c-a4bc-359d79691bec,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-1ec17d90-91ed-498f-ae11-9eccdeaaa872,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-ada73cb2-1a68-4e70-b256-5ae176dc9c68,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-69ef8f5f-10e5-4162-8a53-660d8af52773,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-6fbcc97a-804f-43a4-97c6-20512cbcf5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-3fd46e4e-6ecd-4e16-b95d-e226dae6493f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1347113746-172.17.0.13-1595588721652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38748,DS-160a408e-45dc-4f87-bc49-e94612fdf000,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-d66a1d5d-a05c-445e-96fd-46958a0cf4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-d32fcc6a-91fc-44e8-bdad-21a4ca7cad18,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-c779e7a7-15a5-4482-a0b4-b56ecd95d2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-6875748d-6425-4950-aaba-ec5b61d488d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-5322b562-3541-4074-81a0-a3cff29cf9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-00b103ff-ba40-474a-bada-e0b384ead97f,DISK], DatanodeInfoWithStorage[127.0.0.1:41582,DS-2718101b-7013-4cc9-aa4e-15747190180b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1347113746-172.17.0.13-1595588721652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38748,DS-160a408e-45dc-4f87-bc49-e94612fdf000,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-d66a1d5d-a05c-445e-96fd-46958a0cf4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-d32fcc6a-91fc-44e8-bdad-21a4ca7cad18,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-c779e7a7-15a5-4482-a0b4-b56ecd95d2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-6875748d-6425-4950-aaba-ec5b61d488d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-5322b562-3541-4074-81a0-a3cff29cf9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-00b103ff-ba40-474a-bada-e0b384ead97f,DISK], DatanodeInfoWithStorage[127.0.0.1:41582,DS-2718101b-7013-4cc9-aa4e-15747190180b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1872142954-172.17.0.13-1595589440364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43819,DS-7ad5f02c-9474-4907-9904-0f98a6d728dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-e05af314-f4bd-4459-bb19-00f1cf1feaaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-8507bfef-3ca9-4852-b819-42e81e732dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38792,DS-f9501477-ba0d-457f-9dac-b1493c9f5ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-fdeebd7b-98e9-4152-8c36-d20e64bad19b,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-e83bff6c-ce11-43b2-9607-af9de2af10f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-d07ecaff-36a7-4271-8c17-e10b87167c17,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-5a124c06-e68f-4936-bd6f-60df48cd566b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1872142954-172.17.0.13-1595589440364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43819,DS-7ad5f02c-9474-4907-9904-0f98a6d728dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-e05af314-f4bd-4459-bb19-00f1cf1feaaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-8507bfef-3ca9-4852-b819-42e81e732dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38792,DS-f9501477-ba0d-457f-9dac-b1493c9f5ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-fdeebd7b-98e9-4152-8c36-d20e64bad19b,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-e83bff6c-ce11-43b2-9607-af9de2af10f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-d07ecaff-36a7-4271-8c17-e10b87167c17,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-5a124c06-e68f-4936-bd6f-60df48cd566b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1094482614-172.17.0.13-1595589566990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33441,DS-35a27506-7dfd-47d4-a6eb-e454b03a086c,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-5897f781-61fc-42f9-8f88-766acf52ed72,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-1aaae196-12e9-41c3-86e7-5ed5069fb38c,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-b66fcb32-c281-43ed-8ae9-2d7789bd98f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34615,DS-c85d6bd3-3ded-42ea-9c6e-cd43f43be47e,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-addca8bf-3a82-4eb0-93e7-e20c0aad12b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41935,DS-e0a5d1b0-9f8d-4c83-85d7-add85ff02adf,DISK], DatanodeInfoWithStorage[127.0.0.1:38009,DS-5f45b003-7127-437e-ab9c-9c3bd0c7b511,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1094482614-172.17.0.13-1595589566990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33441,DS-35a27506-7dfd-47d4-a6eb-e454b03a086c,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-5897f781-61fc-42f9-8f88-766acf52ed72,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-1aaae196-12e9-41c3-86e7-5ed5069fb38c,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-b66fcb32-c281-43ed-8ae9-2d7789bd98f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34615,DS-c85d6bd3-3ded-42ea-9c6e-cd43f43be47e,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-addca8bf-3a82-4eb0-93e7-e20c0aad12b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41935,DS-e0a5d1b0-9f8d-4c83-85d7-add85ff02adf,DISK], DatanodeInfoWithStorage[127.0.0.1:38009,DS-5f45b003-7127-437e-ab9c-9c3bd0c7b511,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5548
