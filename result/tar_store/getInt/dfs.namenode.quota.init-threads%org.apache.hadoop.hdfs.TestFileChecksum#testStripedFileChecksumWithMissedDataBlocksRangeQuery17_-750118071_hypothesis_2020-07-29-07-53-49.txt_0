reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1036089006-172.17.0.20-1596009239827:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43886,DS-6f4780d8-cb05-43bd-b9f0-838cb7cd8e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37970,DS-4b9bffec-5ba7-47f0-a646-d819c327f4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43597,DS-cf27d6f3-8163-4af9-92eb-f4f9fc340a13,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-a9fd9e74-2e61-4e07-8915-3942a9f0459d,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-68c8970f-542a-4ef1-929d-ba2cac68a9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-ead2e1f1-6155-4bd9-be68-31131a8595b0,DISK], DatanodeInfoWithStorage[127.0.0.1:32904,DS-1fc2489a-a53d-41d6-b3b4-8f2d234547ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-f1f61511-d981-4f5f-88d7-d173d05a868f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1036089006-172.17.0.20-1596009239827:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43886,DS-6f4780d8-cb05-43bd-b9f0-838cb7cd8e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37970,DS-4b9bffec-5ba7-47f0-a646-d819c327f4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43597,DS-cf27d6f3-8163-4af9-92eb-f4f9fc340a13,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-a9fd9e74-2e61-4e07-8915-3942a9f0459d,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-68c8970f-542a-4ef1-929d-ba2cac68a9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-ead2e1f1-6155-4bd9-be68-31131a8595b0,DISK], DatanodeInfoWithStorage[127.0.0.1:32904,DS-1fc2489a-a53d-41d6-b3b4-8f2d234547ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-f1f61511-d981-4f5f-88d7-d173d05a868f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2041952344-172.17.0.20-1596010183723:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34687,DS-a16151f2-7ef4-4205-91e7-07f4212accb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42364,DS-d93781f1-309b-4e9e-9b4a-d2677208caed,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-94266c96-3fe3-4db5-849e-0e0672d82ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-5c43ae26-c2e3-4da5-aadb-d992b9483995,DISK], DatanodeInfoWithStorage[127.0.0.1:40925,DS-bfedc825-2edc-4578-8f9b-437ac22b02d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-4bc82bf2-e0b9-4bf2-b9da-d9fd907acd46,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-3f69cff3-2661-4bcf-94f4-f64680d9e016,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-31d9f74c-1fe2-4e22-91b1-c8c6632d23fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2041952344-172.17.0.20-1596010183723:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34687,DS-a16151f2-7ef4-4205-91e7-07f4212accb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42364,DS-d93781f1-309b-4e9e-9b4a-d2677208caed,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-94266c96-3fe3-4db5-849e-0e0672d82ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-5c43ae26-c2e3-4da5-aadb-d992b9483995,DISK], DatanodeInfoWithStorage[127.0.0.1:40925,DS-bfedc825-2edc-4578-8f9b-437ac22b02d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-4bc82bf2-e0b9-4bf2-b9da-d9fd907acd46,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-3f69cff3-2661-4bcf-94f4-f64680d9e016,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-31d9f74c-1fe2-4e22-91b1-c8c6632d23fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1486325973-172.17.0.20-1596010407639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36520,DS-fb54feaa-aa21-4997-bdef-24164bba4a82,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-1d3dddfa-e582-4b40-babc-de1637da197d,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-59821885-73b5-42b4-bd09-13d156ad1073,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-6b24969a-7d18-4211-8447-13d6d6834d25,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-1ba9339c-b23d-49b7-802f-f998475b100e,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-43015d91-3516-428a-ac5d-0a8e4e0a6024,DISK], DatanodeInfoWithStorage[127.0.0.1:41254,DS-897d62c2-dda9-44e2-88d0-e44e4a1a49f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-9f5b1dc9-f0de-4c99-9c4e-1972a66ba580,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1486325973-172.17.0.20-1596010407639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36520,DS-fb54feaa-aa21-4997-bdef-24164bba4a82,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-1d3dddfa-e582-4b40-babc-de1637da197d,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-59821885-73b5-42b4-bd09-13d156ad1073,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-6b24969a-7d18-4211-8447-13d6d6834d25,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-1ba9339c-b23d-49b7-802f-f998475b100e,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-43015d91-3516-428a-ac5d-0a8e4e0a6024,DISK], DatanodeInfoWithStorage[127.0.0.1:41254,DS-897d62c2-dda9-44e2-88d0-e44e4a1a49f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-9f5b1dc9-f0de-4c99-9c4e-1972a66ba580,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1339180559-172.17.0.20-1596010496517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42120,DS-2ec626e8-6551-49f3-8f83-d6d9eb8fdc30,DISK], DatanodeInfoWithStorage[127.0.0.1:37656,DS-aaaff90f-fc18-4fa6-8af3-e36fa6be4986,DISK], DatanodeInfoWithStorage[127.0.0.1:39513,DS-c96cda60-d2f7-4292-8959-1ec3f0a54a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-608244ef-0cff-472b-b7c2-ffcded6f204d,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-0b96aba7-0967-420a-9545-931f7468f732,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-c5f97f8b-0105-4a3c-b1dc-2fa9b39bf777,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-03fe53f2-6527-429a-bf3b-9c6e101ff418,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-590685ec-7e93-429b-8d68-58f17f65ed0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1339180559-172.17.0.20-1596010496517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42120,DS-2ec626e8-6551-49f3-8f83-d6d9eb8fdc30,DISK], DatanodeInfoWithStorage[127.0.0.1:37656,DS-aaaff90f-fc18-4fa6-8af3-e36fa6be4986,DISK], DatanodeInfoWithStorage[127.0.0.1:39513,DS-c96cda60-d2f7-4292-8959-1ec3f0a54a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-608244ef-0cff-472b-b7c2-ffcded6f204d,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-0b96aba7-0967-420a-9545-931f7468f732,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-c5f97f8b-0105-4a3c-b1dc-2fa9b39bf777,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-03fe53f2-6527-429a-bf3b-9c6e101ff418,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-590685ec-7e93-429b-8d68-58f17f65ed0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-177375399-172.17.0.20-1596010950855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39466,DS-b0d2b81e-0219-4ff0-9db2-adce0f6e6b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37950,DS-7e00410f-f374-47cc-85cd-9d7cdcf1fa8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-822b9dd1-5be2-408f-b263-402e3001b669,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-611d6fb6-fa8a-4f8c-9b33-78c56106d236,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-c7044d00-2523-4911-8766-28dc7241ff25,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-573b66ce-774c-4dc6-988b-ac8e73e40afd,DISK], DatanodeInfoWithStorage[127.0.0.1:45152,DS-870b6d89-7420-430d-8b06-4a95f89e24e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-b35167b8-dd86-4729-b6a0-9baaa0275d52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-177375399-172.17.0.20-1596010950855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39466,DS-b0d2b81e-0219-4ff0-9db2-adce0f6e6b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37950,DS-7e00410f-f374-47cc-85cd-9d7cdcf1fa8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-822b9dd1-5be2-408f-b263-402e3001b669,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-611d6fb6-fa8a-4f8c-9b33-78c56106d236,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-c7044d00-2523-4911-8766-28dc7241ff25,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-573b66ce-774c-4dc6-988b-ac8e73e40afd,DISK], DatanodeInfoWithStorage[127.0.0.1:45152,DS-870b6d89-7420-430d-8b06-4a95f89e24e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-b35167b8-dd86-4729-b6a0-9baaa0275d52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1396262711-172.17.0.20-1596011910410:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34719,DS-989db3e4-4406-45d3-898d-ae3375238f09,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-6596dca6-fddf-4931-b9d5-34a71dd2a68a,DISK], DatanodeInfoWithStorage[127.0.0.1:36538,DS-e5ecfee2-d51d-4a26-a679-726d5b6c8943,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-857e048f-1262-4e4f-8250-ea1001d091ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-b992c1c9-4489-450e-beb2-de5abe87337a,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-f111340e-2ffc-4df8-904d-987201c678a8,DISK], DatanodeInfoWithStorage[127.0.0.1:32794,DS-cc746e25-1f0b-4d9e-8beb-9a8969421f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-8c5f7afa-96ba-4e6d-aac4-f4c36b567156,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1396262711-172.17.0.20-1596011910410:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34719,DS-989db3e4-4406-45d3-898d-ae3375238f09,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-6596dca6-fddf-4931-b9d5-34a71dd2a68a,DISK], DatanodeInfoWithStorage[127.0.0.1:36538,DS-e5ecfee2-d51d-4a26-a679-726d5b6c8943,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-857e048f-1262-4e4f-8250-ea1001d091ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-b992c1c9-4489-450e-beb2-de5abe87337a,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-f111340e-2ffc-4df8-904d-987201c678a8,DISK], DatanodeInfoWithStorage[127.0.0.1:32794,DS-cc746e25-1f0b-4d9e-8beb-9a8969421f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-8c5f7afa-96ba-4e6d-aac4-f4c36b567156,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-857576550-172.17.0.20-1596012269447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38006,DS-29dc277f-54db-4baf-b355-148ab8d5d89d,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-f7cd6055-64fb-49a4-a858-d0451c7ec3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-03360528-85b3-439e-866e-04c61b864130,DISK], DatanodeInfoWithStorage[127.0.0.1:40443,DS-09cd77f7-e243-45e6-9c36-8caa50d821ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-477f1797-dcb7-4041-92fa-41afedc9d8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-a497f52e-7428-4b6d-8104-8d227420d54e,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-e8c4b2a8-e66c-43d3-af0f-98a4d1b196c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33913,DS-98fe5774-cc14-4dc5-aba7-ed971ae4106d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-857576550-172.17.0.20-1596012269447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38006,DS-29dc277f-54db-4baf-b355-148ab8d5d89d,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-f7cd6055-64fb-49a4-a858-d0451c7ec3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-03360528-85b3-439e-866e-04c61b864130,DISK], DatanodeInfoWithStorage[127.0.0.1:40443,DS-09cd77f7-e243-45e6-9c36-8caa50d821ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-477f1797-dcb7-4041-92fa-41afedc9d8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-a497f52e-7428-4b6d-8104-8d227420d54e,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-e8c4b2a8-e66c-43d3-af0f-98a4d1b196c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33913,DS-98fe5774-cc14-4dc5-aba7-ed971ae4106d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2141976317-172.17.0.20-1596012862229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39825,DS-7070092b-a056-4fd2-b0ff-f2e572b32a59,DISK], DatanodeInfoWithStorage[127.0.0.1:45442,DS-86dbd274-7e64-489a-ac82-7d76a0b35699,DISK], DatanodeInfoWithStorage[127.0.0.1:33696,DS-6899e3e7-d922-49b7-9bc1-1a43c3320969,DISK], DatanodeInfoWithStorage[127.0.0.1:35942,DS-57cf4f2e-c3a0-4789-8f63-c00227e353f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-06a8d19e-d702-4b0e-9e12-6f033f1628a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-d3134293-2018-425e-ab65-2704402549d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35916,DS-4325f8a9-0762-4a1f-b05a-73f6547e5ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-4aa63feb-36cf-4b73-b509-aa32fcb4c9bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2141976317-172.17.0.20-1596012862229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39825,DS-7070092b-a056-4fd2-b0ff-f2e572b32a59,DISK], DatanodeInfoWithStorage[127.0.0.1:45442,DS-86dbd274-7e64-489a-ac82-7d76a0b35699,DISK], DatanodeInfoWithStorage[127.0.0.1:33696,DS-6899e3e7-d922-49b7-9bc1-1a43c3320969,DISK], DatanodeInfoWithStorage[127.0.0.1:35942,DS-57cf4f2e-c3a0-4789-8f63-c00227e353f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-06a8d19e-d702-4b0e-9e12-6f033f1628a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-d3134293-2018-425e-ab65-2704402549d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35916,DS-4325f8a9-0762-4a1f-b05a-73f6547e5ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-4aa63feb-36cf-4b73-b509-aa32fcb4c9bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-606331268-172.17.0.20-1596013223003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41078,DS-c4e13ea0-2e64-4f2c-b799-f5e2cbdf96e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-91a8ab8a-2d44-49ea-8ba2-dbfccba15fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-05a897b1-5938-4f4c-9189-fac4e1391b59,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-8471ce5e-0eca-4b89-b77a-18c52cb662d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-385999e2-78a9-4cb0-991f-29c24f183292,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-57d1094e-98d2-4d35-9f7d-219f0dfc3bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-383735ec-9c1b-45df-b40f-65b5bd2936b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45324,DS-19253b75-df2d-4234-a446-ce442cdebeef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-606331268-172.17.0.20-1596013223003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41078,DS-c4e13ea0-2e64-4f2c-b799-f5e2cbdf96e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-91a8ab8a-2d44-49ea-8ba2-dbfccba15fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-05a897b1-5938-4f4c-9189-fac4e1391b59,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-8471ce5e-0eca-4b89-b77a-18c52cb662d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-385999e2-78a9-4cb0-991f-29c24f183292,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-57d1094e-98d2-4d35-9f7d-219f0dfc3bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-383735ec-9c1b-45df-b40f-65b5bd2936b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45324,DS-19253b75-df2d-4234-a446-ce442cdebeef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1466316497-172.17.0.20-1596013256111:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36072,DS-1850d3fb-9dc1-4117-9c75-556477ea41d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-6648711f-bad0-47ee-8f98-64a359c66472,DISK], DatanodeInfoWithStorage[127.0.0.1:38053,DS-df66a9a6-c5f2-4721-b257-7c477582d310,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-bcd5b07d-f205-4a42-a6cd-e2791651edfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-59903ea8-4e8b-48cb-bf81-80a2ed17f7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-f2ecfb32-a416-409b-8aab-d9830588241f,DISK], DatanodeInfoWithStorage[127.0.0.1:46834,DS-6c7449e9-394a-4ecd-96de-80dee4026f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34383,DS-535f2fb3-f7bf-4387-a481-3a5d03126aed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1466316497-172.17.0.20-1596013256111:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36072,DS-1850d3fb-9dc1-4117-9c75-556477ea41d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-6648711f-bad0-47ee-8f98-64a359c66472,DISK], DatanodeInfoWithStorage[127.0.0.1:38053,DS-df66a9a6-c5f2-4721-b257-7c477582d310,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-bcd5b07d-f205-4a42-a6cd-e2791651edfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-59903ea8-4e8b-48cb-bf81-80a2ed17f7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-f2ecfb32-a416-409b-8aab-d9830588241f,DISK], DatanodeInfoWithStorage[127.0.0.1:46834,DS-6c7449e9-394a-4ecd-96de-80dee4026f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34383,DS-535f2fb3-f7bf-4387-a481-3a5d03126aed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-474677105-172.17.0.20-1596013453574:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39723,DS-f8089eae-459e-4ecc-a9fd-8a774170e1be,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-d9b8a5be-2773-4ee5-8e4e-491c6462b236,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-8d18192d-a029-4b8d-88b0-e46c2107943c,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-64a0ae6f-42f7-499c-a6d0-807c3c32c73d,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-2dbfaffb-4db2-4e7b-8427-5bf40942e212,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-72c65c7e-7b20-4eee-a0b1-ff679e0e1961,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-ee5cc2f9-a386-4a24-b3f7-6aa9b519d9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-472320df-c00b-47ef-98dc-5798d9b19d00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-474677105-172.17.0.20-1596013453574:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39723,DS-f8089eae-459e-4ecc-a9fd-8a774170e1be,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-d9b8a5be-2773-4ee5-8e4e-491c6462b236,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-8d18192d-a029-4b8d-88b0-e46c2107943c,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-64a0ae6f-42f7-499c-a6d0-807c3c32c73d,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-2dbfaffb-4db2-4e7b-8427-5bf40942e212,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-72c65c7e-7b20-4eee-a0b1-ff679e0e1961,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-ee5cc2f9-a386-4a24-b3f7-6aa9b519d9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-472320df-c00b-47ef-98dc-5798d9b19d00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1979255980-172.17.0.20-1596013787029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35597,DS-c1d0f559-588f-4041-995a-f5526653c5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-3a7c80de-8e46-40f1-b4cf-5d8fd40391af,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-5f990442-4091-48c3-a8fa-890fe46a3d05,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-ea9eec75-3a47-4d2d-94a4-36c5d965d29c,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-d3da42fe-5334-4bad-aeda-8e5700fb9b85,DISK], DatanodeInfoWithStorage[127.0.0.1:42591,DS-63a5fce0-a2f4-4614-8a1e-a8baf556c0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-49edb942-382f-4353-b95c-b43020c00a72,DISK], DatanodeInfoWithStorage[127.0.0.1:46183,DS-e0d6c562-8b13-4d45-b81e-c63dd74da45c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1979255980-172.17.0.20-1596013787029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35597,DS-c1d0f559-588f-4041-995a-f5526653c5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-3a7c80de-8e46-40f1-b4cf-5d8fd40391af,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-5f990442-4091-48c3-a8fa-890fe46a3d05,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-ea9eec75-3a47-4d2d-94a4-36c5d965d29c,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-d3da42fe-5334-4bad-aeda-8e5700fb9b85,DISK], DatanodeInfoWithStorage[127.0.0.1:42591,DS-63a5fce0-a2f4-4614-8a1e-a8baf556c0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-49edb942-382f-4353-b95c-b43020c00a72,DISK], DatanodeInfoWithStorage[127.0.0.1:46183,DS-e0d6c562-8b13-4d45-b81e-c63dd74da45c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-748927117-172.17.0.20-1596013886500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36342,DS-ba67700a-107d-47f2-a524-e813c6a94229,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-88a735ad-cb6b-4285-becd-bab5a8b7dd92,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-a9bb7458-e62a-4fc3-bf1d-c98f6e538f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-1792836a-201d-4b1f-a316-6893b4aaa494,DISK], DatanodeInfoWithStorage[127.0.0.1:41942,DS-052d3405-840d-46c0-a1c2-a7af0b676b46,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-03879ae6-f1c3-4681-9cc9-8b38a7fb8a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-80030f82-9945-414b-a5d9-fbbd48d58f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-2112b6a1-33d4-424f-8194-f91dafe9ffb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-748927117-172.17.0.20-1596013886500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36342,DS-ba67700a-107d-47f2-a524-e813c6a94229,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-88a735ad-cb6b-4285-becd-bab5a8b7dd92,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-a9bb7458-e62a-4fc3-bf1d-c98f6e538f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-1792836a-201d-4b1f-a316-6893b4aaa494,DISK], DatanodeInfoWithStorage[127.0.0.1:41942,DS-052d3405-840d-46c0-a1c2-a7af0b676b46,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-03879ae6-f1c3-4681-9cc9-8b38a7fb8a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-80030f82-9945-414b-a5d9-fbbd48d58f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-2112b6a1-33d4-424f-8194-f91dafe9ffb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 4771
