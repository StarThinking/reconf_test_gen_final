reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 65536
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 65536
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1141852296-172.17.0.15-1595556298956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44580,DS-545697d7-787e-4459-9e33-6b972893a054,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-54fef811-20f2-4987-92b6-550094d30577,DISK], DatanodeInfoWithStorage[127.0.0.1:42037,DS-f5c8e204-da7f-4f22-914a-757b650fbea7,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-b9909ac4-5ca7-4b3a-bcb5-edb7526966bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38866,DS-2515320a-228e-429d-933c-ec35972351a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-6e839afa-8451-44fa-9a9f-415dd19e7345,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-1a69326c-96cf-457b-9f53-0af5f3f6fbb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-dafe9f41-6ff6-4f94-8c9e-60da5a04f9c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1141852296-172.17.0.15-1595556298956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44580,DS-545697d7-787e-4459-9e33-6b972893a054,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-54fef811-20f2-4987-92b6-550094d30577,DISK], DatanodeInfoWithStorage[127.0.0.1:42037,DS-f5c8e204-da7f-4f22-914a-757b650fbea7,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-b9909ac4-5ca7-4b3a-bcb5-edb7526966bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38866,DS-2515320a-228e-429d-933c-ec35972351a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-6e839afa-8451-44fa-9a9f-415dd19e7345,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-1a69326c-96cf-457b-9f53-0af5f3f6fbb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-dafe9f41-6ff6-4f94-8c9e-60da5a04f9c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 65536
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-188069709-172.17.0.15-1595557992230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35467,DS-ad8c7881-7f0a-4955-ab46-02244c9f7b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-58b48862-9ba0-4f23-b89f-6cb82d3650d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34285,DS-24c05541-ace9-4e41-8174-c5f2a7de1465,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-7793be1b-947b-4381-8017-58c695be59ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38044,DS-0bd0541e-d561-4297-8692-6e18fcd4b72a,DISK], DatanodeInfoWithStorage[127.0.0.1:38552,DS-c5808d97-0aa8-4557-b602-7fc0be955f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-34700061-ab74-48e0-aae1-12af609fb5da,DISK], DatanodeInfoWithStorage[127.0.0.1:38243,DS-bc28abc0-cd66-4f2d-aa9c-40ee5d3e9318,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-188069709-172.17.0.15-1595557992230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35467,DS-ad8c7881-7f0a-4955-ab46-02244c9f7b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-58b48862-9ba0-4f23-b89f-6cb82d3650d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34285,DS-24c05541-ace9-4e41-8174-c5f2a7de1465,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-7793be1b-947b-4381-8017-58c695be59ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38044,DS-0bd0541e-d561-4297-8692-6e18fcd4b72a,DISK], DatanodeInfoWithStorage[127.0.0.1:38552,DS-c5808d97-0aa8-4557-b602-7fc0be955f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-34700061-ab74-48e0-aae1-12af609fb5da,DISK], DatanodeInfoWithStorage[127.0.0.1:38243,DS-bc28abc0-cd66-4f2d-aa9c-40ee5d3e9318,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 65536
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-770572005-172.17.0.15-1595558629136:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33099,DS-aa1a81cb-768d-46a5-ad8c-a93a3b367669,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-d9477856-acf5-4c40-b2ab-4885352a4c98,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-778288b8-fdcb-453a-a6e0-eb4110c09f88,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-d87b4187-b521-42e1-a8f4-750786c67733,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-e831bbf1-fa06-475c-8fdc-913bd743a1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-be2131b1-5dee-451e-ae4a-229dac6fcdce,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-6f36a2df-d3ec-483c-8562-013b45df2f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-61d61ebb-bb7c-4df4-a64f-68f3c28d6f46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-770572005-172.17.0.15-1595558629136:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33099,DS-aa1a81cb-768d-46a5-ad8c-a93a3b367669,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-d9477856-acf5-4c40-b2ab-4885352a4c98,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-778288b8-fdcb-453a-a6e0-eb4110c09f88,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-d87b4187-b521-42e1-a8f4-750786c67733,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-e831bbf1-fa06-475c-8fdc-913bd743a1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-be2131b1-5dee-451e-ae4a-229dac6fcdce,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-6f36a2df-d3ec-483c-8562-013b45df2f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-61d61ebb-bb7c-4df4-a64f-68f3c28d6f46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 65536
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-194259441-172.17.0.15-1595559958803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38301,DS-06f3093e-1b67-46d5-9e81-77c5b509ec49,DISK], DatanodeInfoWithStorage[127.0.0.1:40229,DS-5d3b509c-9946-4048-98ce-e12e9acf1d22,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-a72e3837-b950-4a50-adee-233ff0d601be,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-83d97b82-0f45-4a0f-83ef-b726959ae563,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-85749adf-6f74-4d6e-9994-be2d11c45482,DISK], DatanodeInfoWithStorage[127.0.0.1:34545,DS-dc27f5f6-1504-4dba-ac69-4fc220e391b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-7ae7a72b-a020-4728-bc50-3b1e6179ad44,DISK], DatanodeInfoWithStorage[127.0.0.1:45889,DS-00dd14ad-d235-480d-b0d2-25f496e64fd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-194259441-172.17.0.15-1595559958803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38301,DS-06f3093e-1b67-46d5-9e81-77c5b509ec49,DISK], DatanodeInfoWithStorage[127.0.0.1:40229,DS-5d3b509c-9946-4048-98ce-e12e9acf1d22,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-a72e3837-b950-4a50-adee-233ff0d601be,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-83d97b82-0f45-4a0f-83ef-b726959ae563,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-85749adf-6f74-4d6e-9994-be2d11c45482,DISK], DatanodeInfoWithStorage[127.0.0.1:34545,DS-dc27f5f6-1504-4dba-ac69-4fc220e391b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-7ae7a72b-a020-4728-bc50-3b1e6179ad44,DISK], DatanodeInfoWithStorage[127.0.0.1:45889,DS-00dd14ad-d235-480d-b0d2-25f496e64fd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 65536
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1641538730-172.17.0.15-1595560978563:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33024,DS-bc960fcd-d47c-4a45-836c-74d340e18c74,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-cb18aac5-546b-45eb-b6d8-8fa335b86da9,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-4cf45930-fb9e-4c92-88dc-ee832bd52485,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-5cf01587-9230-420c-9cf5-12761d7175bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-26845e75-c5ec-47a1-9a28-96e0243bde42,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-da79a560-5a05-4201-a63c-408797d99d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-d1ac02cf-8e2f-4238-8dd8-127fa5520db0,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-117a08bb-af6a-44b8-8074-bf09dede4c18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1641538730-172.17.0.15-1595560978563:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33024,DS-bc960fcd-d47c-4a45-836c-74d340e18c74,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-cb18aac5-546b-45eb-b6d8-8fa335b86da9,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-4cf45930-fb9e-4c92-88dc-ee832bd52485,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-5cf01587-9230-420c-9cf5-12761d7175bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-26845e75-c5ec-47a1-9a28-96e0243bde42,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-da79a560-5a05-4201-a63c-408797d99d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-d1ac02cf-8e2f-4238-8dd8-127fa5520db0,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-117a08bb-af6a-44b8-8074-bf09dede4c18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 65536
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1812221139-172.17.0.15-1595561221010:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39870,DS-8bc25912-e29c-4e31-9290-214077ec9690,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-7aed0e96-df2d-4a67-9643-ea3fae7f12dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-805c6274-cfdd-46a0-af16-b9cf14b8e812,DISK], DatanodeInfoWithStorage[127.0.0.1:33541,DS-65924521-712e-4e9d-b527-81a33842d82b,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-80c7c598-22f1-4645-90bd-78e6dd665363,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-c49ef2c7-1ede-4138-a7b1-6d6230caa26f,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-de843d7d-1353-40ac-8152-9827f601935a,DISK], DatanodeInfoWithStorage[127.0.0.1:43881,DS-3194098c-2d08-4203-a04f-e7df99452fe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1812221139-172.17.0.15-1595561221010:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39870,DS-8bc25912-e29c-4e31-9290-214077ec9690,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-7aed0e96-df2d-4a67-9643-ea3fae7f12dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-805c6274-cfdd-46a0-af16-b9cf14b8e812,DISK], DatanodeInfoWithStorage[127.0.0.1:33541,DS-65924521-712e-4e9d-b527-81a33842d82b,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-80c7c598-22f1-4645-90bd-78e6dd665363,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-c49ef2c7-1ede-4138-a7b1-6d6230caa26f,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-de843d7d-1353-40ac-8152-9827f601935a,DISK], DatanodeInfoWithStorage[127.0.0.1:43881,DS-3194098c-2d08-4203-a04f-e7df99452fe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 65536
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1759698567-172.17.0.15-1595561416148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33208,DS-7325aaa4-932b-498d-9e72-9a3a92add8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-f47650dd-454f-477e-b99d-05953dc4b152,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-d332f85e-a384-4a4f-8cef-669388c3d9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-d0405673-acc7-484b-8cc9-c0e24c731fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-09ff1fd8-1fca-4c1b-9a70-51911d8243cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-27c4fc5a-a30d-40b0-9ce2-f979c5f79975,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-13c657b5-05cc-48d5-92d9-70721284d66c,DISK], DatanodeInfoWithStorage[127.0.0.1:37268,DS-037f0042-5018-4653-9864-6adc66468bfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1759698567-172.17.0.15-1595561416148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33208,DS-7325aaa4-932b-498d-9e72-9a3a92add8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-f47650dd-454f-477e-b99d-05953dc4b152,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-d332f85e-a384-4a4f-8cef-669388c3d9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-d0405673-acc7-484b-8cc9-c0e24c731fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-09ff1fd8-1fca-4c1b-9a70-51911d8243cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-27c4fc5a-a30d-40b0-9ce2-f979c5f79975,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-13c657b5-05cc-48d5-92d9-70721284d66c,DISK], DatanodeInfoWithStorage[127.0.0.1:37268,DS-037f0042-5018-4653-9864-6adc66468bfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 65536
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-692494688-172.17.0.15-1595561730479:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38814,DS-d3539989-ca22-4515-86d4-f63461ad801c,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-1fec70eb-a778-4ac0-9422-d87126db0f93,DISK], DatanodeInfoWithStorage[127.0.0.1:42495,DS-650bd39c-e81b-4f22-ac37-6eefe5150719,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-28efe0d3-a6b7-4251-bb4f-0562463de452,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-c8fd3be6-c3a8-4c61-a34f-6dbd36021516,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-5a6fd0f5-a33a-43ca-9954-f544b129db0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-9242c28b-47a6-49b2-a3f4-175ef15d9cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-53684c28-3aff-4f48-88fb-012b8a31ba5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-692494688-172.17.0.15-1595561730479:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38814,DS-d3539989-ca22-4515-86d4-f63461ad801c,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-1fec70eb-a778-4ac0-9422-d87126db0f93,DISK], DatanodeInfoWithStorage[127.0.0.1:42495,DS-650bd39c-e81b-4f22-ac37-6eefe5150719,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-28efe0d3-a6b7-4251-bb4f-0562463de452,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-c8fd3be6-c3a8-4c61-a34f-6dbd36021516,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-5a6fd0f5-a33a-43ca-9954-f544b129db0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-9242c28b-47a6-49b2-a3f4-175ef15d9cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-53684c28-3aff-4f48-88fb-012b8a31ba5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 65536
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1610146808-172.17.0.15-1595562218297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46829,DS-0ce417a0-4067-4418-89df-6a2e8bd67900,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-219ca3be-69df-4776-a83f-75e865a1af80,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-d2ee060a-efe3-4f58-ab9b-cd1328467e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-5854c6ec-e763-4f25-9785-6171caaf875e,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-0ad1934d-cc71-42ee-8206-9bc3f8916e82,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-d227102f-9bce-4e37-b667-4811c9a99574,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-2b2b7ad1-73fe-4e8a-b1b6-5760a532621c,DISK], DatanodeInfoWithStorage[127.0.0.1:44224,DS-ec4fef71-54a6-4cfd-9deb-3f4ca4d6c7d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1610146808-172.17.0.15-1595562218297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46829,DS-0ce417a0-4067-4418-89df-6a2e8bd67900,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-219ca3be-69df-4776-a83f-75e865a1af80,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-d2ee060a-efe3-4f58-ab9b-cd1328467e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-5854c6ec-e763-4f25-9785-6171caaf875e,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-0ad1934d-cc71-42ee-8206-9bc3f8916e82,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-d227102f-9bce-4e37-b667-4811c9a99574,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-2b2b7ad1-73fe-4e8a-b1b6-5760a532621c,DISK], DatanodeInfoWithStorage[127.0.0.1:44224,DS-ec4fef71-54a6-4cfd-9deb-3f4ca4d6c7d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 65536
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1777539550-172.17.0.15-1595562820045:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43231,DS-efbd9237-726e-4c7b-b11f-8ccd1903fef7,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-c6eab563-0ea6-4a3c-8fae-d57c4a285abf,DISK], DatanodeInfoWithStorage[127.0.0.1:36112,DS-ba712c7f-60fd-4c87-b545-92a007442178,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-073b8e23-f823-4d8e-8429-797d8cdd0f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-5ee79947-87fe-4534-be34-3f6f8f353cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-36d5535b-6f7b-47f5-9ba0-4ab1545b2079,DISK], DatanodeInfoWithStorage[127.0.0.1:43370,DS-e6c3c29b-aedc-4c1c-b290-4c61f1a232f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-6e5d38a4-adb6-4c6d-96f8-b05140785365,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1777539550-172.17.0.15-1595562820045:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43231,DS-efbd9237-726e-4c7b-b11f-8ccd1903fef7,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-c6eab563-0ea6-4a3c-8fae-d57c4a285abf,DISK], DatanodeInfoWithStorage[127.0.0.1:36112,DS-ba712c7f-60fd-4c87-b545-92a007442178,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-073b8e23-f823-4d8e-8429-797d8cdd0f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-5ee79947-87fe-4534-be34-3f6f8f353cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-36d5535b-6f7b-47f5-9ba0-4ab1545b2079,DISK], DatanodeInfoWithStorage[127.0.0.1:43370,DS-e6c3c29b-aedc-4c1c-b290-4c61f1a232f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-6e5d38a4-adb6-4c6d-96f8-b05140785365,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: false positive !!!
Total execution time in seconds : 7216
