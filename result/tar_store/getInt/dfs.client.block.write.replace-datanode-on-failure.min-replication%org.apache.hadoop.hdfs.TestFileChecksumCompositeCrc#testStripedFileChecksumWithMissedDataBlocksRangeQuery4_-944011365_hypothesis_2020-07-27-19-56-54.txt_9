reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483257360-172.17.0.21-1595879916304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35779,DS-a965b9e7-586c-4b36-887b-fcefbbef9e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-6c14a9e9-a43f-49ca-bad7-80a5c96a093f,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-2ad92687-9cc3-49e2-adad-bd230639332c,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-08fbf0d6-3447-4551-a6bb-ad8b0ab7a257,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-72a95c69-69c2-4c17-956b-3f0d9714f6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-3ab59026-a754-44e1-829c-9eb629c60719,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-e2894fd8-d620-481d-976d-a71fae39d37b,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-d213743f-4c5f-4ac0-8231-4ac25d020f1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483257360-172.17.0.21-1595879916304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35779,DS-a965b9e7-586c-4b36-887b-fcefbbef9e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-6c14a9e9-a43f-49ca-bad7-80a5c96a093f,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-2ad92687-9cc3-49e2-adad-bd230639332c,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-08fbf0d6-3447-4551-a6bb-ad8b0ab7a257,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-72a95c69-69c2-4c17-956b-3f0d9714f6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-3ab59026-a754-44e1-829c-9eb629c60719,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-e2894fd8-d620-481d-976d-a71fae39d37b,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-d213743f-4c5f-4ac0-8231-4ac25d020f1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1601838885-172.17.0.21-1595879951416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34387,DS-8f6c61ff-8c58-4c99-b1dc-9d1b7cf4b0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-e7c8310e-6b1d-4060-b44e-924a3944b806,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-67ccdbeb-5b0b-4e17-9503-1f67c28c51df,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-9add547e-60f4-4cf7-a5a3-662c408616ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-3b48c635-e421-4293-8c5e-a0c729cb9671,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-9da7c674-25ea-4746-abc4-d9d4bbfa32c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-e83e039b-eb0c-4261-ae63-e3135bff6163,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-e6f86252-ecf3-4c80-924a-c5d20d8b6e1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1601838885-172.17.0.21-1595879951416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34387,DS-8f6c61ff-8c58-4c99-b1dc-9d1b7cf4b0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-e7c8310e-6b1d-4060-b44e-924a3944b806,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-67ccdbeb-5b0b-4e17-9503-1f67c28c51df,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-9add547e-60f4-4cf7-a5a3-662c408616ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-3b48c635-e421-4293-8c5e-a0c729cb9671,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-9da7c674-25ea-4746-abc4-d9d4bbfa32c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-e83e039b-eb0c-4261-ae63-e3135bff6163,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-e6f86252-ecf3-4c80-924a-c5d20d8b6e1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1204345927-172.17.0.21-1595880094442:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34665,DS-ea9ca008-a6a1-4237-b8ec-b082d32d1baa,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-9c261ae2-30a7-4e25-a539-1290bc257125,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-83a53c26-050e-4bab-b6c9-6da0acf2457b,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-0cc92df7-7618-4188-96ad-319d91e11918,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-f7e682dd-585f-4246-9416-a2d30d610b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-7302f280-2046-4075-8bf4-a8a98c9f363b,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-24f73422-df37-4c52-940c-7e72dc6fe6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38200,DS-8d3edc4c-e74c-4420-b608-ac246a14cdda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1204345927-172.17.0.21-1595880094442:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34665,DS-ea9ca008-a6a1-4237-b8ec-b082d32d1baa,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-9c261ae2-30a7-4e25-a539-1290bc257125,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-83a53c26-050e-4bab-b6c9-6da0acf2457b,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-0cc92df7-7618-4188-96ad-319d91e11918,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-f7e682dd-585f-4246-9416-a2d30d610b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-7302f280-2046-4075-8bf4-a8a98c9f363b,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-24f73422-df37-4c52-940c-7e72dc6fe6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38200,DS-8d3edc4c-e74c-4420-b608-ac246a14cdda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1064264514-172.17.0.21-1595883259327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46750,DS-eefff08d-188a-4e54-8b1e-470386b40e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-161495e1-28b2-4d0a-a7ff-21c543336373,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-91897acf-f2c4-4b11-b36e-4f803e6fe6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-e0dc55cd-2178-4aea-916e-c969c06fed77,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-73f772c1-420d-41d2-93b7-93762bcd3135,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-e8fed9c9-d3e7-4fd5-8da5-cd4740d6ecad,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-776c9ad3-da4e-43e2-a80b-cffb9c3c6402,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-0c0ba733-bb61-4faa-b477-fc4f310ffb01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1064264514-172.17.0.21-1595883259327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46750,DS-eefff08d-188a-4e54-8b1e-470386b40e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-161495e1-28b2-4d0a-a7ff-21c543336373,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-91897acf-f2c4-4b11-b36e-4f803e6fe6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-e0dc55cd-2178-4aea-916e-c969c06fed77,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-73f772c1-420d-41d2-93b7-93762bcd3135,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-e8fed9c9-d3e7-4fd5-8da5-cd4740d6ecad,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-776c9ad3-da4e-43e2-a80b-cffb9c3c6402,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-0c0ba733-bb61-4faa-b477-fc4f310ffb01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2069704758-172.17.0.21-1595883859863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35184,DS-7dad1983-e776-40b4-ae90-9205c62f9993,DISK], DatanodeInfoWithStorage[127.0.0.1:40038,DS-1ff1cc00-9513-4880-b388-cb32bcca75bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-287d7655-7e2d-429d-8864-f6ecc47340ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43098,DS-f4626248-85f7-436c-b1f0-0ff3ae776d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45984,DS-67d3a78a-7602-4800-9747-a8294ef1b0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-80a6cb5f-5f1c-46db-aa89-c12a0755540a,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-7cfc732f-12bf-4303-a187-8138896a86f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-ea817d7b-d3fe-44b3-b7c6-a5677635cdeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2069704758-172.17.0.21-1595883859863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35184,DS-7dad1983-e776-40b4-ae90-9205c62f9993,DISK], DatanodeInfoWithStorage[127.0.0.1:40038,DS-1ff1cc00-9513-4880-b388-cb32bcca75bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-287d7655-7e2d-429d-8864-f6ecc47340ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43098,DS-f4626248-85f7-436c-b1f0-0ff3ae776d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45984,DS-67d3a78a-7602-4800-9747-a8294ef1b0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-80a6cb5f-5f1c-46db-aa89-c12a0755540a,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-7cfc732f-12bf-4303-a187-8138896a86f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-ea817d7b-d3fe-44b3-b7c6-a5677635cdeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1926884218-172.17.0.21-1595884840982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34235,DS-b27b96d9-bedb-4bb9-a195-9494a957dcee,DISK], DatanodeInfoWithStorage[127.0.0.1:38289,DS-dd32389f-8e6a-4504-8976-802771b4035c,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-14a78bb3-20d9-4714-b6eb-3ffd5de716fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46268,DS-701df916-0dc2-4ee7-a994-8bb3eb04e15d,DISK], DatanodeInfoWithStorage[127.0.0.1:34424,DS-8a6376ff-20f6-460a-b80e-d97fb6a55f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-4bbf1305-3059-4cac-b624-0bb323741df9,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-bd7d59ed-5075-4531-b563-5ec7061b604d,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-e4d1c380-6009-4b0b-aaaf-e8132b75f662,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1926884218-172.17.0.21-1595884840982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34235,DS-b27b96d9-bedb-4bb9-a195-9494a957dcee,DISK], DatanodeInfoWithStorage[127.0.0.1:38289,DS-dd32389f-8e6a-4504-8976-802771b4035c,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-14a78bb3-20d9-4714-b6eb-3ffd5de716fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46268,DS-701df916-0dc2-4ee7-a994-8bb3eb04e15d,DISK], DatanodeInfoWithStorage[127.0.0.1:34424,DS-8a6376ff-20f6-460a-b80e-d97fb6a55f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-4bbf1305-3059-4cac-b624-0bb323741df9,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-bd7d59ed-5075-4531-b563-5ec7061b604d,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-e4d1c380-6009-4b0b-aaaf-e8132b75f662,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-888851989-172.17.0.21-1595885218576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38247,DS-6138292e-cfe1-48ab-b6d1-b1632e7c902a,DISK], DatanodeInfoWithStorage[127.0.0.1:46838,DS-19c6f1a3-ed36-4781-9493-8b5accc8c031,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-a736e44e-69cf-4f35-b919-56ff10442484,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-0cf29848-66ca-4c84-93ea-ed553ff52465,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-2d5978ab-f55e-4609-aa39-dbcc35c925f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-569bf3c1-50f6-471b-88e3-20383c284be5,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-b72af526-f8ea-4766-b810-65c0602e9099,DISK], DatanodeInfoWithStorage[127.0.0.1:37515,DS-2283272e-ffe4-4f0d-ab84-e83cc1fe380c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-888851989-172.17.0.21-1595885218576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38247,DS-6138292e-cfe1-48ab-b6d1-b1632e7c902a,DISK], DatanodeInfoWithStorage[127.0.0.1:46838,DS-19c6f1a3-ed36-4781-9493-8b5accc8c031,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-a736e44e-69cf-4f35-b919-56ff10442484,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-0cf29848-66ca-4c84-93ea-ed553ff52465,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-2d5978ab-f55e-4609-aa39-dbcc35c925f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-569bf3c1-50f6-471b-88e3-20383c284be5,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-b72af526-f8ea-4766-b810-65c0602e9099,DISK], DatanodeInfoWithStorage[127.0.0.1:37515,DS-2283272e-ffe4-4f0d-ab84-e83cc1fe380c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-979118231-172.17.0.21-1595885289932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35572,DS-64eb2c95-f62f-485d-bd3d-a1997c9f006d,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-4705e0f1-1838-4a21-9abc-2c7ac3726403,DISK], DatanodeInfoWithStorage[127.0.0.1:37487,DS-cc5d0366-1444-4dc9-be57-e3a286326c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-33ab74b3-625a-4e53-9e4f-c9781ffebb48,DISK], DatanodeInfoWithStorage[127.0.0.1:39874,DS-e9448019-e968-4a65-996a-cb1ff41412a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-13224520-a30b-4683-a353-5304e04049fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38377,DS-7389fcad-996e-4ec9-9d9a-26601e0ed0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41292,DS-4ee12e4e-1f11-4a9f-bcd4-1f5d17523a60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-979118231-172.17.0.21-1595885289932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35572,DS-64eb2c95-f62f-485d-bd3d-a1997c9f006d,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-4705e0f1-1838-4a21-9abc-2c7ac3726403,DISK], DatanodeInfoWithStorage[127.0.0.1:37487,DS-cc5d0366-1444-4dc9-be57-e3a286326c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-33ab74b3-625a-4e53-9e4f-c9781ffebb48,DISK], DatanodeInfoWithStorage[127.0.0.1:39874,DS-e9448019-e968-4a65-996a-cb1ff41412a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-13224520-a30b-4683-a353-5304e04049fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38377,DS-7389fcad-996e-4ec9-9d9a-26601e0ed0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41292,DS-4ee12e4e-1f11-4a9f-bcd4-1f5d17523a60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5493
