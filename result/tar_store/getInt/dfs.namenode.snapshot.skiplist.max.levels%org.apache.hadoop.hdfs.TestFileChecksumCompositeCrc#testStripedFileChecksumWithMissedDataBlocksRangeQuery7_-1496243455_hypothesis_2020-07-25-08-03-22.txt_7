reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1045805597-172.17.0.13-1595664500100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42690,DS-ad027ef5-410a-49a2-827d-4ad47b3bcb71,DISK], DatanodeInfoWithStorage[127.0.0.1:36147,DS-639054d9-39bd-4072-885d-d0b37d4ca83e,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-602aa3d6-a5a4-4057-a135-3625c371fb6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-f45766ff-ba9a-40f9-ba98-d013d4f7e028,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-091d158c-bef8-4648-998b-85b033ad86cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-51f8ce4a-4eae-4622-8655-22a7aa9a9b62,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-0928541d-ecb7-4c8b-818d-2433fb5e8fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-4b545946-d995-4e02-a508-49c91c68b915,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1045805597-172.17.0.13-1595664500100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42690,DS-ad027ef5-410a-49a2-827d-4ad47b3bcb71,DISK], DatanodeInfoWithStorage[127.0.0.1:36147,DS-639054d9-39bd-4072-885d-d0b37d4ca83e,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-602aa3d6-a5a4-4057-a135-3625c371fb6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-f45766ff-ba9a-40f9-ba98-d013d4f7e028,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-091d158c-bef8-4648-998b-85b033ad86cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-51f8ce4a-4eae-4622-8655-22a7aa9a9b62,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-0928541d-ecb7-4c8b-818d-2433fb5e8fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-4b545946-d995-4e02-a508-49c91c68b915,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-823596228-172.17.0.13-1595664677140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44064,DS-997e3e47-bbd8-41f4-a8c5-0488fd1200ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-ce911fd7-fd5f-45d3-a8ef-e9303198c00b,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-d61de122-920f-478d-bf56-3cab68789165,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-eb6ce2f4-dec8-4d61-a883-6170c3ffbb04,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-98ba8b38-e772-4496-8608-87aed7475c76,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-554f0e2f-1c55-44f6-806f-adfac9a97776,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-f6bce14d-95be-4fc9-9da1-924ce96b135d,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-b582851c-ede7-4ab3-94db-3881e807c165,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-823596228-172.17.0.13-1595664677140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44064,DS-997e3e47-bbd8-41f4-a8c5-0488fd1200ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-ce911fd7-fd5f-45d3-a8ef-e9303198c00b,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-d61de122-920f-478d-bf56-3cab68789165,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-eb6ce2f4-dec8-4d61-a883-6170c3ffbb04,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-98ba8b38-e772-4496-8608-87aed7475c76,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-554f0e2f-1c55-44f6-806f-adfac9a97776,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-f6bce14d-95be-4fc9-9da1-924ce96b135d,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-b582851c-ede7-4ab3-94db-3881e807c165,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2128783676-172.17.0.13-1595664896849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46737,DS-052e4588-0bd5-4ce8-91f9-0a0095139590,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-fa47bf83-03b1-451a-9975-6da81f1d3dad,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-d9373043-a502-4480-81e4-725957d0a71a,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-86db9ac4-7c21-4c17-bf46-d5ec840a627a,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-b6685b2f-860d-454f-b108-1e4aaa3f79ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-a3cf96f9-c72b-4038-8f57-5ebb50adda45,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-7c52b42a-4b37-492a-aa88-350ecadbc8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-d66277ea-23e2-4e60-9dfe-bd5524937bf3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2128783676-172.17.0.13-1595664896849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46737,DS-052e4588-0bd5-4ce8-91f9-0a0095139590,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-fa47bf83-03b1-451a-9975-6da81f1d3dad,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-d9373043-a502-4480-81e4-725957d0a71a,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-86db9ac4-7c21-4c17-bf46-d5ec840a627a,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-b6685b2f-860d-454f-b108-1e4aaa3f79ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-a3cf96f9-c72b-4038-8f57-5ebb50adda45,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-7c52b42a-4b37-492a-aa88-350ecadbc8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-d66277ea-23e2-4e60-9dfe-bd5524937bf3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-474674-172.17.0.13-1595664938471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41111,DS-80b021fd-ae45-4997-a41b-11ae6a9344de,DISK], DatanodeInfoWithStorage[127.0.0.1:40548,DS-31920411-113d-4d22-9e1c-39dbd97c5377,DISK], DatanodeInfoWithStorage[127.0.0.1:45431,DS-5421b2d8-9999-41c0-b960-a6fb0fcd3754,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-51594b84-9f67-4dbd-8362-5f2062b5f85e,DISK], DatanodeInfoWithStorage[127.0.0.1:46602,DS-5b443294-79d6-4e6b-ae79-8ad4c38c5b29,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-572f9052-d901-4f28-b8b9-dabb516a50a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-9a649d8c-d27e-43b6-b335-cc03753c6cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-0326f715-e59a-4b64-8f6a-655ce34070f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-474674-172.17.0.13-1595664938471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41111,DS-80b021fd-ae45-4997-a41b-11ae6a9344de,DISK], DatanodeInfoWithStorage[127.0.0.1:40548,DS-31920411-113d-4d22-9e1c-39dbd97c5377,DISK], DatanodeInfoWithStorage[127.0.0.1:45431,DS-5421b2d8-9999-41c0-b960-a6fb0fcd3754,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-51594b84-9f67-4dbd-8362-5f2062b5f85e,DISK], DatanodeInfoWithStorage[127.0.0.1:46602,DS-5b443294-79d6-4e6b-ae79-8ad4c38c5b29,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-572f9052-d901-4f28-b8b9-dabb516a50a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-9a649d8c-d27e-43b6-b335-cc03753c6cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-0326f715-e59a-4b64-8f6a-655ce34070f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-272527656-172.17.0.13-1595664981282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44935,DS-1acca48d-90dd-4926-9ed1-85dc0b49b570,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-527b9d64-a9d9-498e-9620-1463a5049407,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-6b1aa351-11a9-4825-bcf8-5574bfc8c0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-5574932b-a729-4ead-abb5-9ce5a005f2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-8f28d721-44d3-41f6-8264-d290cd7764c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-cce0f651-0e82-45ea-bc33-676a5d6718a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36944,DS-db09c537-b3f5-4291-b34d-3211e63e2e11,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-1e90ba13-5f57-4e91-a44b-314e9b10c5ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-272527656-172.17.0.13-1595664981282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44935,DS-1acca48d-90dd-4926-9ed1-85dc0b49b570,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-527b9d64-a9d9-498e-9620-1463a5049407,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-6b1aa351-11a9-4825-bcf8-5574bfc8c0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-5574932b-a729-4ead-abb5-9ce5a005f2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-8f28d721-44d3-41f6-8264-d290cd7764c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-cce0f651-0e82-45ea-bc33-676a5d6718a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36944,DS-db09c537-b3f5-4291-b34d-3211e63e2e11,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-1e90ba13-5f57-4e91-a44b-314e9b10c5ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-486217400-172.17.0.13-1595665020042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38321,DS-f284c71f-908d-441e-92d7-3abeeb2cad74,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-33091de4-c7ca-4e0d-902f-80c401e5fb82,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-8f44d8d9-66d7-4cfe-afc4-ba1371301786,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-54c7dc17-d2fb-4c42-a799-ad8e8dfba8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-9242718e-13a6-4d57-b15f-e24fa48408ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-1085eb57-a414-44dd-b2c3-7b558f857a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-76e54a50-d685-48ac-a686-2ae2a26d1575,DISK], DatanodeInfoWithStorage[127.0.0.1:38584,DS-3a4f3932-dfd0-4056-a202-250dc47fc026,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-486217400-172.17.0.13-1595665020042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38321,DS-f284c71f-908d-441e-92d7-3abeeb2cad74,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-33091de4-c7ca-4e0d-902f-80c401e5fb82,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-8f44d8d9-66d7-4cfe-afc4-ba1371301786,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-54c7dc17-d2fb-4c42-a799-ad8e8dfba8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-9242718e-13a6-4d57-b15f-e24fa48408ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-1085eb57-a414-44dd-b2c3-7b558f857a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-76e54a50-d685-48ac-a686-2ae2a26d1575,DISK], DatanodeInfoWithStorage[127.0.0.1:38584,DS-3a4f3932-dfd0-4056-a202-250dc47fc026,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2056831387-172.17.0.13-1595665090783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35884,DS-0f940714-9d86-4951-8c68-c5678047088a,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-3080b379-f805-4dad-869a-42d7b2e6c1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-57f2b5b0-9160-4e71-aad8-fa5fae6b4f89,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-40a72cbb-8a18-4e3a-9a3e-ec5159b5d99c,DISK], DatanodeInfoWithStorage[127.0.0.1:35052,DS-f0ed2556-03e0-4131-ae90-c9df55f9bd17,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-e31b9d30-5cf9-425b-87a2-18d21bb014b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-4cdfee55-28db-420b-9ff9-86c2ddcc9ede,DISK], DatanodeInfoWithStorage[127.0.0.1:45419,DS-94f1038b-664d-4a4e-a85e-6dd1126f16dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2056831387-172.17.0.13-1595665090783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35884,DS-0f940714-9d86-4951-8c68-c5678047088a,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-3080b379-f805-4dad-869a-42d7b2e6c1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-57f2b5b0-9160-4e71-aad8-fa5fae6b4f89,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-40a72cbb-8a18-4e3a-9a3e-ec5159b5d99c,DISK], DatanodeInfoWithStorage[127.0.0.1:35052,DS-f0ed2556-03e0-4131-ae90-c9df55f9bd17,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-e31b9d30-5cf9-425b-87a2-18d21bb014b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-4cdfee55-28db-420b-9ff9-86c2ddcc9ede,DISK], DatanodeInfoWithStorage[127.0.0.1:45419,DS-94f1038b-664d-4a4e-a85e-6dd1126f16dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1518832177-172.17.0.13-1595665586713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45683,DS-7ad794e1-6c7f-488c-966d-9ccf360fd98a,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-b906a6ab-ad27-4b88-87df-cf6b80bffabc,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-249f0cca-8188-4c2a-b1a0-8f31214f223a,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-e4432cc2-6fdc-4cf2-8155-86d45f07a371,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-796b9b56-3675-462a-8937-eac1559bf9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35627,DS-75b441d4-00d5-42d6-9af8-f5c58939e1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-7c19be26-d66a-4fe4-b1c1-5bf81101043f,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-9fca88c1-8395-4521-8911-a7d318177f1d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1518832177-172.17.0.13-1595665586713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45683,DS-7ad794e1-6c7f-488c-966d-9ccf360fd98a,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-b906a6ab-ad27-4b88-87df-cf6b80bffabc,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-249f0cca-8188-4c2a-b1a0-8f31214f223a,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-e4432cc2-6fdc-4cf2-8155-86d45f07a371,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-796b9b56-3675-462a-8937-eac1559bf9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35627,DS-75b441d4-00d5-42d6-9af8-f5c58939e1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-7c19be26-d66a-4fe4-b1c1-5bf81101043f,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-9fca88c1-8395-4521-8911-a7d318177f1d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-735742021-172.17.0.13-1595665769044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41154,DS-be5d47c9-73fd-4e22-9677-7a9bf896aeac,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-316e43f2-4d29-4950-af0f-6b3a251fd961,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-34740e67-7d90-44e5-9420-6ae42a4523a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33301,DS-185a43d8-82a3-41c0-b645-086c6871a2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-d3936dbf-1507-46b8-b93f-ce78313e7896,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-80b190a4-4656-463a-8ad1-80718c7a6978,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-7bdd6455-957e-4c5d-b445-16d2601faa4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-87375b5e-3b64-4aa4-a967-ea2520b6592a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-735742021-172.17.0.13-1595665769044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41154,DS-be5d47c9-73fd-4e22-9677-7a9bf896aeac,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-316e43f2-4d29-4950-af0f-6b3a251fd961,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-34740e67-7d90-44e5-9420-6ae42a4523a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33301,DS-185a43d8-82a3-41c0-b645-086c6871a2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-d3936dbf-1507-46b8-b93f-ce78313e7896,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-80b190a4-4656-463a-8ad1-80718c7a6978,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-7bdd6455-957e-4c5d-b445-16d2601faa4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-87375b5e-3b64-4aa4-a967-ea2520b6592a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-421271072-172.17.0.13-1595665879959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34167,DS-3b31a6fc-d128-4479-98e2-f85847bdfb79,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-3e8e6dc0-9600-4274-93c5-12370c65ce50,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-f3c964e5-7190-4b85-96b0-b2237a5b862c,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-ef8b18b3-1775-4f4a-8799-abf72b6b5f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-13b6e5e4-61d0-468b-a0e5-a6f02c2820b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-cccfb341-d381-473e-9593-364cf2dd3b28,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-f80d3038-a496-4ec5-97aa-9d4ad5f63bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-0c14469f-4009-4857-b19c-e779851cda83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-421271072-172.17.0.13-1595665879959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34167,DS-3b31a6fc-d128-4479-98e2-f85847bdfb79,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-3e8e6dc0-9600-4274-93c5-12370c65ce50,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-f3c964e5-7190-4b85-96b0-b2237a5b862c,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-ef8b18b3-1775-4f4a-8799-abf72b6b5f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-13b6e5e4-61d0-468b-a0e5-a6f02c2820b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-cccfb341-d381-473e-9593-364cf2dd3b28,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-f80d3038-a496-4ec5-97aa-9d4ad5f63bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-0c14469f-4009-4857-b19c-e779851cda83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1339940428-172.17.0.13-1595665918610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33351,DS-7e32f053-47a2-4a11-9a27-6263414a3013,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-c81722eb-0a38-4cd3-b83d-27900b806933,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-51c68acf-b588-46fc-b482-fe477fa9b87f,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-d5110dba-8a23-4d0a-85dd-f61bf5ed7e80,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-3a360b6f-c8ca-42b1-89af-982c6531ac7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-8a646207-74a6-4635-a4be-13c051de9d27,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-308b2d3f-c287-4b21-a503-0a4aa1b0807a,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-13f91f83-5ddc-4353-860a-63e7e0c42d90,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1339940428-172.17.0.13-1595665918610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33351,DS-7e32f053-47a2-4a11-9a27-6263414a3013,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-c81722eb-0a38-4cd3-b83d-27900b806933,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-51c68acf-b588-46fc-b482-fe477fa9b87f,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-d5110dba-8a23-4d0a-85dd-f61bf5ed7e80,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-3a360b6f-c8ca-42b1-89af-982c6531ac7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-8a646207-74a6-4635-a4be-13c051de9d27,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-308b2d3f-c287-4b21-a503-0a4aa1b0807a,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-13f91f83-5ddc-4353-860a-63e7e0c42d90,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1260661756-172.17.0.13-1595665999908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44638,DS-ba3490dc-4d99-4fd9-911f-e5e6bca6b01d,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-53709f63-a6fa-4168-8332-91c0f3f08a69,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-59c2528a-54b1-4b39-975d-bdea2350e8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-4000acf0-59bd-4e4b-879f-c5483cadd45c,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-925e9c18-64fa-4097-93f5-c3774861d612,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-94e153a1-9295-460e-b05b-1a88752d81bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37458,DS-f3a607e8-ebc9-4f1f-86e2-f4184986ba5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-6545972e-b8b0-4b8b-acbd-04dd0cb00f13,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1260661756-172.17.0.13-1595665999908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44638,DS-ba3490dc-4d99-4fd9-911f-e5e6bca6b01d,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-53709f63-a6fa-4168-8332-91c0f3f08a69,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-59c2528a-54b1-4b39-975d-bdea2350e8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-4000acf0-59bd-4e4b-879f-c5483cadd45c,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-925e9c18-64fa-4097-93f5-c3774861d612,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-94e153a1-9295-460e-b05b-1a88752d81bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37458,DS-f3a607e8-ebc9-4f1f-86e2-f4184986ba5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-6545972e-b8b0-4b8b-acbd-04dd0cb00f13,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-699744406-172.17.0.13-1595666183320:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37579,DS-a2f2f054-708f-42a3-84ac-ec6b8d88ac80,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-969a3fc9-5055-4b2f-a224-57555016ff5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-b0884da1-b56d-4f7a-8fc7-8de32c40e652,DISK], DatanodeInfoWithStorage[127.0.0.1:34302,DS-957891db-6288-4bdb-9486-44054406955a,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-e61bb218-02aa-494b-ad8d-ff977e3c8fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-21efc64c-8509-4f99-85bd-7b9071c95027,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-f40fa362-f066-43cd-bc0c-94d2768ee1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46216,DS-b20834ec-dd4a-477f-b5ec-4f32cb2c1f25,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-699744406-172.17.0.13-1595666183320:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37579,DS-a2f2f054-708f-42a3-84ac-ec6b8d88ac80,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-969a3fc9-5055-4b2f-a224-57555016ff5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-b0884da1-b56d-4f7a-8fc7-8de32c40e652,DISK], DatanodeInfoWithStorage[127.0.0.1:34302,DS-957891db-6288-4bdb-9486-44054406955a,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-e61bb218-02aa-494b-ad8d-ff977e3c8fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-21efc64c-8509-4f99-85bd-7b9071c95027,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-f40fa362-f066-43cd-bc0c-94d2768ee1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46216,DS-b20834ec-dd4a-477f-b5ec-4f32cb2c1f25,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-384212933-172.17.0.13-1595666314962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45108,DS-c4ca76d5-1bdb-437d-9101-18d18bca230d,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-e01f917c-d5d0-48bd-852e-2b732a52ebd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-ec156e7f-1ab9-484f-ab05-8e51055a7eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:33574,DS-4f86c38e-6226-4c0a-94e3-43f7f9fae115,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-c1de5f42-82c2-43da-a214-2004e428c7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-614301aa-fd7d-4484-ac08-a3d52cd8a2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-7ca0f4da-eb79-4697-8121-067d8d186019,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-4e7c4d6d-af7a-45a5-a45a-94b855e2ea13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-384212933-172.17.0.13-1595666314962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45108,DS-c4ca76d5-1bdb-437d-9101-18d18bca230d,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-e01f917c-d5d0-48bd-852e-2b732a52ebd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-ec156e7f-1ab9-484f-ab05-8e51055a7eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:33574,DS-4f86c38e-6226-4c0a-94e3-43f7f9fae115,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-c1de5f42-82c2-43da-a214-2004e428c7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-614301aa-fd7d-4484-ac08-a3d52cd8a2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-7ca0f4da-eb79-4697-8121-067d8d186019,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-4e7c4d6d-af7a-45a5-a45a-94b855e2ea13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2128832329-172.17.0.13-1595666383607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42253,DS-e5d56b8a-3514-472f-b025-aa97c52e5414,DISK], DatanodeInfoWithStorage[127.0.0.1:33445,DS-f9b86518-0b58-42ae-8c18-9179f9f1b756,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-92531d8f-ec47-428d-9225-665e4ba2a829,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-521c5673-db5a-4619-a32b-a74c553e3240,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-89a31e48-c41c-4050-83e3-430f8739f1af,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-17cbf864-9a96-486f-b49e-729089185f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-681fb3bf-224e-42d5-9cee-c94fb849b9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-3d93e36f-4b15-4d18-ab8f-480781e94aa2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2128832329-172.17.0.13-1595666383607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42253,DS-e5d56b8a-3514-472f-b025-aa97c52e5414,DISK], DatanodeInfoWithStorage[127.0.0.1:33445,DS-f9b86518-0b58-42ae-8c18-9179f9f1b756,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-92531d8f-ec47-428d-9225-665e4ba2a829,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-521c5673-db5a-4619-a32b-a74c553e3240,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-89a31e48-c41c-4050-83e3-430f8739f1af,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-17cbf864-9a96-486f-b49e-729089185f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-681fb3bf-224e-42d5-9cee-c94fb849b9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-3d93e36f-4b15-4d18-ab8f-480781e94aa2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-305195085-172.17.0.13-1595666534775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44418,DS-60371f64-3a79-493b-8613-19c40d6fd8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-a4d0a6f5-7253-4156-88dc-87e0a7a2c5ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-56378171-de92-4c97-99d1-8a3c38f6eb74,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-859561a0-ac0a-4eb7-8374-1c0b393b3e66,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-56f8832a-f2da-42d2-abaf-a452c569bb20,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-7731d584-fa3c-4f06-91de-14a460db74cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-12a7d10a-36e2-4918-8bf5-9a3dd6d28298,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-b110cd63-2ade-446b-a64f-c0c32204c652,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-305195085-172.17.0.13-1595666534775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44418,DS-60371f64-3a79-493b-8613-19c40d6fd8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-a4d0a6f5-7253-4156-88dc-87e0a7a2c5ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-56378171-de92-4c97-99d1-8a3c38f6eb74,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-859561a0-ac0a-4eb7-8374-1c0b393b3e66,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-56f8832a-f2da-42d2-abaf-a452c569bb20,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-7731d584-fa3c-4f06-91de-14a460db74cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-12a7d10a-36e2-4918-8bf5-9a3dd6d28298,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-b110cd63-2ade-446b-a64f-c0c32204c652,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1307790879-172.17.0.13-1595666567052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46298,DS-c19dbb86-6a51-4ab3-bbe0-4e760db0a5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-abbdc1a2-92c5-4153-8dcf-5b95ac5aaec2,DISK], DatanodeInfoWithStorage[127.0.0.1:36945,DS-f141d08e-b91c-4844-877f-80a888771c17,DISK], DatanodeInfoWithStorage[127.0.0.1:40932,DS-d8823178-dfe0-4545-81c8-a5a8202f300f,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-aa7d1b00-2c39-4c40-88d7-47eaad12b192,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-e4b2a05f-acc1-4e09-bc07-3b6dd8a272df,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-8728a1f1-f93c-4f06-b875-d20d485d6d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-127c5e57-4b0f-4de2-bcce-d7f446d21821,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1307790879-172.17.0.13-1595666567052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46298,DS-c19dbb86-6a51-4ab3-bbe0-4e760db0a5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-abbdc1a2-92c5-4153-8dcf-5b95ac5aaec2,DISK], DatanodeInfoWithStorage[127.0.0.1:36945,DS-f141d08e-b91c-4844-877f-80a888771c17,DISK], DatanodeInfoWithStorage[127.0.0.1:40932,DS-d8823178-dfe0-4545-81c8-a5a8202f300f,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-aa7d1b00-2c39-4c40-88d7-47eaad12b192,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-e4b2a05f-acc1-4e09-bc07-3b6dd8a272df,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-8728a1f1-f93c-4f06-b875-d20d485d6d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-127c5e57-4b0f-4de2-bcce-d7f446d21821,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1842798988-172.17.0.13-1595666674678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32803,DS-7b91a1f9-86f1-46eb-a917-02e72a278c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-1b51e9c9-59a4-4ef9-9bed-1092596200bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-de2c6884-e127-4557-aa36-78dd5d8c8fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-8fbf6cc9-acb7-4e77-bee1-55789f32186f,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-5f895e7b-837b-4e43-abe2-bb2c97785f10,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-0d51af7e-1218-41d9-acd1-6cdb0bc3292e,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-9542182f-5208-4ce6-870e-19caf9915863,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-9801ec32-0a74-4459-b21b-1b21d3d11edd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1842798988-172.17.0.13-1595666674678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32803,DS-7b91a1f9-86f1-46eb-a917-02e72a278c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-1b51e9c9-59a4-4ef9-9bed-1092596200bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-de2c6884-e127-4557-aa36-78dd5d8c8fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-8fbf6cc9-acb7-4e77-bee1-55789f32186f,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-5f895e7b-837b-4e43-abe2-bb2c97785f10,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-0d51af7e-1218-41d9-acd1-6cdb0bc3292e,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-9542182f-5208-4ce6-870e-19caf9915863,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-9801ec32-0a74-4459-b21b-1b21d3d11edd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-893800334-172.17.0.13-1595666810313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33389,DS-e4473ba0-819e-4534-b8d9-8aaf127babb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39694,DS-eff6e38d-dc6e-414e-9050-5b385dc134cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-9605cabc-e234-4c34-8bdb-df6449a07bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-a0b62ffd-b9ae-483b-8f02-deb56974cec9,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-87b0abe9-a2f9-4d32-b769-24f89eb17bad,DISK], DatanodeInfoWithStorage[127.0.0.1:35557,DS-21e1719d-38e5-44a3-ae99-d3e17352b63a,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-6bf283cd-e160-4b38-9903-f94aeb242580,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-f954568e-ce10-4201-8d9a-9877f150aaff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-893800334-172.17.0.13-1595666810313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33389,DS-e4473ba0-819e-4534-b8d9-8aaf127babb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39694,DS-eff6e38d-dc6e-414e-9050-5b385dc134cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-9605cabc-e234-4c34-8bdb-df6449a07bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-a0b62ffd-b9ae-483b-8f02-deb56974cec9,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-87b0abe9-a2f9-4d32-b769-24f89eb17bad,DISK], DatanodeInfoWithStorage[127.0.0.1:35557,DS-21e1719d-38e5-44a3-ae99-d3e17352b63a,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-6bf283cd-e160-4b38-9903-f94aeb242580,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-f954568e-ce10-4201-8d9a-9877f150aaff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-430691570-172.17.0.13-1595667017988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35883,DS-ef503c78-a0dd-4515-810b-7a9489c22fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44405,DS-854f5a7d-9a1e-4b76-a945-445d6e61ef2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-5ad44454-fb9d-4dae-8217-560e70f57a48,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-79b86868-1ff1-4d7b-8c68-cf4d851171f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-40198bb9-d0ee-46eb-8b62-8581ccad80ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-cc76eed1-05c2-49d6-afae-0c9159b5f47c,DISK], DatanodeInfoWithStorage[127.0.0.1:40081,DS-85a4c90a-9806-44da-9ae6-bb966345db52,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-7409c706-d4df-464b-b341-38c66cd9066a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-430691570-172.17.0.13-1595667017988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35883,DS-ef503c78-a0dd-4515-810b-7a9489c22fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44405,DS-854f5a7d-9a1e-4b76-a945-445d6e61ef2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-5ad44454-fb9d-4dae-8217-560e70f57a48,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-79b86868-1ff1-4d7b-8c68-cf4d851171f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-40198bb9-d0ee-46eb-8b62-8581ccad80ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-cc76eed1-05c2-49d6-afae-0c9159b5f47c,DISK], DatanodeInfoWithStorage[127.0.0.1:40081,DS-85a4c90a-9806-44da-9ae6-bb966345db52,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-7409c706-d4df-464b-b341-38c66cd9066a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2052241853-172.17.0.13-1595667261174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45285,DS-614b2724-b766-462a-82e0-f461b8aef3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-a4afc417-ef30-449f-bfa2-87fc6d37965a,DISK], DatanodeInfoWithStorage[127.0.0.1:44838,DS-0d8ab2bd-0f62-4972-bb90-031a5a6f0c00,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-8b65b5b5-3e7b-4574-9aff-404261aaaa14,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-a2bc32fe-7de9-440d-aa27-a4303820a3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-332a3e13-7265-4b3c-bd97-7158c04f30c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-6831cd2b-faa0-4fc7-a707-4391c7b90b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-faf2ae02-bf4a-41db-a5da-ba2b2a2de0a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2052241853-172.17.0.13-1595667261174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45285,DS-614b2724-b766-462a-82e0-f461b8aef3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-a4afc417-ef30-449f-bfa2-87fc6d37965a,DISK], DatanodeInfoWithStorage[127.0.0.1:44838,DS-0d8ab2bd-0f62-4972-bb90-031a5a6f0c00,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-8b65b5b5-3e7b-4574-9aff-404261aaaa14,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-a2bc32fe-7de9-440d-aa27-a4303820a3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-332a3e13-7265-4b3c-bd97-7158c04f30c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-6831cd2b-faa0-4fc7-a707-4391c7b90b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-faf2ae02-bf4a-41db-a5da-ba2b2a2de0a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-419216434-172.17.0.13-1595667371802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33774,DS-37984c23-da42-4bf3-b263-c480416b8e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-dfb890ce-c700-474c-9252-790a00730118,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-c0a23854-8985-4213-a7e5-95074605c440,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-dc6f8c94-cc85-41cd-ae36-3864ee625b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-de59723f-15af-46ea-877c-39fe06bfe53b,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-7ab32ad6-dc12-48e6-9c03-4479a70e81f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36690,DS-58609a75-e2ef-4079-b0ba-c8f92001b55b,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-3cae60cf-6484-4c4c-b32d-06ce18a2646b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-419216434-172.17.0.13-1595667371802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33774,DS-37984c23-da42-4bf3-b263-c480416b8e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-dfb890ce-c700-474c-9252-790a00730118,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-c0a23854-8985-4213-a7e5-95074605c440,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-dc6f8c94-cc85-41cd-ae36-3864ee625b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-de59723f-15af-46ea-877c-39fe06bfe53b,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-7ab32ad6-dc12-48e6-9c03-4479a70e81f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36690,DS-58609a75-e2ef-4079-b0ba-c8f92001b55b,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-3cae60cf-6484-4c4c-b32d-06ce18a2646b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1723125285-172.17.0.13-1595667481746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42436,DS-43f2202f-e9eb-447f-a953-8ba9bf8d705e,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-9986c234-2038-47c0-9bfd-d2ff026a879c,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-a7c2a814-6905-4017-becb-51c9376faddf,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-29810474-773b-42d3-9e80-a7fa339f9f24,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-0a422ea0-2751-40f3-ac57-4a011419d475,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-b57efaa1-add0-4d58-867a-595b2844cd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-87ce6c0b-2e14-4692-8567-9255cf7f3c58,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-fd3fbc6f-8e69-4bb6-95fb-ffefb236053a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1723125285-172.17.0.13-1595667481746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42436,DS-43f2202f-e9eb-447f-a953-8ba9bf8d705e,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-9986c234-2038-47c0-9bfd-d2ff026a879c,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-a7c2a814-6905-4017-becb-51c9376faddf,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-29810474-773b-42d3-9e80-a7fa339f9f24,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-0a422ea0-2751-40f3-ac57-4a011419d475,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-b57efaa1-add0-4d58-867a-595b2844cd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-87ce6c0b-2e14-4692-8567-9255cf7f3c58,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-fd3fbc6f-8e69-4bb6-95fb-ffefb236053a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1880435145-172.17.0.13-1595667734230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46175,DS-12cc26b0-497d-42b1-8cb2-9a08e9b3272d,DISK], DatanodeInfoWithStorage[127.0.0.1:35875,DS-b94dd907-1371-44f1-a982-c7d03f02e0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-3e77eac9-1bae-4399-87cc-eee49a26ade7,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-6339595c-8173-4086-8051-26fd338283ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-f728d887-f1ca-4fe8-9bd5-2907abd22235,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-fcdda80e-b900-4f54-a386-db609d4f3306,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-ea785bc5-0613-4f24-9ed9-797dd983bb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37842,DS-e32cf491-76cb-4d02-81b3-f47c3287768c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1880435145-172.17.0.13-1595667734230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46175,DS-12cc26b0-497d-42b1-8cb2-9a08e9b3272d,DISK], DatanodeInfoWithStorage[127.0.0.1:35875,DS-b94dd907-1371-44f1-a982-c7d03f02e0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-3e77eac9-1bae-4399-87cc-eee49a26ade7,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-6339595c-8173-4086-8051-26fd338283ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-f728d887-f1ca-4fe8-9bd5-2907abd22235,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-fcdda80e-b900-4f54-a386-db609d4f3306,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-ea785bc5-0613-4f24-9ed9-797dd983bb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37842,DS-e32cf491-76cb-4d02-81b3-f47c3287768c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-954837956-172.17.0.13-1595667879850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38246,DS-057d08d0-7f7e-43de-ad7a-dff57ef97bad,DISK], DatanodeInfoWithStorage[127.0.0.1:35821,DS-4cf17832-0565-4d09-b47f-4c62d389a99a,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-08ef864c-7ede-49de-8f6f-8f620f171015,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-b1d29736-1f02-45ba-a16b-d02fe62f4443,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-13dbb21c-6d92-4f1c-849c-952b46bb36b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-17a219b8-65f5-4bfa-bfc9-baef55d9e79b,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-7115a55a-972e-4dc2-a7fd-928d03afd379,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-03a78c69-cc3b-42b7-9c3c-365fbdacd3df,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-954837956-172.17.0.13-1595667879850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38246,DS-057d08d0-7f7e-43de-ad7a-dff57ef97bad,DISK], DatanodeInfoWithStorage[127.0.0.1:35821,DS-4cf17832-0565-4d09-b47f-4c62d389a99a,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-08ef864c-7ede-49de-8f6f-8f620f171015,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-b1d29736-1f02-45ba-a16b-d02fe62f4443,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-13dbb21c-6d92-4f1c-849c-952b46bb36b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-17a219b8-65f5-4bfa-bfc9-baef55d9e79b,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-7115a55a-972e-4dc2-a7fd-928d03afd379,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-03a78c69-cc3b-42b7-9c3c-365fbdacd3df,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-588929270-172.17.0.13-1595667944654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42711,DS-fc1429ac-4c9a-4eb7-833d-3e3f9bf1058f,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-a807854d-2ff7-45c8-8a29-71736def40be,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-4c7dfa52-77d6-4faa-89ba-42ce26eef7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37284,DS-d8e6eb19-c30d-4994-9bf0-32786f1b3116,DISK], DatanodeInfoWithStorage[127.0.0.1:34765,DS-9566d4d3-4181-4c88-bbe3-4d1bc28dd2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-e50255f9-5698-4ac0-88ed-d68ac843f780,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-211570ae-ea71-44da-93d0-db931de2012a,DISK], DatanodeInfoWithStorage[127.0.0.1:39166,DS-a46f2a45-85a5-4bc8-b97a-14dfd2bdbb6c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-588929270-172.17.0.13-1595667944654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42711,DS-fc1429ac-4c9a-4eb7-833d-3e3f9bf1058f,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-a807854d-2ff7-45c8-8a29-71736def40be,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-4c7dfa52-77d6-4faa-89ba-42ce26eef7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37284,DS-d8e6eb19-c30d-4994-9bf0-32786f1b3116,DISK], DatanodeInfoWithStorage[127.0.0.1:34765,DS-9566d4d3-4181-4c88-bbe3-4d1bc28dd2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-e50255f9-5698-4ac0-88ed-d68ac843f780,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-211570ae-ea71-44da-93d0-db931de2012a,DISK], DatanodeInfoWithStorage[127.0.0.1:39166,DS-a46f2a45-85a5-4bc8-b97a-14dfd2bdbb6c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-740687630-172.17.0.13-1595668077571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44253,DS-23c5e66f-e454-421a-b3e6-3839c84b10a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-57235e31-499c-4fc4-80ff-559679c9debb,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-859b394d-d1b2-4f3a-88c0-176dd4e56ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-e090c654-36ad-4fd5-ac96-265f73fbca45,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-f60cb5bc-2a44-4ae1-b5be-956c78cad190,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-9750bea4-4e42-45a5-b309-7c10cbe9ac32,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-ca031daf-7241-40d6-b70f-0af0fc27163f,DISK], DatanodeInfoWithStorage[127.0.0.1:38246,DS-1a12010c-d190-4d2c-9726-e024e7e492a6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-740687630-172.17.0.13-1595668077571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44253,DS-23c5e66f-e454-421a-b3e6-3839c84b10a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-57235e31-499c-4fc4-80ff-559679c9debb,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-859b394d-d1b2-4f3a-88c0-176dd4e56ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-e090c654-36ad-4fd5-ac96-265f73fbca45,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-f60cb5bc-2a44-4ae1-b5be-956c78cad190,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-9750bea4-4e42-45a5-b309-7c10cbe9ac32,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-ca031daf-7241-40d6-b70f-0af0fc27163f,DISK], DatanodeInfoWithStorage[127.0.0.1:38246,DS-1a12010c-d190-4d2c-9726-e024e7e492a6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2033570085-172.17.0.13-1595668388069:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37218,DS-9b0bc48d-2405-46ee-b3c5-d19de91e73ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-05bd5d3a-43fa-4a57-9007-6372eec32aff,DISK], DatanodeInfoWithStorage[127.0.0.1:44820,DS-ed4f6641-12f8-4e5a-ab35-e9fc824ecab4,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-4947a763-4791-4c74-bb9a-db12ee7296cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-dd915715-8e7c-4772-82b8-7fab7370e90b,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-1805528b-9e08-45dd-9252-c62eefe9c36c,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-e7add8d5-d8c7-42f5-9c30-6df053e10d03,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-bf349f2f-0bcd-4633-b08d-eaf504817398,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2033570085-172.17.0.13-1595668388069:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37218,DS-9b0bc48d-2405-46ee-b3c5-d19de91e73ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-05bd5d3a-43fa-4a57-9007-6372eec32aff,DISK], DatanodeInfoWithStorage[127.0.0.1:44820,DS-ed4f6641-12f8-4e5a-ab35-e9fc824ecab4,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-4947a763-4791-4c74-bb9a-db12ee7296cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-dd915715-8e7c-4772-82b8-7fab7370e90b,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-1805528b-9e08-45dd-9252-c62eefe9c36c,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-e7add8d5-d8c7-42f5-9c30-6df053e10d03,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-bf349f2f-0bcd-4633-b08d-eaf504817398,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1653594047-172.17.0.13-1595668496496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37815,DS-39220b21-f105-45c4-8c9b-42e3418fdb3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-25f3b5d5-2290-4193-b625-2841992a13b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-00e16ac6-3d1c-476d-bdf3-eb7ca1b2151c,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-9da2779a-18c4-4555-bf24-5afc23a15e11,DISK], DatanodeInfoWithStorage[127.0.0.1:37201,DS-147ac0fd-962f-4e15-82d4-945fcb2936c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-a111c8a2-41da-4de2-9a6f-08aa75c9753f,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-bba35bf9-89b4-4c93-9848-937db0dbcd2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-ae29bd2d-f016-4f9d-8665-c83696037352,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1653594047-172.17.0.13-1595668496496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37815,DS-39220b21-f105-45c4-8c9b-42e3418fdb3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-25f3b5d5-2290-4193-b625-2841992a13b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-00e16ac6-3d1c-476d-bdf3-eb7ca1b2151c,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-9da2779a-18c4-4555-bf24-5afc23a15e11,DISK], DatanodeInfoWithStorage[127.0.0.1:37201,DS-147ac0fd-962f-4e15-82d4-945fcb2936c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-a111c8a2-41da-4de2-9a6f-08aa75c9753f,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-bba35bf9-89b4-4c93-9848-937db0dbcd2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-ae29bd2d-f016-4f9d-8665-c83696037352,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1713057613-172.17.0.13-1595668634592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36827,DS-7ec7b54c-ef4f-4681-b187-35cbcf5eb620,DISK], DatanodeInfoWithStorage[127.0.0.1:36771,DS-f5b514d3-0625-4d5c-9802-6fe8ef56be2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-b521bd15-d2b7-474f-bfbe-c90fd7cb71e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-af0f765c-fcec-4ceb-9dbc-20605e1f4609,DISK], DatanodeInfoWithStorage[127.0.0.1:38792,DS-127d09a1-c9d8-4bac-a97d-ecef0c15f7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-4afde182-9d49-41b4-b97d-0d16c4c8aab9,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-0faec3af-1bae-4115-91ff-218031636ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-1b925f98-87bc-4a8c-82b8-986766ec467a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1713057613-172.17.0.13-1595668634592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36827,DS-7ec7b54c-ef4f-4681-b187-35cbcf5eb620,DISK], DatanodeInfoWithStorage[127.0.0.1:36771,DS-f5b514d3-0625-4d5c-9802-6fe8ef56be2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-b521bd15-d2b7-474f-bfbe-c90fd7cb71e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-af0f765c-fcec-4ceb-9dbc-20605e1f4609,DISK], DatanodeInfoWithStorage[127.0.0.1:38792,DS-127d09a1-c9d8-4bac-a97d-ecef0c15f7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-4afde182-9d49-41b4-b97d-0d16c4c8aab9,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-0faec3af-1bae-4115-91ff-218031636ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-1b925f98-87bc-4a8c-82b8-986766ec467a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-859530850-172.17.0.13-1595668704776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41108,DS-8f037124-1c03-4653-aee9-a5ebb13f5eec,DISK], DatanodeInfoWithStorage[127.0.0.1:44439,DS-4dc43913-dda0-420f-adad-d93f090dc480,DISK], DatanodeInfoWithStorage[127.0.0.1:45577,DS-027b18f6-b55d-40d3-b0dd-172371acfe46,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-604176a1-05ad-455f-94d7-a717a9faf188,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-34da75b6-5cc9-47dd-95d1-d5a2b78ab6df,DISK], DatanodeInfoWithStorage[127.0.0.1:33176,DS-6c79e7a8-12de-4200-a0e0-219be5e155eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-44e35688-f054-4fa2-9a1f-07154f2a609e,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-2ecc9f18-306e-4470-b353-6164c7f03057,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-859530850-172.17.0.13-1595668704776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41108,DS-8f037124-1c03-4653-aee9-a5ebb13f5eec,DISK], DatanodeInfoWithStorage[127.0.0.1:44439,DS-4dc43913-dda0-420f-adad-d93f090dc480,DISK], DatanodeInfoWithStorage[127.0.0.1:45577,DS-027b18f6-b55d-40d3-b0dd-172371acfe46,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-604176a1-05ad-455f-94d7-a717a9faf188,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-34da75b6-5cc9-47dd-95d1-d5a2b78ab6df,DISK], DatanodeInfoWithStorage[127.0.0.1:33176,DS-6c79e7a8-12de-4200-a0e0-219be5e155eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-44e35688-f054-4fa2-9a1f-07154f2a609e,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-2ecc9f18-306e-4470-b353-6164c7f03057,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-174753249-172.17.0.13-1595668892954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42053,DS-36e3a212-787a-4bb2-9b4d-e284b2960ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-65bdf2f7-35dd-4486-8d74-c6e07218bdb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-ce1d2203-b3bf-4ddc-88e8-676c3f7238a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-ece4ba84-48e8-4f44-904d-7d8a91f35f95,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-2154b281-7c81-4893-a31b-73b5cdaa12ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-77c94d09-b45f-4e9f-af78-164fa4748147,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-fcb9f626-573e-4618-89f2-d7ba17daec72,DISK], DatanodeInfoWithStorage[127.0.0.1:40510,DS-bb558412-ff29-477b-81bb-6d7086cf136c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-174753249-172.17.0.13-1595668892954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42053,DS-36e3a212-787a-4bb2-9b4d-e284b2960ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-65bdf2f7-35dd-4486-8d74-c6e07218bdb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-ce1d2203-b3bf-4ddc-88e8-676c3f7238a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-ece4ba84-48e8-4f44-904d-7d8a91f35f95,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-2154b281-7c81-4893-a31b-73b5cdaa12ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-77c94d09-b45f-4e9f-af78-164fa4748147,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-fcb9f626-573e-4618-89f2-d7ba17daec72,DISK], DatanodeInfoWithStorage[127.0.0.1:40510,DS-bb558412-ff29-477b-81bb-6d7086cf136c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1678417928-172.17.0.13-1595669003601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33554,DS-80461f3f-12ae-4b1e-99a2-6ad8cda1e4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-90047689-787d-4003-9359-39b3e740e7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-a86bc258-feb0-4bf0-9926-26b1e33928f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-efa24892-b1e8-4a83-96f7-4057abbe3177,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-c2031e3d-194a-49f1-9a2e-232a42e44d62,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-a84a1147-64ad-4fdd-83ee-427c27d8e9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-de8b7d17-8f74-4741-a600-74f457b2d302,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-7b1174f1-7d75-4c7d-bf5c-d15c097e3118,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1678417928-172.17.0.13-1595669003601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33554,DS-80461f3f-12ae-4b1e-99a2-6ad8cda1e4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-90047689-787d-4003-9359-39b3e740e7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-a86bc258-feb0-4bf0-9926-26b1e33928f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-efa24892-b1e8-4a83-96f7-4057abbe3177,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-c2031e3d-194a-49f1-9a2e-232a42e44d62,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-a84a1147-64ad-4fdd-83ee-427c27d8e9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-de8b7d17-8f74-4741-a600-74f457b2d302,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-7b1174f1-7d75-4c7d-bf5c-d15c097e3118,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-132382292-172.17.0.13-1595669046339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36324,DS-fa2dd29f-f832-4545-a855-8795c2f2b2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-502dfad9-ee66-4a78-9600-684287731f25,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-54deb661-0050-445f-96ad-b9aedb9da984,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-2f341212-3a17-4a8a-b8ca-3c5395d4cf58,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-83b271f8-8814-4d59-82a6-f1f5abccdfc6,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-ad0e6ff6-3566-4ed5-84c1-6af88a9cfa03,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-a22e457a-47a8-4c3d-96e1-c26d908ddb18,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-d1640a2f-edc6-4416-86db-23d2fddcffb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-132382292-172.17.0.13-1595669046339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36324,DS-fa2dd29f-f832-4545-a855-8795c2f2b2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-502dfad9-ee66-4a78-9600-684287731f25,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-54deb661-0050-445f-96ad-b9aedb9da984,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-2f341212-3a17-4a8a-b8ca-3c5395d4cf58,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-83b271f8-8814-4d59-82a6-f1f5abccdfc6,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-ad0e6ff6-3566-4ed5-84c1-6af88a9cfa03,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-a22e457a-47a8-4c3d-96e1-c26d908ddb18,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-d1640a2f-edc6-4416-86db-23d2fddcffb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-857446640-172.17.0.13-1595669479812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37601,DS-72d4c7c9-2518-4aa3-8dca-588275dc5787,DISK], DatanodeInfoWithStorage[127.0.0.1:46138,DS-3f4e7f0e-6c9e-46e1-94d9-a1373f482bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:36311,DS-8fdb4419-f107-4289-aa55-fda5fa128f54,DISK], DatanodeInfoWithStorage[127.0.0.1:46401,DS-0b385033-b989-47ee-9793-1fc3d57ee4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45405,DS-3a353ba7-99ae-4a49-a566-08d9aafd98ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-696a528d-5747-4b3a-8a03-058daf76d08c,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-32605ff5-523f-4794-bb52-25ae1abc1893,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-76e982c1-5009-44b8-aecb-e4866ef36340,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-857446640-172.17.0.13-1595669479812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37601,DS-72d4c7c9-2518-4aa3-8dca-588275dc5787,DISK], DatanodeInfoWithStorage[127.0.0.1:46138,DS-3f4e7f0e-6c9e-46e1-94d9-a1373f482bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:36311,DS-8fdb4419-f107-4289-aa55-fda5fa128f54,DISK], DatanodeInfoWithStorage[127.0.0.1:46401,DS-0b385033-b989-47ee-9793-1fc3d57ee4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45405,DS-3a353ba7-99ae-4a49-a566-08d9aafd98ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-696a528d-5747-4b3a-8a03-058daf76d08c,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-32605ff5-523f-4794-bb52-25ae1abc1893,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-76e982c1-5009-44b8-aecb-e4866ef36340,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.max.levels
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-411044837-172.17.0.13-1595669555311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46706,DS-4baeff49-bce2-44f8-bd21-5f76fe1709c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-bf9955fe-286b-4505-a6a5-4c14872e3ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-6902bc21-3439-4572-8638-87116fb0d158,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-b47de72a-60b3-453c-a8b0-d3c16e12b4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-3649b218-2bb7-4d02-a348-4c4685aa4c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42395,DS-c2e05e85-42d1-4792-9800-08fb227fe454,DISK], DatanodeInfoWithStorage[127.0.0.1:33020,DS-63926e1d-0ff5-4ea1-9c0c-1b4dc714a5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-256c8d71-bd93-494b-bcae-3970e1b5eb25,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-411044837-172.17.0.13-1595669555311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46706,DS-4baeff49-bce2-44f8-bd21-5f76fe1709c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-bf9955fe-286b-4505-a6a5-4c14872e3ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-6902bc21-3439-4572-8638-87116fb0d158,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-b47de72a-60b3-453c-a8b0-d3c16e12b4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-3649b218-2bb7-4d02-a348-4c4685aa4c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42395,DS-c2e05e85-42d1-4792-9800-08fb227fe454,DISK], DatanodeInfoWithStorage[127.0.0.1:33020,DS-63926e1d-0ff5-4ea1-9c0c-1b4dc714a5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-256c8d71-bd93-494b-bcae-3970e1b5eb25,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 13 out of 50
v1v1v2v2 failed with probability 20 out of 50
result: false positive !!!
Total execution time in seconds : 5378
