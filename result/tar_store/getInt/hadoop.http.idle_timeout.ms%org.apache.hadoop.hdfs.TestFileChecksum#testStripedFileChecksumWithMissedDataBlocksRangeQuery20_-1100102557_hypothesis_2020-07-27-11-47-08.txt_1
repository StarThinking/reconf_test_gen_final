reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-113437262-172.17.0.16-1595850470991:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45525,DS-e242b142-9de7-4514-9ef3-a78f92fe2587,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-93603ce7-b197-4703-a9db-0dbe5c6f02d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-6c72ae7b-03fa-4e26-9940-04e4c0dcc17f,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-afc73f52-53f0-43ff-b342-cebb8f5808a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-8512e85e-bd6f-4d46-8460-d5d2f2945e08,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-40e8dcda-5432-46e8-9e71-9172bc26d791,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-f788c4a0-4c08-4e34-8a91-7c8607836c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-93faa55f-2a26-4411-91e8-98d38f97e98a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-113437262-172.17.0.16-1595850470991:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45525,DS-e242b142-9de7-4514-9ef3-a78f92fe2587,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-93603ce7-b197-4703-a9db-0dbe5c6f02d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-6c72ae7b-03fa-4e26-9940-04e4c0dcc17f,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-afc73f52-53f0-43ff-b342-cebb8f5808a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-8512e85e-bd6f-4d46-8460-d5d2f2945e08,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-40e8dcda-5432-46e8-9e71-9172bc26d791,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-f788c4a0-4c08-4e34-8a91-7c8607836c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-93faa55f-2a26-4411-91e8-98d38f97e98a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1029394688-172.17.0.16-1595851741331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45181,DS-d0267aac-06b3-457d-8655-3e372dd5eef8,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-ea313304-6f79-47c9-96cf-db4634e3239a,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-15efe9bc-bf2b-4f97-be78-eba76eb1fae1,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-f269b41a-47ff-4fa5-a5ab-b2fef10381da,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-4f71ae6d-d130-4d0c-bc22-69ea76e11636,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-03cd3939-56d3-40ab-bf09-709b5912276d,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-4ae0fb7f-372b-4e6b-9685-839941c9b6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41935,DS-5daef9cb-f1d7-410e-b471-b2b35f2420dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1029394688-172.17.0.16-1595851741331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45181,DS-d0267aac-06b3-457d-8655-3e372dd5eef8,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-ea313304-6f79-47c9-96cf-db4634e3239a,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-15efe9bc-bf2b-4f97-be78-eba76eb1fae1,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-f269b41a-47ff-4fa5-a5ab-b2fef10381da,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-4f71ae6d-d130-4d0c-bc22-69ea76e11636,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-03cd3939-56d3-40ab-bf09-709b5912276d,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-4ae0fb7f-372b-4e6b-9685-839941c9b6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41935,DS-5daef9cb-f1d7-410e-b471-b2b35f2420dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-301471310-172.17.0.16-1595851850226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33603,DS-a53211ff-a5dd-4579-98ee-9bedcbd36e07,DISK], DatanodeInfoWithStorage[127.0.0.1:41031,DS-cd7d6e68-cd94-4714-9bd8-3d3f6a6a5714,DISK], DatanodeInfoWithStorage[127.0.0.1:44721,DS-c8fc918a-c822-4404-b486-f44cc2b349f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37785,DS-8d83f0d8-5120-4234-a4c5-beff1d7c2015,DISK], DatanodeInfoWithStorage[127.0.0.1:34568,DS-fb6c6158-5627-4e2c-a965-42ba64aadaa0,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-185b1d4f-7cca-4aab-ad4d-86233710085c,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-7dfa353e-fa44-40db-9363-239f39d72bba,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-f2f8e8d8-c741-494a-b4db-eb2cebf310fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-301471310-172.17.0.16-1595851850226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33603,DS-a53211ff-a5dd-4579-98ee-9bedcbd36e07,DISK], DatanodeInfoWithStorage[127.0.0.1:41031,DS-cd7d6e68-cd94-4714-9bd8-3d3f6a6a5714,DISK], DatanodeInfoWithStorage[127.0.0.1:44721,DS-c8fc918a-c822-4404-b486-f44cc2b349f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37785,DS-8d83f0d8-5120-4234-a4c5-beff1d7c2015,DISK], DatanodeInfoWithStorage[127.0.0.1:34568,DS-fb6c6158-5627-4e2c-a965-42ba64aadaa0,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-185b1d4f-7cca-4aab-ad4d-86233710085c,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-7dfa353e-fa44-40db-9363-239f39d72bba,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-f2f8e8d8-c741-494a-b4db-eb2cebf310fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-323696576-172.17.0.16-1595852563943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46533,DS-134c32c2-f8a9-4ecc-89d0-1acef9d3aab7,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-9c50304f-8d2f-4dbb-bbd5-7cda9475438c,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-bc806d5a-4ab3-42b6-b98a-b377e835fea5,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-1323133d-3bff-468e-b632-64749ddd2fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-0dde88d0-5ca5-4631-8546-bee394a013fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38774,DS-7b3bf7cf-fa15-4bcf-9a0d-8b62dd96ded4,DISK], DatanodeInfoWithStorage[127.0.0.1:41719,DS-cea2a1a2-4359-44f2-90e1-090e4645850c,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-222dd9af-07f1-4f85-9a6b-f9f2ce9a3af4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-323696576-172.17.0.16-1595852563943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46533,DS-134c32c2-f8a9-4ecc-89d0-1acef9d3aab7,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-9c50304f-8d2f-4dbb-bbd5-7cda9475438c,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-bc806d5a-4ab3-42b6-b98a-b377e835fea5,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-1323133d-3bff-468e-b632-64749ddd2fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-0dde88d0-5ca5-4631-8546-bee394a013fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38774,DS-7b3bf7cf-fa15-4bcf-9a0d-8b62dd96ded4,DISK], DatanodeInfoWithStorage[127.0.0.1:41719,DS-cea2a1a2-4359-44f2-90e1-090e4645850c,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-222dd9af-07f1-4f85-9a6b-f9f2ce9a3af4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-227366516-172.17.0.16-1595852641912:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46559,DS-e8a9321c-7b73-4ae4-b4a9-8ebe28defac4,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-d1254d1b-432c-496c-aadd-c67bc60f98e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-cd3e8f92-4c42-4481-95c8-a963a9bdd944,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-5b71e106-4d23-46af-aece-68d21e4791e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-3c347fbc-4aee-47bf-b45a-28e4310e2678,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-8a296957-b842-476b-818f-7046524d460e,DISK], DatanodeInfoWithStorage[127.0.0.1:34121,DS-698e04ee-0e78-446b-bc14-adff6359c345,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-9f018813-53e4-452c-829f-1101e8eda6a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-227366516-172.17.0.16-1595852641912:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46559,DS-e8a9321c-7b73-4ae4-b4a9-8ebe28defac4,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-d1254d1b-432c-496c-aadd-c67bc60f98e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-cd3e8f92-4c42-4481-95c8-a963a9bdd944,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-5b71e106-4d23-46af-aece-68d21e4791e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-3c347fbc-4aee-47bf-b45a-28e4310e2678,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-8a296957-b842-476b-818f-7046524d460e,DISK], DatanodeInfoWithStorage[127.0.0.1:34121,DS-698e04ee-0e78-446b-bc14-adff6359c345,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-9f018813-53e4-452c-829f-1101e8eda6a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1244902397-172.17.0.16-1595852915164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42161,DS-a2e80da9-2a95-46dc-89d6-924bc2ab2665,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-e8a2ab16-29bc-46cd-88c4-725fb442491a,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-db10f3f9-5374-46c0-8ff2-ae44116e2920,DISK], DatanodeInfoWithStorage[127.0.0.1:34646,DS-1c9d081f-b245-4432-9099-51a12a948a25,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-d67b8182-11c5-4cae-aeaa-7f479e7d6e66,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-889ff67d-1947-4533-87ec-dd087a7b50a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-a9ca4c44-8627-4ab5-bea9-cd91f98f565d,DISK], DatanodeInfoWithStorage[127.0.0.1:34143,DS-050ac60b-3fb3-4712-b309-5dfa1c6ed9b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1244902397-172.17.0.16-1595852915164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42161,DS-a2e80da9-2a95-46dc-89d6-924bc2ab2665,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-e8a2ab16-29bc-46cd-88c4-725fb442491a,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-db10f3f9-5374-46c0-8ff2-ae44116e2920,DISK], DatanodeInfoWithStorage[127.0.0.1:34646,DS-1c9d081f-b245-4432-9099-51a12a948a25,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-d67b8182-11c5-4cae-aeaa-7f479e7d6e66,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-889ff67d-1947-4533-87ec-dd087a7b50a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-a9ca4c44-8627-4ab5-bea9-cd91f98f565d,DISK], DatanodeInfoWithStorage[127.0.0.1:34143,DS-050ac60b-3fb3-4712-b309-5dfa1c6ed9b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1134446817-172.17.0.16-1595853157732:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45596,DS-fb6f987c-3962-4ef9-8a87-9de01af96dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:37495,DS-f4495b9c-de2e-490d-8ed7-2c30f8aa5f94,DISK], DatanodeInfoWithStorage[127.0.0.1:35714,DS-f727aaff-a199-4246-8308-d489fb2fd551,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-1c2a2f89-d82f-4bc4-9971-8f5d64d50d28,DISK], DatanodeInfoWithStorage[127.0.0.1:37411,DS-944892b4-0b9e-4e57-bf44-8e3d070978e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42302,DS-83dd306d-2621-4f05-937d-729cae4b749b,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-973e7b9c-4e84-418b-991a-05df9fbdb57a,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-f57ef455-efd1-4323-a4bc-b60734fea41a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1134446817-172.17.0.16-1595853157732:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45596,DS-fb6f987c-3962-4ef9-8a87-9de01af96dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:37495,DS-f4495b9c-de2e-490d-8ed7-2c30f8aa5f94,DISK], DatanodeInfoWithStorage[127.0.0.1:35714,DS-f727aaff-a199-4246-8308-d489fb2fd551,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-1c2a2f89-d82f-4bc4-9971-8f5d64d50d28,DISK], DatanodeInfoWithStorage[127.0.0.1:37411,DS-944892b4-0b9e-4e57-bf44-8e3d070978e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42302,DS-83dd306d-2621-4f05-937d-729cae4b749b,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-973e7b9c-4e84-418b-991a-05df9fbdb57a,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-f57ef455-efd1-4323-a4bc-b60734fea41a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1652700345-172.17.0.16-1595853385615:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33853,DS-f16c60d7-47ce-455f-b5d6-f69febb76326,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-810357cc-1f01-4f63-afcd-136322bac5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-5619d1e4-ac8f-4e55-8ef6-41bd658fb6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-7c2ea3b8-790a-4120-9439-02808c66fe1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37900,DS-93f3f1ec-c852-49f1-8126-d130e505a037,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-dee6bbd9-d96d-4050-a27b-243bc938fe2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40962,DS-e623b60d-20dd-4b9f-9a7d-64f416771df8,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-e939f43e-3548-4127-a3ec-f9883136f4db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1652700345-172.17.0.16-1595853385615:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33853,DS-f16c60d7-47ce-455f-b5d6-f69febb76326,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-810357cc-1f01-4f63-afcd-136322bac5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-5619d1e4-ac8f-4e55-8ef6-41bd658fb6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-7c2ea3b8-790a-4120-9439-02808c66fe1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37900,DS-93f3f1ec-c852-49f1-8126-d130e505a037,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-dee6bbd9-d96d-4050-a27b-243bc938fe2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40962,DS-e623b60d-20dd-4b9f-9a7d-64f416771df8,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-e939f43e-3548-4127-a3ec-f9883136f4db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1519613461-172.17.0.16-1595853417835:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36994,DS-32cec37b-5b3b-41ac-9995-19365cfcd168,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-5f827bbb-11e6-488d-93f4-4829d9f5511f,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-8fda5975-6887-4183-8578-e7f9c7f1f145,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-18c09ec3-bff2-4f96-bc4c-5c93ada4f630,DISK], DatanodeInfoWithStorage[127.0.0.1:41532,DS-a2a3373a-ecd1-4cfd-8ce5-4ad5a4c30053,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-32e27315-5f78-4446-9b70-89f5b95d0676,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-ab0c6174-fb3e-4bff-9ae3-99497afe27a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-2767ce9d-761a-4a73-a2d9-77125fe94b74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1519613461-172.17.0.16-1595853417835:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36994,DS-32cec37b-5b3b-41ac-9995-19365cfcd168,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-5f827bbb-11e6-488d-93f4-4829d9f5511f,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-8fda5975-6887-4183-8578-e7f9c7f1f145,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-18c09ec3-bff2-4f96-bc4c-5c93ada4f630,DISK], DatanodeInfoWithStorage[127.0.0.1:41532,DS-a2a3373a-ecd1-4cfd-8ce5-4ad5a4c30053,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-32e27315-5f78-4446-9b70-89f5b95d0676,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-ab0c6174-fb3e-4bff-9ae3-99497afe27a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-2767ce9d-761a-4a73-a2d9-77125fe94b74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1045883800-172.17.0.16-1595853489949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38393,DS-b26551d4-a5a8-4e40-8940-ccd4334ec53e,DISK], DatanodeInfoWithStorage[127.0.0.1:42123,DS-8cc1a66f-d80b-4244-87d5-73f17e7b3c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38390,DS-6132aaa0-a858-4430-aafe-cb2ba71371dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-83c5229e-6ca0-4893-8622-b461d144ac55,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-47e9bb32-0e43-4481-be0f-f0906b4b28d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-5e547f20-1581-489f-a0b5-e45b0a9e6ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-68dcc885-94a8-4d87-966f-0fcf4fc87210,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-e7b2c819-980d-4f49-b043-71c8e717f740,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1045883800-172.17.0.16-1595853489949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38393,DS-b26551d4-a5a8-4e40-8940-ccd4334ec53e,DISK], DatanodeInfoWithStorage[127.0.0.1:42123,DS-8cc1a66f-d80b-4244-87d5-73f17e7b3c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38390,DS-6132aaa0-a858-4430-aafe-cb2ba71371dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-83c5229e-6ca0-4893-8622-b461d144ac55,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-47e9bb32-0e43-4481-be0f-f0906b4b28d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-5e547f20-1581-489f-a0b5-e45b0a9e6ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-68dcc885-94a8-4d87-966f-0fcf4fc87210,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-e7b2c819-980d-4f49-b043-71c8e717f740,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-629776683-172.17.0.16-1595854264358:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44435,DS-ef6637ba-cfe8-4d58-a7c5-80c0fa9a6d61,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-e2770e2e-730b-43f7-9c3e-22b413671d26,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-b96803f1-0e1a-4f42-ac34-a0a71a5822db,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-32857132-2eb6-4582-93a2-1954005eb301,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-c7e24912-b762-441e-ae1c-a862a284b10a,DISK], DatanodeInfoWithStorage[127.0.0.1:42327,DS-f5c39fa3-8a81-4d64-98ec-d8da155a9eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-1c771535-ffc4-4585-ba00-07a512fc4b28,DISK], DatanodeInfoWithStorage[127.0.0.1:35621,DS-d6910b4b-ebb3-4c22-9aa5-60a76db688fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-629776683-172.17.0.16-1595854264358:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44435,DS-ef6637ba-cfe8-4d58-a7c5-80c0fa9a6d61,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-e2770e2e-730b-43f7-9c3e-22b413671d26,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-b96803f1-0e1a-4f42-ac34-a0a71a5822db,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-32857132-2eb6-4582-93a2-1954005eb301,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-c7e24912-b762-441e-ae1c-a862a284b10a,DISK], DatanodeInfoWithStorage[127.0.0.1:42327,DS-f5c39fa3-8a81-4d64-98ec-d8da155a9eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-1c771535-ffc4-4585-ba00-07a512fc4b28,DISK], DatanodeInfoWithStorage[127.0.0.1:35621,DS-d6910b4b-ebb3-4c22-9aa5-60a76db688fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-846863354-172.17.0.16-1595854470403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42671,DS-b385321c-c632-4cf1-9773-6c67fbf88c79,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-5fefc643-07c7-4c31-b386-24ad5a979a49,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-76de2c74-8c17-46e7-939e-e024517e0b75,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-13918881-aa3e-4094-94ea-b3870840ca3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36588,DS-0a16efcb-d762-430a-9944-67e40c36ce74,DISK], DatanodeInfoWithStorage[127.0.0.1:37649,DS-2a9323c4-5aef-4bef-8426-5bb26f0e368f,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-43b4dbaa-42c8-464b-84c2-db0165d0c9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46416,DS-479b1bbf-3263-4ff8-b0c6-daaedb62d2e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-846863354-172.17.0.16-1595854470403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42671,DS-b385321c-c632-4cf1-9773-6c67fbf88c79,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-5fefc643-07c7-4c31-b386-24ad5a979a49,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-76de2c74-8c17-46e7-939e-e024517e0b75,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-13918881-aa3e-4094-94ea-b3870840ca3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36588,DS-0a16efcb-d762-430a-9944-67e40c36ce74,DISK], DatanodeInfoWithStorage[127.0.0.1:37649,DS-2a9323c4-5aef-4bef-8426-5bb26f0e368f,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-43b4dbaa-42c8-464b-84c2-db0165d0c9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46416,DS-479b1bbf-3263-4ff8-b0c6-daaedb62d2e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1644514189-172.17.0.16-1595854498425:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43102,DS-f38da2ba-9ffa-4222-b9d2-dc35015a4960,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-f084b772-e16d-4af6-9080-4f3ff60d033a,DISK], DatanodeInfoWithStorage[127.0.0.1:43202,DS-728778f9-5f87-49d8-9cb0-f8722b8c65d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-f2f4589b-fcbe-450a-8b44-33cdb10d30bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-eb5873df-87ae-46d4-8a3f-0097f28444dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-270d305d-9e18-4043-a7b7-d04b01e38069,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-48144b2b-f122-4faa-98a2-5de2b6a676ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-91d0bf3c-4d7d-41c2-978e-d76f5f4493dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1644514189-172.17.0.16-1595854498425:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43102,DS-f38da2ba-9ffa-4222-b9d2-dc35015a4960,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-f084b772-e16d-4af6-9080-4f3ff60d033a,DISK], DatanodeInfoWithStorage[127.0.0.1:43202,DS-728778f9-5f87-49d8-9cb0-f8722b8c65d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-f2f4589b-fcbe-450a-8b44-33cdb10d30bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-eb5873df-87ae-46d4-8a3f-0097f28444dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-270d305d-9e18-4043-a7b7-d04b01e38069,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-48144b2b-f122-4faa-98a2-5de2b6a676ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-91d0bf3c-4d7d-41c2-978e-d76f5f4493dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2094628174-172.17.0.16-1595854802088:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42575,DS-db20b6a8-21f5-4328-a718-b1349aa7edab,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-28bcc766-bb2b-48bf-9f6c-8d075f6fda08,DISK], DatanodeInfoWithStorage[127.0.0.1:36552,DS-85d0e895-e781-4ea6-b7ee-668f641079bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39789,DS-6b8735f2-709c-4832-ae96-4f4195b57089,DISK], DatanodeInfoWithStorage[127.0.0.1:42565,DS-68872f21-0136-4887-85b8-6be437fb5809,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-7b5a9ef8-270f-48c4-8e0e-beeb0857bd9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44809,DS-d14d4c9c-628c-4a15-98e7-740231fcde79,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-d8a4235e-8000-4caa-a796-65e6ca642859,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2094628174-172.17.0.16-1595854802088:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42575,DS-db20b6a8-21f5-4328-a718-b1349aa7edab,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-28bcc766-bb2b-48bf-9f6c-8d075f6fda08,DISK], DatanodeInfoWithStorage[127.0.0.1:36552,DS-85d0e895-e781-4ea6-b7ee-668f641079bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39789,DS-6b8735f2-709c-4832-ae96-4f4195b57089,DISK], DatanodeInfoWithStorage[127.0.0.1:42565,DS-68872f21-0136-4887-85b8-6be437fb5809,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-7b5a9ef8-270f-48c4-8e0e-beeb0857bd9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44809,DS-d14d4c9c-628c-4a15-98e7-740231fcde79,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-d8a4235e-8000-4caa-a796-65e6ca642859,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2121028453-172.17.0.16-1595855233231:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36990,DS-a056ed27-6f85-469b-9feb-f660a658232d,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-f4c56aaf-3a89-4111-81dd-210101d15695,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-f188ba84-1a3b-478f-aa25-46d5d088d78f,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-ae15bb83-ce45-40bb-9449-91406b7f0f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-5c425a6a-9ad3-4a44-b902-fc3ddc9fddfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-fe29044c-675f-4cc3-bf55-7518514148aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-69182b55-46c6-4ece-9eb4-f73c1e600bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-2b136d41-6115-4f8d-b8c6-af69559ef6d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2121028453-172.17.0.16-1595855233231:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36990,DS-a056ed27-6f85-469b-9feb-f660a658232d,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-f4c56aaf-3a89-4111-81dd-210101d15695,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-f188ba84-1a3b-478f-aa25-46d5d088d78f,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-ae15bb83-ce45-40bb-9449-91406b7f0f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-5c425a6a-9ad3-4a44-b902-fc3ddc9fddfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-fe29044c-675f-4cc3-bf55-7518514148aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-69182b55-46c6-4ece-9eb4-f73c1e600bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-2b136d41-6115-4f8d-b8c6-af69559ef6d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-292807849-172.17.0.16-1595855420946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36972,DS-410c5390-479f-43d8-b964-90d7e75843f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-a56d8a17-22ae-40a7-a498-d9c8dd878df6,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-8f100cd7-21ad-4f36-843c-98319dd0ba97,DISK], DatanodeInfoWithStorage[127.0.0.1:41680,DS-357f2a4a-a648-4ad8-be53-33d33de67a51,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-5ab78c8a-b10c-4065-887d-8e7534d1e2d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-35da0e78-aeca-408a-81d7-6e4bf65f2d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-a1c750b9-82d0-4923-a7ab-9b4bf590110b,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-852d536b-716c-4865-8e79-afc3b06d0d78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-292807849-172.17.0.16-1595855420946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36972,DS-410c5390-479f-43d8-b964-90d7e75843f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-a56d8a17-22ae-40a7-a498-d9c8dd878df6,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-8f100cd7-21ad-4f36-843c-98319dd0ba97,DISK], DatanodeInfoWithStorage[127.0.0.1:41680,DS-357f2a4a-a648-4ad8-be53-33d33de67a51,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-5ab78c8a-b10c-4065-887d-8e7534d1e2d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-35da0e78-aeca-408a-81d7-6e4bf65f2d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-a1c750b9-82d0-4923-a7ab-9b4bf590110b,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-852d536b-716c-4865-8e79-afc3b06d0d78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1043547312-172.17.0.16-1595855562866:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46073,DS-864bb2f7-850e-4662-83f6-9f3aac237953,DISK], DatanodeInfoWithStorage[127.0.0.1:46408,DS-6f031520-426d-43df-a2a7-b01c40f939d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-26a9ea29-c59d-4080-b84e-883b35393cef,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-219298dd-ee71-4801-98cd-1fd6584b7c22,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-c4134ef4-b93a-46d5-9b35-4841cfeb1854,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-08d11731-08f1-42ac-b2f4-e5d189b7807f,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-0096a9da-bedf-4ae6-a3a1-4d05a813b963,DISK], DatanodeInfoWithStorage[127.0.0.1:46030,DS-8606a011-2ab3-428d-84d5-7dd616a11da3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1043547312-172.17.0.16-1595855562866:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46073,DS-864bb2f7-850e-4662-83f6-9f3aac237953,DISK], DatanodeInfoWithStorage[127.0.0.1:46408,DS-6f031520-426d-43df-a2a7-b01c40f939d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-26a9ea29-c59d-4080-b84e-883b35393cef,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-219298dd-ee71-4801-98cd-1fd6584b7c22,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-c4134ef4-b93a-46d5-9b35-4841cfeb1854,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-08d11731-08f1-42ac-b2f4-e5d189b7807f,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-0096a9da-bedf-4ae6-a3a1-4d05a813b963,DISK], DatanodeInfoWithStorage[127.0.0.1:46030,DS-8606a011-2ab3-428d-84d5-7dd616a11da3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5380
