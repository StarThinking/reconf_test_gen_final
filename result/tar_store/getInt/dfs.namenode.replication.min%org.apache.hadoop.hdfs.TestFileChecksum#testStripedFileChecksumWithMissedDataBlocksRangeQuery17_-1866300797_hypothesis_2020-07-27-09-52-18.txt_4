reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1460126383-172.17.0.8-1595844130916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37129,DS-91872d2c-fb3b-4705-a35c-ec921d652620,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-7b74d4b2-38bb-403f-a9f4-1766c46f6a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-818d36ba-ae9f-48f3-b80c-95f908481c26,DISK], DatanodeInfoWithStorage[127.0.0.1:46297,DS-c6384758-e6cb-407c-818c-cfb244c1c5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46688,DS-b61b2d9d-a167-4fef-bc8d-d1ad0475d61c,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-cf250e09-aef0-409c-b104-922f5ca0a91c,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-eccd84ed-d2eb-4e4d-a4d6-f98a0146aafe,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-e7686b6b-9343-41d4-a9b1-0c4d1b5c573b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1460126383-172.17.0.8-1595844130916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37129,DS-91872d2c-fb3b-4705-a35c-ec921d652620,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-7b74d4b2-38bb-403f-a9f4-1766c46f6a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-818d36ba-ae9f-48f3-b80c-95f908481c26,DISK], DatanodeInfoWithStorage[127.0.0.1:46297,DS-c6384758-e6cb-407c-818c-cfb244c1c5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46688,DS-b61b2d9d-a167-4fef-bc8d-d1ad0475d61c,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-cf250e09-aef0-409c-b104-922f5ca0a91c,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-eccd84ed-d2eb-4e4d-a4d6-f98a0146aafe,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-e7686b6b-9343-41d4-a9b1-0c4d1b5c573b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1603515350-172.17.0.8-1595844344370:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41946,DS-bed180f4-b3ac-4360-b17f-78690c12395c,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-d41a9d1c-bbf7-47d9-bfb7-01996c54a33b,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-f880ca4a-be09-4f8f-85fc-36a76da32070,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-f35ddb3d-1abf-4b95-95dc-a73b569d5aed,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-055ae0c3-c67a-46b3-b734-4a1a13a88ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:41876,DS-910bdbf9-fb58-4612-822d-cf71aa02bbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-f0d491c4-4882-4052-8aa1-7356ddbfe8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-080f1261-9196-4ab6-9d79-a5f54da730ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1603515350-172.17.0.8-1595844344370:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41946,DS-bed180f4-b3ac-4360-b17f-78690c12395c,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-d41a9d1c-bbf7-47d9-bfb7-01996c54a33b,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-f880ca4a-be09-4f8f-85fc-36a76da32070,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-f35ddb3d-1abf-4b95-95dc-a73b569d5aed,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-055ae0c3-c67a-46b3-b734-4a1a13a88ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:41876,DS-910bdbf9-fb58-4612-822d-cf71aa02bbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-f0d491c4-4882-4052-8aa1-7356ddbfe8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-080f1261-9196-4ab6-9d79-a5f54da730ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2081993806-172.17.0.8-1595844378832:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43464,DS-b9951e22-c157-4dfd-9130-9000ae12f276,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-37234d6f-c3c0-48ae-8a89-9c460f5a3f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-ffa3da87-436c-41a2-8501-fb134a27c4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-495778ce-b024-4929-a55d-0de4b81ebb20,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-70c55d14-da3e-493d-b3b3-7c6ca70ba56a,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-043a70d2-5e3e-4093-84cb-e944b9734634,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-0933a25f-9594-4b37-9f6c-c830905b6329,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-8602c9fe-3314-42bc-96bb-6aed3aae66fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2081993806-172.17.0.8-1595844378832:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43464,DS-b9951e22-c157-4dfd-9130-9000ae12f276,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-37234d6f-c3c0-48ae-8a89-9c460f5a3f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-ffa3da87-436c-41a2-8501-fb134a27c4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-495778ce-b024-4929-a55d-0de4b81ebb20,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-70c55d14-da3e-493d-b3b3-7c6ca70ba56a,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-043a70d2-5e3e-4093-84cb-e944b9734634,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-0933a25f-9594-4b37-9f6c-c830905b6329,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-8602c9fe-3314-42bc-96bb-6aed3aae66fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1256196320-172.17.0.8-1595844686410:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37010,DS-83c0ea2e-fb15-469f-8f53-fd07690108f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-87e11301-284f-4629-923a-29e9200f3538,DISK], DatanodeInfoWithStorage[127.0.0.1:43562,DS-69ce2fed-d047-4862-98c3-77758884eb8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38066,DS-9ce706e0-e768-429c-beb2-d76fd7d09858,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-fb0ea872-70e8-4367-8ffe-84f3b1224c08,DISK], DatanodeInfoWithStorage[127.0.0.1:45691,DS-db26c5ed-7236-469f-94bc-cdf43dadd3af,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-f9dc88ea-35b2-4073-856e-bce38f74c089,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-ae77781a-a489-4f7f-b5bd-c365db2418c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1256196320-172.17.0.8-1595844686410:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37010,DS-83c0ea2e-fb15-469f-8f53-fd07690108f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-87e11301-284f-4629-923a-29e9200f3538,DISK], DatanodeInfoWithStorage[127.0.0.1:43562,DS-69ce2fed-d047-4862-98c3-77758884eb8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38066,DS-9ce706e0-e768-429c-beb2-d76fd7d09858,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-fb0ea872-70e8-4367-8ffe-84f3b1224c08,DISK], DatanodeInfoWithStorage[127.0.0.1:45691,DS-db26c5ed-7236-469f-94bc-cdf43dadd3af,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-f9dc88ea-35b2-4073-856e-bce38f74c089,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-ae77781a-a489-4f7f-b5bd-c365db2418c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-108576798-172.17.0.8-1595845231251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36503,DS-8c6fd802-0d84-4f3d-8dc2-265a6ed298eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-03ca066c-3e46-464e-be33-3f52fd017d19,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-8a154a11-e8e2-4f07-8208-c5416a4703db,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-44864164-0c68-4324-adad-d1f74093c9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40355,DS-476a51d5-204e-45dc-8be7-a1765149501b,DISK], DatanodeInfoWithStorage[127.0.0.1:41890,DS-95251910-19f2-4c82-94ec-8e6385fc5581,DISK], DatanodeInfoWithStorage[127.0.0.1:45758,DS-26b6495a-6d03-49a6-8db2-4731eb933e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38872,DS-0d87726a-d17e-40ed-bb33-eff2f88982d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-108576798-172.17.0.8-1595845231251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36503,DS-8c6fd802-0d84-4f3d-8dc2-265a6ed298eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-03ca066c-3e46-464e-be33-3f52fd017d19,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-8a154a11-e8e2-4f07-8208-c5416a4703db,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-44864164-0c68-4324-adad-d1f74093c9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40355,DS-476a51d5-204e-45dc-8be7-a1765149501b,DISK], DatanodeInfoWithStorage[127.0.0.1:41890,DS-95251910-19f2-4c82-94ec-8e6385fc5581,DISK], DatanodeInfoWithStorage[127.0.0.1:45758,DS-26b6495a-6d03-49a6-8db2-4731eb933e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38872,DS-0d87726a-d17e-40ed-bb33-eff2f88982d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1332302613-172.17.0.8-1595845376130:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46203,DS-f425491a-7fb1-44a9-9148-aebf1c4b96b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34758,DS-04a1d1ad-c31a-4eb1-8e12-b8e534f0d542,DISK], DatanodeInfoWithStorage[127.0.0.1:38054,DS-55e671a5-7709-444a-b17c-8b70864010e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-5d8f664a-e367-4ac0-b3e2-61cb2152b07b,DISK], DatanodeInfoWithStorage[127.0.0.1:38415,DS-85f42721-137b-43c8-8fe6-8f1d9ac19848,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-dac748bc-939c-4c43-9f6b-9038f3d20f97,DISK], DatanodeInfoWithStorage[127.0.0.1:38001,DS-6a71bba4-73f4-45f2-9742-3bc40b68fffe,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-94679726-ed0d-402b-9cd9-84e36bd4cb98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1332302613-172.17.0.8-1595845376130:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46203,DS-f425491a-7fb1-44a9-9148-aebf1c4b96b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34758,DS-04a1d1ad-c31a-4eb1-8e12-b8e534f0d542,DISK], DatanodeInfoWithStorage[127.0.0.1:38054,DS-55e671a5-7709-444a-b17c-8b70864010e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-5d8f664a-e367-4ac0-b3e2-61cb2152b07b,DISK], DatanodeInfoWithStorage[127.0.0.1:38415,DS-85f42721-137b-43c8-8fe6-8f1d9ac19848,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-dac748bc-939c-4c43-9f6b-9038f3d20f97,DISK], DatanodeInfoWithStorage[127.0.0.1:38001,DS-6a71bba4-73f4-45f2-9742-3bc40b68fffe,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-94679726-ed0d-402b-9cd9-84e36bd4cb98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-275396219-172.17.0.8-1595845713246:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34584,DS-96116f3f-c4f7-46bf-868c-c45c5b2a0997,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-8a605126-1954-4eac-a67b-32a5cd2b7384,DISK], DatanodeInfoWithStorage[127.0.0.1:43784,DS-9f46740d-9912-423a-a5b9-bfce12d28235,DISK], DatanodeInfoWithStorage[127.0.0.1:44199,DS-3f48504b-ff52-4b67-beb1-5739d931c3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-3e8e924b-ce46-49a5-9018-b37d8f76eeb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-fe554eed-a85b-4afe-8979-b6701f0e4385,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-42b3d7c3-a718-4707-b341-2a86a285029f,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-d037e355-890a-4249-96f2-3f8d6061188b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-275396219-172.17.0.8-1595845713246:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34584,DS-96116f3f-c4f7-46bf-868c-c45c5b2a0997,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-8a605126-1954-4eac-a67b-32a5cd2b7384,DISK], DatanodeInfoWithStorage[127.0.0.1:43784,DS-9f46740d-9912-423a-a5b9-bfce12d28235,DISK], DatanodeInfoWithStorage[127.0.0.1:44199,DS-3f48504b-ff52-4b67-beb1-5739d931c3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-3e8e924b-ce46-49a5-9018-b37d8f76eeb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-fe554eed-a85b-4afe-8979-b6701f0e4385,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-42b3d7c3-a718-4707-b341-2a86a285029f,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-d037e355-890a-4249-96f2-3f8d6061188b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1741313935-172.17.0.8-1595846852370:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45629,DS-08c8b90c-892b-4ef1-a267-46c9f5477178,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-b5718942-1e30-435a-9f1b-ead32aa13175,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-fd0de232-d2e6-4394-a21d-e2f283ac6928,DISK], DatanodeInfoWithStorage[127.0.0.1:33838,DS-37744f7f-df5e-4557-badb-5556e2c4f1af,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-07b9dab9-5e0e-41e6-b87d-5347ce584063,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-431da818-5aca-4002-b686-c6f9f1430722,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-ead96090-8203-401f-89ba-32394c2663ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-9aeb7915-49dd-46ee-b3f4-5935b900285e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1741313935-172.17.0.8-1595846852370:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45629,DS-08c8b90c-892b-4ef1-a267-46c9f5477178,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-b5718942-1e30-435a-9f1b-ead32aa13175,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-fd0de232-d2e6-4394-a21d-e2f283ac6928,DISK], DatanodeInfoWithStorage[127.0.0.1:33838,DS-37744f7f-df5e-4557-badb-5556e2c4f1af,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-07b9dab9-5e0e-41e6-b87d-5347ce584063,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-431da818-5aca-4002-b686-c6f9f1430722,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-ead96090-8203-401f-89ba-32394c2663ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-9aeb7915-49dd-46ee-b3f4-5935b900285e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-527508949-172.17.0.8-1595846930270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42258,DS-a5a9f095-a124-42ae-916f-a445d725f56c,DISK], DatanodeInfoWithStorage[127.0.0.1:34560,DS-c75d58ac-e618-4578-b502-1918867415b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-137bcfb6-d29b-480d-bc89-7711d8630b97,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-9daa5bf5-b0cf-44e1-9b38-e04886250be9,DISK], DatanodeInfoWithStorage[127.0.0.1:41862,DS-2d8f2539-4178-450b-afbd-d8ba38919adb,DISK], DatanodeInfoWithStorage[127.0.0.1:44364,DS-d958a797-40d1-497e-abc0-880acf025b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44325,DS-0aa0ad17-4ef9-4688-a026-663791e1a265,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-a1f527dc-2124-4155-94af-8a08cb0882e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-527508949-172.17.0.8-1595846930270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42258,DS-a5a9f095-a124-42ae-916f-a445d725f56c,DISK], DatanodeInfoWithStorage[127.0.0.1:34560,DS-c75d58ac-e618-4578-b502-1918867415b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-137bcfb6-d29b-480d-bc89-7711d8630b97,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-9daa5bf5-b0cf-44e1-9b38-e04886250be9,DISK], DatanodeInfoWithStorage[127.0.0.1:41862,DS-2d8f2539-4178-450b-afbd-d8ba38919adb,DISK], DatanodeInfoWithStorage[127.0.0.1:44364,DS-d958a797-40d1-497e-abc0-880acf025b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44325,DS-0aa0ad17-4ef9-4688-a026-663791e1a265,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-a1f527dc-2124-4155-94af-8a08cb0882e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-887896458-172.17.0.8-1595847269463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45713,DS-9e3bb26e-6998-4e67-94f3-4e1a40281be8,DISK], DatanodeInfoWithStorage[127.0.0.1:39651,DS-7d1425e0-b0b0-42bb-a316-db25ff2441fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-c70eb614-f223-4b8d-8693-4f5c54ca8395,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-5254e566-79bb-4826-9b8e-cc0ceb964a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-5de67830-5d86-4a89-8e69-cc459a0c4792,DISK], DatanodeInfoWithStorage[127.0.0.1:46381,DS-04345ccd-148b-40ea-a307-655449f85fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-b548f559-2f6e-4e12-8f90-d51ab499520b,DISK], DatanodeInfoWithStorage[127.0.0.1:41463,DS-7661a705-6bd4-4fb2-9ea2-5c1f6e3e6cc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-887896458-172.17.0.8-1595847269463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45713,DS-9e3bb26e-6998-4e67-94f3-4e1a40281be8,DISK], DatanodeInfoWithStorage[127.0.0.1:39651,DS-7d1425e0-b0b0-42bb-a316-db25ff2441fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-c70eb614-f223-4b8d-8693-4f5c54ca8395,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-5254e566-79bb-4826-9b8e-cc0ceb964a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-5de67830-5d86-4a89-8e69-cc459a0c4792,DISK], DatanodeInfoWithStorage[127.0.0.1:46381,DS-04345ccd-148b-40ea-a307-655449f85fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-b548f559-2f6e-4e12-8f90-d51ab499520b,DISK], DatanodeInfoWithStorage[127.0.0.1:41463,DS-7661a705-6bd4-4fb2-9ea2-5c1f6e3e6cc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1355849430-172.17.0.8-1595847820183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33769,DS-59420bb3-fbfc-46f6-a4c7-b07e67f8aded,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-2c451e15-4404-4ab1-97c8-f3af7722735e,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-49f0723d-e747-474f-9650-77d4608ec84f,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-8e1c5104-d0d6-49d2-8d87-163dcde58176,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-32fbbb61-b53c-451b-ba25-9ee0f2ba9338,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-ca0121c2-5d75-4071-a9c0-faf8d51fa202,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-3465e2b3-4117-48ba-9451-0d1776c53b48,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-7a95f593-dfff-4ee4-9aca-60b272798f48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1355849430-172.17.0.8-1595847820183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33769,DS-59420bb3-fbfc-46f6-a4c7-b07e67f8aded,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-2c451e15-4404-4ab1-97c8-f3af7722735e,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-49f0723d-e747-474f-9650-77d4608ec84f,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-8e1c5104-d0d6-49d2-8d87-163dcde58176,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-32fbbb61-b53c-451b-ba25-9ee0f2ba9338,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-ca0121c2-5d75-4071-a9c0-faf8d51fa202,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-3465e2b3-4117-48ba-9451-0d1776c53b48,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-7a95f593-dfff-4ee4-9aca-60b272798f48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1548461706-172.17.0.8-1595847887243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46041,DS-54936fc4-b8c6-4dc2-904e-280b339e1966,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-6c428a69-efe3-4066-af73-509bb3c5d84b,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-1655a5f5-d36e-4bf4-86ac-321d6f1d229e,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-2e81d284-7d94-4ee6-a7f0-48c87f99ce8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-ff9893b7-3659-467e-982d-f1c881ed7f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46499,DS-ff305f0c-1f1d-486d-a5fb-65ea347f3acb,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-ffc78019-646b-46f4-a4df-51fc22bd3735,DISK], DatanodeInfoWithStorage[127.0.0.1:39418,DS-024630c3-b1ca-4405-b40a-aa91e1b9395a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1548461706-172.17.0.8-1595847887243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46041,DS-54936fc4-b8c6-4dc2-904e-280b339e1966,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-6c428a69-efe3-4066-af73-509bb3c5d84b,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-1655a5f5-d36e-4bf4-86ac-321d6f1d229e,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-2e81d284-7d94-4ee6-a7f0-48c87f99ce8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-ff9893b7-3659-467e-982d-f1c881ed7f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46499,DS-ff305f0c-1f1d-486d-a5fb-65ea347f3acb,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-ffc78019-646b-46f4-a4df-51fc22bd3735,DISK], DatanodeInfoWithStorage[127.0.0.1:39418,DS-024630c3-b1ca-4405-b40a-aa91e1b9395a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-811992755-172.17.0.8-1595848062921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38354,DS-f0b9d471-6f71-4395-b5ff-61a8837e0e66,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-dec7220c-2d5d-496b-8810-9f551faf61d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-5812f35c-4b26-4cef-82bd-ad572def3737,DISK], DatanodeInfoWithStorage[127.0.0.1:46013,DS-34fb4cb4-96c9-4f46-83f7-91a301a01f33,DISK], DatanodeInfoWithStorage[127.0.0.1:33605,DS-b6370b90-e9b3-4c17-a10d-e143ca0a0263,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-b5f3828d-5286-42c6-a2ea-723bc9da6475,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-4c86b561-44fa-48f1-b535-3d50c2c3c5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-184e6d83-1335-44bc-920c-34884b3f0b55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-811992755-172.17.0.8-1595848062921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38354,DS-f0b9d471-6f71-4395-b5ff-61a8837e0e66,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-dec7220c-2d5d-496b-8810-9f551faf61d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-5812f35c-4b26-4cef-82bd-ad572def3737,DISK], DatanodeInfoWithStorage[127.0.0.1:46013,DS-34fb4cb4-96c9-4f46-83f7-91a301a01f33,DISK], DatanodeInfoWithStorage[127.0.0.1:33605,DS-b6370b90-e9b3-4c17-a10d-e143ca0a0263,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-b5f3828d-5286-42c6-a2ea-723bc9da6475,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-4c86b561-44fa-48f1-b535-3d50c2c3c5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-184e6d83-1335-44bc-920c-34884b3f0b55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-226659318-172.17.0.8-1595848366827:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34105,DS-13128e7f-195d-4a58-bc80-59f8ed3f941e,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-881948cb-9732-4c28-a291-d3b7b5e283f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-d44acb7c-f5ad-4439-8fb9-086a825394bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-72c9269f-1a95-4442-8e01-c49d0ae5b5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42199,DS-0081124a-007d-4bec-9476-3d29eba547aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35237,DS-acae1d87-5a7d-4217-88d6-6aa63a43c5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-91d18924-42e5-4342-b44d-a4df4ff2b960,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-5c277dcc-689b-4d7d-8492-1b682ff80a98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-226659318-172.17.0.8-1595848366827:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34105,DS-13128e7f-195d-4a58-bc80-59f8ed3f941e,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-881948cb-9732-4c28-a291-d3b7b5e283f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-d44acb7c-f5ad-4439-8fb9-086a825394bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-72c9269f-1a95-4442-8e01-c49d0ae5b5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42199,DS-0081124a-007d-4bec-9476-3d29eba547aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35237,DS-acae1d87-5a7d-4217-88d6-6aa63a43c5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-91d18924-42e5-4342-b44d-a4df4ff2b960,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-5c277dcc-689b-4d7d-8492-1b682ff80a98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1445540458-172.17.0.8-1595848402713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36101,DS-12da7f06-2ab0-4556-a367-554f6d6548db,DISK], DatanodeInfoWithStorage[127.0.0.1:42706,DS-dd243de3-fbd7-46e4-b87a-6e58f90b562f,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-7d40a062-0dde-4f49-a513-f194efe9fd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46309,DS-ec82f295-917d-4f82-a8c7-13718bea7f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44388,DS-a934a8e8-3fe3-4dcd-ac40-07be90a8d587,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-c2eb2569-cfa1-4ad6-ab3a-59df6f878103,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-36b7f0ca-3c64-47ee-b22d-2faef88c82b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-7be9c0bc-54a0-4220-923f-b0a629d1aa38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1445540458-172.17.0.8-1595848402713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36101,DS-12da7f06-2ab0-4556-a367-554f6d6548db,DISK], DatanodeInfoWithStorage[127.0.0.1:42706,DS-dd243de3-fbd7-46e4-b87a-6e58f90b562f,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-7d40a062-0dde-4f49-a513-f194efe9fd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46309,DS-ec82f295-917d-4f82-a8c7-13718bea7f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44388,DS-a934a8e8-3fe3-4dcd-ac40-07be90a8d587,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-c2eb2569-cfa1-4ad6-ab3a-59df6f878103,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-36b7f0ca-3c64-47ee-b22d-2faef88c82b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-7be9c0bc-54a0-4220-923f-b0a629d1aa38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1554750618-172.17.0.8-1595848437641:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45966,DS-d3b34aa8-b846-4bc3-9b05-0709025ba4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-39071745-e62e-4543-95b0-794cb6eb5132,DISK], DatanodeInfoWithStorage[127.0.0.1:35618,DS-e9ff1d7d-ed6e-45c3-97ec-f9f60f6e283f,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-0a3b01b8-6aa3-4d46-8e2a-2d5539097324,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-17f3079e-dcd5-4563-ad06-8467a33e4d10,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-60febd92-fdb0-4330-aade-f95af2fc13d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-0a4aaa6f-1ae6-4c1b-b273-b8547cdc1fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-f61efdfa-11db-4503-a402-adb6e14ae027,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1554750618-172.17.0.8-1595848437641:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45966,DS-d3b34aa8-b846-4bc3-9b05-0709025ba4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-39071745-e62e-4543-95b0-794cb6eb5132,DISK], DatanodeInfoWithStorage[127.0.0.1:35618,DS-e9ff1d7d-ed6e-45c3-97ec-f9f60f6e283f,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-0a3b01b8-6aa3-4d46-8e2a-2d5539097324,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-17f3079e-dcd5-4563-ad06-8467a33e4d10,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-60febd92-fdb0-4330-aade-f95af2fc13d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-0a4aaa6f-1ae6-4c1b-b273-b8547cdc1fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-f61efdfa-11db-4503-a402-adb6e14ae027,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-501104742-172.17.0.8-1595848510853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43533,DS-e0c7d5cd-60ad-4077-b098-7568edc79524,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-b90a694c-22fd-4fc5-aeff-72ca5e2f5db4,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-31cadb7a-5e1a-44cf-8636-6f8ea4104824,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-60f3b077-19f3-4864-a5cc-fd70241650ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-7bd163ed-6404-4bb2-a456-b6fc1eea211f,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-4cd88b9f-33ab-4eff-b8f5-0ba6e6047643,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-964fdbdf-f2f9-40c8-a93b-9f3af86542fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-8f9ba1ef-31d9-44e1-955a-6ca9d09c9bc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-501104742-172.17.0.8-1595848510853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43533,DS-e0c7d5cd-60ad-4077-b098-7568edc79524,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-b90a694c-22fd-4fc5-aeff-72ca5e2f5db4,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-31cadb7a-5e1a-44cf-8636-6f8ea4104824,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-60f3b077-19f3-4864-a5cc-fd70241650ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-7bd163ed-6404-4bb2-a456-b6fc1eea211f,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-4cd88b9f-33ab-4eff-b8f5-0ba6e6047643,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-964fdbdf-f2f9-40c8-a93b-9f3af86542fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-8f9ba1ef-31d9-44e1-955a-6ca9d09c9bc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1610331435-172.17.0.8-1595848762078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46357,DS-9adcea68-fda8-4d7e-a493-610ffc0644b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-51fc379c-f6cd-4842-bbb0-210e7d02602f,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-4e613479-ca18-4456-b3ca-ccef3e77fb52,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-70db0947-1454-41af-82d2-dd176dc23fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43410,DS-1f6a8a17-e268-4a14-b090-ecf9ab9cb259,DISK], DatanodeInfoWithStorage[127.0.0.1:39463,DS-2a6b383a-ac41-4e34-b628-c9e47b5e1055,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-423e745b-b125-45d8-8af6-9037a91ba240,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-e40e58a3-884e-4376-bf71-620cbdd0923d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1610331435-172.17.0.8-1595848762078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46357,DS-9adcea68-fda8-4d7e-a493-610ffc0644b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-51fc379c-f6cd-4842-bbb0-210e7d02602f,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-4e613479-ca18-4456-b3ca-ccef3e77fb52,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-70db0947-1454-41af-82d2-dd176dc23fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43410,DS-1f6a8a17-e268-4a14-b090-ecf9ab9cb259,DISK], DatanodeInfoWithStorage[127.0.0.1:39463,DS-2a6b383a-ac41-4e34-b628-c9e47b5e1055,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-423e745b-b125-45d8-8af6-9037a91ba240,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-e40e58a3-884e-4376-bf71-620cbdd0923d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1326034569-172.17.0.8-1595848833396:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42501,DS-9f5d634e-496c-4099-bb4f-572b8490e90b,DISK], DatanodeInfoWithStorage[127.0.0.1:38095,DS-1fdfca54-0bde-4e89-9464-670d62f67b04,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-152babc6-5467-411b-9be2-d0a90d6ab878,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-1bf9093c-c624-4360-a0d3-260aed47fefa,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-56de4754-4bcb-4754-a0e5-d2b0d0dba805,DISK], DatanodeInfoWithStorage[127.0.0.1:46481,DS-cdf2d4e7-b008-46e0-9fe8-12ca19c60dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-3b2ee549-b736-4320-8522-ce2141cd850b,DISK], DatanodeInfoWithStorage[127.0.0.1:37503,DS-da9fa758-2722-4dd3-a67b-344a46050e6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1326034569-172.17.0.8-1595848833396:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42501,DS-9f5d634e-496c-4099-bb4f-572b8490e90b,DISK], DatanodeInfoWithStorage[127.0.0.1:38095,DS-1fdfca54-0bde-4e89-9464-670d62f67b04,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-152babc6-5467-411b-9be2-d0a90d6ab878,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-1bf9093c-c624-4360-a0d3-260aed47fefa,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-56de4754-4bcb-4754-a0e5-d2b0d0dba805,DISK], DatanodeInfoWithStorage[127.0.0.1:46481,DS-cdf2d4e7-b008-46e0-9fe8-12ca19c60dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-3b2ee549-b736-4320-8522-ce2141cd850b,DISK], DatanodeInfoWithStorage[127.0.0.1:37503,DS-da9fa758-2722-4dd3-a67b-344a46050e6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-411067627-172.17.0.8-1595848897154:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38981,DS-2c7580d0-988e-453e-b5a5-6ac90f35a4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-2c8c6187-b2cb-4911-8864-f33ea57dacdd,DISK], DatanodeInfoWithStorage[127.0.0.1:42443,DS-f99fd3d0-f0e2-4846-8be0-c50ec4fb034d,DISK], DatanodeInfoWithStorage[127.0.0.1:38523,DS-ede2e4f2-385a-4365-a2ac-652ad48fbaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-7108de6f-a89f-4ed5-aed5-5e38aa77a33d,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-fd08ae35-a8e1-491d-897b-c76b440b5806,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-95645572-87ba-4181-80b1-4a602be3b978,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-90e57745-8a58-42d1-84f2-f0a25829091c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-411067627-172.17.0.8-1595848897154:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38981,DS-2c7580d0-988e-453e-b5a5-6ac90f35a4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-2c8c6187-b2cb-4911-8864-f33ea57dacdd,DISK], DatanodeInfoWithStorage[127.0.0.1:42443,DS-f99fd3d0-f0e2-4846-8be0-c50ec4fb034d,DISK], DatanodeInfoWithStorage[127.0.0.1:38523,DS-ede2e4f2-385a-4365-a2ac-652ad48fbaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-7108de6f-a89f-4ed5-aed5-5e38aa77a33d,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-fd08ae35-a8e1-491d-897b-c76b440b5806,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-95645572-87ba-4181-80b1-4a602be3b978,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-90e57745-8a58-42d1-84f2-f0a25829091c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5417
