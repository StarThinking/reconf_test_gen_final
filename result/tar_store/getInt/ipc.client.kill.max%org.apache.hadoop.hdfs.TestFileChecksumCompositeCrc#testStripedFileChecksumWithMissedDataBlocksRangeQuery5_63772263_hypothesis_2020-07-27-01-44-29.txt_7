reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2077675534-172.17.0.3-1595814666360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34092,DS-fe41bb4c-7c2a-49b5-a838-0043de45ecb7,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-3ebb411a-b7f7-4ced-873b-11893404df1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-1321a8fd-1472-49ed-8eca-03337a2f6907,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-ede3e1b3-3a35-4724-8b73-27f4fbc534f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-68a6e3a7-ce6f-4514-b51c-17f17aa4696a,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-cc51ac72-41d1-400c-be18-11497a07112d,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-b14be335-62db-4539-829f-7a3b4fed7644,DISK], DatanodeInfoWithStorage[127.0.0.1:36406,DS-3d64a476-046b-4a20-b7af-40a6ce7f6e6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2077675534-172.17.0.3-1595814666360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34092,DS-fe41bb4c-7c2a-49b5-a838-0043de45ecb7,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-3ebb411a-b7f7-4ced-873b-11893404df1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-1321a8fd-1472-49ed-8eca-03337a2f6907,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-ede3e1b3-3a35-4724-8b73-27f4fbc534f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-68a6e3a7-ce6f-4514-b51c-17f17aa4696a,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-cc51ac72-41d1-400c-be18-11497a07112d,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-b14be335-62db-4539-829f-7a3b4fed7644,DISK], DatanodeInfoWithStorage[127.0.0.1:36406,DS-3d64a476-046b-4a20-b7af-40a6ce7f6e6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-230492493-172.17.0.3-1595814814635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40237,DS-96e9967e-cf3a-474b-a915-ff92e9f22157,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-a951677f-e958-4340-930c-a4133b6a8796,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-1eb94008-ca5b-4214-9c4c-9b20a07711ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43223,DS-985ab85d-4dff-4ab0-93e8-64cae2e9ef2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-8b27dc49-484e-450e-8454-a9413571bad5,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-44318111-df84-48d8-ba49-610473bba470,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-10737267-3677-451b-a316-c1baa56372ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-7f615088-6ee9-4688-81e7-104d4eec6623,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-230492493-172.17.0.3-1595814814635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40237,DS-96e9967e-cf3a-474b-a915-ff92e9f22157,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-a951677f-e958-4340-930c-a4133b6a8796,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-1eb94008-ca5b-4214-9c4c-9b20a07711ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43223,DS-985ab85d-4dff-4ab0-93e8-64cae2e9ef2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-8b27dc49-484e-450e-8454-a9413571bad5,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-44318111-df84-48d8-ba49-610473bba470,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-10737267-3677-451b-a316-c1baa56372ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-7f615088-6ee9-4688-81e7-104d4eec6623,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1485233564-172.17.0.3-1595814854709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36511,DS-adae7533-9973-42bb-a184-87197063968a,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-40c7d8a9-69e1-4427-ba4c-cb841963d058,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-7040d745-8e3a-4de6-a894-4ed7f94b091f,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-44861299-9813-4fac-93b9-a7c4045d5ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-f66c3918-5e0f-42cf-b73e-1704e0516828,DISK], DatanodeInfoWithStorage[127.0.0.1:37355,DS-2e05ff61-c4f2-4a5e-b5db-f32e3a3ba6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-f46c7d12-d60e-4798-b4de-4a3b9593946f,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-5ab4ce5a-6c5b-41d6-b28e-6c44536727fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1485233564-172.17.0.3-1595814854709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36511,DS-adae7533-9973-42bb-a184-87197063968a,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-40c7d8a9-69e1-4427-ba4c-cb841963d058,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-7040d745-8e3a-4de6-a894-4ed7f94b091f,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-44861299-9813-4fac-93b9-a7c4045d5ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-f66c3918-5e0f-42cf-b73e-1704e0516828,DISK], DatanodeInfoWithStorage[127.0.0.1:37355,DS-2e05ff61-c4f2-4a5e-b5db-f32e3a3ba6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-f46c7d12-d60e-4798-b4de-4a3b9593946f,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-5ab4ce5a-6c5b-41d6-b28e-6c44536727fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1294060774-172.17.0.3-1595815036940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42481,DS-29e56b04-4a75-4365-9f44-5455e2ac4b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-0e50dcad-93c3-4cdf-a1b4-e67ef9bb7f68,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-ab7c0d16-b215-4540-a3d9-11bdabe52ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:41590,DS-b6005b7f-8f16-4ef3-bf8d-ba1f88160227,DISK], DatanodeInfoWithStorage[127.0.0.1:44965,DS-ee98d188-90ac-49ef-aea2-6fd7d7476075,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-73bc4e99-ecb7-4356-9a9f-26dcea140836,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-578920d7-aa9a-4fcd-b3d1-415d204e2e75,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-6947c56f-e6ca-4533-af1b-3fb1a9274a4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1294060774-172.17.0.3-1595815036940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42481,DS-29e56b04-4a75-4365-9f44-5455e2ac4b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-0e50dcad-93c3-4cdf-a1b4-e67ef9bb7f68,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-ab7c0d16-b215-4540-a3d9-11bdabe52ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:41590,DS-b6005b7f-8f16-4ef3-bf8d-ba1f88160227,DISK], DatanodeInfoWithStorage[127.0.0.1:44965,DS-ee98d188-90ac-49ef-aea2-6fd7d7476075,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-73bc4e99-ecb7-4356-9a9f-26dcea140836,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-578920d7-aa9a-4fcd-b3d1-415d204e2e75,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-6947c56f-e6ca-4533-af1b-3fb1a9274a4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1597876502-172.17.0.3-1595816033846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39119,DS-4303e363-1c1a-4cc5-b4cc-a375d65bccac,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-8d25a92c-249f-4d66-b385-a3675caa1625,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-e72a20f6-f600-4fb5-90c5-b39de8ae01fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-f91f9493-cc89-44b6-95b2-7ae4d227dbee,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-c5157866-44ea-4d9c-a817-e25089781386,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-87e93194-6bb3-447c-b02f-4aaa2d81f2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-bc313349-f375-4fd4-9a5e-adeeaf5f7bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-d4a68d73-e85e-4d5f-bd01-712dcc087722,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1597876502-172.17.0.3-1595816033846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39119,DS-4303e363-1c1a-4cc5-b4cc-a375d65bccac,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-8d25a92c-249f-4d66-b385-a3675caa1625,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-e72a20f6-f600-4fb5-90c5-b39de8ae01fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-f91f9493-cc89-44b6-95b2-7ae4d227dbee,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-c5157866-44ea-4d9c-a817-e25089781386,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-87e93194-6bb3-447c-b02f-4aaa2d81f2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-bc313349-f375-4fd4-9a5e-adeeaf5f7bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-d4a68d73-e85e-4d5f-bd01-712dcc087722,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144849043-172.17.0.3-1595816206703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42730,DS-4240c225-ed90-4b49-bd33-7aa3b01dc516,DISK], DatanodeInfoWithStorage[127.0.0.1:45471,DS-ab6bab82-fae6-48d3-9c9f-a9e10752c3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-fb270d66-9c7f-49e3-9a1c-48a40c5e4588,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-df75ca2d-77cf-49ad-b980-da47604e0205,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-466480b3-9aff-4942-97a3-4786370b1e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-7ffc3111-7d0b-4f5c-838a-e61d6f5f760a,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-3d252983-5436-4ede-bb0f-749bd557adcf,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-a93ebff8-efda-4fd3-bafb-b38f9bfcb3a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144849043-172.17.0.3-1595816206703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42730,DS-4240c225-ed90-4b49-bd33-7aa3b01dc516,DISK], DatanodeInfoWithStorage[127.0.0.1:45471,DS-ab6bab82-fae6-48d3-9c9f-a9e10752c3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-fb270d66-9c7f-49e3-9a1c-48a40c5e4588,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-df75ca2d-77cf-49ad-b980-da47604e0205,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-466480b3-9aff-4942-97a3-4786370b1e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-7ffc3111-7d0b-4f5c-838a-e61d6f5f760a,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-3d252983-5436-4ede-bb0f-749bd557adcf,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-a93ebff8-efda-4fd3-bafb-b38f9bfcb3a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1730969945-172.17.0.3-1595816417501:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40850,DS-e13a3e86-f93e-4ba5-b80b-8d3e61b035cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-783d8014-72ba-4135-962e-a8074c4ee513,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-90281e05-436f-4c35-8393-a0017246d6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-2152c2e4-2904-441e-9e03-70b4691cd217,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-495042b4-2fb7-440c-a129-e3d86f7d7739,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-82249076-5e9b-43e4-bbd6-335d13943db9,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-1d998c11-559f-414a-a811-5318de3315d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-fe3bc6ed-00b1-43fd-b91f-bb00af7f6390,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1730969945-172.17.0.3-1595816417501:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40850,DS-e13a3e86-f93e-4ba5-b80b-8d3e61b035cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-783d8014-72ba-4135-962e-a8074c4ee513,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-90281e05-436f-4c35-8393-a0017246d6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-2152c2e4-2904-441e-9e03-70b4691cd217,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-495042b4-2fb7-440c-a129-e3d86f7d7739,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-82249076-5e9b-43e4-bbd6-335d13943db9,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-1d998c11-559f-414a-a811-5318de3315d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-fe3bc6ed-00b1-43fd-b91f-bb00af7f6390,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1610832128-172.17.0.3-1595816747047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46641,DS-3ca79c74-45e0-483a-a574-5fa4a233bb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-6339ce8b-43d4-4a4c-8a60-ff39f83407e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-458f954d-2abb-4b79-bab0-838867ac5c16,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-ce1388e3-534a-49f3-90a1-88fed0d74175,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-f6dde6f5-c908-4cd1-a260-42ec4fbe97e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-e986036b-a46c-49c7-acb3-af48fcf225a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-7bf0230f-56a4-48fc-813c-8cb27a80c18f,DISK], DatanodeInfoWithStorage[127.0.0.1:44060,DS-5409d1d3-aca4-40a6-b93a-d10c1fe6d956,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1610832128-172.17.0.3-1595816747047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46641,DS-3ca79c74-45e0-483a-a574-5fa4a233bb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-6339ce8b-43d4-4a4c-8a60-ff39f83407e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-458f954d-2abb-4b79-bab0-838867ac5c16,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-ce1388e3-534a-49f3-90a1-88fed0d74175,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-f6dde6f5-c908-4cd1-a260-42ec4fbe97e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-e986036b-a46c-49c7-acb3-af48fcf225a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-7bf0230f-56a4-48fc-813c-8cb27a80c18f,DISK], DatanodeInfoWithStorage[127.0.0.1:44060,DS-5409d1d3-aca4-40a6-b93a-d10c1fe6d956,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-856975523-172.17.0.3-1595817122957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39249,DS-94de89c9-c541-4669-80a5-a942f387a27f,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-f01f9477-665e-49aa-890b-29aa5fe7a85a,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-4491b2bb-b931-44e2-9c4f-028292652ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-d6c2e67e-bf4c-4f2e-96e3-5c15918953c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-3fde560e-7b22-4193-90ed-54b21d2dfbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-600bef5d-d3ba-4728-8d29-bc81068f4267,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-e17f8c5b-9dd9-44bc-9217-fb7392b281ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-30f3bc5f-e8da-4c6c-8ba0-eff59b501b31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-856975523-172.17.0.3-1595817122957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39249,DS-94de89c9-c541-4669-80a5-a942f387a27f,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-f01f9477-665e-49aa-890b-29aa5fe7a85a,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-4491b2bb-b931-44e2-9c4f-028292652ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-d6c2e67e-bf4c-4f2e-96e3-5c15918953c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-3fde560e-7b22-4193-90ed-54b21d2dfbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-600bef5d-d3ba-4728-8d29-bc81068f4267,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-e17f8c5b-9dd9-44bc-9217-fb7392b281ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-30f3bc5f-e8da-4c6c-8ba0-eff59b501b31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1443519697-172.17.0.3-1595817365200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38865,DS-78e05d50-7d8e-4974-be21-ed71e5576e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-f29d4f54-7baa-4522-bbb3-b93ce1fddac9,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-6e5f69c0-c4db-4546-9c8f-605477448fda,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-284a9efb-da89-469b-a490-6cc4692a0866,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-d34d08e6-4361-4f13-b05d-70f1c508a143,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-febaadae-c6dd-458b-9daa-ffca284e7d36,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-11240ad9-d8ab-47da-a382-eaa5ee11643d,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-d4ffa385-4ed0-4248-983c-5a066d9c858d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1443519697-172.17.0.3-1595817365200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38865,DS-78e05d50-7d8e-4974-be21-ed71e5576e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-f29d4f54-7baa-4522-bbb3-b93ce1fddac9,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-6e5f69c0-c4db-4546-9c8f-605477448fda,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-284a9efb-da89-469b-a490-6cc4692a0866,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-d34d08e6-4361-4f13-b05d-70f1c508a143,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-febaadae-c6dd-458b-9daa-ffca284e7d36,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-11240ad9-d8ab-47da-a382-eaa5ee11643d,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-d4ffa385-4ed0-4248-983c-5a066d9c858d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1742460926-172.17.0.3-1595817657284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37551,DS-7f3e5690-3245-4808-a127-257f680249c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35342,DS-12f55992-fed3-4165-9677-4de07b81807e,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-57227155-989f-4039-a981-b0890041e01e,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-5f093fbf-21f9-4788-8b10-2abd2e923745,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-6126a7fa-82ab-46ab-853a-3a65e2c20e97,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-de67624d-5bde-43f1-be89-d90c1496cc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44793,DS-9247d5ef-89ac-4816-b439-c05dfb59702c,DISK], DatanodeInfoWithStorage[127.0.0.1:38302,DS-679c55ca-bdc3-47e8-bf89-84274e0907a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1742460926-172.17.0.3-1595817657284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37551,DS-7f3e5690-3245-4808-a127-257f680249c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35342,DS-12f55992-fed3-4165-9677-4de07b81807e,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-57227155-989f-4039-a981-b0890041e01e,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-5f093fbf-21f9-4788-8b10-2abd2e923745,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-6126a7fa-82ab-46ab-853a-3a65e2c20e97,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-de67624d-5bde-43f1-be89-d90c1496cc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44793,DS-9247d5ef-89ac-4816-b439-c05dfb59702c,DISK], DatanodeInfoWithStorage[127.0.0.1:38302,DS-679c55ca-bdc3-47e8-bf89-84274e0907a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-602535073-172.17.0.3-1595817693540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40562,DS-70ab97d4-d09c-4f36-9b22-814abc808bac,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-ebc42a70-e59f-4488-9987-85ecf1cf9a64,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-653dec75-3910-4b92-badb-2070c50fe82d,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-12e5aceb-1b7a-4663-9574-9231b7776e08,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-e4f2bacd-3cd8-453a-a986-8e1135f21777,DISK], DatanodeInfoWithStorage[127.0.0.1:41322,DS-1195c7eb-33d8-488a-8cc9-7461cb530312,DISK], DatanodeInfoWithStorage[127.0.0.1:34400,DS-ba7282db-01d3-417a-9603-31934e4a9581,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-cbc5cb0d-8ddf-49d3-914c-d77057a713e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-602535073-172.17.0.3-1595817693540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40562,DS-70ab97d4-d09c-4f36-9b22-814abc808bac,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-ebc42a70-e59f-4488-9987-85ecf1cf9a64,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-653dec75-3910-4b92-badb-2070c50fe82d,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-12e5aceb-1b7a-4663-9574-9231b7776e08,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-e4f2bacd-3cd8-453a-a986-8e1135f21777,DISK], DatanodeInfoWithStorage[127.0.0.1:41322,DS-1195c7eb-33d8-488a-8cc9-7461cb530312,DISK], DatanodeInfoWithStorage[127.0.0.1:34400,DS-ba7282db-01d3-417a-9603-31934e4a9581,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-cbc5cb0d-8ddf-49d3-914c-d77057a713e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-997625356-172.17.0.3-1595817910358:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38107,DS-c3fb7133-1e6c-4114-939b-4f4f67ea100b,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-9f6a42ca-3c20-48ce-a459-e2072b8fe3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-86d40b10-79f6-47d2-8647-38e22972236b,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-efe1c427-6155-451e-9452-00a10351a4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-d6a23a9d-1b0e-47ee-97a6-7946131ad2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-d1c0e042-3ea3-48e6-b1d1-6663b7a06346,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-de30ba50-2352-4295-989d-7c3dccdbdee2,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-660725b0-fe2f-438d-a20b-84ea05f93b3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-997625356-172.17.0.3-1595817910358:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38107,DS-c3fb7133-1e6c-4114-939b-4f4f67ea100b,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-9f6a42ca-3c20-48ce-a459-e2072b8fe3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-86d40b10-79f6-47d2-8647-38e22972236b,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-efe1c427-6155-451e-9452-00a10351a4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-d6a23a9d-1b0e-47ee-97a6-7946131ad2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-d1c0e042-3ea3-48e6-b1d1-6663b7a06346,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-de30ba50-2352-4295-989d-7c3dccdbdee2,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-660725b0-fe2f-438d-a20b-84ea05f93b3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2056336690-172.17.0.3-1595818366201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36876,DS-49b3b2bd-f276-44b4-91a9-f5b42b33045b,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-6bf88054-d592-4724-b1e3-7c7b99c20e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-ceaf40b1-eb1d-471e-96e8-8e9016fdcd60,DISK], DatanodeInfoWithStorage[127.0.0.1:42668,DS-acbe38a8-261b-4b64-8273-d20ee55506c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-51c85493-2c83-4086-b483-16d2f342a3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-b8eefa1d-ad6d-4603-b2c5-7978ff1ef2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-5fdb0783-6df5-49ef-813f-be46978a33a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-fd63b7e3-7b1c-412e-af06-28318a69552b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2056336690-172.17.0.3-1595818366201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36876,DS-49b3b2bd-f276-44b4-91a9-f5b42b33045b,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-6bf88054-d592-4724-b1e3-7c7b99c20e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-ceaf40b1-eb1d-471e-96e8-8e9016fdcd60,DISK], DatanodeInfoWithStorage[127.0.0.1:42668,DS-acbe38a8-261b-4b64-8273-d20ee55506c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-51c85493-2c83-4086-b483-16d2f342a3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-b8eefa1d-ad6d-4603-b2c5-7978ff1ef2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-5fdb0783-6df5-49ef-813f-be46978a33a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-fd63b7e3-7b1c-412e-af06-28318a69552b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1819223338-172.17.0.3-1595818442759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35819,DS-7ccae4e9-6c39-483e-add8-e87bf0671652,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-62079766-61f3-451d-87a6-f4b4431cf116,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-7b71b7d5-fa06-49a5-97d4-b5c1203786a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40178,DS-73957e1c-a6cc-41f5-83ed-828f6bfb61d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42189,DS-44f0331d-5040-4b6d-8870-ddb1533bb33f,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-db01a119-4423-4127-9962-543230d83b05,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-69d9e091-0bf4-4b27-a8a8-b5b0e1f55826,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-2ea24eb9-1853-47cf-8a3c-de64032f2366,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1819223338-172.17.0.3-1595818442759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35819,DS-7ccae4e9-6c39-483e-add8-e87bf0671652,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-62079766-61f3-451d-87a6-f4b4431cf116,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-7b71b7d5-fa06-49a5-97d4-b5c1203786a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40178,DS-73957e1c-a6cc-41f5-83ed-828f6bfb61d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42189,DS-44f0331d-5040-4b6d-8870-ddb1533bb33f,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-db01a119-4423-4127-9962-543230d83b05,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-69d9e091-0bf4-4b27-a8a8-b5b0e1f55826,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-2ea24eb9-1853-47cf-8a3c-de64032f2366,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-78095735-172.17.0.3-1595818590444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37600,DS-f0c6726d-d058-49b1-bc04-a5e3e7885ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-8135186b-e084-4a36-be13-b23e1f7fd065,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-7c736ce4-e48c-47b7-9f9b-4ba79a7313e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-5185a71c-4e6a-4fa3-97c5-7a33a7873fce,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-001bb955-9f28-4cfa-b2f0-59f90101dae8,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-290363b6-0ea9-46aa-8497-da93a531ff11,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-788a1b16-6e97-4585-8c01-844a46b8847b,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-edf2fd7f-6518-4e96-a182-e21b993a6876,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-78095735-172.17.0.3-1595818590444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37600,DS-f0c6726d-d058-49b1-bc04-a5e3e7885ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-8135186b-e084-4a36-be13-b23e1f7fd065,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-7c736ce4-e48c-47b7-9f9b-4ba79a7313e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-5185a71c-4e6a-4fa3-97c5-7a33a7873fce,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-001bb955-9f28-4cfa-b2f0-59f90101dae8,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-290363b6-0ea9-46aa-8497-da93a531ff11,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-788a1b16-6e97-4585-8c01-844a46b8847b,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-edf2fd7f-6518-4e96-a182-e21b993a6876,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1839940606-172.17.0.3-1595818784582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44717,DS-5ebee5d4-3913-4fc2-a4b5-c0c103aa9442,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-371b9fc9-fd62-43f2-85d5-15db150a22fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-b5937b7d-a17f-459d-a620-a8dc6e930e87,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-ad786626-c84e-48dd-8b86-ee8a4d0de8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-786144b0-2dff-4846-8751-a94debb71c92,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-7830ddf6-719a-4a76-bc24-f7215aeacb07,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-44c18290-2b29-44f3-ac81-6a338268ed3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37625,DS-f2aefc85-4de0-4bac-b116-cfb51c566a46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1839940606-172.17.0.3-1595818784582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44717,DS-5ebee5d4-3913-4fc2-a4b5-c0c103aa9442,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-371b9fc9-fd62-43f2-85d5-15db150a22fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-b5937b7d-a17f-459d-a620-a8dc6e930e87,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-ad786626-c84e-48dd-8b86-ee8a4d0de8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-786144b0-2dff-4846-8751-a94debb71c92,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-7830ddf6-719a-4a76-bc24-f7215aeacb07,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-44c18290-2b29-44f3-ac81-6a338268ed3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37625,DS-f2aefc85-4de0-4bac-b116-cfb51c566a46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930128669-172.17.0.3-1595818816782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45295,DS-2f941853-d69f-4671-8e7c-2c33e0a80238,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-b1a5c4e8-1b67-4134-bcfa-6553de4cc2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41966,DS-93434276-fcf8-4db3-98b0-8acaa3a01c62,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-974cb931-a494-492f-b6c3-02fbd9fe6988,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-38630c55-b637-40ca-a5ff-bf86742422be,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-dcf6d15a-c84f-4434-a3e1-6d3f5a6a7f84,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-5487017f-ea8e-4c5c-9a11-6018879c3dab,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-2ffe8173-1646-4944-bbd6-393ea1238b1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930128669-172.17.0.3-1595818816782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45295,DS-2f941853-d69f-4671-8e7c-2c33e0a80238,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-b1a5c4e8-1b67-4134-bcfa-6553de4cc2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41966,DS-93434276-fcf8-4db3-98b0-8acaa3a01c62,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-974cb931-a494-492f-b6c3-02fbd9fe6988,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-38630c55-b637-40ca-a5ff-bf86742422be,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-dcf6d15a-c84f-4434-a3e1-6d3f5a6a7f84,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-5487017f-ea8e-4c5c-9a11-6018879c3dab,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-2ffe8173-1646-4944-bbd6-393ea1238b1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-480732612-172.17.0.3-1595819588227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39988,DS-0339c225-0bcc-41b4-bc57-d90597d09292,DISK], DatanodeInfoWithStorage[127.0.0.1:38295,DS-400d4270-93ce-4928-8173-616dfb1422f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-e28044f1-2a53-461b-b7e2-4b22400681aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-3e586cf1-443c-4b9f-b577-09eb0fb770ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-10650549-2962-4649-91bf-406f2e6bb719,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-1db26161-9dc2-4918-8681-1bdcbc2841af,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-ace447b5-07c3-4e0c-83c8-9b7313c72f80,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-c866093a-226b-4329-b40e-aa222db8a330,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-480732612-172.17.0.3-1595819588227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39988,DS-0339c225-0bcc-41b4-bc57-d90597d09292,DISK], DatanodeInfoWithStorage[127.0.0.1:38295,DS-400d4270-93ce-4928-8173-616dfb1422f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-e28044f1-2a53-461b-b7e2-4b22400681aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-3e586cf1-443c-4b9f-b577-09eb0fb770ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-10650549-2962-4649-91bf-406f2e6bb719,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-1db26161-9dc2-4918-8681-1bdcbc2841af,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-ace447b5-07c3-4e0c-83c8-9b7313c72f80,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-c866093a-226b-4329-b40e-aa222db8a330,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5441
