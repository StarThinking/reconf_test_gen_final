reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1594337889-172.17.0.5-1595836548226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37604,DS-b58fb18c-b127-43fb-9e24-78975b6144ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-7f7993cb-d9a3-4eea-90a3-a077e0a7c723,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-60c3f459-619e-437a-9738-477b539ccf35,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-d4892222-7af1-41b1-8b1c-4edd9cc3b50e,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-44832369-f42a-4e2d-8d27-281629ae2cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-1d9e1aa4-66dd-4900-a212-ae4ce1d92851,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-a7be7bf8-4f6b-4c79-8571-9f0aee2d4fef,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-adebd82c-a0b8-4dbb-9ff0-2e46cabfbac2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1594337889-172.17.0.5-1595836548226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37604,DS-b58fb18c-b127-43fb-9e24-78975b6144ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-7f7993cb-d9a3-4eea-90a3-a077e0a7c723,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-60c3f459-619e-437a-9738-477b539ccf35,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-d4892222-7af1-41b1-8b1c-4edd9cc3b50e,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-44832369-f42a-4e2d-8d27-281629ae2cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-1d9e1aa4-66dd-4900-a212-ae4ce1d92851,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-a7be7bf8-4f6b-4c79-8571-9f0aee2d4fef,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-adebd82c-a0b8-4dbb-9ff0-2e46cabfbac2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1171610977-172.17.0.5-1595836589706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46023,DS-b2676fe7-1d32-4fe4-bd92-3c5afb3be0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44922,DS-29896b68-7d6f-44ba-b2f0-73a894e01eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-861b547a-5093-423e-95b4-5337c025649d,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-a0a82511-73a0-4441-a954-88a1cce97e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-12c1380d-fc97-4b3f-b9b5-084094eeb5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-af32697b-667d-4d62-ace5-e2ae27f0c9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-0f57899f-61c3-428e-b2c3-da58ba6fdce0,DISK], DatanodeInfoWithStorage[127.0.0.1:39812,DS-62adc76b-a731-4aed-b53f-882f9d173954,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1171610977-172.17.0.5-1595836589706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46023,DS-b2676fe7-1d32-4fe4-bd92-3c5afb3be0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44922,DS-29896b68-7d6f-44ba-b2f0-73a894e01eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-861b547a-5093-423e-95b4-5337c025649d,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-a0a82511-73a0-4441-a954-88a1cce97e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-12c1380d-fc97-4b3f-b9b5-084094eeb5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-af32697b-667d-4d62-ace5-e2ae27f0c9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-0f57899f-61c3-428e-b2c3-da58ba6fdce0,DISK], DatanodeInfoWithStorage[127.0.0.1:39812,DS-62adc76b-a731-4aed-b53f-882f9d173954,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1665952197-172.17.0.5-1595837134486:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46550,DS-5bd3f7eb-4507-4a3f-a516-fdec146274d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-2081c634-305a-449f-a905-259fa9a2087e,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-f939b1f2-7d25-4694-a59b-9d4be6ddef9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-0ffe4eb6-e08f-4774-b1e2-9bc07e4889df,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-000aac60-bad0-48c7-b1d9-3137899bea7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-6d6c2d8c-09d2-4e56-9d30-f395377d57d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-e68225ae-d83c-4f1f-9509-cd4173b616fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35857,DS-ac6c5752-57f7-4915-ab04-33e9a5fb4a62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1665952197-172.17.0.5-1595837134486:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46550,DS-5bd3f7eb-4507-4a3f-a516-fdec146274d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-2081c634-305a-449f-a905-259fa9a2087e,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-f939b1f2-7d25-4694-a59b-9d4be6ddef9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-0ffe4eb6-e08f-4774-b1e2-9bc07e4889df,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-000aac60-bad0-48c7-b1d9-3137899bea7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-6d6c2d8c-09d2-4e56-9d30-f395377d57d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-e68225ae-d83c-4f1f-9509-cd4173b616fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35857,DS-ac6c5752-57f7-4915-ab04-33e9a5fb4a62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-742812029-172.17.0.5-1595837405330:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36476,DS-e4f71858-c261-4e8f-89f9-5e12f9eaa50b,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-a8dbfb07-5265-4ef2-a7f3-df988e75a516,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-cde9972b-9815-458d-9d84-53fa0d314abf,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-9e1790f6-1f8b-4e74-87ca-4d495d052da0,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-ff37928d-61d5-478f-a0fd-7edeb4f7c5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46050,DS-dae92fad-2c16-4460-aec5-c41bd21b91ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-f697ac8f-175a-485c-b91e-8563c32b2197,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-3f13ede9-abdc-4666-993e-4fefd5e3c2f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-742812029-172.17.0.5-1595837405330:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36476,DS-e4f71858-c261-4e8f-89f9-5e12f9eaa50b,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-a8dbfb07-5265-4ef2-a7f3-df988e75a516,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-cde9972b-9815-458d-9d84-53fa0d314abf,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-9e1790f6-1f8b-4e74-87ca-4d495d052da0,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-ff37928d-61d5-478f-a0fd-7edeb4f7c5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46050,DS-dae92fad-2c16-4460-aec5-c41bd21b91ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-f697ac8f-175a-485c-b91e-8563c32b2197,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-3f13ede9-abdc-4666-993e-4fefd5e3c2f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-656860590-172.17.0.5-1595837900961:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34370,DS-57f8286d-c88e-4cb1-9c88-d3b12dddbcd9,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-40e3e848-9969-4eb8-9827-346bea9daae5,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-b4464d58-2889-457a-bec3-214e2d1d9f06,DISK], DatanodeInfoWithStorage[127.0.0.1:37796,DS-aac2f80b-e106-4457-bf0a-2aea5a10c28d,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-96f224be-4936-4da0-a6b6-b3d344a41886,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-c29442b7-4c77-49b0-86ac-898d7757d6db,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-40c9abf2-d96f-4257-ad49-24d1307debbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-1ed1ec2b-5090-486d-84be-c5a182aa53a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-656860590-172.17.0.5-1595837900961:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34370,DS-57f8286d-c88e-4cb1-9c88-d3b12dddbcd9,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-40e3e848-9969-4eb8-9827-346bea9daae5,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-b4464d58-2889-457a-bec3-214e2d1d9f06,DISK], DatanodeInfoWithStorage[127.0.0.1:37796,DS-aac2f80b-e106-4457-bf0a-2aea5a10c28d,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-96f224be-4936-4da0-a6b6-b3d344a41886,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-c29442b7-4c77-49b0-86ac-898d7757d6db,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-40c9abf2-d96f-4257-ad49-24d1307debbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-1ed1ec2b-5090-486d-84be-c5a182aa53a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-958261084-172.17.0.5-1595837978007:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42792,DS-e0904b01-9447-4375-bf58-6af62392dc9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-1ce266d3-803f-45d9-b957-289c3d6371c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42705,DS-0595b327-366b-4715-badd-17c944600cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:44273,DS-2344d9cb-735b-4c1f-86b3-31fb821a5e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45723,DS-37e2eba3-ecd0-4a11-84ec-43375502150f,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-19921970-4860-4005-a352-bee3a651ffea,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-13f645d3-956c-47aa-b9db-ed1d410b3622,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-4cf7d949-f773-41e5-991c-081e18b5008e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-958261084-172.17.0.5-1595837978007:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42792,DS-e0904b01-9447-4375-bf58-6af62392dc9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-1ce266d3-803f-45d9-b957-289c3d6371c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42705,DS-0595b327-366b-4715-badd-17c944600cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:44273,DS-2344d9cb-735b-4c1f-86b3-31fb821a5e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45723,DS-37e2eba3-ecd0-4a11-84ec-43375502150f,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-19921970-4860-4005-a352-bee3a651ffea,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-13f645d3-956c-47aa-b9db-ed1d410b3622,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-4cf7d949-f773-41e5-991c-081e18b5008e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-69866379-172.17.0.5-1595838257525:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41744,DS-962cb898-8924-48b2-b167-abdea96d3e27,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-9c2e2dd3-4f94-40b1-a6c4-c28b01033e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-3a26e2a6-5a0b-4ea0-aed7-369dcb9fc694,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-0008cc8e-6cfd-40f9-902f-7ace8afa0d55,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-9133eca0-c268-4f35-8978-2e5d93470050,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-b28ab697-f2b9-4421-a460-71f013edfd59,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-94441275-3921-4cd8-aa0a-c58202f3c82d,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-522edf0b-d80d-4f9d-bfee-fcb55a757159,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-69866379-172.17.0.5-1595838257525:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41744,DS-962cb898-8924-48b2-b167-abdea96d3e27,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-9c2e2dd3-4f94-40b1-a6c4-c28b01033e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-3a26e2a6-5a0b-4ea0-aed7-369dcb9fc694,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-0008cc8e-6cfd-40f9-902f-7ace8afa0d55,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-9133eca0-c268-4f35-8978-2e5d93470050,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-b28ab697-f2b9-4421-a460-71f013edfd59,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-94441275-3921-4cd8-aa0a-c58202f3c82d,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-522edf0b-d80d-4f9d-bfee-fcb55a757159,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1064073931-172.17.0.5-1595839805206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42639,DS-a47c97a2-05b4-41f1-afed-031606ffef52,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-237f6a82-fc93-49b1-bc8c-dc8efbdd149d,DISK], DatanodeInfoWithStorage[127.0.0.1:42423,DS-f4b95c2c-32b8-451e-818b-f7ab784a9403,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-52c163f5-2015-40d3-86a3-f8f187524b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-6940c465-905f-416c-aa0b-8810266f1e98,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-8256fd11-79ff-456b-8273-676816046126,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-2213b99c-2f10-4322-83e8-9d4324d77a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-6ee94d1f-3617-4827-82ce-811bf1c5bccf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1064073931-172.17.0.5-1595839805206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42639,DS-a47c97a2-05b4-41f1-afed-031606ffef52,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-237f6a82-fc93-49b1-bc8c-dc8efbdd149d,DISK], DatanodeInfoWithStorage[127.0.0.1:42423,DS-f4b95c2c-32b8-451e-818b-f7ab784a9403,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-52c163f5-2015-40d3-86a3-f8f187524b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-6940c465-905f-416c-aa0b-8810266f1e98,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-8256fd11-79ff-456b-8273-676816046126,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-2213b99c-2f10-4322-83e8-9d4324d77a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-6ee94d1f-3617-4827-82ce-811bf1c5bccf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-19962632-172.17.0.5-1595839879123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39511,DS-c5304354-9b13-46c8-ae6a-22b4a7c1c581,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-90cfc1b6-9675-4007-86e4-ea750bb4fe20,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-ee331238-8b8e-42a6-b3df-acc85ed962f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-04ee366f-1257-4753-a1b2-67bba0356cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-634454ef-c341-46dd-8a52-482618a37f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-13791450-9815-45f6-b082-de123b1a7549,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-9405a3e8-ddeb-4318-b7d8-041379136d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-461aa629-0283-4cb9-8544-3fbe52c4d0c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-19962632-172.17.0.5-1595839879123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39511,DS-c5304354-9b13-46c8-ae6a-22b4a7c1c581,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-90cfc1b6-9675-4007-86e4-ea750bb4fe20,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-ee331238-8b8e-42a6-b3df-acc85ed962f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-04ee366f-1257-4753-a1b2-67bba0356cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-634454ef-c341-46dd-8a52-482618a37f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-13791450-9815-45f6-b082-de123b1a7549,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-9405a3e8-ddeb-4318-b7d8-041379136d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-461aa629-0283-4cb9-8544-3fbe52c4d0c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1830295621-172.17.0.5-1595840317653:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46629,DS-236caaa3-3228-41ed-b174-c4d5a1dbad1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-ae31a660-e908-42a7-aa3a-0a6d28459654,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-c0b8792d-b3ea-4266-8648-2e05f14149e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-1e79bb5b-1242-4daf-838f-0fb094d358e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-d7606088-8550-4fcb-80f1-26584fd975b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-a79332a2-9db1-416d-ac70-091718428e06,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-4d2be529-e640-4fcd-a149-62b73aac71ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-70b6ad25-bf6c-42f1-8415-d1e0454e6e18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1830295621-172.17.0.5-1595840317653:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46629,DS-236caaa3-3228-41ed-b174-c4d5a1dbad1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-ae31a660-e908-42a7-aa3a-0a6d28459654,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-c0b8792d-b3ea-4266-8648-2e05f14149e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-1e79bb5b-1242-4daf-838f-0fb094d358e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-d7606088-8550-4fcb-80f1-26584fd975b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-a79332a2-9db1-416d-ac70-091718428e06,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-4d2be529-e640-4fcd-a149-62b73aac71ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-70b6ad25-bf6c-42f1-8415-d1e0454e6e18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1550478163-172.17.0.5-1595840548212:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41257,DS-abe24422-f1d5-4481-86a1-7099890fcac1,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-15bdfa91-99ab-47c7-817f-915bac13bf96,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-e3424e01-df61-4a13-9607-aaaa419ae8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-9bd439a6-9766-4a1b-b5bd-d01314dda7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-9d76f63e-cdc0-4de1-b6ae-74a2e4d52592,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-34b0b009-7a03-48c3-b245-5792497e2383,DISK], DatanodeInfoWithStorage[127.0.0.1:35210,DS-926d3953-6b6d-459e-9cfd-56f2afe14c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-e34496f4-4ec3-4102-92af-33679387e1f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1550478163-172.17.0.5-1595840548212:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41257,DS-abe24422-f1d5-4481-86a1-7099890fcac1,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-15bdfa91-99ab-47c7-817f-915bac13bf96,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-e3424e01-df61-4a13-9607-aaaa419ae8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-9bd439a6-9766-4a1b-b5bd-d01314dda7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-9d76f63e-cdc0-4de1-b6ae-74a2e4d52592,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-34b0b009-7a03-48c3-b245-5792497e2383,DISK], DatanodeInfoWithStorage[127.0.0.1:35210,DS-926d3953-6b6d-459e-9cfd-56f2afe14c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-e34496f4-4ec3-4102-92af-33679387e1f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-226285719-172.17.0.5-1595840964205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44864,DS-f85f542d-09f0-4b00-b83e-be1551b85b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-17a7a16b-19e6-4a3c-8bd0-a4e872e85d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-766cb6b4-2231-4019-bb72-4e9e9c142b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-b6fd7731-8fd9-4772-91e5-272e427438da,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-ff60b993-28e2-4dda-bed8-6b86313f5475,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-16def2a5-944e-4ea3-9b86-19d02eaddcdd,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-75a5c975-e18d-41d6-b206-ab6f34963424,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-6c1ef7ec-f280-4825-bb3c-0053efe9046c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-226285719-172.17.0.5-1595840964205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44864,DS-f85f542d-09f0-4b00-b83e-be1551b85b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-17a7a16b-19e6-4a3c-8bd0-a4e872e85d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-766cb6b4-2231-4019-bb72-4e9e9c142b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-b6fd7731-8fd9-4772-91e5-272e427438da,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-ff60b993-28e2-4dda-bed8-6b86313f5475,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-16def2a5-944e-4ea3-9b86-19d02eaddcdd,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-75a5c975-e18d-41d6-b206-ab6f34963424,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-6c1ef7ec-f280-4825-bb3c-0053efe9046c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-480781602-172.17.0.5-1595841105146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43608,DS-37d840e1-e3db-4a08-99c2-95683cf6eff1,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-f23aac81-89bc-49d2-8b31-8fb4b8a9200c,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-108d8215-b449-41ad-a5c2-c8ccd77171dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43824,DS-a77b0f57-1cdc-45d0-866e-2aaf0bb23493,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-085860b2-9809-471a-ae93-2dd3433f77a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-3e98d879-1014-48cf-9394-e4ddb05327d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-0c9b9fb0-4741-4917-9ba9-ead79083001c,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-e3095fc5-3b76-404d-ab83-f659baa30e30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-480781602-172.17.0.5-1595841105146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43608,DS-37d840e1-e3db-4a08-99c2-95683cf6eff1,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-f23aac81-89bc-49d2-8b31-8fb4b8a9200c,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-108d8215-b449-41ad-a5c2-c8ccd77171dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43824,DS-a77b0f57-1cdc-45d0-866e-2aaf0bb23493,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-085860b2-9809-471a-ae93-2dd3433f77a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-3e98d879-1014-48cf-9394-e4ddb05327d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-0c9b9fb0-4741-4917-9ba9-ead79083001c,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-e3095fc5-3b76-404d-ab83-f659baa30e30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1551635230-172.17.0.5-1595841244298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38166,DS-0a72d6a2-b39f-427f-9652-3b160e3680b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-7290edac-3397-4d2d-b57b-7f70720bd20b,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-dcf33497-9b21-4692-9c6e-4a3a529f0321,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-5aa263e0-aeb2-4fb0-8646-7bdead943388,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-14540067-1227-4316-a021-1543438c6b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-5ec659cc-ba69-4019-a16c-1f01228c052f,DISK], DatanodeInfoWithStorage[127.0.0.1:38732,DS-99e1054a-ac83-4946-9cf1-dc6ac6e4ae66,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-ea93d401-fff2-4533-bf63-cba8e65352ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1551635230-172.17.0.5-1595841244298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38166,DS-0a72d6a2-b39f-427f-9652-3b160e3680b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-7290edac-3397-4d2d-b57b-7f70720bd20b,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-dcf33497-9b21-4692-9c6e-4a3a529f0321,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-5aa263e0-aeb2-4fb0-8646-7bdead943388,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-14540067-1227-4316-a021-1543438c6b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-5ec659cc-ba69-4019-a16c-1f01228c052f,DISK], DatanodeInfoWithStorage[127.0.0.1:38732,DS-99e1054a-ac83-4946-9cf1-dc6ac6e4ae66,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-ea93d401-fff2-4533-bf63-cba8e65352ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2131443153-172.17.0.5-1595841395166:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43920,DS-405cdbb6-9e8b-40c9-abfc-91027ddda18a,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-bdcf9bf4-100a-446a-bec3-3cbffe14300f,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-be6d16a7-cc4f-482b-8a0e-b7816d635438,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-2bc88067-14ba-4f65-b71e-82e7316404d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-999e8666-e51b-4ad2-9b3a-6fcd229dba40,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-556154f3-c97c-4891-b44e-e3151f5975b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40847,DS-e3933357-3380-4c83-b2c7-7a6a4281ac24,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-4ac28cea-1fb7-4f0a-a193-e5a5a63fc462,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2131443153-172.17.0.5-1595841395166:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43920,DS-405cdbb6-9e8b-40c9-abfc-91027ddda18a,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-bdcf9bf4-100a-446a-bec3-3cbffe14300f,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-be6d16a7-cc4f-482b-8a0e-b7816d635438,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-2bc88067-14ba-4f65-b71e-82e7316404d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-999e8666-e51b-4ad2-9b3a-6fcd229dba40,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-556154f3-c97c-4891-b44e-e3151f5975b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40847,DS-e3933357-3380-4c83-b2c7-7a6a4281ac24,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-4ac28cea-1fb7-4f0a-a193-e5a5a63fc462,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5267
