reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-634047328-172.17.0.11-1595572367393:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43783,DS-068acdef-3237-412c-83fc-8a9e556d2487,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-38d37900-5093-4e45-9db0-0fc914f532e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-d5dc2aa9-774e-410e-b523-dbe9f66d11aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-2ab51d12-c5cc-451d-bacd-336c11a8cf7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-2fc747e9-cd9a-4abf-a44a-db632e9623d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-db303ba6-f679-4384-950f-cd3ef5aa7cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-c4dd6a17-2b7a-4ee6-940d-6e822b3711d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-d92d19b0-fc54-4913-81b7-509e507f5e7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-634047328-172.17.0.11-1595572367393:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43783,DS-068acdef-3237-412c-83fc-8a9e556d2487,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-38d37900-5093-4e45-9db0-0fc914f532e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-d5dc2aa9-774e-410e-b523-dbe9f66d11aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-2ab51d12-c5cc-451d-bacd-336c11a8cf7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-2fc747e9-cd9a-4abf-a44a-db632e9623d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-db303ba6-f679-4384-950f-cd3ef5aa7cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-c4dd6a17-2b7a-4ee6-940d-6e822b3711d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-d92d19b0-fc54-4913-81b7-509e507f5e7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1255471426-172.17.0.11-1595572539113:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43423,DS-177b4d22-a932-45f8-9815-d61723cc101b,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-2e5b1477-b321-40f8-b407-e571a8c51475,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-11071f22-4e3a-4911-a945-23ef4bce3b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-f3bd85d8-a06c-4af0-9e4d-4673a8c6edef,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-c6b5a99d-0ee9-48b9-b891-a50c616d0c25,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-2e1564ef-11fc-49de-933a-44e697ec1238,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-70c73068-187d-4efa-a4f6-a4427c8b4c84,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-7ab51c13-c705-4dfb-afc9-244c40596be1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1255471426-172.17.0.11-1595572539113:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43423,DS-177b4d22-a932-45f8-9815-d61723cc101b,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-2e5b1477-b321-40f8-b407-e571a8c51475,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-11071f22-4e3a-4911-a945-23ef4bce3b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-f3bd85d8-a06c-4af0-9e4d-4673a8c6edef,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-c6b5a99d-0ee9-48b9-b891-a50c616d0c25,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-2e1564ef-11fc-49de-933a-44e697ec1238,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-70c73068-187d-4efa-a4f6-a4427c8b4c84,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-7ab51c13-c705-4dfb-afc9-244c40596be1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1074876301-172.17.0.11-1595572745823:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46773,DS-87378f97-5f5e-4214-9378-a61b56ea2fde,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-aa2f7f1a-db33-41c3-836a-7dfa422b5a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:32806,DS-a7ab3859-fc28-4cf9-84da-210c28fe0546,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-1ffcea3f-9b5a-43a7-ade6-91f3d220c15f,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-e1223891-e69b-44cf-825f-a59f5390bbf9,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-49883391-fa03-4600-9698-50ef6f7a8d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-34eeb5f6-a1fb-4c6d-b1ea-3047db3c4566,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-f5311137-cafd-4224-ae00-ceb8d47e82ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1074876301-172.17.0.11-1595572745823:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46773,DS-87378f97-5f5e-4214-9378-a61b56ea2fde,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-aa2f7f1a-db33-41c3-836a-7dfa422b5a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:32806,DS-a7ab3859-fc28-4cf9-84da-210c28fe0546,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-1ffcea3f-9b5a-43a7-ade6-91f3d220c15f,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-e1223891-e69b-44cf-825f-a59f5390bbf9,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-49883391-fa03-4600-9698-50ef6f7a8d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-34eeb5f6-a1fb-4c6d-b1ea-3047db3c4566,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-f5311137-cafd-4224-ae00-ceb8d47e82ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-453694087-172.17.0.11-1595572986215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41153,DS-7179abcf-43dd-4c8a-9ed1-a80bec43129c,DISK], DatanodeInfoWithStorage[127.0.0.1:35641,DS-e25f5821-4d3d-49c4-8631-f86db4cdc797,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-bcd61691-1177-4bca-b81b-1c3d3d5dfa89,DISK], DatanodeInfoWithStorage[127.0.0.1:44795,DS-22ed0dbb-279f-4e3d-8626-29c3354a8aba,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-536f2420-a8a9-459e-96f7-2b171e9fc2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37074,DS-9a5bc755-9f4f-40f6-bd2b-b43c4e83af2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-8e2c5171-1265-4df6-b667-15c63993d438,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-e2e2255a-4bef-4449-805a-9c376ed25b2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-453694087-172.17.0.11-1595572986215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41153,DS-7179abcf-43dd-4c8a-9ed1-a80bec43129c,DISK], DatanodeInfoWithStorage[127.0.0.1:35641,DS-e25f5821-4d3d-49c4-8631-f86db4cdc797,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-bcd61691-1177-4bca-b81b-1c3d3d5dfa89,DISK], DatanodeInfoWithStorage[127.0.0.1:44795,DS-22ed0dbb-279f-4e3d-8626-29c3354a8aba,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-536f2420-a8a9-459e-96f7-2b171e9fc2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37074,DS-9a5bc755-9f4f-40f6-bd2b-b43c4e83af2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-8e2c5171-1265-4df6-b667-15c63993d438,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-e2e2255a-4bef-4449-805a-9c376ed25b2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-508836319-172.17.0.11-1595573268608:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42010,DS-3bc6026a-81ee-47f2-bef0-5115e3847a45,DISK], DatanodeInfoWithStorage[127.0.0.1:37251,DS-7def1651-2ba1-4285-8a75-6338f6835a67,DISK], DatanodeInfoWithStorage[127.0.0.1:39318,DS-393a0bdd-4d98-4236-ae9f-bc9f5a6903d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-c3234db5-3422-4f79-af8c-c71c2692896e,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-09f83c45-d380-4a30-88dc-801f06f615ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-b6cbc7ad-ee09-4d2f-98a4-e1cba712731e,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-901b2a9a-83ad-46d8-980e-7f0b99414ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-e7d37f02-1674-44a5-98ef-cbaf250dd6c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-508836319-172.17.0.11-1595573268608:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42010,DS-3bc6026a-81ee-47f2-bef0-5115e3847a45,DISK], DatanodeInfoWithStorage[127.0.0.1:37251,DS-7def1651-2ba1-4285-8a75-6338f6835a67,DISK], DatanodeInfoWithStorage[127.0.0.1:39318,DS-393a0bdd-4d98-4236-ae9f-bc9f5a6903d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-c3234db5-3422-4f79-af8c-c71c2692896e,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-09f83c45-d380-4a30-88dc-801f06f615ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-b6cbc7ad-ee09-4d2f-98a4-e1cba712731e,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-901b2a9a-83ad-46d8-980e-7f0b99414ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-e7d37f02-1674-44a5-98ef-cbaf250dd6c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1975325976-172.17.0.11-1595574303482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43776,DS-88efd5f1-f206-4af7-8347-21576b4ff31b,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-3ee4f44b-c042-400c-8e03-fe6d02e14491,DISK], DatanodeInfoWithStorage[127.0.0.1:44965,DS-49408f5e-9d69-46f6-8fe3-f2ccccea0000,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-e73ad972-3532-45bd-836d-b8ba36ff8170,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-31971f64-279b-407e-b969-58c20a0ce4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-3c54eea7-0232-4f61-95af-f68b978e6cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-43caf9f8-62c2-4d90-9221-fabe9ec12c93,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-78d5ced1-8b0c-4a93-99ef-a888e508d91d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1975325976-172.17.0.11-1595574303482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43776,DS-88efd5f1-f206-4af7-8347-21576b4ff31b,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-3ee4f44b-c042-400c-8e03-fe6d02e14491,DISK], DatanodeInfoWithStorage[127.0.0.1:44965,DS-49408f5e-9d69-46f6-8fe3-f2ccccea0000,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-e73ad972-3532-45bd-836d-b8ba36ff8170,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-31971f64-279b-407e-b969-58c20a0ce4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-3c54eea7-0232-4f61-95af-f68b978e6cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-43caf9f8-62c2-4d90-9221-fabe9ec12c93,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-78d5ced1-8b0c-4a93-99ef-a888e508d91d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1563271962-172.17.0.11-1595574904107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38163,DS-29d2be86-b6a7-4d6f-b8a3-1b20e6ad66ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-5ef5eb3e-0fc8-45de-8cbf-8fff9def98b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-06453f1b-0348-4323-9691-94d6eba7e325,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-c46321bf-869e-4de8-828f-ff8ddf3252d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-b886b7c8-c4da-43dd-b78c-33f10c71ab34,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-e54d3df4-c7ef-427b-aa00-f52ca8ff145d,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-0502e0bd-b874-44b2-8db3-f3c90a0b55ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-c8e8e09f-1c9d-4945-8526-a10fd6f66afb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1563271962-172.17.0.11-1595574904107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38163,DS-29d2be86-b6a7-4d6f-b8a3-1b20e6ad66ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-5ef5eb3e-0fc8-45de-8cbf-8fff9def98b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-06453f1b-0348-4323-9691-94d6eba7e325,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-c46321bf-869e-4de8-828f-ff8ddf3252d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-b886b7c8-c4da-43dd-b78c-33f10c71ab34,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-e54d3df4-c7ef-427b-aa00-f52ca8ff145d,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-0502e0bd-b874-44b2-8db3-f3c90a0b55ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-c8e8e09f-1c9d-4945-8526-a10fd6f66afb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1097167531-172.17.0.11-1595575759073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37773,DS-154eedb6-71bb-4af9-9c1d-b3127427636d,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-d8c0c3ba-7bd6-48b7-b47d-3da72f2257ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-fc9330b5-d0fa-42ad-83fa-ee1b70a53ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-dc5a0081-9456-4ade-8207-5637bbd4ddb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37294,DS-e1fb73f5-e7e5-4dad-8e9a-c1dd47575b43,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-0b538e39-09b3-4faf-9177-01ce4dfeb661,DISK], DatanodeInfoWithStorage[127.0.0.1:44226,DS-e87d1428-dc44-4928-a7ed-458e276d65eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-13c5f1e3-ebf7-4bc6-a61f-552a939814b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1097167531-172.17.0.11-1595575759073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37773,DS-154eedb6-71bb-4af9-9c1d-b3127427636d,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-d8c0c3ba-7bd6-48b7-b47d-3da72f2257ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-fc9330b5-d0fa-42ad-83fa-ee1b70a53ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-dc5a0081-9456-4ade-8207-5637bbd4ddb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37294,DS-e1fb73f5-e7e5-4dad-8e9a-c1dd47575b43,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-0b538e39-09b3-4faf-9177-01ce4dfeb661,DISK], DatanodeInfoWithStorage[127.0.0.1:44226,DS-e87d1428-dc44-4928-a7ed-458e276d65eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-13c5f1e3-ebf7-4bc6-a61f-552a939814b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2011375724-172.17.0.11-1595575796571:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33454,DS-09b8c059-9f80-49a9-8724-48e166f2dabd,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-9b199a1b-e080-411d-bf38-07d2f4c094b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42643,DS-9b86bda1-9179-4918-a45f-f464cfab1fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:37451,DS-6f35e624-bc03-4b96-a3d6-84fc1c105db8,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-fca62073-e14f-4336-8fc8-fc7e765814af,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-c5e196b1-8781-4ccd-9365-d2f8964cdd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34225,DS-fb5d581a-4d59-4189-91fd-b05911a4f0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-5cfedb49-dbda-41dc-b85d-f3fc32b37c21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2011375724-172.17.0.11-1595575796571:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33454,DS-09b8c059-9f80-49a9-8724-48e166f2dabd,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-9b199a1b-e080-411d-bf38-07d2f4c094b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42643,DS-9b86bda1-9179-4918-a45f-f464cfab1fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:37451,DS-6f35e624-bc03-4b96-a3d6-84fc1c105db8,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-fca62073-e14f-4336-8fc8-fc7e765814af,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-c5e196b1-8781-4ccd-9365-d2f8964cdd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34225,DS-fb5d581a-4d59-4189-91fd-b05911a4f0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-5cfedb49-dbda-41dc-b85d-f3fc32b37c21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-570222688-172.17.0.11-1595575936689:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35088,DS-62beabda-2ebd-48f0-9381-2c2ef6b09640,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-386dc5fe-1972-4eb6-890b-a97126baea46,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-3c9a5204-2ff7-48d5-ae39-86bc7a8adf55,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-c9f9da27-5bfc-494e-b700-10009f9eb5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-bd06f3e3-2eba-49cd-af29-5e5e7b8f5f51,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-1fed199a-03b3-43f1-aa98-22dfdf5e3ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-207b29b3-b649-4968-afe3-e2e23008a0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-3acd9aa4-e66b-4898-a577-978fac8cb3e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-570222688-172.17.0.11-1595575936689:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35088,DS-62beabda-2ebd-48f0-9381-2c2ef6b09640,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-386dc5fe-1972-4eb6-890b-a97126baea46,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-3c9a5204-2ff7-48d5-ae39-86bc7a8adf55,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-c9f9da27-5bfc-494e-b700-10009f9eb5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-bd06f3e3-2eba-49cd-af29-5e5e7b8f5f51,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-1fed199a-03b3-43f1-aa98-22dfdf5e3ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-207b29b3-b649-4968-afe3-e2e23008a0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-3acd9aa4-e66b-4898-a577-978fac8cb3e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1407416555-172.17.0.11-1595576046601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44364,DS-cacca498-fea5-412a-9ba6-f4f6f0fbcc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-7b683500-52c7-456b-a59c-b30c929c75d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-7146e2e0-b5a0-4678-b226-ae3d80d97882,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-63d10915-6c0b-4aa4-96f5-c93c325a64de,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-76309f58-3e4f-4517-a9d0-d085cfbe8837,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-afddb0e0-4d02-4ab0-b2e9-6ab65250d2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-cf3d0a2f-973b-4531-b3b5-39232fd169c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-017c87a9-68dc-48b0-9f5c-9b979135244e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1407416555-172.17.0.11-1595576046601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44364,DS-cacca498-fea5-412a-9ba6-f4f6f0fbcc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-7b683500-52c7-456b-a59c-b30c929c75d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-7146e2e0-b5a0-4678-b226-ae3d80d97882,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-63d10915-6c0b-4aa4-96f5-c93c325a64de,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-76309f58-3e4f-4517-a9d0-d085cfbe8837,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-afddb0e0-4d02-4ab0-b2e9-6ab65250d2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-cf3d0a2f-973b-4531-b3b5-39232fd169c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-017c87a9-68dc-48b0-9f5c-9b979135244e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5429
