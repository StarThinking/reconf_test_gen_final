reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1954915049-172.17.0.12-1595545702847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33319,DS-d6b6d654-7833-445d-a99f-8127e77530c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37485,DS-8c2ce1d8-e5b9-4df9-872f-4ab40cb721b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-dbd33c7b-851a-4014-82b7-f44ab034ebc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33518,DS-934bb91e-5357-4852-a88e-936b9cf66566,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-0a2ec301-c336-4fab-b12e-44a6dcdd0811,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-5ee41eb5-da69-4c7a-8d7c-79cae8aea131,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-2fd6b941-d029-46b5-b1f0-91c17ce085d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-73680e3e-08e8-4eae-b9a7-c5b41a662392,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1954915049-172.17.0.12-1595545702847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33319,DS-d6b6d654-7833-445d-a99f-8127e77530c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37485,DS-8c2ce1d8-e5b9-4df9-872f-4ab40cb721b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-dbd33c7b-851a-4014-82b7-f44ab034ebc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33518,DS-934bb91e-5357-4852-a88e-936b9cf66566,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-0a2ec301-c336-4fab-b12e-44a6dcdd0811,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-5ee41eb5-da69-4c7a-8d7c-79cae8aea131,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-2fd6b941-d029-46b5-b1f0-91c17ce085d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-73680e3e-08e8-4eae-b9a7-c5b41a662392,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1808508460-172.17.0.12-1595546022670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34917,DS-a24212f3-9aed-4527-8e82-4c7e1935c608,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-88cb6d49-6ae5-4c59-9136-255eb98ac84a,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-87357c5e-7e35-415f-a0e8-461d3b8423c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44210,DS-548e3b44-fb53-4afa-9b85-17678cf93ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-141718fe-ba4d-4714-bf66-67bbdbfd541e,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-df01e45a-f290-4505-89d6-edae9f77f8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-94a21419-d43d-4ca8-af39-09ed5b62267e,DISK], DatanodeInfoWithStorage[127.0.0.1:39785,DS-cd288364-5943-45b8-9fc7-f2c3912f85cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1808508460-172.17.0.12-1595546022670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34917,DS-a24212f3-9aed-4527-8e82-4c7e1935c608,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-88cb6d49-6ae5-4c59-9136-255eb98ac84a,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-87357c5e-7e35-415f-a0e8-461d3b8423c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44210,DS-548e3b44-fb53-4afa-9b85-17678cf93ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-141718fe-ba4d-4714-bf66-67bbdbfd541e,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-df01e45a-f290-4505-89d6-edae9f77f8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-94a21419-d43d-4ca8-af39-09ed5b62267e,DISK], DatanodeInfoWithStorage[127.0.0.1:39785,DS-cd288364-5943-45b8-9fc7-f2c3912f85cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1956636264-172.17.0.12-1595546397361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45658,DS-c508cf1f-6521-49c4-97e4-99796f16de9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-5170bdb1-c9ce-46b5-8a45-f6f1fcbd9017,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-180e343c-b2ca-445a-a0f0-d48b1b7312e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-31a23706-4cae-4bd9-8d59-e8e3b473e9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33891,DS-779a494a-c43b-4a50-896c-15f4535d9c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-88499ac5-e088-4999-af2e-9c6cb6df9406,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-5d40112a-8758-4e73-9a7e-3f7655d62dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-0c57a807-795e-4209-a2de-d1cd5198387c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1956636264-172.17.0.12-1595546397361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45658,DS-c508cf1f-6521-49c4-97e4-99796f16de9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-5170bdb1-c9ce-46b5-8a45-f6f1fcbd9017,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-180e343c-b2ca-445a-a0f0-d48b1b7312e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-31a23706-4cae-4bd9-8d59-e8e3b473e9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33891,DS-779a494a-c43b-4a50-896c-15f4535d9c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-88499ac5-e088-4999-af2e-9c6cb6df9406,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-5d40112a-8758-4e73-9a7e-3f7655d62dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-0c57a807-795e-4209-a2de-d1cd5198387c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1804997600-172.17.0.12-1595546426776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39289,DS-e8c04090-a5ab-4b60-94a3-533b1d7fdf06,DISK], DatanodeInfoWithStorage[127.0.0.1:36161,DS-d91dc8bf-8668-48fd-8aa1-b2f7c9ed7d20,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-069aef3a-9480-4afe-ad19-2ce042ef576d,DISK], DatanodeInfoWithStorage[127.0.0.1:42746,DS-03b131d2-a379-4662-87b9-a8e0c85c9089,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-8ce88285-947f-433d-ba5e-4df0117fa2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-83022dce-d758-4dae-934c-11a76a896f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-e0018f50-b865-463a-af07-f5a204bd3765,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-1a16cb1c-12c5-4224-9958-b261af17a2f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1804997600-172.17.0.12-1595546426776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39289,DS-e8c04090-a5ab-4b60-94a3-533b1d7fdf06,DISK], DatanodeInfoWithStorage[127.0.0.1:36161,DS-d91dc8bf-8668-48fd-8aa1-b2f7c9ed7d20,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-069aef3a-9480-4afe-ad19-2ce042ef576d,DISK], DatanodeInfoWithStorage[127.0.0.1:42746,DS-03b131d2-a379-4662-87b9-a8e0c85c9089,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-8ce88285-947f-433d-ba5e-4df0117fa2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-83022dce-d758-4dae-934c-11a76a896f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-e0018f50-b865-463a-af07-f5a204bd3765,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-1a16cb1c-12c5-4224-9958-b261af17a2f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-212383757-172.17.0.12-1595546706115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39655,DS-ec0005ba-a970-4be4-b7f4-02c771e0ab23,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-aac5bc68-774b-47d5-aa88-0bbff8b63bca,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-d0ca3e21-e012-4c96-b8f0-06bf63558a62,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-157de9c8-df16-4ce9-899c-adb377154ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:37999,DS-6a36c2ec-3ec2-487d-924b-3a06311d6356,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-26fd0912-1201-45f9-b143-2a597004d8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-40d63421-ca5d-4d3c-82cf-daebf403285d,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-9c650c94-1a8e-4e12-af67-eebe59fedaa6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-212383757-172.17.0.12-1595546706115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39655,DS-ec0005ba-a970-4be4-b7f4-02c771e0ab23,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-aac5bc68-774b-47d5-aa88-0bbff8b63bca,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-d0ca3e21-e012-4c96-b8f0-06bf63558a62,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-157de9c8-df16-4ce9-899c-adb377154ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:37999,DS-6a36c2ec-3ec2-487d-924b-3a06311d6356,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-26fd0912-1201-45f9-b143-2a597004d8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-40d63421-ca5d-4d3c-82cf-daebf403285d,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-9c650c94-1a8e-4e12-af67-eebe59fedaa6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910707334-172.17.0.12-1595546999990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34591,DS-aa8241a9-7cd2-402e-81b4-a7b91f983505,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-0bc21dcc-d72d-4c13-8714-b8337a0e1ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-93326007-2c44-4cce-9477-4f487191d66b,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-bb6acd44-d21e-4ed0-815b-23a01f4b2d79,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-23d6d6f0-d83f-4da3-95a8-a87b686e20ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40279,DS-308ada22-c65b-412d-ad8b-78883fc8f57c,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-bac46d65-479c-42b3-8a53-1e26ac603a82,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-a5e8c9cf-0f26-4215-98f3-c05f70689fc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910707334-172.17.0.12-1595546999990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34591,DS-aa8241a9-7cd2-402e-81b4-a7b91f983505,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-0bc21dcc-d72d-4c13-8714-b8337a0e1ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-93326007-2c44-4cce-9477-4f487191d66b,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-bb6acd44-d21e-4ed0-815b-23a01f4b2d79,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-23d6d6f0-d83f-4da3-95a8-a87b686e20ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40279,DS-308ada22-c65b-412d-ad8b-78883fc8f57c,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-bac46d65-479c-42b3-8a53-1e26ac603a82,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-a5e8c9cf-0f26-4215-98f3-c05f70689fc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1491892053-172.17.0.12-1595547138548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44585,DS-3c1df9e6-6d2c-4416-8c22-9eca8a46aefb,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-0fdda752-9960-4fb5-8429-50de3b91e1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-97f42a92-2ca0-48f7-ba6f-c764f784e8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43228,DS-76d2299c-006f-453b-a242-5a1c7772c7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-a5ceff20-ff55-4194-a065-e44a062a2488,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-90484e7d-845e-46c7-8832-2d4450896966,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-8fac7939-2d58-49df-8db6-47f7ce79c869,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-443b3d17-6221-430c-a3b0-35cc1635c1ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1491892053-172.17.0.12-1595547138548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44585,DS-3c1df9e6-6d2c-4416-8c22-9eca8a46aefb,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-0fdda752-9960-4fb5-8429-50de3b91e1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-97f42a92-2ca0-48f7-ba6f-c764f784e8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43228,DS-76d2299c-006f-453b-a242-5a1c7772c7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-a5ceff20-ff55-4194-a065-e44a062a2488,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-90484e7d-845e-46c7-8832-2d4450896966,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-8fac7939-2d58-49df-8db6-47f7ce79c869,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-443b3d17-6221-430c-a3b0-35cc1635c1ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905656986-172.17.0.12-1595547440839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41607,DS-c049ec9c-9632-45e3-ad68-06c3a8ce6da3,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-d4a4bb13-5a77-414c-b2a2-b7ab3d8bc0af,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-9cbcc0ae-e127-462c-ac04-bcfb71e847f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35080,DS-f64331c2-9efa-4d32-8e84-2c0328bb3dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-784c7c4e-bfa9-4509-9671-0ccab89c7204,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-39aeb6ca-4531-4a51-b847-f0eda3dfd453,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-62e218ca-42ea-4303-8844-6e6883b2c334,DISK], DatanodeInfoWithStorage[127.0.0.1:33738,DS-74286254-ac92-445f-bb7b-2516a90b1b87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905656986-172.17.0.12-1595547440839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41607,DS-c049ec9c-9632-45e3-ad68-06c3a8ce6da3,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-d4a4bb13-5a77-414c-b2a2-b7ab3d8bc0af,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-9cbcc0ae-e127-462c-ac04-bcfb71e847f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35080,DS-f64331c2-9efa-4d32-8e84-2c0328bb3dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-784c7c4e-bfa9-4509-9671-0ccab89c7204,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-39aeb6ca-4531-4a51-b847-f0eda3dfd453,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-62e218ca-42ea-4303-8844-6e6883b2c334,DISK], DatanodeInfoWithStorage[127.0.0.1:33738,DS-74286254-ac92-445f-bb7b-2516a90b1b87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1392658581-172.17.0.12-1595547510992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44308,DS-254458cf-d58c-4bd3-bb3c-eb55be0fbcb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-bcf59e6b-ab36-4e4f-91a8-131f37f64eff,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-3e9cc091-4c8e-4ae2-bf85-e448b0187fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-d8e3af44-ed6b-4485-aeb5-e8caec63a4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34513,DS-a006ecad-2065-46c4-aac4-1cc7615801f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-36e7a757-24f1-4f1f-888a-404d1bebb25f,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-3e7bbd16-c7ff-4f2a-ab98-52bba3055b95,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-92cecc41-6071-4455-b201-ebab655b1394,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1392658581-172.17.0.12-1595547510992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44308,DS-254458cf-d58c-4bd3-bb3c-eb55be0fbcb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-bcf59e6b-ab36-4e4f-91a8-131f37f64eff,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-3e9cc091-4c8e-4ae2-bf85-e448b0187fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-d8e3af44-ed6b-4485-aeb5-e8caec63a4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34513,DS-a006ecad-2065-46c4-aac4-1cc7615801f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-36e7a757-24f1-4f1f-888a-404d1bebb25f,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-3e7bbd16-c7ff-4f2a-ab98-52bba3055b95,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-92cecc41-6071-4455-b201-ebab655b1394,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-792212190-172.17.0.12-1595547733996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34444,DS-0eb72993-4d84-4804-b88b-7b1197a48044,DISK], DatanodeInfoWithStorage[127.0.0.1:42000,DS-c9738224-dd65-44b6-9e89-8f925f313943,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-487796a1-1aa0-4417-8539-ad95ffb9f6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-558daf90-4ed6-4aa5-8d46-af82b3233403,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-8f325c04-f8b8-401d-a4fe-691d3ff7e6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-293e8c40-b87e-4733-974d-8db932879182,DISK], DatanodeInfoWithStorage[127.0.0.1:35977,DS-fdff9de8-a954-4e60-83f1-ee198b203a10,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-950e178d-cac7-4328-841f-1760815c4771,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-792212190-172.17.0.12-1595547733996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34444,DS-0eb72993-4d84-4804-b88b-7b1197a48044,DISK], DatanodeInfoWithStorage[127.0.0.1:42000,DS-c9738224-dd65-44b6-9e89-8f925f313943,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-487796a1-1aa0-4417-8539-ad95ffb9f6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-558daf90-4ed6-4aa5-8d46-af82b3233403,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-8f325c04-f8b8-401d-a4fe-691d3ff7e6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-293e8c40-b87e-4733-974d-8db932879182,DISK], DatanodeInfoWithStorage[127.0.0.1:35977,DS-fdff9de8-a954-4e60-83f1-ee198b203a10,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-950e178d-cac7-4328-841f-1760815c4771,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1843276381-172.17.0.12-1595547768047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34202,DS-c74036e4-6175-42c0-9d02-6c682da629a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-2f54ee10-926b-49db-b980-6ddbf1b0f4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-94955964-943c-42e1-94f9-b2036aaa532b,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-6a89b468-37f2-40b2-bb8c-9fe7d3c3c464,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-c03c9510-9fb3-43a7-a404-5d84aa46fa2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36970,DS-10a1c25f-2385-4234-a138-f2ce9bc8f1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-b2edfdbf-312b-414c-9d7c-e9d18be34269,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-c9de8d73-76d5-4a76-b3a0-ba5b43cea911,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1843276381-172.17.0.12-1595547768047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34202,DS-c74036e4-6175-42c0-9d02-6c682da629a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-2f54ee10-926b-49db-b980-6ddbf1b0f4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-94955964-943c-42e1-94f9-b2036aaa532b,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-6a89b468-37f2-40b2-bb8c-9fe7d3c3c464,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-c03c9510-9fb3-43a7-a404-5d84aa46fa2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36970,DS-10a1c25f-2385-4234-a138-f2ce9bc8f1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-b2edfdbf-312b-414c-9d7c-e9d18be34269,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-c9de8d73-76d5-4a76-b3a0-ba5b43cea911,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-854270536-172.17.0.12-1595548295992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46772,DS-9f8aebb3-cae3-4a6f-aeeb-069d338cd382,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-9a111eb6-4abd-4df1-a904-8784899f7383,DISK], DatanodeInfoWithStorage[127.0.0.1:44063,DS-6b30e47b-c6c4-48d1-86f5-c086ef1a1fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-c00b155a-6c5a-4a38-8ee8-42cc038a4e03,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-c2718277-ea5e-4469-a6ca-a23215f038c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-61022b91-ad4a-4ae0-bf99-894d359237fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-60bbc279-e7c4-499f-9201-805672011357,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-ba58eb76-3ad1-4b30-828d-038180c19bb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-854270536-172.17.0.12-1595548295992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46772,DS-9f8aebb3-cae3-4a6f-aeeb-069d338cd382,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-9a111eb6-4abd-4df1-a904-8784899f7383,DISK], DatanodeInfoWithStorage[127.0.0.1:44063,DS-6b30e47b-c6c4-48d1-86f5-c086ef1a1fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-c00b155a-6c5a-4a38-8ee8-42cc038a4e03,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-c2718277-ea5e-4469-a6ca-a23215f038c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-61022b91-ad4a-4ae0-bf99-894d359237fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-60bbc279-e7c4-499f-9201-805672011357,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-ba58eb76-3ad1-4b30-828d-038180c19bb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2098816261-172.17.0.12-1595548690455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36733,DS-545a426e-ff4c-4a2b-b769-01b48e34ecb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-984871ef-cf50-46e8-8321-60c693b151f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-693bf538-edf5-4204-90d1-40b35793953d,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-3dc3800e-1249-4a0a-b427-6dff08841bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-b41f9cac-8335-46ac-8e63-32740de0a0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-9841f1e8-2107-42b3-9572-4656a17755d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41265,DS-3467e9b5-2142-4eba-92f7-6ed1d668237c,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-8bbacc6f-c103-495e-8eb7-cc1f2a1fa22a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2098816261-172.17.0.12-1595548690455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36733,DS-545a426e-ff4c-4a2b-b769-01b48e34ecb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-984871ef-cf50-46e8-8321-60c693b151f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-693bf538-edf5-4204-90d1-40b35793953d,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-3dc3800e-1249-4a0a-b427-6dff08841bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-b41f9cac-8335-46ac-8e63-32740de0a0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-9841f1e8-2107-42b3-9572-4656a17755d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41265,DS-3467e9b5-2142-4eba-92f7-6ed1d668237c,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-8bbacc6f-c103-495e-8eb7-cc1f2a1fa22a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1864227222-172.17.0.12-1595548990934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34299,DS-08128300-34ac-44a3-82ff-4ddcd4887878,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-eb678c67-e736-4ddf-9fca-c62ee9632d21,DISK], DatanodeInfoWithStorage[127.0.0.1:35642,DS-f3ee2a43-23ce-448f-884a-30835bb0be86,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-13873a3d-b1cf-4b2a-af1b-fb57ddf2b839,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-6ff764b7-dd4c-4edc-b222-d7360d8cbf68,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-81c50160-a135-4b06-8c61-b01ca3844dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-37e34f60-9b31-4e27-9c98-15ef9114db2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-1f5b3296-0206-4993-92c2-2e891f05b11a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1864227222-172.17.0.12-1595548990934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34299,DS-08128300-34ac-44a3-82ff-4ddcd4887878,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-eb678c67-e736-4ddf-9fca-c62ee9632d21,DISK], DatanodeInfoWithStorage[127.0.0.1:35642,DS-f3ee2a43-23ce-448f-884a-30835bb0be86,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-13873a3d-b1cf-4b2a-af1b-fb57ddf2b839,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-6ff764b7-dd4c-4edc-b222-d7360d8cbf68,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-81c50160-a135-4b06-8c61-b01ca3844dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-37e34f60-9b31-4e27-9c98-15ef9114db2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-1f5b3296-0206-4993-92c2-2e891f05b11a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-309198310-172.17.0.12-1595549247967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34442,DS-42c6dcc8-1920-4d84-9ca8-58110bb509e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-ba7d1742-44bb-4686-a1bc-f966290418d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-bfab9fd1-69ee-402c-897d-13e3a7425ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-f9f6e1d5-34c7-45e7-8261-da032c67c3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-07056fc0-2de5-41bc-9212-92153e580dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-cc3dcd4f-ead5-46ed-a6a7-906c38762d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-9633eaae-1ddd-47d2-934d-726d8b0f22a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-a7d3271e-8964-48b1-b619-80cbbf2b62c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-309198310-172.17.0.12-1595549247967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34442,DS-42c6dcc8-1920-4d84-9ca8-58110bb509e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-ba7d1742-44bb-4686-a1bc-f966290418d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-bfab9fd1-69ee-402c-897d-13e3a7425ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-f9f6e1d5-34c7-45e7-8261-da032c67c3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-07056fc0-2de5-41bc-9212-92153e580dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-cc3dcd4f-ead5-46ed-a6a7-906c38762d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-9633eaae-1ddd-47d2-934d-726d8b0f22a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-a7d3271e-8964-48b1-b619-80cbbf2b62c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2004816231-172.17.0.12-1595549387141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46604,DS-51392818-9ac2-4832-8053-2d79f50315bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-183ebba2-3104-4408-88ae-76a106db955b,DISK], DatanodeInfoWithStorage[127.0.0.1:45227,DS-9937e7e0-e85e-497f-b7ce-4260746e6a76,DISK], DatanodeInfoWithStorage[127.0.0.1:37363,DS-4492266e-8f22-4628-917e-4caceba6991b,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-0d1a9363-380e-4cc1-80bc-44f4ec4a72eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-27e737a2-895b-4c6a-ae92-8a7454a34ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-92edf074-36e1-4bf8-94d4-d2f54e3e8bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44146,DS-641f8c61-aab5-4005-8424-bbe068d9674a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2004816231-172.17.0.12-1595549387141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46604,DS-51392818-9ac2-4832-8053-2d79f50315bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-183ebba2-3104-4408-88ae-76a106db955b,DISK], DatanodeInfoWithStorage[127.0.0.1:45227,DS-9937e7e0-e85e-497f-b7ce-4260746e6a76,DISK], DatanodeInfoWithStorage[127.0.0.1:37363,DS-4492266e-8f22-4628-917e-4caceba6991b,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-0d1a9363-380e-4cc1-80bc-44f4ec4a72eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-27e737a2-895b-4c6a-ae92-8a7454a34ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-92edf074-36e1-4bf8-94d4-d2f54e3e8bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44146,DS-641f8c61-aab5-4005-8424-bbe068d9674a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-745270568-172.17.0.12-1595549460561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44824,DS-ce91fd70-344b-42d7-8544-0de57801dbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-c611fe0c-6348-4187-a2b3-dde21f1ebf55,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-8d8bb2a0-db5a-410b-b71f-bc9b28e87997,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-37e2f6a9-8cba-45f5-a4c8-2900ffb8a0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38438,DS-188f905a-09f0-4dab-b232-9b974e98ed76,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-ce36fa0a-fb1c-4f30-a66d-3ef99b9eddb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42743,DS-1ac5f22e-4018-4949-8255-7d9bbe532b29,DISK], DatanodeInfoWithStorage[127.0.0.1:38041,DS-a7b884a6-0dce-4d89-9a7c-09f6132d500e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-745270568-172.17.0.12-1595549460561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44824,DS-ce91fd70-344b-42d7-8544-0de57801dbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-c611fe0c-6348-4187-a2b3-dde21f1ebf55,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-8d8bb2a0-db5a-410b-b71f-bc9b28e87997,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-37e2f6a9-8cba-45f5-a4c8-2900ffb8a0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38438,DS-188f905a-09f0-4dab-b232-9b974e98ed76,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-ce36fa0a-fb1c-4f30-a66d-3ef99b9eddb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42743,DS-1ac5f22e-4018-4949-8255-7d9bbe532b29,DISK], DatanodeInfoWithStorage[127.0.0.1:38041,DS-a7b884a6-0dce-4d89-9a7c-09f6132d500e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5437
