reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1173081613-172.17.0.6-1596014200445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42115,DS-3d6b6e4b-7ca0-4772-b94a-49554c9f6d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-58f44419-25e5-4fcb-8e0b-cc741e1dba35,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-0b288bb9-e16b-493c-9804-b8ef0e873a01,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-dae0aee4-2e6a-4e75-9994-bb0ea164600b,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-68c35ded-d3be-43e0-86c1-65b95d21eb63,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-d7f9ee73-59e2-4246-8181-958683dd3f95,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-82975df5-d543-42a5-a25d-ec0c52579b00,DISK], DatanodeInfoWithStorage[127.0.0.1:36727,DS-2e6e0ab0-3339-43c7-97f9-b325b92d9eaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1173081613-172.17.0.6-1596014200445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42115,DS-3d6b6e4b-7ca0-4772-b94a-49554c9f6d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-58f44419-25e5-4fcb-8e0b-cc741e1dba35,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-0b288bb9-e16b-493c-9804-b8ef0e873a01,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-dae0aee4-2e6a-4e75-9994-bb0ea164600b,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-68c35ded-d3be-43e0-86c1-65b95d21eb63,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-d7f9ee73-59e2-4246-8181-958683dd3f95,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-82975df5-d543-42a5-a25d-ec0c52579b00,DISK], DatanodeInfoWithStorage[127.0.0.1:36727,DS-2e6e0ab0-3339-43c7-97f9-b325b92d9eaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-809279532-172.17.0.6-1596014503935:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45449,DS-2c093f37-e625-4ab0-9abe-a16692ad6618,DISK], DatanodeInfoWithStorage[127.0.0.1:33455,DS-c09dc25b-3a69-46ff-8af1-36b357e9b97f,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-79cbeb76-b7e7-4fd5-a790-f2e2db1b8f53,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-71a829a7-59fe-4600-bceb-0f94c50564d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40619,DS-5adef3e2-7701-4872-aa6d-2fb21c7aa4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40376,DS-889a4656-7eee-4283-a8c4-c5cc3b578911,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-25fdd29a-b209-471c-8068-9206f91e2d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-401c0666-5b8b-4f1f-b4ab-0b8411510645,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-809279532-172.17.0.6-1596014503935:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45449,DS-2c093f37-e625-4ab0-9abe-a16692ad6618,DISK], DatanodeInfoWithStorage[127.0.0.1:33455,DS-c09dc25b-3a69-46ff-8af1-36b357e9b97f,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-79cbeb76-b7e7-4fd5-a790-f2e2db1b8f53,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-71a829a7-59fe-4600-bceb-0f94c50564d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40619,DS-5adef3e2-7701-4872-aa6d-2fb21c7aa4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40376,DS-889a4656-7eee-4283-a8c4-c5cc3b578911,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-25fdd29a-b209-471c-8068-9206f91e2d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-401c0666-5b8b-4f1f-b4ab-0b8411510645,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1695523666-172.17.0.6-1596015004044:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40219,DS-bd88a870-c38b-4e61-a35a-50ea4573ab5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37248,DS-41724869-c674-440f-8858-779393d54912,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-442bf806-a3bd-49db-a8ef-4051ecc70a74,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-68b01c70-372d-4858-9b97-7f5fcfa3cec8,DISK], DatanodeInfoWithStorage[127.0.0.1:37950,DS-1177ff3d-72ab-4858-9532-b47451ed0787,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-5adc1e97-9400-40a3-b814-9537b2183d81,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-c2d795e3-8a11-4a0f-b5f5-95b51bb1123f,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-08d84f13-ba54-47f8-9155-9e85d9c5d7fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1695523666-172.17.0.6-1596015004044:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40219,DS-bd88a870-c38b-4e61-a35a-50ea4573ab5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37248,DS-41724869-c674-440f-8858-779393d54912,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-442bf806-a3bd-49db-a8ef-4051ecc70a74,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-68b01c70-372d-4858-9b97-7f5fcfa3cec8,DISK], DatanodeInfoWithStorage[127.0.0.1:37950,DS-1177ff3d-72ab-4858-9532-b47451ed0787,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-5adc1e97-9400-40a3-b814-9537b2183d81,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-c2d795e3-8a11-4a0f-b5f5-95b51bb1123f,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-08d84f13-ba54-47f8-9155-9e85d9c5d7fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1318751808-172.17.0.6-1596015469216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45328,DS-7354cd21-34d9-4993-9129-0948db9ecec1,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-36c8c6e9-c0fd-4527-8f6f-90d5a34faf17,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-6d84ad75-ce60-40e2-9c0d-0d00123746e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-ea274265-96ac-46d4-b883-2704a36bbae9,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-4893c991-c412-4469-ab3b-0f6516ea6ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-443b8382-1642-4b05-86b7-6355f0bb6710,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-56402cc8-158a-45a8-9518-10437f27154d,DISK], DatanodeInfoWithStorage[127.0.0.1:37763,DS-706e80e5-bf8a-4201-b118-8e1983d6e254,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1318751808-172.17.0.6-1596015469216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45328,DS-7354cd21-34d9-4993-9129-0948db9ecec1,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-36c8c6e9-c0fd-4527-8f6f-90d5a34faf17,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-6d84ad75-ce60-40e2-9c0d-0d00123746e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-ea274265-96ac-46d4-b883-2704a36bbae9,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-4893c991-c412-4469-ab3b-0f6516ea6ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-443b8382-1642-4b05-86b7-6355f0bb6710,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-56402cc8-158a-45a8-9518-10437f27154d,DISK], DatanodeInfoWithStorage[127.0.0.1:37763,DS-706e80e5-bf8a-4201-b118-8e1983d6e254,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1626503025-172.17.0.6-1596015857587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44174,DS-a016be77-ff17-4595-aea1-7e1a66bb1ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:38206,DS-5b3c6714-b6ff-4706-bfa2-b36219541746,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-432d1187-6cea-4b6e-bc42-f8766514b3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-2ddc262a-3f85-4a42-bc7d-89f5fffd1c47,DISK], DatanodeInfoWithStorage[127.0.0.1:35656,DS-5beadc9b-db5b-44ab-aa1f-a9bf2432644d,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-9e40d72f-335e-477f-9a2f-c8bc60acc622,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-7101a28b-47f7-48d8-b586-e10396c5b7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-2f203903-7779-4210-9187-688b76f3ddb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1626503025-172.17.0.6-1596015857587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44174,DS-a016be77-ff17-4595-aea1-7e1a66bb1ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:38206,DS-5b3c6714-b6ff-4706-bfa2-b36219541746,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-432d1187-6cea-4b6e-bc42-f8766514b3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-2ddc262a-3f85-4a42-bc7d-89f5fffd1c47,DISK], DatanodeInfoWithStorage[127.0.0.1:35656,DS-5beadc9b-db5b-44ab-aa1f-a9bf2432644d,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-9e40d72f-335e-477f-9a2f-c8bc60acc622,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-7101a28b-47f7-48d8-b586-e10396c5b7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-2f203903-7779-4210-9187-688b76f3ddb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1035150340-172.17.0.6-1596016069466:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43817,DS-e5d879c2-1155-4a9c-95a3-3d0daaeae0af,DISK], DatanodeInfoWithStorage[127.0.0.1:46565,DS-69f8dda1-0972-46ea-bb6f-e5985a91984a,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-4d9713f8-6d7e-458a-a313-210b6b1c8973,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-fa0feee6-6b4c-42de-9959-06c47f3694b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-d80cf6b3-40e9-494c-bf41-1684a3d9cf2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-1ad391ff-f8ad-4f33-9a6d-79611d47e417,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-228f4045-c023-4822-9fef-7e7976e02aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:40121,DS-fc7c874f-423c-44c2-8b86-8dd426f7f99c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1035150340-172.17.0.6-1596016069466:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43817,DS-e5d879c2-1155-4a9c-95a3-3d0daaeae0af,DISK], DatanodeInfoWithStorage[127.0.0.1:46565,DS-69f8dda1-0972-46ea-bb6f-e5985a91984a,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-4d9713f8-6d7e-458a-a313-210b6b1c8973,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-fa0feee6-6b4c-42de-9959-06c47f3694b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-d80cf6b3-40e9-494c-bf41-1684a3d9cf2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-1ad391ff-f8ad-4f33-9a6d-79611d47e417,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-228f4045-c023-4822-9fef-7e7976e02aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:40121,DS-fc7c874f-423c-44c2-8b86-8dd426f7f99c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1110315606-172.17.0.6-1596016290471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37185,DS-5e97390d-9542-47ca-b22f-570766e0162a,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-d0b5652a-9004-4ebe-9e88-43651269dc90,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-a2a1ccb7-409c-4604-8906-20375d99534f,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-b94de33e-7393-4cbe-b9f7-2f9c0dbdd818,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-2d74c6a6-6dc2-41f3-80d7-149e8dd10920,DISK], DatanodeInfoWithStorage[127.0.0.1:42610,DS-9df80f19-18fb-4fe8-a105-3e3afad5f2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38433,DS-e6fef66b-6c3a-436b-b703-fd73c23f49b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40907,DS-39d996d7-762f-4e03-8913-b8e18096541a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1110315606-172.17.0.6-1596016290471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37185,DS-5e97390d-9542-47ca-b22f-570766e0162a,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-d0b5652a-9004-4ebe-9e88-43651269dc90,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-a2a1ccb7-409c-4604-8906-20375d99534f,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-b94de33e-7393-4cbe-b9f7-2f9c0dbdd818,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-2d74c6a6-6dc2-41f3-80d7-149e8dd10920,DISK], DatanodeInfoWithStorage[127.0.0.1:42610,DS-9df80f19-18fb-4fe8-a105-3e3afad5f2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38433,DS-e6fef66b-6c3a-436b-b703-fd73c23f49b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40907,DS-39d996d7-762f-4e03-8913-b8e18096541a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-19933807-172.17.0.6-1596016328952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37504,DS-29f0dcb1-0332-4775-b159-6a6f024f0471,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-9b4f326d-4ba3-4fcc-9f00-56356e754111,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-122a4a63-e17a-4ff3-bc31-1e3de37941eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-51d2aee5-a611-43f1-a508-a51372ce939e,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-be7a48e5-4905-4568-be52-98c8e18b3353,DISK], DatanodeInfoWithStorage[127.0.0.1:46523,DS-3c9279bc-61d8-4a1c-b376-50d51ea4eb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-8949c1d8-0f81-46f5-9116-657951bfe7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41477,DS-3af8c80a-64b8-4ae2-b845-dd3d98733ee1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-19933807-172.17.0.6-1596016328952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37504,DS-29f0dcb1-0332-4775-b159-6a6f024f0471,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-9b4f326d-4ba3-4fcc-9f00-56356e754111,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-122a4a63-e17a-4ff3-bc31-1e3de37941eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-51d2aee5-a611-43f1-a508-a51372ce939e,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-be7a48e5-4905-4568-be52-98c8e18b3353,DISK], DatanodeInfoWithStorage[127.0.0.1:46523,DS-3c9279bc-61d8-4a1c-b376-50d51ea4eb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-8949c1d8-0f81-46f5-9116-657951bfe7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41477,DS-3af8c80a-64b8-4ae2-b845-dd3d98733ee1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-56706708-172.17.0.6-1596016369190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39482,DS-2ffc4088-fead-4ca2-8455-d535b3d8f9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-fb4a9b73-e20c-4ab6-9f32-94881a169306,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-214240b5-3047-4a4d-843a-91bfc1c62240,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-f2a861ac-5a7e-4cc6-9ba9-b7044d84bc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33348,DS-65202c0d-abfa-4431-abcf-51251775126c,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-515909b3-62a1-4067-b93c-d7c3517c2bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-98a8a421-adcd-47ff-9186-90f67b6bf163,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-c268e72b-83e3-401f-a109-3d34981697c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-56706708-172.17.0.6-1596016369190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39482,DS-2ffc4088-fead-4ca2-8455-d535b3d8f9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-fb4a9b73-e20c-4ab6-9f32-94881a169306,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-214240b5-3047-4a4d-843a-91bfc1c62240,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-f2a861ac-5a7e-4cc6-9ba9-b7044d84bc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33348,DS-65202c0d-abfa-4431-abcf-51251775126c,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-515909b3-62a1-4067-b93c-d7c3517c2bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-98a8a421-adcd-47ff-9186-90f67b6bf163,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-c268e72b-83e3-401f-a109-3d34981697c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-824722047-172.17.0.6-1596016573380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40169,DS-1f222280-764e-4ccb-96fc-b97da99bc9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-d70d275e-572c-4560-8f34-e49d6c3cbedb,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-1713e97e-4068-4a1e-b240-45072e3af11a,DISK], DatanodeInfoWithStorage[127.0.0.1:39479,DS-4611a688-a253-421c-b440-76f8fd5ad862,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-dc778f2b-03f8-4391-9255-bfd1fb7ad40c,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-31aeedb6-3d42-411f-9a2f-f6abefc58b72,DISK], DatanodeInfoWithStorage[127.0.0.1:38329,DS-45c33f41-01fd-46c6-8832-654d9c0e1d78,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-ee1b32cd-ca9c-4a8c-9227-e6f3748762b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-824722047-172.17.0.6-1596016573380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40169,DS-1f222280-764e-4ccb-96fc-b97da99bc9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-d70d275e-572c-4560-8f34-e49d6c3cbedb,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-1713e97e-4068-4a1e-b240-45072e3af11a,DISK], DatanodeInfoWithStorage[127.0.0.1:39479,DS-4611a688-a253-421c-b440-76f8fd5ad862,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-dc778f2b-03f8-4391-9255-bfd1fb7ad40c,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-31aeedb6-3d42-411f-9a2f-f6abefc58b72,DISK], DatanodeInfoWithStorage[127.0.0.1:38329,DS-45c33f41-01fd-46c6-8832-654d9c0e1d78,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-ee1b32cd-ca9c-4a8c-9227-e6f3748762b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-848475608-172.17.0.6-1596016720157:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46193,DS-657e28ad-4e20-4ca7-ac78-ac3b4537f525,DISK], DatanodeInfoWithStorage[127.0.0.1:33142,DS-6539cc92-80ed-46fa-b997-32894858cf2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38946,DS-23eb5d9b-0e83-4416-89ae-be635b9517c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-9afe67b1-0fc0-4634-bcc7-49a8bf799462,DISK], DatanodeInfoWithStorage[127.0.0.1:35323,DS-e1879d7c-6581-4152-9121-f96bfca6f98b,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-27ec36ee-d9b8-419d-95de-7d6e65848a93,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-d5e4d012-cac8-4ce4-9aaa-f1f25355adbd,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-c89e725a-36ba-4087-b31f-58233f0b5733,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-848475608-172.17.0.6-1596016720157:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46193,DS-657e28ad-4e20-4ca7-ac78-ac3b4537f525,DISK], DatanodeInfoWithStorage[127.0.0.1:33142,DS-6539cc92-80ed-46fa-b997-32894858cf2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38946,DS-23eb5d9b-0e83-4416-89ae-be635b9517c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-9afe67b1-0fc0-4634-bcc7-49a8bf799462,DISK], DatanodeInfoWithStorage[127.0.0.1:35323,DS-e1879d7c-6581-4152-9121-f96bfca6f98b,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-27ec36ee-d9b8-419d-95de-7d6e65848a93,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-d5e4d012-cac8-4ce4-9aaa-f1f25355adbd,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-c89e725a-36ba-4087-b31f-58233f0b5733,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-403951350-172.17.0.6-1596017034988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40399,DS-f668a1cb-b52d-4ca2-b009-6ab6a59b8cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-1eb5e328-8256-4e33-a3a9-027c7064511a,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-eca05697-0f5d-4969-9187-45ad4855aec7,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-4813d057-aecd-4006-82b4-7482cc80e4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-34e1aa14-95ab-4071-9726-06a44058e31a,DISK], DatanodeInfoWithStorage[127.0.0.1:37874,DS-c35b0ac8-8972-4975-b5c4-fa6780619428,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-0ba7444f-aa31-430d-90d9-41e3c9bbb957,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-31153ba2-12d6-4a5b-8f7c-19fc0b971926,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-403951350-172.17.0.6-1596017034988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40399,DS-f668a1cb-b52d-4ca2-b009-6ab6a59b8cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-1eb5e328-8256-4e33-a3a9-027c7064511a,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-eca05697-0f5d-4969-9187-45ad4855aec7,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-4813d057-aecd-4006-82b4-7482cc80e4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-34e1aa14-95ab-4071-9726-06a44058e31a,DISK], DatanodeInfoWithStorage[127.0.0.1:37874,DS-c35b0ac8-8972-4975-b5c4-fa6780619428,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-0ba7444f-aa31-430d-90d9-41e3c9bbb957,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-31153ba2-12d6-4a5b-8f7c-19fc0b971926,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1736682058-172.17.0.6-1596017769921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46414,DS-df098bcf-6f7d-47c2-b104-953e1644032a,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-66b872fa-6486-42f8-a184-b557d53cba7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-9fe30e20-77d2-4961-ace4-b7f8f830d1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35640,DS-b7647537-cd18-4c94-be7e-e78b4ce7a480,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-937118ba-8c90-4eeb-926c-4b554364fbcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-b1269d67-07d7-4862-8b37-bf3ceeb60ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-7738fdaa-3469-4f0b-a751-bd994094c16b,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-eb9262a2-e561-4031-8e2d-b041220c0c35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1736682058-172.17.0.6-1596017769921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46414,DS-df098bcf-6f7d-47c2-b104-953e1644032a,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-66b872fa-6486-42f8-a184-b557d53cba7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-9fe30e20-77d2-4961-ace4-b7f8f830d1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35640,DS-b7647537-cd18-4c94-be7e-e78b4ce7a480,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-937118ba-8c90-4eeb-926c-4b554364fbcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-b1269d67-07d7-4862-8b37-bf3ceeb60ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-7738fdaa-3469-4f0b-a751-bd994094c16b,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-eb9262a2-e561-4031-8e2d-b041220c0c35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-984387795-172.17.0.6-1596017806602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36665,DS-59366c79-5a80-41e9-a36c-2074dc72206d,DISK], DatanodeInfoWithStorage[127.0.0.1:43262,DS-2c918f28-d2f9-4e43-93e5-24a601571b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-7596dcab-fa15-4a72-aefb-3ffd4d1381da,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-46bcba07-2a7e-4e91-ae03-92a63d2ae3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37802,DS-5f35677f-bf4f-4286-b49c-6385e0e293b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45975,DS-3b2b553e-a49c-4097-a13a-cac9650a23ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-cedb3f43-0feb-46f1-8a07-eb1cbf3d6746,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-6457865b-b660-4f77-8748-1557701ae814,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-984387795-172.17.0.6-1596017806602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36665,DS-59366c79-5a80-41e9-a36c-2074dc72206d,DISK], DatanodeInfoWithStorage[127.0.0.1:43262,DS-2c918f28-d2f9-4e43-93e5-24a601571b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-7596dcab-fa15-4a72-aefb-3ffd4d1381da,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-46bcba07-2a7e-4e91-ae03-92a63d2ae3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37802,DS-5f35677f-bf4f-4286-b49c-6385e0e293b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45975,DS-3b2b553e-a49c-4097-a13a-cac9650a23ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-cedb3f43-0feb-46f1-8a07-eb1cbf3d6746,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-6457865b-b660-4f77-8748-1557701ae814,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-537739054-172.17.0.6-1596017995322:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45544,DS-44f14733-3510-47e9-a526-02a5d88c83ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-4d65aa58-d960-4c42-be69-768dd8c8adc1,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-5fb60816-2523-44cd-a36e-1ea3c65f54b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-415cefad-905d-428c-839b-48948a077419,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-bc137448-d1ee-4ebc-b807-9e0fcc25e6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36561,DS-b9f5453e-1075-470d-bc52-17d163a50f72,DISK], DatanodeInfoWithStorage[127.0.0.1:44305,DS-1c06e769-722f-4469-a294-1db3e258a0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44462,DS-d2253964-3326-4891-9b7f-3653ea74d98f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-537739054-172.17.0.6-1596017995322:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45544,DS-44f14733-3510-47e9-a526-02a5d88c83ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-4d65aa58-d960-4c42-be69-768dd8c8adc1,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-5fb60816-2523-44cd-a36e-1ea3c65f54b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-415cefad-905d-428c-839b-48948a077419,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-bc137448-d1ee-4ebc-b807-9e0fcc25e6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36561,DS-b9f5453e-1075-470d-bc52-17d163a50f72,DISK], DatanodeInfoWithStorage[127.0.0.1:44305,DS-1c06e769-722f-4469-a294-1db3e258a0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44462,DS-d2253964-3326-4891-9b7f-3653ea74d98f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-94263646-172.17.0.6-1596018065897:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41971,DS-3cd258d0-99ec-400c-b22e-2ca2b348d320,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-abc7da23-8303-4714-a0c7-05bf3ac89a23,DISK], DatanodeInfoWithStorage[127.0.0.1:37462,DS-d42ce72b-56ae-4d20-ad78-708e576125a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-94881c2d-af0c-4112-ad09-06d721a1cf0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-90124661-56e9-428f-8c1b-5e1bf735bc68,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-deb67e4f-37f6-41ca-ae6e-f91a23cb6e89,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-6b3d887c-3ac9-4bcb-b5f4-58c310f7240a,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-15d9f002-57f2-4f4a-be22-5a6c68179ddf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-94263646-172.17.0.6-1596018065897:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41971,DS-3cd258d0-99ec-400c-b22e-2ca2b348d320,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-abc7da23-8303-4714-a0c7-05bf3ac89a23,DISK], DatanodeInfoWithStorage[127.0.0.1:37462,DS-d42ce72b-56ae-4d20-ad78-708e576125a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-94881c2d-af0c-4112-ad09-06d721a1cf0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-90124661-56e9-428f-8c1b-5e1bf735bc68,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-deb67e4f-37f6-41ca-ae6e-f91a23cb6e89,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-6b3d887c-3ac9-4bcb-b5f4-58c310f7240a,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-15d9f002-57f2-4f4a-be22-5a6c68179ddf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1322863602-172.17.0.6-1596018498319:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38291,DS-ec0cb6fa-2d65-49d1-9f17-c8cc8362662e,DISK], DatanodeInfoWithStorage[127.0.0.1:37338,DS-3512be08-52f2-42a6-82cb-427f71f9efb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-7c529d7f-9744-4462-987f-157eb5c323e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-3cbd8c2e-8e06-40c1-8149-a1a406683276,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-df799347-ed8b-46bf-9e5a-0cd180a0d1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-dec5f5e9-c338-49b7-82a3-a8e201a50fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35622,DS-510e9f3e-5789-4474-9c7b-f21b57479815,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-94beee01-d59c-41a6-93c0-3ae466d3fc91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1322863602-172.17.0.6-1596018498319:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38291,DS-ec0cb6fa-2d65-49d1-9f17-c8cc8362662e,DISK], DatanodeInfoWithStorage[127.0.0.1:37338,DS-3512be08-52f2-42a6-82cb-427f71f9efb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-7c529d7f-9744-4462-987f-157eb5c323e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-3cbd8c2e-8e06-40c1-8149-a1a406683276,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-df799347-ed8b-46bf-9e5a-0cd180a0d1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-dec5f5e9-c338-49b7-82a3-a8e201a50fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35622,DS-510e9f3e-5789-4474-9c7b-f21b57479815,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-94beee01-d59c-41a6-93c0-3ae466d3fc91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1486636160-172.17.0.6-1596018758651:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35262,DS-a3148f5d-6d1b-44e9-9125-190ececa2e96,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-45a9422e-5fed-4581-a164-72e55b190d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-d5bcccd7-33d4-4fed-ad21-acab0f21bc4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-5bd67370-8f1b-458f-8f1f-690cb647eb1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-05030b57-dde1-40ed-9aec-3a16d7bcc5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-a54f99d8-f941-419a-8f36-6a95feaf0577,DISK], DatanodeInfoWithStorage[127.0.0.1:42889,DS-a4376364-01ad-4e96-8af4-d927a58057ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-1e414613-5b6f-4ef6-900c-cf082d3f7829,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1486636160-172.17.0.6-1596018758651:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35262,DS-a3148f5d-6d1b-44e9-9125-190ececa2e96,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-45a9422e-5fed-4581-a164-72e55b190d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-d5bcccd7-33d4-4fed-ad21-acab0f21bc4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-5bd67370-8f1b-458f-8f1f-690cb647eb1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-05030b57-dde1-40ed-9aec-3a16d7bcc5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-a54f99d8-f941-419a-8f36-6a95feaf0577,DISK], DatanodeInfoWithStorage[127.0.0.1:42889,DS-a4376364-01ad-4e96-8af4-d927a58057ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-1e414613-5b6f-4ef6-900c-cf082d3f7829,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-438401376-172.17.0.6-1596018791386:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36219,DS-41dec7ad-b05b-4b2a-9765-cda5b268fe04,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-0162d5e2-1f72-401e-8190-467903cf2ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-89c9c61c-f34d-4912-8c51-3e2e81165e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-9cb2141d-a8b6-43ae-a32c-9b37ac07789b,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-d06ae4b5-4372-4fad-893b-42ce524d7451,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-737269b6-b3ba-416c-a204-7ce8dbb7a249,DISK], DatanodeInfoWithStorage[127.0.0.1:40543,DS-d14561a4-6f51-4429-812f-e34eda3a4ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-c62f5596-72c3-406e-b207-4a3047908a92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-438401376-172.17.0.6-1596018791386:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36219,DS-41dec7ad-b05b-4b2a-9765-cda5b268fe04,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-0162d5e2-1f72-401e-8190-467903cf2ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-89c9c61c-f34d-4912-8c51-3e2e81165e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-9cb2141d-a8b6-43ae-a32c-9b37ac07789b,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-d06ae4b5-4372-4fad-893b-42ce524d7451,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-737269b6-b3ba-416c-a204-7ce8dbb7a249,DISK], DatanodeInfoWithStorage[127.0.0.1:40543,DS-d14561a4-6f51-4429-812f-e34eda3a4ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-c62f5596-72c3-406e-b207-4a3047908a92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5444
