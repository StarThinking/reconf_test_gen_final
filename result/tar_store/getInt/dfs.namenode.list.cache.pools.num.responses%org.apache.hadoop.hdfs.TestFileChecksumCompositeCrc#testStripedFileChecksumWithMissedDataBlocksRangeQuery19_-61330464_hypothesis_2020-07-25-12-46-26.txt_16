reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-289673211-172.17.0.14-1595681490826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36910,DS-3fbd9129-9e15-48e1-9b90-bf6a6aac1391,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-b74178d3-182a-4f25-a2b0-a349130e927a,DISK], DatanodeInfoWithStorage[127.0.0.1:44668,DS-80a70a6f-7594-48f9-9e6f-faed05675ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-f74a57e3-d72a-4525-89bf-60d794b4b2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-bca8d18a-8a88-4205-9932-eae09ad61676,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-caf08b4b-e06f-4bda-a4fb-794ab6c9b37e,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-6f0503e0-083b-443a-bf59-81ceeef6dbea,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-40edb65e-fa21-4cbb-bf0a-3f4eb3fdb32d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-289673211-172.17.0.14-1595681490826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36910,DS-3fbd9129-9e15-48e1-9b90-bf6a6aac1391,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-b74178d3-182a-4f25-a2b0-a349130e927a,DISK], DatanodeInfoWithStorage[127.0.0.1:44668,DS-80a70a6f-7594-48f9-9e6f-faed05675ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-f74a57e3-d72a-4525-89bf-60d794b4b2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-bca8d18a-8a88-4205-9932-eae09ad61676,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-caf08b4b-e06f-4bda-a4fb-794ab6c9b37e,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-6f0503e0-083b-443a-bf59-81ceeef6dbea,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-40edb65e-fa21-4cbb-bf0a-3f4eb3fdb32d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-223936485-172.17.0.14-1595682092081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39809,DS-63a2948f-c686-45f9-8f69-e2024a236246,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-170d0423-3c7f-4553-804a-a251f69ebcfe,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-8b27bd8d-d463-4f17-ac68-2e1a440f4f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-ff514443-7a54-4016-86b0-e5681179df40,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-0b78eb4c-a84d-4615-82e6-d2c0f5d2fac8,DISK], DatanodeInfoWithStorage[127.0.0.1:35914,DS-a167d267-43f4-4fa3-8aa6-ecd6d76a3f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-629fe48c-bacb-41d9-8577-7fafd8b8263c,DISK], DatanodeInfoWithStorage[127.0.0.1:33245,DS-d53cb405-5d13-47b1-9a6e-c268125f0b10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-223936485-172.17.0.14-1595682092081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39809,DS-63a2948f-c686-45f9-8f69-e2024a236246,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-170d0423-3c7f-4553-804a-a251f69ebcfe,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-8b27bd8d-d463-4f17-ac68-2e1a440f4f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-ff514443-7a54-4016-86b0-e5681179df40,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-0b78eb4c-a84d-4615-82e6-d2c0f5d2fac8,DISK], DatanodeInfoWithStorage[127.0.0.1:35914,DS-a167d267-43f4-4fa3-8aa6-ecd6d76a3f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-629fe48c-bacb-41d9-8577-7fafd8b8263c,DISK], DatanodeInfoWithStorage[127.0.0.1:33245,DS-d53cb405-5d13-47b1-9a6e-c268125f0b10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1947403238-172.17.0.14-1595682223295:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36588,DS-8d31e4f4-c9af-41f1-8abe-c9bc72428aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-cef4ec6a-aa09-4481-b719-149e3af34ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-64745f5a-b677-4d35-af6b-83eaa172bf0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-8e09d433-dd78-4112-a206-7e59913eb1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-39ad00be-7a9a-4f13-bee7-ea2b5b29fa69,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-5a9725d4-c2af-45bd-a87d-24ec4139ce83,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-74439cba-810a-4539-97cd-e9ab850578b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38819,DS-1db5a49a-14aa-4af3-8810-d6f3e05e82ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1947403238-172.17.0.14-1595682223295:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36588,DS-8d31e4f4-c9af-41f1-8abe-c9bc72428aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-cef4ec6a-aa09-4481-b719-149e3af34ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-64745f5a-b677-4d35-af6b-83eaa172bf0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-8e09d433-dd78-4112-a206-7e59913eb1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-39ad00be-7a9a-4f13-bee7-ea2b5b29fa69,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-5a9725d4-c2af-45bd-a87d-24ec4139ce83,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-74439cba-810a-4539-97cd-e9ab850578b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38819,DS-1db5a49a-14aa-4af3-8810-d6f3e05e82ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-403190143-172.17.0.14-1595682567956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33123,DS-e01ee626-4775-43da-97fe-cde4485112a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-be3c74db-ffa2-405e-85da-0029564ea7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-bef26e02-2f10-4654-8ed5-2022d5837de5,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-728fa775-a5ae-463e-8b60-1b3b856f6ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-56a8ca75-b58b-4f81-80e4-109cc55dfa43,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-d3a43c28-c53f-4b3f-b934-39e5c7e05bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-5d8fbcca-25c2-4be2-898c-ed1aa7003522,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-3093d22f-758f-44fb-80e8-3dd349424999,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-403190143-172.17.0.14-1595682567956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33123,DS-e01ee626-4775-43da-97fe-cde4485112a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-be3c74db-ffa2-405e-85da-0029564ea7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-bef26e02-2f10-4654-8ed5-2022d5837de5,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-728fa775-a5ae-463e-8b60-1b3b856f6ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-56a8ca75-b58b-4f81-80e4-109cc55dfa43,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-d3a43c28-c53f-4b3f-b934-39e5c7e05bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-5d8fbcca-25c2-4be2-898c-ed1aa7003522,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-3093d22f-758f-44fb-80e8-3dd349424999,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-126076590-172.17.0.14-1595682700961:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44199,DS-03c00694-7765-42eb-b3d5-4fed281da4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-cfbc35c5-ee9f-4d19-ad86-32014476affc,DISK], DatanodeInfoWithStorage[127.0.0.1:39307,DS-0078caa2-9f1b-4486-a5fe-02718fe44ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-ecd694c1-fee8-490e-aa4a-690d2ac74479,DISK], DatanodeInfoWithStorage[127.0.0.1:45697,DS-86197cf3-b42b-42bd-9d30-a4b2f6476521,DISK], DatanodeInfoWithStorage[127.0.0.1:35779,DS-39295d15-c317-43e2-8ad7-8debaa489827,DISK], DatanodeInfoWithStorage[127.0.0.1:33526,DS-c11287ad-e756-4aed-a1cf-a8ce0d7bc2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-d21e96b0-b998-410c-b65f-e2714c71bbc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-126076590-172.17.0.14-1595682700961:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44199,DS-03c00694-7765-42eb-b3d5-4fed281da4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-cfbc35c5-ee9f-4d19-ad86-32014476affc,DISK], DatanodeInfoWithStorage[127.0.0.1:39307,DS-0078caa2-9f1b-4486-a5fe-02718fe44ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-ecd694c1-fee8-490e-aa4a-690d2ac74479,DISK], DatanodeInfoWithStorage[127.0.0.1:45697,DS-86197cf3-b42b-42bd-9d30-a4b2f6476521,DISK], DatanodeInfoWithStorage[127.0.0.1:35779,DS-39295d15-c317-43e2-8ad7-8debaa489827,DISK], DatanodeInfoWithStorage[127.0.0.1:33526,DS-c11287ad-e756-4aed-a1cf-a8ce0d7bc2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-d21e96b0-b998-410c-b65f-e2714c71bbc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-962737131-172.17.0.14-1595682822184:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45492,DS-336c0624-7d32-48f9-9d28-b56950568eac,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-bdc7a374-48eb-4369-b9a4-d74ce82e55f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-0537b5cd-1d65-4e6e-bc3a-acfdc39ce751,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-ad0724a7-c7d4-450d-82ce-441a16c625e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-cb30a187-e82b-40df-a00b-caea5f13cdf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-865eedac-68c9-4fe8-b0b3-94030265df52,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-35805cde-837a-46bb-9d83-ddd9140cfdc1,DISK], DatanodeInfoWithStorage[127.0.0.1:34077,DS-e64cdfb2-c64f-4ae6-b100-85abe210678d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-962737131-172.17.0.14-1595682822184:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45492,DS-336c0624-7d32-48f9-9d28-b56950568eac,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-bdc7a374-48eb-4369-b9a4-d74ce82e55f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-0537b5cd-1d65-4e6e-bc3a-acfdc39ce751,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-ad0724a7-c7d4-450d-82ce-441a16c625e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-cb30a187-e82b-40df-a00b-caea5f13cdf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-865eedac-68c9-4fe8-b0b3-94030265df52,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-35805cde-837a-46bb-9d83-ddd9140cfdc1,DISK], DatanodeInfoWithStorage[127.0.0.1:34077,DS-e64cdfb2-c64f-4ae6-b100-85abe210678d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-497212313-172.17.0.14-1595682949340:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37891,DS-17d4f101-55db-4507-8122-850b6f751b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-3c885d47-60c1-477f-9812-9bb64bfe98e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-fe44e733-0107-4dc6-b270-cd8aa98bc67c,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-1c0b98c1-a248-40f0-8cad-0af0cd4a2cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-0124c663-e625-40f9-84bc-8e0c57f35efa,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-ad4f1591-6a9d-4e41-8d8f-a7e08111b6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-813a785e-ca5c-4a0e-81a4-3868bce4be20,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-ca2f5298-13a7-4cdd-983b-92be66d933ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-497212313-172.17.0.14-1595682949340:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37891,DS-17d4f101-55db-4507-8122-850b6f751b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-3c885d47-60c1-477f-9812-9bb64bfe98e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-fe44e733-0107-4dc6-b270-cd8aa98bc67c,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-1c0b98c1-a248-40f0-8cad-0af0cd4a2cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-0124c663-e625-40f9-84bc-8e0c57f35efa,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-ad4f1591-6a9d-4e41-8d8f-a7e08111b6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-813a785e-ca5c-4a0e-81a4-3868bce4be20,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-ca2f5298-13a7-4cdd-983b-92be66d933ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1049973709-172.17.0.14-1595685184100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38162,DS-77fb6a73-75ea-4f65-b1e3-68c0eac7bbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-83ce22dd-7874-4b01-bf8e-85a3bbbe03cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-be0d4436-9d2d-4ccb-88c1-c1ffb7470073,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-e8fde86f-b79a-412e-a28b-f881fb1fa865,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-3359dac0-9978-4970-aaf0-0f417f7f390d,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-e523e02e-3670-4489-bb4a-bd107a664290,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-70e9cc96-814a-4a16-b692-0c7279314210,DISK], DatanodeInfoWithStorage[127.0.0.1:38155,DS-a72e8784-2706-4eb5-9c2b-9df345737db8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1049973709-172.17.0.14-1595685184100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38162,DS-77fb6a73-75ea-4f65-b1e3-68c0eac7bbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-83ce22dd-7874-4b01-bf8e-85a3bbbe03cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-be0d4436-9d2d-4ccb-88c1-c1ffb7470073,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-e8fde86f-b79a-412e-a28b-f881fb1fa865,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-3359dac0-9978-4970-aaf0-0f417f7f390d,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-e523e02e-3670-4489-bb4a-bd107a664290,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-70e9cc96-814a-4a16-b692-0c7279314210,DISK], DatanodeInfoWithStorage[127.0.0.1:38155,DS-a72e8784-2706-4eb5-9c2b-9df345737db8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-92522091-172.17.0.14-1595685982666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35276,DS-a867b3d2-6c5f-45fd-8503-6c0e6019b4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-ea43b6ca-7f17-421b-9dda-937436d9ea03,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-de099ee3-5af9-46e9-abde-32d0cc1c7a19,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-f5cb17b5-ce61-4204-9fa9-99cf271700dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-e4c276b8-4156-48e1-a008-3cba43d1f686,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-d486a21d-ccb9-445f-9c38-1cbe4b9baf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-98a82576-3a1a-492c-bf6a-1cdcef6c9328,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-cce35101-e0f4-43e8-8580-37788739ff3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-92522091-172.17.0.14-1595685982666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35276,DS-a867b3d2-6c5f-45fd-8503-6c0e6019b4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-ea43b6ca-7f17-421b-9dda-937436d9ea03,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-de099ee3-5af9-46e9-abde-32d0cc1c7a19,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-f5cb17b5-ce61-4204-9fa9-99cf271700dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-e4c276b8-4156-48e1-a008-3cba43d1f686,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-d486a21d-ccb9-445f-9c38-1cbe4b9baf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-98a82576-3a1a-492c-bf6a-1cdcef6c9328,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-cce35101-e0f4-43e8-8580-37788739ff3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-355824462-172.17.0.14-1595686420203:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42793,DS-f62c721f-4182-4d0a-b7b8-ea56b7d21dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-5c8e0848-fc03-47fa-a020-fad648588071,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-9e2bdd04-17d0-423a-90c1-c9520c2474a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40275,DS-a551e6cf-7ee6-46cd-a9b5-d6379d1cfdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-63122b56-9d83-4f5a-a31b-34adb39a6032,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-62e03bc0-f56c-4878-acc8-b601f03082e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-9fe1a212-6c0f-4093-9c14-28c2a1a4978a,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-6e36af64-9465-409b-a17b-c65463226e0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-355824462-172.17.0.14-1595686420203:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42793,DS-f62c721f-4182-4d0a-b7b8-ea56b7d21dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-5c8e0848-fc03-47fa-a020-fad648588071,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-9e2bdd04-17d0-423a-90c1-c9520c2474a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40275,DS-a551e6cf-7ee6-46cd-a9b5-d6379d1cfdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-63122b56-9d83-4f5a-a31b-34adb39a6032,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-62e03bc0-f56c-4878-acc8-b601f03082e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-9fe1a212-6c0f-4093-9c14-28c2a1a4978a,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-6e36af64-9465-409b-a17b-c65463226e0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1097351397-172.17.0.14-1595687028813:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34963,DS-9193129c-2e66-436e-80aa-676260ad5697,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-c4acd174-7cf9-4e66-8e2a-6fef81d3d394,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-5a86a886-ff22-45a4-8f2b-4585ece8e9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-90c649c4-8221-4f00-a74d-6f0ea280c028,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-7db366fe-880e-4f80-9c74-f3c3ac54e9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46594,DS-cb12dd62-d024-4e17-b538-53546863ffa9,DISK], DatanodeInfoWithStorage[127.0.0.1:41862,DS-6c543c5e-9756-4a3a-a57f-74dda88d7a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39586,DS-bc96b53e-09cd-4d49-a1d9-8cbe458231c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1097351397-172.17.0.14-1595687028813:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34963,DS-9193129c-2e66-436e-80aa-676260ad5697,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-c4acd174-7cf9-4e66-8e2a-6fef81d3d394,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-5a86a886-ff22-45a4-8f2b-4585ece8e9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-90c649c4-8221-4f00-a74d-6f0ea280c028,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-7db366fe-880e-4f80-9c74-f3c3ac54e9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46594,DS-cb12dd62-d024-4e17-b538-53546863ffa9,DISK], DatanodeInfoWithStorage[127.0.0.1:41862,DS-6c543c5e-9756-4a3a-a57f-74dda88d7a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39586,DS-bc96b53e-09cd-4d49-a1d9-8cbe458231c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 1 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 6521
